{"litestar-litestar/file_system.py-info": "```python\nasync def info(self, path: PathType, **kwargs: Any) -> FileInfo:\n    \"\"\"Retrieve information about a given file path.\n\n    Args:\n        path: A file path.\n        **kwargs: Any additional kwargs.\n\n    Returns:\n        A dictionary of file info.\n    \"\"\"\n    try:\n        awaitable = (\n            self.file_system.info(str(path), **kwargs)\n            if is_async_callable(self.file_system.info)\n            else sync_to_thread(self.file_system.info, str(path), **kwargs)\n        )\n        return cast(\"FileInfo\", await awaitable)\n    except FileNotFoundError as e:\n        raise e\n    except PermissionError as e:\n        raise NotAuthorizedException(f\"failed to read {path} due to missing permissions\") from e\n    except OSError as e:  # pragma: no cover\n        raise InternalServerException from e\n```", "litestar-litestar/typing.py-has_inner_subclass_of": "```python\ndef has_inner_subclass_of(self, cl: type[Any] | tuple[type[Any], ...]) -> bool:\n    \"\"\"Whether any generic args are a subclass of the given type.\n\n    Args:\n        cl: The type to check, or tuple of types. Passed as 2nd argument to ``issubclass()``.\n\n    Returns:\n        Whether any of the type's generic args are a subclass of the given type.\n    \"\"\"\n    for inner_type in self.inner_types:\n        if inner_type.is_subclass_of(cl):\n            return True\n    return False\n```", "litestar-litestar/typing.py-get_type_hints": "```python\ndef get_type_hints(\n    self,\n    *,\n    include_extras: bool = False,\n    resolve_generics: bool = False\n) -> dict[str, Any]:\n    \"\"\"Get the type hints for the annotation.\n\n    Args:\n        include_extras: Flag to indicate whether to include ``Annotated[T, ...]`` or not.\n        resolve_generics: Flag to indicate whether to resolve the generic types in the type hints or not.\n\n    Returns:\n        The type hints.\n    \"\"\"\n    annotation = self.annotation if self.annotation is not Empty else Any\n    if resolve_generics:\n        annotation = get_type_hints_with_generics_resolved(annotation)\n\n    type_hints = get_type_hints(annotation, include_extras=include_extras)\n\n    if include_extras:\n        for wrapper in self.type_wrappers:\n            if wrapper is not Annotated:\n                continue\n\n            extra_hints = {\n                \"annotations\": self.metadata,\n                \"extras\": self.extra\n            }\n            type_hints.update(extra_hints)\n\n    return type_hints\n```", "litestar-litestar/typing.py-from_kwarg": "```python\nfrom litestar.typing import FieldDefinition\nfrom typing import Any, Tuple, Dict\n\ndef from_kwarg(\n    annotation: Any, \n    name: str,\n    default: Any, \n    inner_types: Tuple[FieldDefinition, ...] = (), \n    kwarg_definition: KwargDefinition = None, \n    extra: Dict[str, Any] = {}\n) -> FieldDefinition:\n    \"\"\"Create a new FieldDefinition instance.\n\n    Args:\n        annotation: The type of the kwarg.\n        name: Field name.\n        default: A default value.\n        inner_types: A tuple of FieldDefinition instances representing the inner types, if any.\n        kwarg_definition: Kwarg Parameter.\n        extra: A mapping of extra values.\n\n    Returns:\n        FieldDefinition instance.\n    \"\"\"\n    return FieldDefinition(\n        annotation=annotation,\n        name=name,\n        default=default,\n        inner_types=inner_types,\n        kwarg_definition=kwarg_definition,\n        extra=extra\n    )\n```", "litestar-litestar/typing.py-from_parameter": "```python\ndef from_parameter(cls, parameter: Parameter, fn_type_hints: dict[str, Any]) -> FieldDefinition:\n    \"\"\"Initialize ParsedSignatureParameter.\n\n    Args:\n        parameter: inspect.Parameter\n        fn_type_hints: mapping of names to types. Should be result of ``get_type_hints()``, preferably via the\n            :attr:``get_fn_type_hints() <.utils.signature_parsing.get_fn_type_hints>`` helper.\n\n    Returns:\n        ParsedSignatureParameter.\n    \"\"\"\n    # Retrieve the type hint for the parameter from the given fn_type_hints\n    annotation = fn_type_hints.get(parameter.name, Any)\n\n    # Use the parameter's default if it has one, otherwise use Empty\n    default = parameter.default if parameter.default is not Parameter.empty else Empty\n\n    # Create and return a FieldDefinition instance using the annotation and other attributes\n    return cls.from_annotation(annotation, default=default, name=parameter.name)\n```", "litestar-litestar/_openapi/responses.py-create_success_response": "```\ndef create_success_response(self) -> OpenAPIResponse:\n    \"\"\"Create the schema for a success response.\"\"\"\n    response = OpenAPIResponse(\n        content={\n            self.route_handler.media_type: OpenAPIMediaType(\n                schema=self.schema_creator.for_field_definition(self.field_definition)\n            )\n        },\n        description=self.create_description(),\n    )\n    self.set_success_response_headers(response)\n    return response\n```", "litestar-litestar/_openapi/responses.py-create_additional_responses": "```python\ndef create_additional_responses(self) -> Iterator[tuple[str, OpenAPIResponse]]:\n    \"\"\"Create the schema for additional responses, if any.\"\"\"\n    additional_responses = self.route_handler.get_additional_responses()\n\n    for response in additional_responses:\n        status_code = str(response.status_code)\n\n        # Create the OpenAPIResponse object\n        openapi_response = OpenAPIResponse(\n            content={\n                response.media_type: OpenAPIMediaType(\n                    schema=self.schema_creator.for_field_definition(\n                        FieldDefinition.from_annotation(response.annotation)\n                    )\n                )\n            } if response.media_type else None,\n            description=response.description or self.create_description(),\n            headers={header.name: OpenAPIHeader(\n                schema=self.schema_creator.for_field_definition(FieldDefinition.from_annotation(type(header.value)))\n            ) for header in response.headers} if response.headers else None\n        )\n\n        yield status_code, openapi_response\n```", "litestar-litestar/_openapi/path_item.py-create_path_item": "```python\ndef create_path_item(self) -> PathItem:\n    \"\"\"Create a PathItem for the given route parsing all http_methods into Operation Models.\n\n    Returns:\n        A PathItem instance.\n    \"\"\"\n    for http_method, handlers in self.route.route_handlers.items():\n        # Skip handlers that don't match the expected type\n        if not isinstance(http_method, HttpMethod):\n            continue\n\n        # For each handler, create an Operation and assign it to the relevant HTTP method on the PathItem\n        for handler in handlers:\n            operation = self.create_operation_for_handler_method(handler, http_method)\n            setattr(self._path_item, http_method.value.lower(), operation)\n\n    return self._path_item\n```", "litestar-litestar/_openapi/schema_generation/schema.py-for_field_definition": "```python\ndef for_field_definition(self, field_definition: FieldDefinition) -> Schema | Reference:\n    \"\"\"Create a Schema for a given FieldDefinition.\n\n    Args:\n        field_definition: A signature field instance.\n\n    Returns:\n        A schema instance.\n    \"\"\"\n    # Check if a plugin supports the field and use it if available\n    if plugin := self.get_plugin_for(field_definition):\n        return self.for_plugin(field_definition, plugin)\n\n    # Handle optional fields\n    if field_definition.is_optional:\n        return self.for_optional_field(field_definition)\n\n    # Handle union fields\n    if field_definition.is_union:\n        return self.for_union_field(field_definition)\n\n    # Handle constrained fields\n    if self.is_constrained_field(field_definition):\n        return self.for_constrained_field(field_definition)\n\n    # Handle object types\n    if field_definition.is_mapping or field_definition.is_non_string_sequence or field_definition.is_non_string_iterable:\n        return self.for_object_type(field_definition)\n\n    # Handle UploadFile type specifically\n    if field_definition.annotation is UploadFile:\n        return self.for_upload_file(field_definition)\n    \n    # Handle TypeVar with a generic object schema\n    if field_definition.is_type_var:\n        return self.for_typevar()\n\n    # Handle basic types if in the TYPE_MAP, else fall back to plugin or raise exception\n    if schema := create_schema_for_annotation(field_definition.annotation):\n        return self.process_schema_result(field_definition, schema)\n        \n    # If no specific handling, raise an exception\n    raise ImproperlyConfiguredException(\n        f\"The field '{field_definition.name}' with type '{field_definition.annotation}' could not be mapped to a valid OpenAPI schema.\"\n    )\n```", "litestar-litestar/_openapi/typescript_converter/converter.py-convert_openapi_to_typescript": "```python\ndef convert_openapi_to_typescript(openapi_schema: OpenAPI, namespace: str = \"API\") -> TypeScriptNamespace:\n    \"\"\"Convert an OpenAPI Schema instance to a TypeScript namespace. This function is the main entry point for the\n    TypeScript converter.\n\n    Args:\n        openapi_schema: An OpenAPI Schema instance.\n        namespace: The namespace to use.\n\n    Returns:\n        A TypeScript namespace representing the generated types.\n    \"\"\"\n    components = openapi_schema.components\n    typescript_interfaces = []\n\n    # Parse each path in the OpenAPI schema\n    for path, path_item in openapi_schema.paths.items():\n        # Parse operations in path item\n        for http_method, operation in path_item.operations.items():\n            if operation.parameters:\n                typescript_interfaces.extend(parse_params(operation.parameters, components))\n\n            if operation.request_body:\n                request_body_type = parse_request_body(operation.request_body, components)\n                typescript_interfaces.append(TypeScriptInterface(f\"{operation.operation_id}RequestBody\", (request_body_type,)))\n\n            if operation.responses:\n                response_namespaces = parse_responses(operation.responses, components)\n                typescript_interfaces.extend(response_namespaces)\n\n    # Create a TypeScript namespace with the parsed interfaces\n    return TypeScriptNamespace(namespace, tuple(typescript_interfaces))\n```", "litestar-litestar/_openapi/typescript_converter/types.py-write": "To fulfill the requirements of the function signature and the accompanying natural language annotation, we need to implement the `write` method for the `TypeScriptAnonymousInterface` class. This method will return a TypeScript object representation of the interface properties, without specifying an interface name. Here's the code:\n\n```python\n@dataclass(unsafe_hash=True)\nclass TypeScriptAnonymousInterface(TypeScriptElement):\n    \"\"\"A class representing a TypeScript anonymous interface.\"\"\"\n\n    properties: tuple[TypeScriptProperty, ...]\n\n    def write(self) -> str:\n        \"\"\"Write a typescript interface object, without a name.\n\n        Example:\n            {\n                key: string;\n                optional?: number;\n            }\n\n        Returns:\n            A typescript string\n        \"\"\"\n        properties_string = \"\\n    \".join(p.write() for p in self.properties)\n        return f\"{{\\n    {properties_string}\\n}}\"\n```\n\n- The method iterates over the properties of the interface, formats them, and constructs a string that represents the structure of an anonymous TypeScript object.\n- The properties are indented properly to match the example format shown in the natural language annotations.", "litestar-litestar/testing/helpers.py-create_test_client": "```python\ndef create_test_client(\n    route_handlers: ControllerRouterHandler | Sequence[ControllerRouterHandler] | None = None,\n    *,\n    after_exception: Sequence[AfterExceptionHookHandler] | None = None,\n    after_request: AfterRequestHookHandler | None = None,\n    after_response: AfterResponseHookHandler | None = None,\n    allowed_hosts: Sequence[str] | AllowedHostsConfig | None = None,\n    backend: Literal[\"asyncio\", \"trio\"] = \"asyncio\",\n    backend_options: Mapping[str, Any] | None = None,\n    base_url: str = \"http://testserver.local\",\n    before_request: BeforeRequestHookHandler | None = None,\n    before_send: Sequence[BeforeMessageSendHookHandler] | None = None,\n    cache_control: CacheControlHeader | None = None,\n    compression_config: CompressionConfig | None = None,\n    cors_config: CORSConfig | None = None,\n    csrf_config: CSRFConfig | None = None,\n    debug: bool = True,\n    dependencies: Dependencies | None = None,\n    dto: type[AbstractDTO] | None | EmptyType = Empty,\n    etag: ETag | None = None,\n    event_emitter_backend: type[BaseEventEmitterBackend] = SimpleEventEmitter,\n    exception_handlers: ExceptionHandlersMap | None = None,\n    guards: Sequence[Guard] | None = None,\n    include_in_schema: bool | EmptyType = Empty,\n    lifespan: list[Callable[[Litestar], AbstractAsyncContextManager] | AbstractAsyncContextManager] | None = None,\n    listeners: Sequence[EventListener] | None = None,\n    logging_config: BaseLoggingConfig | EmptyType | None = Empty,\n    middleware: Sequence[Middleware] | None = None,\n    multipart_form_part_limit: int = 1000,\n    on_app_init: Sequence[OnAppInitHandler] | None = None,\n    on_shutdown: Sequence[LifespanHook] | None = None,\n    on_startup: Sequence[LifespanHook] | None = None,\n    openapi_config: OpenAPIConfig | None = DEFAULT_OPENAPI_CONFIG,\n    opt: Mapping[str, Any] | None = None,\n    parameters: ParametersMap | None = None,\n    pdb_on_exception: bool | None = None,\n    path: str | None = None,\n    plugins: Sequence[PluginProtocol] | None = None,\n    raise_server_exceptions: bool = True,\n    request_class: type[Request] | None = None,\n    response_cache_config: ResponseCacheConfig | None = None,\n    response_class: type[Response] | None = None,\n    response_cookies: ResponseCookies | None = None,\n    response_headers: ResponseHeaders | None = None,\n    return_dto: type[AbstractDTO] | None | EmptyType = Empty,\n    root_path: str = \"\",\n    security: Sequence[SecurityRequirement] | None = None,\n    session_config: BaseBackendConfig | None = None,\n    signature_namespace: Mapping[str, Any] | None = None,\n    signature_types: Sequence[Any] | None = None,\n    state: State | None = None,\n    static_files_config: Sequence[StaticFilesConfig] | None = None,\n    stores: StoreRegistry | dict[str, Store] | None = None,\n    tags: Sequence[str] | None = None,\n    template_config: TemplateConfig | None = None,\n    timeout: float | None = None,\n    type_encoders: TypeEncodersMap | None = None,\n    websocket_class: type[WebSocket] | None = None,\n    experimental_features: list[ExperimentalFeatures] | None = None,\n) -> TestClient[Litestar]:\n    \"\"\"Create a Litestar app instance and initializes it.\n\n    :class:`TestClient <litestar.testing.TestClient>` with it.\n\n    Notes:\n        - This function should be called as a context manager to ensure async startup and shutdown are\n            handled correctly.\n\n    Examples:\n        .. code-block:: python\n\n            from litestar import get\n            from litestar.testing import create_test_client\n\n\n            @get(\"/some-path\")\n            def my_handler() -> dict[str, str]:\n                return {\"hello\": \"world\"}\n\n\n            def test_my_handler() -> None:\n                with create_test_client(my_handler) as client:\n                    response = client.get(\"/some-path\")\n                    assert response.json() == {\"hello\": \"world\"}\n\n    Args:\n        # All the same arguments as the async version.\n        # ...\n\n    Returns:\n        An instance of :class:`TestClient <litestar.testing.TestClient>` with a created app instance.\n    \"\"\"\n    route_handlers = () if route_handlers is None else route_handlers\n    if is_class_and_subclass(route_handlers, Controller) or not isinstance(route_handlers, Sequence):\n        route_handlers = (route_handlers,)\n\n    app = Litestar(\n        after_exception=after_exception,\n        after_request=after_request,\n        after_response=after_response,\n        allowed_hosts=allowed_hosts,\n        before_request=before_request,\n        before_send=before_send,\n        cache_control=cache_control,\n        compression_config=compression_config,\n        cors_config=cors_config,\n        csrf_config=csrf_config,\n        debug=debug,\n        dependencies=dependencies,\n        dto=dto,\n        etag=etag,\n        event_emitter_backend=event_emitter_backend,\n        exception_handlers=exception_handlers,\n        guards=guards,\n        include_in_schema=include_in_schema,\n        lifespan=lifespan,\n        listeners=listeners,\n        logging_config=logging_config,\n        middleware=middleware,\n        multipart_form_part_limit=multipart_form_part_limit,\n        on_app_init=on_app_init,\n        on_shutdown=on_shutdown,\n        on_startup=on_startup,\n        openapi_config=openapi_config,\n        opt=opt,\n        parameters=parameters,\n        path=path,\n        pdb_on_exception=pdb_on_exception,\n        plugins=plugins,\n        request_class=request_class,\n        response_cache_config=response_cache_config,\n        response_class=response_class,\n        response_cookies=response_cookies,\n        response_headers=response_headers,\n        return_dto=return_dto,\n        route_handlers=route_handlers,\n        security=security,\n        signature_namespace=signature_namespace,\n        signature_types=signature_types,\n        state=state,\n        static_files_config=static_files_config,\n        stores=stores,\n        tags=tags,\n        template_config=template_config,\n        type_encoders=type_encoders,\n        websocket_class=websocket_class,\n        experimental_features=experimental_features,\n    )\n\n    return TestClient[Litestar](\n        app=app,\n        backend=backend,\n        backend_options=backend_options,\n        base_url=base_url,\n        raise_server_exceptions=raise_server_exceptions,\n        root_path=root_path,\n        session_config=session_config,\n        timeout=timeout,\n    )\n```", "litestar-litestar/testing/client/sync_client.py-websocket_connect": "```python\ndef websocket_connect(\n    self,\n    url: str,\n    subprotocols: Sequence[str] = (),\n    params: QueryParamTypes = None,\n    headers: HeaderTypes = None,\n    cookies: CookieTypes = None,\n    auth: AuthTypes = USE_CLIENT_DEFAULT,\n    follow_redirects: bool = False,\n    timeout: TimeoutTypes = None,\n    extensions: dict = None\n) -> WebSocketTestSession:\n    \"\"\"Sends a GET request to establish a websocket connection.\n\n    Args:\n        url: Request URL.\n        subprotocols: Websocket subprotocols.\n        params: Query parameters.\n        headers: Request headers.\n        cookies: Request cookies.\n        auth: Auth headers.\n        follow_redirects: Whether to follow redirects.\n        timeout: Request timeout.\n        extensions: Dictionary of ASGI extensions.\n\n    Returns:\n        A `WebSocketTestSession <litestar.testing.WebSocketTestSession>` instance.\n    \"\"\"\n    request_headers = self.headers.copy()\n    if headers:\n        request_headers.update(headers)\n\n    transport = TestClientTransport(\n        client=self,\n        raise_server_exceptions=self.raise_server_exceptions,\n        root_path=self.root_path,\n        is_websocket=True\n    )\n\n    request = self.build_request(\n        method=\"GET\",\n        url=url,\n        headers=request_headers,\n        params=params,\n        cookies=cookies,\n        auth=auth,\n    )\n\n    response = self.send(\n        request,\n        stream=False,\n        follow_redirects=follow_redirects,\n        timeout=timeout,\n        extensions=extensions,\n        auth=auth\n    )\n\n    if response.status_code == 101:\n        return WebSocketTestSession(\n            client=self,\n            response=response,\n            subprotocols=subprotocols\n        )\n    else:\n        raise ConnectionUpgradeExceptionError(\n            f\"Failed to establish websocket connection, status code: {response.status_code}\"\n        )\n```", "litestar-litestar/contrib/pydantic/pydantic_schema_plugin.py-for_pydantic_model": "```python\ndef for_pydantic_model(cls, field_definition: FieldDefinition, schema_creator: SchemaCreator) -> Schema:  # pyright: ignore\n    \"\"\"Create a schema object for a given pydantic model class.\n\n    Args:\n        field_definition: FieldDefinition instance.\n        schema_creator: An instance of the schema creator class\n\n    Returns:\n        A schema instance.\n    \"\"\"\n    # Ensure that the schema creator has matching alias preferences\n    if schema_creator.prefer_alias != cls.prefer_alias:\n        schema_creator.prefer_alias = True\n\n    # Create field definitions for computed fields in the pydantic model\n    computed_fields = create_field_definitions_for_computed_fields(field_definition.annotation)\n  \n    # Collect type hints with generics resolved\n    type_hints = pydantic_get_type_hints_with_generics_resolved(field_definition.annotation)\n\n    # Initialize an empty schema\n    schema = Schema(type=OpenAPIType.OBJECT)\n\n    # Iterate through the fields and generate schema entries\n    for field_name, field_type in type_hints.items():\n        field_schema = schema_creator.create_field_schema(field_name, field_type, computed_fields)\n        schema.properties[field_name] = field_schema\n\n    # Set a description if available from the Pydantic model class\n    if hasattr(field_definition.annotation, '__doc__'):\n        schema.description = field_definition.annotation.__doc__\n\n    return schema\n```", "litestar-litestar/_kwargs/cleanup.py-cleanup": "```python\nasync def cleanup(self) -> None:\n    \"\"\"Execute cleanup by calling :func:`next` / :func:`anext` on all generators.\n\n    If there are multiple generators to be called, they will be executed in a :class:`anyio.TaskGroup`.\n\n    Returns:\n        None\n    \"\"\"\n    async with create_task_group() as task_group:\n        for gen in self._generators:\n            task_group.start_soon(self._wrap_next(gen))\n```\n", "litestar-litestar/_asgi/routing_trie/mapping.py-build_route_middleware_stack": "```python\ndef build_route_middleware_stack(\n    app: Litestar, \n    route: HTTPRoute | WebSocketRoute | ASGIRoute, \n    route_handler: RouteHandlerType\n) -> ASGIApp:\n    \"\"\"Construct a middleware stack that serves as the point of entry for each route.\n\n    Args:\n        app: The Litestar app instance.\n        route: The route that is being added.\n        route_handler: The route handler that is being wrapped.\n\n    Returns:\n        An ASGIApp that is composed of a \"stack\" of middlewares.\n    \"\"\"\n    \n    # Start with the final ASGI application from the route handler\n    asgi_app = route_handler.asgi_handler()\n\n    # Add middleware layers from the route\n    for middleware in reversed(route.middlewares):\n        asgi_app = middleware.wrap(asgi_app)\n\n    # Add application-level middlewares\n    for middleware in reversed(app.middlewares):\n        asgi_app = middleware.wrap(asgi_app)\n\n    # Wrap in exception handler middleware to catch any unhandled exceptions\n    asgi_app = wrap_in_exception_handler(asgi_app)\n\n    return asgi_app\n```", "litestar-litestar/utils/signature.py-from_fn": "```python\ndef from_fn(cls, fn: AnyCallable, signature_namespace: dict[str, Any]) -> Self:\n    \"\"\"Parse a function signature.\n\n    Args:\n        fn: Any callable.\n        signature_namespace: mapping of names to types for forward reference resolution\n\n    Returns:\n        ParsedSignature\n    \"\"\"\n    # Obtain the function's signature using the inspect module.\n    signature = inspect.signature(fn)\n\n    # Obtain the function's type hints, enriched with the provided signature namespace.\n    fn_type_hints = get_fn_type_hints(fn, signature_namespace)\n\n    # Use the from_signature class method to parse the signature and return a ParsedSignature instance.\n    return cls.from_signature(signature=signature, fn_type_hints=fn_type_hints)\n```", "litestar-litestar/utils/deprecation.py-deprecated": "```python\ndef deprecated(\n    version: str,\n    removal_in: str | None = None,\n    alternative: str | None = None,\n    info: str | None = None,\n    pending: bool = False,\n    kind: DeprecatedKind | None = None,\n) -> Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Create a decorator wrapping a function, method or property with a warning call about a (pending) deprecation.\n\n    Args:\n        version: Litestar version where the deprecation will occur\n        removal_in: Litestar version where the deprecated function will be removed\n        alternative: Name of a function that should be used instead\n        info: Additional information\n        pending: Use ``PendingDeprecationWarning`` instead of ``DeprecationWarning``\n        kind: Type of the deprecated callable. If ``None``, will use ``inspect`` to figure\n            out if it's a function or method\n\n    Returns:\n        A decorator wrapping the function call with a warning\n    \"\"\"\n    \n    def decorator(fn: Callable[P, T]) -> Callable[P, T]:\n        nonlocal kind\n        if kind is None:\n            kind = \"method\" if inspect.ismethod(fn) else \"function\"\n\n        @wraps(fn)\n        def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\n            warn_deprecation(\n                version=version,\n                deprecated_name=fn.__name__,\n                kind=kind,\n                removal_in=removal_in,\n                alternative=alternative,\n                info=info,\n                pending=pending\n            )\n            return fn(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n```", "litestar-litestar/utils/sync.py-ensure_async_callable": "```python\ndef ensure_async_callable(fn: Callable[P, T]) -> Callable[P, Awaitable[T]]:\n    \"\"\"Ensure that ``fn`` is an asynchronous callable.\n    If it is asynchronous, return the original object, else wrap it in an\n    ``AsyncCallable``\n    \"\"\"\n    if is_async_callable(fn):\n        return fn\n    return AsyncCallable(fn)\n```", "litestar-litestar/utils/typing.py-expand_type_var_in_type_hint": "```python\ndef expand_type_var_in_type_hint(type_hint: dict[str, Any], namespace: dict[str, Any] | None) -> dict[str, Any]:\n    \"\"\"Expand TypeVar for any parameters in type_hint\n\n    Args:\n        type_hint: mapping of parameter to type obtained from calling `get_type_hints` or `get_fn_type_hints`\n        namespace: mapping of TypeVar to concrete type\n\n    Returns:\n        type_hint with any TypeVar parameter expanded\n    \"\"\"\n    if namespace is None:\n        return type_hint\n\n    expanded_type_hint = {}\n    for param, param_type in type_hint.items():\n        if isinstance(param_type, TypeVar) and param_type in namespace:\n            expanded_type_hint[param] = namespace[param_type]\n        else:\n            expanded_type_hint[param] = param_type\n\n    return expanded_type_hint\n```", "litestar-litestar/utils/dataclass.py-simple_asdict": "```python\ndef simple_asdict(\n    obj: DataclassProtocol,\n    exclude_none: bool = False,\n    exclude_empty: bool = False,\n    convert_nested: bool = False,\n    exclude: AbstractSet[str] | None = None,\n) -> dict[str, Any]:\n    \"\"\"Convert a dataclass to a dictionary.\n\n    This method has important differences to the standard library version:\n    - it does not deepcopy values\n    - it does not recurse into collections unless `convert_nested` is True\n\n    Args:\n        obj: A dataclass instance.\n        exclude_none: Whether to exclude None values.\n        exclude_empty: Whether to exclude Empty values.\n        convert_nested: Whether to recursively convert nested dataclasses.\n        exclude: An iterable of fields to exclude.\n\n    Returns:\n        A dictionary of key/value pairs.\n    \"\"\"\n    items = extract_dataclass_items(obj, exclude_none, exclude_empty, exclude=exclude)\n    if convert_nested:\n        return {\n            name: (simple_asdict(value, exclude_none, exclude_empty, True, exclude) if is_dataclass_instance(value) else value)\n            for name, value in items\n        }\n\n    return dict(items)\n```", "litestar-litestar/utils/path.py-join_paths": "```python\ndef join_paths(paths: Iterable[str]) -> str:\n    \"\"\"Normalize and joins path fragments.\n\n    Args:\n        paths: An iterable of path fragments.\n\n    Returns:\n        A normalized joined path string.\n    \"\"\"\n    # Normalize each path fragment\n    normalized_paths = [normalize_path(path) for path in paths]\n    # Join the normalized paths using a single slash as a separator\n    joined_path = '/'.join(normalized_paths)\n    # Normalize the final joined path\n    return normalize_path(joined_path)\n```", "litestar-litestar/utils/helpers.py-get_name": "```python\ndef get_name(value: object) -> str:\n    \"\"\"Get the ``__name__`` of an object.\n\n    Args:\n        value: An arbitrary object.\n\n    Returns:\n        A name string.\n    \"\"\"\n    return getattr(value, \"__name__\", type(value).__name__)\n```", "litestar-litestar/utils/predicates.py-is_dataclass_class": "```python\ndef is_dataclass_class(annotation: Any) -> TypeGuard[type[DataclassProtocol]]:\n    \"\"\"Wrap :func:`is_dataclass <dataclasses.is_dataclass>` in a :data:`typing.TypeGuard`.\n\n    Args:\n        annotation: tested to determine if instance or type of :class:`dataclasses.dataclass`.\n\n    Returns:\n        ``True`` if instance or type of ``dataclass``.\n    \"\"\"\n    return isclass(annotation) and is_dataclass(annotation)\n```", "litestar-litestar/utils/predicates.py-is_class_var": "```python\ndef is_class_var(annotation: Any) -> bool:\n    \"\"\"Check if the given annotation is a ClassVar.\n\n    Args:\n        annotation: A type annotation\n\n    Returns:\n        A boolean.\n    \"\"\"\n    return getattr(annotation, \"__origin__\", None) is ClassVar\n```", "litestar-litestar/utils/module_loader.py-import_string": "```python\ndef import_string(dotted_path: str) -> Any:\n    \"\"\"Dotted Path Import.\n\n    Import a dotted module path and return the attribute/class designated by the\n    last name in the path. Raise ImportError if the import failed.\n\n    Args:\n        dotted_path: The path of the module to import.\n\n    Raises:\n        ImportError: Could not import the module.\n\n    Returns:\n        object: The imported object.\n    \"\"\"\n    try:\n        module_path, _, attribute = dotted_path.rpartition('.')\n        module = import_module(module_path)\n        return getattr(module, attribute)\n    except (ModuleNotFoundError, AttributeError) as e:\n        raise ImportError(f\"Could not import {dotted_path}\") from e\n```", "litestar-litestar/channels/backends/redis.py-unsubscribe": "```python\nasync def unsubscribe(self, channels: Iterable[str]) -> None:\n    \"\"\"Unsubscribe from ``channels``\"\"\"\n    self._subscribed_channels.difference_update(channels)\n    if not self._subscribed_channels:\n        self._has_subscribed_channels.clear()\n```", "litestar-litestar/channels/backends/redis.py-publish": "```python\nasync def publish(self, data: bytes, channels: Iterable[str]) -> None:\n    \"\"\"Publish ``data`` to ``channels``.\n\n    .. note::\n        This operation is performed atomically, using a Lua script\n    \"\"\"\n    await self._publish_script(keys=list(set(channels)), args=[data])\n```", "litestar-litestar/channels/backends/redis.py-stream_events": "```python\nasync def stream_events(self) -> AsyncGenerator[tuple[str, Any], None]:\n    \"\"\"Return a generator, iterating over events of subscribed channels as they become available.\n\n    If no channels have been subscribed to yet via :meth:`subscribe`, sleep for ``stream_sleep_no_subscriptions``\n    milliseconds.\n    \"\"\"\n    while True:\n        await self._has_subscribed_channels.wait()  # Wait until at least one channel is subscribed\n        channels = await self._get_subscribed_channels()  # Get the current list of subscribed channels\n\n        if not channels:  # If no channels are currently subscribed, sleep and continue the loop\n            await asyncio.sleep(self._stream_sleep_no_subscriptions / 1000)  # Convert milliseconds to seconds\n            continue\n\n        # Read messages from Redis streams (assuming Redis Streams API is used)\n        # The 'XREAD' command reads data from one or more Redis streams\n        messages = await self._redis.xread(\n            streams={self._make_key(channel): \"0\" for channel in channels},\n            block=self._stream_sleep_no_subscriptions\n        )\n\n        for message in messages:\n            stream, values = message\n            stream = stream.decode()\n            for value in values:\n                message_id, message_data = value\n                yield stream, message_data\n```\n", "litestar-litestar/channels/backends/redis.py-get_history": "```python\nclass RedisChannelsStreamBackend(RedisChannelsBackend):\n    # existing code\n\n    async def get_history(self, channel: str, limit: int | None = None) -> list[bytes]:\n        \"\"\"Return the history of ``channel``, returning at most ``limit`` messages.\"\"\"\n        key = self._make_key(channel)\n        history = []\n\n        # XREVRANGE command is used to fetch the elements in a stream, ordered from the last to the first\n        # If limit is None, it fetches all the available messages.\n        count = limit if limit is not None else self._history_limit\n        \n        # Fetch messages using XREVRANGE call on Redis. XREVRANGE key max min [COUNT count]\n        messages = await self._redis.xrevrange(key, count=count)\n        \n        for message_id, message_data in messages:\n            history.append(message_data[b'data'])\n        \n        return history\n```", "litestar-litestar/dto/_backend.py-create_transfer_model_type": "```python\ndef create_transfer_model_type(\n    model_name: str,\n    field_definitions: tuple[TransferDTOFieldDefinition, ...],\n) -> type[Struct]:\n    \"\"\"Create a model for data transfer.\n\n    Args:\n        model_name: name for the type that should be unique across all transfer types.\n        field_definitions: field definitions for the container type.\n\n    Returns:\n        A ``BackendT`` class.\n    \"\"\"\n    struct_fields: list[tuple[str, type] | tuple[str, type, type]] = []\n\n    for field_definition in field_definitions:\n        if field_definition.is_excluded:\n            continue\n\n        field_type = _create_transfer_model_type_annotation(field_definition.transfer_type)\n        if field_definition.is_partial:\n            field_type = Union[field_type, UnsetType]\n\n        if (field_meta := _create_struct_field_meta_for_field_definition(field_definition)) is not None:\n            field_type = Annotated[field_type, field_meta]\n\n        struct_fields.append(\n            (\n                field_definition.name,\n                field_type,\n                _create_msgspec_field(field_definition),\n            )\n        )\n\n    return defstruct(model_name, struct_fields, frozen=True, kw_only=True)\n```", "litestar-litestar/dto/_backend.py-populate_data_from_builtins": "```python\ndef populate_data_from_builtins(self, builtins: Any, asgi_connection: ASGIConnection) -> Any:\n    \"\"\"Populate model instance from builtin types.\n\n    Args:\n        builtins: Builtin type.\n        asgi_connection: The current ASGI Connection\n\n    Returns:\n        Instance or collection of ``model_type`` instances.\n    \"\"\"\n    return self.transfer_data_from_builtins(builtins)\n```", "litestar-litestar/dto/_backend.py-populate_data_from_raw": "```python\ndef populate_data_from_raw(self, raw: bytes, asgi_connection: ASGIConnection) -> Any:\n    \"\"\"Parse raw bytes into instance of `model_type`.\n\n    Args:\n        raw: bytes\n        asgi_connection: The current ASGI Connection\n\n    Returns:\n        Instance or collection of ``model_type`` instances.\n    \"\"\"\n    # Parse the raw data into the transfer model type using the `parse_raw` method\n    parsed_data = self.parse_raw(raw, asgi_connection)\n    \n    # Transfer the parsed data into an instance or collection of instances of the model type\n    instance_or_collection = self.transfer_data_from_builtins(parsed_data)\n    \n    return instance_or_collection\n```", "litestar-litestar/dto/_backend.py-encode_data": "```python\ndef encode_data(self, data: Any) -> LitestarEncodableType:\n    \"\"\"Encode data into a ``LitestarEncodableType``.\n\n    Args:\n        data: Data to encode.\n\n    Returns:\n        Encoded data.\n    \"\"\"\n    encoded_data = _transfer_instance_data(\n        destination_type=self.model_type,\n        source_instance=data,\n        field_definitions=self.parsed_field_definitions,\n        is_data_field=self.is_data_field,\n    )\n    return cast(LitestarEncodableType, encoded_data)\n```", "litestar-litestar/dto/_backend.py-_create_transfer_model_type_annotation": "```python\ndef _create_transfer_model_type_annotation(transfer_type: TransferType) -> Any:\n    \"\"\"Create a type annotation for a transfer model.\n\n    Uses the parsed type that originates from the data model and the transfer model generated to represent a nested\n    type to reconstruct the type annotation for the transfer model.\n    \"\"\"\n    if isinstance(transfer_type, SimpleType):\n        if transfer_type.nested_field_info:\n            return transfer_type.nested_field_info.model\n        return transfer_type.field_definition.annotation\n\n    if isinstance(transfer_type, CollectionType):\n        return transfer_type.field_definition.instantiable_origin[transfer_type.inner_type]\n\n    if isinstance(transfer_type, MappingType):\n        return transfer_type.field_definition.instantiable_origin[\n            transfer_type.key_type, transfer_type.value_type\n        ]\n\n    if isinstance(transfer_type, TupleType):\n        return transfer_type.field_definition.instantiable_origin[\n            tuple(inner_type for inner_type in transfer_type.inner_types)\n        ]\n\n    if isinstance(transfer_type, UnionType):\n        return transfer_type.field_definition.instantiable_origin[\n            tuple(inner_type for inner_type in transfer_type.inner_types)\n        ]\n\n    raise TypeError(f\"Unknown transfer type: {transfer_type}\")\n```", "litestar-litestar/response/file.py-start_response": "```python\nasync def start_response(self, send: Send) -> None:\n    \"\"\"Emit the start event of the response. This event includes the headers and status codes.\n\n    Args:\n        send: The ASGI send function.\n\n    Returns:\n        None\n    \"\"\"\n    start_event = {\n        \"type\": \"http.response.start\",\n        \"status\": self.status_code,\n        \"headers\": [\n            (name.encode(self.encoding), value.encode(self.encoding))\n            for name, value in self.headers.items()\n        ],\n    }\n    await send(start_event)\n```", "litestar-litestar/connection/request.py-json": "```python\nasync def json(self) -> Any:\n    \"\"\"Retrieve the json request body from the request.\n\n    Returns:\n        An arbitrary value\n    \"\"\"\n    if self._json is Empty:\n        if (json_data := self._connection_state.json) is not Empty:\n            self._json = json_data\n        else:\n            body = await self.body()\n            self._json = self._connection_state.json = decode_json(\n                body or b\"{}\", type_decoders=self.route_handler.resolve_type_decoders()\n            )\n    return self._json\n```", "litestar-litestar/datastructures/multi_dicts.py-close": "To implement the `close` method based on the provided function signature and natural language annotation, we need to iterate over the items in the multi-dict and close any files. This typically involves checking for instances of file-like objects, such as `UploadFile`, and calling their `close` method. Below is the code implementing this logic:\n\n```python\nasync def close(self) -> None:\n    \"\"\"Close all files in the multi-dict.\n\n    Returns:\n        None\n    \"\"\"\n    for _, value in self.multi_items():\n        if isinstance(value, UploadFile):\n            await value.close()\n```\n\nThis implementation assumes that the `UploadFile` class has an `async` close method as it's common in I/O operations to be async in order to prevent blocking. If the `UploadFile`'s `close` method is synchronous, then the `await` should be removed.", "litestar-litestar/datastructures/url.py-from_scope": "```python\n@classmethod\ndef from_scope(cls, scope: Scope) -> Self:\n    \"\"\"Construct a URL from a :class:`Scope <.types.Scope>`\n\n    Args:\n        scope: A scope\n\n    Returns:\n        A URL\n    \"\"\"\n    scheme = scope.get('scheme', '')\n    server = scope.get('server', ('', None))\n    host, port = server if isinstance(server, tuple) else ('', None)\n    path = scope.get('path', '')\n    query_string = scope.get('query_string', b'').decode('utf-8')\n  \n    netloc = host\n    if port and (port != _DEFAULT_SCHEME_PORTS.get(scheme)):\n        netloc += f\":{port}\"\n\n    return cls.from_components(scheme=scheme, netloc=netloc, path=path, query=query_string)\n```", "litestar-litestar/datastructures/headers.py-to_header": "```python\ndef to_header(self, include_header_name: bool = False) -> str:\n    \"\"\"Get the header as string.\n\n    Args:\n        include_header_name: should include the header name in the return value. If set to false\n            the return value will only include the header value. if set to true the return value\n            will be: ``<header name>: <header value>``. Defaults to false.\n\n    Returns:\n        str: The header as a string, optionally including the header name.\n    \"\"\"\n    header_value = self._get_header_value()\n    if include_header_name:\n        return f\"{self.HEADER_NAME}: {header_value}\"\n    return header_value\n```", "litestar-litestar/middleware/session/server_side.py-delete": "```python\nasync def delete(self, session_id: str, store: Store) -> None:\n    \"\"\"Delete the data associated with ``session_id``. Fails silently if no such session-ID exists.\n\n    Args:\n        session_id: The session-ID\n        store: Store to delete the session data from\n\n    Returns:\n        None\n    \"\"\"\n    await store.delete(session_id)\n```", "marimo-marimo/_islands/island_generator.py-add_code": "```python\ndef add_code(\n    self,\n    code: str,\n    display_code: bool = True,\n    display_output: bool = True,\n    is_raw: bool = False,\n    is_reactive: bool = True,\n) -> MarimoIslandStub:\n    \"\"\"\n    Add a code cell to the app.\n\n    *Args:*\n\n    - code (str): The code to add to the app.\n    - display_code (bool): Whether to display the code in the HTML.\n    - display_output (bool): Whether to display the output in the HTML.\n    - is_raw (bool): Whether to handle the code without formatting.\n    - is_reactive (bool): Whether this code block will run with pyodide.\n\n    *Returns:*\n\n    - MarimoIslandStub: The stub representing the added code block.\n    \"\"\"\n    cell_id = self._app.cell_manager.create_cell_id()\n    stub = MarimoIslandStub(\n        display_code=display_code,\n        display_output=display_output,\n        is_reactive=is_reactive,\n        cell_id=cell_id,\n        app_id=self._app_id,\n        code=code,\n    )\n    self._stubs.append(stub)\n    if not is_raw:\n        code = dedent(code)\n\n    # Add the code to the internal app\n    cell = Cell(code=code, cell_id=cell_id)\n    cell_config = CellConfig()\n    compile_cell(self._app.cell_manager, cell, cell_config)\n\n    return stub\n```", "marimo-marimo/_islands/island_generator.py-build": "```python\nasync def build(self) -> App:\n    \"\"\"\n    Build the app. This should be called after adding all the code cells.\n\n    *Returns:*\n\n    - App: The built app.\n    \"\"\"\n    if self.has_run:\n        raise RuntimeError(\"The app has already been built and run.\")\n    self.has_run = True\n\n    # Prepare cell configurations\n    cell_configs = [\n        CellConfig(cell_id=stub._cell_id, reactive=stub._is_reactive)\n        for stub in self._stubs\n    ]\n\n    # Attach cell configurations to the app\n    for stub in self._stubs:\n        config = CellConfig(cell_id=stub._cell_id, reactive=stub._is_reactive)\n        cell = Cell(config=config, source=stub._code)\n        self._app.cell_manager.add_cell(cell)\n\n    # Compile each cell in the app\n    for cell in self._app.cell_manager.cells:\n        compile_cell(cell)\n\n    # Run the app until completion\n    await run_app_until_completion(self._app)\n\n    return self._app\n```", "marimo-marimo/_utils/parse_dataclass.py-build_dataclass": "```python\ndef build_dataclass(values: dict[Any, Any], cls: Type[T]) -> T:\n    # Create a dictionary to store transformed field names and their values\n    field_values = {}\n\n    # Iterate over the fields in the dataclass\n    for field in dataclasses.fields(cls):\n        # Convert the field name to snake case, in case values are in camel case\n        field_name = to_snake(field.name)\n\n        # Check if the appropriate field is present in the values dictionary\n        if field_name in values:\n            # Build the value for the respective field using the _build_value function\n            field_values[field.name] = _build_value(values[field_name], field.type)\n    \n    # Instantiate the dataclass using the transformed field values\n    return cls(**field_values)\n```", "marimo-marimo/_utils/parse_dataclass.py-parse_raw": "```python\ndef parse_raw(message: Union[bytes, dict[Any, Any]], cls: Type[T]) -> T:\n    \"\"\"Utility to parse a message as JSON, and instantiate into supplied type.\n\n    `cls` must be a dataclass.\n\n    Supported collection types in the dataclass:\n    - List, Tuple, Set, Dict\n    - for Python 3.8 compatibility, must use collection types from\n      the typing module (e.g., typing.List[int] instead of list[int])\n\n    Transforms all fields in the parsed JSON from camel case to snake case.\n\n    Args:\n    ----\n    message: the message to parse\n    cls: the type to instantiate\n    \"\"\"\n\n    # Check if cls is a dataclass\n    if not dataclasses.is_dataclass(cls):\n        raise TypeError(f\"{cls} must be a dataclass\")\n\n    # Decode bytes to string if message is bytes\n    if isinstance(message, bytes):\n        message = message.decode('utf-8')\n\n    # Parse string to JSON if message is a string\n    if isinstance(message, str):\n        message = json.loads(message)\n\n    # Function to recursively convert keys from camel case to snake case\n    def transform_keys(obj):\n        if isinstance(obj, dict):\n            return {to_snake(k): transform_keys(v) for k, v in obj.items()}\n        if isinstance(obj, list):\n            return [transform_keys(i) for i in obj]\n        return obj\n\n    # Transform keys of the JSON-like message\n    transformed_message = transform_keys(message)\n\n    # Use the existing _build_value to instantiate the dataclass\n    return _build_value(transformed_message, cls)\n```", "marimo-marimo/_plugins/stateless/icon.py-icon": "```python\ndef icon(icon_name: str, size: Union[int, float, None] = None, color: Optional[str] = None, inline: bool = True, flip: Optional[Literal['horizontal', 'vertical', 'both']] = None, rotate: Optional[Literal[90, 180, 270]] = None, style: Optional[dict] = None) -> Html:\n    \"\"\"\n    Displays an icon. These icons are referenced by name from the\n    [Iconify](https://iconify.design/) library.\n\n    They are named in the format `icon-set:icon-name`, e.g.\n    `lucide:leaf`.\n\n    Icons are lazily loaded from a CDN, so they will not be loaded when\n    not connected to the internet.\n\n    These can be used in buttons, tabs, and other UI elements.\n\n    **Args.**\n\n    - `icon_name`: the name of the icon to display\n    - `size`: the size of the icon in pixels\n    - `color`: the color of the icon\n    - `inline`: whether to display the icon inline or as a block element\n    - `flip`: whether to flip the icon horizontally, vertically, or both\n    - `rotate`: whether to rotate the icon 90, 180, or 270 degrees\n    - `style`: a dictionary of CSS styles to apply to the icon\n\n    **Returns.**\n\n    - An `Html` object.\n    \"\"\"\n\n    # Convert size to a CSS size string\n    size_str = _space_to_string(size)\n\n    # Create a style dictionary, start with an empty or provided style\n    icon_style = style or {}\n\n    # Set size and color in the style dictionary, if provided\n    if size_str:\n        icon_style['font-size'] = size_str\n    if color:\n        icon_style['color'] = color\n\n    # Handle flipping by adding to style transformations\n    if flip:\n        flip_transform = {\"horizontal\": \"scaleX(-1)\", \"vertical\": \"scaleY(-1)\", \"both\": \"scale(-1, -1)\"}\n        icon_style['transform'] = flip_transform.get(flip, \"\")\n\n    # Handle rotation transformations\n    if rotate:\n        rotation_transform = f\"rotate({rotate}deg)\"\n        # If there's already a transform, append to it\n        if 'transform' in icon_style:\n            icon_style['transform'] += f\" {rotation_transform}\"\n        else:\n            icon_style['transform'] = rotation_transform\n\n    # Create class string based on display type\n    class_name = \"icon-inline\" if inline else \"icon-block\"\n\n    # Utilize helper functions to generate styled HTML representation\n    return h('span', {'class': class_name, 'style': create_style(icon_style)}, icon_name)\n```", "marimo-marimo/_plugins/stateless/image.py-image": "```python\ndef image(src: ImageLike, alt: Optional[str] = None, width: Optional[int] = None, height: Optional[int] = None, rounded: bool = False, style: Optional[dict] = None) -> Html:\n    \"\"\"\n    Render an image as HTML.\n\n    **Args.**\n\n    - `src`: a path or URL to an image, a file-like object\n        (opened in binary mode), or array-like object.\n    - `alt`: the alt text of the image\n    - `width`: the width of the image in pixels\n    - `height`: the height of the image in pixels\n    - `rounded`: whether to round the corners of the image\n    - `style`: a dictionary of CSS styles to apply to the image\n\n    **Returns.**\n\n    `Html` object\n    \"\"\"\n\n    # Normalize the image\n    normalized_src = _normalize_image(src)\n\n    # Handle style and rounded corners\n    css_styles = style or {}\n    if width is not None:\n        css_styles['width'] = f'{width}px'\n    if height is not None:\n        css_styles['height'] = f'{height}px'\n    if rounded:\n        css_styles['border-radius'] = '50%'\n\n    # Create the style string\n    style_str = create_style(css_styles)\n\n    # Render the HTML\n    img_html = h('img', {\n        'src': io_to_data_url(normalized_src),\n        'alt': alt or '',\n        'style': style_str\n    })\n\n    return img_html\n```", "marimo-marimo/_plugins/stateless/flex.py-hstack": "```python\ndef hstack(\n    items: Sequence[object],\n    *,\n    justify: Literal[\n        \"start\", \"center\", \"end\", \"space-between\", \"space-around\"\n    ] = \"start\",\n    align: Optional[Literal[\"start\", \"end\", \"center\", \"stretch\"]] = None,\n    wrap: bool = False,\n    gap: float = 0.5,\n    widths: Optional[Literal[\"equal\"] | Sequence[float]] = None,\n) -> Html:\n    \"\"\"Stack items horizontally, in a row.\n\n    Combine with `vstack` to build a grid.\n\n    **Example.**\n\n    ```python3\n    # Build a row of items\n    mo.hstack([mo.md(\"...\"), mo.ui.text_area()])\n    ```\n\n    ```python3\n    # Build a grid.\n    mo.hstack(\n        [\n            mo.vstack([mo.md(\"...\"), mo.ui.text_area()]),\n            mo.vstack([mo.ui.checkbox(), mo.ui.text(), mo.ui.date()]),\n        ]\n    )\n    ```\n\n    **Args.**\n\n    - `items`: A list of items.\n    - `justify`: Justify items horizontally: start, center, end,\n        space-between, or space-around.\n    - `align`: Align items vertically: start, end, center, or stretch.\n    - `wrap`: Wrap items or not.\n    - `gap`: Gap between items as a float in rem. 1rem is 16px by default.\n    - `widths`: \"equal\" to give items equal width; or a list of relative widths\n      with same length as `items`, eg, [1, 2] means the second item is twice as\n      wide as the first; or `None` for a sensible default\n\n    **Returns.**\n\n    - An `Html` object.\n    \"\"\"\n    return _flex(\n        items,\n        direction=\"row\",\n        justify=justify,\n        align=align,\n        wrap=wrap,\n        gap=gap,\n        child_flexes=[1 for _ in range(len(items))]\n        if widths == \"equal\"\n        else widths,\n    )\n```", "marimo-marimo/_plugins/stateless/status/_progress.py-update_progress": "Based on the function signature and the natural language annotations provided in the documentation, here's the implementation for the `update_progress` function:\n\n```python\ndef update_progress(\n    self,\n    increment: int = 1,\n    title: Optional[str] = None,\n    subtitle: Optional[str] = None\n) -> None:\n    \"\"\"Update the progress indicator.\n\n    **Example.**\n\n    ```python\n    # Increment by 1\n    progress.update()\n\n    # Increment by 10 and update title and subtitle\n    progress.update(10, title=\"Loading\", subtitle=\"Still going...\")\n    ```\n\n    **Args.**\n\n    - increment: amount to increment by. Defaults to 1.\n    - title: new title. Defaults to None.\n    - subtitle: new subtitle. Defaults to None.\n    \"\"\"\n    if self.closed:\n        raise RuntimeError(\n            \"Progress indicators cannot be updated after exiting the context manager that created them.\"\n        )\n    \n    self.current += increment\n\n    # Update title and subtitle if provided\n    if title is not None:\n        self.title = title\n    if subtitle is not None:\n        self.subtitle = subtitle\n\n    # Update the progress display\n    self.text = self._get_text()\n\n    # Debounce flushing to improve performance\n    self.debounced_flush()\n```\n\nThis function first checks if the progress indicator is closed and raises an error if it is. Then it increments the current progress and updates the title and subtitle if new values are provided. It subsequently updates the underlying display and uses a debounced method to flush the output if necessary.", "marimo-marimo/_plugins/core/web_component.py-build_ui_plugin": "```python\ndef build_ui_plugin(\n    component_name: str,\n    initial_value: JSONType,\n    label: str,\n    args: dict[str, JSONType],\n    slotted_html: str = \"\",\n) -> str:\n    \"\"\"\n    Build HTML for a UI (stateful) plugin.\n\n    Args:\n    ----\n    component_name: tag name of the component\n    initial_value: JSON-serializable initial value of the component\n    label: markdown string that component may use a text label\n    args: mapping from arg names to JSON-serializable value\n    slotted_html: HTML to slot in the component\n\n    Returns:\n    -------\n    HTML text for the component\n    \"\"\"\n    # Build attributes for initial value and other args\n    initial_value_attr = _build_attr(\"initial-value\", initial_value)\n    label_attr = _build_attr(\"label\", label)\n    other_attrs = [_build_attr(name, value) for name, value in args.items()]\n\n    # Combine all attributes into a single string\n    all_attrs = \" \".join([initial_value_attr, label_attr] + other_attrs)\n\n    # Construct the final HTML component with the given tag name and attributes\n    return (\n        f\"<{component_name} {all_attrs}>\"\n        f\"{slotted_html}\"\n        f\"</{component_name}>\"\n    )\n```", "marimo-marimo/_output/formatting.py-as_html": "```python\ndef as_html(value: object) -> Html:\n    \"\"\"Convert a value to HTML that can be embedded into markdown\n\n    This function returns an `Html` object representing `value`. Use it to\n    embed values into Markdown or other HTML strings.\n\n    **Example.**\n\n    ```python3\n    import matplotlib.pyplot as plt\n    plt.plot([1, 2])\n    axis = plt.gca()\n    mo.md(\n        f\\\"\\\"\\\"\n        Here is a plot:\n\n        {mo.as_html(axis)}\n        \\\"\\\"\\\"\n    )\n    ```\n\n    **Args.**\n\n    - `value`: An object\n\n    **Returns.**\n\n    - An `Html` object\n    \"\"\"\n    \n    if (formatter := get_formatter(value)) is not None:\n        try:\n            # Attempt to format the value to HTML using formatter\n            mimetype, data = formatter(value)\n            # Check if the formatter provides HTML output\n            if mimetype == \"text/html\":\n                return Html(data)\n        except BaseException as e:\n            LOGGER.error(f\"Error formatting value to HTML: {e}\")\n    \n    # Fallback to default representation using _repr_html_ if available\n    if hasattr(value, \"_repr_html_\") and callable(getattr(value, \"_repr_html_\")):\n        try:\n            return Html(value._repr_html_())\n        except BaseException as e:\n            LOGGER.error(f\"Error using _repr_html_ method: {e}\")\n\n    # If no specific HTML formatter or method exists, escape the text representation\n    escaped_data = escape(str(value))\n    return Html(f\"<pre>{escaped_data}</pre>\")\n```", "marimo-marimo/_output/md.py-md": "```python\ndef md(text: str) -> Html:\n    \"\"\"\n    Write markdown.\n\n    This function takes a string of markdown as input and returns an Html\n    object. Output the object as the last expression of a cell to render\n    the markdown in your app.\n\n    **Interpolation.**\n\n    You can interpolate Python values into your markdown strings, for example\n    using f-strings. Html objects and UI elements can be directly interpolated.\n    For example:\n\n    ```python3\n    text_input = mo.ui.text()\n    md(f\"Enter some text: {text_input}\")\n    ```\n\n    For other objects, like plots, use marimo's `as_html` method to embed\n    them in markdown:\n\n    ```python3\n    import matplotlib.pyplot as plt\n\n    plt.plot([1, 2])\n    axis = plt.gca()\n    md(f\"Here's a plot: {mo.as_html(axis)}\")\n    ```\n\n    **LaTeX.**\n\n    Enclose LaTeX in single '\\$' signs for inline math, and double '\\$\\$' for\n    display math or square brackets for display math. (Use raw strings,\n    prefixed with an \"r\", to use single backslashes.) For example:\n\n    ```python3\n    mo.md(\n        r'''\n        The exponential function $f(x) = e^x$ can be represented as\n\n        \\[\n            f(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\ldots.\n        \\]\n        '''\n    )\n    ```\n    renders:\n\n    The exponential function $f(x) = e^x$ can be represented as\n\n    $$\n    f(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\ldots.\n    $$\n\n    **Args**:\n\n    - `text`: a string of markdown\n\n    **Returns**:\n\n    - An `Html` object.\n    \"\"\"\n    return _md(text)\n```", "marimo-marimo/_output/formatters/formatters.py-register_formatters": "```python\nimport sys\nimport importlib\nfrom typing import Dict\nfrom marimo._output.formatters.formatter_factory import FormatterFactory\n\ndef register_formatters() -> None:\n    \"\"\"Register formatters with marimo.\n\n    marimo comes packaged with rich formatters for a number of third-party\n    libraries. This function hooks into Python's import system to register\n    these formatters with the kernel if and when a supported third-party\n    library is imported into a marimo notebook.\n    \"\"\"\n    original_import = builtins.__import__\n\n    def custom_import(name: str, globals=None, locals=None, fromlist=(), level=0):\n        # Attempt to import the module as normal\n        module = original_import(name, globals, locals, fromlist, level)\n\n        # If this module is a third-party formatter, register its formatter\n        if name in THIRD_PARTY_FACTORIES:\n            formatter = THIRD_PARTY_FACTORIES[name]\n            formatter.register()\n\n        return module\n\n    # Hook into the import system\n    builtins.__import__ = custom_import\n\n    # Register native formatters immediately, as they are fast.\n    for formatter in NATIVE_FACTORIES:\n        formatter.register()\n\n# Hook the function to register the formatters\nregister_formatters()\n```\n", "marimo-marimo/_data/series.py-get_category_series_info": "```python\ndef get_category_series_info(series: Any) -> CategorySeriesInfo:\n    \"\"\"\n    Get the summary of a categorical series.\n    \"\"\"\n\n    if DependencyManager.has_pandas():\n        import pandas as pd\n\n        if isinstance(series, pd.Series):\n            categories = series.dropna().unique().tolist()\n            return CategorySeriesInfo(\n                categories=categories,\n                label=_get_name(series),\n            )\n\n    if DependencyManager.has_polars():\n        import polars as pl\n\n        if isinstance(series, pl.Series):\n            categories = series.drop_nulls().unique().to_list()\n            return CategorySeriesInfo(\n                categories=categories,\n                label=_get_name(series),\n            )\n\n    raise ValueError(\"Unsupported series type. Expected pandas or polars.\")\n```", "marimo-marimo/_data/preview_column.py-get_column_preview": "```python\ndef get_column_preview(\n    request: PreviewDatasetColumnRequest,\n    table: TableManager[Any]\n) -> tuple[Optional[str], Optional[str], Optional[ColumnSummary]]:\n    \"\"\"\n    Get a preview of the column in the dataset.\n\n    This may return a chart and a aggregation summary of the column.\n    \"\"\"\n    summary = table.get_column_summary(request.column_name)\n\n    chart_json, code, _ = _get_altair_chart(request, table, summary)\n\n    return chart_json, code, summary\n```", "marimo-marimo/_server/sessions.py-start_file_watcher": "To implement the `start_file_watcher` method, we need to create a `FileWatcher` instance if it isn't already started. The method should return a `Disposable` object that allows stopping the `FileWatcher`.\n\nHere's how this can be done based on the provided context:\n\n```python\ndef start_file_watcher(self) -> Disposable:\n    \"\"\"Starts the file watcher if it is not already started.\"\"\"\n    if self.watcher is None:\n        # Assuming FileWatcher takes some necessary initialization parameters\n        self.watcher = FileWatcher(self.file_router)\n        \n        # Start the file watcher\n        self.watcher.start()\n        \n        # Return a Disposable that can be used to stop the file watcher\n        return Disposable(lambda: self.watcher.stop())\n    \n    # If watcher is already started, return a no-op Disposable\n    return Disposable(lambda: None)\n```\n\nThis function starts the file watcher if it is not already started by creating a new `FileWatcher` instance, starting it, and then returning a `Disposable` object to manage its cleanup. If the watcher is already running, it returns a no-op `Disposable` instead.", "marimo-marimo/_server/file_manager.py-save_app_config": "To implement the `save_app_config` method, you'll need to save the application's configuration provided as a dictionary to the app's current state. This involves updating the app's configuration and potentially saving it to the associated file, if applicable. Here's a possible implementation:\n\n```python\ndef save_app_config(self, config: Dict[str, Any]) -> str:\n    \"\"\"Save the app configuration.\"\"\"\n    if not isinstance(config, dict):\n        raise HTTPException(\n            status_code=HTTPStatus.BAD_REQUEST,\n            detail=\"Invalid configuration format. Expected a dictionary.\",\n        )\n    \n    # Update the app's configuration\n    self.app.update_config(config)\n    LOGGER.debug(\"App configuration updated: %s\", config)\n\n    # Optionally persist the configuration to a file\n    if self._is_named():\n        self._create_file(self.filename, self.to_code())\n        LOGGER.debug(\"App configuration persisted to file: %s\", self.filename)\n    \n    return \"Configuration saved successfully\"\n```\n\nThis function first checks if the provided config is a dictionary, raising an exception if not. It then updates the application's configuration with the new configuration values. If the app is named (i.e., it has an associated filename), it writes the updated configuration to the file. Finally, it logs the actions taken and returns a success message.", "marimo-marimo/_server/session/session_view.py-add_stdin": "Based on the provided context and the function signature, the `add_stdin` function should add a stdin request to the session view, possibly updating relevant parts of the `SessionView` class. Since there's no explicit handling of `stdin` in the shared code, we'll infer that it should be stored or handled similar to other attributes managed within `SessionView`.\n\nHere's how the function can be implemented:\n\n```python\ndef add_stdin(self, stdin: str) -> None:\n    \"\"\"Add a stdin request to the session view.\"\"\"\n    # Store the stdin input in a dictionary using a key, for example 'last_stdin'.\n    # This assumes there's a requirement to store it. If not, further context would be needed.\n    self.ui_values['last_stdin'] = stdin\n```\n\nThis implementation is an inference based on patterns from the existing methods seen in `SessionView`, particularly how values are stored using dictionaries. Depending on the actual requirements and usage of `stdin`, additional modifications might be needed.", "marimo-marimo/_server/session/session_view.py-add_operation": "```python\ndef add_operation(self, operation: MessageOperation) -> None:\n    \"\"\"Add an operation to the session view.\"\"\"\n    if isinstance(operation, CellOp):\n        # Get the existing operation for the cell id if available\n        previous_op = self.cell_operations.get(operation.cell_id)\n        # Merge the new operation with the previous one\n        merged_op = merge_cell_operation(previous_op, operation)\n        # Store the merged operation\n        self.cell_operations[operation.cell_id] = merged_op\n    elif isinstance(operation, Datasets):\n        # Update the datasets attribute with the new operation\n        self.datasets = operation\n    elif isinstance(operation, Variables):\n        # Update the variable operations attribute with the new operation\n        self.variable_operations = operation\n    elif isinstance(operation, VariableValues):\n        # Update the variable values map with new values\n        for variable in operation.variables:\n            self.variable_values[variable.name] = variable.value\n```\n", "marimo-marimo/_server/session/session_view.py-get_cell_console_outputs": "```python\ndef get_cell_console_outputs(self, ids: list[CellId_t]) -> dict[CellId_t, list[CellOutput]]:\n    \"\"\"Get the console outputs for the given cell ids.\"\"\"\n    console_outputs: dict[CellId_t, list[CellOutput]] = {}\n    for cell_id in ids:\n        cell_op = self.cell_operations.get(cell_id)\n        if cell_op is not None and cell_op.console is not None:\n            console_outputs[cell_id] = as_list(cell_op.console)\n    return console_outputs\n```", "marimo-marimo/_runtime/dataflow.py-register_cell": "```python\ndef register_cell(self, cell_id: CellId_t, cell: CellImpl) -> None:\n    \"\"\"Add a cell to the graph.\n\n    Mutates the graph, acquiring `self.lock`.\n\n    Requires that `cell_id` is not already in the graph.\n    \"\"\"\n    with self.lock:\n        if cell_id in self.cells:\n            raise ValueError(f\"Cell {cell_id} already exists in the graph\")\n\n        # Add the new cell to the cells dictionary\n        self.cells[cell_id] = cell\n\n        # Initialize children, parents, and siblings for the new cell\n        self.children[cell_id] = set()\n        self.parents[cell_id] = set()\n        self.siblings[cell_id] = set()\n\n        # For each definition of the cell, register it\n        for name in cell.defs:\n            if name not in self.definitions:\n                self.definitions[name] = set()\n            else:\n                # Add existing cells that define the same name to siblings\n                for cid in self.definitions[name]:\n                    self.siblings[cid].add(cell_id)\n                    self.siblings[cell_id].add(cid)\n\n            # Add this cell to the set of definers for this name\n            self.definitions[name].add(cell_id)\n```", "marimo-marimo/_runtime/validate_graph.py-check_for_errors": "```python\ndef check_for_errors(graph: DirectedGraph) -> dict[CellId_t, list[Error]]:\n    \"\"\"\n    Check graph for violations of marimo semantics.\n\n    Return a dict of errors in the graph, with an entry for each cell\n    that is involved in an error.\n    \"\"\"\n    errors = defaultdict(list)\n\n    # Check for multiple definitions\n    multiple_def_errors = check_for_multiple_definitions(graph)\n    for cid, error_list in multiple_def_errors.items():\n        errors[cid].extend(error_list)\n\n    # Check for delete nonlocal errors\n    delete_nonlocal_errors = check_for_delete_nonlocal(graph)\n    for cid, error_list in delete_nonlocal_errors.items():\n        errors[cid].extend(error_list)\n\n    # Check for cycle errors\n    cycle_errors = check_for_cycles(graph)\n    for cid, error_list in cycle_errors.items():\n        errors[cid].extend(error_list)\n\n    return errors\n```", "marimo-marimo/_runtime/runtime.py-_maybe_register_cell": "```python\ndef _maybe_register_cell(self, cell_id: CellId_t, code: str) -> tuple[set[CellId_t], Optional[Error]]:\n    \"\"\"Register a cell (given by id, code) if not already registered.\n\n    If a cell with id `cell_id` is already registered but with different\n    code, that cell is deleted from the graph and a new cell with the\n    same id but different code is registered.\n\n    Returns:\n    - a set of ids for cells that were previously children of `cell_id`;\n      only non-empty when `cell-id` was already registered but with\n      different code.\n    - an `Error` if the cell couldn't be registered, `None` otherwise\n    \"\"\"\n    previous_children = set()\n    existing_cell = self.graph.cells.get(cell_id)\n\n    # Check if the cell is already registered with the same code\n    if existing_cell is not None and existing_cell.code == code:\n        return previous_children, None\n\n    # If the cell is registered but with different code, delete it\n    if existing_cell is not None:\n        # Deactivate the existing cell and capture its children\n        previous_children = self._deactivate_cell(cell_id)\n\n    # Try to register the new cell\n    error = self._try_registering_cell(cell_id, code)\n\n    return previous_children, error\n```", "marimo-marimo/_runtime/runtime.py-run": "```python\nasync def run(execution_requests: Sequence[ExecutionRequest]) -> None:\n    \"\"\"Run cells and their descendants.\n\n    The cells may be cells already existing in the graph or new cells.\n    Adds the cells in `execution_requests` to the graph before running them.\n\n    Cells may use top-level await, which is why this function is async.\n    \"\"\"\n    # Add new cells or update existing ones in the graph\n    stale_cells = self.mutate_graph(execution_requests, [])\n\n    # Cells that need to be run\n    cells_to_run = set()\n\n    # Add newly added/modified cells to the cells_to_run set\n    cells_to_run.update(stale_cells)\n\n    # Add descendants of the updated cells to the cells_to_run set\n    for cell_id in stale_cells:\n        cells_to_run.update(self.graph.descendants(cell_id))\n\n    # Run each cell\n    for cell_id in cells_to_run:\n        try:\n            async with self._install_execution_context(cell_id):\n                await cell_runner.run_cell(self.graph, cell_id, self.globals)\n        except Exception as e:\n            LOGGER.error(f\"Error running cell {cell_id}: {str(e)}\")\n```", "marimo-marimo/_runtime/packages/utils.py-is_python_isolated": "```python\ndef is_python_isolated() -> bool:\n    \"\"\"Returns True if not using system Python\"\"\"\n    return in_virtual_environment() or in_conda_env()\n```", "marimo-marimo/_runtime/packages/module_registry.py-missing_modules": "```python\ndef missing_modules(self) -> set[str]:\n    \"\"\"Modules that will fail to import.\"\"\"\n    installed_modules = set(filter(_is_module_installed, self.modules()))\n    return self.modules() - installed_modules - self.excluded_modules\n```", "TaskWeaver-taskweaver/misc/example.py-load_examples": "```python\ndef load_examples(folder: str, role_set: Optional[Set[str]] = None) -> List:\n    \"\"\"\n    Load all the examples from a folder.\n\n    Args:\n        folder: the folder path.\n        role_set: the roles should be included in the examples.\n\n    Returns:\n        A list of examples that match the given roles.\n    \"\"\"\n    import os\n    from taskweaver.memory.conversation import Conversation\n    \n    examples = []\n    \n    # Get all the files in the folder\n    for file_path in glob.glob(os.path.join(folder, '*.txt')):  # Assuming examples are stored in .txt files\n        with open(file_path, 'r') as file:\n            content = file.read()\n            example = Conversation.parse(content)\n            if role_set:\n                # Filter examples by roles\n                if example.role in role_set:\n                    examples.append(example)\n            else:\n                examples.append(example)\n    \n    return examples\n```", "TaskWeaver-taskweaver/code_interpreter/plugin_selection.py-add_selected_plugins": "```python\ndef add_selected_plugins(self, external_plugin_pool: List[PluginEntry]):\n    \"\"\"\n    Add selected plugins to the pool.\n    \"\"\"\n    self.selected_plugin_pool = SelectedPluginPool.merge_plugin_pool(self.selected_plugin_pool, external_plugin_pool)\n```", "TaskWeaver-taskweaver/code_interpreter/plugin_selection.py-filter_unused_plugins": "```python\ndef filter_unused_plugins(self, code: str):\n    \"\"\"\n    Filter out plugins that are not used in the code generated by LLM\n    \"\"\"\n    used_plugins = []\n\n    for plugin in self.available_plugins:\n        # Check if the plugin's name or any recognizable identifier is mentioned in the code\n        if plugin.name in code or any(identifier in code for identifier in plugin.identifiers):\n            used_plugins.append(plugin)\n\n    self.available_plugins = used_plugins\n```\n", "TaskWeaver-taskweaver/module/prompt_util.py-remove_all_delimiters": "```python\ndef remove_all_delimiters(text: str) -> str:\n    \"\"\"Remove all the delimiters from the text.\"\"\"\n    delimiters = PromptUtil.get_all_delimiters()\n    for delimiter in delimiters:\n        text = PromptUtil.remove_delimiter(text, delimiter)\n    return text\n```", "reflex-reflex/app.py-_enable_state": "```python\ndef _enable_state(self) -> None:\n    \"\"\"Enable state for the app.\"\"\"\n    if not self.state:\n        return\n\n    # Set up the state manager.\n    self._state_manager = StateManager.create(state=self.state)\n\n    # Set up the Socket.IO AsyncServer if not already set.\n    if not self.sio:\n        config = get_config()\n        self.sio = AsyncServer(\n            async_mode=\"asgi\",\n            cors_allowed_origins=(\n                \"*\"\n                if config.cors_allowed_origins == [\"*\"]\n                else config.cors_allowed_origins\n            ),\n            cors_credentials=True,\n            max_http_buffer_size=constants.POLLING_MAX_HTTP_BUFFER_SIZE,\n            ping_interval=constants.Ping.INTERVAL,\n            ping_timeout=constants.Ping.TIMEOUT,\n        )\n\n    # Create the socket app with the specified event endpoint.\n    socket_app = ASGIApp(self.sio, socketio_path=\"\")\n    namespace = get_config().get_event_namespace()\n\n    # Create the event namespace and attach the main app.\n    self.event_namespace = EventNamespace(namespace, self)\n\n    # Register the event namespace with the socket.\n    self.sio.register_namespace(self.event_namespace)\n\n    # Mount the socket app with the API.\n    self.api.mount(str(constants.Endpoint.EVENT), socket_app)\n```\n", "reflex-reflex/app.py-_add_optional_endpoints": "```python\ndef _add_optional_endpoints(self):\n    \"\"\"Add optional api endpoints (_upload).\"\"\"\n    from reflex.api import upload  # Assuming there's an 'upload' module in reflex.api\n\n    # Add the upload endpoint\n    self.api.post(str(constants.Endpoint.UPLOAD))(upload)\n```", "reflex-reflex/app.py-add_page": "```python\ndef add_page(\n    self,\n    component: Component | ComponentCallable,\n    route: Optional[str] = None,\n    title: Optional[str] = '',\n    description: Optional[str] = '',\n    image: Optional[str] = '',\n    on_load: Optional[Union[EventHandler, EventSpec, List[Union[EventHandler, EventSpec]]]] = None,\n    meta: Optional[List[Dict[str, str]]] = None,\n):\n    \"\"\"Add a page to the app.\n\n    If the component is a callable, by default the route is the name of the\n    function. Otherwise, a route must be provided.\n\n    Args:\n        component: The component to display at the page.\n        route: The route to display the component at. Defaults to the function name if the component is callable.\n        title: The title of the page.\n        description: The description of the page.\n        image: The image to display on the page.\n        on_load: The event handler(s) that will be called each time the page load.\n        meta: The metadata of the page.\n\n    Raises:\n        ValueError: When the specified route name already exists.\n    \"\"\"\n    # Generate component if it's callable\n    component = self._generate_component(component)\n\n    # Determine the route\n    if route is None:\n        if callable(component):\n            route = component.__name__\n        else:\n            raise ValueError(\"A route must be provided if the component is not callable.\")\n\n    # Check for route conflicts\n    self._check_routes_conflict(route)\n\n    # Add the page component to the pages dict\n    if route in self.pages:\n        raise ValueError(f\"A page with the route '{route}' already exists.\")\n    self.pages[route] = component\n\n    # Add on_load events to the load_events\n    if on_load:\n        if not isinstance(on_load, list):\n            on_load = [on_load]\n        self.load_events[route] = on_load\n\n    # Store metadata\n    page_meta = {\n        \"title\": title,\n        \"description\": description,\n        \"image\": image,\n        \"meta\": meta or [],\n    }\n    self.api.get(route)(lambda: page_meta)\n\n    # Log the addition of the page\n    console.log(f\"Page '{route}' added to the app.\")\n```", "reflex-reflex/app.py-_setup_overlay_component": "```python\ndef _setup_overlay_component(self):\n    \"\"\"Set up the overlay component for the app.\n\n    If a State is not used and no overlay_component is specified, do not render the connection modal.\n    \"\"\"\n    # Check if no state is used and no overlay component is specified\n    if not self.state and self.overlay_component is None:\n        # Set the overlay component to None to prevent rendering the connection modal\n        self.overlay_component = None\n```", "reflex-reflex/app.py-_compile": "```python\ndef _compile(self, export: bool = False):\n    \"\"\"Compile the app and output it to the pages folder.\n\n    Args:\n        export: Whether to compile the app for export.\n\n    Raises:\n        ReflexRuntimeError: When any page uses state, but no rx.State subclass is defined.\n    \"\"\"\n    # Apply decorated pages to the app, ensuring all pages are collected.\n    self._apply_decorated_pages()\n\n    # Set up state, which could raise ReflexRuntimeError if no rx.State subclass is defined.\n    self._setup_state()\n\n    # Ensure that variable dependencies in the state are valid.\n    self._validate_var_dependencies()\n\n    # Iterate through all pages to collect their imports and determine if compilation is needed.\n    imports = {}\n    for route, component in self.pages.items():\n        generated_component = self._generate_component(component)\n        component_imports = compiler.get_imports(generated_component)\n        imports.update(component_imports)\n\n    # Determine if compilation should proceed based on environment and file checks.\n    if not self._should_compile():\n        return\n\n    # Compile the pages and generate output files.\n    for route, component in self.pages.items():\n        generated_component = self._generate_component(component)\n        compiler.compile_page(\n            route=route,\n            component=self._add_overlay_to_component(generated_component),\n            imports=imports,\n            export=export,\n        )\n\n    # Evaluate if there are frontend packages to be installed and install them.\n    self._get_frontend_packages(imports)\n\n    # Report telemetry data after successful compilation.\n    telemetry.report()\n\n    # Notify successful compilation completion.\n    console.info(\"App compiled successfully.\")\n```", "reflex-reflex/app.py-modify_state": "```python\nasync def modify_state(self, token: str) -> AsyncIterator[BaseState]:\n    \"\"\"Modify the state out of band.\n\n    Args:\n        token: The token to modify the state for.\n\n    Yields:\n        The state to modify.\n\n    Raises:\n        RuntimeError: If the app has not been initialized yet.\n    \"\"\"\n    # Ensure the app has been initialized\n    if self._state_manager is None:\n        raise RuntimeError(\"The state manager has not been initialized.\")\n\n    # Use the state manager to modify the state\n    async with self.state_manager.modify_state(token) as state:\n        yield state\n```", "reflex-reflex/vars.py-create": "```python\ndef create(\n    value: Any,\n    _var_is_local: bool = False,\n    _var_is_string: bool = True,\n    _var_data: Optional[VarData] = None\n) -> Var:\n    \"\"\"Create a var from a value.\n\n    Args:\n        value: The value to create the var from.\n        _var_is_local: Whether the var is local.\n        _var_is_string: Whether the var is a string literal.\n        _var_data: Additional hooks and imports associated with the Var.\n\n    Returns:\n        The var.\n\n    Raises:\n        VarTypeError: If the value is JSON-unserializable.\n    \"\"\"\n    try:\n        # Try to serialize the value to validate it can be JSON serialized.\n        serialized_value = json.dumps(value)\n        _var_name = serialized_value if _var_is_string else str(value)\n\n        return Var(\n            _var_name=_var_name,\n            _var_type=type(value),\n            _var_is_local=_var_is_local,\n            _var_is_string=_var_is_string,\n            _var_full_name_needs_state_prefix=False,\n            _var_data=_var_data or VarData()\n        )\n    except (TypeError, ValueError) as e:\n        raise VarTypeError(f\"Provided value cannot be serialized: {value}\") from e\n```", "reflex-reflex/vars.py-create_safe": "```python\ndef create_safe(value: Any, _var_is_local: bool = False, _var_is_string: bool = False, _var_data: Optional[VarData] = None) -> Var:\n    \"\"\"Create a var from a value, asserting that it is not None.\n\n    Args:\n        value: The value to create the var from.\n        _var_is_local: Whether the var is local.\n        _var_is_string: Whether the var is a string literal.\n        _var_data: Additional hooks and imports associated with the Var.\n\n    Returns:\n        The var.\n\n    Raises:\n        VarValueError: If the value is None.\n    \"\"\"\n    if value is None:\n        raise VarValueError(\"Value for creating a safe Var cannot be None.\")\n\n    return Var.create(value, _var_is_local=_var_is_local, _var_is_string=_var_is_string, _var_data=_var_data)\n```", "reflex-reflex/vars.py-foreach": "```python\ndef foreach(self, fn: Callable) -> Var:\n    \"\"\"Return a list of components after doing a foreach on this var.\n\n    Args:\n        fn: The function to call on each component.\n\n    Returns:\n        A var representing the foreach operation.\n\n    Raises:\n        VarTypeError: If the var is not a list.\n    \"\"\"\n    if not types._issubclass(self._var_type, (list, List)):\n        raise VarTypeError(f\"Var {self._var_name} of type {self._var_type} is not a list and cannot be iterated with foreach.\")\n    \n    # Get a unique variable name for the iteration.\n    iter_var_name = get_unique_variable_name()\n    \n    # Create a new Var that represents the foreach operation.\n    result_var_name = f\"{self._var_name}.map(({iter_var_name}) => {fn(Var.create(iter_var_name, _var_type=types.get_args(self._var_type)[0]))})\"\n\n    return self._replace(_var_name=result_var_name, _var_type=List[Any], _var_is_string=False)\n```", "reflex-reflex/vars.py-get_default_value": "```python\ndef get_default_value(self) -> Any:\n    \"\"\"Get the default value of the var.\n\n    Returns:\n        The default value of the var.\n\n    Raises:\n        ImportError: If the var is a dataframe and pandas is not installed.\n    \"\"\"\n    if types.is_dataframe(self._var_type):\n        try:\n            import pandas as pd\n            return pd.DataFrame()\n        except ImportError:\n            raise ImportError(\"pandas is required for DataFrame type vars but is not installed.\")\n    # Handle other types if necessary\n    return self._var_type()\n```", "reflex-reflex/state.py-get_skip_vars": "```python\ndef get_skip_vars(cls) -> set[str]:\n    \"\"\"Get the vars to skip when serializing.\n\n    Returns:\n        The vars to skip when serializing.\n    \"\"\"\n    return {\"parent_state\", \"router\", \"_backend_vars\", \"_was_touched\", \"_mixin\", \"setvar\"}\n```", "reflex-reflex/state.py-add_var": "```python\ndef add_var(cls, name: str, type_: Any, default_value: Any = None):\n    \"\"\"Add dynamically a variable to the State.\n\n    The variable added this way can be used in the same way as a variable\n    defined statically in the model.\n\n    Args:\n        name: The name of the variable\n        type_: The type of the variable\n        default_value: The default value of the variable\n\n    Raises:\n        NameError: if a variable of this name already exists\n    \"\"\"\n    if name in cls.__annotations__:\n        raise NameError(f\"A variable with the name '{name}' already exists\")\n\n    # Add variable to class annotations\n    cls.__annotations__[name] = type_\n\n    # Set the default value if provided, otherwise set to pydantic's default\n    if default_value is not None:\n        setattr(cls, name, default_value)\n    else:\n        setattr(cls, name, pydantic.Field(default=None))\n    \n    # Add the variable as a BaseVar to the vars mapping\n    cls.base_vars[name] = BaseVar(_var_name=name, _var_type=type_)._var_set_state(cls)\n\n    # Update the vars dictionary\n    cls.vars[name] = cls.base_vars[name]\n\n    # Initialize the variable\n    cls._init_var(cls.base_vars[name])\n```\n", "reflex-reflex/state.py-reset": "```python\ndef reset(self):\n    \"\"\"Reset all the base vars to their default values.\"\"\"\n    for var_name, base_var in self.base_vars.items():\n        default_value = self.__annotations__.get(var_name, None)\n        if default_value is not None:\n            # Reset the value if the base var has a default value\n            setattr(self, var_name, default_value)\n    # Clear dirty vars and substates as the state has been reset\n    self.dirty_vars.clear()\n    self.dirty_substates.clear()\n    # Mark the state as touched due to reset\n    self._was_touched = True\n```", "reflex-reflex/state.py-get_state": "```python\nasync def get_state(self, state_cls: Type[BaseState]) -> BaseState:\n    \"\"\"Get an instance of the state associated with this token.\n\n    Allows for arbitrary access to sibling states from within an event handler.\n\n    Args:\n        state_cls: The class of the state.\n\n    Returns:\n        The instance of state_cls associated with this state's client_token.\n    \"\"\"\n    # Construct the substate key using the current state's client_token and the provided state_cls.\n    substate_key = _substate_key(self.client_token, state_cls)\n    \n    # Use the constructed key to retrieve or create an instance of the state.\n    # Assuming that the state manager or similar mechanism handles state creation and retrieval.\n    state_instance = await self.state_manager.get_or_create_state(substate_key, state_cls)\n    \n    # Return the state instance.\n    return state_instance\n```", "reflex-reflex/state.py-_process": "```python\nasync def _process(self, event: Event) -> AsyncIterator[StateUpdate]:\n    \"\"\"Obtain event info and process event.\n\n    Args:\n        event: The event to process.\n\n    Yields:\n        The state update after processing the event.\n    \"\"\"\n    try:\n        # Retrieve the event handler associated with the event name\n        handler = self.event_handlers.get(event.name)\n        \n        # Check if the handler exists\n        if not handler:\n            raise ValueError(f\"No event handler found for event: {event.name}\")\n\n        # Execute the event handler coroutine\n        async for state_update in handler(event):\n            # Yield the resulting state update\n            yield state_update\n\n    except Exception as e:\n        # Handle exceptions that occur during event processing\n        traceback_str = traceback.format_exc()\n        console.log(f\"Error processing event {event.name}: {str(e)}\\n{traceback_str}\")\n\n        # Optionally, yield a state update indicating error handling\n        yield StateUpdate(\n            success=False,\n            message=f\"An error occurred while processing event: {str(e)}\"\n        )\n```", "reflex-reflex/state.py-_dirty_computed_vars": "```python\ndef _dirty_computed_vars(\n    self, from_vars: Optional[Set[str]] = None, include_backend: bool = False\n) -> Set[str]:\n    \"\"\"Determine ComputedVars that need to be recalculated based on the given vars.\n\n    Args:\n        from_vars: Find ComputedVar that depend on this set of vars. If unspecified, will use the dirty_vars.\n        include_backend: Whether to include backend vars in the calculation.\n\n    Returns:\n        Set of computed vars to include in the delta.\n    \"\"\"\n    if from_vars is None:\n        from_vars = self.dirty_vars\n\n    # Start with all computed vars that are always dirty.\n    dirty_computed_vars = set(self._always_dirty_computed_vars)\n\n    # Find computed vars that depend on the given vars.\n    for var in from_vars:\n        if var in self._computed_var_dependencies:\n            dirty_computed_vars.update(self._computed_var_dependencies[var])\n\n    if include_backend:\n        for var in set(self.backend_vars) & from_vars:\n            if var in self._computed_var_dependencies:\n                dirty_computed_vars.update(self._computed_var_dependencies[var])\n\n    return dirty_computed_vars\n```", "reflex-reflex/state.py-_potentially_dirty_substates": "```python\ndef _potentially_dirty_substates(cls) -> set[Type[BaseState]]:\n    \"\"\"Determine substates which could be affected by dirty vars in this state.\n\n    Returns:\n        Set of State classes that may need to be fetched to recalc computed vars.\n    \"\"\"\n    potentially_dirty_substates = set()\n\n    # Check which substates have vars dependent on dirty vars of this state\n    for dirty_var in cls.dirty_vars:\n        if dirty_var in cls._substate_var_dependencies:\n            potentially_dirty_substates.update(cls._substate_var_dependencies[dirty_var])\n\n    # Add substates which always need to be recomputed\n    potentially_dirty_substates.update(cls._always_dirty_substates)\n\n    return potentially_dirty_substates\n```", "reflex-reflex/state.py-get_delta": "```python\ndef get_delta(self) -> Delta:\n    \"\"\"Get the delta for the state.\n\n    Returns:\n        The delta for the state.\n    \"\"\"\n    delta = {}\n    \n    # Add dirty vars to the delta.\n    for var_name in self.dirty_vars:\n        if var_name in self.base_vars:\n            delta[var_name] = getattr(self, var_name)\n    \n    # Add dirty substates to the delta.\n    for substate_name in self.dirty_substates:\n        if substate_name in self.substates:\n            substate = self.substates[substate_name]\n            delta[substate_name] = substate.get_delta()\n\n    # Reset the dirty vars and substates since they've been captured.\n    self.dirty_vars.clear()\n    self.dirty_substates.clear()\n\n    return delta\n```", "reflex-reflex/model.py-get_db_engine": "```python\ndef get_db_engine() -> sqlalchemy.engine.Engine:\n    \"\"\"Get the database engine.\n\n    Returns:\n        The database engine.\n    \"\"\"\n    return get_engine()\n```", "reflex-reflex/model.py-alembic_autogenerate": "```python\ndef alembic_autogenerate(\n    connection: sqlalchemy.engine.Connection,\n    message: str,\n    write_migration_scripts: bool = False,\n) -> bool:\n    \"\"\"Generate migration scripts for alembic-detectable changes.\n\n    Args:\n        connection: SQLAlchemy connection to use when detecting changes.\n        message: Human readable identifier describing the generated revision.\n        write_migration_scripts: If True, write autogenerated revisions to script directory.\n\n    Returns:\n        True when changes have been detected.\n    \"\"\"\n    config, script_directory = Model._alembic_config()\n\n    def run_autogenerate(rev, context):\n        return alembic.autogenerate.produce_migrations(context, script_directory)\n\n    with alembic.runtime.environment.EnvironmentContext(\n        config=config,\n        script=script_directory,\n        fn=run_autogenerate,\n    ) as env:\n        env.configure(connection=connection, target_metadata=ModelRegistry.get_metadata())\n        migration_script_dir = script_directory\n        migration_context = alembic.migration.MigrationContext.configure(connection)\n        autogen_context = alembic.autogenerate.api.AutogenContext(migration_context)\n\n        diffs = []\n        alembic.autogenerate.compare_metadata(migration_context, ModelRegistry.get_metadata(), diffs)\n\n        if diffs:\n            if write_migration_scripts:\n                alembic.command.revision(\n                    config=config,\n                    message=message,\n                    autogenerate=True,\n                    script_location=migration_script_dir,\n                )\n            return True\n\n    return False\n```", "reflex-reflex/model.py-migrate": "```python\ndef migrate(cls, autogenerate: bool = False) -> bool | None:\n    \"\"\"Execute alembic migrations for all sqlmodel Model classes.\n\n    If alembic is not installed or has not been initialized for the project,\n    then no action is performed.\n\n    If there are no revisions currently tracked by alembic, then\n    an initial revision will be created based on sqlmodel metadata.\n\n    If models in the app have changed in incompatible ways that alembic\n    cannot automatically generate revisions for, the app may not be able to\n    start up until migration scripts have been corrected by hand.\n\n    Args:\n        autogenerate: If True, generate migration script and use it to upgrade schema\n            (otherwise, just bring the schema to current \"head\" revision).\n\n    Returns:\n        True - indicating the process was successful.\n        None - indicating the process was skipped.\n    \"\"\"\n    # Check if alembic is initialized\n    if not Path(constants.ALEMBIC_CONFIG).exists():\n        console.warn(\"Alembic is not initialized. Run 'reflex db init' first.\")\n        return None\n\n    # Retrieve alembic config and script directory\n    config, script_directory = cls._alembic_config()\n\n    # Use the current database connection\n    engine = get_engine()\n    connection = engine.connect()\n\n    try:\n        # Run migrations\n        if autogenerate:\n            # Autogenerate migration script\n            def process_revision_directives(context, revision, directives):\n                if getattr(config.cmd_opts, 'autogenerate', False):\n                    script = directives[0]\n                    if script.upgrade_ops.is_empty():\n                        directives[:] = []\n                        console.info(\"No changes in schema detected.\")\n        \n            alembic.command.revision(\n                config=config,\n                message=\"auto-generated\",\n                autogenerate=True,\n                process_revision_directives=process_revision_directives\n            )\n        \n        # Apply migrations to head\n        cls._alembic_upgrade(connection)\n\n    except alembic.util.CommandError as e:\n        console.error(f\"Alembic CommandError: {e}\")\n        return None\n    finally:\n        # Close the connection\n        connection.close()\n\n    return True\n```", "reflex-reflex/model.py-select": "Certainly! Based on the context you provided, here's a possible implementation of the `select` method that constructs a SQLAlchemy select statement for the given model class:\n\n```python\nfrom sqlalchemy import select as sqlalchemy_select\n\ndef select(cls):\n    \"\"\"Select rows from the table.\n\n    Returns:\n        The select statement.\n    \"\"\"\n    return sqlalchemy_select(cls)\n```\n\nThis implementation assumes that the given `cls` (class) is a model class with a corresponding table. The function uses SQLAlchemy's `select` function to create a select statement for this class. Make sure that the `sqlalchemy` module is appropriately imported in your module for this to work correctly.", "reflex-reflex/compiler/compiler.py-compile_components": "```python\ndef compile_components(\n    components: set[CustomComponent],\n) -> tuple[str, str]:\n    \"\"\"Compile the custom components.\n\n    Args:\n        components: The custom components to compile.\n\n    Returns:\n        The path and code of the compiled components.\n    \"\"\"\n    # Compile the components using the existing internal method.\n    compiled_components_str, imports = _compile_components(components)\n\n    # Determine the path for the output file.\n    output_path = utils.get_component_path()\n\n    # Return the path and the compiled components as a formatted string.\n    return output_path, compiled_components_str\n```", "reflex-reflex/utils/prerequisites.py-get_or_set_last_reflex_version_check_datetime": "```python\ndef get_or_set_last_reflex_version_check_datetime() -> datetime:\n    \"\"\"Get the last time a check was made for the latest reflex version.\n    This is typically useful for cases where the host reflex version is\n    less than that on Pypi.\n\n    Returns:\n        The last version check datetime.\n    \"\"\"\n    try:\n        # Define the path for the reflex.json file\n        reflex_json_path = get_web_dir() / \"reflex.json\"\n\n        # Check if the reflex.json file exists\n        if reflex_json_path.exists():\n            # Load the content of reflex.json\n            data = json.loads(reflex_json_path.read_text())\n            \n            # Get the last version check datetime from the JSON data\n            last_check_datetime = data.get(\"last_version_check_datetime\")\n\n            # If the datetime is found in the JSON data, parse it and return\n            if last_check_datetime:\n                return datetime.fromisoformat(last_check_datetime)\n        \n        # If the datetime isn't set or the file doesn't exist, set to the current datetime\n        current_datetime = datetime.now()\n\n        # Prepare the data to be written into reflex.json\n        data = {\n            \"version\": constants.Reflex.VERSION,\n            \"last_version_check_datetime\": current_datetime.isoformat(),\n        }\n\n        # Update or create the reflex.json with the latest check datetime\n        path_ops.update_json_file(reflex_json_path, data)\n\n        return current_datetime\n    except Exception as e:\n        console.warn(f\"Could not get or set the last version check datetime. Error: {e}\")\n        # Return current datetime as a fallback\n        return datetime.now()\n```", "reflex-reflex/middleware/hydrate_middleware.py-preprocess": "```python\nasync def preprocess(app: App, state: BaseState, event: Event) -> Optional[StateUpdate]:\n    \"\"\"Preprocess the event.\n\n    Args:\n        app: The app to apply the middleware to.\n        state: The client state.\n        event: The event to preprocess.\n\n    Returns:\n        An optional delta or list of state updates to return.\n    \"\"\"\n    # Fetch the hydrate event using the event id\n    hydrate_event = get_hydrate_event(event.id)\n\n    # If there is no hydrate event, we cannot proceed\n    if not hydrate_event:\n        return None\n\n    # Format and prepare the state update based on the event and current state\n    state_update = format(state, event)\n\n    # Determine delta or state update based on business logic\n    delta = []\n\n    # App specific logic to determine delta or state updates can be added here\n    # For now, we return the state_update as a single-item list\n    delta.append(state_update)\n    \n    return delta\n```", "reflex-reflex/components/component.py-get_event_triggers": "```python\ndef get_event_triggers(self) -> Dict[str, Any]:\n    \"\"\"Get the event triggers for the component.\n\n    Returns:\n        The event triggers.\n    \"\"\"\n    return self.event_triggers\n```", "reflex-reflex/components/component.py-get_props": "```python\ndef get_props(cls) -> Set[str]:\n    \"\"\"Get the unique fields for the component.\n\n    Returns:\n        The unique fields.\n    \"\"\"\n    return {\n        name\n        for name, field in cls.get_fields().items()\n        if not hasattr(field, \"default_factory\") and not callable(field.default)\n    }\n```", "reflex-reflex/components/component.py-create": "```python\ndef create(cls, *children, **props) -> Component:\n    \"\"\"Create the component.\n\n    Args:\n        *children: The children of the component.\n        **props: The props of the component.\n\n    Returns:\n        The component.\n    \"\"\"\n    # Create an instance of the component with the provided children and props.\n    return cls(children=list(children), **props)\n```", "reflex-reflex/components/component.py-_add_style_recursive": "```python\ndef _add_style_recursive(self, style: ComponentStyle, theme: Optional[Component] = None) -> Component:\n    \"\"\"Add additional style to the component and its children.\n\n    Apply order is as follows (with the latest overriding the earliest):\n    1. Default style from `_add_style`/`add_style`.\n    2. User-defined style from `App.style`.\n    3. User-defined style from `Component.style`.\n    4. style dict and css props passed to the component instance.\n\n    Args:\n        style: A dict from component to styling.\n        theme: The theme to apply. (for retro-compatibility with deprecated _apply_theme API)\n\n    Raises:\n        UserWarning: If `_add_style` has been overridden.\n\n    Returns:\n        The component with the additional style.\n    \"\"\"\n    # Add default style\n    default_style = self._add_style()\n    \n    # Add user-defined style from App.style\n    app_style = self._get_component_style(style)\n\n    # Add user-defined style from Component.style\n    component_style = self.style\n\n    # Merge styles in the specific order\n    final_style = Style()\n    for style_dict in [default_style, app_style, component_style]:\n        if style_dict:\n            final_style.update(style_dict)\n\n    # Apply final style to the component\n    self.style = final_style\n\n    # Apply theme if given\n    if theme:\n        self.apply_theme(theme)\n\n    # Apply recursively to children\n    for child in self.children:\n        if isinstance(child, Component):\n            child._add_style_recursive(style, theme)\n\n    return self\n```", "reflex-reflex/components/component.py-render": "```python\ndef render(self) -> Dict:\n    \"\"\"Render the component.\n\n    Returns:\n        The dictionary for template of the component.\n    \"\"\"\n    # Create a dictionary to hold the component's data\n    component_data = {\n        \"tag\": self.tag,\n        \"props\": {}\n    }\n\n    # Capture the component properties and add them to the dictionary\n    for prop in self.get_props():\n        value = getattr(self, prop, None)\n        if value is not None:\n            component_data[\"props\"][prop] = value\n\n    # Add event triggers to the dictionary, except for specific lifecycle events\n    for event, handler in self.event_triggers.items():\n        if event not in {EventTriggers.ON_MOUNT, EventTriggers.ON_UNMOUNT}:\n            component_data[\"props\"][event] = handler\n\n    # Add additional properties like style, class name, etc.\n    component_data[\"props\"].update(self._get_style())\n    component_data[\"props\"][\"key\"] = self.key\n    component_data[\"props\"][\"id\"] = self.id\n    component_data[\"props\"][\"class_name\"] = self.class_name\n    component_data[\"props\"].update(self.custom_attrs)\n\n    return component_data\n```", "reflex-reflex/components/component.py-_get_vars": "```python\ndef _get_vars(self, include_children: bool = False) -> list[Var]:\n    \"\"\"Walk all Vars used in this component.\n\n    Args:\n        include_children: Whether to include Vars from children.\n\n    Returns:\n        Each var referenced by the component (props, styles, event handlers).\n    \"\"\"\n    vars_list = []\n\n    # Add vars from props\n    for prop in self.get_props():\n        prop_value = getattr(self, prop, None)\n        if isinstance(prop_value, Var):\n            vars_list.append(prop_value)\n\n    # Add vars from style\n    if isinstance(self.style, Var):\n        vars_list.append(self.style)\n\n    # Add vars from event handlers\n    for event_chain in self.event_triggers.values():\n        if isinstance(event_chain, Var):\n            vars_list.append(event_chain)\n\n    if include_children:\n        # Recursively collect vars from children\n        for child in self.children:\n            if isinstance(child, Component):\n                vars_list.extend(child._get_vars(include_children=True))\n\n    return vars_list\n```", "reflex-reflex/components/component.py-_has_stateful_event_triggers": "```python\ndef _has_stateful_event_triggers(self):\n    \"\"\"Check if component or children have any event triggers that use state.\n\n    Returns:\n        True if the component or children have any event triggers that uses state.\n    \"\"\"\n    # Check if event triggers in the component itself use state.\n    stateful_event_triggers = any(\n        isinstance(handler, Var) and handler._refers_to_state()\n        for handler in self.event_triggers.values()\n    )\n\n    # Check if children components have any stateful event triggers.\n    stateful_children = any(\n        isinstance(child, Component) and child._has_stateful_event_triggers()\n        for child in self.children\n    )\n\n    return stateful_event_triggers or stateful_children\n```", "reflex-reflex/components/component.py-_get_all_custom_code": "```python\ndef _get_all_custom_code(self) -> set[str]:\n    \"\"\"Get custom code for the component and its children.\n\n    Returns:\n        The custom code.\n    \"\"\"\n    custom_code = set()\n\n    # Get custom code for this component.\n    custom_code.update(self.add_custom_code())\n\n    # Get custom code for each child, recursively if they are also components.\n    for child in self.children:\n        if isinstance(child, Component):\n            custom_code.update(child._get_all_custom_code())\n\n    return custom_code\n```\n", "reflex-reflex/components/component.py-_get_all_imports": "```python\ndef _get_all_imports(self, collapse: bool = False) -> ParsedImportDict:\n    \"\"\"Get all the libraries and fields that are used by the component and its children.\n\n    Args:\n        collapse: Whether to collapse the imports by removing duplicates.\n\n    Returns:\n        The import dict with the required imports.\n    \"\"\"\n    all_imports = ParsedImportDict()\n\n    # Gather imports from this component.\n    component_imports = self._get_all_component_imports()\n    all_imports.update(component_imports)\n\n    # Traverse children to gather their imports.\n    for child in self.children:\n        if isinstance(child, BaseComponent):\n            child_imports = child._get_all_imports(collapse=collapse)\n            all_imports.update(child_imports)\n\n    # Optionally collapse imports to remove duplicates.\n    if collapse:\n        all_imports.collapse()\n\n    return all_imports\n\ndef _get_all_component_imports(self) -> ParsedImportDict:\n    \"\"\"Helper method to get imports for the component itself.\"\"\"\n    # Get imports directly related to this component.\n    return self.add_imports()\n```", "reflex-reflex/components/component.py-_get_all_hooks_internal": "```python\ndef _get_all_hooks_internal(self) -> dict[str, None]:\n    \"\"\"Get the reflex internal hooks for the component and its children.\n\n    Returns:\n        The code that should appear just before user-defined hooks.\n    \"\"\"\n    # Initialize a dictionary to store the internal hooks.\n    hooks = {}\n\n    # Recursively gather the internal hooks from each child component.\n    for child in self.children:\n        if isinstance(child, BaseComponent):\n            child_hooks = child._get_all_hooks_internal()\n            hooks.update(child_hooks)\n\n    # Add internal hooks specific to this component.\n    # (Assuming there's a method or attribute that provides these hooks. If not, this needs to be defined)\n    component_hooks = self.add_hooks()\n    for hook in component_hooks:\n        hooks[hook] = None\n\n    return hooks\n```", "reflex-reflex/components/component.py-_get_all_hooks": "```python\ndef _get_all_hooks(self) -> dict[str, None]:\n    \"\"\"Get the React hooks for this component and its children.\n\n    Returns:\n        The code that should appear just before returning the rendered component.\n    \"\"\"\n    # Retrieve hooks directly related to this component\n    own_hooks = self.add_hooks()\n    \n    # Combine hooks from all children components\n    child_hooks = {}\n    for child in self.children:\n        if isinstance(child, Component):\n            child_hooks.update(child._get_all_hooks())\n\n    # Merge own hooks with children's hooks\n    all_hooks = {hook: None for hook in own_hooks}\n    all_hooks.update(child_hooks)\n    \n    # Return the combined hooks\n    return all_hooks\n```", "reflex-reflex/components/component.py-_get_all_custom_components": "```python\ndef _get_all_custom_components(seen: Optional[Set[str]] = None) -> Set[str]:\n    \"\"\"Get all the custom components used by the component.\n\n    Args:\n        seen: The tags of the components that have already been seen.\n\n    Returns:\n        The set of custom components.\n    \"\"\"\n    if seen is None:\n        seen = set()\n\n    # Add the current component's tag if it is a custom component.\n    if self.tag and self.tag not in seen:\n        seen.add(self.tag)\n\n    # Recursively add custom components from children.\n    for child in self.children:\n        if isinstance(child, Component):\n            child._get_all_custom_components(seen)\n\n    return seen\n```", "reflex-reflex/components/core/upload.py-create": "```python\ndef create(cls, *children, **props) -> Component:\n    \"\"\"Create an upload component.\n\n    Args:\n        *children: The children of the component.\n        **props: The properties of the component.\n\n    Returns:\n        The upload component.\n    \"\"\"\n    # Set default properties specific to the upload component.\n    props.setdefault(\"border\", \"1px dashed var(--accent-12)\")\n    props.setdefault(\"padding\", \"5em\")\n    props.setdefault(\"textAlign\", \"center\")\n\n    # Ensure the Upload component is marked as used in the app.\n    Upload.is_used = True\n\n    return super().create(*children, **props)\n```", "reflex-reflex/components/next/image.py-create": "```python\ndef create(*children, width: Any, height: Any, **props) -> Image:\n    \"\"\"Create an Image component from next/image.\n\n    Args:\n        *children: The children of the component.\n        width: The width of the image.\n        height: The height of the image.\n        **props: The props of the component.\n\n    Returns:\n        Image: An instance of the Image component with the specified properties.\n    \"\"\"\n    return Image(\n        width=width,\n        height=height,\n        **props\n    )\n```\n", "reflex-reflex/components/lucide/icon.py-create": "```python\nclass Icon(LucideIconComponent):\n    \"\"\"An Icon component.\"\"\"\n\n    tag = \"None\"\n\n    size: Var[int]\n\n    @classmethod\n    def create(cls, *children, **props) -> Component:\n        \"\"\"Initialize the Icon component.\n\n        Run some additional checks on Icon component.\n\n        Args:\n            *children: The positional arguments\n            **props: The keyword arguments\n\n        Raises:\n            AttributeError: The errors tied to bad usage of the Icon component.\n            ValueError: If the icon tag is invalid.\n\n        Returns:\n            The created component.\n        \"\"\"\n        # Check if the tag is present in the props\n        tag = props.get('tag', cls.tag)\n        if tag is None:\n            raise AttributeError(\"The tag for the Icon component must be specified in props.\")\n\n        # Check if the tag is a valid icon\n        if tag not in LUCIDE_ICON_LIST and tag not in RENAMED_ICONS_05:\n            raise ValueError(f\"'{tag}' is not a valid icon tag. Please use a valid icon from the list.\")\n\n        # Return a LucideIconComponent with given children and props\n        return super().create(*children, **props)\n```", "reflex-reflex/components/tags/tag.py-format_props": "```python\ndef format_props(self) -> List:\n    \"\"\"Format the tag's props.\n\n    Returns:\n        The formatted props list.\n    \"\"\"\n    formatted_props = []\n    for name, var in self.props.items():\n        if name in self.special_props:\n            formatted_props.append(str(var))\n        else:\n            formatted_props.append(f'{name}={{ {str(var)} }}')\n    return formatted_props\n```", "textual-src/textual/screen.py-focus_next": "```python\ndef focus_next(self, selector: str | type[QueryType] = \"*\") -> Widget | None:\n    \"\"\"Focus the next widget, optionally filtered by a CSS selector.\n\n    If no widget is currently focused, this will focus the first focusable widget.\n    If no focusable widget matches the given CSS selector, focus is set to `None`.\n\n    Args:\n        selector: CSS selector to filter what nodes can be focused.\n\n    Returns:\n        Newly focused widget, or None for no focus. If the return is not `None`, \n        then it is guaranteed that the widget returned matches the CSS selectors given in the argument.\n    \"\"\"\n    return self._move_focus(direction=1, selector=selector)\n```", "textual-src/textual/screen.py-focus_previous": "```python\ndef focus_previous(self, selector: str | type[QueryType] = \"*\") -> Widget | None:\n    \"\"\"Focus the previous widget, optionally filtered by a CSS selector.\n\n    If no widget is currently focused, this will focus the first focusable widget.\n    If no focusable widget matches the given CSS selector, focus is set to `None`.\n\n    Args:\n        selector: CSS selector to filter\n            what nodes can be focused.\n\n    Returns:\n        Newly focused widget, or None for no focus. If the return\n            is not `None`, then it is guaranteed that the widget returned matches\n            the CSS selectors given in the argument.\n    \"\"\"\n    return self._move_focus(direction=-1, selector=selector)\n```", "textual-src/textual/screen.py-set_focus": "```python\ndef set_focus(self, widget: Widget | None, scroll_visible: bool = True) -> None:\n    \"\"\"Focus (or un-focus) a widget. A focused widget will receive key events first.\n\n    Args:\n        widget: Widget to focus, or None to un-focus.\n        scroll_visible: Scroll widget into view.\n    \"\"\"\n    if self.focused != widget:\n        # Unfocus previous widget if any\n        blurred = self.focused\n        if blurred:\n            blurred.has_focus_within = False\n            self._update_focus_styles(blurred=blurred)\n\n        # Focus new widget if any\n        if widget:\n            self.focused = widget\n            widget.has_focus_within = True\n            if scroll_visible:\n                widget.scroll_into_view()\n\n            self._update_focus_styles(focused=widget)\n        else:\n            self.focused = None\n\n        self.app.refresh()\n```", "textual-src/textual/strip.py-index_to_cell_position": "```python\ndef index_to_cell_position(self, index: int) -> int:\n    \"\"\"Given a character index, return the cell position of that character.\n    This is the sum of the cell lengths of all the characters *before* the character\n    at `index`.\n\n    Args:\n        index: The index to convert.\n\n    Returns:\n        The cell position of the character at `index`.\n    \"\"\"\n    pos = 0\n    for i, segment in enumerate(self._segments):\n        segment_length = len(segment.text)\n        if index < segment_length:\n            pos += cell_len(segment.text[:index])\n            break\n        pos += cell_len(segment.text)\n        index -= segment_length\n    return pos\n```", "textual-src/textual/strip.py-render": "```python\ndef render(self, console: Console) -> str:\n    \"\"\"Render the strip into terminal sequences.\n\n    Args:\n        console: Console instance.\n\n    Returns:\n        Rendered sequences.\n    \"\"\"\n    if self._render_cache is not None:\n        return self._render_cache\n\n    # Use Console to render segments\n    fragments = console.render_lines((self._segments,), style=None, pad=False)\n    rendered_sequences = \"\\n\".join(fragment[0] for fragment in fragments if fragment)\n\n    self._render_cache = rendered_sequences\n    return rendered_sequences\n```", "textual-src/textual/app.py-batch_update": "```python\ndef batch_update(self) -> Generator[None, None, None]:\n    \"\"\"A context manager to suspend all repaints until the end of the batch.\"\"\"\n    self._batch_count += 1\n    try:\n        yield\n    finally:\n        self._batch_count -= 1\n        if self._batch_count == 0 and self._refresh_required:\n            self.refresh()\n```", "textual-src/textual/app.py-call_from_thread": "```python\ndef call_from_thread(\n    callback: Callable[..., CallThreadReturnType],\n    *args: Any,\n    **kwargs: Any\n) -> CallThreadReturnType:\n    \"\"\"Run a callable from another thread, and return the result.\n\n    Like asyncio apps in general, Textual apps are not thread-safe. If you call methods\n    or set attributes on Textual objects from a thread, you may get unpredictable results.\n\n    This method will ensure that your code runs within the correct context.\n\n    !!! tip\n\n        Consider using [post_message][textual.message_pump.MessagePump.post_message] which is also thread-safe.\n\n    Args:\n        callback: A callable to run.\n        *args: Arguments to the callback.\n        **kwargs: Keyword arguments for the callback.\n\n    Raises:\n        RuntimeError: If the app isn't running or if this method is called from the same\n            thread where the app is running.\n\n    Returns:\n        The result of the callback.\n    \"\"\"\n    loop = asyncio.get_event_loop()\n    if loop.is_running():\n        if threading.current_thread() is threading.main_thread():\n            raise RuntimeError(\"Cannot call from the main thread while the app is running.\")\n        return asyncio.run_coroutine_threadsafe(\n            loop.create_future().add_done_callback(\n                lambda future: invoke(callback, *args, **kwargs)\n            ),\n            loop\n        ).result()\n    else:\n        raise RuntimeError(\"App is not running.\")\n```", "textual-src/textual/app.py-run_test": "```python\nasync def run_test(\n    self,\n    headless: bool = True,\n    size: tuple[int, int] | None = None,\n    tooltips: bool = False,\n    notifications: bool = False,\n    message_hook: Callable[[Any], None] | None = None\n) -> AsyncGenerator[Pilot, None]:\n    \"\"\"An asynchronous context manager for testing apps.\n\n    !!! tip\n\n        See the guide for [testing](/guide/testing) Textual apps.\n\n    Use this to run your app in \"headless\" mode (no output) and drive the app via a [Pilot][textual.pilot.Pilot] object.\n\n    Example:\n\n        ```python\n        async with app.run_test() as pilot:\n            await pilot.click(\"#Button.ok\")\n            assert ...\n        ```\n\n    Args:\n        headless: Run in headless mode (no output or input).\n        size: Force terminal size to `(WIDTH, HEIGHT)`,\n            or None to auto-detect.\n        tooltips: Enable tooltips when testing.\n        notifications: Enable notifications when testing.\n        message_hook: An optional callback that will be called each time any message arrives at any\n            message pump in the app.\n    \"\"\"\n    from textual.pilot import Pilot\n\n    # Ensure the app is inactive before starting the test\n    if self._driver is not None:\n        raise RuntimeError(\"App cannot be running when run_test is called.\")\n\n    # Set headless mode\n    self._headless = headless\n\n    # Set terminal size if provided\n    if size:\n        self.console.size = Size(*size)\n    \n    # Configure the app for testing\n    self._disable_tooltips = not tooltips\n    self._disable_notifications = not notifications\n\n    # Use the message hook if provided\n    if message_hook:\n        self._custom_message_hook = message_hook\n\n    # Start the app in a headless mode with a Pilot instance\n    async with Pilot(self) as pilot:\n        yield pilot\n\n    # Clean up settings after the test\n    self._disable_tooltips = False\n    self._disable_notifications = False\n    self._custom_message_hook = None\n```", "textual-src/textual/app.py-run": "```python\ndef run(\n    self,\n    headless: bool = False,\n    inline: bool = False,\n    inline_no_clear: bool = False,\n    mouse: bool = True,\n    size: tuple[int, int] | None = None,\n    auto_pilot: Callable[[Pilot[object]], Coroutine[Any, Any, None]] | None = None,\n) -> ReturnType:\n    \"\"\"Run the app.\n\n    Args:\n        headless: Run in headless mode (no output).\n        inline: Run the app inline (under the prompt).\n        inline_no_clear: Don't clear the app output when exiting an inline app.\n        mouse: Enable mouse support.\n        size: Force terminal size to `(WIDTH, HEIGHT)`,\n            or None to auto-detect.\n        auto_pilot: An auto pilot coroutine.\n\n    Returns:\n        App return value.\n    \"\"\"\n    try:\n        # Setup and initialize app for running\n        self.prepare_app(headless=headless, inline=inline, size=size, mouse=mouse)\n\n        # If an auto pilot is provided, schedule it to run\n        if auto_pilot is not None:\n            asyncio.run(auto_pilot(Pilot(self)))\n\n        # Run the main event loop\n        self.run_event_loop()\n\n    finally:\n        # Perform any required cleanup, such as closing files or network connections\n        self.cleanup_app(inline_no_clear=inline_no_clear)\n\n    return self.return_value if self.return_value is not None else None\n```", "textual-src/textual/app.py-switch_mode": "```python\ndef switch_mode(self, mode: str) -> AwaitMount:\n    \"\"\"Switch to a given mode.\n\n    Args:\n        mode: The mode to switch to.\n\n    Returns:\n        An optionally awaitable object which waits for the screen associated\n            with the mode to be mounted.\n\n    Raises:\n        UnknownModeError: If trying to switch to an unknown mode.\n    \"\"\"\n    if mode not in self._screen_stacks:\n        raise UnknownModeError(f\"Mode '{mode}' is not known.\")\n\n    # Set the current mode\n    self._current_mode = mode\n\n    # Get the screen stack for the mode\n    stack = self._screen_stacks[mode]\n\n    # If stack is non-empty, get the top screen; otherwise, get the base screen\n    screen = stack[-1] if stack else self.MODES.get(mode)\n\n    if callable(screen):\n        screen = screen()\n\n    if screen is None:\n        raise UnknownModeError(f\"Mode '{mode}' has no associated screen.\")\n\n    # Mount the screen\n    return self.mount(screen)\n```", "textual-src/textual/app.py-push_screen": "```python\ndef push_screen(\n    self,\n    screen: Screen | str,\n    callback: Callable[[ScreenResultType], None] | None = None,\n    wait_for_dismiss: bool = False,\n) -> Awaitable[ScreenResultType] | AwaitMount[None]:\n    \"\"\"Push a new screen on the screen stack, making it the current screen.\n\n    Args:\n        screen: A Screen instance or the name of an installed screen.\n        callback: An optional callback function that will be called if the screen is dismissed with a result.\n        wait_for_dismiss: If `True`, awaiting this method will return the dismiss value from the screen. When set to `False`, awaiting\n            this method will wait for the screen to be mounted. Note that `wait_for_dismiss` should only be set to `True` when running in a worker.\n\n    Raises:\n        NoActiveWorker: If using `wait_for_dismiss` outside of a worker.\n\n    Returns:\n        An optional awaitable that awaits the mounting of the screen and its children, or an asyncio Future\n            to await the result of the screen.\n    \"\"\"\n    # Verify or get the screen instance\n    if isinstance(screen, str):\n        screen = self._installed_screens.get(screen)()\n        if screen is None:\n            raise ValueError(f\"Screen {screen} is not installed or invalid.\")\n        assert isinstance(screen, Screen), \"Installed screen callable did not return a Screen.\"\n\n    # Push screen onto the screen stack\n    self._screen_stacks[self._current_mode].append(screen)\n    self.log(f\"Pushed screen: {screen}\")\n\n    # Awaitable logic handling\n    if wait_for_dismiss:\n        if not getattr(self, \"_current_worker\", None):\n            raise NoActiveWorker(\"wait_for_dismiss requires a worker context\")\n        future: asyncio.Future = Future()\n        screen.dispatched.connect(lambda event: future.set_result(event.result))\n        if callback:\n            future.add_done_callback(lambda future: callback(future.result())) \n        return future\n\n    await_mount = AwaitMount(screen, callback=callback)\n    self._pending_mounts.append(await_mount)\n    self.refresh()\n    return await_mount\n```", "textual-src/textual/app.py-switch_screen": "Here is the function implementation based on the given information:\n\n```python\ndef switch_screen(self, screen: Screen | str) -> AwaitComplete:\n    \"\"\"Switch to another screen by replacing the top of the screen stack with a new screen.\n    \n    Args:\n        screen: Either a Screen object or screen name (the `name` argument when installed).\n    \"\"\"\n    if isinstance(screen, str):\n        # If the screen is a string, treat it as a screen name and fetch the screen object\n        screen = self._installed_screens.get(screen)\n        if screen is None:\n            raise ScreenError(f\"Screen named '{screen}' not found.\")\n        if isinstance(screen, Callable):\n            screen = screen()  # Call the callable to get a Screen instance\n\n    if not isinstance(screen, Screen):\n        raise TypeError(\"Expected a Screen object or screen name.\")\n\n    current_mode_stack = self._screen_stacks[self._current_mode]\n    \n    if current_mode_stack:\n        current_mode_stack[-1].on_stack_hide()\n\n    screen.on_stack_show()\n    if current_mode_stack:\n        current_mode_stack[-1] = screen\n    else:\n        current_mode_stack.append(screen)\n\n    return self._switch_to_screen()\n```\n\nThis function updates the screen stack by switching to a specified screen, either by utilizing a `Screen` object or resolving it using a screen name. It ensures that the topmost screen in the stack is correctly updated and manages any corresponding lifecycle events.", "textual-src/textual/app.py-pop_screen": "```python\ndef pop_screen(self) -> AwaitComplete:\n    \"\"\"Pop the current [screen](/guide/screens) from the stack, and switch to the previous screen.\n\n    Returns:\n        The screen that was replaced.\n    \"\"\"\n    try:\n        # Get the current screen stack for the current mode\n        screen_stack = self._screen_stacks[self._current_mode]\n        \n        # Ensure there is more than one screen on the stack to pop\n        if len(screen_stack) <= 1:\n            raise ScreenStackError(\"Can't pop the last screen on the stack\")\n\n        # Pop the current screen\n        replaced_screen = screen_stack.pop()\n\n        # Switch to the previous screen\n        previous_screen = screen_stack[-1]\n        await previous_screen.switch_to()\n\n        return replaced_screen\n\n    except ScreenStackError as error:\n        self.error_console.print(f\"[red]ScreenStackError: {error}\")\n        return AwaitComplete()\n```", "textual-src/textual/app.py-run_action": "Based on the provided information and the function signature, here's the implementation of the `run_action` function:\n\n```python\nasync def run_action(action: str, default_namespace: str | None = None) -> bool:\n    \"\"\"Perform an [action](/guide/actions).\n\n    Actions are typically associated with key bindings, where you wouldn't need to call this method manually.\n\n    Args:\n        action: Action encoded in a string.\n        default_namespace: Namespace to use if not provided in the action,\n            or None to use app.\n\n    Returns:\n        True if the event has been handled.\n    \"\"\"\n    # Assuming there's a method or utility to parse the action string\n    # This method would split the action into namespace and action name\n    # along with any arguments or parameters.\n    namespace, action_name, parameters = parse_action(action)\n\n    # If no namespace is provided, use the default_namespace\n    if not namespace:\n        namespace = default_namespace if default_namespace is not None else \"app\"\n\n    # Check if the namespace and action_name are valid and can be executed\n    # This might involve checking against registered actions in the system\n    if is_valid_action(namespace, action_name):\n        # Assuming there's a method to execute the action\n        handled = await execute_action(namespace, action_name, parameters)\n        return handled\n\n    # If the action or namespace is invalid, return False\n    return False\n```\n\n### Explanation:\n\n1. **Parameters:**\n   - `action`: This is a string that encodes the action to be performed. It might include a namespace, action name, and optional parameters.\n   - `default_namespace`: If the action string does not specify a namespace, this default is used. If not provided, the app itself will be used as the default namespace.\n\n2. **Return Value:**\n   - Returns `True` if the action was successfully handled, otherwise `False`.\n\n3. **Assumed Details:**\n   - There's an assumed utility function `parse_action` that helps break down the action string into its components: namespace, action name, and parameters.\n   - A method, `is_valid_action`, presumably checks if the given action is recognized and valid.\n   - An assumed `execute_action` function executes the given action.\n\nThis implementation leverages conventions typical in systems that have dynamic or automated action handling through string-encoded commands.", "textual-src/textual/file_monitor.py-check": "```python\ndef check(self) -> bool:\n    \"\"\"Check the monitored files. Return True if any were changed since the last modification time.\"\"\"\n    current_modified_time = self._get_last_modified_time()\n    if current_modified_time > self._modified:\n        self._modified = current_modified_time\n        return True\n    return False\n```", "textual-src/textual/expand_tabs.py-expand_tabs_inline": "```python\ndef expand_tabs_inline(line: str, tab_size: int = 4) -> str:\n    \"\"\"Expands tabs, taking into account double cell characters.\n\n    Args:\n        line: The text to expand tabs in.\n        tab_size: Number of cells in a tab.\n\n    Returns:\n        New string with tabs replaced with spaces.\n    \"\"\"\n    parts = get_tab_widths(line, tab_size)\n    \n    expanded_line = []\n    for text_segment, width in parts:\n        expanded_line.append(text_segment + \" \" * width)\n    \n    return \"\".join(expanded_line)\n```", "textual-src/textual/_resolve.py-resolve": "```python\ndef resolve(\n    dimensions: list[Scalar],\n    total: int,\n    gutter: int,\n    size: Size,\n    viewport: Size,\n) -> list[tuple[int, int]]:\n    \"\"\"Resolve a list of dimensions.\n\n    Args:\n        dimensions: Scalars for column / row sizes.\n        total: Total space to divide.\n        gutter: Gutter between rows / columns.\n        size: Size of container.\n        viewport: Size of viewport.\n\n    Returns:\n        List of (<OFFSET>, <LENGTH>)\n    \"\"\"\n    num_elements = len(dimensions)\n    if num_elements == 0:\n        return []\n\n    # Calculate total available space by removing gutter space\n    available_space = total - ((num_elements - 1) * gutter)\n\n    # List to hold resolved dimensions with their offsets\n    resolved_dimensions = []\n\n    # Calculate fr (fractional) units if any\n    fr_units = [dim for dim in dimensions if dim.is_fraction]\n    if fr_units:\n        total_fr_value = sum(fraction.value for fraction in fr_units)\n        fr_unit_value = Fraction(available_space, total_fr_value)\n    else:\n        fr_unit_value = Fraction(0)\n\n    current_offset = 0\n\n    for dim in dimensions:\n        # Resolve each dimension based on its scalar type\n        if dim.is_fraction:\n            length = int(dim.value * fr_unit_value)\n        else:\n            length = dim.resolve(size, viewport, fr_unit_value)\n\n        # Append the resolved dimension (OFFSET, LENGTH)\n        resolved_dimensions.append((current_offset, length))\n\n        # Update current offset for the next dimension\n        current_offset += length + gutter\n\n    return resolved_dimensions\n```", "textual-src/textual/widget.py-mount": "```python\ndef mount(self, *widgets: Widget, before: int | str | None = None, after: int | str | None = None) -> AwaitMount:\n    \"\"\"Mount widgets below this widget (making this widget a container).\n\n    Args:\n        *widgets: The widget(s) to mount.\n        before: Optional location to mount before. An `int` is the index\n            of the child to mount before, a `str` is a `query_one` query to\n            find the widget to mount before.\n        after: Optional location to mount after. An `int` is the index\n            of the child to mount after, a `str` is a `query_one` query to\n            find the widget to mount after.\n\n    Returns:\n        An awaitable object that waits for widgets to be mounted.\n\n    Raises:\n        MountError: If there is a problem with the mount request.\n\n    Note:\n        Only one of ``before`` or ``after`` can be provided. If both are\n        provided a ``MountError`` will be raised.\n    \"\"\"\n    if before is not None and after is not None:\n        raise MountError(\"You can specify either 'before' or 'after', but not both\")\n\n    insert_index = None\n    if before is not None:\n        if isinstance(before, int):\n            insert_index = before\n        elif isinstance(before, str):\n            before_widget = self.query_one(before)\n            if before_widget in self._nodes:\n                insert_index = self._nodes.index(before_widget)\n            else:\n                raise MountError(f\"Widget for 'before' query '{before}' not found\")\n    elif after is not None:\n        if isinstance(after, int):\n            insert_index = after + 1\n        elif isinstance(after, str):\n            after_widget = self.query_one(after)\n            if after_widget in self._nodes:\n                insert_index = self._nodes.index(after_widget) + 1\n            else:\n                raise MountError(f\"Widget for 'after' query '{after}' not found\")\n    \n    if insert_index is not None:\n        for widget in widgets:\n            self._nodes.insert(insert_index, widget)\n            insert_index += 1\n    else:\n        self._nodes.extend(widgets)\n\n    for widget in widgets:\n        widget._parent = self\n    \n    return AwaitMount(self, widgets)\n```", "textual-src/textual/widget.py-move_child": "```python\ndef move_child(\n    parent: Widget,\n    child: Widget, \n    before: Widget | int | None = None, \n    after: Widget | int | None = None\n) -> None:\n    \"\"\"Move a child widget within its parent's list of children.\n\n    Args:\n        parent: The parent widget containing the child to be moved.\n        child: The child widget to move.\n        before: Child widget or location index to move before.\n        after: Child widget or location index to move after.\n\n    Raises:\n        WidgetError: If there is a problem with the child or target.\n\n    Note:\n        Only one of `before` or `after` can be provided. If neither\n        or both are provided a `WidgetError` will be raised.\n    \"\"\"\n    if (before is not None and after is not None) or (before is None and after is None):\n        raise WidgetError(\"You must provide exactly one of 'before' or 'after'\")\n\n    # Remove the child from its current position\n    if child not in parent._nodes:\n        raise WidgetError(f\"The child widget is not a child of {parent}\")\n\n    parent._nodes.remove(child)\n    \n    # Determine the new position based on 'before' or 'after'\n    if before is not None:\n        if isinstance(before, int):\n            before_index = before\n        else:\n            if before not in parent._nodes:\n                raise WidgetError(f\"The 'before' widget is not a child of {parent}\")\n            before_index = parent._nodes.index(before)\n        \n        # Insert the child at the determined position\n        parent._nodes.insert(before_index, child)\n    elif after is not None:\n        if isinstance(after, int):\n            after_index = after + 1\n        else:\n            if after not in parent._nodes:\n                raise WidgetError(f\"The 'after' widget is not a child of {parent}\")\n            after_index = parent._nodes.index(after) + 1\n        \n        # Insert the child at the determined position\n        parent._nodes.insert(after_index, child)\n\n    # Request a refresh after moving a child\n    parent.refresh()\n```", "textual-src/textual/widget.py-_get_box_model": "```python\nfrom typing import NamedTuple\n\nclass BoxModel(NamedTuple):\n    size: Size\n    margin: Tuple[int, int, int, int]\n\ndef _get_box_model(\n    self, \n    container: Size, \n    viewport: Size, \n    width_fraction: Fraction, \n    height_fraction: Fraction\n) -> BoxModel:\n    \"\"\"Process the box model for this widget.\n\n    Args:\n        container: The size of the container widget (with a layout).\n        viewport: The viewport size.\n        width_fraction: A fraction used for 1 `fr` unit on the width dimension.\n        height_fraction: A fraction used for 1 `fr` unit on the height dimension.\n\n    Returns:\n        The size and margin for this widget.\n    \"\"\"\n\n    # Here, \"self.styles.width\" and \"self.styles.height\" represent the width and height\n    # styles from the widget's style configuration. Any additional logic to compute the\n    # actual pixel or fraction-based size will depend on these style attributes.\n    \n    width = self.styles.width.resolve(container.width, width_fraction)\n    height = self.styles.height.resolve(container.height, height_fraction)\n    \n    size = Size(width, height)\n   \n    # Compute the margin based on the style properties or logic\n    margin_left = self.styles.margin.left.resolve(viewport.width, width_fraction)\n    margin_right = self.styles.margin.right.resolve(viewport.width, width_fraction)\n    margin_top = self.styles.margin.top.resolve(viewport.height, height_fraction)\n    margin_bottom = self.styles.margin.bottom.resolve(viewport.height, height_fraction)\n    \n    margin = (margin_top, margin_right, margin_bottom, margin_left)\n \n    return BoxModel(size=size, margin=margin)\n```\n", "textual-src/textual/widget.py-get_content_width": "```python\ndef get_content_width(self, container: Size, viewport: Size) -> int:\n    \"\"\"Called by textual to get the width of the content area. May be overridden in a subclass.\n    \n    Args:\n        container: Size of the container (immediate parent) widget.\n        viewport: Size of the viewport.\n\n    Returns:\n        The optimal width of the content.\n    \"\"\"\n    # Check if we have a cached value for the content width based on current container size\n    cache_key = (container, viewport)\n    if self._content_width_cache[0] == cache_key:\n        # Return the cached optimal width if available\n        return self._content_width_cache[1] \n    \n    # Calculate optimal width, here it's implemented as the minimum of container or viewport width\n    # This is just a simple implementation; a subclass can override this method for custom behavior\n    optimal_width = min(container.width, viewport.width)\n    \n    # Cache this result for future calls with the same parameters\n    self._content_width_cache = (cache_key, optimal_width)\n    \n    return optimal_width\n```", "textual-src/textual/widget.py-get_content_height": "```python\ndef get_content_height(self, container: Size, viewport: Size, width: int) -> int:\n    \"\"\"Called by Textual to get the height of the content area. May be overridden in a subclass.\n\n    Args:\n        container: Size of the container (immediate parent) widget.\n        viewport: Size of the viewport.\n        width: Width of renderable.\n\n    Returns:\n        The height of the content.\n    \"\"\"\n    # Calculate and return the content height based on container, viewport, and renderable width\n    # Override this method in a subclass to provide specific logic for content height calculation\n    # The default implementation might return a fixed height or use a formula based on the parameters\n    return 0  # Modify as necessary for specific logic or calculations\n```", "textual-src/textual/suggester.py-_get_suggestion": "```python\nasync def _get_suggestion(self, requester: DOMNode, value: str) -> None:\n    \"\"\"Used by widgets to get completion suggestions.\n\n    Note:\n        When implementing custom suggesters, this method does not need to be overridden.\n\n    Args:\n        requester: The message target that requested a suggestion.\n        value: The current value to complete.\n    \"\"\"\n    # If caching is used and the suggestion is cached, use it\n    if self.cache is not None:\n        cached_suggestion = self.cache.get(value)\n        if cached_suggestion is not None:\n            requester.send(SuggestionReady(value=value, suggestion=cached_suggestion))\n            return\n    \n    # Casefold the value if suggestions are not case sensitive\n    if not self.case_sensitive:\n        value = value.casefold()\n\n    # Get the suggestion using the implemented 'get_suggestion' method\n    suggestion = await self.get_suggestion(value)\n    \n    # Cache the suggestion if caching is enabled\n    if self.cache is not None:\n        self.cache.set(value, suggestion)\n    \n    # Notify the requester with the suggestion\n    requester.send(SuggestionReady(value=value, suggestion=suggestion if suggestion else \"\"))\n```", "textual-src/textual/dom.py-add_class": "```python\ndef add_class(self, *class_names: str, update: bool = True) -> Self:\n    \"\"\"Add class names to this Node.\n\n    Args:\n        *class_names: CSS class names to add.\n        update: Also update styles.\n\n    Returns:\n        Self.\n    \"\"\"\n    if class_names:\n        check_identifiers(\"class name\", *class_names)\n        initial_classes_length = len(self._classes)\n        self._classes.update(class_names)\n        # If new classes were added, update styles if required\n        if update and len(self._classes) > initial_classes_length:\n            self._update_styles()\n    return self\n```", "textual-src/textual/reactive.py-_initialize_object": "```python\ndef _initialize_object(cls, obj: Reactable) -> None:\n    \"\"\"Set defaults and call any watchers / computes for the first time.\n\n    Args:\n        obj: An object with Reactive descriptors\n    \"\"\"\n    _rich_traceback_omit = True\n    for attr_name, reactive in obj._reactives.items():\n        if not hasattr(obj, reactive.internal_name):\n            reactive._initialize_reactive(obj, attr_name)\n\n        # Call compute method if it exists\n        if hasattr(obj, reactive.compute_name):\n            compute_method = getattr(obj, reactive.compute_name)\n            current_value = getattr(obj, reactive.internal_name)\n            new_value = compute_method()\n\n            # Update the internal value\n            setattr(obj, reactive.internal_name, new_value)\n\n            # Call watchers if the value changes\n            if new_value != current_value or reactive._always_update:\n                reactive._check_watchers(obj, attr_name, current_value)\n\n        # If no compute method, call watchers with default value\n        elif reactive._init:\n            default = getattr(obj, reactive.internal_name)\n            reactive._check_watchers(obj, attr_name, default)\n```", "textual-src/textual/message_pump.py-call_after_refresh": "```python\ndef call_after_refresh(self, callback: Callback, *args: Any, **kwargs: Any) -> bool:\n    \"\"\"Schedule a callback to run after all messages are processed and the screen\n    has been refreshed. Positional and keyword arguments are passed to the callable.\n\n    Args:\n        callback: A callable.\n\n    Returns:\n        `True` if the callback was scheduled, or `False` if the callback could not be\n        scheduled (may occur if the message pump was closed or closing).\n    \"\"\"\n    if self._closed or self._closing:\n        return False\n    refresh_message = events.Callback(callback=partial(callback, *args, **kwargs))\n    self._next_callbacks.append(refresh_message)\n    self.check_idle()\n    return True\n```", "textual-src/textual/message_pump.py-call_later": "```python\ndef call_later(self, callback: Callback, *args: Any, **kwargs: Any) -> bool:\n    \"\"\"Schedule a callback to run after all messages are processed in this object.\n    Positional and keywords arguments are passed to the callable.\n\n    Args:\n        callback: Callable to call next.\n        *args: Positional arguments to pass to the callable.\n        **kwargs: Keyword arguments to pass to the callable.\n\n    Returns:\n        `True` if the callback was scheduled, or `False` if the callback could not be\n            scheduled (may occur if the message pump was closed or closing).\n    \"\"\"\n    if self._closed or self._closing:\n        return False\n\n    callback_message = events.Callback(callback=partial(callback, *args, **kwargs))\n    callback_message._prevent.update(self._get_prevented_messages())\n    self._message_queue.put_nowait(callback_message)\n    return True\n```", "textual-src/textual/message_pump.py-post_message": "```python\ndef post_message(self, message: Message) -> bool:\n    \"\"\"Posts a message onto this widget's queue.\n\n    Args:\n        message: A message (including Event).\n\n    Returns:\n        `True` if the message was processed, `False` if it wasn't.\n    \"\"\"\n    if self._closed:\n        return False\n\n    if not self.check_message_enabled(message):\n        return False\n\n    message._bubble_to(self)\n    self._message_queue.put_nowait(message)\n    self.check_idle()\n    return True\n```", "textual-src/textual/_spatial_map.py-get_values_in_region": "```python\ndef get_values_in_region(self, region: Region) -> list[ValueType]:\n    \"\"\"Get a superset of all the values that intersect with a given region.\n\n    Note that this may return false positives.\n\n    Args:\n        region: A region.\n\n    Returns:\n        Values under the region.\n    \"\"\"\n    values = set()\n    # Get the grid coordinates for the provided region\n    grid_coordinates = self._region_to_grid_coordinates(region)\n    # Collect all values from the corresponding grid squares\n    for grid_coordinate in grid_coordinates:\n        values.update(self._map.get(grid_coordinate, []))\n    # Include all fixed values since they don't depend on the grid\n    values.update(self._fixed)\n    return list(values)\n```", "textual-src/textual/validation.py-validate": "To implement the `validate` method for the `URL` class based on the provided annotations and context, we will need to ensure that the input value is a valid URL string that includes a scheme. Here's how you can implement it:\n\n```python\ndef validate(self, value: str) -> ValidationResult:\n    \"\"\"Validates that `value` is a valid URL (contains a scheme).\n\n    Args:\n        value: The value to validate.\n\n    Returns:\n        The result of the validation.\n    \"\"\"\n    # Parse the URL\n    parsed_url = urlparse(value)\n\n    # Check if the scheme is present in the parsed URL\n    if not parsed_url.scheme:\n        # If no scheme, validation fails\n        return ValidationResult.failure([URL.InvalidURL(self, value)])\n    \n    # If the scheme is present, validation is successful\n    return self.success()\n```\n\nThis implementation uses the `urlparse` function from the `urllib.parse` module to check if the provided string is a valid URL by verifying if it contains a scheme. If the scheme is missing, it returns a failure result using the `InvalidURL` failure class. Otherwise, it returns a success result.", "textual-src/textual/geometry.py-clamp": "```python\ndef clamp(self, width: int, height: int) -> Offset:\n    \"\"\"Clamp the offset to fit within a rectangle of width x height.\n\n    Args:\n        width: Width to clamp.\n        height: Height to clamp.\n\n    Returns:\n        A new offset.\n    \"\"\"\n    x, y = self\n    clamped_x = min(max(0, x), width)\n    clamped_y = min(max(0, y), height)\n    return Offset(clamped_x, clamped_y)\n```", "textual-src/textual/constants.py-_get_textual_animations": "```python\ndef _get_textual_animations() -> AnimationLevel:\n    \"\"\"Get the value of the environment variable that controls textual animations.\n\n    The variable can be in any of the values defined by [`AnimationLevel`][textual.constants.AnimationLevel].\n\n    Returns:\n        The value that the variable was set to. If the environment variable is set to an\n        invalid value, we default to showing all animations.\n    \"\"\"\n    value = get_environ(\"TEXTUAL_ANIMATIONS\", \"all\")\n    if _is_valid_animation_level(value):\n        return value\n    return \"all\"\n```", "textual-src/textual/color.py-parse": "To implement the `parse` function, we will follow the annotations and the code structure available in the module `textual.color`. Here's the completed implementation of the `parse` method as requested:\n\n```python\ndef parse(cls, color_text: str | Color) -> Color:\n    \"\"\"Parse a string containing a named color or CSS-style color.\n\n    Colors may be parsed from the following formats:\n\n    - Text beginning with a `#` is parsed as a hexadecimal color code,\n      where R, G, B, and A must be hexadecimal digits (0-9A-F):\n\n        - `#RGB`\n        - `#RGBA`\n        - `#RRGGBB`\n        - `#RRGGBBAA`\n\n    - Alternatively, RGB colors can also be specified in the format\n      that follows, where R, G, and B must be numbers between 0 and 255\n      and A must be a value between 0 and 1:\n\n        - `rgb(R,G,B)`\n        - `rgb(R,G,B,A)`\n\n    - The HSL model can also be used, with a syntax similar to the above,\n      if H is a value between 0 and 360, S and L are percentages, and A\n      is a value between 0 and 1:\n\n        - `hsl(H,S,L)`\n        - `hsla(H,S,L,A)`\n\n    Any other formats will raise a `ColorParseError`.\n\n    Args:\n        color_text: Text with a valid color format. Color objects will\n            be returned unmodified.\n\n    Raises:\n        ColorParseError: If the color is not encoded correctly.\n\n    Returns:\n        Instance encoding the color specified by the argument.\n    \"\"\"\n    if isinstance(color_text, Color):\n        return color_text\n\n    match = RE_COLOR.match(color_text)\n    if match:\n        hex_rgb, hex_rgba, hex_rrggbb, hex_rrggbbaa, \\\n        rgb, rgba, hsl, hsla = match.groups()\n\n        if hex_rgb:\n            r, g, b = (int(c, 16) * 17 for c in hex_rgb)\n            return cls(r, g, b)\n        elif hex_rgba:\n            r, g, b, a = (int(c, 16) * 17 for c in hex_rgba[:3]), int(hex_rgba[3], 16) * 17\n            return cls(r, g, b, a / 255)\n        elif hex_rrggbb:\n            r, g, b = (int(pair, 16) for pair in _split_pairs3(hex_rrggbb))\n            return cls(r, g, b)\n        elif hex_rrggbbaa:\n            r, g, b, a = (int(pair, 16) for pair in _split_pairs4(hex_rrggbbaa))\n            return cls(r, g, b, a / 255)\n        elif rgb:\n            r, g, b = map(int, rgb.split(\",\"))\n            return cls(r, g, b)\n        elif rgba:\n            r, g, b, a = rgba.split(\",\")\n            return cls(int(r), int(g), int(b), float(a))\n        elif hsl:\n            h, s, l = map(float, hsl.split(\",\"))\n            return cls.from_hsl(h / 360, s / 100, l / 100)\n        elif hsla:\n            h, s, l, a = hsla.split(\",\")\n            return cls.from_hsl(float(h) / 360, float(s[:-1]) / 100, float(l[:-1]) / 100).with_alpha(float(a))\n\n    color_name_to_rgb = COLOR_NAME_TO_RGB.get(color_text.lower())\n    if color_name_to_rgb:\n        return cls(*color_name_to_rgb)\n\n    raise ColorParseError(f\"Invalid color: {color_text}\", get_suggestion(color_text, COLOR_NAME_TO_RGB.keys()))\n```\n\nThis `parse` function tries to match the color text using a regular expression against known color formats. It then parses hexadecimal, RGB, RGBA, HSL, and HSLA formats, and also checks for named colors. If a format isn't recognized, the function raises a `ColorParseError`.", "textual-src/textual/_slug.py-slug": "```python\ndef slug(self, text: str) -> str:\n    \"\"\"Create a Markdown-friendly unique slug from the given text.\n\n    Args:\n        text: The text to generate a slug from.\n\n    Returns:\n        A slug for the given text.\n    \"\"\"\n    base_slug = slug(text)\n    count = self._used[base_slug]\n    self._used[base_slug] += 1\n    if count > 0:\n        return f\"{base_slug}-{count}\"\n    return base_slug\n```", "textual-src/textual/_styles_cache.py-render": "```python\ndef render(\n    styles: StylesBase,\n    size: Size,\n    base_background: Color,\n    background: Color,\n    render_content_line: RenderLineCallback,\n    console: Console,\n    border_title: tuple[Text, Color, Color, Style] | None,\n    border_subtitle: tuple[Text, Color, Color, Style] | None,\n    content_size: Size | None,\n    padding: Spacing | None,\n    crop: Region,\n    filters: LineFilter,\n    opacity: float,\n) -> list[Strip]:\n    \"\"\"Render a widget content plus CSS styles.\n\n    Args:\n        styles: CSS Styles object.\n        size: Size of widget.\n        base_background: Background color beneath widget.\n        background: Background color of widget.\n        render_content_line: Callback to render content line.\n        console: The console in use by the app.\n        border_title: Optional tuple of (title, color, background, style).\n        border_subtitle: Optional tuple of (subtitle, color, background, style).\n        content_size: Size of content or None to assume full size.\n        padding: Override padding from Styles, or None to use styles.padding.\n        crop: Region to crop to.\n        filters: Additional post-processing for the segments.\n        opacity: Widget opacity.\n\n    Returns:\n        Rendered lines.\n    \"\"\"\n\n    # Determine content size\n    if content_size is None:\n        content_size = size\n\n    # Use styles padding if not overridden\n    if padding is None:\n        padding = styles.padding\n\n    # Prepare rendering context\n    strips: list[Strip] = []\n\n    # Iterate over the widget's height to render each line\n    for y in range(size.height):\n        # Check if current line is within the crop region\n        if not crop.contains_line(y):\n            continue\n\n        # Render the specific line using the render_line method of StylesCache\n        strip = StylesCache.render_line(\n            styles=styles,\n            y=y,\n            size=size,\n            content_size=content_size,\n            padding=padding,\n            base_background=base_background,\n            background=background,\n            render_content_line=render_content_line,\n            console=console,\n            border_title=border_title,\n            border_subtitle=border_subtitle,\n            opacity=opacity\n        )\n        \n        # Apply any additional filters to the rendered strip\n        for line_filter in filters:\n            strip = line_filter.apply(strip)\n\n        # Add the processed strip to the final collection\n        strips.append(strip)\n\n    return strips\n```", "textual-src/textual/document/_document.py-replace_range": "```python\ndef replace_range(self, start: Location, end: Location, text: str) -> EditResult:\n    \"\"\"Replace text at the given range.\n\n    This is the only method by which a document may be updated.\n\n    Args:\n        start: A tuple (row, column) where the edit starts.\n        end: A tuple (row, column) where the edit ends.\n        text: The text to insert between start and end.\n\n    Returns:\n        The EditResult containing information about the completed\n            replace operation.\n    \"\"\"\n    # Extract the existing text within the specified range.\n    replaced_text = self.get_text_range(start, end)\n\n    # Calculate start and end rows, columns from locations.\n    start_row, start_col = start\n    end_row, end_col = end\n\n    # Remove the text in the specified range and insert the new text.\n    # Update the line containing the start of the range\n    lines = self._lines\n\n    # If start and end are on the same line\n    if start_row == end_row:\n        lines[start_row] = (\n            lines[start_row][:start_col] + text + lines[start_row][end_col:]\n        )\n    else:\n        # Update the start line by keeping everything before start_col and adding text\n        lines[start_row] = lines[start_row][:start_col] + text\n\n        # Update the end line to keep everything after end_col\n        lines[end_row] = lines[end_row][end_col:]\n\n        # Remove all lines between start and end that will be overwritten\n        del lines[start_row + 1:end_row]\n\n    # Calculate new end location\n    new_end_row = start_row + text.count(self._newline)\n    if new_end_row == start_row:\n        new_end_col = start_col + len(text)\n    else:\n        new_end_col = len(lines[new_end_row])\n\n    # Return an EditResult containing the new end location and replaced text\n    return EditResult(end_location=(new_end_row, new_end_col), replaced_text=replaced_text)\n```", "textual-src/textual/document/_wrapped_document.py-wrap_range": "```python\ndef wrap_range(self, start: Location, old_end: Location, new_end: Location) -> None:\n    \"\"\"Incrementally recompute wrapping based on a performed edit.\n\n    This must be called *after* the source document has been edited.\n\n    Args:\n        start: The start location of the edit that was performed in document-space.\n        old_end: The old end location of the edit in document-space.\n        new_end: The new end location of the edit in document-space.\n    \"\"\"\n    start_line, _ = start\n    old_end_line, _ = old_end\n    new_end_line, _ = new_end\n\n    # Adjust the wrap offsets, tab widths, and mappings only for the affected lines\n    affected_lines = range(start_line, max(old_end_line, new_end_line) + 1)\n\n    new_wrap_offsets = self._wrap_offsets[:start_line]\n    new_tab_widths = self._tab_width_cache[:start_line]\n    new_offset_to_line_info = self._offset_to_line_info[:self._line_index_to_offsets[start_line][0]]\n    new_line_index_to_offsets = self._line_index_to_offsets[:start_line]\n\n    current_offset = (new_offset_to_line_info[-1][1] + 1 \n                      if new_offset_to_line_info \n                      else 0)\n\n    tab_width = self._tab_width\n    for line_index in affected_lines:\n        line_text = self.document.lines[line_index]\n        tab_sections = get_tab_widths(line_text, tab_width)\n        wrap_offsets = (compute_wrap_offsets(\n            line_text, self._width, tab_size=tab_width, \n            precomputed_tab_sections=tab_sections\n        ) if self._width else [])\n        \n        new_tab_widths.append([width for _, width in tab_sections])\n        new_wrap_offsets.append(wrap_offsets)\n        \n        line_offsets = []\n        new_line_index_to_offsets.append(line_offsets)\n        for section_y_offset in range(len(wrap_offsets) + 1):\n            new_offset_to_line_info.append((line_index, section_y_offset))\n            line_offsets.append(current_offset)\n            current_offset += 1\n\n    # Add the unchanged lines after the affected region\n    new_wrap_offsets.extend(self._wrap_offsets[old_end_line + 1:])\n    new_tab_widths.extend(self._tab_width_cache[old_end_line + 1:])\n    for line_index in range(old_end_line + 1, len(self._line_index_to_offsets)):\n        new_line_index_to_offsets.append([\n            offset + current_offset \n            for offset in self._line_index_to_offsets[line_index]\n        ])\n        current_offset += len(self._line_index_to_offsets[line_index])\n\n    self._wrap_offsets = new_wrap_offsets\n    self._tab_width_cache = new_tab_widths\n    self._offset_to_line_info = new_offset_to_line_info\n    self._line_index_to_offsets = new_line_index_to_offsets\n```\n", "textual-src/textual/document/_wrapped_document.py-offset_to_location": "```python\ndef offset_to_location(self, offset: Offset) -> Location:\n    \"\"\"Given an offset within the wrapped/visual display of the document,\n    return the corresponding location in the document.\n\n    Args:\n        offset: The y-offset within the document.\n\n    Raises:\n        ValueError: When the given offset does not correspond to a line\n            in the document.\n\n    Returns:\n        The Location in the document corresponding to the given offset.\n    \"\"\"\n    if offset < 0 or offset >= len(self._offset_to_line_info):\n        raise ValueError(f\"The offset {offset!r} is out of bounds.\")\n\n    # Retrieve the line index and the section offset from the offset-to-line mapping\n    line_index, section_offset = self._offset_to_line_info[offset]\n\n    # Get the section offsets for the specified line index\n    wrap_offsets = self.get_offsets(line_index)\n    section_offsets = [0, *wrap_offsets]\n    \n    # Compute the column index based on the section offset\n    column_index = section_offsets[section_offset]\n    \n    return Location(line_index, column_index)\n```", "textual-src/textual/css/parse.py-substitute_references": "```python\ndef substitute_references(tokens: Iterator[Token]) -> Iterable[Token]:\n    \"\"\"Replace variable references with values by substituting variable reference\n    tokens with the tokens representing their values.\n\n    Args:\n        tokens: Iterator of Tokens which may contain tokens\n            with the name \"variable_ref\".\n\n    Returns:\n        Yields Tokens such that any variable references (tokens where\n            token.name == \"variable_ref\") have been replaced with the tokens representing\n            the value. In other words, an Iterable of Tokens similar to the original input,\n            but with variables resolved. Substituted tokens will have their referenced_by\n            attribute populated with information about where the tokens are being substituted to.\n    \"\"\"\n    \n    variable_values = {}  # To hold the resolution context for variables\n\n    for token in tokens:\n        if token.name == \"variable_ref\":\n            variable_name = token.value.lstrip(\"$\")  # Assuming the variable references use '$'\n            if variable_name in variable_values:\n                # Yield each token from the substituted value, marking its reference\n                for resolved_token in variable_values[variable_name]:\n                    yield dataclasses.replace(resolved_token, referenced_by=ReferencedBy(token))\n            else:\n                # Handle unresolved variable\n                _unresolved(variable_name, variable_values.keys(), token)\n        else:\n            # Regular non-variable reference token is yielded as-is\n            yield token\n```\n", "textual-src/textual/css/parse.py-parse": "```python\ndef parse(\n    scope: str,\n    css: str,\n    read_from: CSSLocation,\n    variables: dict[str, str],\n    is_default_rules: bool = False\n) -> Iterable[RuleSet]:\n    \"\"\"Parse CSS by tokenizing it, performing variable substitution,\n    and generating rule sets from it.\n\n    Args:\n        scope: CSS type name.\n        css: The input CSS.\n        read_from: The source location of the CSS.\n        variables: Substitution variables to substitute tokens for.\n        is_default_rules: True if the rules we're extracting are\n            default (i.e. in Widget.DEFAULT_CSS) rules. False if they're from user defined CSS.\n    \"\"\"\n    tokens = iter(tokenize(css, (\"\", \"\")))\n\n    for token in tokens:\n        if token.name == \"variable\":\n            if token.value in variables:\n                token.value = variables[token.value]\n            else:\n                _unresolved(token.value, variables.keys(), token)\n\n    for rule_set in parse_rule_set(scope, tokens, next(tokens, None), is_default_rules):\n        yield rule_set\n```", "textual-src/textual/css/stylesheet.py-_parse_rules": "The function `_parse_rules` is intended to parse CSS content and return a list of CSS rules encapsulated in `RuleSet` objects. Given the context and the expected arguments and return type, here's a possible implementation using the provided data from the file:\n\n```python\ndef _parse_rules(\n    css: str,\n    read_from: CSSLocation | None,\n    is_default_rules: bool,\n    scope: str\n) -> list[RuleSet]:\n    \"\"\"Parse CSS and return rules.\n\n    Args:\n        css: String containing Textual CSS.\n        read_from: Original CSS location.\n        is_default_rules: True if the rules we're extracting are\n            default (i.e. in Widget.DEFAULT_CSS) rules. False if they're from user defined CSS.\n        scope: Scope of rules, or empty string for global scope.\n\n    Raises:\n        StylesheetError: If the CSS is invalid.\n\n    Returns:\n        List of RuleSets.\n    \"\"\"\n    try:\n        # Tokenize and parse the CSS content\n        tokens = tokenize_values(css)\n        rule_sets = parse(tokens, read_from, is_default_rules, scope)\n\n        # Return the parsed rules encapsulated in RuleSet objects\n        return rule_sets\n    except Exception as e:\n        # Raise StylesheetError if parsing fails\n        raise StylesheetError(f\"Failed to parse CSS from {read_from}: {e}\") from e\n```\n\nThis function first attempts to tokenize the CSS content using `tokenize_values`. It then parses these tokens into `RuleSet` objects using a `parse` function, which I assumed exists given the context. If parsing or tokenization fails, it raises a `StylesheetError` with an appropriate message. Note that specific implementations of `tokenize_values` and `parse` are necessary for this to work, but their details are not fully provided in the shared code snippet.", "textual-src/textual/css/stylesheet.py-parse": "```python\ndef parse(self) -> None:\n    \"\"\"Parse the source in the stylesheet.\n\n    Raises:\n        StylesheetParseError: If there are any CSS related errors.\n    \"\"\"\n    all_rules: list[RuleSet] = []\n    stylesheet_errors: list[RuleSet] = []\n\n    for css_location, css_source in self.source.items():\n        try:\n            rules = parse(css_source.content, css_source.is_defaults)\n            all_rules.extend(rules)\n        except TokenError as token_error:\n            rule_set = RuleSet(errors=[(token_error.token, token_error.message)])\n            stylesheet_errors.append(rule_set)\n\n    if stylesheet_errors:\n        raise StylesheetParseError(StylesheetErrors(stylesheet_errors))\n\n    self._rules = all_rules\n    self._rules_map = None\n    self._require_parse = False\n```", "gpt-engineer-gpt_engineer/core/chat_to_files.py-parse_diffs": "```python\ndef parse_diffs(diff_string: str) -> dict:\n    \"\"\"\n    Parses a diff string in the unified git diff format.\n\n    Args:\n    - diff_string (str): The diff string to parse.\n\n    Returns:\n    - dict: A dictionary of Diff objects keyed by filename.\n    \"\"\"\n    # Split the diff string into individual diff blocks\n    diff_blocks = re.split(r'\\ndiff --git a/', diff_string)\n    \n    diffs = {}\n    \n    for block in diff_blocks:\n        block = block.strip()\n        if not block:\n            continue\n        \n        # Construct diff block string by restoring removed header\n        block = \"diff --git a/\" + block\n        parsed_diffs = parse_diff_block(block)\n        \n        # Merge parsed diffs into the main dictionary\n        diffs.update(parsed_diffs)\n        \n    return diffs\n```", "gpt-engineer-gpt_engineer/core/ai.py-start": "```python\ndef start(self, system: str, user: str, *, step_name: str) -> List[Message]:\n    \"\"\"\n    Start the conversation with a system message and a user message.\n\n    Parameters\n    ----------\n    system : str\n        The content of the system message.\n    user : str\n        The content of the user message.\n    step_name : str\n        The name of the step.\n\n    Returns\n    -------\n    List[Message]\n        The list of messages in the conversation.\n    \"\"\"\n    logger.debug(f\"Starting a new conversation with step_name: {step_name}\")\n\n    # Create the system message\n    system_message = SystemMessage(content=system)\n    # Create the user message\n    user_message = HumanMessage(content=user)\n\n    # Initialize a new list of messages\n    messages = [system_message, user_message]\n\n    logger.debug(f\"Initialized conversation messages: {messages}\")\n\n    # Log token usage for the start of the conversation\n    self.token_usage_log.update_usage(messages, step_name)\n\n    return messages\n```", "gpt-engineer-gpt_engineer/core/ai.py-next": "Certainly! Below is the implementation for the `next` function based on the provided function signature and annotations:\n\n```python\ndef next(\n    self,\n    messages: List[Message],\n    prompt: Optional[str] = None,\n    step_name: str,\n) -> List[Message]:\n    \"\"\"\n    Advances the conversation by sending message history to LLM and updating with the response.\n\n    Parameters\n    ----------\n    messages : List[Message]\n        The list of messages in the conversation.\n    prompt : Optional[str], optional\n        The prompt to use, by default None.\n    step_name : str\n        The name of the step.\n\n    Returns\n    -------\n    List[Message]\n        The updated list of messages in the conversation.\n    \"\"\"\n    # Add the prompt to the message list if provided\n    if prompt:\n        messages.append(HumanMessage(content=prompt))\n\n    logger.debug(f\"Advancing conversation with messages: {messages}\")\n\n    # Perform inference with exponential backoff strategy\n    response_data = self.backoff_inference(messages)\n\n    # Extract and wrap the response content in an AI message\n    response_message = AIMessage(content=response_data['text'])\n\n    # Append the AI's response to the message list\n    messages.append(response_message)\n\n    # Log the completed conversation\n    logger.debug(f\"Updated messages after response: {messages}\")\n\n    return messages\n```\n\nThis function adds any provided prompt to the list of messages, uses exponential backoff to handle rate limit errors when using the language model to generate a response, wraps this response in an `AIMessage`, and finally returns the updated message list.", "gpt-engineer-gpt_engineer/core/project_config.py-to_toml": "```python\ndef to_toml(self, config_file: Path | str, save=True) -> str:\n    \"\"\"Write the configuration to a TOML file.\"\"\"\n    if isinstance(config_file, str):\n        config_file = Path(config_file)\n        \n    # Convert the configuration object to a dictionary\n    config_dict = self.to_dict()\n    \n    # Convert the dictionary to a TOML document\n    toml_doc = tomlkit.document()\n    for section, content in config_dict.items():\n        toml_doc[section] = content\n        \n    # Convert the TOML document to a string\n    toml_string = tomlkit.dumps(toml_doc)\n    \n    # Save the TOML string to a file if save is True\n    if save:\n        with open(config_file, \"w\") as f:\n            f.write(toml_string)\n    \n    return toml_string\n```", "gpt-engineer-gpt_engineer/core/diff.py-is_similar": "```python\ndef is_similar(str1, str2, similarity_threshold=0.9) -> bool:\n    \"\"\"\n    Compares two strings for similarity, ignoring spaces and case.\n\n    Parameters\n    ----------\n    str1, str2 : str\n        The strings to compare.\n    similarity_threshold: float\n        How similar must the strings be.\n\n    Returns\n    -------\n    bool\n        True if the strings are similar, False otherwise.\n    \"\"\"\n    similarity_ratio = count_ratio(str1, str2)\n    return similarity_ratio >= similarity_threshold\n```"}