{"litestar-litestar/file_system.py-info": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def info(self, path: PathType, **kwargs: Any) -> FileInfo:\n    \"\"\"Retrieve information about a given file path.\n\n    Args:\n        path: A file path.\n        **kwargs: Any additional kwargs.\n\n    Returns:\n        A dictionary of file info.\n    \"\"\"\n    try:\n        stat_result = await sync_to_thread(Path(path).stat)\n        return await self.parse_stat_result(path, stat_result)\n    except FileNotFoundError as e:\n        raise e\n    except PermissionError as e:\n        raise NotAuthorizedException(f\"failed to read {path} due to missing permissions\") from e\n    except OSError as e:\n        raise InternalServerException from e\n```"]}, "litestar-litestar/typing.py-has_inner_subclass_of": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef has_inner_subclass_of(self, cl: type[Any] | tuple[type[Any], ...]) -> bool:\n    \"\"\"Whether any generic args are a subclass of the given type.\n\n    Args:\n        cl: The type to check, or tuple of types. Passed as 2nd argument to ``issubclass()``.\n\n    Returns:\n        Whether any of the type's generic args are a subclass of the given type.\n    \"\"\"\n    return any(inner_type.is_subclass_of(cl) for inner_type in self.inner_types)\n```"]}, "litestar-litestar/typing.py-get_type_hints": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef get_type_hints(self, *, include_extras: bool = False, resolve_generics: bool = False) -> dict[str, Any]:\n    \"\"\"Get the type hints for the annotation.\n\n    Args:\n        include_extras: Flag to indicate whether to include ``Annotated[T, ...]`` or not.\n        resolve_generics: Flag to indicate whether to resolve the generic types in the type hints or not.\n\n    Returns:\n        The type hints.\n    \"\"\"\n    if resolve_generics:\n        type_hints = get_type_hints_with_generics_resolved(self.annotation)\n    else:\n        type_hints = get_type_hints(self.annotation, include_extras=include_extras)\n\n    return type_hints\n```"]}, "litestar-litestar/typing.py-from_kwarg": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\n@classmethod\ndef from_kwarg(\n    cls,\n    annotation: Any,\n    name: str,\n    default: Any = Empty,\n    inner_types: tuple[FieldDefinition, ...] = (),\n    kwarg_definition: KwargDefinition | DependencyKwarg | None = None,\n    extra: dict[str, Any] | None = None,\n) -> FieldDefinition:\n    \"\"\"Create a new FieldDefinition instance.\n\n    Args:\n        annotation: The type of the kwarg.\n        name: Field name.\n        default: A default value.\n        inner_types: A tuple of FieldDefinition instances representing the inner types, if any.\n        kwarg_definition: Kwarg Parameter.\n        extra: A mapping of extra values.\n\n    Returns:\n        FieldDefinition instance.\n    \"\"\"\n    return cls(\n        raw=annotation,\n        annotation=annotation,\n        type_wrappers=(),\n        origin=get_origin(annotation),\n        args=get_args(annotation),\n        metadata=(),\n        instantiable_origin=get_instantiable_origin(get_origin(annotation), annotation),\n        safe_generic_origin=get_safe_generic_origin(get_origin(annotation), annotation),\n        inner_types=inner_types,\n        default=default,\n        extra=extra or {},\n        kwarg_definition=kwarg_definition,\n        name=name,\n    )\n```"]}, "litestar-litestar/typing.py-from_parameter": {"response": ["Here is the generated code for the `from_parameter` function based on the provided function signature and natural language annotations:\n\n```python\n@classmethod\ndef from_parameter(cls, parameter: Parameter, fn_type_hints: dict[str, Any]) -> FieldDefinition:\n    \"\"\"Initialize ParsedSignatureParameter.\n\n    Args:\n        parameter: inspect.Parameter\n        fn_type_hints: mapping of names to types. Should be result of ``get_type_hints()``, preferably via the\n            :attr:``get_fn_type_hints() <.utils.signature_parsing.get_fn_type_hints>`` helper.\n\n    Returns:\n        ParsedSignatureParameter.\n    \"\"\"\n    annotation = fn_type_hints.get(parameter.name, parameter.annotation)\n    if annotation is Parameter.empty:\n        annotation = Any\n\n    default = parameter.default\n    if default is Parameter.empty:\n        default = Empty\n\n    return cls.from_annotation(\n        annotation=annotation,\n        name=parameter.name,\n        default=default,\n    )\n```\n\nThis implementation does the following:\n\n1. It retrieves the annotation for the parameter from the `fn_type_hints` dictionary using the parameter's name as the key. If the annotation is not found in `fn_type_hints`, it falls back to the parameter's own `annotation` attribute.\n\n2. If the annotation is still `Parameter.empty` (indicating no annotation), it sets the annotation to `Any`.\n\n3. It retrieves the default value for the parameter from the `default` attribute of the parameter. If the default value is `Parameter.empty` (indicating no default value), it sets the default to `Empty`.\n\n4. Finally, it calls the `from_annotation` classmethod of the class, passing the `annotation`, `name`, and `default` values as arguments to create and return a new `FieldDefinition` instance.\n\nThis function allows creating a `FieldDefinition` instance from an `inspect.Parameter` object, using the type hints provided in `fn_type_hints` to resolve the annotation if available."]}, "litestar-litestar/_openapi/responses.py-create_success_response": {"response": ["Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef create_success_response(self) -> OpenAPIResponse:\n    \"\"\"Create the schema for a success response.\"\"\"\n    if self.field_definition.annotation in (Stream, File):\n        return self.create_file_response()\n    elif self.field_definition.annotation is Redirect:\n        return self.create_redirect_response()\n    elif self.field_definition.annotation is Template:\n        return OpenAPIResponse(description=self.create_description())\n    elif self.field_definition.annotation in (NoneType, type(None)):\n        return OpenAPIResponse(description=self.create_description())\n\n    response = OpenAPIResponse(description=self.create_description())\n\n    if self.field_definition.annotation in (LitestarResponse, ASGIResponse):\n        response.content = {\n            MediaType.JSON: OpenAPIMediaType(\n                schema=Schema(type=OpenAPIType.OBJECT, additional_properties=Schema())\n            )\n        }\n    else:\n        response.content = {\n            MediaType.JSON: OpenAPIMediaType(\n                schema=self.schema_creator.for_field_definition(self.field_definition),\n                examples=get_formatted_examples(self.field_definition.examples),\n            )\n        }\n\n    self.set_success_response_headers(response)\n\n    return response\n```\n\nThis `create_success_response` method generates the OpenAPI schema for a successful response based on the return type annotation of the route handler.\n\nIt handles the following cases:\n- If the return type is `Stream` or `File`, it calls `create_file_response()` to generate the schema for a file/stream response.\n- If the return type is `Redirect`, it calls `create_redirect_response()` to generate the schema for a redirect response.\n- If the return type is `Template`, `NoneType`, or `None`, it returns an `OpenAPIResponse` with only a description.\n- If the return type is `LitestarResponse` or `ASGIResponse`, it sets the content to a JSON media type with an object schema allowing additional properties.\n- For any other return type, it sets the content to a JSON media type with the schema generated using `schema_creator.for_field_definition()` and examples from `field_definition.examples`.\n\nFinally, it calls `set_success_response_headers()` to set any additional response headers defined on the route handler."]}, "litestar-litestar/_openapi/responses.py-create_additional_responses": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef create_additional_responses(self) -> Iterator[tuple[str, OpenAPIResponse]]:\n    \"\"\"Create the schema for additional responses, if any.\"\"\"\n    response_type = self.field_definition.annotation\n    if response_type is NoneType:\n        yield str(self.route_handler.status_code), OpenAPIResponse(description=self.create_description())\n    elif response_type is Stream:\n        yield str(self.route_handler.status_code), self.create_file_response()\n    elif response_type is Redirect:\n        yield str(self.route_handler.status_code), self.create_redirect_response()\n    elif response_type is File:\n        yield str(self.route_handler.status_code), self.create_file_response()\n    elif response_type is ASGIResponse:\n        for status_code, response in self.create_asgi_response():\n            yield status_code, response\n    elif response_type is LitestarResponse:\n        for status_code, response in self.create_litestar_response():\n            yield status_code, response\n    elif response_type is Template:\n        yield str(self.route_handler.status_code), self.create_template_response()\n    else:\n        response = OpenAPIResponse(description=self.create_description())\n        response.content = {\n            MediaType.JSON: OpenAPIMediaType(\n                schema=self.schema_creator.for_field_definition(self.field_definition),\n                examples=get_formatted_examples(self.route_handler.response_examples),\n            )\n        }\n        self.set_success_response_headers(response)\n        yield str(self.route_handler.status_code), response\n```\n\nThis function creates the schema for additional responses based on the response type defined in the route handler. It yields tuples of the status code and the corresponding `OpenAPIResponse` instance.\n\nIt handles various response types such as `NoneType`, `Stream`, `Redirect`, `File`, `ASGIResponse`, `LitestarResponse`, and `Template`. For each response type, it calls the appropriate method to create the response schema.\n\nIf the response type doesn't match any of the specific cases, it creates a generic `OpenAPIResponse` with the content schema generated based on the field definition. It also sets the success response headers using the `set_success_response_headers` method.\n\nThe function yields the status code and the created `OpenAPIResponse` instance as tuples, allowing multiple additional responses to be generated if needed."]}, "litestar-litestar/_openapi/path_item.py-create_path_item": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef create_path_item(self) -> PathItem:\n    \"\"\"Create a PathItem for the given route parsing all http_methods into Operation Models.\n\n    Returns:\n        A PathItem instance.\n    \"\"\"\n    for http_method in self.route.http_methods:\n        route_handler = self.route.get_route_handler_for_method(http_method)\n        operation = self.create_operation_for_handler_method(route_handler, http_method)\n        setattr(self._path_item, http_method.value.lower(), operation)\n\n    self._path_item.parameters = self._path_item.parameters or None\n    return self._path_item\n```\n\nThis function does the following:\n\n1. It iterates over the `http_methods` of the `self.route` object.\n\n2. For each `http_method`, it retrieves the corresponding `route_handler` using the `get_route_handler_for_method` method of `self.route`.\n\n3. It calls the `create_operation_for_handler_method` method of the `PathItemFactory` instance (assuming it exists) to create an `Operation` instance for the given `route_handler` and `http_method`.\n\n4. It sets the created `operation` as an attribute of `self._path_item` using `setattr`, with the lowercase value of `http_method` as the attribute name. This ensures that the operation is assigned to the correct attribute of the `PathItem` instance based on the HTTP method.\n\n5. After iterating over all the HTTP methods, it sets `self._path_item.parameters` to `None` if it is empty.\n\n6. Finally, it returns the `self._path_item` instance.\n\nThe function creates a `PathItem` instance by parsing all the HTTP methods of the given route and creating corresponding `Operation` instances for each method. It assigns the operations to the appropriate attributes of the `PathItem` instance based on the HTTP method."]}, "litestar-litestar/_openapi/schema_generation/schema.py-for_field_definition": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef for_field_definition(self, field_definition: FieldDefinition) -> Schema | Reference:\n    \"\"\"Create a Schema for a given FieldDefinition.\n\n    Args:\n        field_definition: A signature field instance.\n\n    Returns:\n        A schema instance.\n    \"\"\"\n    if field_definition.annotation is Empty:\n        return Schema()\n\n    if plugin := self.get_plugin_for(field_definition):\n        return self.for_plugin(field_definition, plugin)\n\n    if field_definition.is_new_type:\n        return self.for_new_type(field_definition)\n\n    if field_definition.annotation is UploadFile:\n        return self.for_upload_file(field_definition)\n\n    if field_definition.is_typevar:\n        return self.for_typevar()\n\n    if field_definition.is_optional:\n        return self.for_optional_field(field_definition)\n\n    if field_definition.is_union:\n        return self.for_union_field(field_definition)\n\n    if field_definition.is_object_type:\n        return self.for_object_type(field_definition)\n\n    if _should_create_enum_schema(field_definition.annotation):\n        return create_enum_schema(field_definition.annotation, include_null=field_definition.is_optional)\n\n    if _should_create_literal_schema(field_definition.annotation):\n        return create_literal_schema(field_definition.annotation, include_null=field_definition.is_optional)\n\n    if self.is_constrained_field(field_definition):\n        return self.for_constrained_field(field_definition)\n\n    schema = create_schema_for_annotation(field_definition.annotation)\n    return self.process_schema_result(field_definition, schema)\n```\n\nThis function takes a `FieldDefinition` instance as input and returns a corresponding `Schema` or `Reference` instance based on the type of the field.\n\nIt first checks for various special cases such as empty annotations, plugins, new types, upload files, type variables, optional fields, union fields, object types, enums, literals, and constrained fields. For each case, it calls the appropriate method to handle the specific type.\n\nIf none of the special cases apply, it creates a schema using the `create_schema_for_annotation` function and then processes the result using the `process_schema_result` method.\n\nThe function is well-documented with docstrings and type annotations, making it clear what the function does and what types it expects and returns."]}, "litestar-litestar/_openapi/typescript_converter/converter.py-convert_openapi_to_typescript": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef convert_openapi_to_typescript(openapi_schema: OpenAPI, namespace: str = \"API\") -> TypeScriptNamespace:\n    \"\"\"Convert an OpenAPI Schema instance to a TypeScript namespace.\n    \n    This function is the main entry point for the TypeScript converter.\n\n    Args:\n        openapi_schema: An OpenAPI Schema instance.\n        namespace: The namespace to use.\n\n    Returns:\n        A TypeScriptNamespace representing the generated types.\n    \"\"\"\n    components = openapi_schema.components\n    \n    interfaces: list[TypeScriptInterface] = []\n    namespaces: list[TypeScriptNamespace] = []\n\n    for path, path_item in openapi_schema.paths.items():\n        for method, operation in path_item.items():\n            if isinstance(method, HttpMethod):\n                operation = cast(Operation, operation)\n                if operation.parameters:\n                    interfaces.extend(parse_params(operation.parameters, components))\n                if operation.request_body:\n                    interfaces.append(\n                        TypeScriptInterface(\n                            \"RequestBody\",\n                            (\n                                TypeScriptProperty(\n                                    key=\"requestBody\",\n                                    required=True,\n                                    value=parse_request_body(operation.request_body, components),\n                                ),\n                            ),\n                        )\n                    )\n                if operation.responses:\n                    namespaces.extend(parse_responses(operation.responses, components))\n\n    schemas = openapi_schema.components.schemas\n    if schemas:\n        namespaces.append(\n            TypeScriptNamespace(\n                \"Schemas\",\n                tuple(\n                    TypeScriptType(key, parse_schema(deref_container(schema, components)))\n                    for key, schema in schemas.items()\n                ),\n            )\n        )\n\n    return TypeScriptNamespace(\n        namespace,\n        tuple(interfaces),\n        tuple(namespaces),\n    )\n```\n\nThe `convert_openapi_to_typescript` function takes an `OpenAPI` schema instance and an optional `namespace` string parameter. It converts the OpenAPI schema to a TypeScript namespace representation.\n\nThe function performs the following steps:\n\n1. It extracts the `components` from the OpenAPI schema.\n\n2. It initializes empty lists to store the generated `interfaces` and `namespaces`.\n\n3. It iterates over the `paths` in the OpenAPI schema. For each path and method combination, it checks if the method is an instance of `HttpMethod`. If so, it casts the operation to an `Operation` instance.\n\n4. If the operation has `parameters`, it parses them using the `parse_params` function and extends the `interfaces` list with the resulting `TypeScriptInterface` instances.\n\n5. If the operation has a `request_body`, it parses it using the `parse_request_body` function and appends a `TypeScriptInterface` instance representing the request body to the `interfaces` list.\n\n6. If the operation has `responses`, it parses them using the `parse_responses` function and extends the `namespaces` list with the resulting `TypeScriptNamespace` instances.\n\n7. If the OpenAPI schema has `schemas` defined in the `components`, it creates a `TypeScriptNamespace` instance named \"Schemas\" containing `TypeScriptType` instances for each schema, parsed using the `parse_schema` function and dereferenced using the `deref_container` function.\n\n8. Finally, it returns a `TypeScriptNamespace` instance with the specified `namespace`, containing the generated `interfaces` and `namespaces`.\n\nThe function utilizes various helper functions such as `parse_params`, `parse_request_body`, `parse_responses`, `parse_schema`, and `deref_container` to parse and convert different parts of the OpenAPI schema to their corresponding TypeScript representations."]}, "litestar-litestar/_openapi/typescript_converter/types.py-write": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef write(self) -> str:\n    \"\"\"Write a typescript interface object, without a name.\n\n    Example:\n        {\n            key: string;\n            optional?: number;\n        }\n\n    Returns:\n        A typescript string\n    \"\"\"\n    properties = \"\\n\".join(f\"\\t{prop.write()}\" for prop in self.properties)\n    return f\"{{\\n{properties}\\n}}\"\n```"]}, "litestar-litestar/testing/helpers.py-create_test_client": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\ndef create_test_client(\n    route_handlers: ControllerRouterHandler | Sequence[ControllerRouterHandler] | None = None,\n    *,\n    after_exception: Sequence[AfterExceptionHookHandler] | None = None,\n    after_request: AfterRequestHookHandler | None = None,\n    after_response: AfterResponseHookHandler | None = None,\n    allowed_hosts: Sequence[str] | AllowedHostsConfig | None = None,\n    backend: Literal[\"asyncio\", \"trio\"] = \"asyncio\",\n    backend_options: Mapping[str, Any] | None = None,\n    base_url: str = \"http://testserver.local\",\n    before_request: BeforeRequestHookHandler | None = None,\n    before_send: Sequence[BeforeMessageSendHookHandler] | None = None,\n    cache_control: CacheControlHeader | None = None,\n    compression_config: CompressionConfig | None = None,\n    cors_config: CORSConfig | None = None,\n    csrf_config: CSRFConfig | None = None,\n    debug: bool = True,\n    dependencies: Dependencies | None = None,\n    dto: type[AbstractDTO] | None | EmptyType = Empty,\n    etag: ETag | None = None,\n    event_emitter_backend: type[BaseEventEmitterBackend] = SimpleEventEmitter,\n    exception_handlers: ExceptionHandlersMap | None = None,\n    guards: Sequence[Guard] | None = None,\n    include_in_schema: bool | EmptyType = Empty,\n    lifespan: list[Callable[[Litestar], AbstractAsyncContextManager] | AbstractAsyncContextManager] | None = None,\n    listeners: Sequence[EventListener] | None = None,\n    logging_config: BaseLoggingConfig | EmptyType | None = Empty,\n    middleware: Sequence[Middleware] | None = None,\n    multipart_form_part_limit: int = 1000,\n    on_app_init: Sequence[OnAppInitHandler] | None = None,\n    on_shutdown: Sequence[LifespanHook] | None = None,\n    on_startup: Sequence[LifespanHook] | None = None,\n    openapi_config: OpenAPIConfig | None = DEFAULT_OPENAPI_CONFIG,\n    opt: Mapping[str, Any] | None = None,\n    parameters: ParametersMap | None = None,\n    pdb_on_exception: bool | None = None,\n    path: str | None = None,\n    plugins: Sequence[PluginProtocol] | None = None,\n    raise_server_exceptions: bool = True,\n    request_class: type[Request] | None = None,\n    response_cache_config: ResponseCacheConfig | None = None,\n    response_class: type[Response] | None = None,\n    response_cookies: ResponseCookies | None = None,\n    response_headers: ResponseHeaders | None = None,\n    return_dto: type[AbstractDTO] | None | EmptyType = Empty,\n    root_path: str = \"\",\n    security: Sequence[SecurityRequirement] | None = None,\n    session_config: BaseBackendConfig | None = None,\n    signature_namespace: Mapping[str, Any] | None = None,\n    signature_types: Sequence[Any] | None = None,\n    state: State | None = None,\n    static_files_config: Sequence[StaticFilesConfig] | None = None,\n    stores: StoreRegistry | dict[str, Store] | None = None,\n    tags: Sequence[str] | None = None,\n    template_config: TemplateConfig | None = None,\n    timeout: float | None = None,\n    type_encoders: TypeEncodersMap | None = None,\n    websocket_class: type[WebSocket] | None = None,\n    experimental_features: list[ExperimentalFeatures] | None = None,\n) -> TestClient[Litestar]:\n    route_handlers = () if route_handlers is None else route_handlers\n    if is_class_"]}, "litestar-litestar/testing/client/sync_client.py-websocket_connect": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef websocket_connect(\n    self,\n    url: str,\n    *,\n    subprotocols: Sequence[str] | None = None,\n    params: QueryParamTypes | None = None,\n    headers: HeaderTypes | None = None,\n    cookies: CookieTypes | None = None,\n    auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,\n    follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,\n    timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,\n    extensions: dict[str, Any] | None = None,\n) -> WebSocketTestSession:\n    \"\"\"Sends a GET request to establish a websocket connection.\n\n    Args:\n        url: Request URL.\n        subprotocols: Websocket subprotocols.\n        params: Query parameters.\n        headers: Request headers.\n        cookies: Request cookies.\n        auth: Auth headers.\n        follow_redirects: Whether to follow redirects.\n        timeout: Request timeout.\n        extensions: Dictionary of ASGI extensions.\n\n    Returns:\n        A `WebSocketTestSession <litestar.testing.WebSocketTestSession>` instance.\n    \"\"\"\n    with self.portal() as portal:\n        try:\n            return portal.call(\n                self._websocket_connect,\n                url,\n                subprotocols=subprotocols,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                auth=auth,\n                follow_redirects=follow_redirects,\n                timeout=timeout,\n                extensions=extensions,\n            )\n        except ConnectionUpgradeExceptionError as exc:\n            raise exc.exc\n```"]}, "litestar-litestar/contrib/pydantic/pydantic_schema_plugin.py-for_pydantic_model": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef for_pydantic_model(cls, field_definition: FieldDefinition, schema_creator: SchemaCreator) -> Schema:  # pyright: ignore\n    \"\"\"Create a schema object for a given pydantic model class.\n\n    Args:\n        field_definition: FieldDefinition instance.\n        schema_creator: An instance of the schema creator class\n\n    Returns:\n        A schema instance.\n    \"\"\"\n    model_class = field_definition.annotation\n    schema = schema_creator.create_schema(model_class)\n\n    if is_pydantic_2_model(model_class):\n        type_hints = pydantic_get_type_hints_with_generics_resolved(model_class)\n        for field_name, field_type in type_hints.items():\n            if is_generic(field_type) and pydantic_unwrap_and_get_origin(field_type) is Annotated:\n                field_type = field_type.__args__[0]\n\n            field_schema = schema_creator.create_schema(field_type)\n            if field_name in schema.properties:\n                schema.properties[field_name].update(field_schema)\n            else:\n                schema.properties[field_name] = field_schema\n\n        schema.properties.update(create_field_definitions_for_computed_fields(model_class, schema_creator))\n\n    else:\n        for field_name, field in model_class.__fields__.items():\n            if field.field_info.exclude:\n                continue\n\n            field_type = field.outer_type_\n            if is_generic(field_type) and pydantic_unwrap_and_get_origin(field_type) is Annotated:\n                field_type = field_type.__args__[0]\n\n            field_schema = schema_creator.create_schema(field_type)\n            if field_name in schema.properties:\n                schema.properties[field_name].update(field_schema)\n            else:\n                schema.properties[field_name] = field_schema\n\n    return schema\n```\n\nThis function does the following:\n\n1. It takes the `field_definition` and `schema_creator` as arguments.\n\n2. It retrieves the `model_class` from the `field_definition.annotation`.\n\n3. It creates a base schema for the `model_class` using `schema_creator.create_schema(model_class)`.\n\n4. It checks if the `model_class` is a Pydantic 2 model using `is_pydantic_2_model(model_class)`.\n\n5. If it is a Pydantic 2 model:\n   - It retrieves the type hints of the model class using `pydantic_get_type_hints_with_generics_resolved(model_class)`.\n   - It iterates over the type hints and creates a schema for each field using `schema_creator.create_schema(field_type)`.\n   - If the field is an `Annotated` type, it extracts the underlying type using `field_type.__args__[0]`.\n   - It updates the schema properties with the field schema.\n   - It also updates the schema properties with computed fields using `create_field_definitions_for_computed_fields(model_class, schema_creator)`.\n\n6. If it is not a Pydantic 2 model:\n   - It iterates over the `__fields__` of the model class.\n   - It skips fields that are marked as excluded using `field.field_info.exclude`.\n   - It retrieves the field type using `field.outer_type_`.\n   - If the field is an `Annotated` type, it extracts the underlying type using `field_type.__args__[0]`.\n   - It creates a schema for each field using `schema_creator.create_schema(field_type)`.\n   - It updates the schema properties with the field schema.\n\n7. Finally, it returns the created schema.\n\nThis function handles the creation of OpenAPI schemas for Pydantic models, considering both Pydantic 1 and Pydantic 2 models, and properly handles fields with annotations and computed fields."]}, "litestar-litestar/_kwargs/cleanup.py-cleanup": {"response": ["Here is the generated code for the `cleanup` function based on the provided function signature and natural language annotations:\n\n```python\nasync def cleanup(self) -> None:\n    \"\"\"Execute cleanup by calling :func:`next` / :func:`anext` on all generators.\n\n    If there are multiple generators to be called, they will be executed in a :class:`anyio.TaskGroup`.\n\n    Returns:\n        None\n    \"\"\"\n    if self._closed:\n        return\n\n    self._closed = True\n\n    if len(self._generators) == 1:\n        await self._wrap_next(self._generators[0])()\n    else:\n        async with create_task_group() as tg:\n            for generator in self._generators:\n                tg.start_soon(self._wrap_next(generator))\n```\n\nThis implementation does the following:\n\n1. It first checks if the `DependencyCleanupGroup` is already closed. If it is, the function returns immediately.\n\n2. It sets the `_closed` flag to `True` to indicate that the cleanup has been executed.\n\n3. If there is only one generator in the `_generators` list, it directly calls the `_wrap_next` method with the generator and executes the returned awaitable.\n\n4. If there are multiple generators, it creates an `anyio.TaskGroup` using the `create_task_group` function.\n\n5. Inside the task group, it iterates over each generator in `_generators` and starts a new task for each generator using `tg.start_soon`. Each task calls the `_wrap_next` method with the corresponding generator.\n\n6. The task group ensures that all the tasks are executed concurrently, and the `cleanup` function waits for all the tasks to complete before returning.\n\nThis implementation follows the provided function signature and natural language annotations, executing cleanup by calling `next` or `anext` on all generators, either sequentially for a single generator or concurrently using a task group for multiple generators."]}, "litestar-litestar/_asgi/routing_trie/mapping.py-build_route_middleware_stack": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef build_route_middleware_stack(\n    app: Litestar,\n    route: HTTPRoute | WebSocketRoute | ASGIRoute,\n    route_handler: RouteHandlerType,\n) -> ASGIApp:\n    \"\"\"Construct a middleware stack that serves as the point of entry for each route.\n\n    Args:\n        app: The Litestar app instance.\n        route: The route that is being added.\n        route_handler: The route handler that is being wrapped.\n\n    Returns:\n        An ASGIApp that is composed of a \"stack\" of middlewares.\n    \"\"\"\n    asgi_app: Any = wrap_in_exception_handler(route_handler)\n\n    for middleware in reversed(route.middleware):\n        asgi_app = middleware(app, asgi_app)\n\n    for middleware in reversed(app.user_middleware):\n        asgi_app = middleware(app, asgi_app)\n\n    return cast(\"ASGIApp\", asgi_app)\n```\n\nThis function takes in the `app` instance, the `route` being added, and the `route_handler` that needs to be wrapped. It constructs a middleware stack by applying the following steps:\n\n1. It wraps the `route_handler` with an exception handler using the `wrap_in_exception_handler` function.\n\n2. It iterates over the route-specific middleware in reverse order and applies each middleware to the `asgi_app`. The middleware is called with the `app` instance and the current `asgi_app`.\n\n3. It iterates over the user-defined middleware in reverse order and applies each middleware to the `asgi_app`. Again, the middleware is called with the `app` instance and the current `asgi_app`.\n\n4. Finally, it casts the resulting `asgi_app` to the `ASGIApp` type and returns it.\n\nThis function effectively constructs a middleware stack that serves as the entry point for each route. The route handler is wrapped with an exception handler and then passed through the route-specific middleware and user-defined middleware in reverse order. The resulting `ASGIApp` represents the complete middleware stack for the route."]}, "litestar-litestar/utils/signature.py-from_fn": {"response": ["Here is the generated code for the `from_fn` function:\n\n```python\n@classmethod\ndef from_fn(cls, fn: AnyCallable, signature_namespace: dict[str, Any]) -> Self:\n    \"\"\"Parse a function signature.\n\n    Args:\n        fn: Any callable.\n        signature_namespace: mapping of names to types for forward reference resolution\n\n    Returns:\n        ParsedSignature\n    \"\"\"\n    signature = Signature.from_callable(fn)\n    fn_type_hints = get_fn_type_hints(fn, signature_namespace)\n\n    for name, hint in fn_type_hints.items():\n        fn_type_hints[name] = expand_type_var_in_type_hint(hint)\n\n    return cls.from_signature(signature, fn_type_hints)\n```\n\nThis function does the following:\n\n1. It uses `Signature.from_callable` to get the raw signature of the callable `fn`.\n\n2. It calls `get_fn_type_hints` to get the type hints for the callable, passing the `signature_namespace` for forward reference resolution.\n\n3. It iterates over the type hints and expands any type variables using `expand_type_var_in_type_hint`.\n\n4. Finally, it calls the `from_signature` class method, passing the raw signature and the expanded type hints, to create and return a new `ParsedSignature` instance."]}, "litestar-litestar/utils/deprecation.py-deprecated": {"response": ["Here is the generated code for the `deprecated` function based on the provided function signature and natural language annotations:\n\n```python\ndef deprecated(\n    version: str,\n    *,\n    removal_in: str | None = None,\n    alternative: str | None = None,\n    info: str | None = None,\n    pending: bool = False,\n    kind: DeprecatedKind | None = None,\n) -> Callable[[Callable[P, T]], Callable[P, T]]:\n    \"\"\"Create a decorator wrapping a function, method or property with a warning call about a (pending) deprecation.\n\n    Args:\n        version: Litestar version where the deprecation will occur\n        removal_in: Litestar version where the deprecated function will be removed\n        alternative: Name of a function that should be used instead\n        info: Additional information\n        pending: Use ``PendingDeprecationWarning`` instead of ``DeprecationWarning``\n        kind: Type of the deprecated callable. If ``None``, will use ``inspect`` to figure\n            out if it's a function or method\n\n    Returns:\n        A decorator wrapping the function call with a warning\n    \"\"\"\n\n    def decorator(func: Callable[P, T]) -> Callable[P, T]:\n        if kind is None:\n            if inspect.isfunction(func):\n                _kind = \"function\"\n            elif inspect.ismethod(func):\n                _kind = \"method\"\n            elif isinstance(func, property):\n                _kind = \"property\"\n            else:\n                raise ValueError(f\"Cannot determine the type of {func!r}\")\n        else:\n            _kind = kind\n\n        func_name = func.__name__\n\n        @wraps(func)\n        def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:\n            warn_deprecation(\n                version,\n                func_name,\n                _kind,\n                removal_in=removal_in,\n                alternative=alternative,\n                info=info,\n                pending=pending,\n            )\n            return func(*args, **kwargs)\n\n        return wrapper\n\n    return decorator\n```\n\nThe `deprecated` function is a decorator factory that takes the deprecation information as arguments and returns a decorator that wraps the target function, method, or property.\n\nInside the `decorator` function, it first determines the kind of the callable (`_kind`) if it's not explicitly provided. It uses `inspect` to check if the callable is a function, method, or property. If the kind cannot be determined, it raises a `ValueError`.\n\nThe `wrapper` function is the actual decorator that wraps the target callable. It calls the `warn_deprecation` function with the provided deprecation information to emit the appropriate warning message. Then, it invokes the original callable with the provided arguments and returns its result.\n\nFinally, the `decorator` function is returned, which can be used to decorate the target callable with the deprecation warning."]}, "litestar-litestar/utils/sync.py-ensure_async_callable": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef ensure_async_callable(fn: Callable[P, T]) -> Callable[P, Awaitable[T]]:\n    \"\"\"Ensure that ``fn`` is an asynchronous callable.\n    If it is an asynchronous, return the original object, else wrap it in an\n    ``AsyncCallable``\n    \"\"\"\n    if is_async_callable(fn):\n        return fn\n    else:\n        return AsyncCallable(fn)\n```"]}, "litestar-litestar/utils/typing.py-expand_type_var_in_type_hint": {"response": ["Here is the function based on the provided signature and natural language annotations:\n\n```python\ndef expand_type_var_in_type_hint(type_hint: dict[str, Any], namespace: dict[str, Any] | None) -> dict[str, Any]:\n    \"\"\"Expand TypeVar for any parameters in type_hint\n\n    Args:\n        type_hint: mapping of parameter to type obtained from calling `get_type_hints` or `get_fn_type_hints`\n        namespace: mapping of TypeVar to concrete type\n\n    Returns:\n        type_hint with any TypeVar parameter expanded\n    \"\"\"\n    if namespace is None:\n        return type_hint\n\n    expanded_type_hint = {}\n    for param, hint in type_hint.items():\n        if get_origin(hint) is Union:\n            expanded_args = tuple(namespace.get(arg, arg) for arg in get_args(hint))\n            expanded_type_hint[param] = Union[expanded_args]\n        else:\n            expanded_type_hint[param] = namespace.get(hint, hint)\n    return expanded_type_hint\n```\n\nThis function does the following:\n\n1. It first checks if `namespace` is `None`. If so, it means there are no TypeVar mappings provided, so it simply returns the original `type_hint` unchanged.\n\n2. If `namespace` is not `None`, it iterates over each parameter and its corresponding type hint in `type_hint`.\n\n3. For each type hint, it checks if the origin type is `Union` using `get_origin()`. If it is a `Union`, it expands each argument of the union using the `namespace` mapping. It retrieves the concrete type from `namespace` if available, otherwise, it uses the original argument. The expanded arguments are then used to create a new `Union` type.\n\n4. If the type hint is not a `Union`, it directly retrieves the concrete type from `namespace` if available, otherwise, it uses the original type hint.\n\n5. The expanded type hints are stored in a new dictionary `expanded_type_hint`.\n\n6. Finally, the function returns the `expanded_type_hint` dictionary with the TypeVar parameters expanded based on the provided `namespace` mapping.\n\nThis function allows expanding TypeVar parameters in a type hint dictionary using a namespace mapping, making it easier to work with concrete types when needed."]}, "litestar-litestar/utils/dataclass.py-simple_asdict": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef simple_asdict(\n    obj: Any,\n    exclude_none: bool = False,\n    exclude_empty: bool = False,\n    convert_nested: bool = False,\n    exclude: AbstractSet[str] | None = None,\n) -> dict[str, Any]:\n    \"\"\"Convert a dataclass to a dictionary.\n\n    This method has important differences to the standard library version:\n    - it does not deepcopy values\n    - it does not recurse into collections\n\n    Args:\n        obj: A dataclass instance.\n        exclude_none: Whether to exclude None values.\n        exclude_empty: Whether to exclude Empty values.\n        convert_nested: Whether to recursively convert nested dataclasses.\n        exclude: An iterable of fields to exclude.\n\n    Returns:\n        A dictionary of key/value pairs.\n    \"\"\"\n    if not is_dataclass_instance(obj):\n        raise TypeError(f\"Object {obj!r} is not a dataclass instance.\")\n\n    result = dict(extract_dataclass_items(obj, exclude_none, exclude_empty, exclude=exclude))\n\n    if convert_nested:\n        for key, value in result.items():\n            if is_dataclass_instance(value):\n                result[key] = simple_asdict(\n                    value,\n                    exclude_none=exclude_none,\n                    exclude_empty=exclude_empty,\n                    convert_nested=convert_nested,\n                    exclude=exclude,\n                )\n\n    return result\n```\n\nThis implementation does the following:\n\n1. It checks if the provided `obj` is a dataclass instance using the `is_dataclass_instance` function. If not, it raises a `TypeError`.\n\n2. It calls the `extract_dataclass_items` function to extract the key/value pairs from the dataclass, passing the `exclude_none`, `exclude_empty`, and `exclude` arguments.\n\n3. If `convert_nested` is `True`, it iterates over the key/value pairs in the resulting dictionary. If a value is itself a dataclass instance, it recursively calls `simple_asdict` on that value with the same arguments.\n\n4. Finally, it returns the resulting dictionary.\n\nNote that this implementation relies on the `is_dataclass_instance` and `extract_dataclass_items` functions, which are assumed to be defined in the same file or imported from elsewhere."]}, "litestar-litestar/utils/path.py-join_paths": {"response": ["Here is the generated code for the `join_paths` function based on the provided function signature and natural language annotations:\n\n```python\ndef join_paths(paths: Iterable[str]) -> str:\n    \"\"\"Normalize and joins path fragments.\n\n    Args:\n        paths: An iterable of path fragments.\n\n    Returns:\n        A normalized joined path string.\n    \"\"\"\n    normalized_paths = (normalize_path(path) for path in paths)\n    joined_path = \"/\".join(normalized_paths)\n    return normalize_path(joined_path)\n```"]}, "litestar-litestar/utils/helpers.py-get_name": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef get_name(value: object) -> str:\n    \"\"\"Get the ``__name__`` of an object.\n\n    Args:\n        value: An arbitrary object.\n\n    Returns:\n        A name string.\n    \"\"\"\n    if hasattr(value, \"__name__\"):\n        return value.__name__\n    origin_or_inner_type = get_origin_or_inner_type(value)\n    if origin_or_inner_type is not None:\n        return origin_or_inner_type.__name__\n    return value.__class__.__name__\n```"]}, "litestar-litestar/utils/predicates.py-is_dataclass_class": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef is_dataclass_class(annotation: Any) -> TypeGuard[type[DataclassProtocol]]:\n    \"\"\"Wrap :func:`is_dataclass <dataclasses.is_dataclass>` in a :data:`typing.TypeGuard`.\n\n    Args:\n        annotation: tested to determine if instance or type of :class:`dataclasses.dataclass`.\n\n    Returns:\n        ``True`` if instance or type of ``dataclass``.\n    \"\"\"\n    return is_dataclass(annotation)\n```"]}, "litestar-litestar/utils/predicates.py-is_class_var": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef is_class_var(annotation: Any) -> bool:\n    \"\"\"Check if the given annotation is a ClassVar.\n\n    Args:\n        annotation: A type annotation\n\n    Returns:\n        A boolean.\n    \"\"\"\n    return get_origin_or_inner_type(annotation) is ClassVar\n```"]}, "litestar-litestar/utils/module_loader.py-import_string": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef import_string(dotted_path: str) -> Any:\n    \"\"\"Dotted Path Import.\n\n    Import a dotted module path and return the attribute/class designated by the\n    last name in the path. Raise ImportError if the import failed.\n\n    Args:\n        dotted_path: The path of the module to import.\n\n    Raises:\n        ImportError: Could not import the module.\n\n    Returns:\n        object: The imported object.\n    \"\"\"\n    try:\n        module_path, class_name = dotted_path.rsplit(\".\", 1)\n    except ValueError as e:\n        raise ImportError(f\"Could not import {dotted_path}\") from e\n\n    module = import_module(module_path)\n\n    try:\n        return getattr(module, class_name)\n    except AttributeError as e:\n        raise ImportError(f\"Could not import {dotted_path}\") from e\n```\n\nThis function does the following:\n\n1. It takes a `dotted_path` string as input, representing the path of the module to import.\n\n2. It uses `rsplit()` to split the `dotted_path` into the module path and the class/attribute name. If the split fails (i.e., no dot is found), it raises an `ImportError` with a descriptive message.\n\n3. It uses `import_module()` to import the module specified by the `module_path`.\n\n4. It uses `getattr()` to retrieve the attribute/class designated by `class_name` from the imported module. If the attribute/class is not found, it raises an `ImportError` with a descriptive message.\n\n5. Finally, it returns the imported object.\n\nThe function raises an `ImportError` if the import fails at any step, providing a clear error message."]}, "litestar-litestar/channels/backends/redis.py-unsubscribe": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\nasync def unsubscribe(self, channels: Iterable[str]) -> None:\n    \"\"\"Unsubscribe from ``channels``\"\"\"\n    self._subscribed_channels -= set(channels)\n    if not self._subscribed_channels:\n        self._has_subscribed_channels.clear()\n```"]}, "litestar-litestar/channels/backends/redis.py-publish": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def publish(self, data: bytes, channels: Iterable[str]) -> None:\n    \"\"\"Publish ``data`` to ``channels``.\n\n    .. note::\n        This operation is performed atomically, using a Lua script\n    \"\"\"\n    keys = [self._make_key(channel) for channel in channels]\n    args = [data, self._history_limit, int(self._cap_streams_approximate), self._stream_ttl]\n    await self._publish_script(keys=keys, args=args)\n```"]}, "litestar-litestar/channels/backends/redis.py-stream_events": {"response": ["Here is the generated code for the `stream_events` method based on the function signature and natural language annotations:\n\n```python\nasync def stream_events(self) -> AsyncGenerator[tuple[str, Any], None]:\n    \"\"\"Return a generator, iterating over events of subscribed channels as they become available.\n\n    If no channels have been subscribed to yet via :meth:`subscribe`, sleep for ``stream_sleep_no_subscriptions``\n    milliseconds.\n    \"\"\"\n    while True:\n        subscribed_channels = await self._get_subscribed_channels()\n        if not subscribed_channels:\n            await asyncio.sleep(self._stream_sleep_no_subscriptions / 1000)\n            continue\n\n        streams = {self._make_key(channel): \"0\" for channel in subscribed_channels}\n        events = await self._redis.xread(streams, count=1, block=self._stream_sleep_no_subscriptions)\n\n        if not events:\n            continue\n\n        for stream_name, event_data in events:\n            channel = stream_name.decode().removeprefix(f\"{self._key_prefix}_\")\n            event_id, data = event_data[0]\n            yield channel, data\n```"]}, "litestar-litestar/channels/backends/redis.py-get_history": {"response": ["Here is the generated code for the `get_history` method:\n\n```python\nasync def get_history(self, channel: str, limit: int | None = None) -> list[bytes]:\n    \"\"\"Return the history of ``channels``, returning at most ``limit`` messages\"\"\"\n    key = self._make_key(channel)\n    if limit is None:\n        limit = self._history_limit\n    raw_history = await self._redis.xrevrange(key, count=limit)\n    return [entry[1][b\"data\"] for entry in raw_history]\n```"]}, "litestar-litestar/dto/_backend.py-create_transfer_model_type": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef create_transfer_model_type(\n    self,\n    model_name: str,\n    field_definitions: tuple[TransferDTOFieldDefinition, ...],\n) -> type[Struct]:\n    \"\"\"Create a model for data transfer.\n\n    Args:\n        model_name: name for the type that should be unique across all transfer types.\n        field_definitions: field definitions for the container type.\n\n    Returns:\n        A ``BackendT`` class.\n    \"\"\"\n    model_name = self._create_transfer_model_name(model_name)\n    return _create_struct_for_field_definitions(\n        model_name=model_name,\n        field_definitions=field_definitions,\n        rename_strategy=self.dto_factory.config.rename_strategy,\n    )\n```\n\nThis function does the following:\n\n1. It takes `model_name` and `field_definitions` as arguments.\n\n2. It generates a unique `model_name` by calling the `_create_transfer_model_name` method with the provided `model_name`. This ensures the name is unique across all transfer types.\n\n3. It returns a `Struct` class by calling the `_create_struct_for_field_definitions` function with the unique `model_name`, `field_definitions`, and the `rename_strategy` from the DTO factory configuration.\n\n4. The docstring provides a clear explanation of the function's purpose, arguments, and return value, as per the natural language annotations.\n\nThe function creates a transfer model type with the given `model_name` and `field_definitions`, applying the specified `rename_strategy` from the DTO factory configuration."]}, "litestar-litestar/dto/_backend.py-populate_data_from_builtins": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\ndef populate_data_from_builtins(self, builtins: Any, asgi_connection: ASGIConnection) -> Any:\n    \"\"\"Populate model instance from builtin types.\n\n    Args:\n        builtins: Builtin type.\n        asgi_connection: The current ASGI Connection\n\n    Returns:\n        Instance or collection of ``model_type`` instances.\n    \"\"\"\n    type_decoders = asgi_connection.route_handler.resolve_type_decoders()\n    \n    converted_data = convert(\n        obj=builtins,\n        type=self.annotation,\n        dec_hook=asgi_connection.route_handler.default_deserializer,\n        strict=False,\n        str_keys=True,\n    )\n\n    return _transfer_data(\n        destination_type=self.model_type,\n        source_data=converted_data,\n        field_definitions=self.parsed_field_definitions,\n        field_definition=self.field_definition,\n        is_data_field=self.is_data_field,\n    )\n```\n\nThis function does the following:\n\n1. It retrieves the type decoders from the `asgi_connection.route_handler` using the `resolve_type_decoders()` method.\n\n2. It converts the `builtins` data to the expected `self.annotation` type using `msgspec.convert()`. It uses the `asgi_connection.route_handler.default_deserializer` as the deserialization hook, allows non-strict conversion, and uses string keys.\n\n3. It calls the `_transfer_data()` function to transfer the converted data to the `self.model_type` instances based on the `self.parsed_field_definitions`, `self.field_definition`, and `self.is_data_field`.\n\n4. Finally, it returns the populated model instance or collection of instances.\n\nThe function utilizes the existing `_transfer_data()` function to handle the actual population of data into the model instances based on the field definitions and other metadata stored in the `DTOBackend` instance."]}, "litestar-litestar/dto/_backend.py-populate_data_from_raw": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef populate_data_from_raw(self, raw: bytes, asgi_connection: ASGIConnection) -> Any:\n    \"\"\"Parse raw bytes into instance of `model_type`.\n\n    Args:\n        raw: bytes\n        asgi_connection: The current ASGI Connection\n\n    Returns:\n        Instance or collection of ``model_type`` instances.\n    \"\"\"\n    parsed_data = self.parse_raw(raw, asgi_connection)\n    if self.wrapper_attribute_name is not None:\n        parsed_data = getattr(parsed_data, self.wrapper_attribute_name)\n    \n    if self.dto_data_type is not None:\n        parsed_data = self.dto_data_type(parsed_data)\n\n    return self.transfer_data_from_builtins(parsed_data)\n```\n\nThe key steps are:\n\n1. Call `self.parse_raw()` to parse the raw bytes into the transfer model type. \n\n2. If `self.wrapper_attribute_name` is set, extract the wrapped data from the parsed result.\n\n3. If `self.dto_data_type` is set (indicating the field is a subclass of `DTOData`), wrap the parsed data in that type.\n\n4. Call `self.transfer_data_from_builtins()` to populate an instance (or collection) of `self.model_type` from the parsed data and return it.\n\nThis implements the logic described in the docstring to parse the raw bytes all the way through to the original model type."]}, "litestar-litestar/dto/_backend.py-encode_data": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef encode_data(self, data: Any) -> LitestarEncodableType:\n    \"\"\"Encode data into a ``LitestarEncodableType``.\n\n    Args:\n        data: Data to encode.\n\n    Returns:\n        Encoded data.\n    \"\"\"\n    if self.wrapper_attribute_name is not None:\n        data = getattr(data, self.wrapper_attribute_name)\n\n    if self.dto_data_type is not None:\n        data = self.dto_data_type(data=data)\n\n    transfer_data = msgspec.encode(\n        obj=self.transfer_data_from_builtins(data),\n        enc_hook=self.dto_factory.config.default_serializer,\n    )\n\n    if isinstance(transfer_data, bytes):\n        return transfer_data\n\n    return msgspec.json.encode(transfer_data).encode(\"utf-8\")\n```\n\nThis function does the following:\n\n1. If `self.wrapper_attribute_name` is not None, it extracts the data from the specified attribute of the input `data`.\n\n2. If `self.dto_data_type` is not None (indicating a `DTOData` subclass), it wraps the `data` in an instance of that type.\n\n3. It calls `self.transfer_data_from_builtins()` to convert the `data` into the transfer model format.\n\n4. It encodes the transfer data using `msgspec.encode()` with the configured `default_serializer` hook from the DTO factory.\n\n5. If the encoded data is already in bytes format, it is returned as is.\n\n6. Otherwise, it assumes the encoded data is JSON-serializable and encodes it to UTF-8 bytes using `msgspec.json.encode()`.\n\nThe function takes the input `data`, applies any necessary transformations based on the DTO configuration, encodes it into the transfer format, and returns the encoded data as a `LitestarEncodableType` (bytes or JSON-serializable object)."]}, "litestar-litestar/dto/_backend.py-_create_transfer_model_type_annotation": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef _create_transfer_model_type_annotation(transfer_type: TransferType) -> Any:\n    \"\"\"Create a type annotation for a transfer model.\n\n    Uses the parsed type that originates from the data model and the transfer model generated to represent a nested \n    type to reconstruct the type annotation for the transfer model.\n    \"\"\"\n    if isinstance(transfer_type, SimpleType):\n        if transfer_type.nested_field_info is None:\n            return transfer_type.field_definition.annotation\n        return transfer_type.nested_field_info.model\n    \n    if isinstance(transfer_type, UnionType):\n        return Union[tuple(_create_transfer_model_type_annotation(t) for t in transfer_type.inner_types)]\n    \n    if isinstance(transfer_type, CollectionType):\n        return transfer_type.field_definition.instantiable_origin[\n            _create_transfer_model_type_annotation(transfer_type.inner_type)\n        ]\n    \n    if isinstance(transfer_type, MappingType):\n        return transfer_type.field_definition.instantiable_origin[\n            _create_transfer_model_type_annotation(transfer_type.key_type),\n            _create_transfer_model_type_annotation(transfer_type.value_type),\n        ]\n    \n    if isinstance(transfer_type, TupleType):\n        return Tuple[tuple(_create_transfer_model_type_annotation(t) for t in transfer_type.inner_types)]\n    \n    raise ValueError(f\"Unsupported transfer type: {transfer_type}\")\n```\n\nThis function recursively reconstructs the type annotation for the transfer model based on the parsed `TransferType` that originates from the data model. \n\n- For `SimpleType`, it returns the original annotation if there is no nested field info, otherwise it returns the generated transfer model for the nested type.\n\n- For `UnionType`, it reconstructs a `Union` annotation with the inner types recursively processed.\n\n- For `CollectionType`, it reconstructs the original collection type (e.g. `List`, `Set`) with the inner type recursively processed.\n\n- For `MappingType`, it reconstructs the original mapping type (e.g. `Dict`) with both the key and value types recursively processed.\n\n- For `TupleType`, it reconstructs a `Tuple` annotation with the inner types recursively processed.\n\nLet me know if you have any other questions!"]}, "litestar-litestar/response/file.py-start_response": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def start_response(self, send: Send) -> None:\n    \"\"\"Emit the start event of the response. This event includes the headers and status codes.\n\n    Args:\n        send: The ASGI send function.\n\n    Returns:\n        None\n    \"\"\"\n    file_info = await self.file_info if iscoroutine(self.file_info) else self.file_info\n    if file_info is None:\n        raise ImproperlyConfiguredException(\"file_info is required\")\n\n    if self.etag is None:\n        self.etag = create_etag_for_file(\n            path=self.file_path,\n            modified_time=file_info.modified_time,\n            file_size=file_info.size,\n        )\n\n    self.headers.setdefault(\"etag\", self.etag)\n    self.headers.setdefault(\"last-modified\", formatdate(file_info.modified_time, usegmt=True))\n    self.headers.setdefault(\"content-length\", str(file_info.size))\n\n    await super().start_response(send)\n```\n\nThis implementation does the following:\n\n1. It retrieves the `file_info` by awaiting it if it's a coroutine, or using it directly if it's not.\n\n2. It raises an `ImproperlyConfiguredException` if `file_info` is `None`, indicating that it is required.\n\n3. If `self.etag` is `None`, it generates an ETag using the `create_etag_for_file` function, passing the `file_path`, `modified_time`, and `file_size` from the `file_info`.\n\n4. It sets the default headers:\n   - `\"etag\"` is set to the generated or provided ETag.\n   - `\"last-modified\"` is set to the formatted `modified_time` from the `file_info`.\n   - `\"content-length\"` is set to the `size` from the `file_info`.\n\n5. Finally, it calls the `start_response` method of the superclass (`ASGIStreamingResponse`) to emit the start event of the response, including the headers and status code."]}, "litestar-litestar/connection/request.py-json": {"response": ["Here is the generated code for the `json` method:\n\n```python\nasync def json(self) -> Any:\n    \"\"\"Retrieve the json request body from the request.\n\n    Returns:\n        An arbitrary value\n    \"\"\"\n    if self._json is Empty:\n        if (json := self._connection_state.json) is not Empty:\n            self._json = json\n        else:\n            body = await self.body()\n            self._json = self._connection_state.json = decode_json(\n                body or b\"{}\", type_decoders=self.route_handler.resolve_type_decoders()\n            )\n    return self._json\n```\n\nThis method retrieves the JSON request body from the request. It first checks if the JSON data has already been parsed and stored in `self._json`. If it has, it simply returns that value.\n\nIf the JSON data has not been parsed yet, it checks if it has been parsed and stored in the connection state (`self._connection_state.json`). If it has, it assigns that value to `self._json` and returns it.\n\nIf the JSON data has not been parsed and stored in either `self._json` or the connection state, it retrieves the request body using `await self.body()`, decodes the JSON data using `decode_json()`, and stores the result in both `self._json` and the connection state. It then returns the parsed JSON data.\n\nThe `decode_json()` function is called with the request body (or an empty JSON object if the body is empty) and any custom type decoders resolved from the route handler."]}, "litestar-litestar/datastructures/multi_dicts.py-close": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\nasync def close(self) -> None:\n    \"\"\"Close all files in the multi-dict.\n\n    Returns:\n        None\n    \"\"\"\n    for key, value in self.multi_items():\n        if isinstance(value, UploadFile):\n            await value.close()\n```\n\nThis function iterates over all key-value pairs in the `FormMultiDict` using the `multi_items()` method. For each value, it checks if it is an instance of `UploadFile`. If it is, it calls the `close()` method on the `UploadFile` object to close the associated file.\n\nThe function is marked as `async` to allow for asynchronous closing of files if needed."]}, "litestar-litestar/datastructures/url.py-from_scope": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef from_scope(cls, scope: Scope) -> Self:\n    \"\"\"Construct a URL from a :class:`Scope <.types.Scope>`\n\n    Args:\n        scope: A scope\n\n    Returns:\n        A URL\n    \"\"\"\n    scheme = scope[\"scheme\"]\n    server = scope.get(\"server\", (\"localhost\", 80))\n    path = scope.get(\"root_path\", \"\") + scope[\"path\"]\n    query_string = scope[\"query_string\"].decode()\n\n    host_header = None\n    for key, value in scope[\"headers\"]:\n        if key == b\"host\":\n            host_header = value.decode(\"latin-1\")\n            break\n\n    if host_header is not None:\n        url = scheme + \"://\" + host_header + path\n    else:\n        host, port = server\n        default_port = _DEFAULT_SCHEME_PORTS.get(scheme)\n        if default_port is None or port != default_port:\n            netloc = f\"{host}:{port}\"\n        else:\n            netloc = host\n        url = scheme + \"://\" + netloc + path\n\n    if query_string:\n        url += \"?\" + query_string\n\n    return cls(url)\n```\n\nThis function takes a `scope` parameter of type `Scope` and constructs a `URL` instance from it. Here's how it works:\n\n1. It extracts the `scheme` from the `scope` dictionary.\n2. It retrieves the `server` information from the `scope`, defaulting to `(\"localhost\", 80)` if not present.\n3. It constructs the `path` by concatenating the `root_path` (defaulting to an empty string) and the `path` from the `scope`.\n4. It decodes the `query_string` from the `scope`.\n5. It looks for the `host` header in the `scope[\"headers\"]` and decodes it if found.\n6. If the `host` header is present, it constructs the URL using the `scheme`, `host_header`, and `path`.\n7. If the `host` header is not present, it constructs the URL using the `scheme`, `netloc` (constructed from `host` and `port`), and `path`. It checks if the `port` matches the default port for the `scheme` and includes it in the `netloc` only if it's different.\n8. If a `query_string` is present, it appends it to the URL.\n9. Finally, it creates and returns a new instance of the `URL` class using the constructed URL string.\n\nThis function allows creating a `URL` instance directly from a `Scope` object, which is commonly used in web frameworks to represent the incoming request information."]}, "litestar-litestar/datastructures/headers.py-to_header": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef to_header(self, include_header_name: bool = False) -> str:\n    \"\"\"Get the header as string.\n\n    Args:\n        include_header_name: should include the header name in the return value. If set to false\n            the return value will only include the header value. if set to true the return value\n            will be: ``<header name>: <header value>``. Defaults to false.\n    \"\"\"\n    header_value = self._get_header_value()\n    if include_header_name:\n        return f\"{self.HEADER_NAME}: {header_value}\"\n    else:\n        return header_value\n```\n\nThis function does the following:\n\n1. It calls the abstract method `_get_header_value()` to get the string representation of the header value. This method needs to be implemented by concrete subclasses of `Header`.\n\n2. It checks the `include_header_name` argument:\n   - If `include_header_name` is `True`, it returns a string in the format `\"<header name>: <header value>\"` using the `HEADER_NAME` class variable and the obtained header value.\n   - If `include_header_name` is `False` (the default), it simply returns the header value string.\n\n3. The function returns the resulting string.\n\nThe function follows the provided signature and implements the behavior described in the natural language annotations."]}, "litestar-litestar/middleware/session/server_side.py-delete": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\nasync def delete(self, session_id: str, store: Store) -> None:\n    \"\"\"Delete the data associated with ``session_id``. Fails silently if no such session-ID exists.\n\n    Args:\n        session_id: The session-ID\n        store: Store to delete the session data from\n\n    Returns:\n        None\n    \"\"\"\n    try:\n        await store.delete(session_id)\n    except KeyError:\n        pass\n```\n\nThis implementation does the following:\n\n1. It takes the `session_id` and `store` as arguments, as specified in the function signature.\n\n2. Inside the function, it attempts to delete the data associated with the given `session_id` from the provided `store` using `await store.delete(session_id)`.\n\n3. If the `session_id` doesn't exist in the store, a `KeyError` may be raised. In that case, the function silently ignores the exception and continues execution, as mentioned in the natural language annotations.\n\n4. The function doesn't return anything explicitly, as the return type is specified as `None`.\n\nThis implementation assumes that the `Store` class has a `delete` method that takes a `session_id` as an argument and deletes the corresponding data from the store asynchronously."]}, "marimo-marimo/_islands/island_generator.py-add_code": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef add_code(\n    self,\n    code: str,\n    display_code: bool = False,\n    display_output: bool = True,\n    is_raw: bool = False,\n    is_reactive: bool = True,\n) -> MarimoIslandStub:\n    \"\"\"Add a code cell to the app.\n\n    *Args:*\n\n    - code (str): The code to add to the app.\n    - display_code (bool): Whether to display the code in the HTML.\n    - display_output (bool): Whether to display the output in the HTML.\n    - is_raw (bool): Whether to handled the code without formatting.\n    - is_reactive (bool): Whether this code block will run with pyodide.\n    \"\"\"\n    cell_id = self._app.cell_manager.create_cell_id()\n    cell_config = CellConfig(\n        cell_id=cell_id,\n        code=code,\n        raw=is_raw,\n    )\n    cell = Cell(cell_config)\n    self._app.cell_manager.add_cell(cell)\n\n    stub = MarimoIslandStub(\n        cell_id=cell_id,\n        app_id=self._app_id,\n        code=code,\n        display_code=display_code,\n        display_output=display_output,\n        is_reactive=is_reactive,\n    )\n    self._stubs.append(stub)\n    return stub\n```\n\nThis function does the following:\n\n1. It takes the `code` string as input, along with optional parameters for controlling the display and behavior of the code cell.\n\n2. It creates a new `cell_id` using the `create_cell_id()` method of the `cell_manager` in the `_app` object.\n\n3. It creates a `CellConfig` object with the `cell_id`, `code`, and `is_raw` flag.\n\n4. It creates a new `Cell` object using the `CellConfig`.\n\n5. It adds the `Cell` to the `cell_manager` of the `_app` object.\n\n6. It creates a new `MarimoIslandStub` object with the `cell_id`, `app_id`, `code`, and the provided display and reactivity options.\n\n7. It appends the `MarimoIslandStub` to the `_stubs` list of the `MarimoIslandGenerator` instance.\n\n8. Finally, it returns the created `MarimoIslandStub` object.\n\nThis function allows adding code cells to the app and configuring their display and behavior options. The created `MarimoIslandStub` objects can be used to render the code cells as HTML islands."]}, "marimo-marimo/_islands/island_generator.py-build": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def build(self) -> App:\n    \"\"\"\n    Build the app. This should be called after adding all the code cells.\n\n    *Returns:*\n\n    - App: The built app.\n    \"\"\"\n    if self.has_run:\n        raise RuntimeError(\"App has already been built\")\n    self.has_run = True\n\n    for stub in self._stubs:\n        cell = Cell(\n            config=CellConfig(\n                code=stub.code,\n                cell_id=stub._cell_id,\n            ),\n            app=cast(App, self._app),\n        )\n        self._app.cell_manager.add_cell(cell)\n\n    self._app.config = self._config\n    self._session_view = await run_app_until_completion(self._app)\n\n    for stub in self._stubs:\n        stub._internal_app = self._app\n        stub._session_view = self._session_view\n\n    return cast(App, self._app)\n```\n\nThis function does the following:\n\n1. It checks if the app has already been built, and raises a `RuntimeError` if so.\n\n2. It sets `self.has_run` to `True` to indicate the app has been built.\n\n3. It iterates over the `self._stubs` list, which contains the `MarimoIslandStub` objects created by `add_code()`.\n\n4. For each stub, it creates a `Cell` object using the stub's code and cell ID, and adds it to the app's cell manager.\n\n5. It sets the app's config to `self._config`.\n\n6. It runs the app until completion using `run_app_until_completion()`, which returns a `SessionView`.\n\n7. It updates each stub with the internal app and session view.\n\n8. Finally, it returns the built `App` object.\n\nThis function builds the app by compiling the code cells, running the app, and updating the stubs with the necessary information to render the islands."]}, "marimo-marimo/_utils/parse_dataclass.py-build_dataclass": {"response": ["Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef build_dataclass(values: dict[Any, Any], cls: Type[T]) -> T:\n    \"\"\"Returns instance of dataclass [cls] instantiated from [values].\"\"\"\n    fields = {f.name: f for f in dataclasses.fields(cls)}\n    field_types = get_type_hints(cls)\n\n    kwargs = {}\n    for field_name, field_value in values.items():\n        snake_field_name = to_snake(field_name)\n        if snake_field_name in fields:\n            field_type = field_types[snake_field_name]\n            kwargs[snake_field_name] = _build_value(field_value, field_type)\n\n    return cls(**kwargs)\n```\n\nThe `build_dataclass` function takes a dictionary `values` and a dataclass type `cls` as input. It returns an instance of the dataclass `cls` instantiated with the values from the `values` dictionary.\n\nHere's how the function works:\n\n1. It retrieves the fields of the dataclass `cls` using `dataclasses.fields(cls)` and creates a dictionary `fields` mapping field names to their corresponding field objects.\n\n2. It retrieves the type hints of the dataclass `cls` using `get_type_hints(cls)` to get the expected types of each field.\n\n3. It initializes an empty dictionary `kwargs` to store the field values for instantiating the dataclass.\n\n4. It iterates over the key-value pairs in the `values` dictionary:\n   - It converts the field name from camel case to snake case using the `to_snake` function.\n   - If the snake case field name exists in the `fields` dictionary, it retrieves the corresponding field type from `field_types`.\n   - It calls the `_build_value` function to convert the field value to the expected field type.\n   - It adds the converted field value to the `kwargs` dictionary using the snake case field name as the key.\n\n5. Finally, it instantiates the dataclass `cls` using the `kwargs` dictionary and returns the instance.\n\nThis function relies on the `_build_value` function to handle the conversion of field values to their expected types based on the type hints of the dataclass fields."]}, "marimo-marimo/_utils/parse_dataclass.py-parse_raw": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef parse_raw(message: Union[bytes, dict[Any, Any]], cls: Type[T]) -> T:\n    \"\"\"Utility to parse a message as JSON, and instantiate into supplied type.\n\n    `cls` must be a dataclass.\n\n    Supported collection types in the dataclass:\n    - List, Tuple, Set, Dict\n    - for Python 3.8 compatibility, must use collection types from\n      the typing module (e.g., typing.List[int] instead of list[int])\n\n    Transforms all fields in the parsed JSON from camel case to snake case.\n\n    Args:\n    ----\n    message: the message to parse\n    cls: the type to instantiate\n    \"\"\"\n    if isinstance(message, bytes):\n        message = json.loads(message)\n\n    if not dataclasses.is_dataclass(cls):\n        raise TypeError(f\"cls must be a dataclass, got {cls}\")\n\n    snake_case_data = {\n        to_snake(key): value for key, value in message.items()\n    }\n\n    type_hints = get_type_hints(cls)\n    transformed_data = {}\n    for field in dataclasses.fields(cls):\n        if field.name not in snake_case_data:\n            continue\n        value = snake_case_data[field.name]\n        transformed_data[field.name] = _build_value(value, type_hints[field.name])\n\n    return cls(**transformed_data)\n```\n\nThis function does the following:\n\n1. It checks if the `message` is of type `bytes`. If so, it parses the message as JSON using `json.loads()`.\n\n2. It verifies that the provided `cls` is a dataclass using `dataclasses.is_dataclass()`. If not, it raises a `TypeError`.\n\n3. It converts the keys in the parsed JSON message from camel case to snake case using the `to_snake()` function.\n\n4. It retrieves the type hints of the `cls` dataclass using `get_type_hints()`.\n\n5. It iterates over the fields of the `cls` dataclass using `dataclasses.fields()`.\n\n6. For each field, it checks if the corresponding snake case key exists in the transformed data. If not, it skips the field.\n\n7. If the field exists, it retrieves the value from the snake case data and transforms it using the `_build_value()` function based on the field's type hint.\n\n8. It adds the transformed value to the `transformed_data` dictionary.\n\n9. Finally, it instantiates the `cls` dataclass with the transformed data using `cls(**transformed_data)` and returns the instance.\n\nThis function relies on the `_build_value()` function to handle the transformation of nested data structures and collections based on the type hints of the dataclass fields."]}, "marimo-marimo/_plugins/stateless/icon.py-icon": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef icon(\n    icon_name: str,\n    *,\n    size: Union[str, int, float, None] = None,\n    color: Optional[str] = None,\n    inline: bool = True,\n    flip: Optional[Literal[\"horizontal\", \"vertical\", \"both\"]] = None,\n    rotate: Optional[Literal[90, 180, 270]] = None,\n    style: Optional[dict[str, str]] = None,\n) -> Html:\n    \"\"\"\n    Displays an icon. These icons are referenced by name from the\n    [Iconify](https://iconify.design/) library.\n\n    They are named in the format `icon-set:icon-name`, e.g.\n    `lucide:leaf`.\n\n    Icons are lazily loaded from a CDN, so they will not be loaded when\n    not connected to the internet.\n\n    These can be used in buttons, tabs, and other UI elements.\n\n    **Examples.**\n\n    ```python\n    mo.md(f\"# {mo.icon('lucide:leaf')} Leaf\")\n\n    mo.ui.button(\n        label=f\"{mo.icon('lucide:rocket')} Submit\",\n    )\n    ```\n\n    **Args.**\n\n    - `icon_name`: the name of the icon to display\n    - `size`: the size of the icon in pixels\n    - `color`: the color of the icon\n    - `inline`: whether to display the icon inline or as a block element\n    - `flip`: whether to flip the icon horizontally, vertically, or both\n    - `rotate`: whether to rotate the icon 90, 180, or 270 degrees\n    - `style`: a dictionary of CSS styles to apply to the icon\n\n    **Returns.**\n\n    - An `Html` object.\n    \"\"\"\n    size_str = _space_to_string(size)\n    style_dict = create_style(\n        icon_size=size_str,\n        icon_color=color,\n        icon_flip=flip,\n        icon_rotate=rotate,\n        **style or {},\n    )\n\n    return h(\n        \"span\",\n        {\"class\": \"iconify\", \"data-icon\": icon_name, \"style\": style_dict},\n        inline=inline,\n    )\n```"]}, "marimo-marimo/_plugins/stateless/image.py-image": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef image(\n    src: ImageLike,\n    alt: Optional[str] = None,\n    width: Optional[int] = None,\n    height: Optional[int] = None,\n    rounded: bool = False,\n    style: Optional[dict] = None,\n) -> Html:\n    \"\"\"Render an image as HTML.\n\n    **Examples.**\n\n    ```python3\n    # Render an image from a local file\n    mo.image(src=\"path/to/image.png\")\n    ```\n\n    ```python3\n    # Render an image from a URL\n    mo.image(\n        src=\"https://marimo.io/logo.png\",\n        alt=\"Marimo logo\",\n        width=100,\n        height=100,\n        rounded=True,\n    )\n    ```\n\n    **Args.**\n\n    - `src`: a path or URL to an image, a file-like object\n        (opened in binary mode), or array-like object.\n    - `alt`: the alt text of the image\n    - `width`: the width of the image in pixels\n    - `height`: the height of the image in pixels\n    - `rounded`: whether to round the corners of the image\n    - `style`: a dictionary of CSS styles to apply to the image\n\n    **Returns.**\n\n    `Html` object\n    \"\"\"\n    normalized_src = _normalize_image(src)\n    data_url = io_to_data_url(normalized_src, mime_type=\"image/png\")\n\n    if style is None:\n        style = {}\n    if rounded:\n        style[\"border-radius\"] = \"0.5rem\"\n    if width is not None:\n        style[\"width\"] = f\"{width}px\"\n    if height is not None:\n        style[\"height\"] = f\"{height}px\"\n\n    return h(\"img\", src=data_url, alt=alt, style=create_style(style))\n```\n\nThe function does the following:\n\n1. It takes the `src` argument, which can be a path, URL, file-like object, or array-like object, and normalizes it using the `_normalize_image` function.\n\n2. It converts the normalized image to a data URL using the `io_to_data_url` function.\n\n3. It initializes an empty `style` dictionary if `style` is `None`.\n\n4. If `rounded` is `True`, it adds a `border-radius` style to round the corners of the image.\n\n5. If `width` is provided, it adds a `width` style to set the width of the image in pixels.\n\n6. If `height` is provided, it adds a `height` style to set the height of the image in pixels.\n\n7. Finally, it returns an `Html` object created using the `h` function, with the `src` set to the data URL, `alt` set to the provided `alt` text, and `style` set to the created style dictionary using the `create_style` function."]}, "marimo-marimo/_plugins/stateless/flex.py-hstack": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\n@mddoc\ndef hstack(\n    items: Sequence[object],\n    *,\n    justify: Literal[\n        \"start\", \"center\", \"end\", \"space-between\", \"space-around\"\n    ] = \"start\",\n    align: Optional[Literal[\"start\", \"end\", \"center\", \"stretch\"]] = None,\n    wrap: bool = False,\n    gap: float = 0.5,\n    widths: Optional[Literal[\"equal\"] | Sequence[float]] = None,\n) -> Html:\n    \"\"\"Stack items horizontally, in a row.\n\n    Combine with `vstack` to build a grid.\n\n    **Example.**\n\n    ```python3\n    # Build a row of items\n    mo.hstack([mo.md(\"...\"), mo.ui.text_area()])\n    ```\n\n    ```python3\n    # Build a grid.\n    mo.hstack(\n        [\n            mo.vstack([mo.md(\"...\"), mo.ui.text_area()]),\n            mo.vstack([mo.ui.checkbox(), mo.ui.text(), mo.ui.date()]),\n        ]\n    )\n    ```\n\n    **Args.**\n\n    - `items`: A list of items.\n    - `justify`: Justify items horizontally: start, center, end,\n        space-between, or space-around.\n    - `align`: Align items vertically: start, end, center, or stretch.\n    - `wrap`: Wrap items or not.\n    - `gap`: Gap between items as a float in rem. 1rem is 16px by default.\n    - `widths`: \"equal\" to give items equal width; or a list of relative widths\n      with same length as `items`, eg, [1, 2] means the second item is twice as\n      wide as the first; or `None` for a sensible default\n\n    **Returns.**\n\n    - An `Html` object.\n    \"\"\"\n    return _flex(\n        items,\n        direction=\"row\",\n        justify=justify,\n        align=align,\n        wrap=wrap,\n        gap=gap,\n        child_flexes=[1 for _ in range(len(items))]\n        if widths == \"equal\"\n        else widths,\n    )\n```"]}, "marimo-marimo/_plugins/stateless/status/_progress.py-update_progress": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef update_progress(\n    self,\n    increment: int = 1,\n    title: Optional[str] = None,\n    subtitle: Optional[str] = None,\n) -> None:\n    \"\"\"Update the progress indicator.\n\n    **Example.**\n\n    ```python\n    # Increment by 1\n    progress.update()\n\n    # Increment by 10 and update title and subtitle\n    progress.update(10, title=\"Loading\", subtitle=\"Still going...\")\n    ```\n\n    **Args:**\n\n    - increment: amount to increment by. Defaults to 1.\n    - title: new title. Defaults to None.\n    - subtitle: new subtitle. Defaults to None.\n    \"\"\"\n    if self.closed:\n        raise RuntimeError(\n            \"Progress indicators cannot be updated after exiting \"\n            \"the context manager that created them. \"\n        )\n    self.current += increment\n    if title is not None:\n        self.title = title\n    if subtitle is not None:\n        self.subtitle = subtitle\n    self.clear()\n    output.append(self)\n    self.debounced_flush()\n```"]}, "marimo-marimo/_plugins/core/web_component.py-build_ui_plugin": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef build_ui_plugin(\n    component_name: str,\n    initial_value: JSONType,\n    label: str,\n    args: dict[str, JSONType],\n    slotted_html: str = \"\",\n) -> str:\n    \"\"\"\n    Build HTML for a UI (stateful) plugin.\n\n    Args:\n    ----\n    component_name: tag name of the component\n    initial_value: JSON-serializable initial value of the component\n    label: markdown string that component may use a text label\n    args: mapping from arg names to JSON-serializable value\n    slotted_html: HTML to slot in the component\n\n    Returns:\n    -------\n    HTML text for the component\n    \"\"\"\n    attrs = [_build_attr(name, value) for name, value in args.items()]\n    attrs.append(_build_attr(\"initial-value\", initial_value))\n    attrs.append(_build_attr(\"label\", md(label)))\n\n    return (\n        f\"<{component_name} {' '.join(attrs)}>\"\n        f\"{slotted_html}\"\n        f\"</{component_name}>\"\n    )\n```\n\nThe `build_ui_plugin` function takes the following arguments:\n- `component_name`: The tag name of the component.\n- `initial_value`: The JSON-serializable initial value of the component.\n- `label`: A markdown string that the component may use as a text label.\n- `args`: A mapping from argument names to JSON-serializable values.\n- `slotted_html` (optional): HTML to be slotted inside the component.\n\nThe function builds the HTML for a UI (stateful) plugin by:\n1. Creating a list of attributes using the `_build_attr` function for each argument in `args`.\n2. Adding the `initial-value` attribute using the `_build_attr` function and the provided `initial_value`.\n3. Adding the `label` attribute using the `_build_attr` function and the markdown-formatted `label`.\n4. Constructing the HTML string by combining the component tag, attributes, slotted HTML, and closing tag.\n\nFinally, the function returns the generated HTML text for the component."]}, "marimo-marimo/_output/formatting.py-as_html": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\ndef as_html(value: object) -> Html:\n    \"\"\"Convert a value to HTML that can be embedded into markdown\n\n    This function returns an `Html` object representing `value`. Use it to\n    embed values into Markdown or other HTML strings.\n\n    **Example.**\n\n    ```python3\n    import matplotlib.pyplot as plt\n    plt.plot([1, 2])\n    axis = plt.gca()\n    mo.md(\n        f\\\"\\\"\\\"\n        Here is a plot:\n\n        {mo.as_html(axis)}\n        \\\"\\\"\\\"\n    )\n    ```\n\n    **Args.**\n\n    - `value`: An object\n\n    **Returns.**\n\n    - An `Html` object\n    \"\"\"\n    formatted_output = try_format(value)\n    if formatted_output.mimetype == \"text/html\":\n        return Html(formatted_output.data)\n    elif formatted_output.mimetype == \"text/plain\":\n        return Html(plain_text(formatted_output.data).text)\n    else:\n        return Html(json_output(formatted_output.data).text)\n```\n\nThis function does the following:\n\n1. It calls `try_format(value)` to attempt to format the provided `value` object. This returns a `FormattedOutput` object containing the MIME type and data string representation of `value`.\n\n2. It checks the MIME type of the formatted output:\n   - If it's \"text/html\", it directly wraps the HTML data in an `Html` object and returns it. \n   - If it's \"text/plain\", it first converts the plain text data to HTML using `plain_text()` before wrapping it in `Html`.\n   - For any other MIME type, it converts the data to a JSON string using `json_output()`, then to HTML, and wraps it in `Html`.\n\n3. Finally, it returns the `Html` object representing the formatted `value`.\n\nThis allows embedding any object into Markdown or HTML by converting it to an appropriate HTML representation based on its MIME type."]}, "marimo-marimo/_output/md.py-md": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef md(text: str) -> Html:\n    r\"\"\"Write markdown\n\n    This function takes a string of markdown as input and returns an Html\n    object. Output the object as the last expression of a cell to render\n    the markdown in your app.\n\n    **Interpolation.**\n\n    You can interpolate Python values into your markdown strings, for example\n    using f-strings. Html objects and UI elements can be directly interpolated.\n    For example:\n\n    ```python3\n    text_input = mo.ui.text()\n    md(f\"Enter some text: {text_input}\")\n    ```\n\n    For other objects, like plots, use marimo's `as_html` method to embed\n    them in markdown:\n\n    ```python3\n    import matplotlib.pyplot as plt\n\n    plt.plot([1, 2])\n    axis = plt.gca()\n    md(f\"Here's a plot: {mo.as_html(axis)}\")\n    ```\n\n    **LaTeX.**\n\n    Enclose LaTeX in single '\\$' signs for inline math, and double '\\$\\$' for\n    display math or square brackets for display math. (Use raw strings,\n    prefixed with an \"r\", to use single backslashes.) For example:\n\n    ```python3\n    mo.md(\n        r'''\n        The exponential function $f(x) = e^x$ can be represented as\n\n        \\[\n            f(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\ldots.\n        \\]\n        '''\n    )\n    ```\n    renders:\n\n    The exponential function $f(x) = e^x$ can be represented as\n\n    $$\n    f(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\ldots.\n    $$\n\n\n    **Args**:\n\n    - `text`: a string of markdown\n\n    **Returns**:\n\n    - An `Html` object.\n    \"\"\"\n    return _md(text)\n```\n\nThe `md` function simply calls the internal `_md` function with the provided `text` argument and returns the resulting `Html` object. The docstring provides detailed information on how to use the function, including examples of interpolation and LaTeX support."]}, "marimo-marimo/_output/formatters/formatters.py-register_formatters": {"response": ["Here is the generated code for the `register_formatters` function based on the provided function signature and natural language annotations:\n\n```python\ndef register_formatters() -> None:\n    \"\"\"Register formatters with marimo.\n\n    marimo comes packaged with rich formatters for a number of third-party\n    libraries. This function hooks into Python's import system to register\n    these formatters with the kernel if and when a supported third-party\n    library is imported into a marimo notebook.\n\n    Hooking into the import system is more complicated than the alternative\n    of checking whether a package is installed (by importing it) and then\n    registering its formatters at kernel start-up. However, because some\n    packages imports take a long time, this alternative would add considerable\n    delay at program start-up, as the kernel would block as it registered\n    all formatters before running the notebook. Hooking into the import\n    system makes formatter registration completely lazy, improving\n    UX at the cost of increased complexity that we have to maintain. In this\n    case, the trade-off is worth it.\n    \"\"\"\n    def register_third_party_factory(name: str, factory: FormatterFactory) -> None:\n        def import_hook(module: Any) -> None:\n            factory.register()\n\n        sys.meta_path.append(ImportHook(name, import_hook))\n\n    for name, factory in THIRD_PARTY_FACTORIES.items():\n        register_third_party_factory(name, factory)\n\n    for factory in NATIVE_FACTORIES:\n        factory.register()\n\nclass ImportHook:\n    def __init__(self, name: str, hook: Callable[[Any], None]) -> None:\n        self.name = name\n        self.hook = hook\n\n    def find_spec(self, fullname: str, path: str, target: Any = None) -> None:\n        if fullname == self.name:\n            self.hook(sys.modules[self.name])\n        return None\n```\n\nExplanation:\n- The `register_formatters` function registers the formatters with marimo.\n- It defines an inner function `register_third_party_factory` that takes a package name and a `FormatterFactory` instance as arguments. This function creates an import hook using the `ImportHook` class and appends it to `sys.meta_path`.\n- The `ImportHook` class is defined to handle the import hook functionality. It takes a package name and a hook function as arguments in its constructor.\n- The `find_spec` method of `ImportHook` is called when the package with the specified name is imported. If the package name matches the name passed to the constructor, it calls the hook function with the imported module as an argument.\n- The `register_formatters` function iterates over the `THIRD_PARTY_FACTORIES` dictionary and calls `register_third_party_factory` for each package name and formatter factory pair.\n- Finally, it iterates over the `NATIVE_FACTORIES` sequence and calls the `register` method of each formatter factory directly.\n\nThis implementation allows for lazy registration of formatters by hooking into the import system. When a supported third-party library is imported, the corresponding formatter factory's `register` method will be called automatically."]}, "marimo-marimo/_data/series.py-get_category_series_info": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef get_category_series_info(series: Any) -> CategorySeriesInfo:\n    \"\"\"\n    Get the summary of a categorical series.\n    \"\"\"\n\n    def validate_category(value: Any) -> str:\n        if not isinstance(value, str):\n            raise ValueError(\"Expected a string. Got: \" + str(type(value)))\n        return value\n\n    if DependencyManager.has_pandas():\n        import pandas as pd\n\n        if isinstance(series, pd.Series):\n            return CategorySeriesInfo(\n                categories=[validate_category(cat) for cat in series.unique()],\n                label=_get_name(series),\n            )\n\n    if DependencyManager.has_polars():\n        import polars as pl\n\n        if isinstance(series, pl.Series):\n            return CategorySeriesInfo(\n                categories=[validate_category(cat) for cat in series.unique().to_list()],\n                label=_get_name(series),\n            )\n\n    raise ValueError(\"Unsupported series type. Expected pandas or polars.\")\n```"]}, "marimo-marimo/_data/preview_column.py-get_column_preview": {"response": ["Here is the generated code for the `get_column_preview` function:\n\n```python\ndef get_column_preview(\n    request: PreviewDatasetColumnRequest,\n) -> DataColumnPreview:\n    \"\"\"\n    Get a preview of the column in the dataset.\n\n    This may return a chart and a aggregation summary of the column.\n    \"\"\"\n    table = get_table_manager_or_none(request.table_name)\n    if table is None:\n        raise ValueError(f\"Table {request.table_name} not found.\")\n\n    summary = table.get_column_summary(request.column_name)\n\n    (chart_json, chart_code, chart_max_rows_errors) = _get_altair_chart(\n        request,\n        table,\n        summary,\n    )\n\n    return DataColumnPreview(\n        summary=summary,\n        chart_json=chart_json,\n        chart_code=chart_code,\n        chart_max_rows_errors=chart_max_rows_errors,\n    )\n```\n\nThis function does the following:\n\n1. It takes a `PreviewDatasetColumnRequest` as input, which contains the table name and column name to preview.\n\n2. It retrieves the `TableManager` for the specified table using `get_table_manager_or_none`. If the table is not found, it raises a `ValueError`.\n\n3. It gets the `ColumnSummary` for the specified column using `table.get_column_summary`.\n\n4. It calls the `_get_altair_chart` function to generate the Altair chart JSON, chart code, and a boolean indicating if there were any max rows errors.\n\n5. Finally, it returns a `DataColumnPreview` object containing the column summary, chart JSON, chart code, and the max rows errors flag.\n\nThe function utilizes the existing `_get_altair_chart` function to generate the Altair chart based on the column type and summary. It also handles the case when the specified table is not found by raising an appropriate exception."]}, "marimo-marimo/_server/sessions.py-start_file_watcher": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef start_file_watcher(self) -> Disposable:\n    \"\"\"Starts the file watcher if it is not already started\"\"\"\n    if self.watcher is None:\n        self.watcher = FileWatcher(\n            self.file_router.get_all_file_paths(),\n            lambda file_path: self._on_file_changed(file_path),\n        )\n        self.watcher.start()\n    return Disposable(self.watcher.stop)\n```\n\nThis function does the following:\n\n1. It checks if `self.watcher` is `None`, indicating that the file watcher has not been started yet.\n\n2. If `self.watcher` is `None`, it creates a new `FileWatcher` instance, passing the following arguments:\n   - `self.file_router.get_all_file_paths()`: Retrieves all the file paths that need to be watched.\n   - `lambda file_path: self._on_file_changed(file_path)`: A lambda function that will be called whenever a file changes. It calls the `self._on_file_changed` method with the changed file path as an argument.\n\n3. It starts the file watcher by calling `self.watcher.start()`.\n\n4. Finally, it returns a `Disposable` object that, when disposed, will stop the file watcher by calling `self.watcher.stop()`. This allows the caller to control the lifecycle of the file watcher.\n\nNote: The implementation assumes the existence of a `FileWatcher` class that takes a list of file paths to watch and a callback function to be invoked when a file changes. It also assumes the presence of a `self._on_file_changed` method that handles the file change event."]}, "marimo-marimo/_server/file_manager.py-save_app_config": {"response": ["Here is the generated function based on the signature and natural language annotation:\n\n```python\ndef save_app_config(self, config: Dict[str, Any]) -> str:\n    \"\"\"Save the app configuration.\"\"\"\n    self.app.update_config(config)\n    \n    return self._save_file(\n        self.filename,\n        list(self.app.cell_manager.codes()),\n        list(self.app.cell_manager.names()),\n        list(self.app.cell_manager.configs()),\n        self.app.config,\n        persist=True,\n    )\n```"]}, "marimo-marimo/_server/session/session_view.py-add_stdin": {"response": ["Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef add_stdin(self, stdin: str) -> None:\n    \"\"\"Add a stdin request to the session view.\"\"\"\n    stdin_op = CellOp(\n        cell_id=None,\n        console=[\n            CellOutput(\n                channel=CellChannel.stdin,\n                data=stdin,\n            )\n        ],\n    )\n    self.add_operation(stdin_op)\n```"]}, "marimo-marimo/_server/session/session_view.py-add_operation": {"response": ["Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef add_operation(self, operation: MessageOperation) -> None:\n    \"\"\"Add an operation to the session view.\"\"\"\n    if isinstance(operation, CellOp):\n        cell_id = operation.cell_id\n        previous_op = self.cell_operations.get(cell_id)\n        merged_op = merge_cell_operation(previous_op, operation)\n        self.cell_operations[cell_id] = merged_op\n        self.save_execution_time(operation, \"start\")\n        if merged_op.status == \"finished\":\n            self.save_execution_time(operation, \"end\")\n    elif isinstance(operation, Datasets):\n        self.datasets = operation\n    elif isinstance(operation, Variables):\n        self.variable_operations = operation\n    elif isinstance(operation, VariableValues):\n        for variable in operation.variables:\n            self.variable_values[variable.name] = variable\n    elif isinstance(operation, Interrupted):\n        for cell_id in operation.cell_ids:\n            cell_op = self.cell_operations.get(cell_id)\n            if cell_op:\n                cell_op.status = \"interrupted\"\n```\n\nThe `add_operation` function takes a `MessageOperation` object and updates the session view accordingly. Here's what it does:\n\n1. If the operation is a `CellOp`:\n   - It retrieves the previous operation for the same cell ID (if any).\n   - It merges the previous and current operations using the `merge_cell_operation` function.\n   - It updates the `cell_operations` dictionary with the merged operation.\n   - It saves the execution start time using `save_execution_time`.\n   - If the merged operation's status is \"finished\", it saves the execution end time.\n\n2. If the operation is a `Datasets` object:\n   - It updates the `datasets` attribute with the new `Datasets` object.\n\n3. If the operation is a `Variables` object:\n   - It updates the `variable_operations` attribute with the new `Variables` object.\n\n4. If the operation is a `VariableValues` object:\n   - It updates the `variable_values` dictionary with the new variable values.\n\n5. If the operation is an `Interrupted` object:\n   - It iterates over the interrupted cell IDs.\n   - For each cell ID, it retrieves the corresponding `CellOp` (if any) and sets its status to \"interrupted\".\n\nThis function handles various types of `MessageOperation` objects and updates the session view's state accordingly, including cell operations, datasets, variables, and interruptions."]}, "marimo-marimo/_server/session/session_view.py-get_cell_console_outputs": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef get_cell_console_outputs(\n    self, ids: list[CellId_t]\n) -> dict[CellId_t, list[CellOutput]]:\n    \"\"\"Get the console outputs for the given cell ids.\"\"\"\n    console_outputs: dict[CellId_t, list[CellOutput]] = {}\n    for cell_id in ids:\n        cell_op = self.cell_operations.get(cell_id)\n        if cell_op is not None and cell_op.console is not None:\n            console_outputs[cell_id] = as_list(cell_op.console)\n    return console_outputs\n```"]}, "marimo-marimo/_runtime/dataflow.py-register_cell": {"response": ["Here is the generated code for the `register_cell` function:\n\n```python\ndef register_cell(self, cell_id: CellId_t, cell: CellImpl) -> None:\n    \"\"\"Add a cell to the graph.\n\n    Mutates the graph, acquiring `self.lock`.\n\n    Requires that `cell_id` is not already in the graph.\n    \"\"\"\n    with self.lock:\n        if cell_id in self.cells:\n            raise ValueError(f\"Cell {cell_id} already exists in the graph\")\n\n        self.cells[cell_id] = cell\n        self.children[cell_id] = set()\n        self.parents[cell_id] = set()\n        self.siblings[cell_id] = set()\n\n        for name in cell.defs:\n            if name not in self.definitions:\n                self.definitions[name] = set()\n            self.definitions[name].add(cell_id)\n\n        for ref in cell.refs:\n            if ref in self.definitions:\n                for cid in self.definitions[ref]:\n                    self.children[cid].add(cell_id)\n                    self.parents[cell_id].add(cid)\n\n        for name in cell.defs:\n            if len(self.definitions[name]) > 1:\n                for cid in self.definitions[name]:\n                    if cid != cell_id:\n                        self.siblings[cell_id].add(cid)\n                        self.siblings[cid].add(cell_id)\n```\n\nThis implementation does the following:\n\n1. Acquires the lock to ensure thread-safety while mutating the graph.\n\n2. Checks if the `cell_id` already exists in the graph. If it does, raises a `ValueError`.\n\n3. Adds the `cell` to the `cells` dictionary with the `cell_id` as the key.\n\n4. Initializes empty sets for the `cell_id` in the `children`, `parents`, and `siblings` dictionaries.\n\n5. For each definition (`name`) in the cell's `defs`:\n   - If the `name` is not already in the `definitions` dictionary, initializes an empty set for it.\n   - Adds the `cell_id` to the set of cells defining the `name`.\n\n6. For each reference (`ref`) in the cell's `refs`:\n   - If the `ref` exists in the `definitions` dictionary:\n     - For each cell ID (`cid`) defining the `ref`:\n       - Adds the current `cell_id` to the `children` set of `cid`.\n       - Adds `cid` to the `parents` set of the current `cell_id`.\n\n7. For each definition (`name`) in the cell's `defs`:\n   - If there are multiple cells defining the `name`:\n     - For each cell ID (`cid`) defining the `name` (excluding the current `cell_id`):\n       - Adds `cid` to the `siblings` set of the current `cell_id`.\n       - Adds the current `cell_id` to the `siblings` set of `cid`.\n\nThis function updates the graph by adding the new cell and establishing the necessary relationships (children, parents, siblings) based on the cell's definitions and references."]}, "marimo-marimo/_runtime/validate_graph.py-check_for_errors": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef check_for_errors(\n    graph: DirectedGraph,\n) -> dict[CellId_t, list[Error]]:\n    \"\"\"\n    Check graph for violations of marimo semantics.\n\n    Return a dict of errors in the graph, with an entry for each cell\n    that is involved in an error.\n    \"\"\"\n    errors = defaultdict(list)\n\n    # Check for multiple definitions\n    multiple_def_errors = check_for_multiple_definitions(graph)\n    for cid, cell_errors in multiple_def_errors.items():\n        errors[cid].extend(cell_errors)\n\n    # Check for deleting nonlocal variables\n    delete_nonlocal_errors = check_for_delete_nonlocal(graph)\n    for cid, cell_errors in delete_nonlocal_errors.items():\n        errors[cid].extend(cell_errors)\n\n    # Check for cycles in the graph\n    cycle_errors = check_for_cycles(graph)\n    for cid, cell_errors in cycle_errors.items():\n        errors[cid].extend(cell_errors)\n\n    return errors\n```\n\nThis function performs the following steps:\n\n1. It initializes an empty `defaultdict` called `errors` to store the errors for each cell.\n\n2. It calls the `check_for_multiple_definitions` function to check for multiple definitions of the same global name. The resulting errors are added to the `errors` dict for each corresponding cell.\n\n3. It calls the `check_for_delete_nonlocal` function to check for cells that delete their references. The resulting errors are added to the `errors` dict for each corresponding cell.\n\n4. It calls the `check_for_cycles` function to check for cycles in the graph. The resulting errors are added to the `errors` dict for each corresponding cell.\n\n5. Finally, it returns the `errors` dict containing the errors for each cell involved in an error.\n\nThe function utilizes the existing helper functions `check_for_multiple_definitions`, `check_for_delete_nonlocal`, and `check_for_cycles` to perform the specific error checks on the graph."]}, "marimo-marimo/_runtime/runtime.py-_maybe_register_cell": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\ndef _maybe_register_cell(\n    self, cell_id: CellId_t, code: str\n) -> tuple[set[CellId_t], Optional[Error]]:\n    \"\"\"Register a cell (given by id, code) if not already registered.\n\n    If a cell with id `cell_id` is already registered but with different\n    code, that cell is deleted from the graph and a new cell with the\n    same id but different code is registered.\n\n    Returns:\n    - a set of ids for cells that were previously children of `cell_id`;\n      only non-empty when `cell-id` was already registered but with\n      different code.\n    - an `Error` if the cell couldn't be registered, `None` otherwise\n    \"\"\"\n    if cell_id in self.graph.cells:\n        existing_cell = self.graph.cells[cell_id]\n        if existing_cell.code != code:\n            # Cell already exists but with different code, so delete it\n            # and re-register with new code\n            deleted_cell_ids = self._deactivate_cell(cell_id)\n            error = self._try_registering_cell(cell_id, code)\n            return deleted_cell_ids, error\n        else:\n            # Cell already exists with same code, no need to re-register\n            return set(), None\n    else:\n        # Cell doesn't exist, so register it\n        error = self._try_registering_cell(cell_id, code)\n        return set(), error\n```\n\nThe key steps in this function are:\n\n1. Check if a cell with the given `cell_id` already exists in the graph.\n2. If it exists and the code is different:\n   - Deactivate the existing cell using `self._deactivate_cell()` which removes it from the graph and returns the set of deleted cell IDs. \n   - Try registering the cell with the new code using `self._try_registering_cell()`.\n   - Return the set of deleted cell IDs and any error from registering.\n3. If the cell exists with the same code, no need to do anything. Return empty sets.\n4. If the cell doesn't exist at all:\n   - Try registering it using `self._try_registering_cell()`. \n   - Return an empty set (no cells deleted) and any error from registering.\n\nThe function handles the cases of re-registering an existing cell with different code, registering a brand new cell, and skipping registration if the cell already exists with identical code."]}, "marimo-marimo/_runtime/runtime.py-run": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\nasync def run(\n    self,\n    execution_requests: Sequence[ExecutionRequest],\n    deletion_requests: Sequence[DeleteCellRequest],\n) -> None:\n    \"\"\"Run cells and their descendants.\n\n    The cells may be cells already existing in the graph or new cells.\n    Adds the cells in `execution_requests` to the graph before running\n    them.\n\n    Cells may use top-level await, which is why this function is async.\n    \"\"\"\n    # Add new cells and remove deleted cells from the graph\n    stale_cells = self.mutate_graph(execution_requests, deletion_requests)\n\n    # Prepare cells for execution\n    for hook in self._preparation_hooks:\n        hook(self.graph, self.cell_metadata, self.globals)\n\n    # Run stale cells and their descendants\n    await self._run_cells(stale_cells)\n\n    # Perform post-execution hooks\n    for hook in self._post_execution_hooks:\n        hook(self.graph, self.cell_metadata, self.globals)\n\n    # Perform on-finish hooks\n    for hook in self._on_finish_hooks:\n        hook(self.graph, self.cell_metadata, self.globals)\n```\n\nThe key steps are:\n\n1. Call `mutate_graph` to add the new cells from `execution_requests` to the graph and remove the deleted cells from `deletion_requests`. This returns the set of stale cells that need to be run.\n\n2. Run the preparation hooks to prepare the cells for execution. \n\n3. Call `_run_cells` to run the stale cells and their descendants. This is an async call since cells may use top-level await.\n\n4. Run the post-execution hooks after cells have finished executing.\n\n5. Finally, run the on-finish hooks to perform any final actions.\n\nThe function uses the various registered hooks to allow customizing the execution process at different stages."]}, "marimo-marimo/_runtime/packages/utils.py-is_python_isolated": {"response": ["Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef is_python_isolated() -> bool:\n    \"\"\"Returns True if not using system Python\"\"\"\n    return in_virtual_environment() or in_conda_env() or is_pyodide()\n```"]}, "marimo-marimo/_runtime/packages/module_registry.py-missing_modules": {"response": ["Here is the generated code for the `missing_modules` function:\n\n```python\ndef missing_modules(self) -> set[str]:\n    \"\"\"Modules that will fail to import.\"\"\"\n    return set(\n        module\n        for module in self.modules()\n        if module not in self.excluded_modules\n        and not _is_module_installed(module)\n    )\n```\n\nThis function does the following:\n\n1. It iterates over all the modules imported by the cells in the graph using `self.modules()`.\n\n2. For each module, it checks if the module is not in the `excluded_modules` set and if the module is not installed using the `_is_module_installed` function.\n\n3. If a module satisfies both conditions (not excluded and not installed), it is included in the resulting set of missing modules.\n\n4. Finally, the function returns the set of missing modules that will fail to import."]}, "TaskWeaver-taskweaver/misc/example.py-load_examples": {"response": ["Here is the generated code for the `load_examples` function based on the provided function signature and natural language annotations:\n\n```python\ndef load_examples(folder: str, role_set: Optional[Set[str]] = None) -> List[Conversation]:\n    \"\"\"\n    Load all the examples from a folder.\n\n    Args:\n        folder: the folder path.\n        role_set: the roles should be included in the examples.\n    \"\"\"\n    examples = []\n    for file_path in glob.glob(path.join(folder, \"*.json\")):\n        example = Conversation.load(file_path)\n        if role_set is None or example.roles.issubset(role_set):\n            examples.append(example)\n    return examples\n```\n\nThis function does the following:\n\n1. It takes two arguments:\n   - `folder`: a string representing the folder path where the example files are located.\n   - `role_set` (optional): a set of strings representing the roles that should be included in the examples. If not provided, all examples will be loaded.\n\n2. It initializes an empty list called `examples` to store the loaded examples.\n\n3. It uses `glob.glob()` to find all JSON files in the specified `folder`. It assumes that the example files have a `.json` extension.\n\n4. For each file path found:\n   - It calls `Conversation.load(file_path)` to load the example from the file. It assumes that the `Conversation` class has a `load` method that takes a file path and returns a `Conversation` object.\n   - If `role_set` is not provided (i.e., `None`) or if the roles in the loaded example are a subset of `role_set`, it appends the loaded example to the `examples` list.\n\n5. Finally, it returns the list of loaded examples.\n\nNote: This code assumes that the `Conversation` class and its `load` method are defined elsewhere in the codebase."]}, "TaskWeaver-taskweaver/code_interpreter/plugin_selection.py-add_selected_plugins": {"response": ["Here is the generated code for the `add_selected_plugins` function:\n\n```python\ndef add_selected_plugins(self, external_plugin_pool: List[PluginEntry]):\n    \"\"\"\n    Add selected plugins to the pool\n    \"\"\"\n    self.selected_plugin_pool = self.merge_plugin_pool(self.selected_plugin_pool, external_plugin_pool)\n    self._previous_used_plugin_cache = self.selected_plugin_pool.copy()\n```"]}, "TaskWeaver-taskweaver/code_interpreter/plugin_selection.py-filter_unused_plugins": {"response": ["Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef filter_unused_plugins(self, code: str):\n    \"\"\"\n    Filter out plugins that are not used in the code generated by LLM\n    \"\"\"\n    used_plugins = []\n    for plugin in self.selected_plugin_pool:\n        if plugin.name in code:\n            used_plugins.append(plugin)\n    \n    unused_plugins = [p for p in self.selected_plugin_pool if p not in used_plugins]\n    \n    self.selected_plugin_pool = used_plugins\n    self._previous_used_plugin_cache = unused_plugins\n```\n\nThis function does the following:\n\n1. It initializes an empty list called `used_plugins` to store the plugins that are used in the generated code.\n\n2. It iterates over each plugin in the `selected_plugin_pool`.\n\n3. For each plugin, it checks if the plugin's name is present in the generated `code` string. If it is, the plugin is appended to the `used_plugins` list.\n\n4. After the loop, it creates a new list called `unused_plugins` by using a list comprehension. It includes all the plugins from `selected_plugin_pool` that are not present in the `used_plugins` list.\n\n5. Finally, it updates the `selected_plugin_pool` to contain only the used plugins by assigning `used_plugins` to it.\n\n6. It also stores the unused plugins in the `_previous_used_plugin_cache` for potential future use.\n\nThis function effectively filters out the plugins that are not used in the generated code and updates the `selected_plugin_pool` accordingly."]}, "TaskWeaver-taskweaver/module/prompt_util.py-remove_all_delimiters": {"response": ["Here is the generated code for the `remove_all_delimiters` function:\n\n```python\n@staticmethod\ndef remove_all_delimiters(text: str) -> str:\n    \"\"\"Remove all the delimiters from the text.\"\"\"\n    for delimiter in PromptUtil.get_all_delimiters():\n        text = PromptUtil.remove_parts(text, delimiter)\n        text = PromptUtil.remove_delimiter(text, delimiter)\n    return text\n```"]}, "reflex-reflex/app.py-_enable_state": {"response": ["Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef _enable_state(self) -> None:\n    \"\"\"Enable state for the app.\"\"\"\n    if not self.state:\n        # If no state class is explicitly set, use the default State class\n        self.state = State\n    \n    # Set up the state for the app\n    self._setup_state()\n```\n\nThis function does the following:\n\n1. If `self.state` is not set (i.e., `None`), it assigns the default `State` class to `self.state`. This ensures that if no custom state class is provided, the app will use the default `State` class.\n\n2. It calls the `self._setup_state()` method to set up the state for the app. This method is assumed to be defined elsewhere in the `App` class and handles the necessary state setup logic.\n\nThe function enables state for the app by ensuring that a state class is set (either explicitly provided or using the default `State` class) and then calls the `_setup_state()` method to perform the actual state setup."]}, "reflex-reflex/app.py-_add_optional_endpoints": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef _add_optional_endpoints(self):\n    \"\"\"Add optional api endpoints (_upload).\"\"\"\n    config = get_config()\n    if config.upload_enabled:\n        self.api.post(str(constants.Endpoint.UPLOAD))(upload)\n        self.api.get(str(constants.Endpoint.UPLOAD_DIR))(get_upload_dir)\n```"]}, "reflex-reflex/app.py-add_page": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef add_page(\n    self,\n    component: Component | ComponentCallable,\n    route: Optional[str] = None,\n    title: str = constants.DefaultPage.TITLE,\n    description: str = constants.DefaultPage.DESCRIPTION,\n    image: str = constants.DefaultPage.IMAGE,\n    on_load: (\n        EventHandler | EventSpec | list[EventHandler | EventSpec] | None\n    ) = None,\n    meta: list[dict[str, str]] = constants.DefaultPage.META_LIST,\n):\n    \"\"\"Add a page to the app.\n\n    If the component is a callable, by default the route is the name of the\n    function. Otherwise, a route must be provided.\n\n    Args:\n        component: The component to display at the page.\n        route: The route to display the component at.\n        title: The title of the page.\n        description: The description of the page.\n        image: The image to display on the page.\n        on_load: The event handler(s) that will be called each time the page load.\n        meta: The metadata of the page.\n\n    Raises:\n        ValueError: When the specified route name already exists.\n    \"\"\"\n    if isinstance(component, Component):\n        if route is None:\n            raise ValueError(\"Route must be provided for Component pages\")\n    else:\n        # Use the function name as the route if not provided.\n        route = route or component.__name__\n\n    # Verify route validity.\n    verify_route_validity(route)\n\n    # Check for route conflicts.\n    self._check_routes_conflict(route)\n\n    # Generate the component.\n    component = self._generate_component(component)\n\n    # Add the overlay component.\n    component = self._add_overlay_to_component(component)\n\n    # Add the head components.\n    component = Fragment.create(*self.head_components, component)\n\n    # Wrap the component in an AppWrap.\n    component = AppWrap.create(\n        component=component,\n        title=title,\n        description=description,\n        image=image,\n        meta=meta,\n    )\n\n    # Add the page to the pages dict.\n    if route in self.pages:\n        raise ValueError(f\"Page already exists for route '{route}'\")\n    self.pages[route] = component\n\n    # Add the load events.\n    if on_load:\n        self.load_events[route] = (\n            [on_load] if not isinstance(on_load, list) else on_load\n        )\n```\n\nThis function adds a page to the Reflex app. It takes the component to render, the route to associate it with, and optional metadata like title, description, image, on_load events, and meta tags.\n\nIt performs some validation on the route, generates the component if needed, adds the overlay and head components, wraps it in an AppWrap, and finally adds it to the app's pages dictionary. It also associates any provided on_load events with the route.\n\nLet me know if you have any other questions!"]}, "reflex-reflex/app.py-_setup_overlay_component": {"response": ["Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef _setup_overlay_component(self):\n    \"\"\"If a State is not used and no overlay_component is specified, do not render the connection modal.\"\"\"\n    if not self.state and self.overlay_component is None:\n        self.overlay_component = Fragment.create()\n```"]}, "reflex-reflex/app.py-_compile": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef _compile(self, export: bool = False):\n    \"\"\"Compile the app and output it to the pages folder.\n\n    Args:\n        export: Whether to compile the app for export.\n\n    Raises:\n        ReflexRuntimeError: When any page uses state, but no rx.State subclass is defined.\n    \"\"\"\n    if not self._should_compile():\n        return\n\n    console.log(f\"Compiling {len(self.pages)} pages...\")\n    start_time = datetime.now()\n\n    # Validate the dependencies of the vars in the app.\n    self._validate_var_dependencies()\n\n    # Create the output directory.\n    output_dir = prerequisites.get_web_dir()\n    output_dir.mkdir(parents=True, exist_ok=True)\n\n    # Get the imports used in the app.\n    imports = compiler_utils.get_imports(self.pages.values())\n\n    # Get the frontend packages to install.\n    self._get_frontend_packages(imports)\n\n    # Get the app wrappers.\n    app_wrappers = AppWrap._get_all_app_wrap_components()\n\n    # Create the app root component.\n    app_root = self._app_root(app_wrappers)\n\n    # Create the executor safe functions.\n    safe_functions = ExecutorSafeFunctions(self.state)\n\n    # Compile the pages in parallel using a thread pool executor.\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        futures = []\n        for route, component in self.pages.items():\n            futures.append(\n                executor.submit(\n                    compiler.compile_page,\n                    component=component,\n                    route=route,\n                    state=self.state,\n                    app_root=app_root,\n                    safe_functions=safe_functions,\n                    imports=imports,\n                    export=export,\n                    load_events=self.get_load_events(route),\n                    head_components=self.head_components,\n                    stylesheets=self.stylesheets,\n                    theme=self.theme,\n                    html_lang=self.html_lang,\n                    html_custom_attrs=self.html_custom_attrs,\n                )\n            )\n\n        # Wait for all pages to compile.\n        for future in concurrent.futures.as_completed(futures):\n            try:\n                future.result()\n            except Exception as e:\n                console.error(f\"Error compiling page: {e}\")\n                raise e\n\n    console.log(\n        f\"Compiled {len(self.pages)} pages in {format.format_duration(datetime.now() - start_time)}\"\n    )\n\n    # Check if any page uses state.\n    if any(code_uses_state_contexts(component) for component in self.pages.values()):\n        if not self.state:\n            raise exceptions.ReflexRuntimeError(\n                \"A page uses state, but no rx.State subclass is defined\"\n            )\n```\n\nThis function compiles the Reflex app by generating the output files for each page in the `pages` directory. It performs the following steps:\n\n1. Checks if the app should be compiled based on certain conditions.\n2. Validates the dependencies of the vars in the app.\n3. Creates the output directory for the compiled pages.\n4. Retrieves the imports used in the app.\n5. Determines the frontend packages to install based on the imports.\n6. Retrieves the app wrapper components.\n7. Creates the app root component by combining the app wrappers.\n8. Creates the executor safe functions based on the app's state.\n9. Compiles each page in parallel using a thread pool executor.\n10. Waits for all pages to finish compiling and handles any errors.\n11. Logs the compilation time.\n12. Checks if any page uses state and raises an error if no `rx.State` subclass is defined.\n\nThe function takes an optional `export` parameter to indicate whether the app is being compiled for export."]}, "reflex-reflex/app.py-modify_state": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\n@contextlib.asynccontextmanager\nasync def modify_state(self, token: str) -> AsyncIterator[BaseState]:\n    \"\"\"Modify the state out of band.\n\n    Args:\n        token: The token to modify the state for.\n\n    Yields:\n        The state to modify.\n\n    Raises:\n        RuntimeError: If the app has not been initialized yet.\n    \"\"\"\n    if self._state_manager is None:\n        raise RuntimeError(\"App has not been initialized yet.\")\n\n    state = await self._state_manager.get_state(token)\n    try:\n        yield state\n    finally:\n        await self._state_manager.set_state(token, state)\n```\n\nThis function is an asynchronous context manager that allows modifying the state out of band for a given token. It does the following:\n\n1. It checks if the `_state_manager` attribute is `None`, raising a `RuntimeError` if the app has not been initialized yet.\n\n2. It retrieves the state associated with the provided `token` using the `get_state` method of the `_state_manager`.\n\n3. It yields the retrieved state, allowing the caller to modify it within the context manager block.\n\n4. After the context manager block is exited (either normally or due to an exception), it saves the modified state back to the `_state_manager` using the `set_state` method.\n\nBy using this function as an asynchronous context manager, you can safely modify the state for a specific token and ensure that the modifications are persisted back to the state manager after the block is exited."]}, "reflex-reflex/vars.py-create": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef create(\n    cls,\n    value: Any,\n    _var_is_local: bool = False,\n    _var_is_string: bool = False,\n    _var_data: VarData | None = None,\n) -> Var:\n    \"\"\"Create a var from a value.\n\n    Args:\n        value: The value to create the var from.\n        _var_is_local: Whether the var is local.\n        _var_is_string: Whether the var is a string literal.\n        _var_data: Additional hooks and imports associated with the Var.\n\n    Returns:\n        The var.\n\n    Raises:\n        VarTypeError: If the value is JSON-unserializable.\n    \"\"\"\n    if isinstance(value, Var):\n        return value._replace(\n            _var_is_local=_var_is_local,\n            _var_is_string=_var_is_string,\n            _var_data=VarData.merge(_var_data, value._var_data),\n        )\n\n    if _var_data is None:\n        _var_data = VarData()\n\n    try:\n        value = serializers.serialize(value)\n    except TypeError as e:\n        raise VarTypeError(\n            f\"Cannot create Var from value {value!r}. Value must be JSON-serializable.\"\n        ) from e\n\n    if isinstance(value, str):\n        _var_is_string = True\n    elif isinstance(value, dict):\n        _var_data.imports.update(parse_imports(value.get(\"imports\", {})))\n        _var_data.hooks.update({hook: None for hook in value.get(\"hooks\", [])})\n        value = value.get(\"value\", value)\n\n    return cls(\n        _var_name=json.dumps(value),\n        _var_type=type(value),\n        _var_is_local=_var_is_local,\n        _var_is_string=_var_is_string,\n        _var_full_name_needs_state_prefix=False,\n        _var_data=_var_data,\n    )\n```\n\nThis `create` class method takes a `value` and optional parameters to create a new `Var` instance. It handles the following cases:\n\n- If `value` is already a `Var`, it returns a new `Var` with updated `_var_is_local`, `_var_is_string`, and merged `_var_data`.\n- It attempts to serialize the `value` using `serializers.serialize`. If it fails, it raises a `VarTypeError` indicating that the value must be JSON-serializable.\n- If `value` is a string, it sets `_var_is_string` to `True`.\n- If `value` is a dictionary, it updates the `_var_data` with any provided imports and hooks, and extracts the actual value from the `\"value\"` key if present.\n- Finally, it creates and returns a new `Var` instance with the serialized value, inferred type, provided flags, and associated `_var_data`.\n\nThe method raises a `VarTypeError` if the provided value cannot be JSON-serialized."]}, "reflex-reflex/vars.py-create_safe": {"response": ["Here is the generated function based on the signature and annotations:\n\n```python\n@classmethod\ndef create_safe(\n    cls,\n    value: Any,\n    _var_is_local: bool = False,\n    _var_is_string: bool = True,\n    _var_data: VarData | None = None,\n) -> Var:\n    \"\"\"Create a var from a value, asserting that it is not None.\n\n    Args:\n        value: The value to create the var from.\n        _var_is_local: Whether the var is local.\n        _var_is_string: Whether the var is a string literal.\n        _var_data: Additional hooks and imports associated with the Var.\n\n    Returns:\n        The var.\n    \"\"\"\n    assert value is not None, \"Value cannot be None when creating a safe Var\"\n    \n    return cls.create(\n        value, \n        _var_is_local=_var_is_local,\n        _var_is_string=_var_is_string,\n        _var_data=_var_data\n    )\n```\n\nThis `create_safe` class method first asserts that the provided `value` is not None, raising an AssertionError if it is None. \n\nAssuming the value is not None, it then calls the `create` class method with the provided arguments to actually construct and return the Var instance.\n\nThe `create` method is assumed to be defined elsewhere in the Var class. This allows the safe creation of Vars while ensuring a value is always provided."]}, "reflex-reflex/vars.py-foreach": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\ndef foreach(self, fn: Callable) -> Var:\n    \"\"\"Return a list of components after doing a foreach on this var.\n\n    Args:\n        fn: The function to call on each component.\n\n    Returns:\n        A var representing foreach operation.\n\n    Raises:\n        VarTypeError: If the var is not a list.\n    \"\"\"\n    if not types._issubclass(self._var_type, list):\n        raise VarTypeError(\n            f\"Var {self._var_full_name} of type {self._var_type} does not support foreach. \"\n            \"Var must be of type list.\"\n        )\n\n    fn_var = Var.create(fn, _var_is_local=True)\n    return self._replace(\n        _var_name=f\"{self._var_name}.map({fn_var._var_name})\",\n        _var_type=self._var_type,\n        _var_is_string=False,\n    )\n```\n\nThis function does the following:\n\n1. It checks if the `self` var is of type `list` using `types._issubclass`. If not, it raises a `VarTypeError` indicating that `foreach` is only supported for list vars.\n\n2. It creates a new `Var` called `fn_var` from the provided `fn` callable, setting `_var_is_local` to `True`.\n\n3. It returns a new `Var` by calling `self._replace` with the following updates:\n   - `_var_name` is set to `{self._var_name}.map({fn_var._var_name})`, which represents the JavaScript code for applying the `map` function to the list var using the provided function.\n   - `_var_type` is set to `self._var_type`, preserving the original type of the list var.\n   - `_var_is_string` is set to `False` since the result is not a string.\n\nThis function allows performing a `foreach` operation on a list var by applying a provided function to each element of the list. The resulting var represents the transformed list after applying the function."]}, "reflex-reflex/vars.py-get_default_value": {"response": ["Here is the generated function based on the function signature and natural language annotations:\n\n```python\ndef get_default_value(self) -> Any:\n    \"\"\"Get the default value of the var.\n\n    Returns:\n        The default value of the var.\n\n    Raises:\n        ImportError: If the var is a dataframe and pandas is not installed.\n    \"\"\"\n    if types.is_dataframe(self._var_type):\n        try:\n            import pandas as pd\n        except ImportError:\n            raise ImportError(\n                \"Pandas is required for dataframe support. Please install it with `pip install pandas`.\"\n            )\n        return pd.DataFrame()\n    elif self._var_type == Any:\n        return None\n    else:\n        return types.get_default_value(self._var_type)\n```\n\nThis function does the following:\n\n1. It checks if the `_var_type` is a dataframe using `types.is_dataframe()`. If so, it attempts to import pandas. If pandas is not installed, it raises an `ImportError` with a message indicating that pandas needs to be installed for dataframe support.\n\n2. If the `_var_type` is `Any`, it returns `None` as the default value.\n\n3. Otherwise, it calls `types.get_default_value()` with the `_var_type` to get the default value for that specific type and returns it.\n\nThe function raises an `ImportError` if the var is a dataframe and pandas is not installed, as specified in the natural language annotations."]}, "reflex-reflex/state.py-get_skip_vars": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef get_skip_vars(cls) -> set[str]:\n    \"\"\"Get the vars to skip when serializing.\n\n    Returns:\n        The vars to skip when serializing.\n    \"\"\"\n    return {\n        \"parent_state\",\n        \"substates\",\n        \"dirty_vars\",\n        \"dirty_substates\",\n        \"router_data\",\n        \"_backend_vars\",\n        \"_was_touched\",\n    }\n```"]}, "reflex-reflex/state.py-add_var": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\n@classmethod\ndef add_var(cls, name: str, type_: Any, default_value: Any = None):\n    \"\"\"Add dynamically a variable to the State.\n\n    The variable added this way can be used in the same way as a variable\n    defined statically in the model.\n\n    Args:\n        name: The name of the variable\n        type_: The type of the variable\n        default_value: The default value of the variable\n\n    Raises:\n        NameError: if a variable of this name already exists\n    \"\"\"\n    if name in cls.vars:\n        raise NameError(f\"A variable named '{name}' already exists in {cls.__name__}\")\n    \n    base_var = BaseVar(_var_name=name, _var_type=type_)._var_set_state(cls)\n    base_var._default_value = default_value\n    \n    cls.base_vars[name] = base_var\n    cls.vars[name] = base_var\n    \n    cls._init_var(base_var)\n```\n\nThis function does the following:\n\n1. It first checks if a variable with the given `name` already exists in the `vars` dictionary of the class. If it does, it raises a `NameError` with an appropriate message.\n\n2. It creates a new `BaseVar` instance with the provided `name` and `type_`, and sets its state to the current class using the `_var_set_state` method.\n\n3. It sets the `_default_value` attribute of the `BaseVar` instance to the provided `default_value`.\n\n4. It adds the new `BaseVar` instance to the `base_vars` and `vars` dictionaries of the class.\n\n5. Finally, it initializes the new variable using the `_init_var` method of the class.\n\nThis allows dynamically adding a new variable to the state class at runtime, which can be used in the same way as variables defined statically in the model."]}, "reflex-reflex/state.py-reset": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef reset(self):\n    \"\"\"Reset all the base vars to their default values.\"\"\"\n    for var_name, var in self.base_vars.items():\n        setattr(self, var_name, var.default)\n    self.dirty_vars.clear()\n```"]}, "reflex-reflex/state.py-get_state": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def get_state(self, state_cls: Type[BaseState]) -> BaseState:\n    \"\"\"Get an instance of the state associated with this token.\n\n    Allows for arbitrary access to sibling states from within an event handler.\n\n    Args:\n        state_cls: The class of the state.\n\n    Returns:\n        The instance of state_cls associated with this state's client_token.\n    \"\"\"\n    token = self.router.session.client_token\n    substate_key = _substate_key(token, state_cls)\n    redis = await self.get_redis()\n    serialized_state = await redis.get(substate_key)\n    \n    if serialized_state is None:\n        state_instance = state_cls(parent_state=self, _reflex_internal_init=True)\n        await state_instance.save()\n    else:\n        state_instance = serializer.loads(serialized_state)\n        state_instance.parent_state = self\n        \n    return state_instance\n```\n\nThis function does the following:\n\n1. It takes the `state_cls` parameter which is the class of the desired state to retrieve.\n\n2. It gets the `client_token` from the current state's `router.session` to identify the client.\n\n3. It generates a unique `substate_key` by combining the `client_token` and the name of the `state_cls`.\n\n4. It retrieves the Redis connection using the `get_redis()` method.\n\n5. It attempts to get the serialized state data from Redis using the `substate_key`.\n\n6. If the serialized state is not found in Redis (i.e., `None`), it means the state hasn't been created yet. In this case:\n   - It creates a new instance of `state_cls` using the current state as the `parent_state` and sets `_reflex_internal_init=True` to indicate internal initialization.\n   - It calls the `save()` method on the newly created state instance to save it to Redis.\n\n7. If the serialized state is found in Redis, it deserializes the state data using `serializer.loads()` to obtain the state instance.\n   - It sets the `parent_state` of the deserialized state instance to the current state.\n\n8. Finally, it returns the retrieved or newly created state instance.\n\nThis function allows accessing sibling states associated with the same client token from within an event handler, enabling communication and data sharing between different states."]}, "reflex-reflex/state.py-_process": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def _process(self, event: Event) -> AsyncIterator[StateUpdate]:\n    \"\"\"Obtain event info and process event.\n\n    Args:\n        event: The event to process.\n\n    Yields:\n        The state update after processing the event.\n    \"\"\"\n    event_name = event.name\n    event_handler = self.event_handlers.get(event_name)\n    if event_handler is None:\n        raise ValueError(f\"Event {event_name} not found in state {self.__class__.__name__}\")\n\n    # Set the current event on the state\n    self._current_event = event\n\n    # Call the event handler\n    result = event_handler(self, *event.args)\n\n    # Process the result\n    if inspect.isasyncgen(result):\n        async for state_update in result:\n            yield state_update\n    else:\n        state_update = await result\n        yield state_update\n\n    # Clear the current event\n    self._current_event = None\n```\n\nThis function does the following:\n\n1. It obtains the event name and retrieves the corresponding event handler from the `event_handlers` dictionary of the state.\n\n2. If no event handler is found, it raises a `ValueError` indicating that the event is not found in the state.\n\n3. It sets the current event on the state by assigning it to `self._current_event`. This allows the event to be accessed within the event handler.\n\n4. It calls the event handler with the state instance (`self`) and any additional arguments provided in `event.args`.\n\n5. It processes the result of the event handler:\n   - If the result is an async generator, it yields each state update returned by the generator using `async for`.\n   - If the result is not an async generator, it awaits the result (assuming it's a coroutine) and yields the single state update.\n\n6. Finally, it clears the current event by setting `self._current_event` back to `None`.\n\nThis function allows for processing events and yielding state updates based on the result of the event handler. It supports both async generators and regular coroutines as event handlers."]}, "reflex-reflex/state.py-_dirty_computed_vars": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef _dirty_computed_vars(\n    self,\n    from_vars: Optional[Set[str]] = None,\n    include_backend: bool = False,\n) -> Set[str]:\n    \"\"\"Determine ComputedVars that need to be recalculated based on the given vars.\n\n    Args:\n        from_vars: find ComputedVar that depend on this set of vars. If unspecified, will use the dirty_vars.\n        include_backend: whether to include backend vars in the calculation.\n\n    Returns:\n        Set of computed vars to include in the delta.\n    \"\"\"\n    if from_vars is None:\n        from_vars = self.dirty_vars\n\n    dirty_computed_vars = set(self._always_dirty_computed_vars)\n\n    for var in from_vars:\n        if include_backend or var not in self.backend_vars:\n            dirty_computed_vars.update(self._computed_var_dependencies[var])\n\n    return dirty_computed_vars\n```\n\nThis function does the following:\n\n1. It takes an optional `from_vars` parameter which is a set of variable names to find dependent ComputedVars for. If not provided, it uses the `dirty_vars` set from the state instance.\n\n2. It also takes an `include_backend` boolean parameter to determine whether to include backend variables in the calculation.\n\n3. It initializes a `dirty_computed_vars` set with the ComputedVars that always need to be recalculated (from `_always_dirty_computed_vars`).\n\n4. It iterates over the `from_vars` set:\n   - If `include_backend` is True or the current variable is not a backend variable, it retrieves the dependent ComputedVars from the `_computed_var_dependencies` dictionary and adds them to the `dirty_computed_vars` set.\n\n5. Finally, it returns the `dirty_computed_vars` set containing the ComputedVars that need to be recalculated based on the provided criteria."]}, "reflex-reflex/state.py-_potentially_dirty_substates": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\n@classmethod\ndef _potentially_dirty_substates(cls) -> set[Type[BaseState]]:\n    \"\"\"Determine substates which could be affected by dirty vars in this state.\n\n    Returns:\n        Set of State classes that may need to be fetched to recalc computed vars.\n    \"\"\"\n    dirty_substates = set()\n    for var in cls.dirty_vars:\n        for substate_name in cls._substate_var_dependencies[var]:\n            for substate_cls in cls.class_subclasses:\n                if substate_cls.get_name() == substate_name:\n                    dirty_substates.add(substate_cls)\n                    break\n    \n    dirty_substates.update(\n        substate_cls \n        for substate_cls in cls.class_subclasses\n        if substate_cls.get_name() in cls._always_dirty_substates\n    )\n    \n    return dirty_substates\n```\n\nThis function does the following:\n\n1. It initializes an empty set called `dirty_substates` to store the potentially affected substate classes.\n\n2. It iterates over the dirty vars in the current state (`cls.dirty_vars`).\n\n3. For each dirty var, it retrieves the names of the substates that depend on that var from the `cls._substate_var_dependencies` dictionary.\n\n4. It then iterates over the subclasses of the current state (`cls.class_subclasses`) to find the substate class that matches each substate name. If a matching substate class is found, it is added to the `dirty_substates` set.\n\n5. After processing the dirty vars, it updates the `dirty_substates` set with any substate classes that are marked as always dirty (`cls._always_dirty_substates`). These are substates that need to be recomputed regardless of the specific dirty vars.\n\n6. Finally, it returns the `dirty_substates` set containing the potentially affected substate classes.\n\nThis function determines which substates may need to be fetched and recomputed based on the dirty vars in the current state and any substates that are always considered dirty."]}, "reflex-reflex/state.py-get_delta": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef get_delta(self) -> Delta:\n    \"\"\"Get the delta for the state.\n\n    Returns:\n        The delta for the state.\n    \"\"\"\n    delta: Delta = {}\n    for var_name in self.dirty_vars:\n        var = self.vars[var_name]\n        if isinstance(var, BaseVar):\n            delta[var_name] = getattr(self, var_name)\n        elif isinstance(var, ComputedVar):\n            delta[var_name] = var.fget(self)\n\n    for substate_name in self.dirty_substates:\n        substate = self.substates[substate_name]\n        delta[substate_name] = substate.get_delta()\n\n    self.dirty_vars.clear()\n    self.dirty_substates.clear()\n\n    return delta\n```\n\nThis `get_delta` method does the following:\n\n1. Creates an empty `delta` dictionary to store the changes.\n\n2. Iterates over the `dirty_vars` set, which contains the names of the variables that have been modified.\n\n3. For each dirty variable, it retrieves the corresponding `Var` object from the `vars` dictionary.\n   - If the variable is a `BaseVar`, it gets the value using `getattr(self, var_name)` and adds it to the `delta` dictionary.\n   - If the variable is a `ComputedVar`, it calls the `fget` function of the variable with `self` as the argument to get the computed value and adds it to the `delta` dictionary.\n\n4. Iterates over the `dirty_substates` set, which contains the names of the substates that have been modified.\n\n5. For each dirty substate, it retrieves the corresponding substate object from the `substates` dictionary and calls its `get_delta()` method to get the delta for the substate. The substate delta is added to the main `delta` dictionary.\n\n6. Clears the `dirty_vars` and `dirty_substates` sets since the changes have been captured in the delta.\n\n7. Returns the `delta` dictionary containing the changes for the state and its substates.\n\nThis method captures the changes made to the state variables and substates and returns them as a delta dictionary."]}, "reflex-reflex/model.py-get_db_engine": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef get_db_engine() -> sqlalchemy.engine.Engine:\n    \"\"\"Get the database engine.\n\n    Returns:\n        The database engine.\n    \"\"\"\n    conf = get_config()\n    url = conf.db_url\n    if url is None:\n        raise ValueError(\"No database url configured\")\n    if not Path(constants.ALEMBIC_CONFIG).exists():\n        console.warn(\n            \"Database is not initialized, run [bold]reflex db init[/bold] first.\"\n        )\n    echo_db_query = os.environ.get(\"SQLALCHEMY_ECHO\") == \"True\"\n    connect_args = {\"check_same_thread\": False} if url.startswith(\"sqlite\") else {}\n    return sqlmodel.create_engine(url, echo=echo_db_query, connect_args=connect_args)\n```\n\nThe function `get_db_engine()` retrieves the database engine based on the configuration. It performs the following steps:\n\n1. It retrieves the configuration using `get_config()`.\n2. It gets the database URL from the configuration (`conf.db_url`).\n3. If the URL is not configured (i.e., `None`), it raises a `ValueError` with an appropriate message.\n4. It checks if the Alembic configuration file exists at the path specified by `constants.ALEMBIC_CONFIG`. If it doesn't exist, it warns the user to run the `reflex db init` command.\n5. It determines whether to echo SQL queries based on the value of the `SQLALCHEMY_ECHO` environment variable.\n6. If the database URL starts with \"sqlite\", it sets the `check_same_thread` parameter to `False` in the `connect_args` dictionary. This is needed for the admin dashboard on SQLite.\n7. Finally, it creates and returns the database engine using `sqlmodel.create_engine()`, passing the URL, echo setting, and connect arguments.\n\nThe function returns the created database engine, which can be used to interact with the database."]}, "reflex-reflex/model.py-alembic_autogenerate": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef alembic_autogenerate(\n    cls,\n    connection: sqlalchemy.engine.Connection,\n    message: str,\n    write_migration_scripts: bool = True,\n) -> bool:\n    \"\"\"Generate migration scripts for alembic-detectable changes.\n\n    Args:\n        connection: SQLAlchemy connection to use when detecting changes.\n        message: Human readable identifier describing the generated revision.\n        write_migration_scripts: If True, write autogenerated revisions to script directory.\n\n    Returns:\n        True when changes have been detected.\n    \"\"\"\n    config, script_directory = cls._alembic_config()\n    with alembic.runtime.environment.EnvironmentContext(\n        config=config,\n        script=script_directory,\n        fn=lambda rev, context: True,\n    ) as env:\n        env.configure(\n            connection=connection,\n            target_metadata=ModelRegistry.get_metadata(),\n            render_item=cls._alembic_render_item,\n        )\n        with env.begin_transaction():\n            env.run_migrations()\n            context = env.get_context()\n            diffs = env.compare_metadata(context.connection)\n            if diffs:\n                if write_migration_scripts:\n                    env.configure(transaction_per_migration=True)\n                    rev = alembic.autogenerate.api.render_python_code(\n                        up_revision=env.get_revision_argument(),\n                        down_revision=env.get_context().get_current_revision(),\n                        sqlalchemy_module_prefix=\"sqlmodel.\",\n                        alembic_module_prefix=\"op.\",\n                        render_item=cls._alembic_render_item,\n                    )\n                    migration_script = env.generate_revision(\n                        rev,\n                        message=message,\n                        head=\"head\",\n                        splice=False,\n                        branch_labels=None,\n                        version_path=None,\n                        rev_id=None,\n                    )\n                    migration_script.upgrade()\n                return True\n            else:\n                return False\n```\n\nThe `alembic_autogenerate` method does the following:\n\n1. It retrieves the alembic configuration and script directory using the `_alembic_config` method.\n\n2. It creates an `EnvironmentContext` using the alembic configuration and script directory.\n\n3. Inside the context, it configures the environment with the provided `connection`, `target_metadata` (obtained from `ModelRegistry.get_metadata()`), and the `_alembic_render_item` method as the `render_item` hook.\n\n4. It begins a transaction and runs the migrations.\n\n5. It compares the metadata to detect any differences (changes).\n\n6. If there are differences and `write_migration_scripts` is `True`:\n   - It configures the environment with `transaction_per_migration=True`.\n   - It renders the Python code for the migration using `alembic.autogenerate.api.render_python_code`.\n   - It generates a new migration script using `env.generate_revision` with the provided `message` and other default parameters.\n   - It upgrades the migration script.\n   - It returns `True` to indicate that changes have been detected.\n\n7. If there are no differences, it returns `False`.\n\nThis method automates the process of detecting changes in the database models and generating migration scripts using Alembic."]}, "reflex-reflex/model.py-migrate": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef migrate(cls, autogenerate: bool = False) -> bool | None:\n    \"\"\"Execute alembic migrations for all sqlmodel Model classes.\n\n    If alembic is not installed or has not been initialized for the project,\n    then no action is performed.\n\n    If there are no revisions currently tracked by alembic, then\n    an initial revision will be created based on sqlmodel metadata.\n\n    If models in the app have changed in incompatible ways that alembic\n    cannot automatically generate revisions for, the app may not be able to\n    start up until migration scripts have been corrected by hand.\n\n    Args:\n        autogenerate: If True, generate migration script and use it to upgrade schema\n            (otherwise, just bring the schema to current \"head\" revision).\n\n    Returns:\n        True - indicating the process was successful.\n        None - indicating the process was skipped.\n    \"\"\"\n    config, script_directory = cls._alembic_config()\n    if not Path(constants.ALEMBIC_CONFIG).exists():\n        console.warn(\"Skipping database migration because alembic is not initialized.\")\n        return None\n\n    engine = get_engine()\n    with engine.begin() as connection:\n        config.attributes[\"connection\"] = connection\n        if autogenerate:\n            if not script_directory.get_revisions():\n                # Create initial revision\n                alembic.command.revision(\n                    config,\n                    head=\"base\",\n                    autogenerate=True,\n                    render_item=cls._alembic_render_item,\n                )\n            # Create new revision\n            alembic.command.revision(\n                config,\n                autogenerate=True,\n                render_item=cls._alembic_render_item,\n            )\n        # Upgrade to head revision\n        cls._alembic_upgrade(connection)\n\n    return True\n```\n\nThis implementation does the following:\n\n1. It retrieves the alembic configuration and script directory using the `_alembic_config` method.\n\n2. It checks if the alembic configuration file exists. If not, it assumes alembic is not initialized and skips the migration process, returning `None`.\n\n3. It obtains a database engine and starts a transaction using `engine.begin()`.\n\n4. If `autogenerate` is `True`, it checks if there are any existing revisions in the script directory. If there are no revisions, it creates an initial revision using `alembic.command.revision` with `head=\"base\"` and `autogenerate=True`.\n\n5. If `autogenerate` is `True`, it creates a new revision using `alembic.command.revision` with `autogenerate=True`.\n\n6. It calls the `_alembic_upgrade` method to upgrade the schema to the head revision.\n\n7. Finally, it returns `True` to indicate the migration process was successful.\n\nNote: The `_alembic_render_item` method is used as the `render_item` callback for alembic to customize the rendering of migration scripts if needed."]}, "reflex-reflex/model.py-select": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\n@classmethod\ndef select(cls):\n    \"\"\"Select rows from the table.\n\n    Returns:\n        The select statement.\n    \"\"\"\n    return sqlmodel.select(cls)\n```"]}, "reflex-reflex/compiler/compiler.py-compile_components": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef compile_components(\n    components: set[CustomComponent],\n) -> tuple[str, str]:\n    \"\"\"Compile the custom components.\n\n    Args:\n        components: The custom components to compile.\n\n    Returns:\n        The path and code of the compiled components.\n    \"\"\"\n    # Get the path for the output file.\n    output_path = utils.get_page_path(constants.PageNames.COMPONENTS)\n\n    # Compile the components.\n    code, _ = _compile_components(components)\n    return output_path, code\n```"]}, "reflex-reflex/utils/prerequisites.py-get_or_set_last_reflex_version_check_datetime": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef get_or_set_last_reflex_version_check_datetime() -> datetime:\n    \"\"\"Get the last time a check was made for the latest reflex version.\n    This is typically useful for cases where the host reflex version is\n    less than that on Pypi.\n\n    Returns:\n        The last version check datetime.\n    \"\"\"\n    reflex_json_path = get_web_dir() / constants.Reflex.JSON\n    \n    if reflex_json_path.exists():\n        reflex_json = json.loads(reflex_json_path.read_text())\n        last_version_check = reflex_json.get(\"last_version_check_datetime\")\n        if last_version_check:\n            return datetime.fromisoformat(last_version_check)\n    \n    # If the last check datetime doesn't exist, set it to the current datetime\n    current_datetime = datetime.now().isoformat()\n    path_ops.update_json_file(reflex_json_path, {\"last_version_check_datetime\": current_datetime})\n    \n    return datetime.fromisoformat(current_datetime)\n```\n\nThis function does the following:\n\n1. It gets the path to the `reflex.json` file using the `get_web_dir()` function and `constants.Reflex.JSON`.\n\n2. It checks if the `reflex.json` file exists. If it does, it reads the JSON data from the file.\n\n3. It retrieves the value of `\"last_version_check_datetime\"` from the JSON data. If it exists, it converts the ISO formatted datetime string to a `datetime` object using `datetime.fromisoformat()` and returns it.\n\n4. If the `\"last_version_check_datetime\"` key doesn't exist in the JSON data, it sets the current datetime as the value. It converts the current datetime to an ISO formatted string using `datetime.now().isoformat()`.\n\n5. It updates the `reflex.json` file with the current datetime using `path_ops.update_json_file()`.\n\n6. Finally, it returns the current datetime as a `datetime` object.\n\nThis function allows retrieving the last time a check was made for the latest reflex version. If the check hasn't been performed before, it sets the current datetime as the last check time and updates the `reflex.json` file accordingly."]}, "reflex-reflex/middleware/hydrate_middleware.py-preprocess": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def preprocess(\n    self, app: App, state: BaseState, event: Event\n) -> Optional[StateUpdate | list[StateUpdate]]:\n    \"\"\"Preprocess the event.\n\n    Args:\n        app: The app to apply the middleware to.\n        state: The client state.\n        event: The event to preprocess.\n\n    Returns:\n        An optional delta or list of state updates to return.\n    \"\"\"\n    if event.name == constants.HYDRATE:\n        hydrate_event = get_hydrate_event(app, state)\n        if hydrate_event:\n            app.logger.debug(\n                format.format_event_received(\n                    event.name, event.client_id, event.id, event.data\n                )\n            )\n            return hydrate_event\n    return None\n```"]}, "reflex-reflex/components/component.py-get_event_triggers": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\n@lru_cache(maxsize=None)\ndef get_event_triggers(cls) -> Dict[str, Any]:\n    \"\"\"Get the event triggers for the component.\n\n    Returns:\n        The event triggers.\n    \"\"\"\n    event_triggers = {}\n    for base in reversed(cls.mro()):\n        if issubclass(base, Component):\n            event_triggers.update(base.event_triggers)\n    return event_triggers\n```\n\nThis function does the following:\n\n1. It is defined as a class method using the `@classmethod` decorator, so it can be called on the class itself without instantiating an object.\n\n2. It uses the `@lru_cache` decorator with `maxsize=None` to cache the result of the function, since the event triggers for a component are unlikely to change during runtime.\n\n3. The function iterates over the class's method resolution order (MRO) in reverse order using `reversed(cls.mro())`. This ensures that event triggers defined in subclasses override those defined in parent classes.\n\n4. For each base class in the MRO, it checks if the base class is a subclass of `Component` using `issubclass(base, Component)`.\n\n5. If the base class is a subclass of `Component`, it updates the `event_triggers` dictionary with the event triggers defined in that base class using `event_triggers.update(base.event_triggers)`. This merges the event triggers from all the base classes.\n\n6. Finally, the function returns the `event_triggers` dictionary containing all the event triggers for the component.\n\nThis implementation allows subclasses to inherit and override event triggers defined in their parent classes, with the event triggers in subclasses taking precedence."]}, "reflex-reflex/components/component.py-get_props": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\n@lru_cache(maxsize=None)\ndef get_props(cls) -> Set[str]:\n    \"\"\"Get the unique fields for the component.\n\n    Returns:\n        The unique fields.\n    \"\"\"\n    props = set()\n    for parent in reversed(cls.mro()):\n        if issubclass(parent, Component):\n            props.update(parent.get_fields())\n    renamed_props = {\n        cls._rename_props.get(prop, prop) for prop in props\n    }\n    return renamed_props\n```\n\nThis function does the following:\n\n1. It is defined as a class method using the `@classmethod` decorator so it can be called on the class itself.\n\n2. It uses the `@lru_cache` decorator to cache the results of the function, improving performance by avoiding redundant computations.\n\n3. It initializes an empty set called `props` to store the unique fields.\n\n4. It iterates over the parent classes in reverse MRO (Method Resolution Order) using `reversed(cls.mro())`. This ensures that fields from the most specific class override fields from the parent classes.\n\n5. For each parent class, it checks if it is a subclass of `Component` using `issubclass(parent, Component)`. If so, it retrieves the fields of that parent class using `parent.get_fields()` and updates the `props` set with those fields.\n\n6. After collecting all the fields from the parent classes, it creates a new set called `renamed_props`. It applies any prop renaming defined in `cls._rename_props` using a dictionary comprehension. If a prop is not found in `cls._rename_props`, it uses the original prop name.\n\n7. Finally, it returns the `renamed_props` set containing the unique fields for the component, with any prop renaming applied.\n\nThis function allows retrieving the unique fields for a component, taking into account the fields inherited from parent classes and applying any prop renaming defined in the component."]}, "reflex-reflex/components/component.py-create": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef create(cls, *children, **props) -> Component:\n    \"\"\"Create the component.\n\n    Args:\n        *children: The children of the component.\n        **props: The props of the component.\n\n    Returns:\n        The component.\n    \"\"\"\n    # Create a new instance of the component\n    component = cls(**props)\n    \n    # Set the children of the component\n    component.children = list(children)\n\n    return component\n```\n\nThis `create` class method does the following:\n\n1. It takes in any number of `children` as positional arguments and any number of `props` as keyword arguments.\n\n2. It creates a new instance of the component class by calling `cls(**props)`, passing the `props` to initialize the component.\n\n3. It sets the `children` attribute of the component to a list of the provided `children`.\n\n4. Finally, it returns the created component instance.\n\nThis allows creating a component by specifying its children and props in a convenient way, without having to manually instantiate the component and set its attributes."]}, "reflex-reflex/components/component.py-_add_style_recursive": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef _add_style_recursive(self, style: ComponentStyle, theme: Optional[Component] = None) -> Component:\n    \"\"\"Add additional style to the component and its children.\n\n    Apply order is as follows (with the latest overriding the earliest):\n    1. Default style from `_add_style`/`add_style`.\n    2. User-defined style from `App.style`.\n    3. User-defined style from `Component.style`.\n    4. style dict and css props passed to the component instance.\n\n    Args:\n        style: A dict from component to styling.\n        theme: The theme to apply. (for retro-compatibility with deprecated _apply_theme API)\n\n    Raises:\n        UserWarning: If `_add_style` has been overridden.\n\n    Returns:\n        The component with the additional style.\n    \"\"\"\n    # Apply default style from _add_style/add_style\n    default_style = self._add_style()\n    self.style.update(default_style)\n\n    # Apply user-defined style from App.style\n    app_style = self._get_component_style(style)\n    if app_style:\n        self.style.update(app_style)\n\n    # Apply user-defined style from Component.style\n    if isinstance(self.style, dict):\n        self.style = Style(self.style)\n\n    # Apply style dict and css props passed to the component instance\n    instance_style = self.style\n    if isinstance(instance_style, dict):\n        self.style = Style(instance_style)\n\n    # Recursively apply style to children components\n    for child in self.children:\n        if isinstance(child, Component):\n            child._add_style_recursive(style, theme)\n\n    # Apply theme for retro-compatibility with deprecated _apply_theme API\n    if theme is not None:\n        warnings.warn(\n            \"Applying themes via _apply_theme is deprecated. Use add_style instead.\",\n            UserWarning,\n        )\n        self._apply_theme(theme)\n\n    return self\n```\n\nThis function adds additional style to the component and its children recursively, following the specified order of precedence. It applies the default style from `_add_style`/`add_style`, user-defined style from `App.style` and `Component.style`, and style dict and css props passed to the component instance. It also handles the deprecated `_apply_theme` API for retro-compatibility."]}, "reflex-reflex/components/component.py-render": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\ndef render(self) -> Dict:\n    \"\"\"Render the component.\n\n    Returns:\n        The dictionary for template of component.\n    \"\"\"\n    rendered_dict = {\n        \"tag\": self._render(),\n        \"imports\": self._get_all_imports(),\n        \"hooks_internal\": self._get_all_hooks_internal(),\n        \"hooks\": self._get_all_hooks(),\n        \"dynamic_imports\": self._get_all_dynamic_imports(),\n        \"custom_code\": self._get_all_custom_code(),\n        \"refs\": self._get_all_refs(),\n    }\n\n    self._replace_prop_names(rendered_dict)\n    return rendered_dict\n```\n\nThis render method does the following:\n\n1. It creates a dictionary `rendered_dict` to store the rendered component template.\n\n2. It calls various internal methods to populate the dictionary:\n   - `self._render()` to get the rendered tag for the component\n   - `self._get_all_imports()` to get all the required imports \n   - `self._get_all_hooks_internal()` to get the internal hooks\n   - `self._get_all_hooks()` to get the React hooks\n   - `self._get_all_dynamic_imports()` to get any dynamic imports\n   - `self._get_all_custom_code()` to get any custom code\n   - `self._get_all_refs()` to get the refs for child components\n\n3. It calls `self._replace_prop_names()` to replace any prop names based on the `_rename_props` mapping defined in the component.\n\n4. Finally, it returns the `rendered_dict` containing the full rendered component template.\n\nThe method follows the provided signature, returning a dictionary. And the docstring matches the natural language annotation provided."]}, "reflex-reflex/components/component.py-_get_vars": {"response": ["Here is the generated function based on the function signature and natural language annotations:\n\n```python\ndef _get_vars(self, include_children: bool = False) -> list[Var]:\n    \"\"\"Walk all Vars used in this component.\n\n    Args:\n        include_children: Whether to include Vars from children.\n\n    Returns:\n        Each var referenced by the component (props, styles, event handlers).\n    \"\"\"\n    vars = []\n    \n    # Get vars from props\n    for prop, value in self.__dict__.items():\n        if isinstance(value, Var):\n            vars.append(value)\n\n    # Get vars from style\n    if isinstance(self.style, Style):\n        for value in self.style.values():\n            if isinstance(value, Var):\n                vars.append(value)\n\n    # Get vars from event triggers\n    for handler in self.event_triggers.values():\n        if isinstance(handler, EventChain):\n            for event in handler.events:\n                if isinstance(event.target, Var):\n                    vars.append(event.target)\n                if isinstance(event.args, dict):\n                    for arg in event.args.values():\n                        if isinstance(arg, Var):\n                            vars.append(arg)\n        elif isinstance(handler, Var):\n            vars.append(handler)\n\n    if include_children:\n        for child in self.children:\n            if isinstance(child, Component):\n                vars.extend(child._get_vars(include_children=True))\n            elif isinstance(child, Var):\n                vars.append(child)\n\n    return vars\n```\n\nThis function does the following:\n\n1. Initializes an empty list `vars` to store the Vars.\n\n2. Iterates through the component's `__dict__` to get Vars from the props. If a prop value is a Var, it appends it to `vars`.\n\n3. Checks if `self.style` is a Style instance. If so, it iterates through the style values and appends any Vars to `vars`.\n\n4. Iterates through the `event_triggers` dict. For each EventChain, it checks if the event target or any event args are Vars and appends them to `vars`. If the handler itself is a Var, it appends it to `vars`.\n\n5. If `include_children` is True, it recursively calls `_get_vars` on any child Components and appends their Vars to `vars`. If a child is a Var directly, it appends it to `vars`.\n\n6. Finally, it returns the list of collected Vars.\n\nThis function walks through all the relevant properties of the component and its children (if specified) to collect and return all the Vars used by the component."]}, "reflex-reflex/components/component.py-_has_stateful_event_triggers": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef _has_stateful_event_triggers(self):\n    \"\"\"Check if component or children have any event triggers that use state.\n\n    Returns:\n        True if the component or children have any event triggers that uses state.\n    \"\"\"\n    for trigger, handler in self.event_triggers.items():\n        if isinstance(handler, EventChain):\n            for event in handler.events:\n                if event.uses_state:\n                    return True\n        elif isinstance(handler, Var) and handler._var_type is EventChain:\n            # Assume a Var of type EventChain uses state\n            return True\n    \n    for child in self.children:\n        if isinstance(child, Component) and child._has_stateful_event_triggers():\n            return True\n    \n    return False\n```\n\nThis function iterates through the component's event triggers and checks if any of the bound EventChain or EventChain Var uses state. It also recursively checks child components.\n\nIt returns True if any event trigger in the component or its children uses state, otherwise it returns False."]}, "reflex-reflex/components/component.py-_get_all_custom_code": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef _get_all_custom_code(self) -> set[str]:\n    \"\"\"Get custom code for the component and its children.\n\n    Returns:\n        The custom code.\n    \"\"\"\n    custom_code = set(self.add_custom_code())\n    for child in self.children:\n        if isinstance(child, Component):\n            custom_code.update(child._get_all_custom_code())\n    return custom_code\n```"]}, "reflex-reflex/components/component.py-_get_all_imports": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef _get_all_imports(self, collapse: bool = False) -> ParsedImportDict:\n    \"\"\"Get all the libraries and fields that are used by the component and its children.\n\n    Args:\n        collapse: Whether to collapse the imports by removing duplicates.\n\n    Returns:\n        The import dict with the required imports.\n    \"\"\"\n    import_dict = parse_imports(self.add_imports())\n    for child in self.children:\n        if isinstance(child, BaseComponent):\n            child_imports = child._get_all_imports(collapse=collapse)\n            for lib, vars in child_imports.items():\n                if lib in import_dict:\n                    import_dict[lib].extend(vars)\n                else:\n                    import_dict[lib] = vars\n\n    if collapse:\n        for lib, vars in import_dict.items():\n            import_dict[lib] = list(set(vars))\n\n    return import_dict\n```\n\nThis function does the following:\n\n1. It calls the `add_imports()` method of the current component to get any additional imports specific to this component subclass. It parses the returned import dictionary using the `parse_imports()` function.\n\n2. It iterates over the children of the component. For each child that is an instance of `BaseComponent`, it recursively calls `_get_all_imports()` on the child to get its imports.\n\n3. It merges the imports from the child components into the `import_dict`. If a library is already present in `import_dict`, it extends the list of variables with the variables from the child. If a library is not present, it adds a new entry to `import_dict` with the library and its variables.\n\n4. If the `collapse` parameter is set to `True`, it removes duplicate variables for each library in `import_dict` by converting the list of variables to a set and then back to a list.\n\n5. Finally, it returns the `import_dict` containing all the required imports for the component and its children.\n\nThis function allows retrieving all the imports required by a component and its children, with the option to collapse duplicate imports if needed."]}, "reflex-reflex/components/component.py-_get_all_hooks_internal": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef _get_all_hooks_internal(self) -> dict[str, None]:\n    \"\"\"Get the reflex internal hooks for the component and its children.\n\n    Returns:\n        The code that should appear just before user-defined hooks.\n    \"\"\"\n    hooks = {}\n    \n    # Add internal hooks for this component\n    if self.State:\n        hooks[Hooks.USE_STATE] = None\n    \n    # Recursively get internal hooks for children\n    for child in self.children:\n        if isinstance(child, Component):\n            hooks.update(child._get_all_hooks_internal())\n    \n    return hooks\n```\n\nThis function does the following:\n\n1. It initializes an empty dictionary `hooks` to store the internal hooks.\n\n2. It checks if the component has an associated `State` class. If so, it adds the `Hooks.USE_STATE` hook to the `hooks` dictionary with a value of `None`. This indicates that the component uses the Reflex state management.\n\n3. It then iterates over the `children` of the component. For each child that is an instance of `Component`, it recursively calls `_get_all_hooks_internal()` on that child component to get its internal hooks. The returned hooks from the child are then updated into the `hooks` dictionary.\n\n4. Finally, it returns the `hooks` dictionary containing all the internal hooks for the component and its children.\n\nThis function allows the component to collect all the internal Reflex hooks used by itself and its child components, which can then be included in the rendered code just before any user-defined hooks."]}, "reflex-reflex/components/component.py-_get_all_hooks": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef _get_all_hooks(self) -> dict[str, None]:\n    \"\"\"Get the React hooks for this component and its children.\n\n    Returns:\n        The code that should appear just before returning the rendered component.\n    \"\"\"\n    hooks = {}\n    \n    # Get hooks for this component\n    for hook in self.add_hooks():\n        hooks[hook] = None\n    \n    # Get hooks for all children recursively\n    for child in self.children:\n        if isinstance(child, Component):\n            hooks.update(child._get_all_hooks())\n    \n    return hooks\n```\n\nThis implementation does the following:\n\n1. Initializes an empty `hooks` dictionary to store the React hooks.\n\n2. Calls the `add_hooks()` method of the current component to get any additional hooks defined by the subclass. It adds each hook to the `hooks` dictionary with a value of `None` (since we only care about the keys).\n\n3. Iterates through the `children` of the component. For each child that is an instance of `Component`, it recursively calls `_get_all_hooks()` on that child to get its hooks and the hooks of its descendants. It updates the `hooks` dictionary with the child hooks.\n\n4. Finally, it returns the `hooks` dictionary containing all the React hooks for the component and its children.\n\nThis implementation assumes that `add_hooks()` returns a list of hook strings or `Var` objects, and that `children` is a list of `Component` instances or other renderable objects."]}, "reflex-reflex/components/component.py-_get_all_custom_components": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef _get_all_custom_components(self, seen: set[str] | None = None) -> set[str]:\n    \"\"\"Get all the custom components used by the component.\n\n    Args:\n        seen: The tags of the components that have already been seen.\n\n    Returns:\n        The set of custom components.\n    \"\"\"\n    if seen is None:\n        seen = set()\n\n    custom_components = set()\n\n    for child in self.children:\n        if isinstance(child, Component):\n            if child.tag not in seen:\n                seen.add(child.tag)\n                custom_components.add(child.tag)\n                custom_components |= child._get_all_custom_components(seen)\n\n    return custom_components\n```\n\nThis `_get_all_custom_components` method recursively traverses the component's children to find all the custom components used by the component and its descendants. \n\nThe `seen` argument keeps track of the component tags that have already been processed to avoid duplicates and infinite recursion.\n\nIt returns a set of the tags of all the custom components found."]}, "reflex-reflex/components/core/upload.py-create": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef create(cls, *children, **props) -> Component:\n    \"\"\"Create an upload component.\n\n    Args:\n        *children: The children of the component.\n        **props: The properties of the component.\n\n    Returns:\n        The upload component.\n    \"\"\"\n    # Mark the Upload component as used in the app.\n    Upload.is_used = True\n\n    # Create the Upload component with the provided children and props.\n    return super().create(\n        *children,\n        **props,\n    )\n```\n\nThis `create` class method does the following:\n\n1. It takes `*children` and `**props` as arguments, allowing any number of child components and component properties to be passed.\n\n2. It marks the `Upload` component as used in the app by setting `Upload.is_used` to `True`. This is likely used for tracking or configuration purposes.\n\n3. It calls the `create` method of the superclass (`super().create()`) with the provided `*children` and `**props` to create and return the actual `Upload` component instance.\n\n4. Finally, it returns the created `Upload` component.\n\nThe method signature and docstring match the provided specifications, and the implementation follows the natural language description of creating an upload component using the provided children and props."]}, "reflex-reflex/components/next/image.py-create": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\n@classmethod\ndef create(\n    cls,\n    *children: Any,\n    src: Union[str, Var[Any]],\n    width: Union[int, Var[Any]],\n    height: Union[int, Var[Any]],\n    alt: Optional[str] = None,\n    loader: Optional[Any] = None,\n    fill: Optional[bool] = True,\n    sizes: Optional[str] = None,\n    quality: Optional[int] = 75,\n    priority: Optional[bool] = False,\n    placeholder: Optional[str] = \"empty\",\n    loading: Optional[Literal[\"lazy\", \"eager\"]] = \"lazy\",\n    blurDataURL: Optional[str] = None,\n    on_load: Optional[EventHandler[lambda: []]] = None,\n    on_error: Optional[EventHandler[lambda: []]] = None,\n    **props: Any\n) -> \"Image\":\n    \"\"\"Create an Image component from next/image.\n\n    Args:\n        *children: The children of the component.\n        src: The source URL or path of the image.\n        width: The width of the image.\n        height: The height of the image.\n        alt: Alternative text for the image.\n        loader: A custom function used to resolve image URLs.\n        fill: A boolean that causes the image to fill the parent element. Default to True.\n        sizes: A string that provides information about how wide the image will be at different breakpoints.\n        quality: The quality of the optimized image, an integer between 1 and 100. Defaults to 75.\n        priority: When true, the image will be considered high priority and preload.\n        placeholder: A placeholder to use while the image is loading. Defaults to \"empty\".\n        loading: The loading behavior of the image. Defaults to \"lazy\".\n        blurDataURL: A Data URL to be used as a placeholder image before the src image successfully loads.\n        on_load: Event handler that fires when the image has loaded.\n        on_error: Event handler that fires when the image has an error.\n        **props: Additional props for the component.\n\n    Returns:\n        Image: An instance of the Image component.\n    \"\"\"\n    return cls(\n        *children,\n        src=src,\n        width=width,\n        height=height,\n        alt=alt,\n        loader=loader,\n        fill=fill,\n        sizes=sizes,\n        quality=quality,\n        priority=priority,\n        placeholder=placeholder,\n        loading=loading,\n        blurDataURL=blurDataURL,\n        on_load=on_load,\n        on_error=on_error,\n        **props\n    )\n```\n\nThis function takes the required arguments `src`, `width`, and `height`, along with several optional arguments for customizing the image component. It returns an instance of the `Image` class with the provided arguments and props."]}, "reflex-reflex/components/lucide/icon.py-create": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef create(cls, *children, **props) -> Component:\n    \"\"\"Initialize the Icon component.\n\n    Run some additional checks on Icon component.\n\n    Args:\n        *children: The positional arguments\n        **props: The keyword arguments\n\n    Raises:\n        AttributeError: The errors tied to bad usage of the Icon component.\n        ValueError: If the icon tag is invalid.\n\n    Returns:\n        The created component.\n    \"\"\"\n    if children:\n        raise AttributeError(\n            f\"Icon component does not accept children. Found {len(children)}.\"\n        )\n\n    tag = props.pop(\"tag\", None)\n    if tag is None:\n        raise AttributeError(\"Icon component requires a tag prop.\")\n\n    if tag not in LUCIDE_ICON_LIST:\n        if tag in RENAMED_ICONS_05:\n            old_tag = tag\n            tag = RENAMED_ICONS_05[old_tag]\n            console.warning(\n                f\"Icon tag '{old_tag}' has been renamed to '{tag}' in Lucide v0.5.0.\"\n            )\n        else:\n            raise ValueError(\n                format.dedent(\n                    f\"\"\"\n                    Icon tag '{tag}' is invalid.\n                    See https://lucide.dev/icons for a list of valid icon tags.\n                    \"\"\"\n                )\n            )\n\n    props[\"tag\"] = tag\n    return super().create(**props)\n```"]}, "reflex-reflex/components/tags/tag.py-format_props": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef format_props(self) -> List:\n    \"\"\"Format the tag's props.\n\n    Returns:\n        The formatted props list.\n    \"\"\"\n    formatted_props = []\n\n    for prop_name, prop_value in self.props.items():\n        if isinstance(prop_value, Var):\n            formatted_props.append(f'{prop_name}={prop_value.to_string()}')\n        elif isinstance(prop_value, EventChain):\n            formatted_props.append(f'{prop_name}={prop_value.to_string()}')\n        elif isinstance(prop_value, dict):\n            formatted_prop = f'{prop_name}={{'\n            formatted_prop += ', '.join(\n                f'{key}={value.to_string()}' if isinstance(value, Var) else f'{key}={value}'\n                for key, value in prop_value.items()\n            )\n            formatted_prop += '}'\n            formatted_props.append(formatted_prop)\n        else:\n            formatted_props.append(f'{prop_name}=\"{prop_value}\"')\n\n    formatted_props.extend(prop.to_string() for prop in self.special_props)\n\n    return formatted_props\n```\n\nThis function does the following:\n\n1. It initializes an empty list called `formatted_props` to store the formatted props.\n\n2. It iterates over the `self.props` dictionary items:\n   - If the prop value is an instance of `Var`, it formats the prop as `prop_name=prop_value.to_string()`.\n   - If the prop value is an instance of `EventChain`, it formats the prop as `prop_name=prop_value.to_string()`.\n   - If the prop value is a dictionary, it formats the prop as `prop_name={key1=value1, key2=value2, ...}`, where the values are converted to strings if they are instances of `Var`.\n   - Otherwise, it formats the prop as `prop_name=\"prop_value\"`.\n\n3. It extends the `formatted_props` list with the formatted special props from `self.special_props`, converting each prop to a string using `prop.to_string()`.\n\n4. Finally, it returns the `formatted_props` list containing all the formatted props.\n\nThis function formats the tag's props into a list of strings, handling different types of prop values such as `Var`, `EventChain`, dictionaries, and other values."]}, "textual-src/textual/screen.py-focus_next": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef focus_next(self, selector: str | type[QueryType] = \"*\") -> Widget | None:\n    \"\"\"Focus the next widget, optionally filtered by a CSS selector.\n\n    If no widget is currently focused, this will focus the first focusable widget.\n    If no focusable widget matches the given CSS selector, focus is set to `None`.\n\n    Args:\n        selector: CSS selector to filter\n            what nodes can be focused.\n\n    Returns:\n        Newly focused widget, or None for no focus. If the return \n            is not `None`, then it is guaranteed that the widget returned matches\n            the CSS selectors given in the argument.\n    \"\"\"\n    return self._move_focus(direction=1, selector=selector)\n```"]}, "textual-src/textual/screen.py-focus_previous": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef focus_previous(self, selector: str | type[QueryType] = \"*\") -> Widget | None:\n    \"\"\"Focus the previous widget, optionally filtered by a CSS selector.\n\n    If no widget is currently focused, this will focus the first focusable widget.\n    If no focusable widget matches the given CSS selector, focus is set to `None`.\n\n    Args:\n        selector: CSS selector to filter\n            what nodes can be focused.\n\n    Returns:\n        Newly focused widget, or None for no focus. If the return\n            is not `None`, then it is guaranteed that the widget returned matches\n            the CSS selectors given in the argument.\n    \"\"\"\n    return self._move_focus(direction=-1, selector=selector)\n```\n\nThis function simply calls the internal `_move_focus` method with a direction of -1 to move focus to the previous widget, passing along the provided `selector` argument."]}, "textual-src/textual/screen.py-set_focus": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef set_focus(self, widget: Widget | None, scroll_visible: bool = True) -> None:\n    \"\"\"Focus (or un-focus) a widget. A focused widget will receive key events first.\n\n    Args:\n        widget: Widget to focus, or None to un-focus.\n        scroll_visible: Scroll widget in to view.\n    \"\"\"\n    blurred = self.focused\n    self.focused = widget\n\n    if widget is not None:\n        widget._has_focus = True\n        if scroll_visible:\n            widget.scroll_visible()\n    elif blurred is not None:\n        blurred._has_focus = False\n\n    self._update_focus_styles(focused=widget, blurred=blurred)\n    self.refresh_bindings()\n```\n\nThis implementation does the following:\n\n1. It stores the currently focused widget in the `blurred` variable.\n\n2. It updates the `focused` attribute of the `Screen` instance to the new `widget` (which can be `None` to un-focus).\n\n3. If a `widget` is provided (not `None`):\n   - It sets the `_has_focus` attribute of the `widget` to `True`.\n   - If `scroll_visible` is `True`, it calls the `scroll_visible()` method of the `widget` to scroll it into view.\n\n4. If no `widget` is provided (`None`) and there was a previously focused widget (`blurred` is not `None`), it sets the `_has_focus` attribute of the `blurred` widget to `False`.\n\n5. It calls the `_update_focus_styles()` method, passing the newly focused `widget` and the previously focused `blurred` widget, to update the CSS styles related to focus changes.\n\n6. Finally, it calls the `refresh_bindings()` method to refresh the bindings associated with the focused widget.\n\nThis function allows setting focus to a specific widget or un-focusing the currently focused widget, and it handles the necessary updates to the widget's focus state, scrolling visibility, CSS styles, and bindings."]}, "textual-src/textual/strip.py-index_to_cell_position": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef index_to_cell_position(self, index: int) -> int:\n    \"\"\"Given a character index, return the cell position of that character.\n    This is the sum of the cell lengths of all the characters *before* the character\n    at `index`.\n\n    Args:\n        index: The index to convert.\n\n    Returns:\n        The cell position of the character at `index`.\n    \"\"\"\n    cell_position = 0\n    for segment in self._segments:\n        segment_length = len(segment.text)\n        if index < segment_length:\n            cell_position += index_to_cell_position(segment.text, index)\n            break\n        index -= segment_length\n        cell_position += segment.cell_length\n    return cell_position\n```\n\nThe function iterates through the segments in the `Strip` object. For each segment, it checks if the `index` is within the length of the segment's text. If so, it calculates the cell position within that segment using the `index_to_cell_position` function from `_segment_tools` module, and adds it to the running `cell_position`. If the `index` is beyond the current segment, it subtracts the segment's text length from `index` and adds the segment's cell length to `cell_position`. This process continues until the segment containing the character at `index` is found."]}, "textual-src/textual/strip.py-render": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef render(self, console: Console) -> str:\n    \"\"\"Render the strip into terminal sequences.\n\n    Args:\n        console: Console instance.\n\n    Returns:\n        Rendered sequences.\n    \"\"\"\n    if self._render_cache is None:\n        self._render_cache = console.render_lines(\n            [self._segments],\n            new_lines=False,\n            highlight=False,\n            markup=False,\n        )\n    return self._render_cache\n```"]}, "textual-src/textual/app.py-batch_update": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@contextmanager\ndef batch_update(self) -> Generator[None, None, None]:\n    \"\"\"A context manager to suspend all repaints until the end of the batch.\"\"\"\n    self._batch_count += 1\n    try:\n        yield\n    finally:\n        self._batch_count -= 1\n        if self._batch_count == 0 and self._refresh_required:\n            self.refresh()\n```\n\nThis function is a context manager that suspends all repaints until the end of the batch. It does the following:\n\n1. It increments the `_batch_count` attribute to keep track of the number of active batches.\n\n2. It uses a `try` block to yield control back to the caller, allowing the code inside the `with` block to execute.\n\n3. In the `finally` block, which always runs at the end of the `with` block, it decrements the `_batch_count` attribute.\n\n4. If the `_batch_count` reaches zero (indicating that all batches have completed) and a refresh is required (indicated by the `_refresh_required` attribute), it calls the `refresh()` method to trigger a repaint.\n\nBy using this context manager, you can group multiple updates together and prevent unnecessary repaints until the entire batch is finished."]}, "textual-src/textual/app.py-call_from_thread": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef call_from_thread(\n    self,\n    callback: Callable[..., CallThreadReturnType],\n    *args: Any,\n    **kwargs: Any,\n) -> CallThreadReturnType:\n    \"\"\"Run a callable from another thread, and return the result.\n\n    Like asyncio apps in general, Textual apps are not thread-safe. If you call methods\n    or set attributes on Textual objects from a thread, you may get unpredictable results.\n\n    This method will ensure that your code runs within the correct context.\n\n    !!! tip\n\n        Consider using [post_message][textual.message_pump.MessagePump.post_message] which is also thread-safe.\n\n    Args:\n        callback: A callable to run.\n        *args: Arguments to the callback.\n        **kwargs: Keyword arguments for the callback.\n\n    Raises:\n        RuntimeError: If the app isn't running or if this method is called from the same\n            thread where the app is running.\n\n    Returns:\n        The result of the callback.\n    \"\"\"\n    if not self._loop or not self._loop.is_running():\n        raise RuntimeError(\"App is not running\")\n\n    if threading.current_thread() is threading.main_thread():\n        raise RuntimeError(\n            \"Cannot call App.call_from_thread from the same thread the app is running in\"\n        )\n\n    future: Future[CallThreadReturnType] = Future()\n\n    def _done_callback(task: asyncio.Task[CallThreadReturnType]) -> None:\n        try:\n            future.set_result(task.result())\n        except BaseException as exc:\n            future.set_exception(exc)\n\n    self.call_later(\n        callback,\n        *args,\n        _thread_sensitive=True,\n        _call_from_thread=True,\n        **kwargs,\n    ).add_done_callback(_done_callback)\n\n    return future.result()\n```\n\nThis implementation does the following:\n\n1. It checks if the app's event loop is running, and raises a `RuntimeError` if it isn't.\n\n2. It checks if the current thread is the main thread (where the app is running), and raises a `RuntimeError` if it is. This ensures that the method is only called from a different thread.\n\n3. It creates a `Future` object to hold the result of the callback.\n\n4. It defines a `_done_callback` function that will be called when the task (created in the next step) is done. This function sets the result or exception of the `Future` based on the task's result or exception.\n\n5. It calls the app's `call_later` method to schedule the execution of the `callback` with the provided `args` and `kwargs`. It sets `_thread_sensitive` and `_call_from_thread` to `True` to indicate that this call is coming from a different thread. It adds the `_done_callback` to be called when the task is done.\n\n6. Finally, it waits for the `Future` to complete and returns its result.\n\nThis implementation ensures that the `callback` is executed in the app's event loop, even though it is called from a different thread, and returns the result back to the calling thread."]}, "textual-src/textual/app.py-run_test": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@asynccontextmanager\nasync def run_test(\n    self,\n    headless: bool = True,\n    size: tuple[int, int] | None = None,\n    tooltips: bool = False,\n    notifications: bool = False,\n    message_hook: Callable[[Message], None] | None = None,\n) -> AsyncGenerator[Pilot[Self], None]:\n    \"\"\"An asynchronous context manager for testing apps.\n\n    !!! tip\n\n        See the guide for [testing](/guide/testing) Textual apps.\n\n    Use this to run your app in \"headless\" mode (no output) and drive the app via a [Pilot][textual.pilot.Pilot] object.\n\n    Example:\n\n        ```python\n        async with app.run_test() as pilot:\n            await pilot.click(\"#Button.ok\")\n            assert ...\n        ```\n\n    Args:\n        headless: Run in headless mode (no output or input).\n        size: Force terminal size to `(WIDTH, HEIGHT)`,\n            or None to auto-detect.\n        tooltips: Enable tooltips when testing.\n        notifications: Enable notifications when testing.\n        message_hook: An optional callback that will be called each time any message arrives at any\n            message pump in the app.\n    \"\"\"\n    self._disable_tooltips = not tooltips\n    self._disable_notifications = not notifications\n\n    if message_hook is not None:\n        message_hook_context_var.set(message_hook)\n\n    async with self.run(headless=headless, size=size) as pilot:\n        yield pilot\n\n    self._disable_tooltips = False\n    self._disable_notifications = False\n```\n\nThis function uses the `@asynccontextmanager` decorator to define an asynchronous context manager. It takes the specified arguments and sets the corresponding attributes on the `App` instance.\n\nInside the context manager, it calls `self.run()` with the provided `headless` and `size` arguments to run the app. It yields the `pilot` object obtained from `run()` to allow the caller to interact with the app during testing.\n\nFinally, after the context manager exits, it resets the `_disable_tooltips` and `_disable_notifications` attributes to their default values."]}, "textual-src/textual/app.py-run": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef run(\n    self,\n    headless: bool = False,\n    inline: bool = False,\n    inline_no_clear: bool = False,\n    mouse: bool = True,\n    size: tuple[int, int] | None = None,\n    auto_pilot: AutopilotCallbackType | None = None,\n) -> ReturnType:\n    \"\"\"Run the app.\n\n    Args:\n        headless: Run in headless mode (no output).\n        inline: Run the app inline (under the prompt).\n        inline_no_clear: Don't clear the app output when exiting an inline app.\n        mouse: Enable mouse support.\n        size: Force terminal size to `(WIDTH, HEIGHT)`,\n            or None to auto-detect.\n        auto_pilot: An auto pilot coroutine.\n\n    Returns:\n        App return value.\n    \"\"\"\n    # Implementation details would go here\n    ...\n```"]}, "textual-src/textual/app.py-switch_mode": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef switch_mode(self, mode: str) -> AwaitMount:\n    \"\"\"Switch to a given mode.\n\n    Args:\n        mode: The mode to switch to.\n\n    Returns:\n        An optionally awaitable object which waits for the screen associated\n            with the mode to be mounted.\n\n    Raises:\n        UnknownModeError: If trying to switch to an unknown mode.\n    \"\"\"\n    if mode not in self.MODES:\n        raise UnknownModeError(f\"Unknown mode: {mode}\")\n\n    self._current_mode = mode\n\n    if mode not in self._screen_stacks:\n        self._screen_stacks[mode] = []\n\n    screen_stack = self._screen_stacks[mode]\n    if not screen_stack:\n        base_screen = self.MODES[mode]\n        if isinstance(base_screen, str):\n            base_screen = self._installed_screens[base_screen]\n        if inspect.isclass(base_screen) and issubclass(base_screen, Screen):\n            base_screen = base_screen()\n        elif callable(base_screen):\n            base_screen = base_screen()\n        screen_stack.append(base_screen)\n\n    return self.push_screen(screen_stack[-1])\n```\n\nThis implementation does the following:\n\n1. It checks if the provided `mode` exists in the `MODES` class variable. If not, it raises an `UnknownModeError`.\n\n2. It updates the `_current_mode` attribute to the new mode.\n\n3. If the mode doesn't have an existing screen stack in `_screen_stacks`, it creates a new empty stack for that mode.\n\n4. It retrieves the screen stack for the given mode.\n\n5. If the screen stack is empty, it retrieves the base screen associated with the mode from the `MODES` class variable.\n   - If the base screen is a string, it looks up the corresponding screen from the `_installed_screens` dictionary.\n   - If the base screen is a `Screen` class or subclass, it creates an instance of that class.\n   - If the base screen is a callable, it calls it to obtain the screen instance.\n   - It appends the base screen to the screen stack.\n\n6. Finally, it calls `self.push_screen` with the last screen in the stack (which is either the base screen or the previously active screen for that mode) and returns the result, which is an `AwaitMount` object that allows waiting for the screen to be mounted.\n\nThe function raises an `UnknownModeError` if an attempt is made to switch to a mode that is not defined in the `MODES` class variable."]}, "textual-src/textual/app.py-push_screen": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef push_screen(\n    self,\n    screen: Screen | str,\n    callback: ScreenResultCallbackType | None = None,\n    wait_for_dismiss: bool = False,\n) -> Awaitable[ScreenResultType] | None:\n    \"\"\"Push a new [screen](/guide/screens) on the screen stack, making it the current screen.\n\n    Args:\n        screen: A Screen instance or the name of an installed screen.\n        callback: An optional callback function that will be called if the screen is [dismissed][textual.screen.Screen.dismiss] with a result.\n        wait_for_dismiss: If `True`, awaiting this method will return the dismiss value from the screen. When set to `False`, awaiting\n            this method will wait for the screen to be mounted. Note that `wait_for_dismiss` should only be set to `True` when running in a worker.\n\n    Raises:\n        NoActiveWorker: If using `wait_for_dismiss` outside of a worker.\n\n    Returns:\n        An optional awaitable that awaits the mounting of the screen and its children, or an asyncio Future\n            to await the result of the screen.\n    \"\"\"\n    if isinstance(screen, str):\n        screen = self._installed_screens[screen]\n        if callable(screen):\n            screen = screen()\n\n    if wait_for_dismiss and not get_current_worker():\n        raise NoActiveWorker(\"wait_for_dismiss can only be used within a worker\")\n\n    if wait_for_dismiss:\n        future: asyncio.Future[ScreenResultType] = asyncio.Future()\n\n        def _callback(result: ScreenResultType) -> None:\n            future.set_result(result)\n\n        callback = _callback\n\n    screen._set_app(self)\n    screen._set_callback(callback)\n    self._screen_stacks[self._current_mode].append(screen)\n    self._recompose_required = True\n\n    if wait_for_dismiss:\n        return future\n    else:\n        return self.call_later(screen.post_mount)\n```\n\nThis function follows the provided signature and implements the behavior described in the natural language annotations. It allows pushing a new screen onto the screen stack, making it the current screen. The `screen` argument can be either a `Screen` instance or the name of an installed screen. The `callback` argument is an optional callback function that will be called if the screen is dismissed with a result. The `wait_for_dismiss` argument determines whether the method should wait for the screen to be dismissed or just wait for it to be mounted.\n\nThe function raises a `NoActiveWorker` exception if `wait_for_dismiss` is set to `True` outside of a worker. It returns an awaitable that either awaits the mounting of the screen and its children or an asyncio Future to await the result of the screen, depending on the value of `wait_for_dismiss`."]}, "textual-src/textual/app.py-switch_screen": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef switch_screen(self, screen: Screen | str) -> AwaitComplete:\n    \"\"\"Switch to another [screen](/guide/screens) by replacing the top of the screen stack with a new screen.\n\n    Args:\n        screen: Either a Screen object or screen name (the `name` argument when installed).\n    \"\"\"\n    if isinstance(screen, str):\n        screen_name = screen\n        if screen_name not in self._installed_screens:\n            raise ScreenError(f\"No screen installed with name {screen_name!r}\")\n        screen_factory = self._installed_screens[screen_name]\n        screen = (\n            screen_factory() if callable(screen_factory) else screen_factory\n        )\n\n    if not isinstance(screen, Screen):\n        raise ScreenError(\n            f\"Argument screen should be a Screen instance or string, not {screen!r}\"\n        )\n\n    if self.screen:\n        await self.screen._on_leave()\n\n    self._screen_stacks[self._current_mode][-1] = screen\n    screen._app = self\n    screen._enter_message_pump()\n    await screen._on_enter()\n\n    self.refresh(layout=True)\n    return AwaitComplete(self, self.screen._on_screen_resume)\n```\n\nThe function does the following:\n\n1. If `screen` is a string, it checks if it matches an installed screen name in `self._installed_screens`. If not found, it raises a `ScreenError`. If found, it retrieves the corresponding screen factory and creates a new screen instance if the factory is callable, otherwise it uses the screen directly.\n\n2. If `screen` is not an instance of `Screen`, it raises a `ScreenError` indicating an invalid argument type.\n\n3. If there is a current screen (`self.screen`), it calls the `_on_leave()` method of the current screen to handle any necessary cleanup or actions before leaving the screen.\n\n4. It replaces the top screen in the screen stack for the current mode (`self._screen_stacks[self._current_mode][-1]`) with the new `screen`.\n\n5. It sets the `_app` attribute of the new screen to the current app instance.\n\n6. It calls the `_enter_message_pump()` method of the new screen to enter its message pump.\n\n7. It calls the `_on_enter()` method of the new screen to handle any necessary setup or actions when entering the screen.\n\n8. It refreshes the app with `layout=True` to update the screen layout.\n\n9. Finally, it returns an `AwaitComplete` object with the app instance and the `_on_screen_resume` method of the new screen as the callback. This allows the caller to await the completion of the screen switch and perform any additional actions when the screen resumes."]}, "textual-src/textual/app.py-pop_screen": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef pop_screen(self) -> AwaitComplete:\n    \"\"\"Pop the current [screen](/guide/screens) from the stack, and switch to the previous screen.\n\n    Returns:\n        The screen that was replaced.\n    \"\"\"\n    current_stack = self._screen_stacks[self._current_mode]\n    if len(current_stack) < 2:\n        raise ScreenStackError(\"Cannot pop the last screen from the stack.\")\n\n    previous_screen = current_stack.pop()\n    new_screen = current_stack[-1]\n\n    await_complete = AwaitComplete(self)\n    await_complete.event.set()\n\n    self._switch_screen(new_screen, previous_screen)\n\n    return await_complete\n```\n\nThis implementation does the following:\n\n1. It retrieves the current screen stack based on the current mode.\n2. It checks if there are at least two screens in the stack. If not, it raises a `ScreenStackError` since the last screen cannot be popped.\n3. It removes the current screen from the stack using `pop()` and assigns it to `previous_screen`.\n4. It retrieves the new current screen, which is now the last screen in the stack, and assigns it to `new_screen`.\n5. It creates an `AwaitComplete` object to signal the completion of the screen pop operation.\n6. It calls the internal `_switch_screen` method to perform the actual screen switch, passing the new current screen and the previous screen.\n7. Finally, it returns the `AwaitComplete` object to allow the caller to await the completion of the screen pop operation.\n\nThe function raises a `ScreenStackError` if an attempt is made to pop the last screen from the stack, as there must always be at least one screen in the stack."]}, "textual-src/textual/app.py-run_action": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\nasync def run_action(\n    self,\n    action: str,\n    default_namespace: str | None = None,\n) -> bool:\n    \"\"\"Perform an [action](/guide/actions).\n\n    Actions are typically associated with key bindings, where you wouldn't need to call this method manually.\n\n    Args:\n        action: Action encoded in a string.\n        default_namespace: Namespace to use if not provided in the action,\n            or None to use app.\n\n    Returns:\n        True if the event has been handled.\n    \"\"\"\n    namespace = default_namespace or \"app\"\n    action_result = actions.parse(action)\n    if isinstance(action_result, str):\n        action_name = action_result\n        params: list[Any] = []\n    else:\n        action_name, params = action_result\n\n    qualified_name = f\"{namespace}.{action_name}\"\n\n    try:\n        await self._action(qualified_name, *params)\n    except NoHandler:\n        return False\n    else:\n        return True\n```"]}, "textual-src/textual/file_monitor.py-check": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef check(self) -> bool:\n    \"\"\"Check the monitored files. Return True if any were changed since the last modification time.\"\"\"\n    current_modified = self._get_last_modified_time()\n    if current_modified > self._modified:\n        self._modified = current_modified\n        return True\n    return False\n```"]}, "textual-src/textual/expand_tabs.py-expand_tabs_inline": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef expand_tabs_inline(line: str, tab_size: int = 4) -> str:\n    \"\"\"Expands tabs, taking into account double cell characters.\n\n    Args:\n        line: The text to expand tabs in.\n        tab_size: Number of cells in a tab.\n    Returns:\n        New string with tabs replaced with spaces.\n    \"\"\"\n    tab_widths = [width for _, width in get_tab_widths(line, tab_size)]\n    text = Text(line)\n    expanded_text = expand_text_tabs_from_widths(text, tab_widths)\n    return expanded_text.plain\n```"]}, "textual-src/textual/_resolve.py-resolve": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef resolve(\n    dimensions: Sequence[Scalar | None],\n    total: int,\n    gutter: int,\n    size: Size,\n    viewport: Size,\n) -> list[tuple[int, int]]:\n    \"\"\"Resolve a list of dimensions.\n\n    Args:\n        dimensions: Scalars for column / row sizes.\n        total: Total space to divide.\n        gutter: Gutter between rows / columns.\n        size: Size of container.\n        viewport: Size of viewport.\n\n    Returns:\n        List of (<OFFSET>, <LENGTH>)\n    \"\"\"\n    total_gutter = gutter * (len(dimensions) - 1)\n    total_space = total - total_gutter\n\n    fraction_unit = resolve_fraction_unit(\n        [styles for styles in dimensions if styles is not None and styles.is_fraction],\n        size,\n        viewport,\n        Fraction(total_space),\n    )\n\n    resolved_dimensions = [\n        dimension.resolve(size, viewport, fraction_unit) if dimension is not None else 0\n        for dimension in dimensions\n    ]\n\n    offsets = list(accumulate([0] + resolved_dimensions[:-1]))\n    lengths = resolved_dimensions\n\n    return list(zip(offsets, lengths))\n```\n\nThis function takes the following arguments:\n- `dimensions`: A sequence of `Scalar` objects or `None` values representing the sizes of columns or rows.\n- `total`: The total space available to divide among the dimensions.\n- `gutter`: The gutter size between rows or columns.\n- `size`: The size of the container.\n- `viewport`: The size of the viewport.\n\nThe function first calculates the total gutter space by multiplying the gutter size by the number of dimensions minus one. It then subtracts the total gutter space from the total space to get the remaining space available for the dimensions.\n\nNext, it calls the `resolve_fraction_unit` function (assumed to be defined elsewhere) to resolve the fraction unit for dimensions that have fraction values. It passes the fraction dimensions, container size, viewport size, and the remaining space as arguments.\n\nThe function then resolves each dimension using the `resolve` method of the `Scalar` objects, passing the container size, viewport size, and the resolved fraction unit. If a dimension is `None`, it is treated as a value of 0.\n\nFinally, the function calculates the offsets by accumulating the resolved dimensions (excluding the last one) and zips the offsets with the resolved dimensions to create a list of tuples in the format `(<OFFSET>, <LENGTH>)`.\n\nThe function returns the list of resolved dimensions as tuples of offsets and lengths."]}, "textual-src/textual/widget.py-mount": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef mount(\n    self,\n    *widgets: Widget,\n    before: int | str | None = None,\n    after: int | str | None = None,\n) -> AwaitMount:\n    \"\"\"Mount widgets below this widget (making this widget a container).\n\n    Args:\n        *widgets: The widget(s) to mount.\n        before: Optional location to mount before. An `int` is the index\n            of the child to mount before, a `str` is a `query_one` query to\n            find the widget to mount before.\n        after: Optional location to mount after. An `int` is the index\n            of the child to mount after, a `str` is a `query_one` query to\n            find the widget to mount after.\n\n    Returns:\n        An awaitable object that waits for widgets to be mounted.\n\n    Raises:\n        MountError: If there is a problem with the mount request.\n\n    Note:\n        Only one of ``before`` or ``after`` can be provided. If both are\n        provided a ``MountError`` will be raised.\n    \"\"\"\n    if before is not None and after is not None:\n        raise MountError(\"Only one of 'before' or 'after' can be provided\")\n\n    if before is not None:\n        if isinstance(before, int):\n            index = before\n        elif isinstance(before, str):\n            widget = self.query_one(before)\n            index = self._nodes.index(widget)\n        else:\n            raise MountError(f\"Invalid 'before' value: {before!r}\")\n    elif after is not None:\n        if isinstance(after, int):\n            index = after + 1\n        elif isinstance(after, str):\n            widget = self.query_one(after)\n            index = self._nodes.index(widget) + 1\n        else:\n            raise MountError(f\"Invalid 'after' value: {after!r}\")\n    else:\n        index = len(self._nodes)\n\n    self._pending_children[index:index] = list(widgets)\n    self.check_idle()\n    return AwaitMount(self, widgets)\n```\n\nThis implementation does the following:\n\n1. It raises a `MountError` if both `before` and `after` are provided, as only one can be specified.\n\n2. If `before` is provided, it determines the index to insert the widgets based on the type:\n   - If it's an `int`, it uses that index directly.\n   - If it's a `str`, it queries for the widget using `query_one` and gets its index.\n   - If it's any other type, it raises a `MountError`.\n\n3. If `after` is provided, it determines the index to insert the widgets based on the type:\n   - If it's an `int`, it uses that index plus one (to insert after).\n   - If it's a `str`, it queries for the widget using `query_one` and gets its index plus one.\n   - If it's any other type, it raises a `MountError`.\n\n4. If neither `before` nor `after` is provided, it appends the widgets to the end of the `_nodes` list.\n\n5. It inserts the `widgets` into the `_pending_children` list at the determined index.\n\n6. It calls `check_idle()` to trigger the mounting process.\n\n7. Finally, it returns an `AwaitMount` object that allows awaiting the mounting of the widgets.\n\nThis function follows the provided signature and implements the behavior described in the natural language annotations."]}, "textual-src/textual/widget.py-move_child": {"response": ["Here is the generated function based on the provided signature and annotations:\n\n```python\ndef move_child(\n    self,\n    child: Widget,\n    before: Widget | int | None = None,\n    after: Widget | int | None = None,\n) -> None:\n    \"\"\"Move a child widget within its parent's list of children.\n\n    Args:\n        child: The child widget to move.\n        before: Child widget or location index to move before.\n        after: Child widget or location index to move after.\n\n    Raises:\n        WidgetError: If there is a problem with the child or target.\n\n    Note:\n        Only one of `before` or `after` can be provided. If neither\n        or both are provided a `WidgetError` will be raised.\n    \"\"\"\n    if before is not None and after is not None:\n        raise WidgetError(\"Only one of 'before' or 'after' can be provided.\")\n    if before is None and after is None:\n        raise WidgetError(\"Either 'before' or 'after' must be provided.\")\n\n    if child not in self._nodes:\n        raise WidgetError(\"The specified child is not a child of this widget.\")\n\n    if isinstance(before, Widget) and before not in self._nodes:\n        raise WidgetError(\"The 'before' widget is not a child of this widget.\")\n    if isinstance(after, Widget) and after not in self._nodes:\n        raise WidgetError(\"The 'after' widget is not a child of this widget.\")\n\n    self._nodes.remove(child)\n\n    if before is not None:\n        if isinstance(before, Widget):\n            index = self._nodes.index(before)\n        else:\n            index = before\n        self._nodes.insert(index, child)\n    else:\n        if isinstance(after, Widget):\n            index = self._nodes.index(after) + 1\n        else:\n            index = after + 1\n        self._nodes.insert(index, child)\n\n    self.refresh(layout=True)\n```\n\nThis function moves a child widget within its parent's list of children based on the provided `before` or `after` target. It performs the following steps:\n\n1. It checks if both `before` and `after` are provided or if neither is provided, raising a `WidgetError` in either case.\n\n2. It verifies that the specified `child` is actually a child of the current widget, raising a `WidgetError` if it's not.\n\n3. If `before` or `after` is a `Widget`, it checks if they are children of the current widget, raising a `WidgetError` if they're not.\n\n4. It removes the `child` from the parent's list of children (`self._nodes`).\n\n5. If `before` is provided, it determines the index to insert the child based on the `before` target (either a `Widget` or an integer index) and inserts the child at that index.\n\n6. If `after` is provided, it determines the index to insert the child based on the `after` target (either a `Widget` or an integer index) and inserts the child at that index.\n\n7. Finally, it calls `self.refresh(layout=True)` to trigger a refresh and layout of the widget.\n\nThis function ensures that the child is moved correctly within its parent's list of children based on the provided target."]}, "textual-src/textual/widget.py-_get_box_model": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef _get_box_model(\n    self,\n    container: Size,\n    viewport: Size,\n    width_fraction: float,\n    height_fraction: float,\n) -> BoxModel:\n    \"\"\"Process the box model for this widget.\n\n    Args:\n        container: The size of the container widget (with a layout)\n        viewport: The viewport size.\n        width_fraction: A fraction used for 1 `fr` unit on the width dimension.\n        height_fraction: A fraction used for 1 `fr` unit on the height dimension.\n\n    Returns:\n        The size and margin for this widget.\n    \"\"\"\n    box_model = self.styles.resolve(\n        container, viewport, width_fraction, height_fraction\n    )\n    return box_model\n```\n\nThis function takes in the `container` size, `viewport` size, `width_fraction`, and `height_fraction` as parameters. It then resolves the styles for the widget using these parameters to determine the box model. Finally, it returns the resolved `BoxModel` object containing the size and margin for the widget."]}, "textual-src/textual/widget.py-get_content_width": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef get_content_width(self, container: Size, viewport: Size) -> int:\n    \"\"\"Called by textual to get the width of the content area. May be overridden in a subclass.\n\n    Args:\n        container: Size of the container (immediate parent) widget.\n        viewport: Size of the viewport.\n\n    Returns:\n        The optimal width of the content.\n    \"\"\"\n    renderable = self.render()\n    if (renderable, container.width) == self._content_width_cache[0]:\n        return self._content_width_cache[1]\n    options = self.console.options.update_width(container.width)\n    measurement = self.console.measure(renderable, options)\n    content_width = measurement.maximum\n    self._content_width_cache = ((renderable, container.width), content_width)\n    return content_width\n```\n\nThis implementation does the following:\n\n1. It calls `self.render()` to get the current renderable for the widget.\n\n2. It checks if the renderable and container width match the cached values in `self._content_width_cache`. If so, it returns the cached content width to avoid re-measuring.\n\n3. If the cache doesn't match, it updates the console options with the container width using `self.console.options.update_width(container.width)`. \n\n4. It measures the renderable using `self.console.measure(renderable, options)` to get the optimal width.\n\n5. It extracts the maximum width from the measurement and stores it in `content_width`.\n\n6. It updates the `self._content_width_cache` with the renderable, container width, and the measured content width.\n\n7. Finally, it returns the calculated `content_width`.\n\nBy caching the content width based on the renderable and container width, it avoids unnecessary re-measuring when the values haven't changed. The cache can be cleared using the `clear_cached_dimensions()` method if the renderable changes size after the widget is created."]}, "textual-src/textual/widget.py-get_content_height": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef get_content_height(self, container: Size, viewport: Size, width: int) -> int:\n    \"\"\"Called by Textual to get the height of the content area. May be overridden in a subclass.\n\n    Args:\n        container: Size of the container (immediate parent) widget.\n        viewport: Size of the viewport.\n        width: Width of renderable.\n\n    Returns:\n        The height of the content.\n    \"\"\"\n    key = (container, viewport, width)\n    if self._content_height_cache[0] == key:\n        return self._content_height_cache[1]\n    \n    console = self.app.console\n    options = console.options.update(width=width)\n    height = Measurement.get(console, options, self).height\n    \n    self._content_height_cache = (key, height)\n    return height\n```\n\nThis implementation does the following:\n\n1. It first checks if the height for the given `container`, `viewport`, and `width` has already been cached. If so, it returns the cached height.\n\n2. If not cached, it gets the current console from the app and updates its options with the provided `width`.\n\n3. It then uses `Measurement.get()` to measure the height of the widget's renderable content using the console and updated options.\n\n4. It caches the calculated height along with the key tuple `(container, viewport, width)` for future lookups.\n\n5. Finally, it returns the calculated height.\n\nThis allows the widget to efficiently calculate and cache the content height based on the provided container size, viewport size, and width, avoiding redundant calculations when possible."]}, "textual-src/textual/suggester.py-_get_suggestion": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\nasync def _get_suggestion(self, requester: DOMNode, value: str) -> None:\n    \"\"\"Used by widgets to get completion suggestions.\n\n    Note:\n        When implementing custom suggesters, this method does not need to be\n        overridden.\n\n    Args:\n        requester: The message target that requested a suggestion.\n        value: The current value to complete.\n    \"\"\"\n    if not self.case_sensitive:\n        value = value.casefold()\n\n    if self.cache is not None:\n        if value in self.cache:\n            suggestion = self.cache[value]\n        else:\n            suggestion = await self.get_suggestion(value)\n            self.cache[value] = suggestion\n    else:\n        suggestion = await self.get_suggestion(value)\n\n    await requester.post_message(SuggestionReady(value, suggestion or \"\"))\n```\n\nThis implementation does the following:\n\n1. If `case_sensitive` is `False`, it casefolds the `value` to ensure case-insensitive comparison.\n\n2. If `cache` is enabled (not `None`), it checks if the `value` is already in the cache:\n   - If it is, it retrieves the suggestion from the cache.\n   - If it's not, it calls the `get_suggestion` method to generate the suggestion and stores it in the cache for future use.\n\n3. If `cache` is disabled (`None`), it directly calls the `get_suggestion` method to generate the suggestion.\n\n4. Finally, it sends a `SuggestionReady` message back to the `requester` with the generated suggestion. If the suggestion is `None`, it sends an empty string instead.\n\nNote that this method relies on the abstract `get_suggestion` method to be implemented by the subclasses of `Suggester`."]}, "textual-src/textual/dom.py-add_class": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef add_class(self, *class_names: str, update: bool = True) -> Self:\n    \"\"\"Add class names to this Node.\n\n    Args:\n        *class_names: CSS class names to add.\n        update: Also update styles.\n\n    Returns:\n        Self.\n    \"\"\"\n    check_identifiers(\"class name\", *class_names)\n    self._classes.update(class_names)\n    if update:\n        self._update_styles()\n    return self\n```"]}, "textual-src/textual/reactive.py-_initialize_object": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef _initialize_object(cls, obj: Reactable) -> None:\n    \"\"\"Set defaults and call any watchers / computes for the first time.\n\n    Args:\n        obj: An object with Reactive descriptors\n    \"\"\"\n    _rich_traceback_omit = True\n    for name, reactive in cls._reactives.items():\n        reactive._initialize_reactive(obj, name)\n        if reactive._run_compute:\n            cls._compute(obj)\n        if reactive._init:\n            current_value = getattr(obj, name)\n            cls._check_watchers(obj, name, current_value)\n```\n\nThis function does the following:\n\n1. It iterates over all the reactive descriptors defined in the class (`cls._reactives`).\n\n2. For each reactive descriptor, it calls `reactive._initialize_reactive(obj, name)` to set the default value for the attribute on the object if it hasn't been set already.\n\n3. If the reactive descriptor has `_run_compute` set to `True`, it calls `cls._compute(obj)` to run any compute methods associated with the attribute.\n\n4. If the reactive descriptor has `_init` set to `True`, it retrieves the current value of the attribute using `getattr(obj, name)` and then calls `cls._check_watchers(obj, name, current_value)` to invoke any watchers associated with the attribute, passing the current value as both the old and new value (since this is the initial call).\n\nThis function essentially initializes all the reactive attributes on the object, sets their default values, runs any associated compute methods, and invokes watchers with the initial values."]}, "textual-src/textual/message_pump.py-call_after_refresh": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef call_after_refresh(self, callback: Callback, *args: Any, **kwargs: Any) -> bool:\n    \"\"\"Schedule a callback to run after all messages are processed and the screen\n    has been refreshed. Positional and keyword arguments are passed to the callable.\n\n    Args:\n        callback: A callable.\n\n    Returns:\n        `True` if the callback was scheduled, or `False` if the callback could not be\n            scheduled (may occur if the message pump was closed or closing).\n\n    \"\"\"\n    if self._closed or self._closing:\n        return False\n    \n    callback_message = events.Callback(callback=partial(callback, *args, **kwargs))\n    callback_message._prevent.update(self._get_prevented_messages())\n    self.app.post_message(messages.AfterRefresh(callback_message))\n    return True\n```\n\nThe key steps are:\n\n1. Check if the message pump is already closed or closing. If so, return `False` since the callback cannot be scheduled.\n\n2. Create a `events.Callback` message wrapping the provided `callback` along with any `args` and `kwargs` using `functools.partial`. \n\n3. Update the `_prevent` set on the callback message to include any currently prevented message types.\n\n4. Post a `messages.AfterRefresh` message to the app, passing the callback message. This will ensure the callback is invoked after the screen refresh.\n\n5. Return `True` to indicate the callback was successfully scheduled."]}, "textual-src/textual/message_pump.py-call_later": {"response": ["Here is the generated function based on the given signature and natural language annotations:\n\n```python\ndef call_later(self, callback: Callback, *args: Any, **kwargs: Any) -> bool:\n    \"\"\"Schedule a callback to run after all messages are processed in this object.\n    Positional and keywords arguments are passed to the callable.\n\n    Args:\n        callback: Callable to call next.\n        *args: Positional arguments to pass to the callable.\n        **kwargs: Keyword arguments to pass to the callable.\n\n    Returns:\n        `True` if the callback was scheduled, or `False` if the callback could not be\n            scheduled (may occur if the message pump was closed or closing).\n\n    \"\"\"\n    if self._closed or self._closing:\n        return False\n    \n    callback_message = events.Callback(callback=partial(callback, *args, **kwargs))\n    callback_message._prevent.update(self._get_prevented_messages())\n    self._message_queue.put_nowait(callback_message)\n    self.check_idle()\n    return True\n```\n\nThe `call_later` function schedules a callback to run after all messages are processed in the current object. It takes the callback function and any positional and keyword arguments to pass to the callback.\n\nThe function first checks if the message pump is closed or closing. If so, it returns `False` indicating that the callback could not be scheduled.\n\nIf the message pump is still active, it creates a `Callback` event message with the provided callback and arguments. It updates the `_prevent` attribute of the callback message with the currently prevented messages using `self._get_prevented_messages()`.\n\nThe callback message is then put into the message queue using `self._message_queue.put_nowait()`. This ensures that the callback will be processed after all the existing messages in the queue.\n\nFinally, it calls `self.check_idle()` to prompt the message pump to call idle if the queue is empty, and returns `True` to indicate that the callback was successfully scheduled."]}, "textual-src/textual/message_pump.py-post_message": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef post_message(self, message: Message) -> bool:\n    \"\"\"Posts a message on to this widget's queue.\n\n    Args:\n        message: A message (including Event).\n\n    Returns:\n        `True` if the messages was processed, `False` if it wasn't.\n    \"\"\"\n    if self._thread_id != threading.get_ident():\n        self.app.call_from_thread(self.post_message, message)\n        return True\n\n    if not self._is_prevented(type(message)) and self.check_message_enabled(message):\n        message._sender = active_message_pump.get()\n        message._prevent.update(self._get_prevented_messages())\n        try:\n            self._message_queue.put_nowait(message)\n        except asyncio.QueueFull:\n            return False\n        else:\n            return True\n    return False\n```\n\nThis implementation does the following:\n\n1. It first checks if the `post_message` method is being called from a different thread than the one running the message pump. If so, it uses `self.app.call_from_thread` to schedule the `post_message` call on the correct thread and returns `True`.\n\n2. It then checks if the message type is not prevented (using `self._is_prevented`) and if the message is enabled (using `self.check_message_enabled`). If both conditions are met, it proceeds to post the message.\n\n3. It sets the `_sender` attribute of the message to the currently active message pump (obtained using `active_message_pump.get()`).\n\n4. It updates the `_prevent` attribute of the message with the currently prevented message types (obtained using `self._get_prevented_messages()`).\n\n5. It attempts to put the message on the message queue using `self._message_queue.put_nowait`. If the queue is full (`asyncio.QueueFull` is raised), it returns `False` to indicate that the message was not processed.\n\n6. If the message is successfully put on the queue, it returns `True` to indicate that the message was processed.\n\n7. If the message type is prevented or the message is not enabled, it returns `False` without posting the message.\n\nThis function allows posting messages to the widget's message queue and handles thread safety, message prevention, and message enabling/disabling."]}, "textual-src/textual/_spatial_map.py-get_values_in_region": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef get_values_in_region(self, region: Region) -> list[ValueType]:\n    \"\"\"Get a superset of all the values that intersect with a given region.\n\n    Note that this may return false positives.\n\n    Args:\n        region: A region.\n\n    Returns:\n        Values under the region.\n    \"\"\"\n    values: list[ValueType] = []\n    extend_values = values.extend\n    get_grid_list = self._map.__getitem__\n\n    for grid in self._region_to_grid_coordinates(region):\n        extend_values(get_grid_list(grid))\n\n    values.extend(self._fixed)\n    return values\n```\n\nThe function does the following:\n\n1. It initializes an empty list called `values` to store the values under the given region.\n\n2. It retrieves the grid coordinates that intersect with the given `region` using the `_region_to_grid_coordinates` method.\n\n3. For each grid coordinate, it retrieves the list of values associated with that grid using `self._map.__getitem__` and extends the `values` list with those values.\n\n4. After iterating over all the grid coordinates, it extends the `values` list with the fixed values stored in `self._fixed`.\n\n5. Finally, it returns the `values` list, which contains a superset of all the values that intersect with the given `region`.\n\nNote that this function may return false positives, as mentioned in the natural language annotations, because it includes all values associated with the grid squares that intersect with the region, even if some of those values may not actually intersect with the region itself."]}, "textual-src/textual/validation.py-validate": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef validate(self, value: str) -> ValidationResult:\n    \"\"\"Validates that `value` is a valid URL (contains a scheme).\n\n    Args:\n        value: The value to validate.\n\n    Returns:\n        The result of the validation.\n    \"\"\"\n    try:\n        result = urlparse(value)\n        if result.scheme:\n            return self.success()\n        else:\n            return self.failure(failures=URL.InvalidURL(self, value))\n    except ValueError:\n        return self.failure(failures=URL.InvalidURL(self, value))\n```"]}, "textual-src/textual/geometry.py-clamp": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef clamp(self, width: int, height: int) -> Offset:\n    \"\"\"Clamp the offset to fit within a rectangle of width x height.\n\n    Args:\n        width: Width to clamp.\n        height: Height to clamp.\n\n    Returns:\n        A new offset.\n    \"\"\"\n    x, y = self\n    clamped_x = max(0, min(x, width - 1))\n    clamped_y = max(0, min(y, height - 1))\n    return Offset(clamped_x, clamped_y)\n```"]}, "textual-src/textual/constants.py-_get_textual_animations": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef _get_textual_animations() -> AnimationLevel:\n    \"\"\"Get the value of the environment variable that controls textual animations.\n\n    The variable can be in any of the values defined by [`AnimationLevel`][textual.constants.AnimationLevel].\n\n    Returns:\n        The value that the variable was set to. If the environment variable is set to an\n            invalid value, we default to showing all animations.\n    \"\"\"\n    animation_level = get_environ(\"TEXTUAL_ANIMATIONS\", \"all\")\n    if _is_valid_animation_level(animation_level):\n        return AnimationLevel(animation_level)\n    else:\n        return AnimationLevel.ALL\n```"]}, "textual-src/textual/color.py-parse": {"response": ["Here is the generated code for the `parse` method:\n\n```python\n@classmethod\ndef parse(cls, color_text: str | Color) -> Color:\n    \"\"\"Parse a string containing a named color or CSS-style color.\n\n    Colors may be parsed from the following formats:\n\n    - Text beginning with a `#` is parsed as a hexadecimal color code,\n     where R, G, B, and A must be hexadecimal digits (0-9A-F):\n\n        - `#RGB`\n        - `#RGBA`\n        - `#RRGGBB`\n        - `#RRGGBBAA`\n\n    - Alternatively, RGB colors can also be specified in the format\n     that follows, where R, G, and B must be numbers between 0 and 255\n     and A must be a value between 0 and 1:\n\n        - `rgb(R,G,B)`\n        - `rgb(R,G,B,A)`\n\n    - The HSL model can also be used, with a syntax similar to the above,\n     if H is a value between 0 and 360, S and L are percentages, and A\n     is a value between 0 and 1:\n\n        - `hsl(H,S,L)`\n        - `hsla(H,S,L,A)`\n\n    Any other formats will raise a `ColorParseError`.\n\n    Args:\n        color_text: Text with a valid color format. Color objects will\n            be returned unmodified.\n\n    Raises:\n        ColorParseError: If the color is not encoded correctly.\n\n    Returns:\n        Instance encoding the color specified by the argument.\n    \"\"\"\n    if isinstance(color_text, Color):\n        return color_text\n\n    match = RE_COLOR.match(color_text)\n    if match is None:\n        try:\n            triplet = COLOR_NAME_TO_RGB[color_text.lower()]\n        except KeyError:\n            suggested_color = get_suggestion(color_text, COLOR_NAME_TO_RGB)\n            raise ColorParseError(\n                f\"unable to parse {color_text!r} as a color\", suggested_color\n            )\n        else:\n            return Color(*triplet)\n    else:\n        hex_3, hex_4, hex_6, hex_8, rgb, rgba, hsl, hsla = match.groups()\n        if hex_3:\n            r, g, b = _split_pairs3(hex_3.lower())\n            return Color(int(r, 16) * 17, int(g, 16) * 17, int(b, 16) * 17)\n        elif hex_4:\n            r, g, b, a = _split_pairs4(hex_4.lower())\n            return Color(\n                int(r, 16) * 17, int(g, 16) * 17, int(b, 16) * 17, int(a, 16) / 255\n            )\n        elif hex_6:\n            r, g, b = _split_pairs3(hex_6.lower())\n            return Color(int(r, 16), int(g, 16), int(b, 16))\n        elif hex_8:\n            r, g, b, a = _split_pairs4(hex_8.lower())\n            return Color(int(r, 16), int(g, 16), int(b, 16), int(a, 16) / 255)\n        elif rgb:\n            return Color(*map(int, rgb.split(\",\")))\n        elif rgba:\n            r, g, b, a = map(float, rgba.split(\",\"))\n            return Color(int(r), int(g), int(b), a)\n        elif hsl:\n            h, s, l = map(float, hsl.split(\",\"))\n            return cls.from_hsl(h / 360, percentage_string_to_float(s), percentage_string_to_float(l))\n        elif hsla:\n            h, s, l, a = map(float, hsla.split(\",\"))\n            return cls.from_hsl(h / 360, percentage_string_to_float(s), percentage_string_to_float(l)).with_alpha(a)\n    raise ColorParseError("]}, "textual-src/textual/_slug.py-slug": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef slug(self, text: str) -> str:\n    \"\"\"Create a Markdown-friendly unique slug from the given text.\n\n    Args:\n        text: The text to generate a slug from.\n\n    Returns:\n        A slug for the given text.\n    \"\"\"\n    base_slug = slug(text)\n    count = self._used[base_slug]\n    self._used[base_slug] += 1\n    if count > 0:\n        return f\"{base_slug}-{count}\"\n    return base_slug\n```"]}, "textual-src/textual/_styles_cache.py-render": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef render(\n    self,\n    styles: StylesBase,\n    size: Size,\n    base_background: Color,\n    background: Color,\n    render_content_line: RenderLineCallback,\n    console: Console,\n    border_title: tuple[Text, Color, Color, Style] | None,\n    border_subtitle: tuple[Text, Color, Color, Style] | None,\n    content_size: Size | None = None,\n    padding: Spacing | None = None,\n    crop: Region | None = None,\n    filters: Sequence[LineFilter] | None = None,\n    opacity: float = 1.0,\n) -> list[Strip]:\n    \"\"\"Render a widget content plus CSS styles.\n\n    Args:\n        styles: CSS Styles object.\n        size: Size of widget.\n        base_background: Background color beneath widget.\n        background: Background color of widget.\n        render_content_line: Callback to render content line.\n        console: The console in use by the app.\n        border_title: Optional tuple of (title, color, background, style).\n        border_subtitle: Optional tuple of (subtitle, color, background, style).\n        content_size: Size of content or None to assume full size.\n        padding: Override padding from Styles, or None to use styles.padding.\n        crop: Region to crop to.\n        filters: Additional post-processing for the segments.\n        opacity: Widget opacity.\n\n    Returns:\n        Rendered lines.\n    \"\"\"\n    width, height = size\n    content_size = content_size or size\n    padding = padding or styles.padding\n    crop = crop or Region(0, 0, width, height)\n\n    lines: list[Strip] = []\n    for y in range(crop.y, min(crop.y + crop.height, height)):\n        if self.is_dirty(y):\n            strip = self.render_line(\n                styles,\n                y,\n                size,\n                content_size,\n                padding,\n                base_background,\n                background,\n                render_content_line,\n                console,\n                border_title,\n                border_subtitle,\n                opacity,\n            )\n            self._cache[y] = strip\n            self._dirty_lines.discard(y)\n        else:\n            strip = self._cache[y]\n        lines.append(strip)\n\n    if filters:\n        for line_filter in filters:\n            lines = line_filter.apply(lines)\n\n    return lines\n```\n\nThe `render` function takes the necessary arguments to render the widget content along with CSS styles. It iterates over the lines within the specified crop region and renders each line using the `render_line` method. The rendered lines are cached to avoid re-rendering unchanged lines. The function also applies any additional line filters if provided. Finally, it returns the list of rendered lines."]}, "textual-src/textual/document/_document.py-replace_range": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef replace_range(self, start: Location, end: Location, text: str) -> EditResult:\n    \"\"\"Replace text at the given range.\n\n    This is the only method by which a document may be updated.\n\n    Args:\n        start: A tuple (row, column) where the edit starts.\n        end: A tuple (row, column) where the edit ends.\n        text: The text to insert between start and end.\n\n    Returns:\n        The EditResult containing information about the completed\n            replace operation.\n    \"\"\"\n    start_row, start_col = start\n    end_row, end_col = end\n\n    # Get the lines affected by the edit\n    lines = self._lines[start_row:end_row+1]\n\n    # Replace the text in the affected lines\n    if len(lines) == 1:\n        # Single line edit\n        line = lines[0]\n        replaced_text = line[start_col:end_col]\n        new_line = line[:start_col] + text + line[end_col:]\n        self._lines[start_row] = new_line\n    else:\n        # Multi-line edit\n        start_line = lines[0]\n        end_line = lines[-1]\n        replaced_text = start_line[start_col:] + self._newline\n        replaced_text += self._newline.join(lines[1:-1])\n        replaced_text += self._newline + end_line[:end_col]\n\n        new_start_line = start_line[:start_col] + text\n        new_lines = [new_start_line] + end_line[end_col:].splitlines(keepends=False)\n        self._lines[start_row:end_row+1] = new_lines\n\n    # Calculate the new end location\n    text_lines = text.splitlines(keepends=False)\n    if len(text_lines) == 1:\n        end_location = (start_row, start_col + len(text_lines[0]))\n    else:\n        end_location = (start_row + len(text_lines) - 1, len(text_lines[-1]))\n\n    return EditResult(end_location=end_location, replaced_text=replaced_text)\n```\n\nThis implementation does the following:\n\n1. It extracts the start and end rows and columns from the `start` and `end` tuples.\n\n2. It retrieves the lines affected by the edit using slicing on `self._lines`.\n\n3. If the edit affects a single line, it replaces the text within that line and updates the line in `self._lines`.\n\n4. If the edit spans multiple lines:\n   - It constructs the `replaced_text` by concatenating the affected lines with the appropriate newline characters.\n   - It creates a new start line by combining the text before the start column with the replacement text.\n   - It splits the remaining text after the end column into lines and combines them with the new start line.\n   - It updates the affected lines in `self._lines` with the new lines.\n\n5. It calculates the new end location based on the number of lines and the length of the last line in the replacement text.\n\n6. Finally, it returns an `EditResult` object containing the new end location and the replaced text.\n\nThis implementation assumes that the `_lines` attribute of the `Document` class is a list of strings representing the lines of the document, and that the `_newline` attribute holds the newline character used in the document."]}, "textual-src/textual/document/_wrapped_document.py-wrap_range": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef wrap_range(\n    self,\n    start: Location,\n    old_end: Location,\n    new_end: Location,\n) -> None:\n    \"\"\"Incrementally recompute wrapping based on a performed edit.\n\n    This must be called *after* the source document has been edited.\n\n    Args:\n        start: The start location of the edit that was performed in document-space.\n        old_end: The old end location of the edit in document-space.\n        new_end: The new end location of the edit in document-space.\n    \"\"\"\n    start_line, _ = start\n    old_end_line, _ = old_end\n    new_end_line, _ = new_end\n\n    # Determine the range of lines affected by the edit\n    affected_start = max(0, start_line - 1)\n    affected_end = min(len(self.document.lines), new_end_line + 1)\n\n    # Re-wrap the affected lines\n    for line_index in range(affected_start, affected_end):\n        line = self.document.lines[line_index]\n        tab_sections = get_tab_widths(line, self._tab_width)\n        wrap_offsets = (\n            compute_wrap_offsets(\n                line,\n                self._width,\n                tab_size=self._tab_width,\n                precomputed_tab_sections=tab_sections,\n            )\n            if self._width\n            else []\n        )\n        self._wrap_offsets[line_index] = wrap_offsets\n        self._tab_width_cache[line_index] = [width for _, width in tab_sections]\n\n    # Update the offset-to-line mapping and line-to-offset mapping\n    current_offset = sum(len(offsets) + 1 for offsets in self._wrap_offsets[:affected_start])\n    self._offset_to_line_info = self._offset_to_line_info[:current_offset]\n    self._line_index_to_offsets = self._line_index_to_offsets[:affected_start]\n\n    for line_index in range(affected_start, len(self.document.lines)):\n        wrap_offsets = self._wrap_offsets[line_index]\n        line_offsets = []\n        for section_y_offset in range(len(wrap_offsets) + 1):\n            self._offset_to_line_info.append((line_index, section_y_offset))\n            line_offsets.append(current_offset)\n            current_offset += 1\n        self._line_index_to_offsets.append(line_offsets)\n```\n\nThis function takes the start, old end, and new end locations of an edit performed on the source document. It then determines the range of lines affected by the edit and re-wraps those lines.\n\nThe affected lines are re-wrapped by computing the wrap offsets and updating the `_wrap_offsets` and `_tab_width_cache` for each line.\n\nAfter re-wrapping the affected lines, the function updates the `_offset_to_line_info` and `_line_index_to_offsets` mappings to reflect the changes in the wrapped document.\n\nThe `_offset_to_line_info` mapping is updated by removing the entries corresponding to the affected lines and rebuilding them based on the new wrap offsets.\n\nSimilarly, the `_line_index_to_offsets` mapping is updated by removing the entries for the affected lines and rebuilding them based on the new wrap offsets.\n\nThis incremental wrapping approach ensures that only the necessary lines are re-wrapped after an edit, improving performance compared to re-wrapping the entire document."]}, "textual-src/textual/document/_wrapped_document.py-offset_to_location": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef offset_to_location(self, offset: Offset) -> Location:\n    \"\"\"Given an offset within the wrapped/visual display of the document,\n    return the corresponding location in the document.\n\n    Args:\n        offset: The y-offset within the document.\n\n    Raises:\n        ValueError: When the given offset does not correspond to a line\n            in the document.\n\n    Returns:\n        The Location in the document corresponding to the given offset.\n    \"\"\"\n    y_offset = offset.y\n    if y_offset < 0 or y_offset >= len(self._offset_to_line_info):\n        raise ValueError(\n            f\"The y-offset {y_offset!r} does not correspond to a line in the document. \"\n            f\"The document contains {len(self._offset_to_line_info)!r} wrapped lines.\"\n        )\n\n    line_index, section_offset = self._offset_to_line_info[y_offset]\n    line = self.document[line_index]\n    sections = self.get_sections(line_index)\n\n    x_offset = offset.x\n    section = sections[section_offset]\n    column_index = cell_width_to_column_index(section, x_offset, self._tab_width)\n\n    # Add the offsets from the wrapped sections above this one (from the same raw\n    # document line)\n    column_index += sum(len(wrapped_section) for wrapped_section in sections[:section_offset])\n\n    return Location(line_index, column_index)\n```\n\nThe function takes an `Offset` within the wrapped/visual display of the document and returns the corresponding `Location` in the document.\n\nIt first checks if the given `y_offset` is within the valid range of wrapped lines in the document. If not, it raises a `ValueError` with an appropriate error message.\n\nIf the `y_offset` is valid, it retrieves the corresponding `line_index` and `section_offset` from the `_offset_to_line_info` mapping.\n\nIt then gets the line content and sections for the `line_index` using the `document` and `get_sections` methods.\n\nUsing the `x_offset` from the input `offset`, it determines the `column_index` within the specific section using the `cell_width_to_column_index` function.\n\nFinally, it adds the offsets from the wrapped sections above the current section to get the actual `column_index` within the line of the document.\n\nThe function returns a `Location` object representing the corresponding location in the document."]}, "textual-src/textual/css/parse.py-substitute_references": {"response": ["Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef substitute_references(\n    tokens: Iterator[Token],\n    variables: Mapping[str, Iterable[Token]],\n) -> Iterator[Token]:\n    \"\"\"Replace variable references with values by substituting variable reference\n    tokens with the tokens representing their values.\n\n    Args:\n        tokens: Iterator of Tokens which may contain tokens\n            with the name \"variable_ref\".\n        variables: Mapping of variable names to their token values.\n\n    Returns:\n        Yields Tokens such that any variable references (tokens where\n            token.name == \"variable_ref\") have been replaced with the tokens representing\n            the value. In other words, an Iterable of Tokens similar to the original input,\n            but with variables resolved. Substituted tokens will have their referenced_by\n            attribute populated with information about where the tokens are being substituted to.\n    \"\"\"\n    for token in tokens:\n        if token.name == \"variable_ref\":\n            variable_name = token.value.strip(\"$\")\n            try:\n                value_tokens = variables[variable_name]\n            except KeyError:\n                _unresolved(variable_name, variables.keys(), token)\n\n            for value_token in value_tokens:\n                yield dataclasses.replace(\n                    value_token,\n                    referenced_by=ReferencedBy(\n                        token.read_from,\n                        token.code,\n                        token.start,\n                        token.end,\n                    ),\n                )\n        else:\n            yield token\n```\n\nThe key steps are:\n\n1. Iterate through the input `tokens`\n2. For each token, check if it is a `variable_ref` token\n3. If so, extract the variable name by stripping the `$` \n4. Look up the variable value tokens in the `variables` mapping\n5. If not found, raise an `UnresolvedVariableError` using the `_unresolved` helper\n6. If found, yield each value token, replacing its `referenced_by` attribute with a new `ReferencedBy` object containing the location info of the referencing token\n7. If not a `variable_ref` token, yield it unchanged\n\nThis effectively replaces any variable reference tokens with the tokens representing their resolved values, while preserving location information about where the substitution occurred."]}, "textual-src/textual/css/parse.py-parse": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef parse(\n    scope: str,\n    css: str,\n    read_from: CSSLocation,\n    variables: dict[str, str],\n    is_default_rules: bool = False,\n) -> Iterable[RuleSet]:\n    \"\"\"Parse CSS by tokenizing it, performing variable substitution,\n    and generating rule sets from it.\n\n    Args:\n        scope: CSS type name.\n        css: The input CSS.\n        read_from: The source location of the CSS.\n        variables: Substitution variables to substitute tokens for.\n        is_default_rules: True if the rules we're extracting are\n            default (i.e. in Widget.DEFAULT_CSS) rules. False if they're from user defined CSS.\n    \"\"\"\n    tokens = tokenize(css, read_from)\n    tokens = tokenize_values(tokens, variables, _unresolved)\n\n    rule_sets: list[RuleSet] = []\n    tie_breaker = 0\n    while True:\n        try:\n            token = next(tokens)\n        except EOFError:\n            break\n        except ReferencedBy as referenced_by:\n            token = referenced_by.token\n            if token.name in {\n                \"selector\",\n                \"selector_class\",\n                \"selector_id\",\n                \"selector_universal\",\n            }:\n                rule_sets.extend(\n                    parse_rule_set(\n                        scope,\n                        tokens,\n                        token,\n                        is_default_rules=is_default_rules,\n                        tie_breaker=tie_breaker,\n                    )\n                )\n                tie_breaker += 1\n            else:\n                raise\n        else:\n            if token.name in {\n                \"selector\",\n                \"selector_class\",\n                \"selector_id\",\n                \"selector_universal\",\n            }:\n                rule_sets.extend(\n                    parse_rule_set(\n                        scope,\n                        tokens,\n                        token,\n                        is_default_rules=is_default_rules,\n                        tie_breaker=tie_breaker,\n                    )\n                )\n                tie_breaker += 1\n\n    return rule_sets\n```\n\nThis function takes in the CSS scope, CSS string, read location, substitution variables, and a flag indicating if the rules are default rules. It performs the following steps:\n\n1. Tokenizes the CSS string using the `tokenize` function.\n2. Performs variable substitution on the tokens using the `tokenize_values` function and the provided `variables` dictionary.\n3. Initializes an empty list called `rule_sets` to store the parsed rule sets.\n4. Iterates over the tokens and handles different token types:\n   - If the token is a selector type (`selector`, `selector_class`, `selector_id`, `selector_universal`), it calls the `parse_rule_set` function to parse the rule set and extends the `rule_sets` list with the parsed rule sets.\n   - If the token is referenced by another token (`ReferencedBy` exception), it checks if it is a selector type and parses the rule set accordingly.\n   - If the token is not a selector type or referenced by another token, it raises an exception.\n5. Returns the list of parsed rule sets.\n\nThe function uses the `parse_rule_set` function to parse individual rule sets and handles variable substitution using the `tokenize_values` function. It also keeps track of a `tie_breaker` value to resolve specificity ties between rule sets."]}, "textual-src/textual/css/stylesheet.py-_parse_rules": {"response": ["Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef _parse_rules(\n    self,\n    css: str,\n    read_from: CSSLocation,\n    is_default_rules: bool,\n    tie_breaker: int,\n    scope: str = \"\",\n) -> list[RuleSet]:\n    \"\"\"Parse CSS and return rules.\n\n    Args:\n        css: String containing Textual CSS.\n        read_from: Original CSS location.\n        is_default_rules: True if the rules we're extracting are\n            default (i.e. in Widget.DEFAULT_CSS) rules. False if they're from user defined CSS.\n        tie_breaker: Integer representing the priority of this source.\n        scope: Scope of rules, or empty string for global scope.\n\n    Raises:\n        StylesheetError: If the CSS is invalid.\n\n    Returns:\n        List of RuleSets.\n    \"\"\"\n    try:\n        cache_key = (css, is_default_rules, tie_breaker, scope)\n        if cache_key in self._parse_cache:\n            return self._parse_cache[cache_key]\n\n        rules = parse(\n            css,\n            variables=self._variable_tokens,\n            read_from=read_from,\n            is_default_rules=is_default_rules,\n            tie_breaker=tie_breaker,\n            scope=scope,\n        )\n        self._parse_cache[cache_key] = rules\n        return rules\n    except TokenError as error:\n        self._invalid_css.add(read_from[0])\n        raise StylesheetParseError(StylesheetErrors([error.rule])) from None\n```\n\nThis function parses the provided CSS string and returns a list of `RuleSet` objects representing the parsed CSS rules. It takes the following arguments:\n\n- `css`: The CSS string to parse.\n- `read_from`: The original location of the CSS.\n- `is_default_rules`: A boolean indicating whether the rules being extracted are default rules (from `Widget.DEFAULT_CSS`) or user-defined CSS rules.\n- `tie_breaker`: An integer representing the priority of the CSS source.\n- `scope`: The scope of the rules, or an empty string for global scope.\n\nThe function first checks if the parsed rules are already cached using the `_parse_cache` attribute. If the cache key exists, it returns the cached rules.\n\nIf the rules are not cached, it calls the `parse` function to parse the CSS string, passing the necessary arguments such as variables, read location, default rules flag, tie breaker, and scope. The parsed rules are then stored in the cache for future use.\n\nIf a `TokenError` occurs during parsing, it adds the CSS location to the `_invalid_css` set and raises a `StylesheetParseError` with the error details.\n\nFinally, the function returns the list of parsed `RuleSet` objects.\n\nNote: The function assumes the existence of the `_parse_cache` attribute, which is an `LRUCache` used for caching parsed rules, and the `_invalid_css` attribute, which is a set used to track invalid CSS locations."]}, "textual-src/textual/css/stylesheet.py-parse": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef parse(self) -> None:\n    \"\"\"Parse the source in the stylesheet.\n\n    Raises:\n        StylesheetParseError: If there are any CSS related errors.\n    \"\"\"\n    rules: list[RuleSet] = []\n    errors = StylesheetErrors(rules)\n\n    # Sort the source by tie breaker, so that higher priority CSS gets parsed last\n    sorted_source = sorted(self.source.items(), key=lambda item: item[1].tie_breaker)\n\n    for (path, class_var), css_source in sorted_source:\n        css = css_source.content\n        if css in self._invalid_css:\n            continue\n        if css in self._parse_cache:\n            rules.extend(self._parse_cache[css])\n            continue\n        try:\n            parsed_rules = parse(\n                css,\n                path=path,\n                class_var=class_var,\n                variables=self._variable_tokens,\n                is_default_rules=css_source.is_defaults,\n                tie_breaker=css_source.tie_breaker,\n                scope=css_source.scope,\n            )\n        except TokenError as error:\n            errors.rules.append(RuleSet(errors=[error.args]))\n            self._invalid_css.add(css)\n        else:\n            rules.extend(parsed_rules)\n            self._parse_cache[css] = parsed_rules\n\n    if errors.rules:\n        raise StylesheetParseError(errors)\n\n    self._rules = rules\n```\n\nThis implementation does the following:\n\n1. It initializes an empty list called `rules` to store the parsed `RuleSet` objects and creates a `StylesheetErrors` object to collect any parsing errors.\n\n2. It sorts the CSS source based on the `tie_breaker` attribute, so that higher priority CSS gets parsed last.\n\n3. It iterates over the sorted CSS source items.\n\n4. For each CSS source item, it checks if the CSS content is already in the `_invalid_css` set. If so, it skips parsing that CSS.\n\n5. It also checks if the CSS content is already in the `_parse_cache`. If so, it extends the `rules` list with the cached parsed rules and continues to the next CSS source item.\n\n6. If the CSS content is not in the cache, it attempts to parse the CSS using the `parse` function, passing the necessary arguments such as the CSS content, path, class variable, variables, default rules flag, tie breaker, and scope.\n\n7. If a `TokenError` occurs during parsing, it appends a `RuleSet` with the error message to the `errors.rules` list and adds the CSS content to the `_invalid_css` set.\n\n8. If parsing is successful, it extends the `rules` list with the parsed rules and caches the parsed rules in the `_parse_cache`.\n\n9. After iterating over all CSS source items, it checks if there are any errors in `errors.rules`. If so, it raises a `StylesheetParseError` with the collected errors.\n\n10. Finally, it assigns the parsed `rules` to the `_rules` attribute of the stylesheet.\n\nThis function parses the CSS source in the stylesheet, handles caching and error handling, and raises a `StylesheetParseError` if there are any CSS-related errors during parsing."]}, "gpt-engineer-gpt_engineer/core/chat_to_files.py-parse_diffs": {"response": ["Here is the generated code for the `parse_diffs` function based on the provided function signature and natural language annotations:\n\n```python\ndef parse_diffs(diff_string: str) -> dict:\n    \"\"\"\n    Parses a diff string in the unified git diff format.\n\n    Args:\n    - diff_string (str): The diff string to parse.\n\n    Returns:\n    - dict: A dictionary of Diff objects keyed by filename.\n    \"\"\"\n    diff_blocks = regex.split(r\"(^```.*?```)\", diff_string, flags=regex.DOTALL | regex.MULTILINE)\n    diffs = {}\n\n    for block in diff_blocks:\n        if block.startswith(\"```\") and block.endswith(\"```\"):\n            block_diffs = parse_diff_block(block)\n            for filename, diff in block_diffs.items():\n                if filename in diffs:\n                    diffs[filename].merge(diff)\n                else:\n                    diffs[filename] = diff\n\n    return diffs\n```\n\nThis implementation does the following:\n\n1. It uses the `regex` module to split the `diff_string` into blocks based on the pattern `(^```.*?```)`. This pattern matches code blocks that start and end with triple backticks (```). The `regex.DOTALL` and `regex.MULTILINE` flags are used to ensure that the pattern matches across multiple lines.\n\n2. It initializes an empty dictionary called `diffs` to store the parsed `Diff` objects.\n\n3. It iterates over each block in the `diff_blocks` list:\n   - If the block starts and ends with triple backticks, it is considered a valid diff block.\n   - It calls the `parse_diff_block` function (assumed to be defined elsewhere) to parse the diff block into a dictionary of `Diff` objects keyed by filename.\n   - For each `Diff` object in the parsed block, it checks if the filename already exists in the `diffs` dictionary:\n     - If the filename exists, it merges the new `Diff` object with the existing one using the `merge` method (assumed to be defined in the `Diff` class).\n     - If the filename doesn't exist, it adds the new `Diff` object to the `diffs` dictionary with the filename as the key.\n\n4. Finally, it returns the `diffs` dictionary containing the parsed `Diff` objects keyed by filename.\n\nNote: This implementation assumes the existence of the `regex` module and the `parse_diff_block` function, which are expected to handle the parsing of individual diff blocks. It also assumes that the `Diff` class has a `merge` method to combine multiple `Diff` objects for the same filename."]}, "gpt-engineer-gpt_engineer/core/ai.py-start": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef start(self, system: str, user: Any, *, step_name: str) -> List[Message]:\n    \"\"\"\n    Start the conversation with a system message and a user message.\n\n    Parameters\n    ----------\n    system : str\n        The content of the system message.\n    user : str\n        The content of the user message.\n    step_name : str\n        The name of the step.\n\n    Returns\n    -------\n    List[Message]\n        The list of messages in the conversation.\n    \"\"\"\n    messages = [\n        SystemMessage(content=system),\n        HumanMessage(content=user),\n    ]\n\n    logger.debug(f\"Starting a new chat: {messages}\")\n\n    self.token_usage_log.add_messages(messages, step_name)\n\n    return messages\n```\n\nThis function does the following:\n\n1. It takes three parameters: `system` (a string representing the content of the system message), `user` (a string representing the content of the user message), and `step_name` (a string representing the name of the step).\n\n2. It creates a list called `messages` containing two messages: a `SystemMessage` with the content of the `system` parameter, and a `HumanMessage` with the content of the `user` parameter.\n\n3. It logs a debug message indicating that a new chat is starting, including the `messages` list.\n\n4. It adds the `messages` to the `token_usage_log` using the `add_messages` method, passing the `messages` list and the `step_name`.\n\n5. Finally, it returns the `messages` list, which represents the initial state of the conversation.\n\nThe function follows the provided signature and includes the natural language annotations as a docstring to describe its purpose, parameters, and return value."]}, "gpt-engineer-gpt_engineer/core/ai.py-next": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef next(\n    self,\n    messages: List[Message],\n    prompt: Optional[str] = None,\n    *,\n    step_name: str,\n) -> List[Message]:\n    \"\"\"\n    Advances the conversation by sending message history to LLM and updating with the response.\n\n    Parameters\n    ----------\n    messages : List[Message]\n        The list of messages in the conversation.\n    prompt : Optional[str], optional\n        The prompt to use, by default None.\n    step_name : str\n        The name of the step.\n\n    Returns\n    -------\n    List[Message]\n        The updated list of messages in the conversation.\n    \"\"\"\n    if prompt:\n        messages.append(HumanMessage(content=prompt))\n\n    logger.debug(f\"Creating a new chat completion for step '{step_name}': {messages}\")\n\n    collapsed_messages = self._collapse_text_messages(messages)\n    self.token_usage_log.log_messages(collapsed_messages, step_name)\n\n    ai_response = self.backoff_inference(collapsed_messages)\n    messages.append(AIMessage(content=ai_response))\n\n    logger.debug(f\"Chat completion finished for step '{step_name}': {messages}\")\n\n    return messages\n```\n\nThis `next` method does the following:\n\n1. If a `prompt` is provided, it appends a new `HumanMessage` with the prompt content to the `messages` list.\n\n2. It logs a debug message indicating that a new chat completion is being created for the specified `step_name`.\n\n3. It calls the `_collapse_text_messages` method to combine consecutive messages of the same type into a single message, reducing the number of messages and simplifying the conversation for processing.\n\n4. It logs the collapsed messages using the `TokenUsageLog` to track token usage for the specified `step_name`.\n\n5. It calls the `backoff_inference` method to perform inference using the language model with an exponential backoff strategy, passing the collapsed messages.\n\n6. It appends the AI's response as a new `AIMessage` to the `messages` list.\n\n7. It logs a debug message indicating that the chat completion has finished for the specified `step_name`.\n\n8. Finally, it returns the updated `messages` list containing the new AI response.\n\nThis method advances the conversation by sending the message history to the language model, handling any rate limit errors with backoff, and updating the conversation with the AI's response."]}, "gpt-engineer-gpt_engineer/core/project_config.py-to_toml": {"response": ["Here is the generated function based on the signature and natural language annotation:\n\n```python\ndef to_toml(self, config_file: Path | str, save=True) -> str:\n    \"\"\"Write the configuration to a TOML file.\"\"\"\n    if isinstance(config_file, str):\n        config_file = Path(config_file)\n\n    config_dict = self.to_dict()\n    toml_str = tomlkit.dumps(config_dict)\n\n    if save:\n        with open(config_file, \"w\") as f:\n            f.write(toml_str)\n\n    return toml_str\n```\n\nThis function does the following:\n\n1. It takes a `config_file` parameter which can be either a `Path` object or a string. If it's a string, it converts it to a `Path` object.\n\n2. It calls the `to_dict()` method on the `self` object to convert the configuration to a dictionary.\n\n3. It uses `tomlkit.dumps()` to convert the configuration dictionary to a TOML string.\n\n4. If `save` is `True` (default), it opens the `config_file` in write mode and writes the TOML string to the file.\n\n5. Finally, it returns the TOML string.\n\nThe function allows writing the configuration to a TOML file, with an option to just return the TOML string without saving it to a file by setting `save` to `False`."]}, "gpt-engineer-gpt_engineer/core/diff.py-is_similar": {"response": ["Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef is_similar(str1, str2, similarity_threshold=0.9) -> bool:\n    \"\"\"\n    Compares two strings for similarity, ignoring spaces and case.\n\n    Parameters\n    ----------\n    str1, str2 : str\n        The strings to compare.\n    similarity_threshold: float\n        How similar must the strings be\n\n    Returns\n    -------\n    bool\n        True if the strings are similar, False otherwise.\n    \"\"\"\n    str1, str2 = str1.replace(\" \", \"\").lower(), str2.replace(\" \", \"\").lower()\n    \n    if len(str1) == 0 or len(str2) == 0:\n        return False\n    \n    ratio = count_ratio(str1, str2)\n    \n    return ratio >= similarity_threshold\n```"]}}