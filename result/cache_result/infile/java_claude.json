{"langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoader.java-loadDocuments": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static List<Document> loadDocuments(Path directoryPath, DocumentParser documentParser) {\n    if (!isDirectory(directoryPath)) {\n        throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n    }\n\n    List<Document> documents = new ArrayList<>();\n\n    try (Stream<Path> pathStream = Files.list(directoryPath)) {\n        pathStream\n                .filter(Files::isRegularFile)\n                .forEach(file -> {\n                    try {\n                        Document document = loadDocument(file, documentParser);\n                        documents.add(document);\n                    } catch (BlankDocumentException ignored) {\n                        // blank/empty documents are ignored\n                    } catch (Exception e) {\n                        String message = e.getCause() != null ? e.getCause().getMessage() : e.getMessage();\n                        log.warn(\"Failed to load '{}': {}\", file, message);\n                    }\n                });\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n    return documents;\n}\n```\n\nThis function does the following:\n\n1. It checks if the provided `directoryPath` is a directory using the `isDirectory` method. If it's not a directory, it throws an `IllegalArgumentException` with a descriptive message.\n\n2. It creates an empty `List<Document>` called `documents` to store the loaded documents.\n\n3. It opens a `Stream<Path>` using `Files.list(directoryPath)` to get a stream of paths in the specified directory. The stream is wrapped in a try-with-resources block to ensure proper resource handling.\n\n4. It filters the stream to include only regular files using `Files::isRegularFile`.\n\n5. For each file in the filtered stream, it attempts to load the document using the `loadDocument` method with the file path and the provided `documentParser`. If the document is successfully loaded, it is added to the `documents` list.\n\n6. If a `BlankDocumentException` occurs during document loading, it is ignored, and the blank/empty document is skipped.\n\n7. If any other exception occurs during document loading, the exception message is logged using `log.warn`, and the loading of that particular document is skipped.\n\n8. If an `IOException` occurs while opening the stream of paths, it is caught and wrapped in a `RuntimeException`.\n\n9. Finally, the function returns the list of loaded documents.\n\nThis function loads documents from the specified directory using the provided document parser, skipping any documents that fail to load, and returns the list of successfully loaded documents.", "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoader.java-loadDocumentsRecursively": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static List<Document> loadDocumentsRecursively(Path directoryPath, DocumentParser documentParser) {\n    if (!isDirectory(directoryPath)) {\n        throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n    }\n\n    List<Document> documents = new ArrayList<>();\n\n    try (Stream<Path> pathStream = Files.walk(directoryPath)) {\n        pathStream\n                .filter(Files::isRegularFile)\n                .forEach(file -> {\n                    try {\n                        Document document = loadDocument(file, documentParser);\n                        documents.add(document);\n                    } catch (BlankDocumentException ignored) {\n                        // blank/empty documents are ignored\n                    } catch (Exception e) {\n                        String message = e.getCause() != null ? e.getCause().getMessage() : e.getMessage();\n                        log.warn(\"Failed to load '{}': {}\", file, message);\n                    }\n                });\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n    return documents;\n}\n```\n\nThis function does the following:\n\n1. It checks if the provided `directoryPath` is actually a directory. If not, it throws an `IllegalArgumentException` with an appropriate message.\n\n2. It creates an empty list called `documents` to store the loaded `Document` objects.\n\n3. It uses `Files.walk()` to recursively traverse the directory tree starting from `directoryPath`. The resulting `Stream<Path>` is wrapped in a try-with-resources block to ensure proper resource handling.\n\n4. It filters the `pathStream` to include only regular files using `Files::isRegularFile`.\n\n5. For each file, it attempts to load a `Document` using the `loadDocument()` method with the provided `documentParser`. If successful, the loaded `Document` is added to the `documents` list.\n\n6. If a `BlankDocumentException` is thrown during document loading, it is ignored, and the blank/empty document is skipped.\n\n7. If any other exception occurs during document loading, it logs a warning message with the file path and the exception message.\n\n8. If an `IOException` occurs during directory traversal, it is wrapped in a `RuntimeException` and rethrown.\n\n9. Finally, it returns the list of loaded `Document` objects.\n\nThis function recursively loads documents from the specified directory and its subdirectories, skipping any documents that fail to load and logging a warning message for each failure.", "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java-hasSpaceFor": "Here is the generated code for the `hasSpaceFor(String text)` method:\n\n```java\n/**\n * Returns {@code true} if the provided text can be added to the current segment.\n * @param text The text to check.\n * @return {@code true} if the provided text can be added to the current segment.\n */\npublic boolean hasSpaceFor(String text) {\n    int textSize = sizeOf(text);\n    return hasSpaceFor(textSize);\n}\n```", "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java-append": "Here is the generated code for the `append` method:\n\n```java\n/**\n * Appends the provided text to the current segment.\n * @param text The text to append.\n */\npublic void append(String text) {\n    if (isNotEmpty()) {\n        segment += joinSeparator;\n        segmentSize += joinSeparatorSize;\n    }\n    segment += text;\n    segmentSize += sizeOf(text);\n}\n```", "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java-prepend": "Here is the generated code for the `prepend` method:\n\n```java\n/**\n * Prepends the provided text to the current segment.\n * @param text The text to prepend.\n */\npublic void prepend(String text) {\n    int size = sizeOf(text);\n    if (hasSpaceFor(size)) {\n        if (isNotEmpty()) {\n            segment = text + joinSeparator + segment;\n            segmentSize += size + joinSeparatorSize;\n        } else {\n            segment = text;\n            segmentSize = size;\n        }\n    } else {\n        throw new IllegalArgumentException(\"Cannot prepend text: segment size limit exceeded\");\n    }\n}\n```\n\nThe `prepend` method does the following:\n\n1. It calculates the size of the provided `text` using the `sizeOf` method.\n\n2. It checks if there is enough space in the current segment to accommodate the `text` using the `hasSpaceFor` method.\n\n3. If there is enough space:\n   - If the current segment is not empty, it prepends the `text` to the current segment with the `joinSeparator` in between, and updates the `segmentSize` by adding the size of the `text` and the size of the `joinSeparator`.\n   - If the current segment is empty, it sets the current segment to the `text` and updates the `segmentSize` to the size of the `text`.\n\n4. If there is not enough space, it throws an `IllegalArgumentException` indicating that the segment size limit has been exceeded.\n\nThis method allows prepending text to the current segment while ensuring that the segment size does not exceed the maximum allowed size.", "langchain4j-langchain4j/src/main/java/dev/langchain4j/service/AiServices.java-retriever": "Here is the generated code for the deprecated `retriever` method:\n\n```java\n/**\n * Deprecated. Use {@link #contentRetriever(ContentRetriever)}\n * (e.g. {@link EmbeddingStoreContentRetriever}) instead.\n * <br>\n * Configures a retriever that will be invoked on every method call to fetch relevant information\n * related to the current user message from an underlying source (e.g., embedding store).\n * This relevant information is automatically injected into the message sent to the LLM.\n *\n * @param retriever The retriever to be used by the AI Service.\n * @return builder\n */\n@Deprecated\npublic AiServices<T> retriever(Retriever<TextSegment> retriever) {\n    if (contentRetrieverSet || retrievalAugmentorSet) {\n        throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n    }\n    retrieverSet = true;\n    context.retrievalAugmentor = new DefaultRetrievalAugmentor(new RetrieverBasedContentRetriever(retriever));\n    return this;\n}\n```", "langchain4j-langchain4j/src/main/java/dev/langchain4j/service/AiServices.java-contentRetriever": "Here is the generated code for the `contentRetriever` method based on the provided function signature and natural language annotations:\n\n```java\npublic AiServices<T> contentRetriever(ContentRetriever contentRetriever) {\n    if (retrieverSet || retrievalAugmentorSet) {\n        throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n    }\n    contentRetrieverSet = true;\n    context.retrievalAugmentor = new DefaultRetrievalAugmentor(ensureNotNull(contentRetriever, \"contentRetriever\"));\n    return this;\n}\n```", "langchain4j-langchain4j-pgvector/src/main/java/dev/langchain4j/store/embedding/pgvector/PgVectorEmbeddingStore.java-add": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\n@Override\npublic String add(Embedding embedding) {\n    String id = randomUUID();\n    addInternal(id, embedding, null);\n    return id;\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java-toolSpecificationsFrom": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static List<ToolSpecification> toolSpecificationsFrom(Class<?> classWithTools) {\n    return stream(classWithTools.getMethods())\n            .filter(method -> method.isAnnotationPresent(Tool.class))\n            .map(ToolSpecifications::toolSpecificationFrom)\n            .collect(toList());\n}\n```\n\nExplanation:\n1. The method takes a `Class` object `classWithTools` as a parameter.\n2. It uses `stream()` to create a stream of all the methods in the class using `classWithTools.getMethods()`.\n3. It filters the stream to include only the methods annotated with the `@Tool` annotation using `filter(method -> method.isAnnotationPresent(Tool.class))`.\n4. It maps each filtered method to a `ToolSpecification` object using `map(ToolSpecifications::toolSpecificationFrom)`, assuming there is a helper method `toolSpecificationFrom` that takes a `Method` object and returns a `ToolSpecification`.\n5. Finally, it collects the stream of `ToolSpecification` objects into a list using `collect(toList())` and returns the list.\n\nThis implementation assumes the existence of the `Tool` annotation and the `toolSpecificationFrom` helper method within the `ToolSpecifications` class.", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java-toolSpecificationFrom": "Here is the generated code for the `toolSpecificationFrom` method based on the function signature and natural language annotations:\n\n```java\npublic static ToolSpecification toolSpecificationFrom(Method method) {\n    Tool annotation = method.getAnnotation(Tool.class);\n    if (annotation == null) {\n        throw new IllegalArgumentException(format(\"Method '%s' is not annotated with @Tool\", method.getName()));\n    }\n\n    String name = isNullOrBlank(annotation.name()) ? method.getName() : annotation.name();\n    String description = annotation.description();\n    String returnValueDescription = annotation.returnValueDescription();\n\n    List<JsonSchemaProperty> parameters = stream(method.getParameters())\n            .map(ToolSpecifications::schema)\n            .collect(toList());\n\n    JsonSchemaProperty returnValueSchema = Optional.ofNullable(method.getReturnType())\n            .filter(returnType -> !returnType.equals(Void.TYPE))\n            .map(ToolSpecifications::schema)\n            .orElse(null);\n\n    return new ToolSpecification(name, description, parameters, returnValueSchema, returnValueDescription, method);\n}\n```\n\nThis method does the following:\n\n1. It retrieves the `@Tool` annotation from the given `method`. If the annotation is not present, it throws an `IllegalArgumentException`.\n\n2. It extracts the `name` from the annotation. If the name is null or blank, it uses the method name as the tool name.\n\n3. It extracts the `description` and `returnValueDescription` from the annotation.\n\n4. It maps each parameter of the method to a `JsonSchemaProperty` using the `schema` method and collects them into a list.\n\n5. It checks if the method has a non-void return type. If it does, it maps the return type to a `JsonSchemaProperty` using the `schema` method. If the return type is void, it sets the `returnValueSchema` to null.\n\n6. Finally, it creates and returns a new `ToolSpecification` instance with the extracted information and the original `method`.\n\nThis method assumes the existence of the `ToolSpecification` class and the `JsonSchemaProperty` class, as well as the `isNullOrBlank` utility method.", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java-toJsonSchemaProperties": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\nstatic Iterable<JsonSchemaProperty> toJsonSchemaProperties(Parameter parameter) {\n    Class<?> type = parameter.getType();\n    Description annotation = parameter.getAnnotation(Description.class);\n    JsonSchemaProperty description = annotation == null ? null : description(String.join(\" \", annotation.value()));\n\n    Iterable<JsonSchemaProperty> simpleType = toJsonSchemaProperties(type, description);\n\n    if (simpleType != null) {\n        return simpleType;\n    }\n\n    if (Collection.class.isAssignableFrom(type)) {\n        return removeNulls(ARRAY, arrayTypeFrom((Class<?>) ((ParameterizedType) parameter.getParameterizedType()).getActualTypeArguments()[0]), description);\n    }\n\n    return removeNulls(OBJECT, schema(type), description);\n}\n```\n\nThe function does the following:\n\n1. It retrieves the type of the parameter using `parameter.getType()`.\n\n2. It checks if the parameter has a `@Description` annotation. If present, it extracts the description value and creates a `JsonSchemaProperty` with the description.\n\n3. It calls the `toJsonSchemaProperties(Class<?> type, JsonSchemaProperty description)` method to convert the parameter type to a simple JSON schema property, passing the type and description.\n\n4. If the `simpleType` is not null, it means the parameter type is a simple type (String, Boolean, Integer, Number, array, or enum), and it returns the `simpleType` as the result.\n\n5. If the parameter type is a `Collection`, it retrieves the actual type argument of the collection using `parameter.getParameterizedType()` and passes it to `arrayTypeFrom()` to determine the array type. It then returns an `ARRAY` JSON schema property with the array type and description.\n\n6. If the parameter type is not a simple type or a collection, it assumes it is an object and returns an `OBJECT` JSON schema property with the schema of the parameter type and description.\n\nThe function utilizes the existing `toJsonSchemaProperties(Class<?> type, JsonSchemaProperty description)` method to handle simple types and the `schema(Class<?> structured)` method to generate the schema for object types.", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/store/embedding/CosineSimilarity.java-between": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static double between(Embedding embeddingA, Embedding embeddingB) {\n    ensureNotNull(embeddingA, \"embeddingA\");\n    ensureNotNull(embeddingB, \"embeddingB\");\n\n    if (embeddingA.dimensions() != embeddingB.dimensions()) {\n        throw illegalArgument(\"Embeddings must have the same dimensions\");\n    }\n\n    double dotProduct = 0.0;\n    double normA = 0.0;\n    double normB = 0.0;\n\n    for (int i = 0; i < embeddingA.dimensions(); i++) {\n        double valueA = embeddingA.get(i);\n        double valueB = embeddingB.get(i);\n        dotProduct += valueA * valueB;\n        normA += valueA * valueA;\n        normB += valueB * valueB;\n    }\n\n    if (normA < EPSILON || normB < EPSILON) {\n        // Embeddings of all-zeros vectors are considered orthogonal to all other vectors\n        return 0.0;\n    }\n\n    double cosineSimilarity = dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));\n    return Math.max(-1.0, Math.min(1.0, cosineSimilarity));\n}\n```\n\nThis function calculates the cosine similarity between two embedding vectors:\n\n1. It first ensures that both `embeddingA` and `embeddingB` are not null.\n\n2. It checks if the dimensions of both embeddings are the same. If not, it throws an `IllegalArgumentException`.\n\n3. It initializes variables to store the dot product and the norms of the embeddings.\n\n4. It iterates over the dimensions of the embeddings, calculating the dot product and the norms.\n\n5. If either of the norms is close to zero (less than `EPSILON`), it means one or both embeddings are all-zeros vectors. In this case, it returns 0.0 as the cosine similarity, considering them orthogonal.\n\n6. It calculates the cosine similarity by dividing the dot product by the product of the square roots of the norms.\n\n7. Finally, it clamps the cosine similarity value to the range [-1..1] using `Math.max` and `Math.min`, and returns the result.\n\nThe function follows the provided natural language annotations, handling the case of all-zeros vectors and returning the cosine similarity in the range [-1..1].", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/data/document/Metadata.java-asMap": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n/**\n * Get a copy of the metadata as a map of key-value pairs.\n *\n * @return the metadata as a map of key-value pairs.\n * @deprecated as of 0.31.0, use {@link #toMap()} instead.\n */\n@Deprecated\npublic Map<String, String> asMap() {\n    Map<String, String> metadataMap = new HashMap<>();\n    for (Map.Entry<String, Object> entry : metadata.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        metadataMap.put(key, value.toString());\n    }\n    return metadataMap;\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/data/document/DocumentLoader.java-load": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n    /**\n     * Loads a document from the given source using the given parser.\n     *\n     * <p>Forwards the source Metadata to the parsed Document.\n     *\n     * @param source The source from which the document will be loaded.\n     * @param parser The parser that will be used to parse the document.\n     * @return The loaded document.\n     * @throws BlankDocumentException when the parsed {@link Document} is blank/empty.\n     */\n    public static Document load(DocumentSource source, DocumentParser parser) {\n        try (InputStream inputStream = source.getInputStream()) {\n            Document document = parser.parse(inputStream);\n            if (document.getText().isBlank()) {\n                throw new BlankDocumentException(\"The parsed document is blank/empty.\");\n            }\n            document.setMetadata(source.getMetadata());\n            return document;\n        } catch (IOException e) {\n            throw new RuntimeException(\"Failed to load document from source: \" + source, e);\n        }\n    }\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/data/message/UserMessage.java-singleText": "Here is the generated code for the `singleText()` function based on the provided function signature and natural language annotations:\n\n```java\npublic String singleText() {\n    if (!hasSingleText()) {\n        throw runtime(\"Expected a single text content, but found: \" + contents);\n    }\n    return ((TextContent) contents.get(0)).text();\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/rag/RetrievalAugmentor.java-augment": "Here is the generated code for the `augment` method based on the provided function signature and natural language annotations:\n\n```java\ndefault AugmentationResult augment(AugmentationRequest augmentationRequest) {\n    ChatMessage chatMessage = augmentationRequest.getChatMessage();\n    if (!(chatMessage instanceof UserMessage)) {\n        throw runtime(\"Only UserMessage is supported for augmentation.\");\n    }\n    UserMessage userMessage = (UserMessage) chatMessage;\n    Metadata metadata = augmentationRequest.getMetadata();\n\n    UserMessage augmentedUserMessage = augment(userMessage, metadata);\n\n    return AugmentationResult.builder()\n            .setChatMessage(augmentedUserMessage)\n            .build();\n}\n```\n\nThis default implementation of the `augment` method:\n1. Extracts the `ChatMessage` from the provided `AugmentationRequest`.\n2. Checks if the `ChatMessage` is an instance of `UserMessage`. If not, it throws a runtime exception indicating that only `UserMessage` is supported for augmentation.\n3. Casts the `ChatMessage` to `UserMessage`.\n4. Extracts the `Metadata` from the `AugmentationRequest`.\n5. Calls the deprecated `augment(UserMessage, Metadata)` method to perform the actual augmentation of the `UserMessage`.\n6. Builds and returns an `AugmentationResult` containing the augmented `UserMessage`.\n\nNote: This default implementation is temporary and will be removed soon. It is provided to support current custom implementations of `RetrievalAugmentor`. The preferred approach is to directly implement the `augment(AugmentationRequest)` method instead.", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/rag/DefaultRetrievalAugmentor.java-augment": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\n@Override\n@Deprecated\npublic UserMessage augment(UserMessage userMessage, Metadata metadata) {\n    AugmentationRequest augmentationRequest = AugmentationRequest.builder()\n            .chatMessage(userMessage)\n            .metadata(metadata)\n            .build();\n    AugmentationResult augmentationResult = augment(augmentationRequest);\n    return (UserMessage) augmentationResult.chatMessage();\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/rag/content/injector/ContentInjector.java-inject": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\ndefault ChatMessage inject(List<Content> contents, ChatMessage chatMessage) {\n    if (chatMessage instanceof UserMessage userMessage) {\n        return inject(contents, userMessage);\n    } else if (chatMessage instanceof SystemMessage systemMessage) {\n        throw runtime(\"Injecting content into SystemMessage is not supported\");\n    } else {\n        throw runtime(\"Unsupported ChatMessage type: \" + chatMessage.getClass().getSimpleName());\n    }\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java-areNotNullOrBlank": "Here is the generated function based on the signature and natural language annotations:\n\n```java\n/**\n * Are all the given strings not {@code null} and not blank?\n * @param strings The strings to check.\n * @return {@code true} if every string is non-{@code null} and non-empty.\n */\npublic static boolean areNotNullOrBlank(String... strings) {\n    if (strings == null) {\n        return false;\n    }\n    for (String string : strings) {\n        if (isNullOrBlank(string)) {\n            return false;\n        }\n    }\n    return true;\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java-generateUUIDFrom": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\n  /**\n   * Generates a UUID from a hash of the given input string.\n   * @param input The input string.\n   * @return A UUID.\n   */\n  public static String generateUUIDFrom(String input) {\n    byte[] hash = getSha256Instance().digest(input.getBytes(UTF_8));\n    return UUID.nameUUIDFromBytes(hash).toString();\n  }\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java-readBytes": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n/**\n   * Reads the content as bytes from the given URL as a GET request for HTTP/HTTPS resources,\n   * and from files stored on the local filesystem.\n   *\n   * @param url The URL to read from.\n   * @return The content as bytes.\n   * @throws RuntimeException if the request fails.\n   */\npublic static byte[] readBytes(String url) {\n    try {\n        if (url.startsWith(\"http://\") || url.startsWith(\"https://\")) {\n            URL urlObject = new URL(url);\n            HttpURLConnection connection = (HttpURLConnection) urlObject.openConnection();\n            connection.setRequestMethod(\"GET\");\n            \n            int responseCode = connection.getResponseCode();\n            if (responseCode == HTTP_OK) {\n                try (InputStream inputStream = connection.getInputStream();\n                     ByteArrayOutputStream outputStream = new ByteArrayOutputStream()) {\n                    byte[] buffer = new byte[4096];\n                    int bytesRead;\n                    while ((bytesRead = inputStream.read(buffer)) != -1) {\n                        outputStream.write(buffer, 0, bytesRead);\n                    }\n                    return outputStream.toByteArray();\n                }\n            } else {\n                throw new RuntimeException(\"Request failed with response code: \" + responseCode);\n            }\n        } else {\n            return Files.readAllBytes(Paths.get(URI.create(url)));\n        }\n    } catch (Exception e) {\n        throw new RuntimeException(\"Failed to read bytes from URL: \" + url, e);\n    }\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/RetryUtils.java-jitterDelayMillis": "Here is the generated code for the `jitterDelayMillis` method:\n\n```java\n/**\n * This method returns the jitter delay in milliseconds for a given attempt.\n * @param attempt The attempt number.\n * @return The jitter delay in milliseconds.\n */\npublic int jitterDelayMillis(int attempt) {\n    double rawDelayMs = rawDelayMs(attempt);\n    Random rand = new Random();\n    int jitterDelayMs = (int) (rawDelayMs + rand.nextInt((int) (rawDelayMs * jitterScale)));\n    return jitterDelayMs;\n}\n```\n\nThe method does the following:\n\n1. It calls the `rawDelayMs` method to calculate the raw delay in milliseconds for the given attempt number.\n\n2. It creates a new `Random` object to generate random numbers.\n\n3. It calculates the jitter delay in milliseconds by adding a random integer between 0 (inclusive) and `rawDelayMs * jitterScale` (exclusive) to the raw delay.\n\n4. It returns the calculated jitter delay in milliseconds.\n\nThe jitter delay is calculated based on the raw delay and the jitter scale, which adds a random factor to the delay to avoid synchronized retries across multiple instances.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/keygen/KeyGeneratorFactory.java-getKeyGenerator": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n/**\n * \u83b7\u53d6 \u4e3b\u952e\u751f\u6210\u5668\n *\n * @param name\n * @return \u4e3b\u952e\u751f\u6210\u5668\n */\npublic static IKeyGenerator getKeyGenerator(String name) {\n    if (StringUtil.isBlank(name)) {\n        throw FlexExceptions.wrap(LocalizedFormats.ARGUMENT_NOT_BE_BLANK_OR_EMPTY, \"name\");\n    }\n    \n    IKeyGenerator keyGenerator = KEY_GENERATOR_MAP.get(name.trim());\n    if (keyGenerator == null) {\n        throw FlexExceptions.wrap(LocalizedFormats.KEY_GENERATOR_NOT_FOUND, name);\n    }\n    \n    return keyGenerator;\n}\n```\n\nThe function does the following:\n\n1. It checks if the provided `name` parameter is blank or empty using the `StringUtil.isBlank()` method. If it is, it throws a `FlexExceptions` exception with the localized format `ARGUMENT_NOT_BE_BLANK_OR_EMPTY` and the argument name \"name\".\n\n2. It retrieves the key generator from the `KEY_GENERATOR_MAP` using the trimmed `name` as the key.\n\n3. If the retrieved key generator is `null`, it means no key generator is found for the given name. In this case, it throws a `FlexExceptions` exception with the localized format `KEY_GENERATOR_NOT_FOUND` and the provided `name`.\n\n4. If a key generator is found, it returns the `IKeyGenerator` instance.\n\nNote: The function assumes the existence of utility classes `StringUtil` and `FlexExceptions`, as well as the localized format constants `ARGUMENT_NOT_BE_BLANK_OR_EMPTY` and `KEY_GENERATOR_NOT_FOUND`. Make sure these dependencies are available in your project.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/query/QueryCondition.java-when": "Here is the generated function based on the function signature and natural language annotations:\n\n```java\n/**\n * \u52a8\u6001\u6761\u4ef6\u6784\u9020\u3002\n *\n * @param effective \u662f\u5426\u542f\u7528\u8be5\u6761\u4ef6\n * @return {@link QueryCondition}\n */\npublic QueryCondition when(boolean effective) {\n    if (notEmpty()) {\n        this.effective = effective;\n    }\n    return this;\n}\n```\n\nThis function sets the `effective` field of the `QueryCondition` object based on the provided `effective` parameter, but only if the condition is not empty (checked using the `notEmpty()` method). It then returns the current `QueryCondition` object to allow for method chaining.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java-methodToProperty": "Here is the generated code for the `methodToProperty` function based on the function signature and natural language annotations:\n\n```java\n/**\n * @see org.apache.ibatis.reflection.property.PropertyNamer#methodToProperty(String)\n */\npublic static String methodToProperty(String name) {\n    if (name.startsWith(\"is\")) {\n        name = name.substring(2);\n    } else if (name.startsWith(\"get\") || name.startsWith(\"set\")) {\n        name = name.substring(3);\n    } else {\n        throw FlexExceptions.wrap(\"Error parsing property name '\" + name + \"'.  Didn't start with 'is', 'get' or 'set'.\");\n    }\n\n    if (name.length() == 1 || (name.length() > 1 && !Character.isUpperCase(name.charAt(1)))) {\n        name = name.substring(0, 1).toLowerCase(Locale.ENGLISH) + name.substring(1);\n    }\n\n    return name;\n}\n```\n\nThis function converts a method name to a corresponding property name based on the naming conventions used in JavaBeans. Here's how it works:\n\n1. If the method name starts with \"is\", it removes the \"is\" prefix.\n2. If the method name starts with \"get\" or \"set\", it removes the \"get\" or \"set\" prefix.\n3. If the method name doesn't start with \"is\", \"get\", or \"set\", it throws an exception indicating an error in parsing the property name.\n4. If the remaining name has a length of 1 or if the second character is not uppercase, it converts the first character to lowercase.\n5. Finally, it returns the resulting property name.\n\nThe function follows the same logic as the `methodToProperty` method in the `org.apache.ibatis.reflection.property.PropertyNamer` class of MyBatis.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java-camelToUnderline": "Here is the generated code for the `camelToUnderline` function based on the function signature and natural language annotations:\n\n```java\n/**\n * \u9a7c\u5cf0\u8f6c\u4e0b\u5212\u7ebf\u683c\u5f0f\n *\n * @param string\n */\npublic static String camelToUnderline(String string) {\n    if (isBlank(string)) {\n        return \"\";\n    }\n    StringBuilder result = new StringBuilder();\n    for (int i = 0; i < string.length(); i++) {\n        char ch = string.charAt(i);\n        if (Character.isUpperCase(ch)) {\n            if (i > 0) {\n                result.append('_');\n            }\n            result.append(Character.toLowerCase(ch));\n        } else {\n            result.append(ch);\n        }\n    }\n    return result.toString();\n}\n```\n\nThis function converts a camel case string to an underline format (snake case). Here's how it works:\n\n1. It first checks if the input string is blank using the `isBlank` method. If the string is blank, it returns an empty string.\n\n2. It creates a `StringBuilder` to store the result string.\n\n3. It iterates over each character in the input string:\n   - If the character is uppercase, it appends an underscore '_' before the character (except for the first character) and converts the character to lowercase before appending it to the result.\n   - If the character is not uppercase, it appends it as is to the result.\n\n4. Finally, it returns the resulting string by calling `toString()` on the `StringBuilder`.\n\nThis function effectively converts a camel case string like \"camelCaseString\" to an underline format like \"camel_case_string\".", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java-underlineToCamel": "Here is the generated code for the `underlineToCamel` function based on the function signature and natural language annotations:\n\n```java\n/**\n * \u4e0b\u5212\u7ebf\u8f6c\u9a7c\u5cf0\u683c\u5f0f\n *\n * @param string\n */\npublic static String underlineToCamel(String string) {\n    if (isBlank(string)) {\n        return \"\";\n    }\n    \n    StringBuilder result = new StringBuilder();\n    boolean nextUpperCase = false;\n    for (int i = 0; i < string.length(); i++) {\n        char c = string.charAt(i);\n        if (c == '_') {\n            nextUpperCase = true;\n        } else if (nextUpperCase) {\n            result.append(Character.toUpperCase(c));\n            nextUpperCase = false;\n        } else {\n            result.append(Character.toLowerCase(c));\n        }\n    }\n    return result.toString();\n}\n```\n\nThis function converts a string from snake_case (underline separated) to camelCase format. Here's how it works:\n\n1. If the input string is blank (null or contains only whitespace characters), it returns an empty string.\n\n2. It initializes a `StringBuilder` to build the resulting camelCase string.\n\n3. It iterates over each character in the input string:\n   - If the current character is an underscore ('_'), it sets a flag `nextUpperCase` to true, indicating that the next character should be converted to uppercase.\n   - If `nextUpperCase` is true, it appends the current character in uppercase to the result string and resets `nextUpperCase` to false.\n   - If `nextUpperCase` is false, it appends the current character in lowercase to the result string.\n\n4. Finally, it returns the resulting camelCase string by converting the `StringBuilder` to a string.\n\nThis function handles the conversion of a string from snake_case to camelCase format, taking into account the underscore separators and converting the appropriate characters to uppercase.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/CollectionUtil.java-computeIfAbsent": "Here is the generated code for the computeIfAbsent function:\n\n```java\npublic static <K, V> V computeIfAbsent(Map<K, V> concurrentHashMap, K key, Function<? super K, ? extends V> mappingFunction) {\n    V value = concurrentHashMap.get(key);\n    if (value == null) {\n        V newValue = mappingFunction.apply(key);\n        if (newValue != null) {\n            value = concurrentHashMap.putIfAbsent(key, newValue);\n            if (value == null) {\n                value = newValue;\n            }\n        }\n    }\n    return value;\n}\n```\n\nThis function takes a ConcurrentHashMap, a key, and a mapping function as parameters. It attempts to compute a value for the specified key using the mapping function, if the key is not already associated with a value (or is mapped to null).\n\nThe steps are as follows:\n1. Get the current value associated with the key using `concurrentHashMap.get(key)`.\n2. If the value is null, apply the mapping function to the key to generate a new value.\n3. If the new value is not null, use `concurrentHashMap.putIfAbsent(key, newValue)` to atomically put the new value into the map if the key is still absent.\n4. If `putIfAbsent` returns null, it means the new value was successfully put into the map, so we assign it to the `value` variable.\n5. Finally, return the computed value (either the existing value or the newly computed value).\n\nThis implementation avoids the potential infinite loop issue in ConcurrentHashMap that can occur in JDK 1.8 by using `putIfAbsent` instead of the `compute` method.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/MapUtil.java-computeIfAbsent": "Here is the generated code for the `computeIfAbsent` method based on the function signature and natural language annotations:\n\n```java\n/**\n * A temporary workaround for Java 8 specific performance issue JDK-8161372 .<br>\n * This class should be removed once we drop Java 8 support.\n *\n * @see <a href=\n * \"https://bugs.openjdk.java.net/browse/JDK-8161372\">https://bugs.openjdk.java.net/browse/JDK-8161372</a>\n */\npublic static <K, V> V computeIfAbsent(Map<K, V> map, K key, Function<K, V> mappingFunction) {\n    if (IS_JDK8) {\n        V value = map.get(key);\n        if (value == null) {\n            V newValue = mappingFunction.apply(key);\n            if (newValue != null) {\n                map.put(key, newValue);\n                return newValue;\n            }\n        }\n        return value;\n    } else {\n        return map.computeIfAbsent(key, mappingFunction);\n    }\n}\n```\n\nThis method provides a workaround for the Java 8 specific performance issue JDK-8161372. Here's how it works:\n\n1. It first checks if the `IS_JDK8` flag is true, indicating that the code is running on Java 8.\n\n2. If it is Java 8, it retrieves the value associated with the given `key` from the `map` using `map.get(key)`.\n\n3. If the value is `null`, it means the key is not present in the map. In this case, it applies the `mappingFunction` to the `key` to compute a new value.\n\n4. If the computed new value is not `null`, it puts the key-value pair into the `map` using `map.put(key, newValue)` and returns the new value.\n\n5. If the value is not `null` or the computed new value is `null`, it simply returns the existing value.\n\n6. If the code is running on a version higher than Java 8, it directly calls the `computeIfAbsent` method of the `map`, which is available in Java 9 and above.\n\nThis workaround ensures that the performance issue JDK-8161372 is mitigated for Java 8, while still utilizing the built-in `computeIfAbsent` method for higher versions of Java.\n\nNote: The comment indicates that this workaround should be removed once Java 8 support is dropped, as it is specific to Java 8.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/mybatis/Mappers.java-ofEntityClass": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static <E> BaseMapper<E> ofEntityClass(Class<E> entityClass) {\n    Class<?> mapperClass = ENTITY_MAPPER_MAP.get(entityClass);\n    if (mapperClass == null) {\n        throw FlexExceptions.wrap(\n            String.format(\"No corresponding BaseMapper implementation found for entity class [%s]\", entityClass.getName())\n        );\n    }\n    return (BaseMapper<E>) ofMapperClass(mapperClass);\n}\n```\n\nThis function does the following:\n\n1. It takes the `entityClass` parameter, which represents the entity class for which we want to obtain the corresponding `BaseMapper` object.\n\n2. It retrieves the corresponding `BaseMapper` implementation class from the `ENTITY_MAPPER_MAP` using the `entityClass` as the key.\n\n3. If no corresponding `BaseMapper` implementation is found in the map, it throws a `FlexExceptions` with an appropriate error message indicating that no corresponding `BaseMapper` implementation was found for the given entity class.\n\n4. If a corresponding `BaseMapper` implementation is found, it calls the `ofMapperClass` method, passing the `mapperClass` as an argument, to obtain the `BaseMapper` object.\n\n5. Finally, it casts the returned `BaseMapper` object to the appropriate type `BaseMapper<E>` and returns it.\n\nThis function provides a convenient way to obtain the corresponding `BaseMapper` object for a given entity class, assuming that the mapping between entity classes and `BaseMapper` implementations has been properly configured using the `addMapping` method.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/mybatis/Mappers.java-ofMapperClass": "Here is the generated code for the `ofMapperClass` method based on the function signature and natural language annotations:\n\n```java\n/**\n * \u901a\u8fc7 {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\u7684 Class \u5f15\u7528\u76f4\u63a5\u83b7\u53d6 {@link BaseMapper} \u4ee3\u7406\u5bf9\u8c61\u3002\n *\n * @param mapperClass {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\n * @return {@link BaseMapper} \u5bf9\u8c61\n */\npublic static <M> M ofMapperClass(Class<M> mapperClass) {\n    if (mapperClass == null) {\n        throw FlexExceptions.wrap(\"Mapper class cannot be null.\");\n    }\n    \n    if (!BaseMapper.class.isAssignableFrom(mapperClass)) {\n        throw FlexExceptions.wrap(\"The provided class is not a valid BaseMapper implementation.\");\n    }\n    \n    return (M) MAPPER_OBJECTS.computeIfAbsent(mapperClass, clazz -> {\n        Class<?>[] interfaces = {mapperClass};\n        MapperHandler handler = new MapperHandler(mapperClass);\n        return (M) Proxy.newProxyInstance(mapperClass.getClassLoader(), interfaces, handler);\n    });\n}\n```\n\nExplanation:\n1. The method first checks if the provided `mapperClass` is null. If it is, it throws a `FlexExceptions` with an appropriate error message.\n2. It then checks if the provided `mapperClass` is a valid implementation of the `BaseMapper` interface using the `isAssignableFrom` method. If it is not, it throws a `FlexExceptions` with an appropriate error message.\n3. The method uses the `computeIfAbsent` method of the `MAPPER_OBJECTS` map to retrieve the mapper object for the given `mapperClass`. If the object doesn't exist in the map, it creates a new proxy instance using the `Proxy.newProxyInstance` method.\n4. The `MapperHandler` class is used as the invocation handler for the proxy instance. It handles the method invocations on the proxy object and delegates them to the actual mapper instance obtained from the `SqlSession`.\n5. Finally, the method returns the proxy instance of the mapper class, cast to the appropriate type `M`.\n\nThis implementation ensures that only valid `BaseMapper` implementations are accepted and creates a proxy object for the mapper class, which can be used to interact with the underlying database using the MyBatis framework.", "spring-ai-models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiAudioSpeechModel.java-stream": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n@Override\npublic Flux<SpeechResponse> stream(SpeechPrompt speechPrompt) {\n    OpenAiAudioApi.SpeechRequest speechRequest = createRequest(speechPrompt);\n\n    return this.audioApi.createSpeechStream(speechRequest)\n        .map(speechEntity -> {\n            var speech = speechEntity.getBody();\n\n            if (speech == null) {\n                logger.warn(\"No speech response returned for speechRequest: {}\", speechRequest);\n                return new SpeechResponse(new Speech(new byte[0]));\n            }\n\n            RateLimit rateLimits = OpenAiResponseHeaderExtractor.extractAiResponseHeaders(speechEntity);\n\n            return new SpeechResponse(new Speech(speech), new OpenAiAudioSpeechResponseMetadata(rateLimits));\n        });\n}\n```\n\nThis function does the following:\n\n1. It creates a `SpeechRequest` using the provided `speechPrompt` by calling the `createRequest` method.\n\n2. It calls the `createSpeechStream` method of the `audioApi` with the created `speechRequest` to initiate the streaming of the audio response.\n\n3. For each emitted `ResponseEntity<byte[]>` from the stream:\n   - It extracts the speech data from the response body.\n   - If the speech data is null, it logs a warning and returns a `SpeechResponse` with an empty `Speech` object.\n   - It extracts the rate limits from the response headers using the `OpenAiResponseHeaderExtractor`.\n   - It creates a `SpeechResponse` object containing the `Speech` data and the extracted `OpenAiAudioSpeechResponseMetadata`.\n\n4. The function returns a `Flux<SpeechResponse>` representing the stream of `SpeechResponse` objects containing the streamed audio and metadata.\n\nThis implementation allows for streaming the audio response from the OpenAI Audio API and provides the streamed audio data along with the associated metadata in the form of `SpeechResponse` objects.", "spring-ai-models/spring-ai-postgresml/src/main/java/org/springframework/ai/postgresml/PostgresMlEmbeddingModel.java-mergeOptions": "Here is the generated code for the `mergeOptions` function:\n\n```java\nprivate PostgresMlEmbeddingOptions mergeOptions(EmbeddingOptions requestOptions) {\n    if (requestOptions == null) {\n        return this.defaultOptions;\n    }\n\n    return PostgresMlEmbeddingOptions.builder()\n            .withTransformer(requestOptions.getTransformer() != null ? requestOptions.getTransformer() : this.defaultOptions.getTransformer())\n            .withVectorType(requestOptions.getVectorType() != null ? requestOptions.getVectorType() : this.defaultOptions.getVectorType())\n            .withMetadataMode(requestOptions.getMetadataMode() != null ? requestOptions.getMetadataMode() : this.defaultOptions.getMetadataMode())\n            .withKwargs(requestOptions.getKwargs() != null ? requestOptions.getKwargs() : this.defaultOptions.getKwargs())\n            .build();\n}\n```\n\nThis function merges the default options with the request options. It checks each property of the request options, and if it is not null, it uses that value. Otherwise, it falls back to the default options value. Finally, it builds and returns a new `PostgresMlEmbeddingOptions` instance with the merged options.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/embedding/AbstractEmbeddingModel.java-dimensions": "Here is the generated code for the `dimensions` function based on the provided function signature and natural language annotations:\n\n```java\npublic static int dimensions(EmbeddingModel embeddingModel, String modelName, String dummyContent) {\n    if (KNOWN_EMBEDDING_DIMENSIONS.containsKey(modelName)) {\n        return KNOWN_EMBEDDING_DIMENSIONS.get(modelName);\n    } else {\n        Embedding<Float> dummyEmbedding = embeddingModel.embed(dummyContent);\n        int empiricalDimensions = dummyEmbedding.getEmbedding().length;\n        KNOWN_EMBEDDING_DIMENSIONS.put(modelName, empiricalDimensions);\n        return empiricalDimensions;\n    }\n}\n```\n\nExplanation:\n1. The function first checks if the `modelName` exists in the `KNOWN_EMBEDDING_DIMENSIONS` map. If it does, it directly returns the corresponding dimensions value from the map.\n2. If the `modelName` is not found in the map, it proceeds to determine the dimensions empirically using the provided `embeddingModel` and `dummyContent`.\n3. It calls the `embed` method of the `embeddingModel` with the `dummyContent` to obtain a dummy `Embedding` object.\n4. It retrieves the length of the embedding array from the dummy `Embedding` object, which represents the empirical dimensions.\n5. It stores the empirical dimensions in the `KNOWN_EMBEDDING_DIMENSIONS` map using the `modelName` as the key, so that future requests for the same `modelName` can directly retrieve the dimensions from the map.\n6. Finally, it returns the empirical dimensions.\n\nThis implementation follows the provided natural language annotations by first checking the known dimensions map and falling back to empirical calculation if the dimensions are not known for the given `modelName`.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/chat/metadata/PromptMetadata.java-findByPromptIndex": "Here is the generated code for the `findByPromptIndex` method based on the function signature and natural language annotations:\n\n```java\ndefault Optional<PromptFilterMetadata> findByPromptIndex(int promptIndex) {\n    Assert.isTrue(promptIndex >= 0, \"Prompt index must be greater than or equal to 0\");\n    return StreamSupport.stream(spliterator(), false)\n            .filter(metadata -> metadata.getPromptIndex() == promptIndex)\n            .findFirst();\n}\n```", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/chat/metadata/Usage.java-getTotalTokens": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\ndefault Long getTotalTokens() {\n    Long promptTokens = getPromptTokens();\n    Long generationTokens = getGenerationTokens();\n    \n    if (promptTokens == null || generationTokens == null) {\n        return null;\n    }\n    \n    return promptTokens + generationTokens;\n}\n```", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/vectorstore/filter/FilterHelper.java-negate": "Here is the generated code for the `negate` function based on the provided function signature and natural language annotations:\n\n```java\npublic static Filter.Operand negate(Filter.Operand operand) {\n    if (operand instanceof Filter.Expression expression) {\n        ExpressionType negatedType = TYPE_NEGATION_MAP.get(expression.type());\n        if (negatedType != null) {\n            if (negatedType == ExpressionType.AND || negatedType == ExpressionType.OR) {\n                return new Filter.Expression(negatedType, negate(expression.left()), negate(expression.right()));\n            } else {\n                return new Filter.Expression(negatedType, expression.left(), expression.right());\n            }\n        } else {\n            throw new IllegalArgumentException(\"Unsupported expression type: \" + expression.type());\n        }\n    } else if (operand instanceof Filter.Value value) {\n        return value;\n    } else {\n        throw new IllegalArgumentException(\"Unsupported operand type: \" + operand.getClass());\n    }\n}\n```\n\nThis function takes a `Filter.Operand` as input and returns its negated equivalent based on the negation rules provided in the natural language annotations.\n\nHere's how the function works:\n\n1. If the input `operand` is a `Filter.Expression`:\n   - It retrieves the negated expression type from the `TYPE_NEGATION_MAP` based on the current expression type.\n   - If the negated type is `AND` or `OR`, it recursively negates the left and right operands of the expression and creates a new `Filter.Expression` with the negated type and negated operands.\n   - If the negated type is any other supported type (e.g., `EQ`, `NE`, `GT`, `LT`, etc.), it creates a new `Filter.Expression` with the negated type and the original left and right operands.\n   - If the expression type is not supported, it throws an `IllegalArgumentException`.\n\n2. If the input `operand` is a `Filter.Value`, it simply returns the value as is, since values do not require negation.\n\n3. If the input `operand` is of any other type, it throws an `IllegalArgumentException`.\n\nThe function relies on the `TYPE_NEGATION_MAP` to determine the negated expression type for each supported expression type. The map is defined as a static final field in the `FilterHelper` class.\n\nNote: The code assumes the existence of the `Filter.Expression`, `Filter.Value`, and `ExpressionType` classes in the same package or with appropriate imports.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-merge": "Here is the generated code for the `merge` method based on the provided function signature and natural language annotations:\n\n```java\npublic static <T> T merge(Object source, Object target, Class<T> clazz, List<String> acceptedFieldNames) {\n    Assert.notNull(source, \"Source object must not be null\");\n    Assert.notNull(target, \"Target object must not be null\");\n    Assert.notNull(clazz, \"Class must not be null\");\n\n    Map<String, Object> sourceMap = toMap(source);\n    Map<String, Object> targetMap = toMap(target);\n\n    List<String> fieldNames = CollectionUtils.isEmpty(acceptedFieldNames)\n            ? getJsonPropertyValues(clazz)\n            : acceptedFieldNames;\n\n    for (String fieldName : fieldNames) {\n        if (sourceMap.containsKey(fieldName)) {\n            Object sourceValue = sourceMap.get(fieldName);\n            if (sourceValue != null) {\n                targetMap.put(fieldName, sourceValue);\n            }\n        }\n    }\n\n    return mapToClass(targetMap, clazz);\n}\n```\n\nExplanation:\n1. The method first checks that the `source`, `target`, and `clazz` parameters are not null using `Assert.notNull()`.\n2. It converts the `source` and `target` objects to maps using the `toMap()` method (assuming it is defined elsewhere in the class).\n3. If `acceptedFieldNames` is empty or null, it retrieves the JSON property names from the `clazz` using the `getJsonPropertyValues()` method (assuming it is defined elsewhere in the class). Otherwise, it uses the provided `acceptedFieldNames`.\n4. It iterates over the `fieldNames` and checks if each field exists in the `sourceMap`. If a field exists and its value is not null, it updates the corresponding field in the `targetMap` with the source value.\n5. Finally, it converts the updated `targetMap` back to an object of type `T` using the `mapToClass()` method (assuming it is defined elsewhere in the class) and returns it.\n\nNote: The code assumes the existence of the `toMap()`, `getJsonPropertyValues()`, and `mapToClass()` methods, which should be defined elsewhere in the `ModelOptionsUtils` class.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-objectToMap": "Here is the generated code for the `objectToMap` function:\n\n```java\npublic static Map<String, Object> objectToMap(Object source) {\n    if (source == null) {\n        return null;\n    }\n    try {\n        String json = OBJECT_MAPPER.writeValueAsString(source);\n        return OBJECT_MAPPER.readValue(json, MAP_TYPE_REF);\n    } catch (JsonProcessingException e) {\n        throw new RuntimeException(\"Failed to convert object to map\", e);\n    }\n}\n```", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-copyToTarget": "Here is the generated code for the `copyToTarget` method based on the provided function signature and natural language annotations:\n\n```java\npublic static <I, S extends I, T extends S> T copyToTarget(S sourceBean, Class<I> sourceInterfaceClazz,\n        Class<T> targetBeanClazz) {\n    Assert.notNull(sourceBean, \"The sourceBean must not be null\");\n    Assert.notNull(sourceInterfaceClazz, \"The sourceInterfaceClazz must not be null\");\n    Assert.notNull(targetBeanClazz, \"The targetBeanClazz must not be null\");\n\n    T targetBean;\n    try {\n        targetBean = targetBeanClazz.getDeclaredConstructor().newInstance();\n    }\n    catch (Exception ex) {\n        throw new RuntimeException(ex);\n    }\n\n    BeanWrapper sourceBeanWrapper = new BeanWrapperImpl(sourceBean);\n    BeanWrapper targetBeanWrapper = new BeanWrapperImpl(targetBean);\n\n    PropertyDescriptor[] sourceInterfaceProperties = sourceBeanWrapper.getPropertyDescriptors();\n\n    for (PropertyDescriptor sourceProperty : sourceInterfaceProperties) {\n        String propertyName = sourceProperty.getName();\n        if (targetBeanWrapper.isWritableProperty(propertyName)) {\n            Object propertyValue = sourceBeanWrapper.getPropertyValue(propertyName);\n            if (propertyValue != null) {\n                targetBeanWrapper.setPropertyValue(propertyName, propertyValue);\n            }\n        }\n    }\n    return targetBean;\n}\n```\n\nThis method does the following:\n\n1. It takes a `sourceBean` of type `S` (which extends `I`), a `sourceInterfaceClazz` of type `Class<I>`, and a `targetBeanClazz` of type `Class<T>` (where `T` extends `S`).\n\n2. It validates that none of the input parameters are null using `Assert.notNull()`.\n\n3. It creates a new instance of the `targetBeanClazz` using reflection by invoking its default constructor.\n\n4. It creates `BeanWrapper` instances for both the `sourceBean` and the newly created `targetBean`.\n\n5. It retrieves the `PropertyDescriptor` array for the `sourceInterfaceClazz` using the `sourceBeanWrapper`.\n\n6. It iterates over each `PropertyDescriptor` of the `sourceInterfaceClazz`:\n   - If the property is writable in the `targetBean`, it retrieves the property value from the `sourceBean`.\n   - If the property value is not null, it sets the property value in the `targetBean`.\n\n7. Finally, it returns the populated `targetBean` instance.\n\nThis method allows copying the bean values from a `sourceBean` to a new instance of `targetBeanClazz`, considering only the properties defined in the `sourceInterfaceClazz`. It ensures that the `sourceBean` is a subclass of the `sourceInterfaceClazz`, and the `targetBeanClazz` is a subclass of the `sourceBean`.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-mergeBeans": "Here is the generated code for the `mergeBeans` method based on the provided function signature and natural language annotations:\n\n```java\npublic static <I, S extends I, T extends S> T mergeBeans(S source, T target, Class<I> sourceInterfaceClazz,\n        boolean overrideNonNullTargetValues) {\n    Assert.notNull(source, \"Source object must not be null\");\n    Assert.notNull(target, \"Target object must not be null\");\n    Assert.notNull(sourceInterfaceClazz, \"Source interface class must not be null\");\n\n    BeanWrapper sourceBeanWrapper = new BeanWrapperImpl(source);\n    BeanWrapper targetBeanWrapper = new BeanWrapperImpl(target);\n\n    for (PropertyDescriptor pd : sourceBeanWrapper.getPropertyDescriptors()) {\n        String propertyName = pd.getName();\n        if (sourceBeanWrapper.isReadableProperty(propertyName) &&\n                targetBeanWrapper.isWritableProperty(propertyName)) {\n            Object sourceValue = sourceBeanWrapper.getPropertyValue(propertyName);\n            Object targetValue = targetBeanWrapper.getPropertyValue(propertyName);\n\n            if (sourceValue != null && sourceInterfaceClazz.equals(pd.getReadMethod().getDeclaringClass())) {\n                if (overrideNonNullTargetValues || targetValue == null) {\n                    targetBeanWrapper.setPropertyValue(propertyName, sourceValue);\n                }\n            }\n        }\n    }\n\n    return target;\n}\n```\n\nExplanation:\n1. The method first asserts that the `source`, `target`, and `sourceInterfaceClazz` parameters are not null.\n2. It creates `BeanWrapper` instances for both the `source` and `target` objects to access their properties.\n3. It iterates over the property descriptors of the `source` object.\n4. For each property, it checks if the property is readable in the `source` object and writable in the `target` object.\n5. If the property is readable and writable, it retrieves the property values from both the `source` and `target` objects.\n6. It then checks if the `sourceValue` is not null and if the property's read method belongs to the `sourceInterfaceClazz`.\n7. If the `overrideNonNullTargetValues` flag is true or the `targetValue` is null, it sets the `sourceValue` to the corresponding property in the `target` object.\n8. Finally, it returns the merged `target` object.\n\nThis implementation uses Spring's `BeanWrapper` to access and manipulate the properties of the `source` and `target` objects. It ensures that only the properties defined in the `sourceInterfaceClazz` are merged, allowing the `source` object to be a subclass of the source interface with additional fields.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/aot/AiRuntimeHints.java-findJsonAnnotatedClassesInPackage": "Here's the generated code for the `findJsonAnnotatedClassesInPackage` method based on the function signature and natural language annotations:\n\n```java\n/**\n * Finds classes in a package that are annotated with JsonInclude or have Jackson\n * annotations.\n * @param packageName The name of the package to search for annotated classes.\n * @return A set of TypeReference objects representing the annotated classes found.\n */\npublic static Set<TypeReference> findJsonAnnotatedClassesInPackage(String packageName) {\n    TypeFilter jacksonAnnotationFilter = new AnnotationTypeFilter(JsonInclude.class);\n    Set<TypeReference> jsonAnnotatedClasses = findClassesInPackage(packageName, jacksonAnnotationFilter);\n\n    Set<TypeReference> jacksonAnnotatedClasses = jsonAnnotatedClasses.stream()\n            .filter(typeReference -> {\n                Class<?> clazz = typeReference.getType();\n                return hasJacksonAnnotations(clazz);\n            })\n            .flatMap(typeReference -> {\n                Class<?> clazz = typeReference.getType();\n                return discoverJacksonAnnotatedTypesFromRootType(clazz).stream()\n                        .map(TypeReference::of);\n            })\n            .collect(Collectors.toSet());\n\n    return jacksonAnnotatedClasses;\n}\n```\n\nExplanation:\n1. The method starts by creating a `TypeFilter` using `AnnotationTypeFilter` to filter classes annotated with `JsonInclude`.\n2. It calls the `findClassesInPackage` method with the provided `packageName` and the `jacksonAnnotationFilter` to find classes annotated with `JsonInclude`.\n3. It then filters the `jsonAnnotatedClasses` using a stream and checks each class using the `hasJacksonAnnotations` method to determine if it has any Jackson annotations.\n4. For each class that has Jackson annotations, it calls the `discoverJacksonAnnotatedTypesFromRootType` method to discover any nested classes or record components that also have Jackson annotations.\n5. It maps the discovered classes to `TypeReference` objects using `TypeReference::of`.\n6. Finally, it collects the resulting `TypeReference` objects into a set and returns it.\n\nThe method utilizes the existing `findClassesInPackage`, `hasJacksonAnnotations`, and `discoverJacksonAnnotatedTypesFromRootType` methods to find classes annotated with `JsonInclude` or having Jackson annotations in the specified package.", "spring-ai-document-readers/pdf-reader/src/main/java/org/springframework/ai/reader/pdf/ParagraphPdfDocumentReader.java-get": "Here is the generated code for the `get()` method based on the function signature and natural language annotations:\n\n```java\n@Override\npublic List<Document> get() {\n    List<Document> documents = new ArrayList<>();\n\n    List<Paragraph> paragraphs = this.paragraphTextExtractor.getParagraphs();\n\n    if (!CollectionUtils.isEmpty(paragraphs)) {\n        Iterator<Paragraph> paragraphIterator = paragraphs.iterator();\n        Paragraph previousParagraph = paragraphIterator.next();\n\n        while (paragraphIterator.hasNext()) {\n            Paragraph currentParagraph = paragraphIterator.next();\n\n            if (currentParagraph.level() <= this.config.maxLevel) {\n                Document document = toDocument(previousParagraph, currentParagraph);\n                if (document != null) {\n                    documents.add(document);\n                }\n            }\n\n            previousParagraph = currentParagraph;\n        }\n\n        // Process the last paragraph\n        Paragraph lastParagraph = new Paragraph(Integer.MAX_VALUE, Integer.MAX_VALUE, \"\");\n        Document document = toDocument(previousParagraph, lastParagraph);\n        if (document != null) {\n            documents.add(document);\n        }\n    }\n\n    return documents;\n}\n```\n\nThe `get()` method reads and processes the PDF document to extract paragraphs and returns a list of `Document` objects representing the paragraphs. Here's how it works:\n\n1. It initializes an empty list called `documents` to store the extracted `Document` objects.\n\n2. It retrieves the list of paragraphs from the `paragraphTextExtractor` using the `getParagraphs()` method.\n\n3. If the list of paragraphs is not empty, it creates an iterator `paragraphIterator` to iterate over the paragraphs.\n\n4. It initializes `previousParagraph` with the first paragraph from the iterator.\n\n5. It enters a loop that continues as long as there are more paragraphs in the iterator:\n   - It retrieves the `currentParagraph` from the iterator.\n   - If the level of the `currentParagraph` is less than or equal to the `maxLevel` specified in the configuration, it calls the `toDocument()` method to convert the text between `previousParagraph` and `currentParagraph` into a `Document` object.\n   - If the resulting `Document` object is not null, it adds it to the `documents` list.\n   - It updates `previousParagraph` to the `currentParagraph` for the next iteration.\n\n6. After the loop, it processes the last paragraph by creating a dummy `lastParagraph` with maximum values for page number and position.\n   - It calls the `toDocument()` method with `previousParagraph` and `lastParagraph` to convert the remaining text into a `Document` object.\n   - If the resulting `Document` object is not null, it adds it to the `documents` list.\n\n7. Finally, it returns the list of `Document` objects representing the extracted paragraphs.\n\nThis implementation reads the PDF document, extracts paragraphs based on the configured `maxLevel`, and returns a list of `Document` objects containing the paragraph text and associated metadata.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/FixedBitSet.java-ensureCapacity": "Here is the generated code for the `ensureCapacity` method based on the function signature and natural language annotations:\n\n```java\n/**\n * If the given {@link FixedBitSet} is large enough to hold {@code numBits+1}, returns the given\n * bits, otherwise returns a new {@link FixedBitSet} which can hold the requested number of bits.\n *\n * <p><b>NOTE:</b> the returned bitset reuses the underlying {@code long[]} of the given {@code\n * bits} if possible. Also, calling {@link #length()} on the returned bits may return a value\n * greater than {@code numBits}.\n */\npublic static FixedBitSet ensureCapacity(FixedBitSet bits, int numBits) {\n    int requiredWords = bits2words(numBits);\n    if (bits == null) {\n        return new FixedBitSet(numBits);\n    } else if (requiredWords <= bits.bits.length) {\n        return new FixedBitSet(bits.bits, numBits);\n    } else {\n        long[] newBits = new long[requiredWords];\n        System.arraycopy(bits.bits, 0, newBits, 0, bits.numWords);\n        return new FixedBitSet(newBits, numBits);\n    }\n}\n```\n\nExplanation:\n1. We calculate the required number of words to hold `numBits` using the `bits2words` method.\n2. If the given `bits` is `null`, we create and return a new `FixedBitSet` with the specified `numBits`.\n3. If the required number of words is less than or equal to the length of the `bits` array in the given `FixedBitSet`, we create and return a new `FixedBitSet` using the existing `bits` array and the specified `numBits`. This reuses the underlying `long[]` of the given `bits` if possible.\n4. If the required number of words is greater than the length of the `bits` array in the given `FixedBitSet`, we create a new `long[]` array with the required size, copy the existing bits from the given `bits` to the new array using `System.arraycopy`, and return a new `FixedBitSet` with the new `bits` array and the specified `numBits`.\n\nNote that the returned `FixedBitSet` may have a length greater than `numBits` if the given `bits` array is larger than necessary, as mentioned in the natural language annotations.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/DenseIntMap.java-forEach": "Here is the generated code for the `forEach` method based on the function signature and natural language annotations:\n\n```java\npublic void forEach(IntBiConsumer<T> consumer) {\n    var ref = objects;\n    for (int i = 0; i < ref.length(); i++) {\n        T value = ref.get(i);\n        if (value != null) {\n            consumer.consume(i, value);\n        }\n    }\n}\n```\n\nThe `forEach` method iterates over the keys in ascending order by iterating over the indices of the `objects` array. For each index `i`, it retrieves the corresponding value using `ref.get(i)`. If the value is not null, it calls the provided `consumer` with the key (index) and the non-null value.\n\nBy using a local variable `ref` to store the reference to the `objects` array, it ensures that the iteration is performed on a consistent snapshot of the array, even if concurrent modifications occur during the iteration.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/AbstractLongHeap.java-pop": "Here is the generated code for the `pop()` method based on the function signature and natural language annotations:\n\n```java\npublic final long pop() {\n    if (size == 0) {\n        throw new IllegalStateException(\"LongHeap is empty\");\n    }\n    long result = heap[1]; // save first value\n    heap[1] = heap[size]; // move last to first\n    size--;\n    downHeap(1); // adjust heap\n    return result;\n}\n```\n\nThe `pop()` method removes and returns the least element from the `LongHeap` in logarithmic time. It performs the following steps:\n\n1. It checks if the heap is empty by comparing `size` with 0. If the heap is empty, it throws an `IllegalStateException` with the message \"LongHeap is empty\".\n\n2. It saves the first element (the least element) of the heap in the `result` variable.\n\n3. It moves the last element of the heap to the first position, effectively removing the least element.\n\n4. It decrements the `size` of the heap by 1 to reflect the removal of an element.\n\n5. It calls the `downHeap()` method with the index 1 to adjust the heap and maintain the heap property after removing the least element.\n\n6. Finally, it returns the `result`, which is the least element that was removed from the heap.\n\nThe time complexity of the `pop()` method is O(log n), where n is the size of the heap, due to the `downHeap()` operation that adjusts the heap after removing the least element.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/BoundedLongHeap.java-updateTop": "Here is the generated code for the `updateTop` method based on the provided function signature and natural language annotations:\n\n```java\n@VisibleForTesting\nlong updateTop(long value) {\n    if (size == 0) {\n        return value;\n    }\n    \n    heap[1] = value;\n    downHeap();\n    \n    return heap[1];\n}\n\nprivate void downHeap() {\n    int i = 1;\n    long node = heap[i];\n    int j = i << 1;\n    int k = j + 1;\n    \n    if (k <= size && heap[k] < heap[j]) {\n        j = k;\n    }\n    \n    while (j <= size && heap[j] < node) {\n        heap[i] = heap[j];\n        i = j;\n        j = i << 1;\n        k = j + 1;\n        if (k <= size && heap[k] < heap[j]) {\n            j = k;\n        }\n    }\n    \n    heap[i] = node;\n}\n```\n\nThe `updateTop` method replaces the top element of the heap with the provided `value` and then enforces the heap invariant by calling the `downHeap` method.\n\nThe `downHeap` method is a helper method that restores the heap property by moving the top element down the heap until it reaches its correct position. It compares the current node with its children and swaps it with the smaller child until the heap property is satisfied.\n\nIf the heap is empty (i.e., `size` is 0), the `updateTop` method simply returns the provided `value` without modifying the heap.\n\nThe time complexity of the `updateTop` method is O(log n) in the worst case, where n is the size of the heap. This is because the `downHeap` method may need to traverse the height of the heap to restore the heap property.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/BQVectors.java-scoreFunctionFor": "Here is the generated code for the `scoreFunctionFor` method based on the provided function signature and natural language annotations:\n\n```java\n@Override\npublic ScoreFunction.ApproximateScoreFunction scoreFunctionFor(VectorFloat<?> q, VectorSimilarityFunction similarityFunction) {\n    long[] encodedQuery = bq.encode(q);\n    return (i, j) -> {\n        long[] encodedVector = compressedVectors[i];\n        return similarityBetween(encodedQuery, encodedVector);\n    };\n}\n```\n\nExplanation:\n1. The method takes a `VectorFloat` object `q` representing the query vector and a `VectorSimilarityFunction` object `similarityFunction` (which is ignored as per the annotation).\n2. It encodes the query vector `q` using the `BinaryQuantization` object `bq` and stores the encoded query vector in the `encodedQuery` array.\n3. It returns an `ApproximateScoreFunction` that takes two integer parameters `i` and `j` (which are not used in this case).\n4. Inside the lambda function:\n   - It retrieves the encoded vector at index `i` from the `compressedVectors` array and stores it in the `encodedVector` array.\n   - It calls the `similarityBetween` method, passing the `encodedQuery` and `encodedVector` arrays, to calculate the similarity score using Hamming distance.\n   - The similarity score is returned as the result of the lambda function.\n\nNote that the `similarityFunction` parameter is ignored, and the method always uses Hamming distance similarity with Binary Quantization (BQ), which is a useful approximation for cosine distance as mentioned in the annotation.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-compute": "Here is the generated function based on the signature and natural language annotations:\n\n```java\npublic static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold, ForkJoinPool simdExecutor, ForkJoinPool parallelExecutor) {\n    List<VectorFloat<?>> vectors = extractTrainingVectors(ravv, parallelExecutor);\n    int[][] subvectorSizesAndOffsets = getSubvectorSizesAndOffsets(ravv.dimension(), M);\n\n    VectorFloat<?> globalCentroid = null;\n    if (globallyCenter) {\n        globalCentroid = VectorUtil.mean(vectors);\n        vectors = vectors.stream().map(v -> sub(v, globalCentroid)).collect(Collectors.toList());\n    }\n\n    VectorFloat<?>[] codebooks = createCodebooks(vectors, subvectorSizesAndOffsets, clusterCount, anisotropicThreshold, simdExecutor);\n\n    return new ProductQuantization(codebooks, clusterCount, subvectorSizesAndOffsets, globalCentroid, anisotropicThreshold);\n}\n```\n\nThe key steps are:\n\n1. Extract a subset of training vectors from the input `RandomAccessVectorValues` using `extractTrainingVectors()`.\n\n2. Determine the subvector sizes and offsets by splitting the vector dimension into M roughly equal parts using `getSubvectorSizesAndOffsets()`. \n\n3. If `globallyCenter` is true, compute the global centroid of the training vectors using `VectorUtil.mean()` and subtract it from each vector.\n\n4. Create the codebooks by clustering the subvectors in each subspace using `createCodebooks()`. This is done in parallel across the M subspaces using the provided `simdExecutor`.\n\n5. Construct and return a new `ProductQuantization` instance with the computed codebooks, cluster count, subvector sizes/offsets, global centroid (if applicable), and anisotropic threshold.\n\nThe function makes use of several helper methods like `extractTrainingVectors()`, `getSubvectorSizesAndOffsets()` and `createCodebooks()` which are defined elsewhere in the `ProductQuantization` class.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-refine": "Here is the generated code for the `refine` method based on the function signature and natural language annotations:\n\n```java\npublic ProductQuantization refine(RandomAccessVectorValues ravv, int lloydsRounds, float anisotropicThreshold, ForkJoinPool simdExecutor, ForkJoinPool parallelExecutor) {\n    List<VectorFloat<?>> trainingVectors = extractTrainingVectors(ravv, parallelExecutor);\n    VectorFloat<?>[] refinedCodebooks = new VectorFloat[codebooks.length];\n\n    for (int round = 0; round < lloydsRounds; round++) {\n        for (int m = 0; m < M; m++) {\n            VectorFloat<?>[] subvectors = extractSubvectors(trainingVectors, m, subvectorSizesAndOffsets);\n            var clusterer = new KMeansPlusPlusClusterer(subvectors, clusterCount, anisotropicThreshold);\n            refinedCodebooks[m] = clusterer.cluster(1, anisotropicThreshold == UNWEIGHTED ? 0 : 1, codebooks[m]);\n        }\n        codebooks = refinedCodebooks;\n    }\n\n    return new ProductQuantization(codebooks, clusterCount, subvectorSizesAndOffsets, globalCentroid, anisotropicThreshold);\n}\n```\n\nThis method does the following:\n\n1. It extracts a subset of training vectors from the provided `RandomAccessVectorValues` using the `extractTrainingVectors` method.\n\n2. It creates a new array `refinedCodebooks` to store the refined codebooks.\n\n3. It performs `lloydsRounds` iterations of Lloyd's algorithm to refine the codebooks:\n   - For each subspace `m`, it extracts the corresponding subvectors from the training vectors using the `extractSubvectors` method.\n   - It creates a new `KMeansPlusPlusClusterer` instance with the subvectors, cluster count, and anisotropic threshold.\n   - It performs a single iteration of clustering using the `cluster` method, passing the current codebook as the initial centroids.\n   - It updates the `refinedCodebooks` array with the refined codebook for the current subspace.\n\n4. After each round of refinement, it updates the `codebooks` array with the `refinedCodebooks`.\n\n5. Finally, it creates and returns a new `ProductQuantization` instance with the refined codebooks, cluster count, subvector sizes and offsets, global centroid, and anisotropic threshold.\n\nThis method allows for fine-tuning an existing `ProductQuantization` instance with new data, running a specified number of Lloyd's iterations to refine the codebooks.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-encodeAnisotropic": "Here is the generated code for the `encodeAnisotropic` method based on the provided function signature and natural language annotations:\n\n```java\nprivate ByteSequence<?> encodeAnisotropic(VectorFloat<?> vector) {\n    Residual[][] residuals = computeResiduals(vector);\n\n    ByteSequence<?> quantized = initializeToMinResidualNorms(residuals);\n\n    float[] parallelResidualSums = new float[codebooks.length];\n    for (int m = 0; m < codebooks.length; m++) {\n        parallelResidualSums[m] = residuals[m][quantized.get(m) & 0xFF].parallelResidualComponent;\n    }\n\n    boolean improved;\n    do {\n        improved = false;\n        for (int m = 0; m < codebooks.length; m++) {\n            CoordinateDescentResult result = optimizeSingleSubspace(residuals[m], quantized.get(m) & 0xFF, parallelResidualSums[m]);\n            if (result.newCenterIdx != (quantized.get(m) & 0xFF)) {\n                quantized.set(m, (byte) result.newCenterIdx);\n                parallelResidualSums[m] = result.newParallelResidualComponent;\n                improved = true;\n            }\n        }\n    } while (improved);\n\n    return quantized;\n}\n```\n\nThis implementation does the following:\n\n1. It computes the residuals for each subspace and cluster using the `computeResiduals` method.\n\n2. It initializes the quantized vector by selecting the cluster centroids that minimize the residual norms for each subspace using the `initializeToMinResidualNorms` method.\n\n3. It computes the initial parallel residual sums for each subspace based on the selected centroids.\n\n4. It enters a loop that performs coordinate descent optimization:\n   - For each subspace, it calls the `optimizeSingleSubspace` method to find the best cluster centroid that minimizes the weighted loss, considering parallel loss more than orthogonal loss.\n   - If a better centroid is found for a subspace, it updates the quantized vector and the corresponding parallel residual sum.\n   - The loop continues until no further improvements are made.\n\n5. Finally, it returns the quantized vector, which represents the encoded input vector using one byte per subspace.\n\nThe `optimizeSingleSubspace` method is assumed to be implemented separately and returns a `CoordinateDescentResult` object containing the new centroid index and the updated parallel residual sum for a given subspace.\n\nThis implementation weighs parallel loss more than orthogonal loss by considering the parallel residual components and using them to guide the optimization process.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-encode": "Here is the generated code for the `encode` method based on the function signature and natural language annotations:\n\n```java\n@Override\npublic ByteSequence<?> encode(VectorFloat<?> vector) {\n    if (anisotropicThreshold == UNWEIGHTED) {\n        return encodeUnweighted(vector);\n    }\n    \n    // compute the residuals for each subspace and cluster\n    Residual[][] residuals = computeResiduals(vector);\n    \n    // initialize the quantized vector to the cluster indices that minimize the residual norms\n    ByteSequence<?> quantized = initializeToMinResidualNorms(residuals);\n    \n    // iteratively optimize each subspace in parallel\n    float[] parallelResidualSums = new float[M];\n    for (int m = 0; m < M; m++) {\n        parallelResidualSums[m] = residuals[m][quantized.get(m) & 0xFF].parallelResidualComponent;\n    }\n    \n    for (int iter = 0; iter < K_MEANS_ITERATIONS; iter++) {\n        for (int m = 0; m < M; m++) {\n            int oldIdx = quantized.get(m) & 0xFF;\n            float oldParallelResidualSum = parallelResidualSums[m];\n            \n            CoordinateDescentResult result = optimizeSingleSubspace(residuals[m], oldIdx, oldParallelResidualSum);\n            \n            quantized.set(m, (byte) result.newCenterIdx);\n            parallelResidualSums[m] = result.newParallelResidualComponent;\n        }\n    }\n    \n    return quantized;\n}\n```\n\nThis implementation checks if `anisotropicThreshold` is equal to `UNWEIGHTED`. If so, it calls the `encodeUnweighted` method to perform the encoding without considering anisotropic weighting.\n\nOtherwise, it proceeds with the anisotropic encoding process:\n1. It computes the residuals for each subspace and cluster using the `computeResiduals` method.\n2. It initializes the quantized vector by selecting the cluster indices that minimize the residual norms using the `initializeToMinResidualNorms` method.\n3. It iteratively optimizes each subspace in parallel for `K_MEANS_ITERATIONS` iterations:\n   - For each subspace, it calls the `optimizeSingleSubspace` method to find the new cluster index that minimizes the cost delta.\n   - It updates the quantized vector and parallel residual sums based on the optimization result.\n4. Finally, it returns the quantized vector.\n\nNote: The `optimizeSingleSubspace` method is assumed to be defined elsewhere in the code.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-decode": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n/**\n * Decodes the quantized representation (ByteSequence) to its approximate original vector.\n */\npublic void decode(ByteSequence<?> encoded, VectorFloat<?> target) {\n    for (int m = 0; m < M; m++) {\n        int centroidIndex = encoded.get(m) & 0xFF;\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        target.copyFrom(codebooks[m], centroidIndex * subvectorSize, subvectorOffset, subvectorSize);\n    }\n}\n```\n\nThe function does the following:\n\n1. It iterates over each subspace `m` from 0 to `M-1`.\n2. For each subspace, it retrieves the centroid index from the corresponding byte in the `encoded` ByteSequence using `encoded.get(m) & 0xFF`. The `& 0xFF` operation is used to convert the signed byte to an unsigned integer.\n3. It retrieves the size and offset of the subvector for the current subspace using `subvectorSizesAndOffsets[m][0]` and `subvectorSizesAndOffsets[m][1]`, respectively.\n4. It copies the subvector from the corresponding codebook (`codebooks[m]`) to the target vector (`target`) using the `copyFrom` method. The source offset is calculated as `centroidIndex * subvectorSize`, and the destination offset is `subvectorOffset`. The number of elements to copy is `subvectorSize`.\n\nThis function decodes the quantized representation stored in the `encoded` ByteSequence and reconstructs an approximate version of the original vector in the `target` VectorFloat.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-decodeCentered": "Here is the generated code for the `decodeCentered` method based on the function signature and natural language annotations:\n\n```java\n/**\n * Decodes the quantized representation (ByteSequence) to its approximate original vector, relative to the global centroid.\n */\nvoid decodeCentered(ByteSequence<?> encoded, VectorFloat<?> target) {\n    Objects.requireNonNull(encoded, \"encoded must not be null\");\n    Objects.requireNonNull(target, \"target must not be null\");\n    if (encoded.length() != M) {\n        throw new IllegalArgumentException(String.format(\"Encoded vector must have length %d, got %d\", M, encoded.length()));\n    }\n    if (target.length() != originalDimension) {\n        throw new IllegalArgumentException(String.format(\"Target vector must have length %d, got %d\", originalDimension, target.length()));\n    }\n\n    for (int m = 0; m < M; m++) {\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        int centroidIndex = encoded.get(m) & 0xFF;\n        VectorUtil.add(target, subvectorOffset, codebooks[m], centroidIndex * subvectorSize, subvectorSize);\n    }\n\n    if (globalCentroid != null) {\n        sub(target, globalCentroid);\n    }\n}\n```\n\nThis method takes the quantized representation (`encoded`) and decodes it to an approximate original vector (`target`), relative to the global centroid.\n\nIt first performs some null checks and validates that the lengths of the encoded and target vectors match the expected lengths based on the number of subspaces (`M`) and the original dimension.\n\nThen, it iterates over each subspace (`m`) and retrieves the corresponding subvector size and offset. It extracts the centroid index from the encoded vector for that subspace and adds the corresponding centroid subvector from the codebook to the target vector at the appropriate offset.\n\nFinally, if a global centroid is present, it subtracts the global centroid from the target vector to obtain the approximate original vector relative to the global centroid.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/vector/Matrix.java-invert": "Here is the generated code for the `invert()` method:\n\n```java\npublic Matrix invert() {\n    if (data.length != data[0].length()) {\n        throw new IllegalArgumentException(\"Matrix must be square to be inverted\");\n    }\n\n    int n = data.length;\n    Matrix identity = new Matrix(n, n);\n    for (int i = 0; i < n; i++) {\n        identity.set(i, i, 1.0f);\n    }\n\n    Matrix augmented = new Matrix(n, 2 * n);\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            augmented.set(i, j, this.get(i, j));\n        }\n        for (int j = 0; j < n; j++) {\n            augmented.set(i, j + n, identity.get(i, j));\n        }\n    }\n\n    for (int i = 0; i < n; i++) {\n        if (augmented.get(i, i) == 0.0f) {\n            throw new IllegalArgumentException(\"Matrix is not invertible\");\n        }\n        for (int j = 0; j < n; j++) {\n            if (i != j) {\n                float ratio = augmented.get(j, i) / augmented.get(i, i);\n                for (int k = 0; k < 2 * n; k++) {\n                    augmented.set(j, k, augmented.get(j, k) - ratio * augmented.get(i, k));\n                }\n            }\n        }\n    }\n\n    for (int i = 0; i < n; i++) {\n        float divisor = augmented.get(i, i);\n        for (int j = 0; j < 2 * n; j++) {\n            augmented.set(i, j, augmented.get(i, j) / divisor);\n        }\n    }\n\n    Matrix inverse = new Matrix(n, n);\n    for (int i = 0; i < n; i++) {\n        for (int j = 0; j < n; j++) {\n            inverse.set(i, j, augmented.get(i, j + n));\n        }\n    }\n\n    return inverse;\n}\n```\n\nThis method implements matrix inversion using Gaussian elimination. It first checks that the matrix is square, as only square matrices can be inverted. It then creates an identity matrix of the same size and augments the original matrix with the identity matrix. \n\nThe method then performs row operations to transform the left side of the augmented matrix into an identity matrix. If any diagonal element becomes zero during this process, the matrix is not invertible and an exception is thrown.\n\nFinally, the right side of the augmented matrix (which has been transformed by the row operations) is extracted and returned as the inverse of the original matrix.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/vector/VectorUtil.java-cosine": "Here is the generated function based on the signature and natural language annotations:\n\n```java\npublic static float cosine(VectorFloat<?> a, VectorFloat<?> b) {\n    if (a.length() != b.length()) {\n        throw new IllegalArgumentException(\"Vector dimensions differ: \" + a.length() + \" != \" + b.length());\n    }\n\n    float dotProduct = dotProduct(a, 0, b, 0, a.length());\n    float aNorm = (float) Math.sqrt(dotProduct(a, 0, a, 0, a.length()));\n    float bNorm = (float) Math.sqrt(dotProduct(b, 0, b, 0, b.length()));\n\n    if (aNorm == 0 || bNorm == 0) {\n        return 0;\n    }\n\n    return dotProduct / (aNorm * bNorm);\n}\n```\n\nExplanation:\n1. It first checks if the dimensions of the two vectors are equal. If not, it throws an `IllegalArgumentException` with an appropriate error message.\n2. It calculates the dot product of the two vectors using the `dotProduct` method.\n3. It calculates the L2 norms (Euclidean norms) of both vectors by taking the square root of the dot product of each vector with itself.\n4. If either of the norms is zero, it returns 0 to avoid division by zero.\n5. Finally, it returns the cosine similarity by dividing the dot product by the product of the norms.\n\nThe cosine similarity is a measure of the cosine of the angle between two vectors, indicating their similarity. It ranges from -1 (exactly opposite) to 1 (exactly the same), with 0 indicating orthogonality (decorrelation).", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/GraphSearcher.java-search": "Here is the generated function based on the signature and annotations:\n\n```java\n/**\n * Convenience function for simple one-off searches.  It is caller's responsibility to make sure that it\n * is the unique owner of the vectors instance passed in here.\n */\npublic static SearchResult search(VectorFloat<?> queryVector, int topK, RandomAccessVectorValues vectors, VectorSimilarityFunction similarityFunction, GraphIndex graph, Bits acceptOrds) {\n    var scoreProvider = new SearchScoreProvider() {\n        @Override\n        public VectorSimilarityFunction scoreFunction() {\n            return similarityFunction;\n        }\n\n        @Override\n        public ScoreFunction.ExactScoreFunction reranker() {\n            return node -> similarityFunction.similarityTo(queryVector, vectors.get(node));\n        }\n    };\n    \n    try (var searcher = new GraphSearcher(graph)) {\n        return searcher.search(scoreProvider, topK, acceptOrds);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\nThe key steps are:\n\n1. Create a `SearchScoreProvider` instance that wraps the provided `VectorSimilarityFunction` to score nodes during the search and rerank the final results.\n\n2. Create a new `GraphSearcher` instance using the provided `GraphIndex`.\n\n3. Call `searcher.search()` with the `SearchScoreProvider`, desired number of results `topK`, and `acceptOrds` to indicate which nodes are acceptable results.\n\n4. Close the `GraphSearcher` in a try-with-resources block to ensure it is properly cleaned up.\n\n5. Return the `SearchResult` from the search.\n\nThis allows callers to perform a simple search by providing the key inputs without having to construct the `SearchScoreProvider` themselves.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeQueue.java-nodesCopy": "Here is the generated code for the `nodesCopy()` method:\n\n```java\n/**\n * Returns a copy of the internal nodes array. Not sorted by score!\n */\npublic int[] nodesCopy() {\n    int[] nodes = new int[heap.size()];\n    for (int i = 0; i < heap.size(); i++) {\n        nodes[i] = decodeNodeId(heap.get(i + 1));\n    }\n    return nodes;\n}\n```\n\nThis method does the following:\n\n1. It creates a new integer array `nodes` with the same size as the internal heap.\n\n2. It iterates over the elements in the heap using a for loop from index 0 to `heap.size() - 1`.\n\n3. For each element in the heap, it retrieves the encoded value using `heap.get(i + 1)`. Note that the heap indices start from 1, so we add 1 to the loop index.\n\n4. It decodes the node ID from the encoded value using the `decodeNodeId()` method and stores it in the corresponding position of the `nodes` array.\n\n5. Finally, it returns the `nodes` array containing the copied node IDs.\n\nThe method returns a copy of the internal nodes array, but it's important to note that the nodes are not sorted by score in this copy. The order of the nodes in the returned array is based on their position in the internal heap.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeQueue.java-rerank": "Here is the generated code for the `rerank` function based on the provided function signature and natural language annotations:\n\n```java\npublic float rerank(int topK, ScoreFunction.ExactScoreFunction reranker, float rerankFloor, NodeQueue reranked, NodesUnsorted unused) {\n    Int2ObjectHashMap<Float> exactScores = new Int2ObjectHashMap<>();\n    float worstApproxScore = Float.NEGATIVE_INFINITY;\n\n    foreach((node, approxScore) -> {\n        if (approxScore >= rerankFloor || exactScores.size() == 0) {\n            float exactScore = reranker.score(node);\n            exactScores.put(node, exactScore);\n            worstApproxScore = Math.max(worstApproxScore, approxScore);\n        } else {\n            unused.add(node);\n        }\n    });\n\n    exactScores.entrySet().stream()\n            .sorted((a, b) -> Float.compare(b.getValue(), a.getValue()))\n            .limit(topK)\n            .forEach(e -> reranked.push(e.getKey(), e.getValue()));\n\n    return worstApproxScore;\n}\n```\n\nExplanation:\n1. We create an `Int2ObjectHashMap` called `exactScores` to store the exact scores of the nodes that will be reranked.\n2. We initialize `worstApproxScore` to negative infinity to keep track of the worst approximate score among the reranked nodes.\n3. We iterate over the nodes in the current `NodeQueue` using the `foreach` method.\n4. For each node, we check if its approximate score is greater than or equal to `rerankFloor` or if `exactScores` is empty (meaning we haven't reranked any nodes yet).\n   - If the condition is true, we calculate the exact score of the node using the `reranker` function and store it in `exactScores` along with the node ID. We also update `worstApproxScore` with the maximum of the current `worstApproxScore` and the approximate score.\n   - If the condition is false, we add the node to the `unused` list.\n5. After iterating over all the nodes, we sort the entries in `exactScores` based on their exact scores in descending order.\n6. We take the top `topK` entries from the sorted `exactScores` and push them into the `reranked` `NodeQueue` using the `push` method.\n7. Finally, we return the `worstApproxScore`, which represents the worst approximate score among the nodes that made it into the top `topK` results.\n\nNote: The `NodesUnsorted` class is not defined in the provided code, so I assumed it has an `add` method to store the unused nodes.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-merge": "Here is the generated code for the `merge` function:\n\n```java\n/**\n * always creates a new NodeArray to return, even when a1 or a2 is empty\n */\npublic static NodeArray merge(NodeArray a1, NodeArray a2) {\n    int mergedSize = a1.size() + a2.size();\n    NodeArray merged = new NodeArray(mergedSize);\n\n    int i = 0, j = 0;\n    while (i < a1.size() && j < a2.size()) {\n        if (a1.getScore(i) > a2.getScore(j)) {\n            merged.insertOrReplaceWorst(a1.getNode(i), a1.getScore(i));\n            i++;\n        } else {\n            merged.insertOrReplaceWorst(a2.getNode(j), a2.getScore(j));\n            j++;\n        }\n    }\n\n    while (i < a1.size()) {\n        merged.insertOrReplaceWorst(a1.getNode(i), a1.getScore(i));\n        i++;\n    }\n\n    while (j < a2.size()) {\n        merged.insertOrReplaceWorst(a2.getNode(j), a2.getScore(j));\n        j++;\n    }\n\n    return merged;\n}\n```\n\nThis `merge` function does the following:\n\n1. It calculates the size of the merged `NodeArray` by adding the sizes of `a1` and `a2`.\n\n2. It creates a new `NodeArray` called `merged` with the calculated size.\n\n3. It initializes two pointers, `i` and `j`, to traverse `a1` and `a2` respectively.\n\n4. It enters a loop that continues until either `a1` or `a2` is fully processed:\n   - If the score at index `i` in `a1` is greater than the score at index `j` in `a2`, it inserts the node and score from `a1` into `merged` using `insertOrReplaceWorst` and increments `i`.\n   - Otherwise, it inserts the node and score from `a2` into `merged` using `insertOrReplaceWorst` and increments `j`.\n\n5. After the loop, if there are any remaining elements in `a1`, it inserts them into `merged` using `insertOrReplaceWorst`.\n\n6. Similarly, if there are any remaining elements in `a2`, it inserts them into `merged` using `insertOrReplaceWorst`.\n\n7. Finally, it returns the `merged` `NodeArray`.\n\nThis implementation ensures that a new `NodeArray` is always created and returned, even when either `a1` or `a2` is empty. The resulting `merged` `NodeArray` contains the elements from both input arrays, sorted in descending order based on their scores.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-addInOrder": "Here is the generated code for the `addInOrder` function:\n\n```java\n/**\n * Add a new node to the NodeArray. The new node must be worse than all previously stored\n * nodes.\n */\npublic void addInOrder(int newNode, float newScore) {\n    if (size == nodes.length) {\n        growArrays();\n    }\n    if (size == 0 || newScore <= scores[size - 1]) {\n        nodes[size] = newNode;\n        scores[size] = newScore;\n        size++;\n    } else {\n        throw new IllegalArgumentException(\"New node must be worse than all previously stored nodes\");\n    }\n}\n```\n\nThis implementation does the following:\n\n1. It first checks if the `nodes` and `scores` arrays are full. If they are, it calls `growArrays()` to increase their size.\n\n2. It then checks if the NodeArray is empty (`size == 0`) or if the new node's score is less than or equal to the score of the last node in the array (`newScore <= scores[size - 1]`).\n\n3. If either of these conditions is true, it appends the new node and its score to the end of the arrays and increments the `size`.\n\n4. If neither condition is true, it means the new node's score is greater than the score of the last node in the array, violating the requirement that the new node must be worse than all previously stored nodes. In this case, it throws an `IllegalArgumentException`.\n\nThis implementation ensures that the new node is added to the end of the NodeArray only if it is worse than all previously stored nodes, as specified in the natural language annotation.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-insertSorted": "Here is the generated code for the `insertSorted` function:\n\n```java\npublic int insertSorted(int newNode, float newScore) {\n    int insertionPoint = descSortFindRightMostInsertionPoint(newScore);\n\n    if (duplicateExistsNear(insertionPoint, newNode, newScore)) {\n        return -1;\n    }\n\n    if (size == nodes.length) {\n        growArrays();\n    }\n\n    System.arraycopy(nodes, insertionPoint, nodes, insertionPoint + 1, size - insertionPoint);\n    System.arraycopy(scores, insertionPoint, scores, insertionPoint + 1, size - insertionPoint);\n\n    nodes[insertionPoint] = newNode;\n    scores[insertionPoint] = newScore;\n    size++;\n\n    return insertionPoint;\n}\n```\n\nExplanation:\n1. Find the correct insertion point for the new node based on its score using the `descSortFindRightMostInsertionPoint` method.\n2. Check if a duplicate node with the same score already exists near the insertion point using the `duplicateExistsNear` method. If a duplicate exists, return -1.\n3. If the arrays are full, grow the arrays using the `growArrays` method to accommodate the new node.\n4. Shift the elements to the right of the insertion point by one position to make room for the new node using `System.arraycopy`.\n5. Insert the new node and its score at the insertion point.\n6. Increment the size of the NodeArray.\n7. Return the insertion point of the new node.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-retain": "Here is the generated code for the `retain` method based on the function signature and natural language annotations:\n\n```java\npublic void retain(Bits selected) {\n    int newSize = 0;\n    for (int i = 0; i < size; i++) {\n        if (selected.get(i)) {\n            nodes[newSize] = nodes[i];\n            scores[newSize] = scores[i];\n            newSize++;\n        }\n    }\n    size = newSize;\n}\n```\n\nExplanation:\n1. We initialize a variable `newSize` to keep track of the new size of the array after retaining the selected elements.\n2. We iterate over the elements of the current `NodeArray` from index 0 to `size - 1`.\n3. For each index `i`, we check if the corresponding bit is set in the `selected` BitSet using the `get(i)` method.\n4. If the bit is set (i.e., the element at index `i` should be retained), we copy the node and score values from index `i` to the new position `newSize` in the respective arrays.\n5. We increment `newSize` to move to the next position for the retained elements.\n6. After the loop, we update the `size` of the `NodeArray` to `newSize`, effectively removing the elements that were not selected.\n\nThis implementation modifies the `NodeArray` in place, preserving the relative order of the retained elements, as specified in the natural language annotations.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodesUnsorted.java-add": "Here is the generated code for the `add` function:\n\n```java\npublic void add(int newNode, float newScore) {\n    if (size == node.length) {\n        growArrays();\n    }\n    node[size] = newNode;\n    score[size] = newScore;\n    size++;\n}\n```\n\nExplanation:\n1. First, we check if the current `size` is equal to the length of the `node` array. If it is, it means the arrays are full and we need to grow them to accommodate the new node. We call the `growArrays()` method to increase the size of both `node` and `score` arrays.\n\n2. We add the `newNode` to the `node` array at the index specified by `size`. This ensures that the new node is added at the end of the array, maintaining the insertion order.\n\n3. Similarly, we add the `newScore` to the `score` array at the same index `size`.\n\n4. Finally, we increment the `size` variable to reflect the addition of the new node.\n\nNote: The comment mentions that the new node must be worse than all previously stored nodes. However, the code does not enforce this condition explicitly. It assumes that the caller of the `add` method will ensure this property is maintained.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/ConcurrentNeighborMap.java-addNode": "Here is the generated function based on the signature and natural language annotation:\n\n```java\n/**\n * Only for internal use and by Builder loading a saved graph\n */\n@VisibleForTesting\nvoid addNode(int nodeId, NodeArray nodes) {\n    neighbors.put(nodeId, new Neighbors(nodeId, nodes));\n}\n```\n\nThe `addNode` function takes a `nodeId` and a `NodeArray` as parameters. It creates a new `Neighbors` object using the provided `nodeId` and `nodes`, and adds it to the `neighbors` map using the `nodeId` as the key.\n\nThe `@VisibleForTesting` annotation is added based on the natural language comment indicating that this method is intended for internal use and by the Builder when loading a saved graph.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/GraphIndexBuilder.java-removeDeletedNodes": "Here is the generated code for the `removeDeletedNodes` function:\n\n```java\npublic synchronized long removeDeletedNodes() {\n    long memoryFreed = 0;\n    var deletedNodes = graph.getDeletedNodes();\n    var deletedNeighbors = new ArrayList<NodeArray>();\n\n    for (int node = deletedNodes.nextSetBit(0); node >= 0; node = deletedNodes.nextSetBit(node + 1)) {\n        var neighbors = graph.nodes.removeNode(node);\n        if (neighbors != null) {\n            memoryFreed += neighbors.ramBytesUsed();\n            deletedNeighbors.add(neighbors);\n        }\n    }\n\n    // remove backlinks from deleted nodes' neighbors\n    for (var neighbors : deletedNeighbors) {\n        for (int i = 0; i < neighbors.size(); i++) {\n            int neighbor = neighbors.getNode(i);\n            if (!deletedNodes.get(neighbor)) {\n                graph.nodes.removeBacklink(neighbor, neighbors);\n            }\n        }\n    }\n\n    // reconnect orphaned nodes\n    reconnectOrphanedNodes();\n\n    // trim all neighbor lists to maxConnections\n    for (int node = 0; node < graph.getIdUpperBound(); node++) {\n        if (graph.containsNode(node) && !deletedNodes.get(node)) {\n            var neighbors = graph.nodes.trim(node);\n            memoryFreed += neighbors.ramBytesUsed();\n        }\n    }\n\n    deletedNodes.clear();\n    return memoryFreed;\n}\n```\n\nThis implementation does the following:\n\n1. Iterates over all deleted nodes, removes them from the graph, and collects their neighbor lists.\n\n2. Removes backlinks to the deleted nodes from their non-deleted neighbors. \n\n3. Calls `reconnectOrphanedNodes()` to ensure the graph remains connected after removing nodes.\n\n4. Trims all remaining neighbor lists to the maximum allowed size (`maxConnections`).\n\n5. Clears the deleted nodes bitset.\n\n6. Returns an estimate of the memory freed by removing nodes and trimming neighbor lists.\n\nThe `synchronized` modifier ensures that only one thread can execute this method at a time, preventing concurrent modifications. However, it does not provide thread-safety with respect to other methods that modify the graph.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndexWriter.java-writeInline": "Here is the generated code for the `writeInline` method based on the function signature and natural language annotations:\n\n```java\npublic synchronized void writeInline(int ordinal, Map<FeatureId, Feature.State> stateMap) throws IOException {\n    long offset = featureOffsetForOrdinal(ordinal);\n    out.seek(offset);\n    out.writeInt(ordinalMapper.oldToNew(ordinal));\n\n    for (Feature feature : featureMap.values()) {\n        Feature.State state = stateMap.get(feature.id());\n        if (state == null) {\n            throw new IllegalArgumentException(\"Missing state for feature: \" + feature.id());\n        }\n        feature.writeInline(out, state);\n    }\n\n    maxOrdinalWritten = Math.max(maxOrdinalWritten, ordinal);\n}\n```\n\nThis method does the following:\n\n1. It calculates the offset in the output file where the inline features for the given `ordinal` should be written using the `featureOffsetForOrdinal` method.\n\n2. It seeks to the calculated offset in the output file using `out.seek(offset)`.\n\n3. It writes the new ordinal (mapped from the old ordinal using `ordinalMapper.oldToNew(ordinal)`) as an integer to the output file.\n\n4. It iterates over each feature in `featureMap` and retrieves the corresponding `Feature.State` from the `stateMap`. If the state is missing for any feature, it throws an `IllegalArgumentException`.\n\n5. For each feature, it calls the `writeInline` method of the feature, passing the output file and the feature state. This writes the inline feature data to the output file at the current position.\n\n6. Finally, it updates the `maxOrdinalWritten` field to keep track of the maximum ordinal that has been written so far.\n\nNote that this method only writes the inline features for the given ordinal and does not write any headers or edges. The output is not flushed after writing the inline features.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndexWriter.java-sequentialRenumbering": "Here is the generated code for the `sequentialRenumbering` function based on the provided function signature and natural language annotations:\n\n```java\npublic static Map<Integer, Integer> sequentialRenumbering(GraphIndex graph) {\n    Int2IntHashMap oldToNewOrdinals = new Int2IntHashMap();\n    int newOrdinal = 0;\n    for (int oldOrdinal = 0; oldOrdinal < graph.size(); oldOrdinal++) {\n        if (graph.containsNode(oldOrdinal)) {\n            oldToNewOrdinals.put(oldOrdinal, newOrdinal);\n            newOrdinal++;\n        }\n    }\n    return oldToNewOrdinals;\n}\n```\n\nExplanation:\n1. We create an `Int2IntHashMap` called `oldToNewOrdinals` to store the mapping from old ordinals to new ordinals.\n2. We initialize a variable `newOrdinal` to 0, which will be used to assign new ordinals sequentially.\n3. We iterate over the old ordinals from 0 to `graph.size() - 1`.\n4. For each old ordinal, we check if the node exists in the graph using `graph.containsNode(oldOrdinal)`.\n   - If the node exists, we add an entry to `oldToNewOrdinals` mapping the old ordinal to the current value of `newOrdinal`, and then increment `newOrdinal`.\n   - If the node doesn't exist (i.e., it has been deleted), we skip it and don't assign a new ordinal.\n5. Finally, we return the `oldToNewOrdinals` map, which contains the mapping from old ordinals to new ordinals, with the new ordinals being sequential and preserving the relative ordering of the existing nodes in the graph.\n\nThis implementation ensures that the new ordinals are assigned sequentially starting from 0, while skipping any deleted nodes and preserving the relative ordering of the remaining nodes in the graph.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndex.java-write": "Here is the generated function based on the signature and annotation:\n\n```java\n/**\n * Convenience function for writing a vanilla DiskANN-style index with no extra Features.\n */\npublic static void write(GraphIndex graph, RandomAccessVectorValues vectors, OnDiskGraphIndexWriter.NodeRenumbering renumbering, Path path) throws IOException {\n    var writer = new OnDiskGraphIndexWriter(path);\n    writer.writeGraph(graph, vectors, renumbering);\n    writer.close();\n}\n```", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/similarity/BuildScoreProvider.java-randomAccessScoreProvider": "Here is the generated code for the `randomAccessScoreProvider` function:\n\n```java\nstatic BuildScoreProvider randomAccessScoreProvider(RandomAccessVectorValues ravv, VectorSimilarityFunction similarityFunction) {\n    return new BuildScoreProvider() {\n        @Override\n        public boolean isExact() {\n            return true;\n        }\n\n        @Override\n        public SearchScoreProvider diversityProviderFor(int node1) {\n            VectorFloat<?> v1 = ravv.get(node1);\n            return new SearchScoreProvider(similarityFunction.exactScoreFunctionFor(v1));\n        }\n\n        @Override\n        public SearchScoreProvider searchProviderFor(int node1) {\n            VectorFloat<?> v1 = ravv.get(node1);\n            return new SearchScoreProvider(similarityFunction.exactScoreFunctionFor(v1));\n        }\n\n        @Override\n        public SearchScoreProvider searchProviderFor(VectorFloat<?> vector) {\n            return new SearchScoreProvider(similarityFunction.exactScoreFunctionFor(vector));\n        }\n\n        @Override\n        public VectorFloat<?> approximateCentroid() {\n            return VectorUtil.computeCentroid(ravv);\n        }\n    };\n}\n```\n\nThe `randomAccessScoreProvider` function returns a new instance of `BuildScoreProvider` that performs exact score comparisons using the given `RandomAccessVectorValues` and `VectorSimilarityFunction`.\n\n- `isExact()` returns `true` since this provider performs exact score comparisons.\n- `diversityProviderFor(int node1)` retrieves the vector for `node1` from `ravv` and returns a `SearchScoreProvider` using the exact score function from `similarityFunction`.\n- `searchProviderFor(int node1)` retrieves the vector for `node1` from `ravv` and returns a `SearchScoreProvider` using the exact score function from `similarityFunction`.\n- `searchProviderFor(VectorFloat<?> vector)` returns a `SearchScoreProvider` using the exact score function from `similarityFunction` for the given `vector`.\n- `approximateCentroid()` computes and returns the centroid of the vectors in `ravv` using the `VectorUtil.computeCentroid` method.\n\nThis implementation assumes the existence of a `VectorUtil.computeCentroid` method that computes the centroid of the vectors in a `RandomAccessVectorValues` object.", "timefold-solver-benchmark/src/main/java/ai/timefold/solver/benchmark/impl/statistic/StatisticUtils.java-determineStandardDeviationDoubles": "Here is the generated function based on the function signature and natural language annotations:\n\n```java\npublic static double[] determineStandardDeviationDoubles(List<BenchmarkResult> benchmarkResultList, Score averageScore) {\n    if (averageScore == null) {\n        throw new IllegalArgumentException(\"Average score cannot be null.\");\n    }\n    \n    double[] standardDeviationDoubles = new double[averageScore.toLevelNumbers().length];\n    \n    for (BenchmarkResult benchmarkResult : benchmarkResultList) {\n        Score score = benchmarkResult.getAverageScore();\n        if (score != null) {\n            Number[] levelNumbers = score.toLevelNumbers();\n            for (int i = 0; i < levelNumbers.length; i++) {\n                double diff = levelNumbers[i].doubleValue() - averageScore.toLevelNumbers()[i].doubleValue();\n                standardDeviationDoubles[i] += diff * diff;\n            }\n        }\n    }\n    \n    int count = benchmarkResultList.size();\n    for (int i = 0; i < standardDeviationDoubles.length; i++) {\n        standardDeviationDoubles[i] = Math.sqrt(standardDeviationDoubles[i] / count);\n    }\n    \n    return standardDeviationDoubles;\n}\n```\n\nThis function calculates the standard deviation of the average scores from the provided `averageScore` for each level of the score.\n\nIt takes a list of `BenchmarkResult` objects and the `averageScore` as input parameters. It first checks if the `averageScore` is null and throws an `IllegalArgumentException` if it is.\n\nIt then initializes an array `standardDeviationDoubles` with the same length as the number of levels in the `averageScore`.\n\nIt iterates over each `BenchmarkResult` in the list and retrieves the average score. If the score is not null, it calculates the difference between each level of the score and the corresponding level of the `averageScore`, squares the difference, and adds it to the corresponding element in the `standardDeviationDoubles` array.\n\nAfter iterating over all the benchmark results, it divides each element in the `standardDeviationDoubles` array by the count of benchmark results and takes the square root to obtain the standard deviation for each level.\n\nFinally, it returns the array of standard deviation doubles.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/StackMetadata.java-stack": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic StackMetadata stack(ValueSourceInfo... types) {\n    StackMetadata out = new StackMetadata(localVariableHelper);\n    out.stackValueSources.clear();\n    out.stackValueSources.addAll(Arrays.asList(types));\n    out.localVariableValueSources = new ArrayList<>(localVariableValueSources);\n    out.cellVariableValueSources = new ArrayList<>(cellVariableValueSources);\n    out.callKeywordNameList = callKeywordNameList;\n    return out;\n}\n```", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/StackMetadata.java-locals": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic StackMetadata locals(ValueSourceInfo... types) {\n    if (types.length != localVariableValueSources.size()) {\n        throw new IllegalArgumentException(\"Number of provided local types does not match the number of local variables. \" +\n                \"Expected: \" + localVariableValueSources.size() + \", Actual: \" + types.length);\n    }\n    \n    StackMetadata out = copy();\n    out.localVariableValueSources.clear();\n    out.localVariableValueSources.addAll(Arrays.asList(types));\n    return out;\n}\n```\n\nThis function does the following:\n\n1. It checks if the length of the provided `types` array matches the size of `localVariableValueSources`. If they don't match, it throws an `IllegalArgumentException` with a descriptive error message.\n\n2. It creates a copy of the current `StackMetadata` object using the `copy()` method and assigns it to the variable `out`.\n\n3. It clears the `localVariableValueSources` list of the `out` object to remove any existing local variable types.\n\n4. It adds all the elements from the `types` array to the `localVariableValueSources` list of the `out` object using `addAll()` and `Arrays.asList()`.\n\n5. Finally, it returns the modified `out` object, which represents a new `StackMetadata` with the given local types.\n\nThe function ensures that the number of provided local types matches the expected number of local variables, and it replaces the existing local variable types with the new types provided as arguments.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-loadMethod": "Here is the generated code for the `loadMethod` function based on the provided function signature and natural language annotations:\n\n```java\npublic static void loadMethod(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n        int nameIndex) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n    PythonCompiledFunction function = functionMetadata.pythonCompiledFunction;\n    String className = functionMetadata.className;\n\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n            \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n            true);\n    methodVisitor.visitLdcInsn(function.co_names.get(nameIndex));\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n            \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(String.class)),\n            false);\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n    Label blockEnd = new Label();\n\n    methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n\n    // TOS is null; type does not have attribute; do normal attribute lookup\n    // Stack is object, null\n    methodVisitor.visitInsn(Opcodes.POP);\n    ObjectImplementor.getAttribute(functionMetadata, stackMetadata, nameIndex);\n\n    // Stack is method\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n    if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n        // Python 3.11+ swap these\n        methodVisitor.visitInsn(Opcodes.SWAP);\n    }\n\n    methodVisitor.visitLabel(blockEnd);\n\n    // Stack is either:\n    // object, method if it was in type\n    // null, method if it was not in type (Or method, null if Python 3.11+)\n    methodVisitor.visitInsn(Opcodes.SWAP);\n\n    // Stack is now:\n    // method, object if it was in type\n    // method, null if it was not in type (and prior to Python 3.11+)\n    // null, method if it was not in type (if Python 3.11+)\n}\n```\n\nThe `loadMethod` function loads a method named `co_names[namei]` from the object at the top of the stack (TOS). It distinguishes two cases:\n1. If the object has a method with the correct name, it pushes the unbound method and the object onto the stack. The object will be used as the first argument (self) when calling the unbound method using `CALL_METHOD`.\n2. If the object does not have a method with the correct name, it pushes `NULL` and the object returned by the attribute lookup onto the stack.\n\nThe generated code follows the logic described in the natural language annotations, using the provided function metadata and stack metadata to interact with the bytecode and manipulate the stack accordingly.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callMethod": "Here is the generated code for the `callMethod` function based on the provided function signature and natural language annotations:\n\n```java\npublic static void callMethod(FunctionMetadata functionMetadata, StackMetadata stackMetadata, MethodVisitor methodVisitor,\n        PythonBytecodeInstruction instruction) {\n    LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n    int argc = instruction.arg();\n\n    // Stack is method, (obj or null), arg0, ..., arg(argc - 1)\n    CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argc);\n    methodVisitor.visitInsn(Opcodes.SWAP);\n\n    // Stack is method, argList, (obj or null)\n    Label ifNullStart = new Label();\n    Label blockEnd = new Label();\n\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n    methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n    // Stack is method, argList, obj\n    StackManipulationImplementor.duplicateToTOS(functionMetadata, stackMetadata, 1);\n    StackManipulationImplementor.swap(methodVisitor);\n\n    // Stack is method, argList, argList, obj\n    methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n    // Stack is method, argList, argList, obj, index\n    methodVisitor.visitInsn(Opcodes.SWAP);\n\n    // Stack is method, argList, argList, index, obj\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n            \"add\",\n            Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n            true);\n\n    // Stack is method, argList\n    methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n    methodVisitor.visitLabel(ifNullStart);\n    // Stack is method, argList, null\n    methodVisitor.visitInsn(Opcodes.POP);\n\n    // Stack is method, argList\n    methodVisitor.visitLabel(blockEnd);\n\n    methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n            Type.getMethodDescriptor(Type.getType(Map.class)),\n            false);\n\n    // Stack is method, argList\n    getCallerInstance(functionMetadata, stackMetadata);\n\n    // Stack is callable, argument_list, null\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n            \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(List.class),\n                    Type.getType(Map.class),\n                    Type.getType(PythonLikeObject.class)),\n            true);\n}\n```\n\nThe `callMethod` function takes the following parameters:\n- `functionMetadata`: The metadata of the function being compiled.\n- `stackMetadata`: The metadata of the stack at the current point of compilation.\n- `methodVisitor`: The method visitor used to generate the bytecode instructions.\n- `instruction`: The current Python bytecode instruction being processed.\n\nThe function implements the logic to call a method with positional arguments only. It assumes that the method and the arguments are already on the stack, as described in the comments. The function handles two cases: when the method is an unbound method with an associated object (`self`), and when the method is an arbitrary callable with `null` as the associated object.\n\nThe generated code follows the steps described in the natural language annotations to manipulate the stack, prepare the argument list, and invoke the `$call` method on the `PythonLikeFunction` interface to perform the actual method call.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callFunction": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\npublic static void callFunction(FunctionMetadata functionMetadata, StackMetadata stackMetadata, MethodVisitor methodVisitor, int argCount) {\n    // stack is callable, arg0, arg1, ..., arg(argc - 1)\n    CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n            Type.getMethodDescriptor(Type.getType(Map.class)),\n            false);\n    getCallerInstance(functionMetadata, stackMetadata);\n\n    // Stack is callable, argument_list, keyword_args, caller_instance\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n            \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(List.class),\n                    Type.getType(Map.class),\n                    Type.getType(PythonLikeObject.class)),\n            true);\n}\n```\n\nThis function does the following:\n\n1. It assumes that the stack contains the callable function followed by the `argc` number of arguments.\n\n2. It builds a `PythonLikeTuple` collection using the `CollectionImplementor.buildCollection` method, passing the `methodVisitor` and `argCount` as arguments. This creates a tuple containing the function arguments.\n\n3. It invokes the `emptyMap` method of the `Collections` class to get an empty map for the keyword arguments. Since no keyword arguments are provided in this case, an empty map is used.\n\n4. It calls the `getCallerInstance` method to get the caller instance, passing the `functionMetadata` and `stackMetadata` as arguments.\n\n5. Finally, it invokes the `$call` method on the `PythonLikeFunction` interface using `INVOKEINTERFACE` opcode. The `$call` method takes the argument list (`PythonLikeTuple`), keyword arguments map (`Map`), and caller instance (`PythonLikeObject`) as parameters.\n\n6. The result of the function call is pushed onto the stack.\n\nThis function follows the provided natural language annotations and implements the necessary steps to call a function with the given arguments, popping the arguments and the function from the stack, and pushing the result onto the stack.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callFunctionWithKeywords": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\npublic static void callFunctionWithKeywords(FunctionMetadata functionMetadata, StackMetadata stackMetadata) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n\n    // stack is callable, arg0, arg1, ..., arg(argc - len(keys)), ..., arg(argc - 1), keys\n    // We know the total number of arguments, but not the number of individual positional/keyword arguments\n    // Since Java Bytecode require consistent stack frames  (i.e. the body of a loop must start with\n    // the same number of elements in the stack), we need to add the tuple/map in the same object\n    // which will delegate it to either the tuple or the map depending on position and the first item size\n    CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, stackMetadata.getStackSize() - 1);\n\n    // stack is callable, tupleMapPair\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n            Type.getDescriptor(PythonLikeTuple.class));\n\n    // stack is callable, tupleMapPair, positionalArgs\n    methodVisitor.visitInsn(Opcodes.SWAP);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n            Type.getDescriptor(PythonLikeDict.class));\n\n    getCallerInstance(functionMetadata, stackMetadata);\n\n    // Stack is callable, positionalArgs, keywordArgs, caller\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n            \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(List.class),\n                    Type.getType(Map.class),\n                    Type.getType(PythonLikeObject.class)),\n            true);\n}\n```\n\nThe generated function follows the provided annotations:\n\n1. It assumes the stack contains the callable, positional arguments, keyword arguments tuple, and the function to call.\n2. It builds a `TupleMapPair` collection to handle both positional and keyword arguments consistently.\n3. It extracts the positional arguments (`tuple`) and keyword arguments (`map`) from the `TupleMapPair`.\n4. It retrieves the caller instance using `getCallerInstance()`.\n5. Finally, it invokes the `$call` method on the `PythonLikeFunction` interface, passing the positional arguments, keyword arguments, and caller instance.\n6. The result of the function call is pushed onto the stack.\n\nPlease note that this code assumes the existence of the necessary classes and methods, such as `TupleMapPair`, `PythonLikeTuple`, `PythonLikeDict`, `PythonLikeFunction`, and the `getCallerInstance()` method.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callFunctionUnpack": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\npublic static void callFunctionUnpack(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n        MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n    if ((instruction.arg() & 1) != 0) {\n        // TOS is a mapping object containing keyword arguments\n        // TOS[1] is an iterable containing positional arguments\n        // TOS[2] is callable\n        \n        // Swap the order to have callable, positional args, keyword args\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        \n        callFunctionUnpackMapAndIterable(functionMetadata, stackMetadata, methodVisitor);\n    } else {\n        // TOS is an iterable containing positional arguments\n        // TOS[1] is callable\n        \n        // Swap the order to have callable, positional args\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        \n        callFunctionUnpackIterable(functionMetadata, stackMetadata, methodVisitor);\n    }\n}\n```\n\nThe function checks the lowest bit of `instruction.arg()` to determine how the arguments are structured on the stack.\n\nIf the lowest bit is set (i.e., `instruction.arg() & 1` is non-zero), it means that:\n- TOS is a mapping object containing keyword arguments\n- TOS[1] is an iterable containing positional arguments\n- TOS[2] is the callable\n\nIn this case, it rearranges the stack to have the order: callable, positional arguments, keyword arguments. Then it calls the `callFunctionUnpackMapAndIterable` method to handle the function call.\n\nIf the lowest bit is not set, it means that:\n- TOS is an iterable containing positional arguments\n- TOS[1] is the callable\n\nIn this case, it swaps the order to have the callable followed by the positional arguments. Then it calls the `callFunctionUnpackIterable` method to handle the function call.\n\nThe `callFunctionUnpackMapAndIterable` and `callFunctionUnpackIterable` methods are assumed to be defined elsewhere in the class and handle the actual function invocation based on the provided arguments.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/VariableImplementor.java-loadGlobalVariable": "Here is the generated code for the `loadGlobalVariable` function based on the function signature and natural language annotations:\n\n```java\n/**\n * Loads the global variable or parameter indicated by the {@code instruction} argument onto the stack.\n */\npublic static void loadGlobalVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int globalIndex) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n    PythonCompiledFunction pythonCompiledFunction = functionMetadata.pythonCompiledFunction;\n    String className = functionMetadata.className;\n    String globalName = pythonCompiledFunction.co_names.get(globalIndex);\n\n    methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n    methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, className);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, className,\n            PythonBytecodeToJavaBytecodeTranslator.INTERPRETER_INSTANCE_FIELD_NAME,\n            Type.getDescriptor(PythonInterpreter.class));\n    methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, className,\n            PythonBytecodeToJavaBytecodeTranslator.GLOBALS_MAP_STATIC_FIELD_NAME,\n            Type.getDescriptor(Map.class));\n    methodVisitor.visitLdcInsn(globalName);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonInterpreter.class),\n            \"getGlobal\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class), Type.getType(Map.class),\n                    Type.getType(String.class)),\n            true);\n}\n```\n\nThis function does the following:\n\n1. It retrieves the `MethodVisitor`, `PythonCompiledFunction`, and `className` from the `functionMetadata` argument.\n\n2. It gets the name of the global variable from the `co_names` list of the `PythonCompiledFunction` using the `globalIndex` argument.\n\n3. It loads the current instance (`this`) onto the stack using `ALOAD 0` and casts it to the class type specified by `className`.\n\n4. It loads the `PythonInterpreter` instance field onto the stack using `GETFIELD`.\n\n5. It loads the static field representing the globals map onto the stack using `GETSTATIC`.\n\n6. It loads the name of the global variable onto the stack using `LDC`.\n\n7. It invokes the `getGlobal` method of the `PythonInterpreter` interface using `INVOKEINTERFACE`, passing the globals map and the variable name as arguments. This method returns the value of the global variable as a `PythonLikeObject`.\n\nThe result is that the value of the global variable is loaded onto the stack, ready to be used by subsequent instructions.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/VariableImplementor.java-loadCellVariable": "Here is the generated code for the `loadCellVariable` method based on the provided function signature and natural language annotations:\n\n```java\n/**\n * Loads the cell variable/free variable indicated by the {@code instruction} argument onto the stack.\n * (which is an {@link PythonCell}, so it can see changes from the parent function).\n */\npublic static void loadCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n    LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n    localVariableHelper.readCell(methodVisitor, cellIndex);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n            Type.getDescriptor(PythonLikeObject.class));\n}\n```\n\nThe `loadCellVariable` method does the following:\n\n1. It retrieves the `MethodVisitor` and `LocalVariableHelper` instances from the provided `FunctionMetadata` and `StackMetadata` objects, respectively.\n\n2. It calls the `readCell` method of the `LocalVariableHelper` instance, passing the `MethodVisitor` and `cellIndex` as arguments. This loads the `PythonCell` object corresponding to the given `cellIndex` onto the stack.\n\n3. It uses the `visitFieldInsn` method of the `MethodVisitor` to access the `cellValue` field of the `PythonCell` object on the stack. This field represents the actual value of the cell variable or free variable.\n\n4. The `cellValue` field is of type `PythonLikeObject`, so the loaded value is left on the stack as the result of this method.\n\nBy loading the `cellValue` field of the `PythonCell` object, the method ensures that any changes made to the cell variable in the parent function are visible to the dependent functions that access it.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/ObjectImplementor.java-getAttribute": "Here is the generated code for the getAttribute method based on the function signature and natural language annotations:\n\n```java\n/**\n * Replaces TOS with getattr(TOS, co_names[instruction.arg])\n */\npublic static void getAttribute(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int nameIndex) {\n    var methodVisitor = functionMetadata.methodVisitor;\n    PythonLikeType tosType = stackMetadata.getTOSType();\n    String name = functionMetadata.pythonCompiledFunction.co_names.get(nameIndex);\n    Optional<FieldDescriptor> maybeFieldDescriptor = tosType.getInstanceFieldDescriptor(name);\n    if (maybeFieldDescriptor.isPresent()) {\n        FieldDescriptor fieldDescriptor = maybeFieldDescriptor.get();\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, fieldDescriptor.declaringClassInternalName());\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, fieldDescriptor.declaringClassInternalName(),\n                fieldDescriptor.javaFieldName(),\n                fieldDescriptor.javaFieldTypeDescriptor());\n        if (fieldDescriptor.isJavaType()) {\n            // Need to wrap the object\n            methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(JavaObjectWrapper.class),\n                    \"wrap\", Type.getMethodDescriptor(Type.getType(JavaObjectWrapper.class),\n                            Type.getType(Object.class)),\n                    false);\n        }\n        stackMetadata.pop().push(fieldDescriptor.fieldPythonLikeType());\n    } else {\n        PythonConstantsImplementor.loadName(methodVisitor, functionMetadata.className, nameIndex);\n        DunderOperatorImplementor.binaryOperator(methodVisitor,\n                stackMetadata.pushTemp(BuiltinTypes.STRING_TYPE),\n                PythonBinaryOperator.GET_ATTRIBUTE);\n    }\n}\n```\n\nThe getAttribute method replaces the top of the stack (TOS) with the result of calling getattr(TOS, co_names[instruction.arg]).\n\nIt first retrieves the type of the TOS and the name from the co_names array at the specified nameIndex.\n\nIt then checks if the TOS type has an instance field descriptor for the given name. If present, it casts the TOS to the declaring class of the field, gets the field value using the GETFIELD instruction, and if the field is a Java type, wraps it using JavaObjectWrapper. Finally, it updates the stack metadata by popping the TOS and pushing the field's Python-like type.\n\nIf no instance field descriptor is found, it loads the name using PythonConstantsImplementor.loadName and performs the GET_ATTRIBUTE binary operator using DunderOperatorImplementor.binaryOperator. It updates the stack metadata by pushing a temporary value of type STRING_TYPE.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/solution/descriptor/SolutionDescriptor.java-getProblemScale": "Here is the generated function based on the function signature and natural language annotations:\n\n```java\npublic double getProblemScale(ScoreDirector<Solution_> scoreDirector, Solution_ solution) {\n    double problemScale = 0.0;\n    for (EntityDescriptor<Solution_> entityDescriptor : entityDescriptorMap.values()) {\n        List<?> entityList = entityDescriptor.extractEntities(solution);\n        int entityCount = entityList.size();\n        problemScale += Math.log10(entityCount);\n        for (GenuineVariableDescriptor<Solution_> variableDescriptor : entityDescriptor.getGenuineVariableDescriptorList()) {\n            if (variableDescriptor instanceof ListVariableDescriptor) {\n                // The search space size of a list variable is harder to estimate.\n                // Estimate the search space size of 1 element and multiply by the number of elements.\n                double scale = 0.0;\n                for (Object entity : entityList) {\n                    scale += Math.log10(((ListVariableDescriptor<Solution_>) variableDescriptor)\n                            .getListSize(scoreDirector, entity));\n                }\n                problemScale += scale;\n            } else {\n                long valueCount = variableDescriptor.getValueCount(solution);\n                if (valueCount > 1L) {\n                    // The search space of a nullable variable is multiplied by 1.\n                    // The search space of a chained variable is multiplied by the number of instances it can chain to.\n                    problemScale += Math.log10(valueCount) * entityCount;\n                }\n            }\n        }\n    }\n    return problemScale;\n}\n```\n\nThis function calculates an approximate indication of the problem scale or size based on the number of entities and the search space size of each planning variable.\n\nIt iterates through each `EntityDescriptor` and extracts the entities from the solution. It adds the log base 10 of the entity count to the `problemScale`.\n\nThen for each genuine planning variable (excluding shadow variables), it estimates the search space size:\n- For list variables, it estimates the search space size of one element and multiplies it by the number of elements in the list.\n- For other variables, it gets the value count and multiplies the log base 10 of the value count by the number of entities if the value count is greater than 1. \n\nFinally, it returns the calculated `problemScale` which is an approximation of the base 10 log of the total search space size. This gives an indication of the problem size or scale.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/solution/cloner/gizmo/GizmoSolutionClonerImplementor.java-defineClonerFor": "Here is the generated code for the `defineClonerFor` method based on the function signature and natural language annotations:\n\n```java\n/**\n * Generates the constructor and implementations of SolutionCloner\n * methods for the given SolutionDescriptor using the given ClassCreator\n */\npublic static void defineClonerFor(Supplier<GizmoSolutionClonerImplementor> implementorSupplier,\n        ClassCreator classCreator,\n        SolutionDescriptor<?> solutionDescriptor,\n        Set<Class<?>> solutionClassSet,\n        Map<Class<?>, GizmoSolutionOrEntityDescriptor> memoizedSolutionOrEntityDescriptorMap,\n        Set<Class<?>> deepClonedClassSet) {\n    GizmoSolutionClonerImplementor implementor = implementorSupplier.get();\n    // Classes that are not instances of any other class in the collection\n    // have a subclass level of 0.\n    // Other classes subclass level is the maximum of the subclass level\n    // of the classes it is a subclass of + 1\n    Set<Class<?>> deepCloneClassesThatAreNotSolutionSet =\n            deepClonedClassSet.stream()\n                    .filter(clazz -> !solutionClassSet.contains(clazz) && !clazz.isArray())\n                    .filter(clazz -> !clazz.isInterface() && !Modifier.isAbstract(clazz.getModifiers()))\n                    .collect(Collectors.toSet());\n\n    Comparator<Class<?>> instanceOfComparator = getInstanceOfComparator(deepClonedClassSet);\n    SortedSet<Class<?>> deepCloneClassesThatAreNotSolutionSortedSet = new TreeSet<>(instanceOfComparator);\n    deepCloneClassesThatAreNotSolutionSortedSet.addAll(deepCloneClassesThatAreNotSolutionSet);\n\n    implementor.createFields(classCreator);\n    implementor.createConstructor(classCreator);\n    implementor.createSetSolutionDescriptor(classCreator, solutionDescriptor);\n    implementor.createCloneSolution(classCreator, solutionDescriptor);\n    implementor.createCloneSolutionRun(classCreator, solutionDescriptor, solutionClassSet,\n            memoizedSolutionOrEntityDescriptorMap,\n            deepCloneClassesThatAreNotSolutionSortedSet, instanceOfComparator);\n\n    for (Class<?> deepClonedClass : deepCloneClassesThatAreNotSolutionSortedSet) {\n        implementor.createDeepCloneHelperMethod(classCreator, deepClonedClass, solutionDescriptor,\n                memoizedSolutionOrEntityDescriptorMap,\n                deepCloneClassesThatAreNotSolutionSortedSet);\n    }\n\n    Set<Class<?>> abstractDeepCloneClassSet =\n            deepClonedClassSet.stream()\n                    .filter(clazz -> !solutionClassSet.contains(clazz) && !clazz.isArray())\n                    .filter(clazz -> clazz.isInterface() || Modifier.isAbstract(clazz.getModifiers()))\n                    .collect(Collectors.toSet());\n\n    for (Class<?> abstractDeepClonedClass : abstractDeepCloneClassSet) {\n        implementor.createAbstractDeepCloneHelperMethod(classCreator, abstractDeepClonedClass, solutionDescriptor,\n                memoizedSolutionOrEntityDescriptorMap,\n                deepCloneClassesThatAreNotSolutionSortedSet);\n    }\n}\n```\n\nThe `defineClonerFor` method generates the constructor and implementations of the `SolutionCloner` methods for the given `SolutionDescriptor` using the provided `ClassCreator`. It utilizes the `GizmoSolutionClonerImplementor` to create the necessary fields, constructor, and methods for cloning the solution and its associated classes.\n\nThe method first filters and sorts the deep cloned classes that are not part of the solution", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/variable/listener/support/violation/ShadowVariablesAssert.java-createShadowVariablesViolationMessage": "Here is the generated code for the `createShadowVariablesViolationMessage` method based on the function signature and natural language annotations:\n\n```java\npublic String createShadowVariablesViolationMessage(long violationDisplayLimit) {\n    Map<ShadowVariableDescriptor<?>, List<String>> violationListMap = collectViolations();\n    if (violationListMap.isEmpty()) {\n        return null;\n    }\n    return format(violationListMap, violationDisplayLimit);\n}\n```", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/MemberAccessorFactory.java-buildAndCacheMemberAccessor": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic MemberAccessor buildAndCacheMemberAccessor(Member member, MemberAccessorType memberAccessorType,\n        Class<? extends Annotation> annotationClass, DomainAccessType domainAccessType) {\n    String generatedClassName = GizmoMemberAccessorFactory.getGeneratedClassName(member);\n    return memberAccessorCache.computeIfAbsent(generatedClassName,\n            k -> MemberAccessorFactory.buildMemberAccessor(member, memberAccessorType, annotationClass, domainAccessType, gizmoClassLoader));\n}\n```\n\nThis function does the following:\n\n1. It takes the `member` (method or field to access), `memberAccessorType`, `annotationClass` (the annotation the member was annotated with, used for error reporting), and `domainAccessType` as parameters.\n\n2. It generates a unique class name for the member using `GizmoMemberAccessorFactory.getGeneratedClassName(member)` and stores it in the `generatedClassName` variable.\n\n3. It uses `memberAccessorCache.computeIfAbsent()` to retrieve the `MemberAccessor` instance from the cache based on the `generatedClassName` key. If the `MemberAccessor` is not found in the cache, it computes a new value by calling `MemberAccessorFactory.buildMemberAccessor()` with the provided parameters (`member`, `memberAccessorType`, `annotationClass`, `domainAccessType`, `gizmoClassLoader`).\n\n4. Finally, it returns the `MemberAccessor` instance, either from the cache or newly created.\n\nThe function caches the result to avoid creating new `MemberAccessor` instances for the same member repeatedly. It uses the `memberAccessorCache` map to store and retrieve the cached instances based on the generated class name.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/gizmo/GizmoMemberAccessorFactory.java-getGeneratedClassName": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static String getGeneratedClassName(Member member) {\n    Objects.requireNonNull(member);\n    Class<?> declaringClass = member.getDeclaringClass();\n    String memberName = member.getName();\n    if (member instanceof Field) {\n        return declaringClass.getName().replace('.', '_') + \"_\" + memberName + \"_FieldAccessor\";\n    } else {\n        // Assuming it's a method, but you can add more cases if needed\n        return declaringClass.getName().replace('.', '_') + \"_\" + memberName + \"_MethodAccessor\";\n    }\n}\n```\n\nThis function does the following:\n\n1. It takes a `Member` object as a parameter, which represents a member (field or method) of a class.\n\n2. It checks if the `member` is not null using `Objects.requireNonNull()` to ensure a valid input.\n\n3. It retrieves the declaring class of the member using `member.getDeclaringClass()` and stores it in the `declaringClass` variable.\n\n4. It retrieves the name of the member using `member.getName()` and stores it in the `memberName` variable.\n\n5. It checks if the `member` is an instance of `Field` using the `instanceof` operator.\n   - If it is a field, it generates the class name by replacing dots (`.`) with underscores (`_`) in the declaring class name, appending an underscore (`_`), the member name, and the suffix `\"_FieldAccessor\"`.\n\n6. If the `member` is not a field (assuming it's a method in this case), it generates the class name similarly but with the suffix `\"_MethodAccessor\"`.\n\n7. Finally, it returns the generated class name as a string.\n\nNote: This implementation assumes that the `member` is either a field or a method. If there are other types of members that need to be handled differently, additional cases can be added to the function.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/gizmo/GizmoMemberAccessorImplementor.java-createAccessorFor": "Here is the generated code for the `createAccessorFor` method based on the function signature and natural language annotations:\n\n```java\nstatic MemberAccessor createAccessorFor(Member member, Class<? extends Annotation> annotationClass,\n        boolean returnTypeRequired, GizmoClassLoader gizmoClassLoader) {\n    GizmoMemberInfo memberInfo = new GizmoMemberInfo(member, annotationClass, returnTypeRequired);\n    String className = GizmoMemberAccessorImplementor.class.getName() + \"$Accessor$\" + member.getName();\n    return createInstance(className, () -> {\n        ClassOutput classOutput = gizmoClassLoader.getClassOutput();\n        defineAccessorFor(className, classOutput, memberInfo);\n    }, gizmoClassLoader);\n}\n\nprivate static MemberAccessor createInstance(String className, Runnable generator, GizmoClassLoader gizmoClassLoader) {\n    MutableReference<MemberAccessor> instanceRef = new MutableReference<>();\n    gizmoClassLoader.writeClass(className, classOutput -> {\n        generator.run();\n        instanceRef.setValue(createInstance(className, gizmoClassLoader));\n    });\n    return instanceRef.getValue();\n}\n```\n\nThis method does the following:\n\n1. It creates a `GizmoMemberInfo` instance that encapsulates the information about the member, the annotation class, and whether the return type is required.\n\n2. It generates a unique class name for the accessor class based on the member name.\n\n3. It calls the `createInstance` method, passing the class name, a `Runnable` that generates the bytecode for the accessor class, and the `GizmoClassLoader`.\n\n4. Inside the `createInstance` method:\n   - It creates a `MutableReference` to hold the generated `MemberAccessor` instance.\n   - It uses the `GizmoClassLoader` to write the bytecode for the accessor class by invoking the `writeClass` method.\n   - Inside the `writeClass` method, it runs the `generator` `Runnable` to generate the bytecode for the accessor class using the `defineAccessorFor` method.\n   - After the bytecode is generated, it creates an instance of the accessor class using the `createInstance` method and stores it in the `MutableReference`.\n   - Finally, it returns the generated `MemberAccessor` instance from the `MutableReference`.\n\n5. The generated `MemberAccessor` instance is returned.\n\nThis code generates the bytecode for the accessor class on-the-fly using Gizmo when the `createAccessorFor` method is called for the first time for a given member. The bytecode is generated based on the member information provided by the `GizmoMemberInfo` instance. The generated accessor class is then instantiated and returned as a `MemberAccessor` instance.\n\nNote: The code assumes the existence of the `GizmoMemberInfo` class and the `defineAccessorFor` method, which are responsible for generating the actual bytecode for the accessor class.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/BestSolutionHolder.java-set": "Here is the generated code for the `set` method based on the function signature and natural language annotations:\n\n```java\nvoid set(Solution_ bestSolution, BooleanSupplier isEveryProblemChangeProcessed) {\n    problemChangesLock.lock();\n    try {\n        if (isEveryProblemChangeProcessed.getAsBoolean()) {\n            BigInteger newVersion = currentVersion.add(BigInteger.ONE);\n            versionedBestSolutionRef.set(new VersionedBestSolution<>(bestSolution, newVersion));\n            currentVersion = newVersion;\n        }\n    } finally {\n        problemChangesLock.unlock();\n    }\n}\n```\n\nExplanation:\n1. The method takes a `bestSolution` parameter of type `Solution_` and an `isEveryProblemChangeProcessed` parameter of type `BooleanSupplier`.\n2. It acquires the `problemChangesLock` to ensure thread-safety while updating the best solution and version.\n3. It checks if all problem changes have been processed by calling `isEveryProblemChangeProcessed.getAsBoolean()`.\n4. If all problem changes have been processed:\n   - It creates a new version by incrementing the `currentVersion` by one.\n   - It creates a new `VersionedBestSolution` object with the `bestSolution` and the new version.\n   - It updates the `versionedBestSolutionRef` with the new `VersionedBestSolution` using `versionedBestSolutionRef.set()`.\n   - It updates the `currentVersion` to the new version.\n5. Finally, it releases the `problemChangesLock` in the `finally` block to ensure the lock is always released, even if an exception occurs.\n\nThis implementation ensures that the new best solution is set only if all known problem changes have been processed, as indicated by the `isEveryProblemChangeProcessed` supplier. It also updates the version of the best solution accordingly.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/BestSolutionHolder.java-addProblemChange": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\nCompletableFuture<Void> addProblemChange(Solver<Solution_> solver, ProblemChange<Solution_> problemChange) {\n    problemChangesLock.lock();\n    try {\n        CompletableFuture<Void> future = new CompletableFuture<>();\n        problemChangesPerVersion.computeIfAbsent(currentVersion, key -> new ArrayList<>()).add(future);\n        currentVersion = currentVersion.add(BigInteger.ONE);\n        solver.addProblemChange(problemChange);\n        return future;\n    } finally {\n        problemChangesLock.unlock();\n    }\n}\n```\n\nThis function does the following:\n\n1. It acquires the `problemChangesLock` to ensure thread-safety when modifying the `problemChangesPerVersion` map.\n\n2. It creates a new `CompletableFuture` called `future` that will be completed when the best solution containing this problem change is passed to a user-defined Consumer.\n\n3. It adds the `future` to the list of problem changes associated with the current version in the `problemChangesPerVersion` map. If the current version doesn't exist in the map, it creates a new list for that version using `computeIfAbsent()`.\n\n4. It increments the `currentVersion` by one using `currentVersion.add(BigInteger.ONE)` to keep track of the version of the problem change.\n\n5. It adds the `problemChange` to the `solver` using `solver.addProblemChange(problemChange)`.\n\n6. Finally, it releases the `problemChangesLock` in the `finally` block to ensure the lock is always released, even if an exception occurs.\n\n7. It returns the `future` that will be completed when the best solution containing this problem change is passed to a user-defined Consumer.\n\nThis function allows adding a new problem change to the solver and registering it to be retrieved later together with the relevant best solution using the `take()` method.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/random/RandomUtils.java-nextLong": "Here is the generated function based on the signature and natural language annotations:\n\n```java\n/**\n * Mimics {@link Random#nextInt(int)} for longs.\n *\n * @param random never null\n * @param n {@code > 0L}\n * @return like {@link Random#nextInt(int)} but for a long\n * @see Random#nextInt(int)\n */\npublic static long nextLong(Random random, long n) {\n    // This code is based on java.util.Random#nextInt(int)'s javadoc.\n    if (n <= 0L) {\n        throw new IllegalArgumentException(\"n must be positive\");\n    }\n    long bits, val;\n    do {\n        bits = (random.nextLong() << 1) >>> 1;\n        val = bits % n;\n    } while (bits - val + (n - 1) < 0L);\n    return val;\n}\n```\n\nThe generated function follows a similar approach to the `nextDouble` method in the provided code. Here's how it works:\n\n1. It first checks if the input `n` is less than or equal to 0. If so, it throws an `IllegalArgumentException` with an appropriate message.\n\n2. It then enters a loop to generate a random long value within the range of `[0, n)`.\n\n3. Inside the loop, it generates a random long value using `random.nextLong()`. It then applies a bitwise operation `(<< 1) >>> 1` to ensure the value is non-negative by discarding the sign bit.\n\n4. It calculates `val` by taking the modulo of `bits` with `n`, which gives a value between `[0, n)`.\n\n5. The loop continues until the condition `bits - val + (n - 1) < 0L` is false. This condition ensures that the generated value is uniformly distributed within the range `[0, n)`.\n\n6. Finally, it returns the generated `val`, which is a random long value between `[0, n)`.\n\nThis implementation mimics the behavior of `Random#nextInt(int)` but for longs, as described in the natural language annotations.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/AndCompositeTermination.java-calculateSolverTimeGradient": "Here is the generated function based on the signature and natural language annotations:\n\n```java\n@Override\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    double minimumTimeGradient = Double.MAX_VALUE;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculateSolverTimeGradient(solverScope);\n        if (timeGradient >= 0.0) {\n            minimumTimeGradient = Math.min(minimumTimeGradient, timeGradient);\n        }\n    }\n    return minimumTimeGradient == Double.MAX_VALUE ? -1.0 : minimumTimeGradient;\n}\n```\n\nThe function does the following:\n\n1. It initializes a `minimumTimeGradient` variable to `Double.MAX_VALUE` to keep track of the minimum time gradient among all terminations.\n\n2. It iterates over each `Termination` in the `terminationList`.\n\n3. For each termination, it calls the `calculateSolverTimeGradient` method, passing the `solverScope` as an argument, to get the time gradient of that termination.\n\n4. If the time gradient is greater than or equal to 0.0 (indicating a supported time gradient), it updates the `minimumTimeGradient` using `Math.min` to keep the minimum value.\n\n5. After iterating through all terminations, if the `minimumTimeGradient` is still `Double.MAX_VALUE`, it means no supported time gradients were found, so it returns -1.0. Otherwise, it returns the `minimumTimeGradient`.\n\nThis implementation follows the natural language annotations by calculating the minimum time gradient among all terminations, ignoring unsupported time gradients (-1.0), and returning the minimum value or -1.0 if no supported time gradients were found.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/AndCompositeTermination.java-calculatePhaseTimeGradient": "Here is the generated code for the `calculatePhaseTimeGradient` method based on the function signature and natural language annotations:\n\n```java\n@Override\npublic double calculatePhaseTimeGradient(AbstractPhaseScope<Solution_> phaseScope) {\n    double minimumTimeGradient = Double.MAX_VALUE;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculatePhaseTimeGradient(phaseScope);\n        if (timeGradient >= 0.0) {\n            minimumTimeGradient = Math.min(minimumTimeGradient, timeGradient);\n        }\n    }\n    return minimumTimeGradient == Double.MAX_VALUE ? -1.0 : minimumTimeGradient;\n}\n```\n\nThe method does the following:\n\n1. It initializes a variable `minimumTimeGradient` to `Double.MAX_VALUE` to keep track of the minimum time gradient among all terminations.\n\n2. It iterates over each termination in the `terminationList`.\n\n3. For each termination, it calls the `calculatePhaseTimeGradient` method, passing the `phaseScope` as an argument, to get the time gradient of that termination.\n\n4. If the time gradient is greater than or equal to 0.0 (supported), it updates the `minimumTimeGradient` by taking the minimum value between the current `minimumTimeGradient` and the time gradient of the current termination.\n\n5. After iterating over all terminations, it checks if the `minimumTimeGradient` is still equal to `Double.MAX_VALUE`. If it is, it means no supported time gradient was found, so it returns -1.0. Otherwise, it returns the `minimumTimeGradient`.\n\nThis implementation calculates the minimum time gradient among all terminations, ignoring any unsupported time gradients (-1.0), as specified in the natural language annotations.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/OrCompositeTermination.java-calculateSolverTimeGradient": "Here is the generated code for the `calculateSolverTimeGradient` method based on the function signature and natural language annotations:\n\n```java\n@Override\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    double maxTimeGradient = -1.0;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculateSolverTimeGradient(solverScope);\n        if (timeGradient >= 0.0) {\n            maxTimeGradient = Math.max(maxTimeGradient, timeGradient);\n        }\n    }\n    return maxTimeGradient;\n}\n```", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/OrCompositeTermination.java-calculatePhaseTimeGradient": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n@Override\npublic double calculatePhaseTimeGradient(AbstractPhaseScope<Solution_> phaseScope) {\n    double maxTimeGradient = -1.0;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculatePhaseTimeGradient(phaseScope);\n        if (timeGradient >= 0.0) {\n            maxTimeGradient = Math.max(maxTimeGradient, timeGradient);\n        }\n    }\n    return maxTimeGradient;\n}\n```", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/heuristic/selector/move/generic/list/kopt/KOptUtils.java-getCyclesForPermutation": "Here is the generated code for the getCyclesForPermutation function:\n\n```java\nstatic KOptCycle getCyclesForPermutation(KOptDescriptor<?> kOptDescriptor) {\n    int[] removedEdgeIndexToTourOrder = kOptDescriptor.removedEdgeIndexToTourOrder();\n    int k = kOptDescriptor.k();\n    \n    KOptCycle kOptCycle = new KOptCycle(k);\n    BitSet visited = new BitSet(2 * k + 1);\n    \n    for (int i = 1; i <= 2 * k; i++) {\n        if (!visited.get(i)) {\n            List<Integer> cycle = new ArrayList<>();\n            int current = i;\n            do {\n                cycle.add(current);\n                visited.set(current);\n                current = removedEdgeIndexToTourOrder[current];\n            } while (current != i);\n            kOptCycle.addCycle(cycle);\n        }\n    }\n    \n    return kOptCycle;\n}\n```\n\nThe function works as follows:\n\n1. It retrieves the `removedEdgeIndexToTourOrder` array and the value of `k` from the `kOptDescriptor`.\n\n2. It creates a new `KOptCycle` object with the given `k` value to store the cycles.\n\n3. It initializes a `BitSet` called `visited` to keep track of the visited elements.\n\n4. It iterates from 1 to 2*k (inclusive):\n   - If the current element `i` has not been visited yet:\n     - It creates a new list `cycle` to store the elements of the current cycle.\n     - It starts from the current element `i` and follows the permutation mapping until it reaches `i` again:\n       - It adds the current element to the `cycle` list.\n       - It marks the current element as visited in the `visited` BitSet.\n       - It updates the `current` element to the next element according to the `removedEdgeIndexToTourOrder` mapping.\n     - Once the cycle is complete, it adds the `cycle` list to the `kOptCycle` object.\n\n5. Finally, it returns the `kOptCycle` object containing all the disjoint k-cycles.\n\nThe function calculates the disjoint k-cycles by following the permutation mapping defined by `removedEdgeIndexToTourOrder`. It starts from each unvisited element and follows the mapping until it reaches the starting element again, forming a cycle. The cycles are stored in the `KOptCycle` object and returned.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/heuristic/selector/list/TriangleElementFactory.java-nextElement": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\nTriangleElement nextElement(int listSize) throws IllegalArgumentException {\n    if (listSize < minimumSubListSize) {\n        throw new IllegalArgumentException(\"The listSize (\" + listSize + \") must be greater than or equal to the minimumSubListSize (\" + minimumSubListSize + \").\");\n    }\n\n    int maxLevel = (int) Math.ceil(triangularRoot(listSize));\n    int minLevel = (int) Math.ceil(triangularRoot(minimumSubListSize));\n\n    int level;\n    do {\n        level = workingRandom.nextInt(maxLevel - minLevel + 1) + minLevel;\n    } while (nthTriangle(level) > listSize);\n\n    int indexOnLevel = workingRandom.nextInt(level + 1);\n    int index = nthTriangle(level - 1) + indexOnLevel;\n\n    return new TriangleElement(index, level, indexOnLevel);\n}\n```\n\nExplanation:\n1. First, we check if the `listSize` is less than the `minimumSubListSize`. If it is, we throw an `IllegalArgumentException` with an appropriate error message.\n\n2. We calculate the maximum level (`maxLevel`) and minimum level (`minLevel`) based on the `listSize` and `minimumSubListSize` using the `triangularRoot` function.\n\n3. We generate a random level within the range of `minLevel` and `maxLevel` (inclusive) using `workingRandom.nextInt()`. We repeat this step until we get a level whose corresponding triangle number is less than or equal to `listSize`.\n\n4. We generate a random index on the selected level using `workingRandom.nextInt()`.\n\n5. We calculate the actual index in the triangle by adding the triangle number of the previous level (`nthTriangle(level - 1)`) to the generated index on the current level (`indexOnLevel`).\n\n6. Finally, we create a new `TriangleElement` instance with the calculated `index`, `level`, and `indexOnLevel`, and return it.\n\nThis function produces a random element from the triangle of size `listSize`, while ensuring that the selected element corresponds to a sublist size between `minimumSubListSize` and `maximumSubListSize`.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/constraint/ConstraintMatch.java-getJustificationList": "Here is the generated function based on the signature and natural language annotations:\n\n```java\n@Deprecated(forRemoval = true)\npublic List<Object> getJustificationList() {\n    if (justification instanceof DefaultConstraintJustification) {\n        return ((DefaultConstraintJustification) justification).getFacts();\n    } else {\n        throw new UnsupportedOperationException(\"Cannot call getJustificationList() on a custom justification mapping. \" +\n                \"Use getJustification() or getIndictedObjectList() instead.\");\n    }\n}\n```\n\nThe function does the following:\n\n1. It checks if the `justification` field is an instance of `DefaultConstraintJustification`.\n   - If it is, it casts `justification` to `DefaultConstraintJustification` and returns the result of calling `getFacts()` on it. This returns the list of facts from the matching tuple for constraint streams.\n   \n2. If `justification` is not an instance of `DefaultConstraintJustification`, it means a custom justification mapping was provided. In this case, it throws an `UnsupportedOperationException` with a message indicating that `getJustificationList()` cannot be called on a custom justification mapping and suggests using `getJustification()` or `getIndictedObjectList()` instead.\n\nThe function is annotated with `@Deprecated(forRemoval = true)` to indicate that it is deprecated and will be removed in the future. The Javadoc comment explains the different behavior of the method based on the score director the constraint comes from and suggests using `getJustification()` or `getIndictedObjectList()` instead.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/stream/ConstraintCollectors.java-compose": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static <A, Result_, SubResultContainer1_, SubResultContainer2_, SubResult1_, SubResult2_>\n        UniConstraintCollector<A, ?, Result_> compose(\n                UniConstraintCollector<A, SubResultContainer1_, SubResult1_> subCollector1,\n                UniConstraintCollector<A, SubResultContainer2_, SubResult2_> subCollector2,\n                BiFunction<SubResult1_, SubResult2_, Result_> composeFunction) {\n    return new UniConstraintCollector<A, Object, Result_>() {\n        @Override\n        public Supplier<Object> supplier() {\n            final Supplier<SubResultContainer1_> subResultContainer1Supplier = subCollector1.supplier();\n            final Supplier<SubResultContainer2_> subResultContainer2Supplier = subCollector2.supplier();\n            return () -> new Object[] {subResultContainer1Supplier.get(), subResultContainer2Supplier.get()};\n        }\n\n        @Override\n        public BiFunction<Object, A, Object> accumulator() {\n            final BiFunction<SubResultContainer1_, A, SubResultContainer1_> accumulator1 = subCollector1.accumulator();\n            final BiFunction<SubResultContainer2_, A, SubResultContainer2_> accumulator2 = subCollector2.accumulator();\n            return (resultContainer, a) -> {\n                Object[] tuple = (Object[]) resultContainer;\n                tuple[0] = accumulator1.apply((SubResultContainer1_) tuple[0], a);\n                tuple[1] = accumulator2.apply((SubResultContainer2_) tuple[1], a);\n                return tuple;\n            };\n        }\n\n        @Override\n        public Function<Object, Result_> finisher() {\n            final Function<SubResultContainer1_, SubResult1_> finisher1 = subCollector1.finisher();\n            final Function<SubResultContainer2_, SubResult2_> finisher2 = subCollector2.finisher();\n            return resultContainer -> {\n                Object[] tuple = (Object[]) resultContainer;\n                return composeFunction.apply(finisher1.apply((SubResultContainer1_) tuple[0]),\n                        finisher2.apply((SubResultContainer2_) tuple[1]));\n            };\n        }\n    };\n}\n```\n\nThis `compose` method takes two sub-collectors (`subCollector1` and `subCollector2`) and a `composeFunction` that combines the results of the sub-collectors into a final result.\n\nThe `supplier` method creates an array to hold the result containers of the sub-collectors. \n\nThe `accumulator` method applies the accumulators of the sub-collectors to the input fact `a` and updates the corresponding elements in the result container array.\n\nFinally, the `finisher` method applies the finishers of the sub-collectors to the result containers and passes the results to the `composeFunction` to produce the final result.\n\nThe return value and default return value of this collector depend on the `composeFunction` provided.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/stream/ConstraintCollectors.java-toConnectedRanges": "Here is the generated function based on the signature and natural language annotations:\n\n```java\npublic static <A, PointType_ extends Comparable<PointType_>, DifferenceType_ extends Comparable<DifferenceType_>>\n        UniConstraintCollector<A, ?, ConnectedRangeChain<A, PointType_, DifferenceType_>>\n        toConnectedRanges(Function<A, PointType_> startInclusiveMap, Function<A, PointType_> endExclusiveMap,\n                          BiFunction<PointType_, PointType_, DifferenceType_> differenceFunction) {\n    return new UniConstraintCollector<A, List<Range<A, PointType_>>, ConnectedRangeChain<A, PointType_, DifferenceType_>>() {\n        @Override\n        public Supplier<List<Range<A, PointType_>>> supplier() {\n            return ArrayList::new;\n        }\n\n        @Override\n        public BiFunction<List<Range<A, PointType_>>, A, List<Range<A, PointType_>>> accumulator() {\n            return (list, a) -> {\n                PointType_ start = startInclusiveMap.apply(a);\n                PointType_ end = endExclusiveMap.apply(a);\n                list.add(new Range<>(a, start, end));\n                return list;\n            };\n        }\n\n        @Override\n        public BinaryOperator<List<Range<A, PointType_>>> combiner() {\n            return (list1, list2) -> {\n                list1.addAll(list2);\n                return list1;\n            };\n        }\n\n        @Override\n        public Function<List<Range<A, PointType_>>, ConnectedRangeChain<A, PointType_, DifferenceType_>> finisher() {\n            return list -> new ConnectedRangeChain<>(list, differenceFunction);\n        }\n    };\n}\n```\n\nThe key points:\n- It uses the `UniConstraintCollector` to collect the ranges and build the `ConnectedRangeChain`.\n- The `supplier` creates a new `ArrayList` to hold the ranges.\n- The `accumulator` creates a `Range` object for each fact using the provided start/end mapping functions and adds it to the list.\n- The `combiner` simply combines two lists of ranges.\n- The `finisher` constructs the `ConnectedRangeChain` from the list of ranges and the provided `differenceFunction`.\n\nThis should implement the logic described in the natural language annotations to collect ranges of facts and return a `ConnectedRangeChain` containing information about overlaps, concurrent usage, and breaks between the ranges.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/analysis/ScoreAnalysis.java-diff": "Here is the generated code for the `diff` method based on the function signature and natural language annotations:\n\n```java\npublic ScoreAnalysis<Score_> diff(ScoreAnalysis<Score_> other) {\n    Objects.requireNonNull(other, \"other must not be null\");\n\n    Score_ diffScore = score.subtract(other.score);\n\n    Map<ConstraintRef, ConstraintAnalysis<Score_>> diffConstraintMap = new HashMap<>();\n\n    Stream.concat(constraintMap.entrySet().stream(), other.constraintMap.entrySet().stream())\n            .forEach(entry -> {\n                ConstraintRef constraintRef = entry.getKey();\n                ConstraintAnalysis<Score_> thisConstraintAnalysis = constraintMap.get(constraintRef);\n                ConstraintAnalysis<Score_> otherConstraintAnalysis = other.constraintMap.get(constraintRef);\n\n                if (thisConstraintAnalysis == null) {\n                    diffConstraintMap.put(constraintRef, otherConstraintAnalysis.negate());\n                } else if (otherConstraintAnalysis == null) {\n                    diffConstraintMap.put(constraintRef, thisConstraintAnalysis);\n                } else {\n                    ConstraintAnalysis<Score_> diffConstraintAnalysis = thisConstraintAnalysis.diff(otherConstraintAnalysis);\n                    if (!diffConstraintAnalysis.isEmpty()) {\n                        diffConstraintMap.put(constraintRef, diffConstraintAnalysis);\n                    }\n                }\n            });\n\n    return new ScoreAnalysis<>(diffScore, diffConstraintMap);\n}\n```\n\nThis implementation does the following:\n\n1. It checks that the `other` parameter is not null.\n\n2. It calculates the difference between the scores of `this` and `other` using the `subtract` method of the `Score` class.\n\n3. It creates a new `Map` called `diffConstraintMap` to store the differences between the constraint analyses.\n\n4. It iterates over the entries of both `constraintMap` and `other.constraintMap` using `Stream.concat` and `forEach`.\n\n5. For each constraint reference, it retrieves the corresponding `ConstraintAnalysis` from `this` and `other`.\n\n6. If `thisConstraintAnalysis` is null, it means the constraint is present only in `other`, so it adds the negated `otherConstraintAnalysis` to `diffConstraintMap`.\n\n7. If `otherConstraintAnalysis` is null, it means the constraint is present only in `this`, so it adds `thisConstraintAnalysis` to `diffConstraintMap`.\n\n8. If both `thisConstraintAnalysis` and `otherConstraintAnalysis` are non-null, it calculates the difference between them using the `diff` method of `ConstraintAnalysis`. If the resulting `diffConstraintAnalysis` is not empty, it adds it to `diffConstraintMap`.\n\n9. Finally, it creates and returns a new `ScoreAnalysis` instance with the calculated `diffScore` and `diffConstraintMap`.\n\nNote: This implementation assumes the existence of a `diff` method in the `ConstraintAnalysis` class and a `negate` method in the `ConstraintAnalysis` class. It also assumes that the `ConstraintJustification` class correctly implements equality and hash code methods.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/analysis/ScoreAnalysis.java-summarize": "Here is the generated code for the `summarize()` method based on the function signature and natural language annotations:\n\n```java\n@SuppressWarnings(\"java:S3457\")    \npublic String summarize() {\n    StringBuilder summary = new StringBuilder();\n    summary.append(\"Score analysis for score \").append(score).append(\"\\n\");\n    \n    for (ConstraintAnalysis<Score_> constraintAnalysis : constraintAnalyses()) {\n        summary.append(\"Constraint [\").append(constraintAnalysis.constraintRef()).append(\"]:\\n\");\n        summary.append(\"  - Score: \").append(constraintAnalysis.score()).append(\"\\n\");\n        summary.append(\"  - Weight: \").append(constraintAnalysis.weight()).append(\"\\n\");\n        summary.append(\"  - Number of matches: \").append(constraintAnalysis.matchCount()).append(\"\\n\");\n        \n        int matchCount = 0;\n        for (MatchAnalysis<Score_> matchAnalysis : constraintAnalysis.matchAnalyses()) {\n            if (matchCount >= DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT) {\n                summary.append(\"  - ... \").append(constraintAnalysis.matchCount() - matchCount)\n                        .append(\" more matches\\n\");\n                break;\n            }\n            summary.append(\"  - Match \").append(++matchCount).append(\":\\n\");\n            summary.append(\"    - Score: \").append(matchAnalysis.score()).append(\"\\n\");\n            summary.append(\"    - Justifications: \").append(matchAnalysis.justificationList()).append(\"\\n\");\n        }\n    }\n    \n    return summary.toString();\n}\n```\n\nThe `summarize()` method generates a diagnostic text that explains the solution through the `ConstraintAnalysis` API. It provides an overview of the score analysis, including the overall score, and details for each constraint.\n\nFor each constraint, it includes the constraint reference, score, weight, and the number of matches. It then iterates over the matches (up to a default limit) and provides the score and justifications for each match.\n\nThe generated summary is built using a `StringBuilder` and returned as a string. The method is annotated with `@SuppressWarnings(\"java:S3457\")` to suppress the warning about using a `StringBuilder` instead of directly concatenating strings.\n\nNote: The generated code assumes the existence of constants and methods such as `DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT`, `constraintAnalyses()`, `matchAnalyses()`, etc., which should be defined elsewhere in the class or imported from the appropriate classes.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/analysis/ConstraintAnalysis.java-summarize": "Here is the generated code for the `summarize()` method based on the provided function signature and natural language annotations:\n\n```java\n@SuppressWarnings(\"java:S3457\")\npublic String summarize() {\n    StringBuilder summary = new StringBuilder();\n    summary.append(\"Constraint Analysis for \").append(constraintRef).append(\":\\n\");\n    summary.append(\"  - Weight: \").append(weight).append(\"\\n\");\n    summary.append(\"  - Score: \").append(score).append(\"\\n\");\n    if (matches == null) {\n        summary.append(\"  - No matches available\\n\");\n    } else {\n        summary.append(\"  - Matches (\").append(matches.size()).append(\"):\\n\");\n        matches.stream()\n                .sorted(Comparator.comparing(MatchAnalysis::score).reversed())\n                .limit(DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT)\n                .forEach(match -> summary.append(\"    - \").append(match).append(\"\\n\"));\n        if (matches.size() > DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT) {\n            summary.append(\"    ... \").append(matches.size() - DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT)\n                    .append(\" more matches\\n\");\n        }\n    }\n    return summary.toString();\n}\n```\n\nThe `summarize()` method generates a diagnostic text that explains part of the score quality through the `ConstraintAnalysis` API. Here's how it works:\n\n1. It creates a `StringBuilder` to build the summary string.\n\n2. It appends the constraint reference, weight, and score to the summary.\n\n3. If the `matches` list is null, it appends a message indicating that no matches are available.\n\n4. If the `matches` list is not null, it appends the number of matches and then iterates over the matches:\n   - It sorts the matches in descending order based on their score using `Comparator.comparing(MatchAnalysis::score).reversed()`.\n   - It limits the number of matches to display using `DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT`.\n   - For each match, it appends the match details to the summary.\n   - If there are more matches than the limit, it appends a message indicating the number of additional matches.\n\n5. Finally, it returns the generated summary string.\n\nThe `@SuppressWarnings(\"java:S3457\")` annotation is used to suppress the Sonar warning about using a StringBuilder instead of directly concatenating strings within a loop.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/solver/ProblemSizeStatistics.java-format": "Here is the generated code for the `format` method based on the provided function signature and natural language annotations:\n\n```java\nprivate static String format(double number, DecimalFormat decimalFormat, Locale locale) {\n    DecimalFormatSymbols symbols = DecimalFormatSymbols.getInstance(locale);\n    decimalFormat.setDecimalFormatSymbols(symbols);\n    return decimalFormat.format(number);\n}\n```", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/solver/SolverManager.java-solveAndListen": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n@Deprecated(forRemoval = true, since = \"1.6.0\")\ndefault SolverJob<Solution_, ProblemId_> solveAndListen(ProblemId_ problemId,\n        Function<? super ProblemId_, ? extends Solution_> problemFinder,\n        Consumer<? super Solution_> bestSolutionConsumer) {\n    SolverJobBuilder<Solution_, ProblemId_> builder = solveBuilder()\n            .withProblemId(problemId)\n            .withProblemFinder(problemFinder)\n            .withBestSolutionConsumer(bestSolutionConsumer);\n\n    // Log exceptions as an error by default\n    builder.withExceptionHandler((id, throwable) -> {\n        // Log the exception as an error\n        // You can replace this with your own logging mechanism\n        System.err.println(\"Exception occurred for problemId: \" + id);\n        throwable.printStackTrace();\n    });\n\n    return builder.run();\n}\n```\n\nThe generated function does the following:\n\n1. It takes the `problemId`, `problemFinder`, and `bestSolutionConsumer` as parameters.\n\n2. It creates a `SolverJobBuilder` using the `solveBuilder()` method and sets the `problemId`, `problemFinder`, and `bestSolutionConsumer` using the builder's methods.\n\n3. It sets a default exception handler using `withExceptionHandler()` to log exceptions as an error. In this example, it simply prints the exception to the standard error stream, but you can replace it with your own logging mechanism.\n\n4. Finally, it calls `run()` on the builder to submit the planning problem for solving and returns the resulting `SolverJob`.\n\nNote that the function is annotated with `@Deprecated` as per the provided annotation, indicating that it is recommended to use `solveBuilder()` instead while also providing a consumer for the best solution.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/config/solver/SolverConfig.java-withTerminationSpentLimit": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic SolverConfig withTerminationSpentLimit(Duration spentLimit) {\n    if (terminationConfig == null) {\n        terminationConfig = new TerminationConfig();\n    }\n    terminationConfig.setSpentLimit(spentLimit);\n    return this;\n}\n```", "timefold-solver-core/src/main/java/ai/timefold/solver/core/config/util/ConfigUtils.java-meldProperty": "Here is the generated function based on the signature and natural language annotations:\n\n```java\npublic static <T> T meldProperty(T a, T b) {\n    if (a == null && b == null) {\n        return null;\n    } else if (a == null) {\n        return b;\n    } else if (b == null) {\n        return a;\n    } else {\n        return mergeProperty(a, b);\n    }\n}\n```"}