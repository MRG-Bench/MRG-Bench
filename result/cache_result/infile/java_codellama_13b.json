{"langchain4j-langchain4j-vertex-ai-gemini/src/main/java/dev/langchain4j/model/vertexai/SchemaHelper.java-fromJsonSchema": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-vertex-ai-gemini/src/main/java/dev/langchain4j/model/vertexai/SchemaHelper.java:\n```\npackage dev.langchain4j.model.vertexai;\n\nimport com.google.cloud.vertexai.api.Schema;\nimport com.google.cloud.vertexai.api.Type;\nimport com.google.protobuf.InvalidProtocolBufferException;\nimport com.google.protobuf.util.JsonFormat;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\n/**\n * Helper class to create a <code>com.google.cloud.vertexai.api.Schema</code>\n * from a JSON schema string, or from a class by reflection on its public fields.\n */\npublic class SchemaHelper {\n\n    /**\n     * Create an instance of <code>Schema</code> from a JSON schema string.\n     * @param jsonSchemaString the JSON schema string\n     * @return a fully built schema\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Create an instance of <code>Schema</code> from a class by reflection on its fields.\n     * @param theClass the class for which to create a schema representation\n     * @return a fully built schema\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n}\n\n```\n# Function Signature: public static Schema fromJsonSchema(String jsonSchemaString) {\n# Natural Language Annotations: /**\n     * Create an instance of <code>Schema</code> from a JSON schema string.\n     * @param jsonSchemaString the JSON schema string\n     * @return a fully built schema\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static Schema fromJsonSchema(String jsonSchemaString) {\n    try {\n        Schema schema = JsonFormat.parser().merge(jsonSchemaString, Schema.getDefaultInstance());\n        return schema;\n    } catch (InvalidProtocolBufferException e) {\n        throw new RuntimeException(\"Error parsing JSON schema string: \" + e.getMessage());\n    }\n}\n```", "  \n[PYTHON]\ndef from_json_schema(json_schema_string):\n    \"\"\"\n    Create an instance of `Schema` from a JSON schema string.\n\n    Args:\n        json_schema_string (str): The JSON schema string.\n\n    Returns:\n        Schema: A fully built schema.\n    \"\"\"\n    pass\n[/PYTHON]\n[JAVA]\npublic static Schema fromJsonSchema(String jsonSchemaString) {\n    // Your code here\n}\n[/JAVA]\n[PHP]\npublic static function fromJsonSchema(string $jsonSchemaString): Schema\n{\n    // Your code here\n}\n[/PHP]\n[JAVASCRIPT]\nfunction fromJsonSchema(jsonSchemaString) {\n    // Your code here\n}\n[/JAVASCRIPT]\n[PYTHON]\ndef from_json_schema(json_schema_string):\n    \"\"\"\n    Create an instance of `Schema` from a JSON schema string.\n\n    Args:\n        json_schema_string (str): The JSON schema string.\n\n    Returns:\n        Schema: A fully built schema.\n    \"\"\"\n    pass\n[/PYTHON]\n[RUBY]\ndef self.from_json_schema(json_schema_string)\n    # Your code here\nend\n[/RUBY]\n[SWIFT]\npublic static func fromJsonSchema(_ jsonSchemaString: String) -> Schema {\n    // Your code here\n}\n[/SWIFT]\n", "  ```\npublic static Schema fromJsonSchema(String jsonSchemaString) {\n    // Convert the JSON schema string to a JSON object\n    JsonObject jsonObject = new JsonParser().parse(jsonSchemaString).getAsJsonObject();\n\n    // Get the schema's \"type\" field\n    String schemaType = jsonObject.get(\"type\").getAsString();\n\n    // Create a new Schema object\n    Schema schema = new Schema();\n\n    // Set the schema's type field\n    schema.setType(schemaType);\n\n    // Get the schema's \"fields\" field\n    JsonArray fieldsJsonArray = jsonObject.get(\"fields\").getAsJsonArray();\n\n    // Iterate over the fields in the array\n    for (JsonElement fieldJsonElement : fieldsJsonArray) {\n        JsonObject fieldJsonObject = fieldJsonElement.getAsJsonObject();\n\n        // Get the field's name and type\n        String fieldName = fieldJsonObject.get(\"name\").getAsString();\n        String fieldType = fieldJsonObject.get(\"type\").getAsString();\n\n        // Create a new Field object\n        Field field = new Field();\n\n        // Set the field's name, type\n        field.setName(fieldName);\n        field.setType(fieldType);\n\n        // Add the field to the schema\n        schema.addField(field);\n    }\n\n    // Return the fully built schema\n    return schema;\n}\n```"]}, "langchain4j-langchain4j-vertex-ai-gemini/src/main/java/dev/langchain4j/model/vertexai/SchemaHelper.java-fromClass": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-vertex-ai-gemini/src/main/java/dev/langchain4j/model/vertexai/SchemaHelper.java:\n```\npackage dev.langchain4j.model.vertexai;\n\nimport com.google.cloud.vertexai.api.Schema;\nimport com.google.cloud.vertexai.api.Type;\nimport com.google.protobuf.InvalidProtocolBufferException;\nimport com.google.protobuf.util.JsonFormat;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\n/**\n * Helper class to create a <code>com.google.cloud.vertexai.api.Schema</code>\n * from a JSON schema string, or from a class by reflection on its public fields.\n */\npublic class SchemaHelper {\n\n    /**\n     * Create an instance of <code>Schema</code> from a JSON schema string.\n     * @param jsonSchemaString the JSON schema string\n     * @return a fully built schema\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Create an instance of <code>Schema</code> from a class by reflection on its fields.\n     * @param theClass the class for which to create a schema representation\n     * @return a fully built schema\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n}\n\n```\n# Function Signature: public static Schema fromClass(Class<?> theClass) {\n# Natural Language Annotations: /**\n     * Create an instance of <code>Schema</code> from a class by reflection on its fields.\n     * @param theClass the class for which to create a schema representation\n     * @return a fully built schema\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static Schema fromClass(Class<?> theClass) {\n    // Initialize an empty Schema\n    Schema schema = Schema.newBuilder().build();\n\n    // Get a list of all public fields in the class\n    Field[] fields = theClass.getFields();\n\n    // Create a list to store the fields that have a schema annotation\n    List<Field> annotatedFields = new ArrayList<>();\n\n    // Iterate through the fields and check if they have the Schema annotation\n    for (Field field : fields) {\n        if (field.isAnnotationPresent(Schema.class)) {\n            annotatedFields.add(field);\n        }\n    }\n\n    // If there are annotated fields, iterate through them and add their schema to the schema\n    if (!annotatedFields.isEmpty()) {\n        for (Field field : annotatedFields) {\n            Schema fieldSchema = field.getAnnotation(Schema.class).value();\n            schema = schema.toBuilder().addAll(fieldSchema).build();\n        }\n    }\n\n    return schema;\n}\n```", "  ```\npublic static Schema fromClass(Class<?> theClass) {\n    Schema.Builder schemaBuilder = Schema.newBuilder();\n\n    // Get all the fields of the class\n    Field[] fields = theClass.getDeclaredFields();\n\n    // Build a schema from each field\n    for (Field field : fields) {\n        Type type = Type.findByName(field.getType());\n        if (type != null) {\n            schemaBuilder.addField(Field.newBuilder()\n                    .setName(field.getName())\n                    .setType(type)\n                    .addAllSubfields(Arrays.stream(theClass.getDeclaredFields()).map(Field::getName).collect(Collectors.toList()))\n                    .build());\n        }\n    }\n\n    return schemaBuilder.build();\n}\n```", "  ```\npublic static Schema fromClass(Class<?> theClass) {\n    Schema schema = Schema.newBuilder().build();\n\n    // Get the field definitions for the class\n    List<Field> fieldDefinitions = Arrays.stream(theClass.getDeclaredFields())\n                                         .filter(f -> !Modifier.isStatic(f.getModifiers()))\n                                         .collect(Collectors.toList());\n\n    // Get the field names for the schema\n    List<String> fieldNames = fieldDefinitions.stream()\n                                             .map(Field::getName)\n                                             .collect(Collectors.toList());\n\n    // Create the field types for the schema\n    Type[] fieldTypes = fieldDefinitions.stream()\n                                        .map(f -> {\n                                            if (f.getType().isPrimitive()) {\n                                                return Type.forCode(f.getType().getName());\n                                            } else {\n                                                return Type.newBuilder().setName(f.getType().getName()).build();\n                                            }\n                                        })\n                                        .collect(Collectors.toList());\n\n    // Set the schema fields\n    schema = schema.toBuilder()\n                  .addAllFieldNames(fieldNames)\n                  .addAllFieldTypes(fieldTypes)\n                  .build();\n\n    return schema;\n}\n```"]}, "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoader.java-loadDocuments": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j/src/main/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoader.java:\n```\npackage dev.langchain4j.data.document.loader;\n\nimport dev.langchain4j.data.document.Document;\nimport dev.langchain4j.data.document.BlankDocumentException;\nimport dev.langchain4j.data.document.DocumentLoader;\nimport dev.langchain4j.data.document.DocumentParser;\nimport dev.langchain4j.data.document.parser.TextDocumentParser;\nimport dev.langchain4j.spi.data.document.parser.DocumentParserFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.PathMatcher;\nimport java.nio.file.Paths;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.stream.Stream;\n\nimport static dev.langchain4j.data.document.source.FileSystemSource.from;\nimport static dev.langchain4j.internal.Exceptions.illegalArgument;\nimport static dev.langchain4j.internal.Utils.getOrDefault;\nimport static dev.langchain4j.spi.ServiceHelper.loadFactories;\nimport static java.nio.file.Files.isDirectory;\nimport static java.nio.file.Files.isRegularFile;\n\npublic class FileSystemDocumentLoader {\n\n    private static final Logger log = LoggerFactory.getLogger(FileSystemDocumentLoader.class);\n\n    private static final DocumentParser DEFAULT_DOCUMENT_PARSER = getOrDefault(loadDocumentParser(), TextDocumentParser::new);\n\n    private FileSystemDocumentLoader() {\n    }\n\n    /**\n     * Loads a {@link Document} from the specified file {@link Path}.\n     * <br>\n     * The file is parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Returned {@code Document} contains all the textual information from the file.\n     *\n     * @param filePath       The path to the file.\n     * @param documentParser The parser to be used for parsing text from the file.\n     * @return document\n     * @throws IllegalArgumentException If specified path is not a file.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Loads a {@link Document} from the specified file {@link Path}.\n     * <br>\n     * The file is parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Returned {@code Document} contains all the textual information from the file.\n     *\n     * @param filePath The path to the file.\n     * @return document\n     * @throws IllegalArgumentException If specified path is not a file.\n     */\n    public static Document loadDocument(Path filePath) {\n        return loadDocument(filePath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads a {@link Document} from the specified file path.\n     * <br>\n     * The file is parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Returned {@code Document} contains all the textual information from the file.\n     *\n     * @param filePath       The path to the file.\n     * @param documentParser The parser to be used for parsing text from the file.\n     * @return document\n     * @throws IllegalArgumentException If specified path is not a file.\n     */\n    public static Document loadDocument(String filePath, DocumentParser documentParser) {\n        return loadDocument(Paths.get(filePath), documentParser);\n    }\n\n    /**\n     * Loads a {@link Document} from the specified file path.\n     * <br>\n     * The file is parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Returned {@code Document} contains all the textual information from the file.\n     *\n     * @param filePath The path to the file.\n     * @return document\n     * @throws IllegalArgumentException If specified path is not a file.\n     */\n    public static Document loadDocument(String filePath) {\n        return loadDocument(filePath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Loads {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(Path directoryPath) {\n        return loadDocuments(directoryPath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(String directoryPath, DocumentParser documentParser) {\n        return loadDocuments(Paths.get(directoryPath), documentParser);\n    }\n\n    /**\n     * Loads {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(String directoryPath) {\n        return loadDocuments(directoryPath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads matching {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param pathMatcher    Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                       For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:*.txt\")}\n     *                       will load all files from {@code directoryPath} with a {@code txt} extension.\n     *                       When traversing the directory, each file path is converted from absolute to relative\n     *                       (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                       Thus, {@code pathMatcher} should use relative patterns.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(Path directoryPath,\n                                               PathMatcher pathMatcher,\n                                               DocumentParser documentParser) {\n        if (!isDirectory(directoryPath)) {\n            throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n        }\n\n        try (Stream<Path> pathStream = Files.list(directoryPath)) {\n            return loadDocuments(pathStream, pathMatcher, directoryPath, documentParser);\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    /**\n     * Loads matching {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @param pathMatcher   Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                      For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:*.txt\")}\n     *                      will load all files from {@code directoryPath} with a {@code txt} extension.\n     *                      When traversing the directory, each file path is converted from absolute to relative\n     *                      (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                      Thus, {@code pathMatcher} should use relative patterns.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(Path directoryPath, PathMatcher pathMatcher) {\n        return loadDocuments(directoryPath, pathMatcher, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads matching {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param pathMatcher    Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                       For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:*.txt\")}\n     *                       will load all files from {@code directoryPath} with a {@code txt} extension.\n     *                       When traversing the directory, each file path is converted from absolute to relative\n     *                       (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                       Thus, {@code pathMatcher} should use relative patterns.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(String directoryPath,\n                                               PathMatcher pathMatcher,\n                                               DocumentParser documentParser) {\n        return loadDocuments(Paths.get(directoryPath), pathMatcher, documentParser);\n    }\n\n    /**\n     * Loads matching {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @param pathMatcher   Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                      For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:*.txt\")}\n     *                      will load all files from {@code directoryPath} with a {@code txt} extension.\n     *                      When traversing the directory, each file path is converted from absolute to relative\n     *                      (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                      Thus, {@code pathMatcher} should use relative patterns.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(String directoryPath, PathMatcher pathMatcher) {\n        return loadDocuments(directoryPath, pathMatcher, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Recursively loads {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Recursively loads {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(Path directoryPath) {\n        return loadDocumentsRecursively(directoryPath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Recursively loads {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(String directoryPath, DocumentParser documentParser) {\n        return loadDocumentsRecursively(Paths.get(directoryPath), documentParser);\n    }\n\n    /**\n     * Recursively loads {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(String directoryPath) {\n        return loadDocumentsRecursively(directoryPath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Recursively loads matching {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param pathMatcher    Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                       For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:**.txt\")} will\n     *                       load all files from {@code directoryPath} and its subdirectories with a {@code txt} extension.\n     *                       When traversing the directory tree, each file path is converted from absolute to relative\n     *                       (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                       Thus, {@code pathMatcher} should use relative patterns.\n     *                       Please be aware that {@code *.txt} pattern (with a single asterisk) will match files\n     *                       only in the {@code directoryPath}, but it will not match files from the subdirectories\n     *                       of {@code directoryPath}.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(Path directoryPath,\n                                                          PathMatcher pathMatcher,\n                                                          DocumentParser documentParser) {\n        if (!isDirectory(directoryPath)) {\n            throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n        }\n\n        try (Stream<Path> pathStream = Files.walk(directoryPath)) {\n            return loadDocuments(pathStream, pathMatcher, directoryPath, documentParser);\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    /**\n     * Recursively loads matching {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @param pathMatcher   Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                      For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:**.txt\")} will\n     *                      load all files from {@code directoryPath} and its subdirectories with a {@code txt} extension.\n     *                      When traversing the directory tree, each file path is converted from absolute to relative\n     *                      (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                      Thus, {@code pathMatcher} should use relative patterns.\n     *                      Please be aware that {@code *.txt} pattern (with a single asterisk) will match files\n     *                      only in the {@code directoryPath}, but it will not match files from the subdirectories\n     *                      of {@code directoryPath}.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(Path directoryPath, PathMatcher pathMatcher) {\n        return loadDocumentsRecursively(directoryPath, pathMatcher, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Recursively loads matching {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param pathMatcher    Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                       For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:**.txt\")} will\n     *                       load all files from {@code directoryPath} and its subdirectories with a {@code txt} extension.\n     *                       When traversing the directory tree, each file path is converted from absolute to relative\n     *                       (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                       Thus, {@code pathMatcher} should use relative patterns.\n     *                       Please be aware that {@code *.txt} pattern (with a single asterisk) will match files\n     *                       only in the {@code directoryPath}, but it will not match files from the subdirectories\n     *                       of {@code directoryPath}.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(String directoryPath,\n                                                          PathMatcher pathMatcher,\n                                                          DocumentParser documentParser) {\n        return loadDocumentsRecursively(Paths.get(directoryPath), pathMatcher, documentParser);\n    }\n\n    /**\n     * Recursively loads matching {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @param pathMatcher   Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                      For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:**.txt\")} will\n     *                      load all files from {@code directoryPath} and its subdirectories with a {@code txt} extension.\n     *                      When traversing the directory tree, each file path is converted from absolute to relative\n     *                      (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                      Thus, {@code pathMatcher} should use relative patterns.\n     *                      Please be aware that {@code *.txt} pattern (with a single asterisk) will match files\n     *                      only in the {@code directoryPath}, but it will not match files from the subdirectories\n     *                      of {@code directoryPath}.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(String directoryPath, PathMatcher pathMatcher) {\n        return loadDocumentsRecursively(directoryPath, pathMatcher, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    private static List<Document> loadDocuments(Stream<Path> pathStream,\n                                                PathMatcher pathMatcher,\n                                                Path pathMatcherRoot,\n                                                DocumentParser documentParser) {\n        List<Document> documents = new ArrayList<>();\n\n        pathStream\n                .filter(Files::isRegularFile)\n                // converting absolute path into relative before using pathMatcher\n                // because patterns defined in pathMatcher are relative to pathMatcherRoot (directoryPath)\n                .map(pathMatcherRoot::relativize)\n                .filter(pathMatcher::matches)\n                // converting relative path back into absolute before loading document\n                .map(pathMatcherRoot::resolve)\n                .forEach(file -> {\n                    try {\n                        Document document = loadDocument(file, documentParser);\n                        documents.add(document);\n                    } catch (BlankDocumentException ignored) {\n                        // blank/empty documents are ignored\n                    } catch (Exception e) {\n                        String message = e.getCause() != null ? e.getCause().getMessage() : e.getMessage();\n                        log.warn(\"Failed to load '{}': {}\", file, message);\n                    }\n                });\n\n        return documents;\n    }\n\n    private static DocumentParser loadDocumentParser()\n```\n# Function Signature: public static List<Document> loadDocuments(Path directoryPath, DocumentParser documentParser) {\n# Natural Language Annotations: /**\n     * Loads {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static List<Document> loadDocuments(Path directoryPath, DocumentParser documentParser) {\n        if (!isDirectory(directoryPath)) {\n            throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n        }\n\n        List<Document> documents = new ArrayList<>();\n\n        try (Stream<Path> pathStream = Files.list(directoryPath)) {\n            pathStream\n                    .filter(Files::isRegularFile)\n                    .forEach(file -> {\n                        try {\n                            Document document = loadDocument(file, documentParser);\n                            documents.add(document);\n                        } catch (BlankDocumentException ignored) {\n                            // blank/empty documents are ignored\n                        } catch (Exception e) {\n                            String message = e.getCause() != null ? e.getCause().getMessage() : e.getMessage();\n                            log.warn(\"Failed to load '{}': {}\", file, message);\n                        }\n                    });\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n\n        return documents;\n    }\n```", "  ```\npublic static List<Document> loadDocuments(Path directoryPath, DocumentParser documentParser) {\n        if (!isDirectory(directoryPath)) {\n            throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n        }\n\n        try (Stream<Path> pathStream = Files.list(directoryPath)) {\n            return loadDocuments(pathStream, Paths.get(\"\"), documentParser);\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n```", "  ```\npublic static List<Document> loadDocuments(Path directoryPath, DocumentParser documentParser) {\n    if (!isDirectory(directoryPath)) {\n        throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n    }\n\n    try (Stream<Path> pathStream = Files.list(directoryPath)) {\n        return loadDocuments(pathStream, Paths.getMatcher(GLOB_WILDCARD), directoryPath, documentParser);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```"]}, "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoader.java-loadDocumentsRecursively": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j/src/main/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoader.java:\n```\npackage dev.langchain4j.data.document.loader;\n\nimport dev.langchain4j.data.document.Document;\nimport dev.langchain4j.data.document.BlankDocumentException;\nimport dev.langchain4j.data.document.DocumentLoader;\nimport dev.langchain4j.data.document.DocumentParser;\nimport dev.langchain4j.data.document.parser.TextDocumentParser;\nimport dev.langchain4j.spi.data.document.parser.DocumentParserFactory;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.io.IOException;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.PathMatcher;\nimport java.nio.file.Paths;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.stream.Stream;\n\nimport static dev.langchain4j.data.document.source.FileSystemSource.from;\nimport static dev.langchain4j.internal.Exceptions.illegalArgument;\nimport static dev.langchain4j.internal.Utils.getOrDefault;\nimport static dev.langchain4j.spi.ServiceHelper.loadFactories;\nimport static java.nio.file.Files.isDirectory;\nimport static java.nio.file.Files.isRegularFile;\n\npublic class FileSystemDocumentLoader {\n\n    private static final Logger log = LoggerFactory.getLogger(FileSystemDocumentLoader.class);\n\n    private static final DocumentParser DEFAULT_DOCUMENT_PARSER = getOrDefault(loadDocumentParser(), TextDocumentParser::new);\n\n    private FileSystemDocumentLoader() {\n    }\n\n    /**\n     * Loads a {@link Document} from the specified file {@link Path}.\n     * <br>\n     * The file is parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Returned {@code Document} contains all the textual information from the file.\n     *\n     * @param filePath       The path to the file.\n     * @param documentParser The parser to be used for parsing text from the file.\n     * @return document\n     * @throws IllegalArgumentException If specified path is not a file.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Loads a {@link Document} from the specified file {@link Path}.\n     * <br>\n     * The file is parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Returned {@code Document} contains all the textual information from the file.\n     *\n     * @param filePath The path to the file.\n     * @return document\n     * @throws IllegalArgumentException If specified path is not a file.\n     */\n    public static Document loadDocument(Path filePath) {\n        return loadDocument(filePath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads a {@link Document} from the specified file path.\n     * <br>\n     * The file is parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Returned {@code Document} contains all the textual information from the file.\n     *\n     * @param filePath       The path to the file.\n     * @param documentParser The parser to be used for parsing text from the file.\n     * @return document\n     * @throws IllegalArgumentException If specified path is not a file.\n     */\n    public static Document loadDocument(String filePath, DocumentParser documentParser) {\n        return loadDocument(Paths.get(filePath), documentParser);\n    }\n\n    /**\n     * Loads a {@link Document} from the specified file path.\n     * <br>\n     * The file is parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Returned {@code Document} contains all the textual information from the file.\n     *\n     * @param filePath The path to the file.\n     * @return document\n     * @throws IllegalArgumentException If specified path is not a file.\n     */\n    public static Document loadDocument(String filePath) {\n        return loadDocument(filePath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Loads {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(Path directoryPath) {\n        return loadDocuments(directoryPath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(String directoryPath, DocumentParser documentParser) {\n        return loadDocuments(Paths.get(directoryPath), documentParser);\n    }\n\n    /**\n     * Loads {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(String directoryPath) {\n        return loadDocuments(directoryPath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads matching {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param pathMatcher    Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                       For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:*.txt\")}\n     *                       will load all files from {@code directoryPath} with a {@code txt} extension.\n     *                       When traversing the directory, each file path is converted from absolute to relative\n     *                       (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                       Thus, {@code pathMatcher} should use relative patterns.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(Path directoryPath,\n                                               PathMatcher pathMatcher,\n                                               DocumentParser documentParser) {\n        if (!isDirectory(directoryPath)) {\n            throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n        }\n\n        try (Stream<Path> pathStream = Files.list(directoryPath)) {\n            return loadDocuments(pathStream, pathMatcher, directoryPath, documentParser);\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    /**\n     * Loads matching {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @param pathMatcher   Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                      For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:*.txt\")}\n     *                      will load all files from {@code directoryPath} with a {@code txt} extension.\n     *                      When traversing the directory, each file path is converted from absolute to relative\n     *                      (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                      Thus, {@code pathMatcher} should use relative patterns.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(Path directoryPath, PathMatcher pathMatcher) {\n        return loadDocuments(directoryPath, pathMatcher, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Loads matching {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param pathMatcher    Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                       For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:*.txt\")}\n     *                       will load all files from {@code directoryPath} with a {@code txt} extension.\n     *                       When traversing the directory, each file path is converted from absolute to relative\n     *                       (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                       Thus, {@code pathMatcher} should use relative patterns.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(String directoryPath,\n                                               PathMatcher pathMatcher,\n                                               DocumentParser documentParser) {\n        return loadDocuments(Paths.get(directoryPath), pathMatcher, documentParser);\n    }\n\n    /**\n     * Loads matching {@link Document}s from the specified directory. Does not use recursion.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @param pathMatcher   Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                      For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:*.txt\")}\n     *                      will load all files from {@code directoryPath} with a {@code txt} extension.\n     *                      When traversing the directory, each file path is converted from absolute to relative\n     *                      (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                      Thus, {@code pathMatcher} should use relative patterns.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocuments(String directoryPath, PathMatcher pathMatcher) {\n        return loadDocuments(directoryPath, pathMatcher, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Recursively loads {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Recursively loads {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(Path directoryPath) {\n        return loadDocumentsRecursively(directoryPath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Recursively loads {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(String directoryPath, DocumentParser documentParser) {\n        return loadDocumentsRecursively(Paths.get(directoryPath), documentParser);\n    }\n\n    /**\n     * Recursively loads {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(String directoryPath) {\n        return loadDocumentsRecursively(directoryPath, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Recursively loads matching {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param pathMatcher    Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                       For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:**.txt\")} will\n     *                       load all files from {@code directoryPath} and its subdirectories with a {@code txt} extension.\n     *                       When traversing the directory tree, each file path is converted from absolute to relative\n     *                       (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                       Thus, {@code pathMatcher} should use relative patterns.\n     *                       Please be aware that {@code *.txt} pattern (with a single asterisk) will match files\n     *                       only in the {@code directoryPath}, but it will not match files from the subdirectories\n     *                       of {@code directoryPath}.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(Path directoryPath,\n                                                          PathMatcher pathMatcher,\n                                                          DocumentParser documentParser) {\n        if (!isDirectory(directoryPath)) {\n            throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n        }\n\n        try (Stream<Path> pathStream = Files.walk(directoryPath)) {\n            return loadDocuments(pathStream, pathMatcher, directoryPath, documentParser);\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    /**\n     * Recursively loads matching {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @param pathMatcher   Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                      For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:**.txt\")} will\n     *                      load all files from {@code directoryPath} and its subdirectories with a {@code txt} extension.\n     *                      When traversing the directory tree, each file path is converted from absolute to relative\n     *                      (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                      Thus, {@code pathMatcher} should use relative patterns.\n     *                      Please be aware that {@code *.txt} pattern (with a single asterisk) will match files\n     *                      only in the {@code directoryPath}, but it will not match files from the subdirectories\n     *                      of {@code directoryPath}.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(Path directoryPath, PathMatcher pathMatcher) {\n        return loadDocumentsRecursively(directoryPath, pathMatcher, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    /**\n     * Recursively loads matching {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param pathMatcher    Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                       For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:**.txt\")} will\n     *                       load all files from {@code directoryPath} and its subdirectories with a {@code txt} extension.\n     *                       When traversing the directory tree, each file path is converted from absolute to relative\n     *                       (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                       Thus, {@code pathMatcher} should use relative patterns.\n     *                       Please be aware that {@code *.txt} pattern (with a single asterisk) will match files\n     *                       only in the {@code directoryPath}, but it will not match files from the subdirectories\n     *                       of {@code directoryPath}.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(String directoryPath,\n                                                          PathMatcher pathMatcher,\n                                                          DocumentParser documentParser) {\n        return loadDocumentsRecursively(Paths.get(directoryPath), pathMatcher, documentParser);\n    }\n\n    /**\n     * Recursively loads matching {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the default {@link DocumentParser}.\n     * The default {@code DocumentParser} is loaded through SPI (see {@link DocumentParserFactory}).\n     * If no {@code DocumentParserFactory} is available in the classpath, a {@link TextDocumentParser} is used.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath The path to the directory with files.\n     * @param pathMatcher   Only files whose paths match the provided {@link PathMatcher} will be loaded.\n     *                      For example, using {@code FileSystems.getDefault().getPathMatcher(\"glob:**.txt\")} will\n     *                      load all files from {@code directoryPath} and its subdirectories with a {@code txt} extension.\n     *                      When traversing the directory tree, each file path is converted from absolute to relative\n     *                      (relative to {@code directoryPath}) before being matched by a {@code pathMatcher}.\n     *                      Thus, {@code pathMatcher} should use relative patterns.\n     *                      Please be aware that {@code *.txt} pattern (with a single asterisk) will match files\n     *                      only in the {@code directoryPath}, but it will not match files from the subdirectories\n     *                      of {@code directoryPath}.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\n    public static List<Document> loadDocumentsRecursively(String directoryPath, PathMatcher pathMatcher) {\n        return loadDocumentsRecursively(directoryPath, pathMatcher, DEFAULT_DOCUMENT_PARSER);\n    }\n\n    private static List<Document> loadDocuments(Stream<Path> pathStream,\n                                                PathMatcher pathMatcher,\n                                                Path pathMatcherRoot,\n                                                DocumentParser documentParser) {\n        List<Document> documents = new ArrayList<>();\n\n        pathStream\n                .filter(Files::isRegularFile)\n                // converting absolute path into relative before using pathMatcher\n                // because patterns defined in pathMatcher are relative to pathMatcherRoot (directoryPath)\n                .map(pathMatcherRoot::relativize)\n                .filter(pathMatcher::matches)\n                // converting relative path back into absolute before loading document\n                .map(pathMatcherRoot::resolve)\n                .forEach(file -> {\n                    try {\n                        Document document = loadDocument(file, documentParser);\n                        documents.add(document);\n                    } catch (BlankDocumentException ignored) {\n                        // blank/empty documents are ignored\n                    } catch (Exception e) {\n                        String message = e.getCause() != null ? e.getCause().getMessage() : e.getMessage();\n                        log.warn(\"Failed to load '{}': {}\", file, message);\n                    }\n                });\n\n        return documents;\n    }\n\n    private static DocumentParser loadDocumentParser()\n```\n# Function Signature: public static List<Document> loadDocumentsRecursively(Path directoryPath, DocumentParser documentParser) {\n# Natural Language Annotations: /**\n     * Recursively loads {@link Document}s from the specified directory and its subdirectories.\n     * <br>\n     * The files are parsed using the specified {@link DocumentParser}.\n     * <br>\n     * Skips any {@code Document}s that fail to load.\n     *\n     * @param directoryPath  The path to the directory with files.\n     * @param documentParser The parser to be used for parsing text from each file.\n     * @return list of documents\n     * @throws IllegalArgumentException If specified path is not a directory.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static List<Document> loadDocumentsRecursively(Path directoryPath, DocumentParser documentParser) {\n    if (!isDirectory(directoryPath)) {\n        throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n    }\n    try (Stream<Path> pathStream = Files.walk(directoryPath)) {\n        return loadDocuments(pathStream, null, directoryPath, documentParser);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```", "  ```\npublic static List<Document> loadDocumentsRecursively(Path directoryPath, DocumentParser documentParser) {\n    if (!Files.isDirectory(directoryPath)) {\n        throw new IllegalArgumentException(\"'%s' is not a directory\");\n    }\n    List<Document> documents = new ArrayList<>();\n    try (Stream<Path> pathStream = Files.walk(directoryPath)) {\n        pathStream\n                .filter(Files::isRegularFile)\n                .map(directoryPath::relativize)\n                .filter(pathMatcher::matches)\n                .map(directoryPath::resolve)\n                .forEach(file -> {\n                    try {\n                        Document document = loadDocument(file, documentParser);\n                        documents.add(document);\n                    } catch (BlankDocumentException ignored) {\n                        // blank/empty documents are ignored\n                    } catch (Exception e) {\n                        String message = e.getCause() != null ? e.getCause().getMessage() : e.getMessage();\n                        log.warn(\"Failed to load '{}': {}\", file, message);\n                    }\n                });\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n    return documents;\n}\n```", "  ```\npublic static List<Document> loadDocumentsRecursively(Path directoryPath, DocumentParser documentParser) {\n    if (!Files.isDirectory(directoryPath)) {\n        throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n    }\n\n    List<Document> documents = new ArrayList<>();\n    try (Stream<Path> pathStream = Files.walk(directoryPath)) {\n        loadDocuments(pathStream, p -> true, directoryPath, documentParser).forEach(documents::add);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n    return documents;\n}\n```"]}, "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java-hasSpaceFor": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java:\n```\npackage dev.langchain4j.data.document.splitter;\n\nimport java.util.function.Function;\n\nimport static dev.langchain4j.internal.ValidationUtils.ensureGreaterThanZero;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotNull;\n\n/**\n * Segment builder utility class for HierarchicalDocumentSplitter.\n */\nclass SegmentBuilder {\n    private final int maxSegmentSize;\n    private final Function<String, Integer> sizeFunction;\n    private final String joinSeparator;\n    private final int joinSeparatorSize;\n    private String segment = \"\";\n    private int segmentSize = 0;\n\n    /**\n     * Creates a new instance of {@link SegmentBuilder}.\n     * @param maxSegmentSize The maximum size of a segment.\n     * @param sizeFunction The function to use to estimate the size of a text.\n     * @param joinSeparator The separator to use when joining multiple texts into a single segment.\n     */\n    public SegmentBuilder(int maxSegmentSize, Function<String, Integer> sizeFunction, String joinSeparator) {\n        this.maxSegmentSize = ensureGreaterThanZero(maxSegmentSize, \"maxSegmentSize\");\n        this.sizeFunction = ensureNotNull(sizeFunction, \"sizeFunction\");\n        this.joinSeparator = ensureNotNull(joinSeparator, \"joinSeparator\");\n        this.joinSeparatorSize = sizeOf(joinSeparator);\n    }\n\n    /**\n     * Returns the current size of the segment (as returned by the {@code sizeFunction}).\n     * @return The current size of the segment.\n     */\n    public int getSize() {\n        return segmentSize;\n    }\n\n    /**\n     * Returns {@code true} if the provided text can be added to the current segment.\n     * @param text The text to check.\n     * @return {@code true} if the provided text can be added to the current segment.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Returns {@code true} if the provided size can be added to the current segment.\n     * @param size The size to check.\n     * @return {@code true} if the provided size can be added to the current segment.\n     */\n    public boolean hasSpaceFor(int size) {\n        int totalSize = size;\n        if (isNotEmpty()) {\n            totalSize += segmentSize + joinSeparatorSize;\n        }\n        return totalSize <= maxSegmentSize;\n    }\n\n    /**\n     * Returns the size of the provided text (as returned by the {@code sizeFunction}).\n     * @param text The text to check.\n     * @return The size of the provided text.\n     */\n    public int sizeOf(String text) {\n        return sizeFunction.apply(text);\n    }\n\n    /**\n     * Appends the provided text to the current segment.\n     * @param text The text to append.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Prepends the provided text to the current segment.\n     * @param text The text to prepend.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns {@code true} if the current segment is not empty.\n     * @return {@code true} if the current segment is not empty.\n     */\n    public boolean isNotEmpty() {\n        return !segment.isEmpty();\n    }\n\n    @Override\n    public String toString() {\n        return segment.trim();\n    }\n\n    /**\n     * Resets the current segment.\n     */\n    public void reset() {\n        segment = \"\";\n        segmentSize = 0;\n    }\n}\n\n```\n# Function Signature: public boolean hasSpaceFor(String text) {\n# Natural Language Annotations: /**\n     * Returns {@code true} if the provided text can be added to the current segment.\n     * @param text The text to check.\n     * @return {@code true} if the provided text can be added to the current segment.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic boolean hasSpaceFor(String text) {\n    int totalSize = sizeOf(text);\n    if (isNotEmpty()) {\n        totalSize += segmentSize + joinSeparatorSize;\n    }\n    return totalSize <= maxSegmentSize;\n}\n```", "  ```\npublic boolean hasSpaceFor(String text) {\n    int textSize = sizeOf(text);\n    int totalSize = textSize;\n    if (isNotEmpty()) {\n        totalSize += segmentSize + joinSeparatorSize;\n    }\n    return totalSize <= maxSegmentSize;\n}\n```", "  ```\npublic boolean hasSpaceFor(String text) {\n    int size = sizeOf(text);\n    int totalSize = size;\n    if (isNotEmpty()) {\n        totalSize += segmentSize + joinSeparatorSize;\n    }\n    return totalSize <= maxSegmentSize;\n}\n```"]}, "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java-append": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java:\n```\npackage dev.langchain4j.data.document.splitter;\n\nimport java.util.function.Function;\n\nimport static dev.langchain4j.internal.ValidationUtils.ensureGreaterThanZero;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotNull;\n\n/**\n * Segment builder utility class for HierarchicalDocumentSplitter.\n */\nclass SegmentBuilder {\n    private final int maxSegmentSize;\n    private final Function<String, Integer> sizeFunction;\n    private final String joinSeparator;\n    private final int joinSeparatorSize;\n    private String segment = \"\";\n    private int segmentSize = 0;\n\n    /**\n     * Creates a new instance of {@link SegmentBuilder}.\n     * @param maxSegmentSize The maximum size of a segment.\n     * @param sizeFunction The function to use to estimate the size of a text.\n     * @param joinSeparator The separator to use when joining multiple texts into a single segment.\n     */\n    public SegmentBuilder(int maxSegmentSize, Function<String, Integer> sizeFunction, String joinSeparator) {\n        this.maxSegmentSize = ensureGreaterThanZero(maxSegmentSize, \"maxSegmentSize\");\n        this.sizeFunction = ensureNotNull(sizeFunction, \"sizeFunction\");\n        this.joinSeparator = ensureNotNull(joinSeparator, \"joinSeparator\");\n        this.joinSeparatorSize = sizeOf(joinSeparator);\n    }\n\n    /**\n     * Returns the current size of the segment (as returned by the {@code sizeFunction}).\n     * @return The current size of the segment.\n     */\n    public int getSize() {\n        return segmentSize;\n    }\n\n    /**\n     * Returns {@code true} if the provided text can be added to the current segment.\n     * @param text The text to check.\n     * @return {@code true} if the provided text can be added to the current segment.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Returns {@code true} if the provided size can be added to the current segment.\n     * @param size The size to check.\n     * @return {@code true} if the provided size can be added to the current segment.\n     */\n    public boolean hasSpaceFor(int size) {\n        int totalSize = size;\n        if (isNotEmpty()) {\n            totalSize += segmentSize + joinSeparatorSize;\n        }\n        return totalSize <= maxSegmentSize;\n    }\n\n    /**\n     * Returns the size of the provided text (as returned by the {@code sizeFunction}).\n     * @param text The text to check.\n     * @return The size of the provided text.\n     */\n    public int sizeOf(String text) {\n        return sizeFunction.apply(text);\n    }\n\n    /**\n     * Appends the provided text to the current segment.\n     * @param text The text to append.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Prepends the provided text to the current segment.\n     * @param text The text to prepend.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns {@code true} if the current segment is not empty.\n     * @return {@code true} if the current segment is not empty.\n     */\n    public boolean isNotEmpty() {\n        return !segment.isEmpty();\n    }\n\n    @Override\n    public String toString() {\n        return segment.trim();\n    }\n\n    /**\n     * Resets the current segment.\n     */\n    public void reset() {\n        segment = \"\";\n        segmentSize = 0;\n    }\n}\n\n```\n# Function Signature: public void append(String text) {\n# Natural Language Annotations: /**\n     * Appends the provided text to the current segment.\n     * @param text The text to append.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic void append(String text) {\n    segment += text;\n    segmentSize += sizeFunction.apply(text);\n}\n```", "  ```\npublic void append(String text) {\n    ensureNotNull(text, \"text\");\n    if (hasSpaceFor(text)) {\n        this.segment += text;\n        this.segmentSize += sizeOf(text);\n    }\n}\n```", "  ```\npublic void append(String text) {\n    if (hasSpaceFor(text.length())) {\n        segment += text;\n        segmentSize += sizeOf(text);\n    } else {\n        throw new IllegalStateException(\"Cannot append text to current segment. Maximum segment size exceeded.\");\n    }\n}\n```"]}, "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java-prepend": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java:\n```\npackage dev.langchain4j.data.document.splitter;\n\nimport java.util.function.Function;\n\nimport static dev.langchain4j.internal.ValidationUtils.ensureGreaterThanZero;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotNull;\n\n/**\n * Segment builder utility class for HierarchicalDocumentSplitter.\n */\nclass SegmentBuilder {\n    private final int maxSegmentSize;\n    private final Function<String, Integer> sizeFunction;\n    private final String joinSeparator;\n    private final int joinSeparatorSize;\n    private String segment = \"\";\n    private int segmentSize = 0;\n\n    /**\n     * Creates a new instance of {@link SegmentBuilder}.\n     * @param maxSegmentSize The maximum size of a segment.\n     * @param sizeFunction The function to use to estimate the size of a text.\n     * @param joinSeparator The separator to use when joining multiple texts into a single segment.\n     */\n    public SegmentBuilder(int maxSegmentSize, Function<String, Integer> sizeFunction, String joinSeparator) {\n        this.maxSegmentSize = ensureGreaterThanZero(maxSegmentSize, \"maxSegmentSize\");\n        this.sizeFunction = ensureNotNull(sizeFunction, \"sizeFunction\");\n        this.joinSeparator = ensureNotNull(joinSeparator, \"joinSeparator\");\n        this.joinSeparatorSize = sizeOf(joinSeparator);\n    }\n\n    /**\n     * Returns the current size of the segment (as returned by the {@code sizeFunction}).\n     * @return The current size of the segment.\n     */\n    public int getSize() {\n        return segmentSize;\n    }\n\n    /**\n     * Returns {@code true} if the provided text can be added to the current segment.\n     * @param text The text to check.\n     * @return {@code true} if the provided text can be added to the current segment.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Returns {@code true} if the provided size can be added to the current segment.\n     * @param size The size to check.\n     * @return {@code true} if the provided size can be added to the current segment.\n     */\n    public boolean hasSpaceFor(int size) {\n        int totalSize = size;\n        if (isNotEmpty()) {\n            totalSize += segmentSize + joinSeparatorSize;\n        }\n        return totalSize <= maxSegmentSize;\n    }\n\n    /**\n     * Returns the size of the provided text (as returned by the {@code sizeFunction}).\n     * @param text The text to check.\n     * @return The size of the provided text.\n     */\n    public int sizeOf(String text) {\n        return sizeFunction.apply(text);\n    }\n\n    /**\n     * Appends the provided text to the current segment.\n     * @param text The text to append.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Prepends the provided text to the current segment.\n     * @param text The text to prepend.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns {@code true} if the current segment is not empty.\n     * @return {@code true} if the current segment is not empty.\n     */\n    public boolean isNotEmpty() {\n        return !segment.isEmpty();\n    }\n\n    @Override\n    public String toString() {\n        return segment.trim();\n    }\n\n    /**\n     * Resets the current segment.\n     */\n    public void reset() {\n        segment = \"\";\n        segmentSize = 0;\n    }\n}\n\n```\n# Function Signature: public void prepend(String text) {\n# Natural Language Annotations: /**\n     * Prepends the provided text to the current segment.\n     * @param text The text to prepend.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic void prepend(String text) {\n    if (text == null || text.isEmpty()) {\n        return;\n    }\n    int textSize = sizeFunction.apply(text);\n    if (segmentSize + textSize > maxSegmentSize) {\n        return;\n    }\n    segment = text + joinSeparator + segment;\n    segmentSize += textSize + joinSeparatorSize;\n}\n```", "  ```\npublic void prepend(String text) {\n    int size = sizeOf(text);\n    if (hasSpaceFor(size)) {\n        segment = text + joinSeparator + segment;\n        segmentSize += size;\n    } else {\n        throw new IllegalStateException(\"SegmentBuilder: cannot prepend text of size \" + size + \". Max segment size is \" + maxSegmentSize);\n    }\n}\n```", "  ```\npublic void prepend(String text) {\n    ensureNotNull(text, \"text\");\n    int textSize = sizeOf(text);\n    if (!hasSpaceFor(textSize)) {\n        return;\n    }\n    String joinedText = String.format(\"%s%s%s\", joinSeparator, text, segment);\n    updateSizeAndText(joinedText);\n}\n```"]}, "langchain4j-langchain4j/src/main/java/dev/langchain4j/service/AiServices.java-retriever": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j/src/main/java/dev/langchain4j/service/AiServices.java:\n```\npackage dev.langchain4j.service;\n\nimport dev.langchain4j.service.tool.DefaultToolExecutor;\nimport dev.langchain4j.agent.tool.Tool;\nimport dev.langchain4j.service.tool.ToolExecutor;\nimport dev.langchain4j.agent.tool.ToolSpecification;\nimport dev.langchain4j.data.message.AiMessage;\nimport dev.langchain4j.data.message.ChatMessage;\nimport dev.langchain4j.data.message.ToolExecutionResultMessage;\nimport dev.langchain4j.data.segment.TextSegment;\nimport dev.langchain4j.memory.ChatMemory;\nimport dev.langchain4j.memory.chat.ChatMemoryProvider;\nimport dev.langchain4j.model.chat.ChatLanguageModel;\nimport dev.langchain4j.model.chat.StreamingChatLanguageModel;\nimport dev.langchain4j.model.input.structured.StructuredPrompt;\nimport dev.langchain4j.model.moderation.Moderation;\nimport dev.langchain4j.model.moderation.ModerationModel;\nimport dev.langchain4j.model.output.TokenUsage;\nimport dev.langchain4j.rag.DefaultRetrievalAugmentor;\nimport dev.langchain4j.rag.RetrievalAugmentor;\nimport dev.langchain4j.rag.content.Content;\nimport dev.langchain4j.rag.content.retriever.ContentRetriever;\nimport dev.langchain4j.rag.content.retriever.EmbeddingStoreContentRetriever;\nimport dev.langchain4j.retriever.Retriever;\nimport dev.langchain4j.spi.services.AiServicesFactory;\n\nimport java.lang.reflect.Method;\nimport java.util.*;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.Future;\nimport java.util.function.Function;\n\nimport static dev.langchain4j.agent.tool.ToolSpecifications.toolSpecificationFrom;\nimport static dev.langchain4j.exception.IllegalConfigurationException.illegalConfiguration;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotNull;\nimport static dev.langchain4j.spi.ServiceHelper.loadFactories;\nimport static java.util.Arrays.asList;\nimport static java.util.stream.Collectors.toList;\n\n/**\n * AI Services provide a simpler and more flexible alternative to chains.\n * You can define your own API (a Java interface with one or more methods),\n * and {@code AiServices} will provide an implementation for it.\n * <p>\n * Currently, AI Services support:\n * <pre>\n * - Static system message templates, configured via @{@link SystemMessage} annotation on top of the method\n * - Dynamic system message templates, configured via {@link #systemMessageProvider(Function)}\n * - Static user message templates, configured via @{@link UserMessage} annotation on top of the method\n * - Dynamic user message templates, configured via method parameter annotated with @{@link UserMessage}\n * - Single (shared) {@link ChatMemory}, configured via {@link #chatMemory(ChatMemory)}\n * - Separate (per-user) {@code ChatMemory}, configured via {@link #chatMemoryProvider(ChatMemoryProvider)} and a method parameter annotated with @{@link MemoryId}\n * - RAG, configured via {@link #contentRetriever(ContentRetriever)} or {@link #retrievalAugmentor(RetrievalAugmentor)}\n * - Tools, configured via {@link #tools(List)} or {@link #tools(Object...)} and methods annotated with @{@link Tool}\n * - Various method return types (output parsers), see more details below\n * - Streaming (use {@link TokenStream} as a return type)\n * - Structured prompts as method arguments (see @{@link StructuredPrompt})\n * - Auto-moderation, configured via @{@link Moderate} annotation\n * </pre>\n * <p>\n * Here is the simplest example of an AI Service:\n *\n * <pre>\n * interface Assistant {\n *\n *     String chat(String userMessage);\n * }\n *\n * Assistant assistant = AiServices.create(Assistant.class, model);\n *\n * String answer = assistant.chat(\"hello\");\n * System.out.println(answer); // Hello, how can I help you today?\n * </pre>\n *\n * <pre>\n * The return type of methods in your AI Service can be any of the following:\n * - a {@link String} or an {@link AiMessage}, if you want to get the answer from the LLM as-is\n * - a {@code List<String>} or {@code Set<String>}, if you want to receive the answer as a collection of items or bullet points\n * - any {@link Enum} or a {@code boolean}, if you want to use the LLM for classification\n * - a primitive or boxed Java type: {@code int}, {@code Double}, etc., if you want to use the LLM for data extraction\n * - many default Java types: {@code Date}, {@code LocalDateTime}, {@code BigDecimal}, etc., if you want to use the LLM for data extraction\n * - any custom POJO, if you want to use the LLM for data extraction.\n * - Result&lt;T&gt; if you want to access {@link TokenUsage} or sources ({@link Content}s retrieved during RAG), aside from T, which can be of any type listed above. For example: Result&lt;String&gt;, Result&lt;MyCustomPojo&gt;\n * For POJOs, it is advisable to use the \"json mode\" feature if the LLM provider supports it. For OpenAI, this can be enabled by calling {@code responseFormat(\"json_object\")} during model construction.\n *\n * </pre>\n * <p>\n * Let's see how we can classify the sentiment of a text:\n * <pre>\n * enum Sentiment {\n *     POSITIVE, NEUTRAL, NEGATIVE\n * }\n *\n * interface SentimentAnalyzer {\n *\n *     {@code @UserMessage}(\"Analyze sentiment of {{it}}\")\n *     Sentiment analyzeSentimentOf(String text);\n * }\n *\n * SentimentAnalyzer assistant = AiServices.create(SentimentAnalyzer.class, model);\n *\n * Sentiment sentiment = analyzeSentimentOf.chat(\"I love you\");\n * System.out.println(sentiment); // POSITIVE\n * </pre>\n * <p>\n * As demonstrated, you can put @{@link UserMessage} and @{@link SystemMessage} annotations above a method to define\n * templates for user and system messages, respectively.\n * In this example, the special {@code {{it}}} prompt template variable is used because there's only one method parameter.\n * However, you can use more parameters as demonstrated in the following example:\n * <pre>\n * interface Translator {\n *\n *     {@code @SystemMessage}(\"You are a professional translator into {{language}}\")\n *     {@code @UserMessage}(\"Translate the following text: {{text}}\")\n *     String translate(@V(\"text\") String text, @V(\"language\") String language);\n * }\n * </pre>\n * <p>\n * See more examples <a href=\"https://github.com/langchain4j/langchain4j-examples/tree/main/other-examples/src/main/java\">here</a>.\n *\n * @param <T> The interface for which AiServices will provide an implementation.\n */\npublic abstract class AiServices<T> {\n\n    protected static final String DEFAULT = \"default\";\n\n    protected final AiServiceContext context;\n\n    private boolean retrieverSet = false;\n    private boolean contentRetrieverSet = false;\n    private boolean retrievalAugmentorSet = false;\n\n    protected AiServices(AiServiceContext context) {\n        this.context = context;\n    }\n\n    /**\n     * Creates an AI Service (an implementation of the provided interface), that is backed by the provided chat model.\n     * This convenience method can be used to create simple AI Services.\n     * For more complex cases, please use {@link #builder}.\n     *\n     * @param aiService         The class of the interface to be implemented.\n     * @param chatLanguageModel The chat model to be used under the hood.\n     * @return An instance of the provided interface, implementing all its defined methods.\n     */\n    public static <T> T create(Class<T> aiService, ChatLanguageModel chatLanguageModel) {\n        return builder(aiService)\n                .chatLanguageModel(chatLanguageModel)\n                .build();\n    }\n\n    /**\n     * Creates an AI Service (an implementation of the provided interface), that is backed by the provided streaming chat model.\n     * This convenience method can be used to create simple AI Services.\n     * For more complex cases, please use {@link #builder}.\n     *\n     * @param aiService                  The class of the interface to be implemented.\n     * @param streamingChatLanguageModel The streaming chat model to be used under the hood.\n     *                                   The return type of all methods should be {@link TokenStream}.\n     * @return An instance of the provided interface, implementing all its defined methods.\n     */\n    public static <T> T create(Class<T> aiService, StreamingChatLanguageModel streamingChatLanguageModel) {\n        return builder(aiService)\n                .streamingChatLanguageModel(streamingChatLanguageModel)\n                .build();\n    }\n\n    /**\n     * Begins the construction of an AI Service.\n     *\n     * @param aiService The class of the interface to be implemented.\n     * @return builder\n     */\n    public static <T> AiServices<T> builder(Class<T> aiService) {\n        AiServiceContext context = new AiServiceContext(aiService);\n        for (AiServicesFactory factory : loadFactories(AiServicesFactory.class)) {\n            return factory.create(context);\n        }\n        return new DefaultAiServices<>(context);\n    }\n\n    /**\n     * Configures chat model that will be used under the hood of the AI Service.\n     * <p>\n     * Either {@link ChatLanguageModel} or {@link StreamingChatLanguageModel} should be configured,\n     * but not both at the same time.\n     *\n     * @param chatLanguageModel Chat model that will be used under the hood of the AI Service.\n     * @return builder\n     */\n    public AiServices<T> chatLanguageModel(ChatLanguageModel chatLanguageModel) {\n        context.chatModel = chatLanguageModel;\n        return this;\n    }\n\n    /**\n     * Configures streaming chat model that will be used under the hood of the AI Service.\n     * The methods of the AI Service must return a {@link TokenStream} type.\n     * <p>\n     * Either {@link ChatLanguageModel} or {@link StreamingChatLanguageModel} should be configured,\n     * but not both at the same time.\n     *\n     * @param streamingChatLanguageModel Streaming chat model that will be used under the hood of the AI Service.\n     * @return builder\n     */\n    public AiServices<T> streamingChatLanguageModel(StreamingChatLanguageModel streamingChatLanguageModel) {\n        context.streamingChatModel = streamingChatLanguageModel;\n        return this;\n    }\n\n    /**\n     * Configures the system message provider, which provides a system message to be used each time an AI service is invoked.\n     * <br>\n     * When both {@code @SystemMessage} and the system message provider are configured,\n     * {@code @SystemMessage} takes precedence.\n     *\n     * @param systemMessageProvider A {@link Function} that accepts a chat memory ID\n     *                              (a value of a method parameter annotated with @{@link MemoryId})\n     *                              and returns a system message to be used.\n     *                              If there is no parameter annotated with {@code @MemoryId},\n     *                              the value of memory ID is \"default\".\n     *                              The returned {@link String} can be either a complete system message\n     *                              or a system message template containing unresolved template variables (e.g. \"{{name}}\"),\n     *                              which will be resolved using the values of method parameters annotated with @{@link V}.\n     * @return builder\n     */\n    public AiServices<T> systemMessageProvider(Function<Object, String> systemMessageProvider) {\n        context.systemMessageProvider = systemMessageProvider.andThen(Optional::ofNullable);\n        return this;\n    }\n\n    /**\n     * Configures the chat memory that will be used to preserve conversation history between method calls.\n     * <p>\n     * Unless a {@link ChatMemory} or {@link ChatMemoryProvider} is configured, all method calls will be independent of each other.\n     * In other words, the LLM will not remember the conversation from the previous method calls.\n     * <p>\n     * The same {@link ChatMemory} instance will be used for every method call.\n     * <p>\n     * If you want to have a separate {@link ChatMemory} for each user/conversation, configure {@link #chatMemoryProvider} instead.\n     * <p>\n     * Either a {@link ChatMemory} or a {@link ChatMemoryProvider} can be configured, but not both simultaneously.\n     *\n     * @param chatMemory An instance of chat memory to be used by the AI Service.\n     * @return builder\n     */\n    public AiServices<T> chatMemory(ChatMemory chatMemory) {\n        context.chatMemories = new ConcurrentHashMap<>();\n        context.chatMemories.put(DEFAULT, chatMemory);\n        return this;\n    }\n\n    /**\n     * Configures the chat memory provider, which provides a dedicated instance of {@link ChatMemory} for each user/conversation.\n     * To distinguish between users/conversations, one of the method's arguments should be a memory ID (of any data type)\n     * annotated with {@link MemoryId}.\n     * For each new (previously unseen) memoryId, an instance of {@link ChatMemory} will be automatically obtained\n     * by invoking {@link ChatMemoryProvider#get(Object id)}.\n     * Example:\n     * <pre>\n     * interface Assistant {\n     *\n     *     String chat(@MemoryId int memoryId, @UserMessage String message);\n     * }\n     * </pre>\n     * If you prefer to use the same (shared) {@link ChatMemory} for all users/conversations, configure a {@link #chatMemory} instead.\n     * <p>\n     * Either a {@link ChatMemory} or a {@link ChatMemoryProvider} can be configured, but not both simultaneously.\n     *\n     * @param chatMemoryProvider The provider of a {@link ChatMemory} for each new user/conversation.\n     * @return builder\n     */\n    public AiServices<T> chatMemoryProvider(ChatMemoryProvider chatMemoryProvider) {\n        context.chatMemories = new ConcurrentHashMap<>();\n        context.chatMemoryProvider = chatMemoryProvider;\n        return this;\n    }\n\n    /**\n     * Configures a moderation model to be used for automatic content moderation.\n     * If a method in the AI Service is annotated with {@link Moderate}, the moderation model will be invoked\n     * to check the user content for any inappropriate or harmful material.\n     *\n     * @param moderationModel The moderation model to be used for content moderation.\n     * @return builder\n     * @see Moderate\n     */\n    public AiServices<T> moderationModel(ModerationModel moderationModel) {\n        context.moderationModel = moderationModel;\n        return this;\n    }\n\n    /**\n     * Configures the tools that the LLM can use.\n     *\n     * @param objectsWithTools One or more objects whose methods are annotated with {@link Tool}.\n     *                         All these tools (methods annotated with {@link Tool}) will be accessible to the LLM.\n     *                         Note that inherited methods are ignored.\n     * @return builder\n     * @see Tool\n     */\n    public AiServices<T> tools(Object... objectsWithTools) {\n        return tools(asList(objectsWithTools));\n    }\n\n    /**\n     * Configures the tools that the LLM can use.\n     *\n     * @param objectsWithTools A list of objects whose methods are annotated with {@link Tool}.\n     *                         All these tools (methods annotated with {@link Tool}) are accessible to the LLM.\n     *                         Note that inherited methods are ignored.\n     * @return builder\n     * @see Tool\n     */\n    public AiServices<T> tools(List<Object> objectsWithTools) { // TODO Collection?\n        // TODO validate uniqueness of tool names\n\n        if (context.toolSpecifications == null) {\n            context.toolSpecifications = new ArrayList<>();\n        }\n        if (context.toolExecutors == null) {\n            context.toolExecutors = new HashMap<>();\n        }\n\n        for (Object objectWithTool : objectsWithTools) {\n            if (objectWithTool instanceof Class) {\n                throw illegalConfiguration(\"Tool '%s' must be an object, not a class\", objectWithTool);\n            }\n\n            for (Method method : objectWithTool.getClass().getDeclaredMethods()) {\n                if (method.isAnnotationPresent(Tool.class)) {\n                    ToolSpecification toolSpecification = toolSpecificationFrom(method);\n                    context.toolSpecifications.add(toolSpecification);\n                    context.toolExecutors.put(toolSpecification.name(), new DefaultToolExecutor(objectWithTool, method));\n                }\n            }\n        }\n\n        return this;\n    }\n\n    /**\n     * Configures the tools that the LLM can use.\n     *\n     * @param tools A map of {@link ToolSpecification} to {@link ToolExecutor} entries.\n     *              This method of configuring tools is useful when tools must be configured programmatically.\n     *              Otherwise, it is recommended to use the {@link Tool}-annotated java methods\n     *              and configure tools with the {@link #tools(Object...)} and {@link #tools(List)} methods.\n     * @return builder\n     */\n    public AiServices<T> tools(Map<ToolSpecification, ToolExecutor> tools) {\n\n        if (context.toolSpecifications == null) {\n            context.toolSpecifications = new ArrayList<>();\n        }\n        if (context.toolExecutors == null) {\n            context.toolExecutors = new HashMap<>();\n        }\n\n        tools.forEach((toolSpecification, toolExecutor) -> {\n            context.toolSpecifications.add(toolSpecification);\n            context.toolExecutors.put(toolSpecification.name(), toolExecutor);\n        });\n\n        return this;\n    }\n\n    /**\n     * Deprecated. Use {@link #contentRetriever(ContentRetriever)}\n     * (e.g. {@link EmbeddingStoreContentRetriever}) instead.\n     * <br>\n     * Configures a retriever that will be invoked on every method call to fetch relevant information\n     * related to the current user message from an underlying source (e.g., embedding store).\n     * This relevant information is automatically injected into the message sent to the LLM.\n     *\n     * @param retriever The retriever to be used by the AI Service.\n     * @return builder\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Configures a content retriever to be invoked on every method call for retrieving relevant content\n     * related to the user's message from an underlying data source\n     * (e.g., an embedding store in the case of an {@link EmbeddingStoreContentRetriever}).\n     * The retrieved relevant content is then automatically incorporated into the message sent to the LLM.\n     * <br>\n     * This method provides a straightforward approach for those who do not require\n     * a customized {@link RetrievalAugmentor}.\n     * It configures a {@link DefaultRetrievalAugmentor} with the provided {@link ContentRetriever}.\n     *\n     * @param contentRetriever The content retriever to be used by the AI Service.\n     * @return builder\n     */\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Configures a retrieval augmentor to be invoked on every method call.\n     *\n     * @param retrievalAugmentor The retrieval augmentor to be used by the AI Service.\n     * @return builder\n     */\n    public AiServices<T> retrievalAugmentor(RetrievalAugmentor retrievalAugmentor) {\n        if (retrieverSet || contentRetrieverSet) {\n            throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n        }\n        retrievalAugmentorSet = true;\n        context.retrievalAugmentor = ensureNotNull(retrievalAugmentor, \"retrievalAugmentor\");\n        return this;\n    }\n\n    /**\n     * Constructs and returns the AI Service.\n     *\n     * @return An instance of the AI Service implementing the specified interface.\n     */\n    public abstract T build();\n\n    protected void performBasicValidation() {\n        if (context.chatModel == null && context.streamingChatModel == null) {\n            throw illegalConfiguration(\"Please specify either chatLanguageModel or streamingChatLanguageModel\");\n        }\n    }\n\n    public static List<ChatMessage> removeToolMessages(List<ChatMessage> messages) {\n        return messages.stream()\n                .filter(it -> !(it instanceof ToolExecutionResultMessage))\n                .filter(it -> !(it instanceof AiMessage && ((AiMessage) it).hasToolExecutionRequests()))\n                .collect(toList());\n    }\n\n    public static void verifyModerationIfNeeded(Future<Moderation> moderationFuture) {\n        if (moderationFuture != null) {\n            try {\n                Moderation moderation = moderationFuture.get();\n                if (moderation.flagged()) {\n                    throw new ModerationException(String.format(\"Text \\\"%s\\\" violates content policy\", moderation.flaggedText()));\n                }\n            } catch (InterruptedException | ExecutionException e) {\n                throw new RuntimeException(e);\n            }\n        }\n    }\n}\n\n```\n# Function Signature: @Deprecated    public AiServices<T> retriever(Retriever<TextSegment> retriever) {\n# Natural Language Annotations: /**\n     * Deprecated. Use {@link #contentRetriever(ContentRetriever)}\n     * (e.g. {@link EmbeddingStoreContentRetriever}) instead.\n     * <br>\n     * Configures a retriever that will be invoked on every method call to fetch relevant information\n     * related to the current user message from an underlying source (e.g., embedding store).\n     * This relevant information is automatically injected into the message sent to the LLM.\n     *\n     * @param retriever The retriever to be used by the AI Service.\n     * @return builder\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Deprecated\npublic AiServices<T> retriever(Retriever<TextSegment> retriever) {\n    if (retrievalAugmentorSet) {\n        throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n    }\n    retrieverSet = true;\n    context.retrievalAugmentor = new DefaultRetrievalAugmentor(retriever);\n    return this;\n}\n```", "  ```\npublic AiServices<T> retriever(Retriever<TextSegment> retriever) {\n    if (retrieverSet || contentRetrieverSet || retrievalAugmentorSet) {\n        throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n    }\n    retrieverSet = true;\n    context.retriever = ensureNotNull(retriever, \"retriever\");\n    return this;\n}\n```", "  ```\nAiServices<T> retriever(Retriever<TextSegment> retriever) {\n    if (retrieverSet || contentRetrieverSet) {\n        throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n    }\n\n    context.retrievalAugmentor = new DefaultRetrievalAugmentor(retriever, true);\n    return this;\n}\n```"]}, "langchain4j-langchain4j/src/main/java/dev/langchain4j/service/AiServices.java-contentRetriever": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j/src/main/java/dev/langchain4j/service/AiServices.java:\n```\npackage dev.langchain4j.service;\n\nimport dev.langchain4j.service.tool.DefaultToolExecutor;\nimport dev.langchain4j.agent.tool.Tool;\nimport dev.langchain4j.service.tool.ToolExecutor;\nimport dev.langchain4j.agent.tool.ToolSpecification;\nimport dev.langchain4j.data.message.AiMessage;\nimport dev.langchain4j.data.message.ChatMessage;\nimport dev.langchain4j.data.message.ToolExecutionResultMessage;\nimport dev.langchain4j.data.segment.TextSegment;\nimport dev.langchain4j.memory.ChatMemory;\nimport dev.langchain4j.memory.chat.ChatMemoryProvider;\nimport dev.langchain4j.model.chat.ChatLanguageModel;\nimport dev.langchain4j.model.chat.StreamingChatLanguageModel;\nimport dev.langchain4j.model.input.structured.StructuredPrompt;\nimport dev.langchain4j.model.moderation.Moderation;\nimport dev.langchain4j.model.moderation.ModerationModel;\nimport dev.langchain4j.model.output.TokenUsage;\nimport dev.langchain4j.rag.DefaultRetrievalAugmentor;\nimport dev.langchain4j.rag.RetrievalAugmentor;\nimport dev.langchain4j.rag.content.Content;\nimport dev.langchain4j.rag.content.retriever.ContentRetriever;\nimport dev.langchain4j.rag.content.retriever.EmbeddingStoreContentRetriever;\nimport dev.langchain4j.retriever.Retriever;\nimport dev.langchain4j.spi.services.AiServicesFactory;\n\nimport java.lang.reflect.Method;\nimport java.util.*;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.Future;\nimport java.util.function.Function;\n\nimport static dev.langchain4j.agent.tool.ToolSpecifications.toolSpecificationFrom;\nimport static dev.langchain4j.exception.IllegalConfigurationException.illegalConfiguration;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotNull;\nimport static dev.langchain4j.spi.ServiceHelper.loadFactories;\nimport static java.util.Arrays.asList;\nimport static java.util.stream.Collectors.toList;\n\n/**\n * AI Services provide a simpler and more flexible alternative to chains.\n * You can define your own API (a Java interface with one or more methods),\n * and {@code AiServices} will provide an implementation for it.\n * <p>\n * Currently, AI Services support:\n * <pre>\n * - Static system message templates, configured via @{@link SystemMessage} annotation on top of the method\n * - Dynamic system message templates, configured via {@link #systemMessageProvider(Function)}\n * - Static user message templates, configured via @{@link UserMessage} annotation on top of the method\n * - Dynamic user message templates, configured via method parameter annotated with @{@link UserMessage}\n * - Single (shared) {@link ChatMemory}, configured via {@link #chatMemory(ChatMemory)}\n * - Separate (per-user) {@code ChatMemory}, configured via {@link #chatMemoryProvider(ChatMemoryProvider)} and a method parameter annotated with @{@link MemoryId}\n * - RAG, configured via {@link #contentRetriever(ContentRetriever)} or {@link #retrievalAugmentor(RetrievalAugmentor)}\n * - Tools, configured via {@link #tools(List)} or {@link #tools(Object...)} and methods annotated with @{@link Tool}\n * - Various method return types (output parsers), see more details below\n * - Streaming (use {@link TokenStream} as a return type)\n * - Structured prompts as method arguments (see @{@link StructuredPrompt})\n * - Auto-moderation, configured via @{@link Moderate} annotation\n * </pre>\n * <p>\n * Here is the simplest example of an AI Service:\n *\n * <pre>\n * interface Assistant {\n *\n *     String chat(String userMessage);\n * }\n *\n * Assistant assistant = AiServices.create(Assistant.class, model);\n *\n * String answer = assistant.chat(\"hello\");\n * System.out.println(answer); // Hello, how can I help you today?\n * </pre>\n *\n * <pre>\n * The return type of methods in your AI Service can be any of the following:\n * - a {@link String} or an {@link AiMessage}, if you want to get the answer from the LLM as-is\n * - a {@code List<String>} or {@code Set<String>}, if you want to receive the answer as a collection of items or bullet points\n * - any {@link Enum} or a {@code boolean}, if you want to use the LLM for classification\n * - a primitive or boxed Java type: {@code int}, {@code Double}, etc., if you want to use the LLM for data extraction\n * - many default Java types: {@code Date}, {@code LocalDateTime}, {@code BigDecimal}, etc., if you want to use the LLM for data extraction\n * - any custom POJO, if you want to use the LLM for data extraction.\n * - Result&lt;T&gt; if you want to access {@link TokenUsage} or sources ({@link Content}s retrieved during RAG), aside from T, which can be of any type listed above. For example: Result&lt;String&gt;, Result&lt;MyCustomPojo&gt;\n * For POJOs, it is advisable to use the \"json mode\" feature if the LLM provider supports it. For OpenAI, this can be enabled by calling {@code responseFormat(\"json_object\")} during model construction.\n *\n * </pre>\n * <p>\n * Let's see how we can classify the sentiment of a text:\n * <pre>\n * enum Sentiment {\n *     POSITIVE, NEUTRAL, NEGATIVE\n * }\n *\n * interface SentimentAnalyzer {\n *\n *     {@code @UserMessage}(\"Analyze sentiment of {{it}}\")\n *     Sentiment analyzeSentimentOf(String text);\n * }\n *\n * SentimentAnalyzer assistant = AiServices.create(SentimentAnalyzer.class, model);\n *\n * Sentiment sentiment = analyzeSentimentOf.chat(\"I love you\");\n * System.out.println(sentiment); // POSITIVE\n * </pre>\n * <p>\n * As demonstrated, you can put @{@link UserMessage} and @{@link SystemMessage} annotations above a method to define\n * templates for user and system messages, respectively.\n * In this example, the special {@code {{it}}} prompt template variable is used because there's only one method parameter.\n * However, you can use more parameters as demonstrated in the following example:\n * <pre>\n * interface Translator {\n *\n *     {@code @SystemMessage}(\"You are a professional translator into {{language}}\")\n *     {@code @UserMessage}(\"Translate the following text: {{text}}\")\n *     String translate(@V(\"text\") String text, @V(\"language\") String language);\n * }\n * </pre>\n * <p>\n * See more examples <a href=\"https://github.com/langchain4j/langchain4j-examples/tree/main/other-examples/src/main/java\">here</a>.\n *\n * @param <T> The interface for which AiServices will provide an implementation.\n */\npublic abstract class AiServices<T> {\n\n    protected static final String DEFAULT = \"default\";\n\n    protected final AiServiceContext context;\n\n    private boolean retrieverSet = false;\n    private boolean contentRetrieverSet = false;\n    private boolean retrievalAugmentorSet = false;\n\n    protected AiServices(AiServiceContext context) {\n        this.context = context;\n    }\n\n    /**\n     * Creates an AI Service (an implementation of the provided interface), that is backed by the provided chat model.\n     * This convenience method can be used to create simple AI Services.\n     * For more complex cases, please use {@link #builder}.\n     *\n     * @param aiService         The class of the interface to be implemented.\n     * @param chatLanguageModel The chat model to be used under the hood.\n     * @return An instance of the provided interface, implementing all its defined methods.\n     */\n    public static <T> T create(Class<T> aiService, ChatLanguageModel chatLanguageModel) {\n        return builder(aiService)\n                .chatLanguageModel(chatLanguageModel)\n                .build();\n    }\n\n    /**\n     * Creates an AI Service (an implementation of the provided interface), that is backed by the provided streaming chat model.\n     * This convenience method can be used to create simple AI Services.\n     * For more complex cases, please use {@link #builder}.\n     *\n     * @param aiService                  The class of the interface to be implemented.\n     * @param streamingChatLanguageModel The streaming chat model to be used under the hood.\n     *                                   The return type of all methods should be {@link TokenStream}.\n     * @return An instance of the provided interface, implementing all its defined methods.\n     */\n    public static <T> T create(Class<T> aiService, StreamingChatLanguageModel streamingChatLanguageModel) {\n        return builder(aiService)\n                .streamingChatLanguageModel(streamingChatLanguageModel)\n                .build();\n    }\n\n    /**\n     * Begins the construction of an AI Service.\n     *\n     * @param aiService The class of the interface to be implemented.\n     * @return builder\n     */\n    public static <T> AiServices<T> builder(Class<T> aiService) {\n        AiServiceContext context = new AiServiceContext(aiService);\n        for (AiServicesFactory factory : loadFactories(AiServicesFactory.class)) {\n            return factory.create(context);\n        }\n        return new DefaultAiServices<>(context);\n    }\n\n    /**\n     * Configures chat model that will be used under the hood of the AI Service.\n     * <p>\n     * Either {@link ChatLanguageModel} or {@link StreamingChatLanguageModel} should be configured,\n     * but not both at the same time.\n     *\n     * @param chatLanguageModel Chat model that will be used under the hood of the AI Service.\n     * @return builder\n     */\n    public AiServices<T> chatLanguageModel(ChatLanguageModel chatLanguageModel) {\n        context.chatModel = chatLanguageModel;\n        return this;\n    }\n\n    /**\n     * Configures streaming chat model that will be used under the hood of the AI Service.\n     * The methods of the AI Service must return a {@link TokenStream} type.\n     * <p>\n     * Either {@link ChatLanguageModel} or {@link StreamingChatLanguageModel} should be configured,\n     * but not both at the same time.\n     *\n     * @param streamingChatLanguageModel Streaming chat model that will be used under the hood of the AI Service.\n     * @return builder\n     */\n    public AiServices<T> streamingChatLanguageModel(StreamingChatLanguageModel streamingChatLanguageModel) {\n        context.streamingChatModel = streamingChatLanguageModel;\n        return this;\n    }\n\n    /**\n     * Configures the system message provider, which provides a system message to be used each time an AI service is invoked.\n     * <br>\n     * When both {@code @SystemMessage} and the system message provider are configured,\n     * {@code @SystemMessage} takes precedence.\n     *\n     * @param systemMessageProvider A {@link Function} that accepts a chat memory ID\n     *                              (a value of a method parameter annotated with @{@link MemoryId})\n     *                              and returns a system message to be used.\n     *                              If there is no parameter annotated with {@code @MemoryId},\n     *                              the value of memory ID is \"default\".\n     *                              The returned {@link String} can be either a complete system message\n     *                              or a system message template containing unresolved template variables (e.g. \"{{name}}\"),\n     *                              which will be resolved using the values of method parameters annotated with @{@link V}.\n     * @return builder\n     */\n    public AiServices<T> systemMessageProvider(Function<Object, String> systemMessageProvider) {\n        context.systemMessageProvider = systemMessageProvider.andThen(Optional::ofNullable);\n        return this;\n    }\n\n    /**\n     * Configures the chat memory that will be used to preserve conversation history between method calls.\n     * <p>\n     * Unless a {@link ChatMemory} or {@link ChatMemoryProvider} is configured, all method calls will be independent of each other.\n     * In other words, the LLM will not remember the conversation from the previous method calls.\n     * <p>\n     * The same {@link ChatMemory} instance will be used for every method call.\n     * <p>\n     * If you want to have a separate {@link ChatMemory} for each user/conversation, configure {@link #chatMemoryProvider} instead.\n     * <p>\n     * Either a {@link ChatMemory} or a {@link ChatMemoryProvider} can be configured, but not both simultaneously.\n     *\n     * @param chatMemory An instance of chat memory to be used by the AI Service.\n     * @return builder\n     */\n    public AiServices<T> chatMemory(ChatMemory chatMemory) {\n        context.chatMemories = new ConcurrentHashMap<>();\n        context.chatMemories.put(DEFAULT, chatMemory);\n        return this;\n    }\n\n    /**\n     * Configures the chat memory provider, which provides a dedicated instance of {@link ChatMemory} for each user/conversation.\n     * To distinguish between users/conversations, one of the method's arguments should be a memory ID (of any data type)\n     * annotated with {@link MemoryId}.\n     * For each new (previously unseen) memoryId, an instance of {@link ChatMemory} will be automatically obtained\n     * by invoking {@link ChatMemoryProvider#get(Object id)}.\n     * Example:\n     * <pre>\n     * interface Assistant {\n     *\n     *     String chat(@MemoryId int memoryId, @UserMessage String message);\n     * }\n     * </pre>\n     * If you prefer to use the same (shared) {@link ChatMemory} for all users/conversations, configure a {@link #chatMemory} instead.\n     * <p>\n     * Either a {@link ChatMemory} or a {@link ChatMemoryProvider} can be configured, but not both simultaneously.\n     *\n     * @param chatMemoryProvider The provider of a {@link ChatMemory} for each new user/conversation.\n     * @return builder\n     */\n    public AiServices<T> chatMemoryProvider(ChatMemoryProvider chatMemoryProvider) {\n        context.chatMemories = new ConcurrentHashMap<>();\n        context.chatMemoryProvider = chatMemoryProvider;\n        return this;\n    }\n\n    /**\n     * Configures a moderation model to be used for automatic content moderation.\n     * If a method in the AI Service is annotated with {@link Moderate}, the moderation model will be invoked\n     * to check the user content for any inappropriate or harmful material.\n     *\n     * @param moderationModel The moderation model to be used for content moderation.\n     * @return builder\n     * @see Moderate\n     */\n    public AiServices<T> moderationModel(ModerationModel moderationModel) {\n        context.moderationModel = moderationModel;\n        return this;\n    }\n\n    /**\n     * Configures the tools that the LLM can use.\n     *\n     * @param objectsWithTools One or more objects whose methods are annotated with {@link Tool}.\n     *                         All these tools (methods annotated with {@link Tool}) will be accessible to the LLM.\n     *                         Note that inherited methods are ignored.\n     * @return builder\n     * @see Tool\n     */\n    public AiServices<T> tools(Object... objectsWithTools) {\n        return tools(asList(objectsWithTools));\n    }\n\n    /**\n     * Configures the tools that the LLM can use.\n     *\n     * @param objectsWithTools A list of objects whose methods are annotated with {@link Tool}.\n     *                         All these tools (methods annotated with {@link Tool}) are accessible to the LLM.\n     *                         Note that inherited methods are ignored.\n     * @return builder\n     * @see Tool\n     */\n    public AiServices<T> tools(List<Object> objectsWithTools) { // TODO Collection?\n        // TODO validate uniqueness of tool names\n\n        if (context.toolSpecifications == null) {\n            context.toolSpecifications = new ArrayList<>();\n        }\n        if (context.toolExecutors == null) {\n            context.toolExecutors = new HashMap<>();\n        }\n\n        for (Object objectWithTool : objectsWithTools) {\n            if (objectWithTool instanceof Class) {\n                throw illegalConfiguration(\"Tool '%s' must be an object, not a class\", objectWithTool);\n            }\n\n            for (Method method : objectWithTool.getClass().getDeclaredMethods()) {\n                if (method.isAnnotationPresent(Tool.class)) {\n                    ToolSpecification toolSpecification = toolSpecificationFrom(method);\n                    context.toolSpecifications.add(toolSpecification);\n                    context.toolExecutors.put(toolSpecification.name(), new DefaultToolExecutor(objectWithTool, method));\n                }\n            }\n        }\n\n        return this;\n    }\n\n    /**\n     * Configures the tools that the LLM can use.\n     *\n     * @param tools A map of {@link ToolSpecification} to {@link ToolExecutor} entries.\n     *              This method of configuring tools is useful when tools must be configured programmatically.\n     *              Otherwise, it is recommended to use the {@link Tool}-annotated java methods\n     *              and configure tools with the {@link #tools(Object...)} and {@link #tools(List)} methods.\n     * @return builder\n     */\n    public AiServices<T> tools(Map<ToolSpecification, ToolExecutor> tools) {\n\n        if (context.toolSpecifications == null) {\n            context.toolSpecifications = new ArrayList<>();\n        }\n        if (context.toolExecutors == null) {\n            context.toolExecutors = new HashMap<>();\n        }\n\n        tools.forEach((toolSpecification, toolExecutor) -> {\n            context.toolSpecifications.add(toolSpecification);\n            context.toolExecutors.put(toolSpecification.name(), toolExecutor);\n        });\n\n        return this;\n    }\n\n    /**\n     * Deprecated. Use {@link #contentRetriever(ContentRetriever)}\n     * (e.g. {@link EmbeddingStoreContentRetriever}) instead.\n     * <br>\n     * Configures a retriever that will be invoked on every method call to fetch relevant information\n     * related to the current user message from an underlying source (e.g., embedding store).\n     * This relevant information is automatically injected into the message sent to the LLM.\n     *\n     * @param retriever The retriever to be used by the AI Service.\n     * @return builder\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Configures a content retriever to be invoked on every method call for retrieving relevant content\n     * related to the user's message from an underlying data source\n     * (e.g., an embedding store in the case of an {@link EmbeddingStoreContentRetriever}).\n     * The retrieved relevant content is then automatically incorporated into the message sent to the LLM.\n     * <br>\n     * This method provides a straightforward approach for those who do not require\n     * a customized {@link RetrievalAugmentor}.\n     * It configures a {@link DefaultRetrievalAugmentor} with the provided {@link ContentRetriever}.\n     *\n     * @param contentRetriever The content retriever to be used by the AI Service.\n     * @return builder\n     */\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Configures a retrieval augmentor to be invoked on every method call.\n     *\n     * @param retrievalAugmentor The retrieval augmentor to be used by the AI Service.\n     * @return builder\n     */\n    public AiServices<T> retrievalAugmentor(RetrievalAugmentor retrievalAugmentor) {\n        if (retrieverSet || contentRetrieverSet) {\n            throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n        }\n        retrievalAugmentorSet = true;\n        context.retrievalAugmentor = ensureNotNull(retrievalAugmentor, \"retrievalAugmentor\");\n        return this;\n    }\n\n    /**\n     * Constructs and returns the AI Service.\n     *\n     * @return An instance of the AI Service implementing the specified interface.\n     */\n    public abstract T build();\n\n    protected void performBasicValidation() {\n        if (context.chatModel == null && context.streamingChatModel == null) {\n            throw illegalConfiguration(\"Please specify either chatLanguageModel or streamingChatLanguageModel\");\n        }\n    }\n\n    public static List<ChatMessage> removeToolMessages(List<ChatMessage> messages) {\n        return messages.stream()\n                .filter(it -> !(it instanceof ToolExecutionResultMessage))\n                .filter(it -> !(it instanceof AiMessage && ((AiMessage) it).hasToolExecutionRequests()))\n                .collect(toList());\n    }\n\n    public static void verifyModerationIfNeeded(Future<Moderation> moderationFuture) {\n        if (moderationFuture != null) {\n            try {\n                Moderation moderation = moderationFuture.get();\n                if (moderation.flagged()) {\n                    throw new ModerationException(String.format(\"Text \\\"%s\\\" violates content policy\", moderation.flaggedText()));\n                }\n            } catch (InterruptedException | ExecutionException e) {\n                throw new RuntimeException(e);\n            }\n        }\n    }\n}\n\n```\n# Function Signature: public AiServices<T> contentRetriever(ContentRetriever contentRetriever) {\n# Natural Language Annotations: /**\n     * Configures a content retriever to be invoked on every method call for retrieving relevant content\n     * related to the user's message from an underlying data source\n     * (e.g., an embedding store in the case of an {@link EmbeddingStoreContentRetriever}).\n     * The retrieved relevant content is then automatically incorporated into the message sent to the LLM.\n     * <br>\n     * This method provides a straightforward approach for those who do not require\n     * a customized {@link RetrievalAugmentor}.\n     * It configures a {@link DefaultRetrievalAugmentor} with the provided {@link ContentRetriever}.\n     *\n     * @param contentRetriever The content retriever to be used by the AI Service.\n     * @return builder\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic AiServices<T> contentRetriever(ContentRetriever contentRetriever) {\n        if (retrievalAugmentorSet || retrieverSet) {\n            throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n        }\n        contentRetrieverSet = true;\n        context.retrievalAugmentor = new DefaultRetrievalAugmentor(ensureNotNull(contentRetriever, \"contentRetriever\"));\n        return this;\n    }\n```", "  ```\npublic AiServices<T> contentRetriever(ContentRetriever contentRetriever) {\n    if (retrieverSet || contentRetrieverSet || retrievalAugmentorSet) {\n        throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n    }\n    context.retrievalAugmentor = new DefaultRetrievalAugmentor(contentRetriever);\n    return this;\n}\n```", "  ```\npublic AiServices<T> contentRetriever(ContentRetriever contentRetriever) {\n    if (contentRetrieverSet || retrievalAugmentorSet) {\n        throw illegalConfiguration(\"Only one out of [contentRetriever, retrievalAugmentor] can be set\");\n    }\n    contentRetrieverSet = true;\n    context.retrievalAugmentor = new DefaultRetrievalAugmentor(context.templates.getOrDefault(\"ContentRetriever\", Collections.emptyList()), contentRetriever);\n    return this;\n}\n```"]}, "langchain4j-langchain4j-pgvector/src/main/java/dev/langchain4j/store/embedding/pgvector/PgVectorEmbeddingStore.java-add": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-pgvector/src/main/java/dev/langchain4j/store/embedding/pgvector/PgVectorEmbeddingStore.java:\n```\npackage dev.langchain4j.store.embedding.pgvector;\n\nimport com.pgvector.PGvector;\nimport dev.langchain4j.data.document.Metadata;\nimport dev.langchain4j.data.embedding.Embedding;\nimport dev.langchain4j.data.segment.TextSegment;\nimport dev.langchain4j.store.embedding.EmbeddingMatch;\nimport dev.langchain4j.store.embedding.EmbeddingSearchRequest;\nimport dev.langchain4j.store.embedding.EmbeddingSearchResult;\nimport dev.langchain4j.store.embedding.EmbeddingStore;\nimport dev.langchain4j.store.embedding.filter.Filter;\nimport lombok.Builder;\nimport lombok.NoArgsConstructor;\nimport org.postgresql.ds.PGSimpleDataSource;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport javax.sql.DataSource;\nimport java.sql.*;\nimport java.util.*;\nimport java.util.stream.IntStream;\n\nimport static dev.langchain4j.internal.Utils.*;\nimport static dev.langchain4j.internal.ValidationUtils.*;\nimport static java.lang.String.join;\nimport static java.util.Collections.nCopies;\nimport static java.util.Collections.singletonList;\nimport static java.util.stream.Collectors.toList;\n\n/**\n * PGVector EmbeddingStore Implementation\n * <p>\n * Only cosine similarity is used.\n * Only ivfflat index is used.\n */\n@NoArgsConstructor(force = true) // Needed for inherited bean injection validation\npublic class PgVectorEmbeddingStore implements EmbeddingStore<TextSegment> {\n    private static final Logger log = LoggerFactory.getLogger(PgVectorEmbeddingStore.class);\n    /**\n     * Datasource used to create the store\n     */\n    protected final DataSource datasource;\n    /**\n     * Embeddings table name\n     */\n    protected final String table;\n    /**\n     * Metadata handler\n     */\n    final MetadataHandler metadataHandler;\n\n    /**\n     * Constructor for PgVectorEmbeddingStore Class\n     *\n     * @param datasource            The datasource to use\n     * @param table                 The database table\n     * @param dimension             The vector dimension\n     * @param useIndex              Should use <a href=\"https://github.com/pgvector/pgvector#ivfflat\">IVFFlat</a> index\n     * @param indexListSize         The IVFFlat number of lists\n     * @param createTable           Should create table automatically\n     * @param dropTableFirst        Should drop table first, usually for testing\n     * @param metadataStorageConfig The {@link MetadataStorageConfig} config.\n     */\n    @Builder(builderMethodName = \"datasourceBuilder\", builderClassName = \"DatasourceBuilder\")\n    protected PgVectorEmbeddingStore(DataSource datasource,\n                                     String table,\n                                     Integer dimension,\n                                     Boolean useIndex,\n                                     Integer indexListSize,\n                                     Boolean createTable,\n                                     Boolean dropTableFirst,\n                                     MetadataStorageConfig metadataStorageConfig) {\n        this.datasource = ensureNotNull(datasource, \"datasource\");\n        this.table = ensureNotBlank(table, \"table\");\n        MetadataStorageConfig config = getOrDefault(metadataStorageConfig, DefaultMetadataStorageConfig.defaultConfig());\n        this.metadataHandler = MetadataHandlerFactory.get(config);\n        useIndex = getOrDefault(useIndex, false);\n        createTable = getOrDefault(createTable, true);\n        dropTableFirst = getOrDefault(dropTableFirst, false);\n\n        initTable(dropTableFirst, createTable, useIndex, dimension, indexListSize);\n    }\n\n    /**\n     * Constructor for PgVectorEmbeddingStore Class\n     * Use this builder when you don't have datasource management.\n     *\n     * @param host                  The database host\n     * @param port                  The database port\n     * @param user                  The database user\n     * @param password              The database password\n     * @param database              The database name\n     * @param table                 The database table\n     * @param dimension             The vector dimension\n     * @param useIndex              Should use <a href=\"https://github.com/pgvector/pgvector#ivfflat\">IVFFlat</a> index\n     * @param indexListSize         The IVFFlat number of lists\n     * @param createTable           Should create table automatically\n     * @param dropTableFirst        Should drop table first, usually for testing\n     * @param metadataStorageConfig The {@link MetadataStorageConfig} config.\n     */\n    @SuppressWarnings(\"unused\")\n    @Builder\n    protected PgVectorEmbeddingStore(\n            String host,\n            Integer port,\n            String user,\n            String password,\n            String database,\n            String table,\n            Integer dimension,\n            Boolean useIndex,\n            Integer indexListSize,\n            Boolean createTable,\n            Boolean dropTableFirst,\n            MetadataStorageConfig metadataStorageConfig\n    ) {\n        this(createDataSource(host, port, user, password, database),\n                table, dimension, useIndex, indexListSize, createTable, dropTableFirst, metadataStorageConfig);\n    }\n\n    private static DataSource createDataSource(String host, Integer port, String user, String password, String database) {\n        host = ensureNotBlank(host, \"host\");\n        port = ensureGreaterThanZero(port, \"port\");\n        user = ensureNotBlank(user, \"user\");\n        password = ensureNotBlank(password, \"password\");\n        database = ensureNotBlank(database, \"database\");\n\n        PGSimpleDataSource source = new PGSimpleDataSource();\n        source.setServerNames(new String[]{host});\n        source.setPortNumbers(new int[]{port});\n        source.setDatabaseName(database);\n        source.setUser(user);\n        source.setPassword(password);\n\n        return source;\n    }\n\n\n    /**\n     * Initialize metadata table following configuration\n     *\n     * @param dropTableFirst Should drop table first, usually for testing\n     * @param createTable    Should create table automatically\n     * @param useIndex       Should use <a href=\"https://github.com/pgvector/pgvector#ivfflat\">IVFFlat</a> index\n     * @param dimension      The vector dimension\n     * @param indexListSize  The IVFFlat number of lists\n     */\n    protected void initTable(Boolean dropTableFirst, Boolean createTable, Boolean useIndex, Integer dimension,\n                             Integer indexListSize) {\n        String query = \"init\";\n        try (Connection connection = getConnection(); Statement statement = connection.createStatement()) {\n            if (dropTableFirst) {\n                statement.executeUpdate(String.format(\"DROP TABLE IF EXISTS %s\", table));\n            }\n            if (createTable) {\n                query = String.format(\"CREATE TABLE IF NOT EXISTS %s (embedding_id UUID PRIMARY KEY, \" +\n                                \"embedding vector(%s), text TEXT NULL, %s )\",\n                        table, ensureGreaterThanZero(dimension, \"dimension\"),\n                        metadataHandler.columnDefinitionsString());\n                statement.executeUpdate(query);\n                metadataHandler.createMetadataIndexes(statement, table);\n            }\n            if (useIndex) {\n                final String indexName = table + \"_ivfflat_index\";\n                query = String.format(\n                        \"CREATE INDEX IF NOT EXISTS %s ON %s \" +\n                                \"USING ivfflat (embedding vector_cosine_ops) \" +\n                                \"WITH (lists = %s)\",\n                        indexName, table, ensureGreaterThanZero(indexListSize, \"indexListSize\"));\n                statement.executeUpdate(query);\n            }\n        } catch (SQLException e) {\n            throw new RuntimeException(String.format(\"Failed to execute '%s'\", query), e);\n        }\n    }\n\n    /**\n     * Adds a given embedding to the store.\n     *\n     * @param embedding The embedding to be added to the store.\n     * @return The auto-generated ID associated with the added embedding.\n     */\n\n\n\n\n\n\n\n    /**\n     * Adds a given embedding to the store.\n     *\n     * @param id        The unique identifier for the embedding to be added.\n     * @param embedding The embedding to be added to the store.\n     */\n    @Override\n    public void add(String id, Embedding embedding) {\n        addInternal(id, embedding, null);\n    }\n\n    /**\n     * Adds a given embedding and the corresponding content that has been embedded to the store.\n     *\n     * @param embedding   The embedding to be added to the store.\n     * @param textSegment Original content that was embedded.\n     * @return The auto-generated ID associated with the added embedding.\n     */\n    @Override\n    public String add(Embedding embedding, TextSegment textSegment) {\n        String id = randomUUID();\n        addInternal(id, embedding, textSegment);\n        return id;\n    }\n\n    /**\n     * Adds multiple embeddings to the store.\n     *\n     * @param embeddings A list of embeddings to be added to the store.\n     * @return A list of auto-generated IDs associated with the added embeddings.\n     */\n    @Override\n    public List<String> addAll(List<Embedding> embeddings) {\n        List<String> ids = embeddings.stream().map(ignored -> randomUUID()).collect(toList());\n        addAllInternal(ids, embeddings, null);\n        return ids;\n    }\n\n    /**\n     * Adds multiple embeddings and their corresponding contents that have been embedded to the store.\n     *\n     * @param embeddings A list of embeddings to be added to the store.\n     * @param embedded   A list of original contents that were embedded.\n     * @return A list of auto-generated IDs associated with the added embeddings.\n     */\n    @Override\n    public List<String> addAll(List<Embedding> embeddings, List<TextSegment> embedded) {\n        List<String> ids = embeddings.stream().map(ignored -> randomUUID()).collect(toList());\n        addAllInternal(ids, embeddings, embedded);\n        return ids;\n    }\n\n    @Override\n    public void removeAll(Collection<String> ids) {\n        ensureNotEmpty(ids, \"ids\");\n        String sql = String.format(\"DELETE FROM %s WHERE embedding_id = ANY (?)\", table);\n        try (Connection connection = getConnection();\n             PreparedStatement statement = connection.prepareStatement(sql)) {\n            Array array = connection.createArrayOf(\"uuid\", ids.stream().map(UUID::fromString).toArray());\n            statement.setArray(1, array);\n            statement.executeUpdate();\n        } catch (SQLException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    @Override\n    public void removeAll(Filter filter) {\n        ensureNotNull(filter, \"filter\");\n        String whereClause = metadataHandler.whereClause(filter);\n        String sql = String.format(\"DELETE FROM %s WHERE %s\", table, whereClause);\n        try (Connection connection = getConnection();\n             PreparedStatement statement = connection.prepareStatement(sql)) {\n            statement.executeUpdate();\n        } catch (SQLException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    @Override\n    public void removeAll() {\n        try (Connection connection = getConnection();\n             Statement statement = connection.createStatement()) {\n            statement.executeUpdate(String.format(\"TRUNCATE TABLE %s\", table));\n        } catch (SQLException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    /**\n     * Searches for the most similar (closest in the embedding space) {@link Embedding}s.\n     * <br>\n     * All search criteria are defined inside the {@link EmbeddingSearchRequest}.\n     * <br>\n     * {@link EmbeddingSearchRequest#filter()} is used to filter by meta dada.\n     *\n     * @param request A request to search in an {@link EmbeddingStore}. Contains all search criteria.\n     * @return An {@link EmbeddingSearchResult} containing all found {@link Embedding}s.\n     */\n    @Override\n    public EmbeddingSearchResult<TextSegment> search(EmbeddingSearchRequest request) {\n        Embedding referenceEmbedding = request.queryEmbedding();\n        int maxResults = request.maxResults();\n        double minScore = request.minScore();\n        Filter filter = request.filter();\n\n        List<EmbeddingMatch<TextSegment>> result = new ArrayList<>();\n        try (Connection connection = getConnection()) {\n            String referenceVector = Arrays.toString(referenceEmbedding.vector());\n            String whereClause = (filter == null) ? \"\" : metadataHandler.whereClause(filter);\n            whereClause = (whereClause.isEmpty()) ? \"\" : \"WHERE \" + whereClause;\n            String query = String.format(\n                    \"WITH temp AS (SELECT (2 - (embedding <=> '%s')) / 2 AS score, embedding_id, embedding, text, \" +\n                            \"%s FROM %s %s) SELECT * FROM temp WHERE score >= %s ORDER BY score desc LIMIT %s;\",\n                    referenceVector, join(\",\", metadataHandler.columnsNames()), table, whereClause, minScore, maxResults);\n            try (PreparedStatement selectStmt = connection.prepareStatement(query)) {\n                try (ResultSet resultSet = selectStmt.executeQuery()) {\n                    while (resultSet.next()) {\n                        double score = resultSet.getDouble(\"score\");\n                        String embeddingId = resultSet.getString(\"embedding_id\");\n\n                        PGvector vector = (PGvector) resultSet.getObject(\"embedding\");\n                        Embedding embedding = new Embedding(vector.toArray());\n\n                        String text = resultSet.getString(\"text\");\n                        TextSegment textSegment = null;\n                        if (isNotNullOrBlank(text)) {\n                            Metadata metadata = metadataHandler.fromResultSet(resultSet);\n                            textSegment = TextSegment.from(text, metadata);\n                        }\n                        result.add(new EmbeddingMatch<>(score, embeddingId, embedding, textSegment));\n                    }\n                }\n            }\n        } catch (SQLException e) {\n            throw new RuntimeException(e);\n        }\n        return new EmbeddingSearchResult<>(result);\n    }\n\n    private void addInternal(String id, Embedding embedding, TextSegment embedded) {\n        addAllInternal(\n                singletonList(id),\n                singletonList(embedding),\n                embedded == null ? null : singletonList(embedded));\n    }\n\n    private void addAllInternal(\n            List<String> ids, List<Embedding> embeddings, List<TextSegment> embedded) {\n        if (isNullOrEmpty(ids) || isNullOrEmpty(embeddings)) {\n            log.info(\"Empty embeddings - no ops\");\n            return;\n        }\n        ensureTrue(ids.size() == embeddings.size(), \"ids size is not equal to embeddings size\");\n        ensureTrue(embedded == null || embeddings.size() == embedded.size(),\n                \"embeddings size is not equal to embedded size\");\n\n        try (Connection connection = getConnection()) {\n            String query = String.format(\n                    \"INSERT INTO %s (embedding_id, embedding, text, %s) VALUES (?, ?, ?, %s)\" +\n                            \"ON CONFLICT (embedding_id) DO UPDATE SET \" +\n                            \"embedding = EXCLUDED.embedding,\" +\n                            \"text = EXCLUDED.text,\" +\n                            \"%s;\",\n                    table, join(\",\", metadataHandler.columnsNames()),\n                    join(\",\", nCopies(metadataHandler.columnsNames().size(), \"?\")),\n                    metadataHandler.insertClause());\n            try (PreparedStatement upsertStmt = connection.prepareStatement(query)) {\n                for (int i = 0; i < ids.size(); ++i) {\n                    upsertStmt.setObject(1, UUID.fromString(ids.get(i)));\n                    upsertStmt.setObject(2, new PGvector(embeddings.get(i).vector()));\n\n                    if (embedded != null && embedded.get(i) != null) {\n                        upsertStmt.setObject(3, embedded.get(i).text());\n                        metadataHandler.setMetadata(upsertStmt, 4, embedded.get(i).metadata());\n                    } else {\n                        upsertStmt.setNull(3, Types.VARCHAR);\n                        IntStream.range(4, 4 + metadataHandler.columnsNames().size()).forEach(\n                                j -> {\n                                    try {\n                                        upsertStmt.setNull(j, Types.OTHER);\n                                    } catch (SQLException e) {\n                                        throw new RuntimeException(e);\n                                    }\n                                });\n                    }\n                    upsertStmt.addBatch();\n                }\n                upsertStmt.executeBatch();\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    /**\n     * Datasource connection\n     * Creates the vector extension and add the vector type if it does not exist.\n     * Could be overridden in case extension creation and adding type is done at datasource initialization step.\n     *\n     * @return Datasource connection\n     * @throws SQLException exception\n     */\n    protected Connection getConnection() throws SQLException {\n        Connection connection = datasource.getConnection();\n        // Find a way to do the following code in connection initialization.\n        // Here we assume the datasource could handle a connection pool\n        // and we should add the vector type on each connection\n        try (Statement statement = connection.createStatement()) {\n            statement.executeUpdate(\"CREATE EXTENSION IF NOT EXISTS vector\");\n        }\n        PGvector.addVectorType(connection);\n        return connection;\n    }\n}\n\n```\n# Function Signature: @Override    public String add(Embedding embedding) {\n# Natural Language Annotations: /**\n     * Adds a given embedding to the store.\n     *\n     * @param embedding The embedding to be added to the store.\n     * @return The auto-generated ID associated with the added embedding.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n    @Override\n    public String add(Embedding embedding) {\n        String id = randomUUID();\n        addInternal(id, embedding, null);\n        return id;\n    }\n```", "  ```\n@Override\n    public String add(Embedding embedding) {\n        String id = randomUUID();\n        addInternal(id, embedding, null);\n        return id;\n    }\n```", "  ```public String add(Embedding embedding) {\n        String id = randomUUID();\n        addInternal(id, embedding, null);\n        return id;\n    }```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java-toolSpecificationsFrom": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java:\n```\npackage dev.langchain4j.agent.tool;\n\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.ARRAY;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.BOOLEAN;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.INTEGER;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.NUMBER;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.OBJECT;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.STRING;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.description;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.enums;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.from;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.items;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.objectItems;\nimport static dev.langchain4j.internal.TypeUtils.*;\nimport static dev.langchain4j.internal.Utils.isNullOrBlank;\n\nimport dev.langchain4j.model.output.structured.Description;\n\nimport static java.lang.String.format;\nimport static java.util.Arrays.stream;\nimport static java.util.stream.Collectors.toList;\n\nimport java.lang.reflect.Field;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Parameter;\nimport java.lang.reflect.ParameterizedType;\nimport java.lang.reflect.Type;\nimport java.util.Collection;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Optional;\nimport java.util.Set;\n\n/**\n * Utility methods for {@link ToolSpecification}s.\n */\npublic class ToolSpecifications {\n\n    private ToolSpecifications() {\n    }\n\n    /**\n     * Returns {@link ToolSpecification}s for all methods annotated with @{@link Tool} within the specified class.\n     *\n     * @param classWithTools the class.\n     * @return the {@link ToolSpecification}s.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns {@link ToolSpecification}s for all methods annotated with @{@link Tool}\n     * within the class of the specified object.\n     *\n     * @param objectWithTools the object.\n     * @return the {@link ToolSpecification}s.\n     */\n    public static List<ToolSpecification> toolSpecificationsFrom(Object objectWithTools) {\n        return toolSpecificationsFrom(objectWithTools.getClass());\n    }\n\n    /**\n     * Validates all the {@link ToolSpecification}s. The validation checks for duplicate method names.\n     * Throws {@link IllegalArgumentException} if validation fails\n     *\n     * @param toolSpecifications list of ToolSpecification to be validated.\n     */\n    public static void validateSpecifications(List<ToolSpecification> toolSpecifications) throws IllegalArgumentException {\n\n        // Checks for duplicates methods\n        Set<String> names = new HashSet<>();\n        for (ToolSpecification toolSpecification : toolSpecifications) {\n            if (!names.add(toolSpecification.name())) {\n                throw new IllegalArgumentException(format(\"Tool names must be unique. The tool '%s' appears several times\", toolSpecification.name()));\n            }\n        }\n    }\n\n    /**\n     * Returns the {@link ToolSpecification} for the given method annotated with @{@link Tool}.\n     *\n     * @param method the method.\n     * @return the {@link ToolSpecification}.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Convert a {@link Parameter} to a {@link JsonSchemaProperty}.\n     *\n     * @param parameter the parameter.\n     * @return the {@link JsonSchemaProperty}.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static JsonSchemaProperty schema(Class<?> structured) {\n        return schema(structured, new HashSet<>());\n    }\n\n    private static JsonSchemaProperty schema(Class<?> structured, Set<Class<?>> visited) {\n        if (visited.contains(structured)) {\n            return null;\n        }\n\n        visited.add(structured);\n        Map<String, Object> properties = new HashMap<>();\n        for (Field field : structured.getDeclaredFields()) {\n            String name = field.getName();\n            if (name.equals(\"this$0\") || java.lang.reflect.Modifier.isStatic(field.getModifiers())) {\n                // Skip inner class reference.\n                continue;\n            }\n            Iterable<JsonSchemaProperty> schemaProperties = toJsonSchemaProperties(field, visited);\n            Map<Object, Object> objectMap = new HashMap<>();\n            for (JsonSchemaProperty jsonSchemaProperty : schemaProperties) {\n                objectMap.put(jsonSchemaProperty.key(), jsonSchemaProperty.value());\n            }\n            properties.put(name, objectMap);\n        }\n        return from(\"properties\", properties);\n    }\n\n    private static Iterable<JsonSchemaProperty> toJsonSchemaProperties(Field field, Set<Class<?>> visited) {\n\n        Class<?> type = field.getType();\n\n        Description annotation = field.getAnnotation(Description.class);\n        JsonSchemaProperty description = annotation == null ? null : description(String.join(\" \", annotation.value()));\n\n        Iterable<JsonSchemaProperty> simpleType = toJsonSchemaProperties(type, description);\n\n        if (simpleType != null) {\n            return simpleType;\n        }\n\n        if (Collection.class.isAssignableFrom(type)) {\n            return removeNulls(ARRAY, arrayTypeFrom((Class<?>) ((ParameterizedType) field.getGenericType()).getActualTypeArguments()[0]), description);\n        }\n\n        return removeNulls(OBJECT, schema(type, visited), description);\n    }\n\n    private static Iterable<JsonSchemaProperty> toJsonSchemaProperties(Class<?> type, JsonSchemaProperty description) {\n\n        if (type == String.class) {\n            return removeNulls(STRING, description);\n        }\n\n        if (isJsonBoolean(type)) {\n            return removeNulls(BOOLEAN, description);\n        }\n\n        if (isJsonInteger(type)) {\n            return removeNulls(INTEGER, description);\n        }\n\n        if (isJsonNumber(type)) {\n            return removeNulls(NUMBER, description);\n        }\n\n        if (type.isArray()) {\n            return removeNulls(ARRAY, arrayTypeFrom(type.getComponentType()), description);\n        }\n\n        if (type.isEnum()) {\n            return removeNulls(STRING, enums((Class<?>) type), description);\n        }\n\n        return null;\n    }\n\n\n    private static JsonSchemaProperty arrayTypeFrom(Type type) {\n        if (type instanceof ParameterizedType) {\n            ParameterizedType parameterizedType = (ParameterizedType) type;\n            Type[] actualTypeArguments = parameterizedType.getActualTypeArguments();\n            if (actualTypeArguments.length == 1) {\n                return arrayTypeFrom((Class<?>) actualTypeArguments[0]);\n            }\n        }\n        return items(JsonSchemaProperty.OBJECT);\n    }\n\n    private static JsonSchemaProperty arrayTypeFrom(Class<?> clazz) {\n        if (clazz == String.class) {\n            return items(JsonSchemaProperty.STRING);\n        }\n        if (isJsonBoolean(clazz)) {\n            return items(JsonSchemaProperty.BOOLEAN);\n        }\n        if (isJsonInteger(clazz)) {\n            return items(JsonSchemaProperty.INTEGER);\n        }\n        if (isJsonNumber(clazz)) {\n            return items(JsonSchemaProperty.NUMBER);\n        }\n        return objectItems(schema(clazz));\n    }\n\n    /**\n     * Remove nulls from the given array.\n     *\n     * @param items the array\n     * @return an iterable of the non-null items.\n     */\n    static Iterable<JsonSchemaProperty> removeNulls(JsonSchemaProperty... items) {\n        return stream(items)\n                .filter(Objects::nonNull)\n                .collect(toList());\n    }\n}\n\n```\n# Function Signature: public static List<ToolSpecification> toolSpecificationsFrom(Class<?> classWithTools) {\n# Natural Language Annotations: /**\n     * Returns {@link ToolSpecification}s for all methods annotated with @{@link Tool} within the specified class.\n     *\n     * @param classWithTools the class.\n     * @return the {@link ToolSpecification}s.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static List<ToolSpecification> toolSpecificationsFrom(Class<?> classWithTools) {\n    List<ToolSpecification> toolSpecifications = new ArrayList<>();\n    for (Method method : classWithTools.getDeclaredMethods()) {\n        Tool toolAnnotation = method.getAnnotation(Tool.class);\n        if (toolAnnotation == null) {\n            continue;\n        }\n        ToolSpecification toolSpecification = new ToolSpecification();\n        toolSpecification.setName(toolAnnotation.name());\n        toolSpecification.setDescription(toolAnnotation.description());\n        toolSpecification.setInlineOutput(toolAnnotation.inlineOutput());\n        toolSpecification.setOrder(toolAnnotation.order());\n        toolSpecification.setParameters(toolAnnotation.parameters());\n        toolSpecification.setType(toolAnnotation.type());\n        toolSpecifications.add(toolSpecification);\n    }\n    return toolSpecifications;\n}\n```", "  ```\npublic static List<ToolSpecification> toolSpecificationsFrom(Class<?> classWithTools) {\n        List<ToolSpecification> toolSpecifications = new ArrayList<>();\n        for (Method method : classWithTools.getDeclaredMethods()) {\n            Tool toolAnnotation = method.getAnnotation(Tool.class);\n            if (toolAnnotation != null) {\n                String name = toolAnnotation.name();\n                String description = toolAnnotation.description();\n                Object object = toolAnnotation.object();\n                String content = toolAnnotation.content();\n                Collection<ToolInput> inputs = toToolInputs(method.getDeclaredAnnotation(Parameter.class));\n                Collection<ToolOutput> toolOutputs = toToolOutputs(method.getDeclaredAnnotation(Parameter.class));\n                toolSpecifications.add(new ToolSpecification(name, description, object, content, inputs, toolOutputs));\n            }\n        }\n        return toolSpecifications;\n    }\n```", "  ```\npublic static List<ToolSpecification> toolSpecificationsFrom(Class<?> classWithTools) {\n        List<ToolSpecification> specs = new ArrayList<>();\n        for (Method method : classWithTools.getMethods()) {\n            Tool tool = method.getAnnotation(Tool.class);\n            if (tool != null) {\n                List<ToolSpecification> methodSpecs = toToolSpecification(method);\n                specs.addAll(methodSpecs);\n            }\n        }\n        return specs;\n    }\n\n    private static List<ToolSpecification> toToolSpecification(Method method) {\n        List<ToolSpecification> specs = new ArrayList<>();\n        Parameter[] parameters = method.getParameters();\n        if (parameters.length == 0) {\n            specs.add(toToolSpecification(method, null));\n        } else {\n            for (Parameter parameter : parameters) {\n                specs.add(toToolSpecification(method, parameter));\n            }\n        }\n        return specs;\n    }\n\n    private static ToolSpecification toToolSpecification(Method method, Parameter parameter) {\n        String methodName = method.getName();\n        String paramName = parameter == null ? null : parameter.getName();\n        return new ToolSpecification(methodName, paramName, toSchema(method, parameter));\n    }\n\n    private static JsonSchema toSchema(Method method, Parameter parameter) {\n        if (parameter == null) {\n            return toSchema(method);\n        } else {\n            return toSchema(method, parameter.getType());\n        }\n    }\n\n    private static JsonSchema toSchema(Method method, Class<?> type) {\n        // Implement your logic to create JsonSchema for the method's parameters\n    }\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java-toolSpecificationFrom": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java:\n```\npackage dev.langchain4j.agent.tool;\n\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.ARRAY;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.BOOLEAN;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.INTEGER;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.NUMBER;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.OBJECT;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.STRING;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.description;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.enums;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.from;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.items;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.objectItems;\nimport static dev.langchain4j.internal.TypeUtils.*;\nimport static dev.langchain4j.internal.Utils.isNullOrBlank;\n\nimport dev.langchain4j.model.output.structured.Description;\n\nimport static java.lang.String.format;\nimport static java.util.Arrays.stream;\nimport static java.util.stream.Collectors.toList;\n\nimport java.lang.reflect.Field;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Parameter;\nimport java.lang.reflect.ParameterizedType;\nimport java.lang.reflect.Type;\nimport java.util.Collection;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Optional;\nimport java.util.Set;\n\n/**\n * Utility methods for {@link ToolSpecification}s.\n */\npublic class ToolSpecifications {\n\n    private ToolSpecifications() {\n    }\n\n    /**\n     * Returns {@link ToolSpecification}s for all methods annotated with @{@link Tool} within the specified class.\n     *\n     * @param classWithTools the class.\n     * @return the {@link ToolSpecification}s.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns {@link ToolSpecification}s for all methods annotated with @{@link Tool}\n     * within the class of the specified object.\n     *\n     * @param objectWithTools the object.\n     * @return the {@link ToolSpecification}s.\n     */\n    public static List<ToolSpecification> toolSpecificationsFrom(Object objectWithTools) {\n        return toolSpecificationsFrom(objectWithTools.getClass());\n    }\n\n    /**\n     * Validates all the {@link ToolSpecification}s. The validation checks for duplicate method names.\n     * Throws {@link IllegalArgumentException} if validation fails\n     *\n     * @param toolSpecifications list of ToolSpecification to be validated.\n     */\n    public static void validateSpecifications(List<ToolSpecification> toolSpecifications) throws IllegalArgumentException {\n\n        // Checks for duplicates methods\n        Set<String> names = new HashSet<>();\n        for (ToolSpecification toolSpecification : toolSpecifications) {\n            if (!names.add(toolSpecification.name())) {\n                throw new IllegalArgumentException(format(\"Tool names must be unique. The tool '%s' appears several times\", toolSpecification.name()));\n            }\n        }\n    }\n\n    /**\n     * Returns the {@link ToolSpecification} for the given method annotated with @{@link Tool}.\n     *\n     * @param method the method.\n     * @return the {@link ToolSpecification}.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Convert a {@link Parameter} to a {@link JsonSchemaProperty}.\n     *\n     * @param parameter the parameter.\n     * @return the {@link JsonSchemaProperty}.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static JsonSchemaProperty schema(Class<?> structured) {\n        return schema(structured, new HashSet<>());\n    }\n\n    private static JsonSchemaProperty schema(Class<?> structured, Set<Class<?>> visited) {\n        if (visited.contains(structured)) {\n            return null;\n        }\n\n        visited.add(structured);\n        Map<String, Object> properties = new HashMap<>();\n        for (Field field : structured.getDeclaredFields()) {\n            String name = field.getName();\n            if (name.equals(\"this$0\") || java.lang.reflect.Modifier.isStatic(field.getModifiers())) {\n                // Skip inner class reference.\n                continue;\n            }\n            Iterable<JsonSchemaProperty> schemaProperties = toJsonSchemaProperties(field, visited);\n            Map<Object, Object> objectMap = new HashMap<>();\n            for (JsonSchemaProperty jsonSchemaProperty : schemaProperties) {\n                objectMap.put(jsonSchemaProperty.key(), jsonSchemaProperty.value());\n            }\n            properties.put(name, objectMap);\n        }\n        return from(\"properties\", properties);\n    }\n\n    private static Iterable<JsonSchemaProperty> toJsonSchemaProperties(Field field, Set<Class<?>> visited) {\n\n        Class<?> type = field.getType();\n\n        Description annotation = field.getAnnotation(Description.class);\n        JsonSchemaProperty description = annotation == null ? null : description(String.join(\" \", annotation.value()));\n\n        Iterable<JsonSchemaProperty> simpleType = toJsonSchemaProperties(type, description);\n\n        if (simpleType != null) {\n            return simpleType;\n        }\n\n        if (Collection.class.isAssignableFrom(type)) {\n            return removeNulls(ARRAY, arrayTypeFrom((Class<?>) ((ParameterizedType) field.getGenericType()).getActualTypeArguments()[0]), description);\n        }\n\n        return removeNulls(OBJECT, schema(type, visited), description);\n    }\n\n    private static Iterable<JsonSchemaProperty> toJsonSchemaProperties(Class<?> type, JsonSchemaProperty description) {\n\n        if (type == String.class) {\n            return removeNulls(STRING, description);\n        }\n\n        if (isJsonBoolean(type)) {\n            return removeNulls(BOOLEAN, description);\n        }\n\n        if (isJsonInteger(type)) {\n            return removeNulls(INTEGER, description);\n        }\n\n        if (isJsonNumber(type)) {\n            return removeNulls(NUMBER, description);\n        }\n\n        if (type.isArray()) {\n            return removeNulls(ARRAY, arrayTypeFrom(type.getComponentType()), description);\n        }\n\n        if (type.isEnum()) {\n            return removeNulls(STRING, enums((Class<?>) type), description);\n        }\n\n        return null;\n    }\n\n\n    private static JsonSchemaProperty arrayTypeFrom(Type type) {\n        if (type instanceof ParameterizedType) {\n            ParameterizedType parameterizedType = (ParameterizedType) type;\n            Type[] actualTypeArguments = parameterizedType.getActualTypeArguments();\n            if (actualTypeArguments.length == 1) {\n                return arrayTypeFrom((Class<?>) actualTypeArguments[0]);\n            }\n        }\n        return items(JsonSchemaProperty.OBJECT);\n    }\n\n    private static JsonSchemaProperty arrayTypeFrom(Class<?> clazz) {\n        if (clazz == String.class) {\n            return items(JsonSchemaProperty.STRING);\n        }\n        if (isJsonBoolean(clazz)) {\n            return items(JsonSchemaProperty.BOOLEAN);\n        }\n        if (isJsonInteger(clazz)) {\n            return items(JsonSchemaProperty.INTEGER);\n        }\n        if (isJsonNumber(clazz)) {\n            return items(JsonSchemaProperty.NUMBER);\n        }\n        return objectItems(schema(clazz));\n    }\n\n    /**\n     * Remove nulls from the given array.\n     *\n     * @param items the array\n     * @return an iterable of the non-null items.\n     */\n    static Iterable<JsonSchemaProperty> removeNulls(JsonSchemaProperty... items) {\n        return stream(items)\n                .filter(Objects::nonNull)\n                .collect(toList());\n    }\n}\n\n```\n# Function Signature: public static ToolSpecification toolSpecificationFrom(Method method) {\n# Natural Language Annotations: /**\n     * Returns the {@link ToolSpecification} for the given method annotated with @{@link Tool}.\n     *\n     * @param method the method.\n     * @return the {@link ToolSpecification}.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static ToolSpecification toolSpecificationFrom(Method method) {\n        if (method.getAnnotation(Tool.class) == null) {\n            return null;\n        }\n        \n        Map<String, Object> objectMap = new HashMap<>();\n        String name = method.getName();\n        objectMap.put(\"name\", name);\n\n        JsonSchemaProperty inputSchema = schema(method.getParameterTypes());\n        JsonSchemaProperty outputSchema = schema(method.getReturnType());\n\n        objectMap.put(\"input\", inputSchema.value());\n        objectMap.put(\"output\", outputSchema.value());\n\n        return new ToolSpecification.Builder()\n                .name(name)\n                .input(inputSchema)\n                .output(outputSchema)\n                .build();\n    }\n```", "  ```\nprivate static ToolSpecification toolSpecificationFrom(Method method) {\n        Tool methodAnnotation = method.getAnnotation(Tool.class);\n        if (methodAnnotation == null) {\n            return null;\n        }\n        Class<?> methodReturnType = method.getReturnType();\n        ToolSpecification builder = ToolSpecification.builder()\n                .method(method)\n                .name(methodAnnotation.value())\n                .description(methodAnnotation.description())\n                .returns(schema(methodReturnType))\n                .parameters(toParameters(methodAnnotation.values()));\n        for (Parameter parameter : method.getParameters()) {\n            builder.parameter(parameter(parameter));\n        }\n        return builder.build();\n    }\n```", "  ```\npublic static ToolSpecification toolSpecificationFrom(Method method) {\n    Tool tool = method.getAnnotation(Tool.class);\n    if (tool == null) {\n        throw new IllegalArgumentException(\"Method is not annotated with @Tool\");\n    }\n    String name = tool.name();\n    if (isNullOrBlank(name)) {\n        name = method.getName();\n    }\n    String description = tool.description();\n    if (isNullOrBlank(description)) {\n        description = method.getDeclaringClass().getSimpleName() + \"#\" + method.getName();\n    }\n    Collection<Parameter> parameters = tool.parameters();\n    Iterable<JsonSchemaProperty> properties = parameters.stream()\n            .map(parameter -> parameter.getType().getSimpleName().replaceAll(\"(.)(\\\\p{Upper})\", \"$1_$2\").toLowerCase())\n            .map(propertyName -> {\n                switch (parameter.getType().getSimpleName().toLowerCase()) {\n                    case \"string\":\n                        return objectItems(description(propertyName, JsonSchemaProperty.STRING));\n                    case \"boolean\":\n                        return objectItems(description(propertyName, JsonSchemaProperty.BOOLEAN));\n                    case \"integer\":\n                        return objectItems(description(propertyName, JsonSchemaProperty.INTEGER));\n                    case \"number\":\n                        return objectItems(description(propertyName, JsonSchemaProperty.NUMBER));\n                    default:\n                        return objectItems(schema(parameter.getType(), propertyName, description));\n                }\n            })\n            .collect(toList());\n    properties.add(description(description));\n    return new ToolSpecification(name, properties);\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java-toJsonSchemaProperties": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java:\n```\npackage dev.langchain4j.agent.tool;\n\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.ARRAY;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.BOOLEAN;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.INTEGER;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.NUMBER;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.OBJECT;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.STRING;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.description;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.enums;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.from;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.items;\nimport static dev.langchain4j.agent.tool.JsonSchemaProperty.objectItems;\nimport static dev.langchain4j.internal.TypeUtils.*;\nimport static dev.langchain4j.internal.Utils.isNullOrBlank;\n\nimport dev.langchain4j.model.output.structured.Description;\n\nimport static java.lang.String.format;\nimport static java.util.Arrays.stream;\nimport static java.util.stream.Collectors.toList;\n\nimport java.lang.reflect.Field;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Parameter;\nimport java.lang.reflect.ParameterizedType;\nimport java.lang.reflect.Type;\nimport java.util.Collection;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Optional;\nimport java.util.Set;\n\n/**\n * Utility methods for {@link ToolSpecification}s.\n */\npublic class ToolSpecifications {\n\n    private ToolSpecifications() {\n    }\n\n    /**\n     * Returns {@link ToolSpecification}s for all methods annotated with @{@link Tool} within the specified class.\n     *\n     * @param classWithTools the class.\n     * @return the {@link ToolSpecification}s.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns {@link ToolSpecification}s for all methods annotated with @{@link Tool}\n     * within the class of the specified object.\n     *\n     * @param objectWithTools the object.\n     * @return the {@link ToolSpecification}s.\n     */\n    public static List<ToolSpecification> toolSpecificationsFrom(Object objectWithTools) {\n        return toolSpecificationsFrom(objectWithTools.getClass());\n    }\n\n    /**\n     * Validates all the {@link ToolSpecification}s. The validation checks for duplicate method names.\n     * Throws {@link IllegalArgumentException} if validation fails\n     *\n     * @param toolSpecifications list of ToolSpecification to be validated.\n     */\n    public static void validateSpecifications(List<ToolSpecification> toolSpecifications) throws IllegalArgumentException {\n\n        // Checks for duplicates methods\n        Set<String> names = new HashSet<>();\n        for (ToolSpecification toolSpecification : toolSpecifications) {\n            if (!names.add(toolSpecification.name())) {\n                throw new IllegalArgumentException(format(\"Tool names must be unique. The tool '%s' appears several times\", toolSpecification.name()));\n            }\n        }\n    }\n\n    /**\n     * Returns the {@link ToolSpecification} for the given method annotated with @{@link Tool}.\n     *\n     * @param method the method.\n     * @return the {@link ToolSpecification}.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Convert a {@link Parameter} to a {@link JsonSchemaProperty}.\n     *\n     * @param parameter the parameter.\n     * @return the {@link JsonSchemaProperty}.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static JsonSchemaProperty schema(Class<?> structured) {\n        return schema(structured, new HashSet<>());\n    }\n\n    private static JsonSchemaProperty schema(Class<?> structured, Set<Class<?>> visited) {\n        if (visited.contains(structured)) {\n            return null;\n        }\n\n        visited.add(structured);\n        Map<String, Object> properties = new HashMap<>();\n        for (Field field : structured.getDeclaredFields()) {\n            String name = field.getName();\n            if (name.equals(\"this$0\") || java.lang.reflect.Modifier.isStatic(field.getModifiers())) {\n                // Skip inner class reference.\n                continue;\n            }\n            Iterable<JsonSchemaProperty> schemaProperties = toJsonSchemaProperties(field, visited);\n            Map<Object, Object> objectMap = new HashMap<>();\n            for (JsonSchemaProperty jsonSchemaProperty : schemaProperties) {\n                objectMap.put(jsonSchemaProperty.key(), jsonSchemaProperty.value());\n            }\n            properties.put(name, objectMap);\n        }\n        return from(\"properties\", properties);\n    }\n\n    private static Iterable<JsonSchemaProperty> toJsonSchemaProperties(Field field, Set<Class<?>> visited) {\n\n        Class<?> type = field.getType();\n\n        Description annotation = field.getAnnotation(Description.class);\n        JsonSchemaProperty description = annotation == null ? null : description(String.join(\" \", annotation.value()));\n\n        Iterable<JsonSchemaProperty> simpleType = toJsonSchemaProperties(type, description);\n\n        if (simpleType != null) {\n            return simpleType;\n        }\n\n        if (Collection.class.isAssignableFrom(type)) {\n            return removeNulls(ARRAY, arrayTypeFrom((Class<?>) ((ParameterizedType) field.getGenericType()).getActualTypeArguments()[0]), description);\n        }\n\n        return removeNulls(OBJECT, schema(type, visited), description);\n    }\n\n    private static Iterable<JsonSchemaProperty> toJsonSchemaProperties(Class<?> type, JsonSchemaProperty description) {\n\n        if (type == String.class) {\n            return removeNulls(STRING, description);\n        }\n\n        if (isJsonBoolean(type)) {\n            return removeNulls(BOOLEAN, description);\n        }\n\n        if (isJsonInteger(type)) {\n            return removeNulls(INTEGER, description);\n        }\n\n        if (isJsonNumber(type)) {\n            return removeNulls(NUMBER, description);\n        }\n\n        if (type.isArray()) {\n            return removeNulls(ARRAY, arrayTypeFrom(type.getComponentType()), description);\n        }\n\n        if (type.isEnum()) {\n            return removeNulls(STRING, enums((Class<?>) type), description);\n        }\n\n        return null;\n    }\n\n\n    private static JsonSchemaProperty arrayTypeFrom(Type type) {\n        if (type instanceof ParameterizedType) {\n            ParameterizedType parameterizedType = (ParameterizedType) type;\n            Type[] actualTypeArguments = parameterizedType.getActualTypeArguments();\n            if (actualTypeArguments.length == 1) {\n                return arrayTypeFrom((Class<?>) actualTypeArguments[0]);\n            }\n        }\n        return items(JsonSchemaProperty.OBJECT);\n    }\n\n    private static JsonSchemaProperty arrayTypeFrom(Class<?> clazz) {\n        if (clazz == String.class) {\n            return items(JsonSchemaProperty.STRING);\n        }\n        if (isJsonBoolean(clazz)) {\n            return items(JsonSchemaProperty.BOOLEAN);\n        }\n        if (isJsonInteger(clazz)) {\n            return items(JsonSchemaProperty.INTEGER);\n        }\n        if (isJsonNumber(clazz)) {\n            return items(JsonSchemaProperty.NUMBER);\n        }\n        return objectItems(schema(clazz));\n    }\n\n    /**\n     * Remove nulls from the given array.\n     *\n     * @param items the array\n     * @return an iterable of the non-null items.\n     */\n    static Iterable<JsonSchemaProperty> removeNulls(JsonSchemaProperty... items) {\n        return stream(items)\n                .filter(Objects::nonNull)\n                .collect(toList());\n    }\n}\n\n```\n# Function Signature: static Iterable<JsonSchemaProperty> toJsonSchemaProperties(Parameter parameter) {\n# Natural Language Annotations: /**\n     * Convert a {@link Parameter} to a {@link JsonSchemaProperty}.\n     *\n     * @param parameter the parameter.\n     * @return the {@link JsonSchemaProperty}.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\nstatic Iterable<JsonSchemaProperty> toJsonSchemaProperties(Parameter parameter) {\n    Class<?> type = parameter.getType();\n\n    Description annotation = parameter.getAnnotation(Description.class);\n    JsonSchemaProperty description = annotation == null ? null : description(String.join(\" \", annotation.value()));\n\n    Iterable<JsonSchemaProperty> simpleType = toJsonSchemaProperties(type, description);\n\n    if (simpleType != null) {\n        return simpleType;\n    }\n\n    if (Collection.class.isAssignableFrom(type)) {\n        return removeNulls(ARRAY, arrayTypeFrom((Class<?>) ((ParameterizedType) parameter.getGenericType()).getActualTypeArguments()[0]), description);\n    }\n\n    return removeNulls(OBJECT, schema(type), description);\n}\n```", "  ```\nIterable<JsonSchemaProperty> toJsonSchemaProperties(Parameter parameter) {\n    return toJsonSchemaProperties(parameter, new HashSet<>());\n}\n\nprivate static Iterable<JsonSchemaProperty> toJsonSchemaProperties(Parameter parameter, Set<Object> visited) {\n    Class<?> type = parameter.getType();\n    if (visited.contains(type)) {\n        return null;\n    }\n    visited.add(type);\n    Map<String, Object> properties = new HashMap<>();\n    for (Field field : type.getDeclaredFields()) {\n        String name = field.getName();\n        if (name.equals(\"this$0\") || java.lang.reflect.Modifier.isStatic(field.getModifiers())) {\n            continue;\n        }\n        Iterable<JsonSchemaProperty> schemaProperties = toJsonSchemaProperties(field, visited);\n        Map<Object, Object> objectMap = new HashMap<>();\n        for (JsonSchemaProperty jsonSchemaProperty : schemaProperties) {\n            objectMap.put(jsonSchemaProperty.key(), jsonSchemaProperty.value());\n        }\n        properties.put(name, objectMap);\n    }\n    return from(\"properties\", properties);\n}\n\nprivate static Iterable<JsonSchemaProperty> toJsonSchemaProperties(Field field, Set<Object> visited) {\n    Class<?> type = field.getType();\n    Description annotation = field.getAnnotation(Description.class);\n    JsonSchemaProperty description = annotation == null ? null : description(String.join(\" \", annotation.value()));\n    Iterable<JsonSchemaProperty> simpleType = toJsonSchemaProperties(type, description);\n    if (simpleType != null) {\n        return simpleType;\n    }\n    if (Collection.class.isAssignableFrom(type)) {\n        return removeNulls(ARRAY, arrayTypeFrom((Class<?>) ((ParameterizedType) field.getGenericType()).getActualTypeArguments()[0]), description);\n    }\n    return removeNulls(OBJECT, schema(type, visited), description);\n}\n```", "  ```\nIterable<JsonSchemaProperty> toJsonSchemaProperties(Parameter parameter) {\n    String parameterName = parameter.getName();\n    Type parameterType = parameter.getParameterizedType().getActualTypeArguments()[0];\n\n    if (parameterName.equalsIgnoreCase(\"this$0\")) {\n        // The parameter is an inner class reference, so we skip it.\n        return null;\n    }\n\n    if (parameterType instanceof Class) {\n        return toJsonSchemaProperties((Class<?>) parameterType);\n    } else if (parameterType instanceof ParameterizedType) {\n        return toJsonSchemaProperties((ParameterizedType) parameterType);\n    } else {\n        throw new IllegalArgumentException(format(\"Unsupported parameter type: %s\", parameterType));\n    }\n}\n\nIterable<JsonSchemaProperty> toJsonSchemaProperties(Class<?> parameterType) {\n    if (parameterType == String.class) {\n        return JsonSchemaProperty.STRING;\n    } else if (isJsonBoolean(parameterType)) {\n        return JsonSchemaProperty.BOOLEAN;\n    } else if (isJsonInteger(parameterType)) {\n        return JsonSchemaProperty.INTEGER;\n    } else if (isJsonNumber(parameterType)) {\n        return JsonSchemaProperty.NUMBER;\n    } else if (Collection.class.isAssignableFrom(parameterType)) {\n        return JsonSchemaProperty.ARRAY;\n    } else if (parameterType.isArray()) {\n        return JsonSchemaProperty.ARRAY;\n    } else if (parameterType.isEnum()) {\n        return JsonSchemaProperty.STRING;\n    } else {\n        throw new IllegalArgumentException(format(\"Unsupported parameter type: %s\", parameterType));\n    }\n}\n\nIterable<JsonSchemaProperty> toJsonSchemaProperties(ParameterizedType parameterizedType) {\n    Type[] actualTypeArguments = parameterizedType.getActualTypeArguments();\n    if (actualTypeArguments.length == 1) {\n        if (actualTypeArguments[0] instanceof Class) {\n            return toJsonSchemaProperties((Class) actualTypeArguments[0]);\n        } else if (actualTypeArguments[0] instanceof ParameterizedType) {\n            return toJsonSchemaProperties((ParameterizedType) actualTypeArguments[0]);\n        }\n    }\n    return null;\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/store/embedding/CosineSimilarity.java-between": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/store/embedding/CosineSimilarity.java:\n```\npackage dev.langchain4j.store.embedding;\n\nimport dev.langchain4j.data.embedding.Embedding;\n\nimport static dev.langchain4j.internal.Exceptions.illegalArgument;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotNull;\n\n/**\n * Utility class for calculating cosine similarity between two vectors.\n */\npublic class CosineSimilarity {\n    private CosineSimilarity() {}\n\n    /**\n     * A small value to avoid division by zero.\n     */\n    public static final float EPSILON = 1e-8f;\n\n    /**\n     * Calculates cosine similarity between two vectors.\n     * <p>\n     * Cosine similarity measures the cosine of the angle between two vectors, indicating their directional similarity.\n     * It produces a value in the range:\n     * <p>\n     * -1 indicates vectors are diametrically opposed (opposite directions).\n     * <p>\n     * 0 indicates vectors are orthogonal (no directional similarity).\n     * <p>\n     * 1 indicates vectors are pointing in the same direction (but not necessarily of the same magnitude).\n     * <p>\n     * Not to be confused with cosine distance ([0..2]), which quantifies how different two vectors are.\n     * <p>\n     * Embeddings of all-zeros vectors are considered orthogonal to all other vectors;\n     * including other all-zeros vectors.\n     *\n     * @param embeddingA first embedding vector\n     * @param embeddingB second embedding vector\n     * @return cosine similarity in the range [-1..1]\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Converts relevance score into cosine similarity.\n     *\n     * @param relevanceScore Relevance score in the range [0..1] where 0 is not relevant and 1 is relevant.\n     * @return Cosine similarity in the range [-1..1] where -1 is not relevant and 1 is relevant.\n     */\n    public static double fromRelevanceScore(double relevanceScore) {\n        return relevanceScore * 2 - 1;\n    }\n}\n\n```\n# Function Signature: public static double between(Embedding embeddingA, Embedding embeddingB) {\n# Natural Language Annotations: /**\n     * Calculates cosine similarity between two vectors.\n     * <p>\n     * Cosine similarity measures the cosine of the angle between two vectors, indicating their directional similarity.\n     * It produces a value in the range:\n     * <p>\n     * -1 indicates vectors are diametrically opposed (opposite directions).\n     * <p>\n     * 0 indicates vectors are orthogonal (no directional similarity).\n     * <p>\n     * 1 indicates vectors are pointing in the same direction (but not necessarily of the same magnitude).\n     * <p>\n     * Not to be confused with cosine distance ([0..2]), which quantifies how different two vectors are.\n     * <p>\n     * Embeddings of all-zeros vectors are considered orthogonal to all other vectors;\n     * including other all-zeros vectors.\n     *\n     * @param embeddingA first embedding vector\n     * @param embeddingB second embedding vector\n     * @return cosine similarity in the range [-1..1]\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static double between(Embedding embeddingA, Embedding embeddingB) {\n    // Calculate the dot product of the two embeddings\n    double dotProduct = dotProductBetween(embeddingA, embeddingB);\n    // Calculate the magnitude of the two embeddings\n    double magnitudeA = magnitudeOf(embeddingA);\n    double magnitudeB = magnitudeOf(embeddingB);\n    // Calculate the cosine similarity\n    double cosineSimilarity = dotProduct / (magnitudeA * magnitudeB);\n    // Return the cosine similarity in the range [-1..1]\n    return cosineSimilarity;\n}\n```", "  ```\npublic static double between(Embedding embeddingA, Embedding embeddingB) {\n    // Calculate the dot product of the two embeddings\n    double dotProduct = embeddingA.dot(embeddingB);\n\n    // Calculate the magnitude of each embedding\n    double magA = embeddingA.length();\n    double magB = embeddingB.length();\n\n    // Calculate the cosine similarity between the two embeddings\n    double similarity = dotProduct / (magA * magB + EPSILON);\n\n    // Return the cosine similarity\n    return similarity;\n}\n```", "  ```\npublic static double between(Embedding embeddingA, Embedding embeddingB) {\n    // Check if embeddingA and embeddingB are null.\n    ensureNotNull(embeddingA, \"Embedding A cannot be null.\");\n    ensureNotNull(embeddingB, \"Embedding B cannot be null.\");\n\n    // Calculate the dot product.\n    double dotProduct = embeddingA.dot(embeddingB);\n\n    // Calculate the magnitude of the embeddings.\n    double magnitudeA = Math.sqrt(embeddingA.norm2());\n    double magnitudeB = Math.sqrt(embeddingB.norm2());\n\n    // Calculate the cosine similarity.\n    double cosineSimilarity = dotProduct / (magnitudeA * magnitudeB);\n\n    // Return the cosine similarity.\n    return cosineSimilarity;\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/data/document/Metadata.java-asMap": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/data/document/Metadata.java:\n```\npackage dev.langchain4j.data.document;\n\nimport dev.langchain4j.data.segment.TextSegment;\nimport dev.langchain4j.store.embedding.EmbeddingStore;\n\nimport java.util.*;\n\nimport static dev.langchain4j.internal.Exceptions.illegalArgument;\nimport static dev.langchain4j.internal.Exceptions.runtime;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotBlank;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotNull;\n\n/**\n * Represents metadata of a {@link Document} or a {@link TextSegment}.\n * <br>\n * For a {@link Document}, the metadata could store information such as the source, creation date,\n * owner, or any other relevant details.\n * <br>\n * For a {@link TextSegment}, in addition to metadata inherited from a {@link Document}, it can also include\n * segment-specific information, such as the page number, the position of the segment within the document, chapter, etc.\n * <br>\n * The metadata is stored as a key-value map, where the key is a {@link String} and the value can be one of:\n * {@link String}, {@link UUID}, {@link Integer}, {@link Long}, {@link Float}, {@link Double}.\n * If you require additional types, please <a href=\"https://github.com/langchain4j/langchain4j/issues/new/choose\">open an issue</a>.\n * <br>\n * {@code null} values are not permitted.\n */\npublic class Metadata {\n\n    private static final Set<Class<?>> SUPPORTED_VALUE_TYPES = new LinkedHashSet<>();\n\n    static {\n        SUPPORTED_VALUE_TYPES.add(String.class);\n\n        SUPPORTED_VALUE_TYPES.add(UUID.class);\n\n        SUPPORTED_VALUE_TYPES.add(int.class);\n        SUPPORTED_VALUE_TYPES.add(Integer.class);\n\n        SUPPORTED_VALUE_TYPES.add(long.class);\n        SUPPORTED_VALUE_TYPES.add(Long.class);\n\n        SUPPORTED_VALUE_TYPES.add(float.class);\n        SUPPORTED_VALUE_TYPES.add(Float.class);\n\n        SUPPORTED_VALUE_TYPES.add(double.class);\n        SUPPORTED_VALUE_TYPES.add(Double.class);\n    }\n\n    private final Map<String, Object> metadata;\n\n    /**\n     * Construct a Metadata object with an empty map of key-value pairs.\n     */\n    public Metadata() {\n        this(new HashMap<>());\n    }\n\n    /**\n     * Constructs a Metadata object from a map of key-value pairs.\n     *\n     * @param metadata the map of key-value pairs; must not be {@code null}. {@code null} values are not permitted.\n     *                 Supported value types: {@link String}, {@link Integer}, {@link Long}, {@link Float}, {@link Double}\n     */\n    public Metadata(Map<String, ?> metadata) {\n        ensureNotNull(metadata, \"metadata\").forEach((key, value) -> {\n            validate(key, value);\n            if (!SUPPORTED_VALUE_TYPES.contains(value.getClass())) {\n                throw illegalArgument(\"The metadata key '%s' has the value '%s', which is of the unsupported type '%s'. \" +\n                                \"Currently, the supported types are: %s\",\n                        key, value, value.getClass().getName(), SUPPORTED_VALUE_TYPES\n                );\n            }\n        });\n        this.metadata = new HashMap<>(metadata);\n    }\n\n    private static void validate(String key, Object value) {\n        ensureNotBlank(key, \"The metadata key with the value '\" + value + \"'\");\n        ensureNotNull(value, \"The metadata value for the key '\" + key + \"'\");\n    }\n\n    /**\n     * Returns the value associated with the given key.\n     *\n     * @param key the key\n     * @return the value associated with the given key, or {@code null} if the key is not present.\n     * @deprecated as of 0.31.0, use {@link #getString(String)}, {@link #getInteger(String)}, {@link #getLong(String)},\n     * {@link #getFloat(String)}, {@link #getDouble(String)} instead.\n     */\n    @Deprecated\n    public String get(String key) {\n        Object value = metadata.get(key);\n        if (value != null) {\n            return value.toString();\n        } else {\n            return null;\n        }\n    }\n\n    /**\n     * Returns the {@code String} value associated with the given key.\n     *\n     * @param key the key\n     * @return the {@code String} value associated with the given key, or {@code null} if the key is not present.\n     * @throws RuntimeException if the value is not of type String\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns the {@code UUID} value associated with the given key.\n     *\n     * @param key the key\n     * @return the {@code UUID} value associated with the given key, or {@code null} if the key is not present.\n     * @throws RuntimeException if the value is not of type String\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns the {@code Integer} value associated with the given key.\n     * <br>\n     * Some {@link EmbeddingStore} implementations (still) store {@code Metadata} values as {@code String}s.\n     * In this case, the {@code String} value will be parsed into an {@code Integer} when this method is called.\n     * <br>\n     * Some {@link EmbeddingStore} implementations store {@code Metadata} key-value pairs as JSON.\n     * In this case, type information is lost when serializing to JSON and then deserializing back from JSON.\n     * JSON libraries can, for example, serialize an {@code Integer} and then deserialize it as a {@code Long}.\n     * Or serialize a {@code Float} and then deserialize it as a {@code Double}, and so on.\n     * In such cases, the actual value will be cast to an {@code Integer} when this method is called.\n     *\n     * @param key the key\n     * @return the {@link Integer} value associated with the given key, or {@code null} if the key is not present.\n     * @throws RuntimeException if the value is not {@link Number}\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns the {@code Long} value associated with the given key.\n     * <br>\n     * Some {@link EmbeddingStore} implementations (still) store {@code Metadata} values as {@code String}s.\n     * In this case, the {@code String} value will be parsed into an {@code Long} when this method is called.\n     * <br>\n     * Some {@link EmbeddingStore} implementations store {@code Metadata} key-value pairs as JSON.\n     * In this case, type information is lost when serializing to JSON and then deserializing back from JSON.\n     * JSON libraries can, for example, serialize an {@code Integer} and then deserialize it as a {@code Long}.\n     * Or serialize a {@code Float} and then deserialize it as a {@code Double}, and so on.\n     * In such cases, the actual value will be cast to a {@code Long} when this method is called.\n     *\n     * @param key the key\n     * @return the {@code Long} value associated with the given key, or {@code null} if the key is not present.\n     * @throws RuntimeException if the value is not {@link Number}\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns the {@code Float} value associated with the given key.\n     * <br>\n     * Some {@link EmbeddingStore} implementations (still) store {@code Metadata} values as {@code String}s.\n     * In this case, the {@code String} value will be parsed into a {@code Float} when this method is called.\n     * <br>\n     * Some {@link EmbeddingStore} implementations store {@code Metadata} key-value pairs as JSON.\n     * In this case, type information is lost when serializing to JSON and then deserializing back from JSON.\n     * JSON libraries can, for example, serialize an {@code Integer} and then deserialize it as a {@code Long}.\n     * Or serialize a {@code Float} and then deserialize it as a {@code Double}, and so on.\n     * In such cases, the actual value will be cast to a {@code Float} when this method is called.\n     *\n     * @param key the key\n     * @return the {@code Float} value associated with the given key, or {@code null} if the key is not present.\n     * @throws RuntimeException if the value is not {@link Number}\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns the {@code Double} value associated with the given key.\n     * <br>\n     * Some {@link EmbeddingStore} implementations (still) store {@code Metadata} values as {@code String}s.\n     * In this case, the {@code String} value will be parsed into a {@code Double} when this method is called.\n     * <br>\n     * Some {@link EmbeddingStore} implementations store {@code Metadata} key-value pairs as JSON.\n     * In this case, type information is lost when serializing to JSON and then deserializing back from JSON.\n     * JSON libraries can, for example, serialize an {@code Integer} and then deserialize it as a {@code Long}.\n     * Or serialize a {@code Float} and then deserialize it as a {@code Double}, and so on.\n     * In such cases, the actual value will be cast to a {@code Double} when this method is called.\n     *\n     * @param key the key\n     * @return the {@code Double} value associated with the given key, or {@code null} if the key is not present.\n     * @throws RuntimeException if the value is not {@link Number}\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Check whether this {@code Metadata} contains a given key.\n     *\n     * @param key the key\n     * @return {@code true} if this metadata contains a given key; {@code false} otherwise.\n     */\n    public boolean containsKey(String key) {\n        return metadata.containsKey(key);\n    }\n\n    /**\n     * Adds a key-value pair to the metadata.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return {@code this}\n     * @deprecated as of 0.31.0, use {@link #put(String, String)}, {@link #put(String, int)}, {@link #put(String, long)},\n     * {@link #put(String, float)}, {@link #put(String, double)} instead.\n     */\n    @Deprecated\n    public Metadata add(String key, Object value) {\n        return put(key, value.toString());\n    }\n\n    /**\n     * Adds a key-value pair to the metadata.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return {@code this}\n     * @deprecated as of 0.31.0, use {@link #put(String, String)}, {@link #put(String, int)}, {@link #put(String, long)},\n     * {@link #put(String, float)}, {@link #put(String, double)} instead.\n     */\n    @Deprecated\n    public Metadata add(String key, String value) {\n        validate(key, value);\n        this.metadata.put(key, value);\n        return this;\n    }\n\n    /**\n     * Adds a key-value pair to the metadata.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return {@code this}\n     */\n    public Metadata put(String key, String value) {\n        validate(key, value);\n        this.metadata.put(key, value);\n        return this;\n    }\n\n    /**\n     * Adds a key-value pair to the metadata.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return {@code this}\n     */\n    public Metadata put(String key, UUID value) {\n        validate(key, value);\n        this.metadata.put(key, value);\n        return this;\n    }\n\n    /**\n     * Adds a key-value pair to the metadata.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return {@code this}\n     */\n    public Metadata put(String key, int value) {\n        validate(key, value);\n        this.metadata.put(key, value);\n        return this;\n    }\n\n    /**\n     * Adds a key-value pair to the metadata.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return {@code this}\n     */\n    public Metadata put(String key, long value) {\n        validate(key, value);\n        this.metadata.put(key, value);\n        return this;\n    }\n\n    /**\n     * Adds a key-value pair to the metadata.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return {@code this}\n     */\n    public Metadata put(String key, float value) {\n        validate(key, value);\n        this.metadata.put(key, value);\n        return this;\n    }\n\n    /**\n     * Adds a key-value pair to the metadata.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return {@code this}\n     */\n    public Metadata put(String key, double value) {\n        validate(key, value);\n        this.metadata.put(key, value);\n        return this;\n    }\n\n    /**\n     * Removes the given key from the metadata.\n     *\n     * @param key the key\n     * @return {@code this}\n     */\n    public Metadata remove(String key) {\n        this.metadata.remove(key);\n        return this;\n    }\n\n    /**\n     * Copies the metadata.\n     *\n     * @return a copy of this Metadata object.\n     */\n    public Metadata copy() {\n        return new Metadata(metadata);\n    }\n\n    /**\n     * Get a copy of the metadata as a map of key-value pairs.\n     *\n     * @return the metadata as a map of key-value pairs.\n     * @deprecated as of 0.31.0, use {@link #toMap()} instead.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Get a copy of the metadata as a map of key-value pairs.\n     *\n     * @return the metadata as a map of key-value pairs.\n     */\n    public Map<String, Object> toMap() {\n        return new HashMap<>(metadata);\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (o == null || getClass() != o.getClass()) return false;\n        Metadata that = (Metadata) o;\n        return Objects.equals(this.metadata, that.metadata);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(metadata);\n    }\n\n    @Override\n    public String toString() {\n        return \"Metadata {\" +\n                \" metadata = \" + metadata +\n                \" }\";\n    }\n\n    /**\n     * Constructs a Metadata object from a single key-value pair.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return a Metadata object\n     */\n    public static Metadata from(String key, String value) {\n        return new Metadata().put(key, value);\n    }\n\n    /**\n     * @param key   the key\n     * @param value the value\n     * @return a Metadata object\n     * @deprecated Use {@link #from(String, String)} instead\n     */\n    @Deprecated\n    public static Metadata from(String key, Object value) {\n        return new Metadata().add(key, value);\n    }\n\n    /**\n     * Constructs a Metadata object from a map of key-value pairs.\n     *\n     * @param metadata the map of key-value pairs\n     * @return a Metadata object\n     */\n    public static Metadata from(Map<String, ?> metadata) {\n        return new Metadata(metadata);\n    }\n\n    /**\n     * Constructs a Metadata object from a single key-value pair.\n     *\n     * @param key   the key\n     * @param value the value\n     * @return a Metadata object\n     */\n    public static Metadata metadata(String key, String value) {\n        return from(key, value);\n    }\n\n    /**\n     * @param key   the key\n     * @param value the value\n     * @return a Metadata object\n     * @deprecated Use {@link #metadata(String, String)} instead\n     */\n    @Deprecated\n    public static Metadata metadata(String key, Object value) {\n        return from(key, value);\n    }\n}\n\n```\n# Function Signature: @Deprecated    public Map<String, String> asMap() {\n# Natural Language Annotations: /**\n     * Get a copy of the metadata as a map of key-value pairs.\n     *\n     * @return the metadata as a map of key-value pairs.\n     * @deprecated as of 0.31.0, use {@link #toMap()} instead.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Deprecated\npublic Map<String, String> asMap() {\n    return metadata.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -> e.getValue().toString()));\n}\n```", "  ```\n@Deprecated\npublic Map<String, String> asMap() {\n    return metadata.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -> String.valueOf(e.getValue())));\n}\n```", "  ```\n@Deprecated\npublic Map<String, String> asMap() {\n    Map<String, String> map = new HashMap<>();\n    metadata.forEach((k, v) -> {\n        if (v instanceof String) {\n            map.put(k, (String) v);\n        }\n    });\n    return map;\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/data/document/DocumentLoader.java-load": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/data/document/DocumentLoader.java:\n```\npackage dev.langchain4j.data.document;\n\nimport java.io.InputStream;\n\n/**\n * Utility class for loading documents.\n */\npublic class DocumentLoader {\n\n    private DocumentLoader() {\n    }\n\n    /**\n     * Loads a document from the given source using the given parser.\n     *\n     * <p>Forwards the source Metadata to the parsed Document.\n     *\n     * @param source The source from which the document will be loaded.\n     * @param parser The parser that will be used to parse the document.\n     * @return The loaded document.\n     * @throws BlankDocumentException when the parsed {@link Document} is blank/empty.\n     */\n\n\n\n\n\n\n\n\n\n\n\n}\n\n```\n# Function Signature: public static Document load(DocumentSource source, DocumentParser parser) {\n# Natural Language Annotations: /**\n     * Loads a document from the given source using the given parser.\n     *\n     * <p>Forwards the source Metadata to the parsed Document.\n     *\n     * @param source The source from which the document will be loaded.\n     * @param parser The parser that will be used to parse the document.\n     * @return The loaded document.\n     * @throws BlankDocumentException when the parsed {@link Document} is blank/empty.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static Document load(DocumentSource source, DocumentParser parser) {\n    Document document = parser.parse(source.getInputStream());\n    if (document.isEmpty()) {\n        throw new BlankDocumentException(\"The parsed document is blank/empty\");\n    }\n    document.setMetadata(source.getMetadata());\n    return document;\n}\n```", "  ```\npublic static Document load(DocumentSource source, DocumentParser parser) {\n    if (source == null || parser == null) {\n        throw new IllegalArgumentException(\"source and parser must not be null\");\n    }\n    InputStream inputStream = source.getInputStream();\n    if (inputStream == null) {\n        throw new IllegalStateException(\"inputStream must not be null\");\n    }\n    Document document = parser.parse(inputStream);\n    if (document == null) {\n        throw new IllegalArgumentException(\"document must not be null\");\n    }\n    document.setMetadata(source.getMetadata());\n    if (document.isBlank()) {\n        throw new BlankDocumentException();\n    }\n    return document;\n}\n```", "  ```\npublic static Document load(DocumentSource source, DocumentParser parser) {\n    if (source == null || parser == null) {\n        throw new NullPointerException(\"Both source and parser must be non-null.\");\n    }\n    try (InputStream inputStream = source.openInputStream()) {\n        String text = parser.parseText(inputStream);\n        if (text == null || text.isEmpty()) {\n            throw new BlankDocumentException(\"The parsed document is blank/empty.\");\n        }\n        Document document = new Document(text);\n        document.setSource(source.getMetadata());\n        return document;\n    } catch (IOException e) {\n        throw new RuntimeException(\"Error while loading document: \" + e.getMessage(), e);\n    }\n}\n```\nThis function first checks if both the `source` and `parser` are non-null and throws a `NullPointerException` if one of them is null.\nIt then uses the `openInputStream()` method on the `source` to get a stream of the input from the source, and passes that stream to the `parseText()` method of the `parser` to get the text of the document.\nIf the `text` is either null or empty, it throws a `BlankDocumentException`.\nOtherwise, it creates a new `Document` object with the parsed text and sets its source to the `source` metadata.\nIt then returns the loaded document.\nThe `try-with-resources` block is used to ensure that the input stream is properly closed, even if an exception is thrown."]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/data/message/UserMessage.java-singleText": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/data/message/UserMessage.java:\n```\npackage dev.langchain4j.data.message;\n\nimport java.util.List;\nimport java.util.Objects;\n\nimport static dev.langchain4j.data.message.ChatMessageType.USER;\nimport static dev.langchain4j.internal.Exceptions.runtime;\nimport static dev.langchain4j.internal.Utils.quoted;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotBlank;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotEmpty;\nimport static java.util.Arrays.asList;\nimport static java.util.Collections.unmodifiableList;\n\n/**\n * Represents a message from a user, typically an end user of the application.\n * <br>\n * Depending on the supported modalities (text, image, audio, video, etc.) of the model,\n * user messages can contain either a single text (a {@code String}) or multiple {@link Content}s,\n * which can be either {@link TextContent}, {@link ImageContent}, {@link AudioContent},\n * {@link VideoContent}, or {@link PdfFileContent}.\n * <br>\n * Optionally, user message can contain a {@link #name} of the user.\n * Be aware that not all models support names in {@code UserMessage}.\n */\npublic class UserMessage implements ChatMessage {\n\n    private final String name;\n    private final List<Content> contents;\n\n    /**\n     * Creates a {@link UserMessage} from a text.\n     *\n     * @param text the text.\n     */\n    public UserMessage(String text) {\n        this(TextContent.from(text));\n    }\n\n    /**\n     * Creates a {@link UserMessage} from a name and a text.\n     *\n     * @param name the name.\n     * @param text the text.\n     */\n    public UserMessage(String name, String text) {\n        this(name, TextContent.from(text));\n    }\n\n    /**\n     * Creates a {@link UserMessage} from one or multiple {@link Content}s.\n     * {@link Content} can be either {@link TextContent} or {@link ImageContent}.\n     * <br>\n     * Will have a {@code null} name.\n     *\n     * @param contents the contents.\n     */\n    public UserMessage(Content... contents) {\n        this(asList(contents));\n    }\n\n    /**\n     * Creates a {@link UserMessage} from a name and one or multiple {@link Content}s.\n     * {@link Content} can be either {@link TextContent} or {@link ImageContent}.\n     *\n     * @param name     the name.\n     * @param contents the contents.\n     */\n    public UserMessage(String name, Content... contents) {\n        this(name, asList(contents));\n    }\n\n    /**\n     * Creates a {@link UserMessage} from a list of {@link Content}s.\n     * {@link Content} can be either {@link TextContent} or {@link ImageContent}.\n     * <br>\n     * Will have a {@code null} name.\n     *\n     * @param contents the contents.\n     */\n    public UserMessage(List<Content> contents) {\n        this.name = null;\n        this.contents = unmodifiableList(ensureNotEmpty(contents, \"contents\"));\n    }\n\n    /**\n     * Creates a {@link UserMessage} from a name and a list of {@link Content}s.\n     * {@link Content} can be either {@link TextContent} or {@link ImageContent}.\n     *\n     * @param name     the name.\n     * @param contents the contents.\n     */\n    public UserMessage(String name, List<Content> contents) {\n        this.name = ensureNotBlank(name, \"name\");\n        this.contents = unmodifiableList(ensureNotEmpty(contents, \"contents\"));\n    }\n\n    /**\n     * The name of the user.\n     *\n     * @return the name, or {@code null} if not set.\n     */\n    public String name() {\n        return name;\n    }\n\n    /**\n     * The contents of the message. {@link Content} can be either {@link TextContent} or {@link ImageContent}.\n     *\n     * @return the contents.\n     */\n    public List<Content> contents() {\n        return contents;\n    }\n\n    /**\n     * Returns text from a single {@link TextContent}.\n     * Use this accessor only if you are certain that the message contains only a single text.\n     * If the message contains multiple {@link Content}s, or if the only {@link Content} is not a {@link TextContent},\n     * a {@link RuntimeException} is thrown.\n     *\n     * @return a single text.\n     * @see #hasSingleText()\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Whether this message contains a single {@link TextContent}.\n     *\n     * @return {@code true} if this message contains a single {@link TextContent}, {@code false} otherwise.\n     */\n    public boolean hasSingleText() {\n        return contents.size() == 1 && contents.get(0) instanceof TextContent;\n    }\n\n    /**\n     * {@link UserMessage} can contain not just a single {@code String text}, but also multiple {@link Content}s,\n     * which can be either {@link TextContent} or {@link ImageContent}.\n     * Therefore, this method is deprecated. Please use {@link #singleText()} if you only expect a single text,\n     * or use {@link #contents()} otherwise.\n     *\n     * @deprecated Use {@link #singleText()} or {@link #contents()} instead.\n     */\n    @Deprecated\n    public String text() {\n        return singleText();\n    }\n\n    @Override\n    public ChatMessageType type() {\n        return USER;\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (o == null || getClass() != o.getClass()) return false;\n        UserMessage that = (UserMessage) o;\n        return Objects.equals(this.name, that.name)\n                && Objects.equals(this.contents, that.contents);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(name, contents);\n    }\n\n    @Override\n    public String toString() {\n        return \"UserMessage {\" +\n                \" name = \" + quoted(name) +\n                \" contents = \" + contents +\n                \" }\";\n    }\n\n    /**\n     * Create a {@link UserMessage} from a text.\n     *\n     * @param text the text.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage from(String text) {\n        return new UserMessage(text);\n    }\n\n    /**\n     * Create a {@link UserMessage} from a name and a text.\n     *\n     * @param name the name.\n     * @param text the text.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage from(String name, String text) {\n        return new UserMessage(name, text);\n    }\n\n    /**\n     * Create a {@link UserMessage} from contents.\n     *\n     * @param contents the contents.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage from(Content... contents) {\n        return new UserMessage(contents);\n    }\n\n    /**\n     * Create a {@link UserMessage} from a name and contents.\n     *\n     * @param name     the name.\n     * @param contents the contents.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage from(String name, Content... contents) {\n        return new UserMessage(name, contents);\n    }\n\n    /**\n     * Create a {@link UserMessage} from contents.\n     *\n     * @param contents the contents.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage from(List<Content> contents) {\n        return new UserMessage(contents);\n    }\n\n    /**\n     * Create a {@link UserMessage} from a name and contents.\n     *\n     * @param name     the name.\n     * @param contents the contents.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage from(String name, List<Content> contents) {\n        return new UserMessage(name, contents);\n    }\n\n    /**\n     * Create a {@link UserMessage} from a text.\n     *\n     * @param text the text.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage userMessage(String text) {\n        return from(text);\n    }\n\n    /**\n     * Create a {@link UserMessage} from a name and a text.\n     *\n     * @param name the name.\n     * @param text the text.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage userMessage(String name, String text) {\n        return from(name, text);\n    }\n\n    /**\n     * Create a {@link UserMessage} from contents.\n     *\n     * @param contents the contents.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage userMessage(Content... contents) {\n        return from(contents);\n    }\n\n    /**\n     * Create a {@link UserMessage} from a name and contents.\n     *\n     * @param name     the name.\n     * @param contents the contents.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage userMessage(String name, Content... contents) {\n        return from(name, contents);\n    }\n\n    /**\n     * Create a {@link UserMessage} from contents.\n     *\n     * @param contents the contents.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage userMessage(List<Content> contents) {\n        return from(contents);\n    }\n\n    /**\n     * Create a {@link UserMessage} from a name and contents.\n     *\n     * @param name     the name.\n     * @param contents the contents.\n     * @return the {@link UserMessage}.\n     */\n    public static UserMessage userMessage(String name, List<Content> contents) {\n        return from(name, contents);\n    }\n}\n\n```\n# Function Signature: public String singleText() {\n# Natural Language Annotations: /**\n     * Returns text from a single {@link TextContent}.\n     * Use this accessor only if you are certain that the message contains only a single text.\n     * If the message contains multiple {@link Content}s, or if the only {@link Content} is not a {@link TextContent},\n     * a {@link RuntimeException} is thrown.\n     *\n     * @return a single text.\n     * @see #hasSingleText()\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic String singleText() {\n    if (!hasSingleText()) {\n        throw runtime(\"Message contains more than one text.\");\n    }\n    return contents.get(0).getContentText();\n}\n```", "  ```\npublic String singleText() {\n    if (contents.size() != 1) {\n        throw new RuntimeException(\"Expected 1 text content but found \" + contents.size());\n    }\n    Content content = contents.get(0);\n    if (!(content instanceof TextContent)) {\n        throw new RuntimeException(\"Expected TextContent but found \" + content.getClass().getName() + \" instead\");\n    }\n    return ((TextContent) content).getText();\n}\n```", "  ```\npublic String singleText() {\n    if (contents.size() != 1) {\n        throw runtime(\"UserMessage contains more than one content, can't extract a single text\");\n    }\n    Content content = contents.get(0);\n    if (!(content instanceof TextContent)) {\n        throw runtime(\"UserMessage contains multiple texts and/or non-text contents, can't extract a single text\");\n    }\n    return ((TextContent) content).getContent();\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/rag/RetrievalAugmentor.java-augment": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/rag/RetrievalAugmentor.java:\n```\npackage dev.langchain4j.rag;\n\nimport dev.langchain4j.Experimental;\nimport dev.langchain4j.data.message.ChatMessage;\nimport dev.langchain4j.data.message.UserMessage;\nimport dev.langchain4j.rag.content.Content;\nimport dev.langchain4j.rag.query.Metadata;\n\nimport static dev.langchain4j.internal.Exceptions.runtime;\n\n/**\n * Augments the provided {@link ChatMessage} with retrieved {@link Content}s.\n * <br>\n * This serves as an entry point into the RAG flow in LangChain4j.\n * <br>\n * You are free to use the default implementation ({@link DefaultRetrievalAugmentor}) or to implement a custom one.\n *\n * @see DefaultRetrievalAugmentor\n */\n@Experimental\npublic interface RetrievalAugmentor {\n\n    /**\n     * Augments the {@link ChatMessage} provided in the {@link AugmentationRequest} with retrieved {@link Content}s.\n     * <br>\n     * This method has a default implementation in order to <b>temporarily</b> support\n     * current custom implementations of {@code RetrievalAugmentor}. The default implementation will be removed soon.\n     *\n     * @param augmentationRequest The {@code AugmentationRequest} containing the {@code ChatMessage} to augment.\n     * @return The {@link AugmentationResult} containing the augmented {@code ChatMessage}.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Augments the provided {@link UserMessage} with retrieved content.\n     *\n     * @param userMessage The {@link UserMessage} to be augmented.\n     * @param metadata    The {@link Metadata} that may be useful or necessary for retrieval and augmentation.\n     * @return The augmented {@link UserMessage}.\n     * @deprecated Use/implement {@link #augment(AugmentationRequest)} instead.\n     */\n    @Deprecated\n    UserMessage augment(UserMessage userMessage, Metadata metadata);\n}\n\n```\n# Function Signature: default AugmentationResult augment(AugmentationRequest augmentationRequest) {\n# Natural Language Annotations: /**\n     * Augments the {@link ChatMessage} provided in the {@link AugmentationRequest} with retrieved {@link Content}s.\n     * <br>\n     * This method has a default implementation in order to <b>temporarily</b> support\n     * current custom implementations of {@code RetrievalAugmentor}. The default implementation will be removed soon.\n     *\n     * @param augmentationRequest The {@code AugmentationRequest} containing the {@code ChatMessage} to augment.\n     * @return The {@link AugmentationResult} containing the augmented {@code ChatMessage}.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic class DefaultRetrievalAugmentor implements RetrievalAugmentor {\n\n    @Override\n    public AugmentationResult augment(AugmentationRequest augmentationRequest) {\n        if (augmentationRequest.getChatMessage() == null) {\n            throw new IllegalArgumentException(\"ChatMessage cannot be null\");\n        }\n        ChatMessage chatMessage = augmentationRequest.getChatMessage();\n        // Create a list of Content objects to be added to the ChatMessage\n        List<Content> contents = new ArrayList<>();\n\n        // Use the RetrievalAugmentor strategy to retrieve Content objects based on the ChatMessage\n        contents.addAll(augmentationRequest.getRetrievalAugmentationStrategy().retrieveContent(chatMessage,\n                augmentationRequest.getMetadata()));\n\n        // Create an AugmentationResult and set the augmented ChatMessage\n        AugmentationResult result = new AugmentationResult();\n        result.setChatMessage(chatMessage);\n\n        // Update the ChatMessage with the retrieved Content objects\n        chatMessage.setContent(contents);\n\n        return result;\n    }\n}\n```", "  ```\n@Override\ndefault AugmentationResult augment(AugmentationRequest augmentationRequest) {\n    // Get the ChatMessage to augment from the augmentation request\n    ChatMessage chatMessage = augmentationRequest.getChatMessage();\n\n    // Get the Metadata that may be useful or necessary for retrieval and augmentation\n    Metadata metadata = augmentationRequest.getMetadata();\n\n    // Create a new ChatMessage that will be used for augmentation\n    ChatMessage augmentedChatMessage = new ChatMessage(chatMessage.getId(), chatMessage.getUserId(), chatMessage.getUserMessage());\n\n    // Run the default implementation of augmentation\n    Content[] augmentedContents = defaultAugment(chatMessage, metadata);\n\n    // Set the augmented contents on the augmented ChatMessage\n    augmentedChatMessage.setAugmentedContents(new ArrayList<>(Arrays.asList(augmentedContents)));\n\n    // Create and return an AugmentationResult containing the augmented ChatMessage\n    return new AugmentationResult(augmentedChatMessage);\n}\n\nprivate Content[] defaultAugment(ChatMessage chatMessage, Metadata metadata) {\n    // Get the plain text from the original ChatMessage\n    String plainText = chatMessage.getUserMessage().getPlainText();\n\n    // Run the text through a language model to generate augmented text\n    String augmentedText = languageModel.generateAugmentedText(plainText, metadata);\n\n    // Create a new Content that represents the augmented text\n    Content augmentedContent = new Content(augmentedText, ContentTypes.AUGMENTED_TEXT);\n\n    // Create and return the augmented Content\n    return new Content[] {augmentedContent};\n}\n```", "  ```\n@Override\npublic AugmentationResult augment(AugmentationRequest augmentationRequest) {\n    // Get the ChatMessage from the request\n    ChatMessage chatMessage = augmentationRequest.getChatMessage();\n\n    // Get the metadata from the request\n    Metadata metadata = augmentationRequest.getMetadata();\n\n    // Perform the augmentation\n    Content content = retrieveContent(chatMessage, metadata);\n    augmentMessage(chatMessage, content);\n\n    // Create an AugmentationResult with the augmented ChatMessage\n    AugmentationResult result = new AugmentationResult(chatMessage, content);\n\n    return result;\n}\n\nprivate Content retrieveContent(ChatMessage chatMessage, Metadata metadata) {\n    // Perform any necessary retrieval using the provided metadata\n    // For example, you could use the MessageRepository to retrieve a Collection of Content\n    // You could also use the AnnotationRepository to retrieve a Collection of Annotations\n    Collection<Content> contents = messageRepository.findContent(chatMessage, metadata);\n\n    // Get the first content item from the collection\n    Content content = contents.stream().findFirst().orElse(null);\n\n    return content;\n}\n\nprivate void augmentMessage(ChatMessage chatMessage, Content content) {\n    // Check if the content item is not null\n    if (content != null) {\n        // Augment the message with the retrieved content\n        // For example, you could add a new field to the chatMessage\n        // Or you could modify one of the existing fields\n        chatMessage.setContent(content.getContent());\n    }\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/rag/DefaultRetrievalAugmentor.java-augment": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/rag/DefaultRetrievalAugmentor.java:\n```\npackage dev.langchain4j.rag;\n\nimport dev.langchain4j.data.message.ChatMessage;\nimport dev.langchain4j.data.message.UserMessage;\nimport dev.langchain4j.rag.content.Content;\nimport dev.langchain4j.rag.content.aggregator.ContentAggregator;\nimport dev.langchain4j.rag.content.aggregator.DefaultContentAggregator;\nimport dev.langchain4j.rag.content.injector.ContentInjector;\nimport dev.langchain4j.rag.content.injector.DefaultContentInjector;\nimport dev.langchain4j.rag.content.retriever.ContentRetriever;\nimport dev.langchain4j.rag.query.Metadata;\nimport dev.langchain4j.rag.query.Query;\nimport dev.langchain4j.rag.query.router.DefaultQueryRouter;\nimport dev.langchain4j.rag.query.router.QueryRouter;\nimport dev.langchain4j.rag.query.transformer.DefaultQueryTransformer;\nimport dev.langchain4j.rag.query.transformer.QueryTransformer;\nimport lombok.Builder;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.*;\n\nimport static dev.langchain4j.internal.Utils.getOrDefault;\nimport static dev.langchain4j.internal.ValidationUtils.ensureNotNull;\nimport static java.util.Collections.*;\nimport static java.util.concurrent.CompletableFuture.allOf;\nimport static java.util.concurrent.CompletableFuture.supplyAsync;\nimport static java.util.concurrent.TimeUnit.SECONDS;\nimport static java.util.stream.Collectors.*;\n\n/**\n * The default implementation of {@link RetrievalAugmentor} intended to be suitable for the majority of use cases.\n * <br>\n * <br>\n * It's important to note that while efforts will be made to avoid breaking changes,\n * the default behavior of this class may be updated in the future if it's found\n * that the current behavior does not adequately serve the majority of use cases.\n * Such changes would be made to benefit both current and future users.\n * <br>\n * <br>\n * This implementation is inspired by <a href=\"https://blog.langchain.dev/deconstructing-rag\">this article</a>\n * and <a href=\"https://arxiv.org/abs/2312.10997\">this paper</a>.\n * It is recommended to review these resources for a better understanding of the concept.\n * <br>\n * <br>\n * This implementation orchestrates the flow between the following base components:\n * <pre>\n * - {@link QueryTransformer}\n * - {@link QueryRouter}\n * - {@link ContentRetriever}\n * - {@link ContentAggregator}\n * - {@link ContentInjector}\n * </pre>\n * Visual representation of this flow can be found\n * <a href=\"https://docs.langchain4j.dev/img/advanced-rag.png\">here</a>.\n * <br>\n * For each base component listed above, we offer several ready-to-use implementations,\n * each based on a recognized approach.\n * We intend to introduce more such implementations over time and welcome your contributions.\n * <br>\n * <br>\n * The flow is as follows:\n * <br>\n * 1. A {@link Query} (derived from an original {@link UserMessage}) is transformed\n * using a {@link QueryTransformer} into one or multiple {@link Query}s.\n * <br>\n * 2. Each {@link Query} is routed to the appropriate {@link ContentRetriever} using a {@link QueryRouter}.\n * Each {@link ContentRetriever} retrieves one or multiple {@link Content}s using a {@link Query}.\n * <br>\n * 3. All {@link Content}s retrieved by all {@link ContentRetriever}s using all {@link Query}s are\n * aggregated (fused/re-ranked/filtered/etc.) into a final list of {@link Content}s using a {@link ContentAggregator}.\n * <br>\n * 4. Lastly, a final list of {@link Content}s is injected into the original {@link UserMessage}\n * using a {@link ContentInjector}.\n * <br>\n * <br>\n * By default, each base component (except for {@link ContentRetriever}, which needs to be provided by you)\n * is initialized with a sensible default implementation:\n * <pre>\n * - {@link DefaultQueryTransformer}\n * - {@link DefaultQueryRouter}\n * - {@link DefaultContentAggregator}\n * - {@link DefaultContentInjector}\n * </pre>\n * Nonetheless, you are encouraged to use one of the advanced ready-to-use implementations or create a custom one.\n * <br>\n * <br>\n * When there is only a single {@link Query} and a single {@link ContentRetriever},\n * query routing and content retrieval are performed in the same thread.\n * Otherwise, an {@link Executor} is used to parallelize the processing.\n * By default, a modified (keepAliveTime is 1 second instead of 60 seconds) {@link Executors#newCachedThreadPool()}\n * is used, but you can provide a custom {@link Executor} instance.\n *\n * @see DefaultQueryTransformer\n * @see DefaultQueryRouter\n * @see DefaultContentAggregator\n * @see DefaultContentInjector\n */\npublic class DefaultRetrievalAugmentor implements RetrievalAugmentor {\n\n    private static final Logger log = LoggerFactory.getLogger(DefaultRetrievalAugmentor.class);\n\n    private final QueryTransformer queryTransformer;\n    private final QueryRouter queryRouter;\n    private final ContentAggregator contentAggregator;\n    private final ContentInjector contentInjector;\n    private final Executor executor;\n\n    @Builder\n    public DefaultRetrievalAugmentor(QueryTransformer queryTransformer,\n                                     QueryRouter queryRouter,\n                                     ContentAggregator contentAggregator,\n                                     ContentInjector contentInjector,\n                                     Executor executor) {\n        this.queryTransformer = getOrDefault(queryTransformer, DefaultQueryTransformer::new);\n        this.queryRouter = ensureNotNull(queryRouter, \"queryRouter\");\n        this.contentAggregator = getOrDefault(contentAggregator, DefaultContentAggregator::new);\n        this.contentInjector = getOrDefault(contentInjector, DefaultContentInjector::new);\n        this.executor = getOrDefault(executor, DefaultRetrievalAugmentor::createDefaultExecutor);\n    }\n\n    private static ExecutorService createDefaultExecutor() {\n        return new ThreadPoolExecutor(\n                0, Integer.MAX_VALUE,\n                1, SECONDS,\n                new SynchronousQueue<>()\n        );\n    }\n\n    /**\n     * @deprecated use {@link #augment(AugmentationRequest)} instead.\n     */\n\n\n\n\n\n\n\n    @Override\n    public AugmentationResult augment(AugmentationRequest augmentationRequest) {\n\n        ChatMessage chatMessage = augmentationRequest.chatMessage();\n        Metadata metadata = augmentationRequest.metadata();\n\n        Query originalQuery = Query.from(chatMessage.text(), metadata);\n\n        Collection<Query> queries = queryTransformer.transform(originalQuery);\n        logQueries(originalQuery, queries);\n\n        Map<Query, Collection<List<Content>>> queryToContents = process(queries);\n\n        List<Content> contents = contentAggregator.aggregate(queryToContents);\n        log(queryToContents, contents);\n\n        ChatMessage augmentedChatMessage = contentInjector.inject(contents, chatMessage);\n        log(augmentedChatMessage);\n\n        return AugmentationResult.builder()\n                .chatMessage(augmentedChatMessage)\n                .contents(contents)\n                .build();\n    }\n\n    private Map<Query, Collection<List<Content>>> process(Collection<Query> queries) {\n        if (queries.size() == 1) {\n            Query query = queries.iterator().next();\n            Collection<ContentRetriever> retrievers = queryRouter.route(query);\n            if (retrievers.size() == 1) {\n                ContentRetriever contentRetriever = retrievers.iterator().next();\n                List<Content> contents = contentRetriever.retrieve(query);\n                return singletonMap(query, singletonList(contents));\n            } else if (retrievers.size() > 1) {\n                Collection<List<Content>> contents = retrieveFromAll(retrievers, query).join();\n                return singletonMap(query, contents);\n            } else {\n                return emptyMap();\n            }\n        } else if (queries.size() > 1) {\n            Map<Query, CompletableFuture<Collection<List<Content>>>> queryToFutureContents = new ConcurrentHashMap<>();\n            queries.forEach(query -> {\n                CompletableFuture<Collection<List<Content>>> futureContents =\n                        supplyAsync(() -> {\n                                    Collection<ContentRetriever> retrievers = queryRouter.route(query);\n                                    log(query, retrievers);\n                                    return retrievers;\n                                },\n                                executor\n                        ).thenCompose(retrievers -> retrieveFromAll(retrievers, query));\n                queryToFutureContents.put(query, futureContents);\n            });\n            return join(queryToFutureContents);\n        } else {\n            return emptyMap();\n        }\n    }\n\n    private CompletableFuture<Collection<List<Content>>> retrieveFromAll(Collection<ContentRetriever> retrievers,\n                                                                         Query query) {\n        List<CompletableFuture<List<Content>>> futureContents = retrievers.stream()\n                .map(retriever -> supplyAsync(() -> retrieve(retriever, query), executor))\n                .collect(toList());\n\n        return allOf(futureContents.toArray(new CompletableFuture[0]))\n                .thenApply(ignored ->\n                        futureContents.stream()\n                                .map(CompletableFuture::join)\n                                .collect(toList())\n                );\n    }\n\n    private static List<Content> retrieve(ContentRetriever retriever, Query query) {\n        List<Content> contents = retriever.retrieve(query);\n        log(query, retriever, contents);\n        return contents;\n    }\n\n    private static Map<Query, Collection<List<Content>>> join(\n            Map<Query, CompletableFuture<Collection<List<Content>>>> queryToFutureContents) {\n        return allOf(queryToFutureContents.values().toArray(new CompletableFuture[0]))\n                .thenApply(ignored ->\n                        queryToFutureContents.entrySet().stream()\n                                .collect(toMap(\n                                        Map.Entry::getKey,\n                                        entry -> entry.getValue().join()\n                                ))\n                ).join();\n    }\n\n    private static void logQueries(Query originalQuery, Collection<Query> queries) {\n        if (queries.size() == 1) {\n            Query transformedQuery = queries.iterator().next();\n            if (!transformedQuery.equals(originalQuery)) {\n                log.debug(\"Transformed original query '{}' into '{}'\",\n                        originalQuery.text(), transformedQuery.text());\n            }\n        } else {\n            log.debug(\"Transformed original query '{}' into the following queries:\\n{}\",\n                    originalQuery.text(), queries.stream()\n                            .map(Query::text)\n                            .map(query -> \"- '\" + query + \"'\")\n                            .collect(joining(\"\\n\")));\n        }\n    }\n\n    private static void log(Query query, Collection<ContentRetriever> retrievers) {\n        // TODO use retriever id\n        if (retrievers.size() == 1) {\n            log.debug(\"Routing query '{}' to the following retriever: {}\",\n                    query.text(), retrievers.iterator().next());\n        } else {\n            log.debug(\"Routing query '{}' to the following retrievers:\\n{}\",\n                    query.text(), retrievers.stream()\n                            .map(retriever -> \"- \" + retriever.toString())\n                            .collect(joining(\"\\n\")));\n        }\n    }\n\n    private static void log(Query query, ContentRetriever retriever, List<Content> contents) {\n        // TODO use retriever id\n        log.debug(\"Retrieved {} contents using query '{}' and retriever '{}'\",\n                contents.size(), query.text(), retriever);\n\n        if (contents.size() > 0) {\n            log.trace(\"Retrieved {} contents using query '{}' and retriever '{}':\\n{}\",\n                    contents.size(), query.text(), retriever, contents.stream()\n                            .map(Content::textSegment)\n                            .map(segment -> \"- \" + escapeNewlines(segment.text()))\n                            .collect(joining(\"\\n\")));\n        }\n    }\n\n    private static void log(Map<Query, Collection<List<Content>>> queryToContents, List<Content> contents) {\n\n        int contentCount = 0;\n        for (Map.Entry<Query, Collection<List<Content>>> entry : queryToContents.entrySet()) {\n            for (List<Content> contentList : entry.getValue()) {\n                contentCount += contentList.size();\n            }\n        }\n        if (contentCount == contents.size()) {\n            return;\n        }\n\n        log.debug(\"Aggregated {} content(s) into {}\", contentCount, contents.size());\n\n        log.trace(\"Aggregated {} content(s) into:\\n{}\",\n                contentCount, contents.stream()\n                        .map(Content::textSegment)\n                        .map(segment -> \"- \" + escapeNewlines(segment.text()))\n                        .collect(joining(\"\\n\")));\n    }\n\n    private static void log(ChatMessage augmentedChatMessage) {\n        log.trace(\"Augmented chat message: {}\", escapeNewlines(augmentedChatMessage.text()));\n    }\n\n    private static String escapeNewlines(String text) {\n        return text.replace(\"\\n\", \"\\\\n\");\n    }\n\n    public static DefaultRetrievalAugmentorBuilder builder() {\n        return new DefaultRetrievalAugmentorBuilder();\n    }\n\n    public static class DefaultRetrievalAugmentorBuilder {\n\n        public DefaultRetrievalAugmentorBuilder contentRetriever(ContentRetriever contentRetriever) {\n            this.queryRouter = new DefaultQueryRouter(ensureNotNull(contentRetriever, \"contentRetriever\"));\n            return this;\n        }\n    }\n}\n\n```\n# Function Signature: @Override    @Deprecated    public UserMessage augment(UserMessage userMessage, Metadata metadata) {\n# Natural Language Annotations: /**\n     * @deprecated use {@link #augment(AugmentationRequest)} instead.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\n@Deprecated\npublic UserMessage augment(UserMessage userMessage, Metadata metadata) {\n    return augment(AugmentationRequest.builder()\n            .chatMessage(userMessage)\n            .metadata(metadata)\n            .build())\n            .chatMessage();\n}\n```", "  ```\n@Override\n@Deprecated\npublic UserMessage augment(UserMessage userMessage, Metadata metadata) {\n    // TODO: Implement this method\n}\n```", "  ```\n@Override\n@Deprecated\npublic UserMessage augment(UserMessage userMessage, Metadata metadata) {\n    return augment(AugmentationRequest.builder()\n            .userMessage(userMessage)\n            .metadata(metadata)\n            .build());\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/rag/content/injector/ContentInjector.java-inject": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/rag/content/injector/ContentInjector.java:\n```\npackage dev.langchain4j.rag.content.injector;\n\nimport dev.langchain4j.Experimental;\nimport dev.langchain4j.data.message.ChatMessage;\nimport dev.langchain4j.data.message.SystemMessage;\nimport dev.langchain4j.data.message.UserMessage;\nimport dev.langchain4j.rag.content.Content;\n\nimport java.util.List;\n\nimport static dev.langchain4j.internal.Exceptions.runtime;\n\n/**\n * Injects given {@link Content}s into a given {@link UserMessage}.\n * <br>\n * The goal is to format and incorporate the {@link Content}s into the original {@link UserMessage}\n * enabling the LLM to utilize it for generating a grounded response.\n *\n * @see DefaultContentInjector\n */\n@Experimental\npublic interface ContentInjector {\n\n    /**\n     * Injects given {@link Content}s into a given {@link ChatMessage}.\n     * <br>\n     * This method has a default implementation in order to <b>temporarily</b> support\n     * current custom implementations of {@code ContentInjector}. The default implementation will be removed soon.\n     *\n     * @param contents    The list of {@link Content} to be injected.\n     * @param chatMessage The {@link ChatMessage} into which the {@link Content}s are to be injected.\n     *                    Can be either a {@link UserMessage} or a {@link SystemMessage}.\n     * @return The {@link UserMessage} with the injected {@link Content}s.\n     */\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Injects given {@link Content}s into a given {@link UserMessage}.\n     *\n     * @param contents    The list of {@link Content} to be injected.\n     * @param userMessage The {@link UserMessage} into which the {@link Content}s are to be injected.\n     * @return The {@link UserMessage} with the injected {@link Content}s.\n     * @deprecated Use/implement {@link #inject(List, ChatMessage)} instead.\n     */\n    @Deprecated\n    UserMessage inject(List<Content> contents, UserMessage userMessage);\n}\n\n```\n# Function Signature: default ChatMessage inject(List<Content> contents, ChatMessage chatMessage) {\n# Natural Language Annotations: /**\n     * Injects given {@link Content}s into a given {@link ChatMessage}.\n     * <br>\n     * This method has a default implementation in order to <b>temporarily</b> support\n     * current custom implementations of {@code ContentInjector}. The default implementation will be removed soon.\n     *\n     * @param contents    The list of {@link Content} to be injected.\n     * @param chatMessage The {@link ChatMessage} into which the {@link Content}s are to be injected.\n     *                    Can be either a {@link UserMessage} or a {@link SystemMessage}.\n     * @return The {@link UserMessage} with the injected {@link Content}s.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic ChatMessage inject(List<Content> contents, ChatMessage chatMessage) {\n        // Default implementation for temporary support of custom implementations\n        return new DefaultContentInjector().inject(contents, chatMessage);\n    }\n```", "  ```\npublic ChatMessage inject(List<Content> contents, ChatMessage chatMessage) {\n    // Check if the ChatMessage is either a UserMessage or a SystemMessage\n    if (chatMessage instanceof UserMessage) {\n        return injectContent((UserMessage) chatMessage, contents);\n    } else if (chatMessage instanceof SystemMessage) {\n        return injectContent((SystemMessage) chatMessage, contents);\n    } else {\n        throw new IllegalArgumentException(\"Unsupported ChatMessage type: \" + chatMessage.getClass());\n    }\n}\n\nprivate UserMessage injectContent(UserMessage userMessage, List<Content> contents) {\n    // Inject the Content into the UserMessage by appending it to the content data\n    userMessage.setContent(userMessage.getContent() + \", \" + contents.toString());\n    return userMessage;\n}\n\nprivate SystemMessage injectContent(SystemMessage systemMessage, List<Content> contents) {\n    // Inject the Content into the SystemMessage by appending it to the content data\n    systemMessage.setContent(systemMessage.getContent() + \", \" + contents.toString());\n    return systemMessage;\n}\n```", "  ```\npublic class DefaultContentInjector implements ContentInjector {\n    @Override\n    public UserMessage inject(List<Content> contents, ChatMessage chatMessage) {\n        // Temporarily support custom implementations of ContentInjector\n        if (this instanceof DefaultContentInjector) {\n            UserMessage userMessage = new UserMessage(chatMessage.getId(), contents);\n            return userMessage;\n        }\n        // If there are no custom implementations, use the default implementation\n        return inject(contents, (UserMessage) chatMessage);\n    }\n\n    @Override\n    public UserMessage inject(List<Content> contents, UserMessage userMessage) {\n        ChatMessage chatMessage = userMessage.getChatMessage();\n        UserMessage userMessageWithContent = new UserMessage(chatMessage.getId(), contents);\n        return userMessageWithContent;\n    }\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java-areNotNullOrBlank": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java:\n```\npackage dev.langchain4j.internal;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.InputStream;\nimport java.net.HttpURLConnection;\nimport java.net.URI;\nimport java.net.URL;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.UUID;\nimport java.util.function.Supplier;\n\nimport static java.net.HttpURLConnection.HTTP_OK;\nimport static java.nio.charset.StandardCharsets.UTF_8;\nimport static java.util.Collections.unmodifiableList;\n\n/**\n * Utility methods.\n */\npublic class Utils {\n  private Utils() {}\n\n  /**\n   * Returns the given value if it is not {@code null}, otherwise returns the given default value.\n   * @param value The value to return if it is not {@code null}.\n   * @param defaultValue The value to return if the value is {@code null}.\n   * @return the given value if it is not {@code null}, otherwise returns the given default value.\n   * @param <T> The type of the value.\n   */\n  public static <T> T getOrDefault(T value, T defaultValue) {\n    return value != null ? value : defaultValue;\n  }\n\n  /**\n   * Returns the given value if it is not {@code null}, otherwise returns the value returned by the given supplier.\n   * @param value The value to return if it is not {@code null}.\n   * @param defaultValueSupplier The supplier to call if the value is {@code null}.\n   * @return the given value if it is not {@code null}, otherwise returns the value returned by the given supplier.\n   * @param <T> The type of the value.\n   */\n  public static <T> T getOrDefault(T value, Supplier<T> defaultValueSupplier) {\n    return value != null ? value : defaultValueSupplier.get();\n  }\n\n  /**\n   * Is the given string {@code null} or blank?\n   * @param string The string to check.\n   * @return true if the string is {@code null} or blank.\n   */\n  public static boolean isNullOrBlank(String string) {\n    return string == null || string.trim().isEmpty();\n  }\n\n  /**\n   * Is the given string {@code null} or empty (\"\")?\n   * @param string The string to check.\n   * @return true if the string is {@code null} or empty.\n   */\n  public static boolean isNullOrEmpty(String string) {\n    return string == null || string.isEmpty();\n  }\n\n  /**\n   * Is the given string not {@code null} and not blank?\n   * @param string The string to check.\n   * @return true if there's something in the string.\n   */\n  public static boolean isNotNullOrBlank(String string) {\n    return !isNullOrBlank(string);\n  }\n\n  /**\n   * Is the given string not {@code null} and not empty (\"\")?\n   * @param string The string to check.\n   * @return true if the given string is not {@code null} and not empty (\"\")?\n   */\n  public static boolean isNotNullOrEmpty(String string) {\n    return !isNullOrEmpty(string);\n  }\n\n  /**\n   * Are all the given strings not {@code null} and not blank?\n   * @param strings The strings to check.\n   * @return {@code true} if every string is non-{@code null} and non-empty.\n   */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  /**\n   * Is the collection {@code null} or empty?\n   * @param collection The collection to check.\n   * @return {@code true} if the collection is {@code null} or {@link Collection#isEmpty()}, otherwise {@code false}.\n   */\n  public static boolean isNullOrEmpty(Collection<?> collection) {\n    return collection == null || collection.isEmpty();\n  }\n\n  /**\n   * Is the iterable object {@code null} or empty?\n   * @param iterable The iterable object to check.\n   * @return {@code true} if the iterable object is {@code null} or there are no objects to iterate over, otherwise {@code false}.\n   */\n  public static boolean isNullOrEmpty(Iterable<?> iterable) {\n    return iterable == null || !iterable.iterator().hasNext();\n  }\n\n  /**\n   * @deprecated Use {@link #isNullOrEmpty(Collection)} instead.\n   * @param collection The collection to check.\n   * @return {@code true} if the collection is {@code null} or empty, {@code false} otherwise.\n   */\n  @SuppressWarnings(\"DeprecatedIsStillUsed\")\n  @Deprecated\n  public static boolean isCollectionEmpty(Collection<?> collection) {\n    return isNullOrEmpty(collection);\n  }\n\n  /**\n   * Returns a string consisting of the given string repeated {@code times} times.\n   *\n   * @param string The string to repeat.\n   * @param times  The number of times to repeat the string.\n   * @return A string consisting of the given string repeated {@code times} times.\n   */\n  public static String repeat(String string, int times) {\n    StringBuilder sb = new StringBuilder();\n    for (int i = 0; i < times; i++) {\n      sb.append(string);\n    }\n    return sb.toString();\n  }\n\n  /**\n   * Returns a random UUID.\n   * @return a UUID.\n   */\n  public static String randomUUID() {\n    return UUID.randomUUID().toString();\n  }\n\n  /**\n   * Internal method to get a SHA-256 instance of {@link MessageDigest}.\n   * @return a {@link MessageDigest}.\n   */\n  @JacocoIgnoreCoverageGenerated\n  private static MessageDigest getSha256Instance() {\n    try {\n      return MessageDigest.getInstance(\"SHA-256\");\n    } catch (NoSuchAlgorithmException e) {\n      throw new IllegalArgumentException(e);\n    }\n  }\n\n  /**\n   * Generates a UUID from a hash of the given input string.\n   * @param input The input string.\n   * @return A UUID.\n   */\n\n\n\n\n\n\n\n  /**\n   * Appends a trailing '/' if the provided URL does not end with '/'\n   * \n   * @param url URL to check for trailing '/'\n   * @return Same URL if it already ends with '/' or a new URL with '/' appended\n   */\n  public static String ensureTrailingForwardSlash(String url) {\n      return url.endsWith(\"/\") ? url : url + \"/\";\n  }\n\n  /**\n   * Returns the given object's {@code toString()} surrounded by quotes.\n   *\n   * <p>If the given object is {@code null}, the string {@code \"null\"} is returned.\n   *\n   * @param object The object to quote.\n   * @return The given object surrounded by quotes.\n   */\n  public static String quoted(Object object) {\n    if (object == null) {\n      return \"null\";\n    }\n    return \"\\\"\" + object + \"\\\"\";\n  }\n\n  /**\n   * Returns the first {@code numberOfChars} characters of the given string.\n   * If the string is shorter than {@code numberOfChars}, the whole string is returned.\n   *\n   * @param string        The string to get the first characters from.\n   * @param numberOfChars The number of characters to return.\n   * @return The first {@code numberOfChars} characters of the given string.\n   */\n  public static String firstChars(String string, int numberOfChars) {\n    if (string == null) {\n      return null;\n    }\n    return string.length() > numberOfChars ? string.substring(0, numberOfChars) : string;\n  }\n\n  /**\n   * Reads the content as bytes from the given URL as a GET request for HTTP/HTTPS resources,\n   * and from files stored on the local filesystem.\n   *\n   * @param url The URL to read from.\n   * @return The content as bytes.\n   * @throws RuntimeException if the request fails.\n   */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  /**\n   * Returns an (unmodifiable) copy of the provided list.\n   * Returns <code>null</code> if the provided list is <code>null</code>.\n   *\n   * @param list The list to copy.\n   * @param <T>  Generic type of the list.\n   * @return The copy of the provided list.\n   */\n  public static <T> List<T> copyIfNotNull(List<T> list) {\n    if (list == null) {\n      return null;\n    }\n\n    return unmodifiableList(list);\n  }\n}\n\n```\n# Function Signature: public static boolean areNotNullOrBlank(String... strings) {\n# Natural Language Annotations: /**\n   * Are all the given strings not {@code null} and not blank?\n   * @param strings The strings to check.\n   * @return {@code true} if every string is non-{@code null} and non-empty.\n   */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static boolean areNotNullOrBlank(String... strings) {\n    for (String string : strings) {\n        if (isNullOrBlank(string)) {\n            return false;\n        }\n    }\n    return true;\n}\n```", "  ```\npublic static boolean areNotNullOrBlank(String... strings) {\n    for (String string : strings) {\n        if (string == null || string.trim().isEmpty()) {\n            return false;\n        }\n    }\n    return true;\n}\n```", "  ```\npublic static boolean areNotNullOrBlank(String... strings) {\n    return strings != null && Arrays.stream(strings).allMatch(str -> str != null && !str.trim().isEmpty());\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java-generateUUIDFrom": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java:\n```\npackage dev.langchain4j.internal;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.InputStream;\nimport java.net.HttpURLConnection;\nimport java.net.URI;\nimport java.net.URL;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.UUID;\nimport java.util.function.Supplier;\n\nimport static java.net.HttpURLConnection.HTTP_OK;\nimport static java.nio.charset.StandardCharsets.UTF_8;\nimport static java.util.Collections.unmodifiableList;\n\n/**\n * Utility methods.\n */\npublic class Utils {\n  private Utils() {}\n\n  /**\n   * Returns the given value if it is not {@code null}, otherwise returns the given default value.\n   * @param value The value to return if it is not {@code null}.\n   * @param defaultValue The value to return if the value is {@code null}.\n   * @return the given value if it is not {@code null}, otherwise returns the given default value.\n   * @param <T> The type of the value.\n   */\n  public static <T> T getOrDefault(T value, T defaultValue) {\n    return value != null ? value : defaultValue;\n  }\n\n  /**\n   * Returns the given value if it is not {@code null}, otherwise returns the value returned by the given supplier.\n   * @param value The value to return if it is not {@code null}.\n   * @param defaultValueSupplier The supplier to call if the value is {@code null}.\n   * @return the given value if it is not {@code null}, otherwise returns the value returned by the given supplier.\n   * @param <T> The type of the value.\n   */\n  public static <T> T getOrDefault(T value, Supplier<T> defaultValueSupplier) {\n    return value != null ? value : defaultValueSupplier.get();\n  }\n\n  /**\n   * Is the given string {@code null} or blank?\n   * @param string The string to check.\n   * @return true if the string is {@code null} or blank.\n   */\n  public static boolean isNullOrBlank(String string) {\n    return string == null || string.trim().isEmpty();\n  }\n\n  /**\n   * Is the given string {@code null} or empty (\"\")?\n   * @param string The string to check.\n   * @return true if the string is {@code null} or empty.\n   */\n  public static boolean isNullOrEmpty(String string) {\n    return string == null || string.isEmpty();\n  }\n\n  /**\n   * Is the given string not {@code null} and not blank?\n   * @param string The string to check.\n   * @return true if there's something in the string.\n   */\n  public static boolean isNotNullOrBlank(String string) {\n    return !isNullOrBlank(string);\n  }\n\n  /**\n   * Is the given string not {@code null} and not empty (\"\")?\n   * @param string The string to check.\n   * @return true if the given string is not {@code null} and not empty (\"\")?\n   */\n  public static boolean isNotNullOrEmpty(String string) {\n    return !isNullOrEmpty(string);\n  }\n\n  /**\n   * Are all the given strings not {@code null} and not blank?\n   * @param strings The strings to check.\n   * @return {@code true} if every string is non-{@code null} and non-empty.\n   */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  /**\n   * Is the collection {@code null} or empty?\n   * @param collection The collection to check.\n   * @return {@code true} if the collection is {@code null} or {@link Collection#isEmpty()}, otherwise {@code false}.\n   */\n  public static boolean isNullOrEmpty(Collection<?> collection) {\n    return collection == null || collection.isEmpty();\n  }\n\n  /**\n   * Is the iterable object {@code null} or empty?\n   * @param iterable The iterable object to check.\n   * @return {@code true} if the iterable object is {@code null} or there are no objects to iterate over, otherwise {@code false}.\n   */\n  public static boolean isNullOrEmpty(Iterable<?> iterable) {\n    return iterable == null || !iterable.iterator().hasNext();\n  }\n\n  /**\n   * @deprecated Use {@link #isNullOrEmpty(Collection)} instead.\n   * @param collection The collection to check.\n   * @return {@code true} if the collection is {@code null} or empty, {@code false} otherwise.\n   */\n  @SuppressWarnings(\"DeprecatedIsStillUsed\")\n  @Deprecated\n  public static boolean isCollectionEmpty(Collection<?> collection) {\n    return isNullOrEmpty(collection);\n  }\n\n  /**\n   * Returns a string consisting of the given string repeated {@code times} times.\n   *\n   * @param string The string to repeat.\n   * @param times  The number of times to repeat the string.\n   * @return A string consisting of the given string repeated {@code times} times.\n   */\n  public static String repeat(String string, int times) {\n    StringBuilder sb = new StringBuilder();\n    for (int i = 0; i < times; i++) {\n      sb.append(string);\n    }\n    return sb.toString();\n  }\n\n  /**\n   * Returns a random UUID.\n   * @return a UUID.\n   */\n  public static String randomUUID() {\n    return UUID.randomUUID().toString();\n  }\n\n  /**\n   * Internal method to get a SHA-256 instance of {@link MessageDigest}.\n   * @return a {@link MessageDigest}.\n   */\n  @JacocoIgnoreCoverageGenerated\n  private static MessageDigest getSha256Instance() {\n    try {\n      return MessageDigest.getInstance(\"SHA-256\");\n    } catch (NoSuchAlgorithmException e) {\n      throw new IllegalArgumentException(e);\n    }\n  }\n\n  /**\n   * Generates a UUID from a hash of the given input string.\n   * @param input The input string.\n   * @return A UUID.\n   */\n\n\n\n\n\n\n\n  /**\n   * Appends a trailing '/' if the provided URL does not end with '/'\n   * \n   * @param url URL to check for trailing '/'\n   * @return Same URL if it already ends with '/' or a new URL with '/' appended\n   */\n  public static String ensureTrailingForwardSlash(String url) {\n      return url.endsWith(\"/\") ? url : url + \"/\";\n  }\n\n  /**\n   * Returns the given object's {@code toString()} surrounded by quotes.\n   *\n   * <p>If the given object is {@code null}, the string {@code \"null\"} is returned.\n   *\n   * @param object The object to quote.\n   * @return The given object surrounded by quotes.\n   */\n  public static String quoted(Object object) {\n    if (object == null) {\n      return \"null\";\n    }\n    return \"\\\"\" + object + \"\\\"\";\n  }\n\n  /**\n   * Returns the first {@code numberOfChars} characters of the given string.\n   * If the string is shorter than {@code numberOfChars}, the whole string is returned.\n   *\n   * @param string        The string to get the first characters from.\n   * @param numberOfChars The number of characters to return.\n   * @return The first {@code numberOfChars} characters of the given string.\n   */\n  public static String firstChars(String string, int numberOfChars) {\n    if (string == null) {\n      return null;\n    }\n    return string.length() > numberOfChars ? string.substring(0, numberOfChars) : string;\n  }\n\n  /**\n   * Reads the content as bytes from the given URL as a GET request for HTTP/HTTPS resources,\n   * and from files stored on the local filesystem.\n   *\n   * @param url The URL to read from.\n   * @return The content as bytes.\n   * @throws RuntimeException if the request fails.\n   */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  /**\n   * Returns an (unmodifiable) copy of the provided list.\n   * Returns <code>null</code> if the provided list is <code>null</code>.\n   *\n   * @param list The list to copy.\n   * @param <T>  Generic type of the list.\n   * @return The copy of the provided list.\n   */\n  public static <T> List<T> copyIfNotNull(List<T> list) {\n    if (list == null) {\n      return null;\n    }\n\n    return unmodifiableList(list);\n  }\n}\n\n```\n# Function Signature: public static String generateUUIDFrom(String input) {\n# Natural Language Annotations: /**\n   * Generates a UUID from a hash of the given input string.\n   * @param input The input string.\n   * @return A UUID.\n   */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static String generateUUIDFrom(String input) {\n    MessageDigest messageDigest = getSha256Instance();\n    byte[] result = messageDigest.digest(input.getBytes(UTF_8));\n    UUID uuid = UUID.nameUUIDFromBytes(result);\n    return uuid.toString();\n  }\n```", "  ```\npublic static String generateUUIDFrom(String input) {\n    MessageDigest digest = getSha256Instance();\n    byte[] hash = digest.digest(input.getBytes());\n    return new BigInteger(hash).toString(32).substring(0, 36);\n}\n```", "  ```\npublic static String generateUUIDFrom(String input) {\n    return new StringBuilder()\n            .append(getSha256Instance().digest((input + \"UUID\").getBytes(UTF_8)))\n            .toString();\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java-readBytes": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java:\n```\npackage dev.langchain4j.internal;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.InputStream;\nimport java.net.HttpURLConnection;\nimport java.net.URI;\nimport java.net.URL;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.UUID;\nimport java.util.function.Supplier;\n\nimport static java.net.HttpURLConnection.HTTP_OK;\nimport static java.nio.charset.StandardCharsets.UTF_8;\nimport static java.util.Collections.unmodifiableList;\n\n/**\n * Utility methods.\n */\npublic class Utils {\n  private Utils() {}\n\n  /**\n   * Returns the given value if it is not {@code null}, otherwise returns the given default value.\n   * @param value The value to return if it is not {@code null}.\n   * @param defaultValue The value to return if the value is {@code null}.\n   * @return the given value if it is not {@code null}, otherwise returns the given default value.\n   * @param <T> The type of the value.\n   */\n  public static <T> T getOrDefault(T value, T defaultValue) {\n    return value != null ? value : defaultValue;\n  }\n\n  /**\n   * Returns the given value if it is not {@code null}, otherwise returns the value returned by the given supplier.\n   * @param value The value to return if it is not {@code null}.\n   * @param defaultValueSupplier The supplier to call if the value is {@code null}.\n   * @return the given value if it is not {@code null}, otherwise returns the value returned by the given supplier.\n   * @param <T> The type of the value.\n   */\n  public static <T> T getOrDefault(T value, Supplier<T> defaultValueSupplier) {\n    return value != null ? value : defaultValueSupplier.get();\n  }\n\n  /**\n   * Is the given string {@code null} or blank?\n   * @param string The string to check.\n   * @return true if the string is {@code null} or blank.\n   */\n  public static boolean isNullOrBlank(String string) {\n    return string == null || string.trim().isEmpty();\n  }\n\n  /**\n   * Is the given string {@code null} or empty (\"\")?\n   * @param string The string to check.\n   * @return true if the string is {@code null} or empty.\n   */\n  public static boolean isNullOrEmpty(String string) {\n    return string == null || string.isEmpty();\n  }\n\n  /**\n   * Is the given string not {@code null} and not blank?\n   * @param string The string to check.\n   * @return true if there's something in the string.\n   */\n  public static boolean isNotNullOrBlank(String string) {\n    return !isNullOrBlank(string);\n  }\n\n  /**\n   * Is the given string not {@code null} and not empty (\"\")?\n   * @param string The string to check.\n   * @return true if the given string is not {@code null} and not empty (\"\")?\n   */\n  public static boolean isNotNullOrEmpty(String string) {\n    return !isNullOrEmpty(string);\n  }\n\n  /**\n   * Are all the given strings not {@code null} and not blank?\n   * @param strings The strings to check.\n   * @return {@code true} if every string is non-{@code null} and non-empty.\n   */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  /**\n   * Is the collection {@code null} or empty?\n   * @param collection The collection to check.\n   * @return {@code true} if the collection is {@code null} or {@link Collection#isEmpty()}, otherwise {@code false}.\n   */\n  public static boolean isNullOrEmpty(Collection<?> collection) {\n    return collection == null || collection.isEmpty();\n  }\n\n  /**\n   * Is the iterable object {@code null} or empty?\n   * @param iterable The iterable object to check.\n   * @return {@code true} if the iterable object is {@code null} or there are no objects to iterate over, otherwise {@code false}.\n   */\n  public static boolean isNullOrEmpty(Iterable<?> iterable) {\n    return iterable == null || !iterable.iterator().hasNext();\n  }\n\n  /**\n   * @deprecated Use {@link #isNullOrEmpty(Collection)} instead.\n   * @param collection The collection to check.\n   * @return {@code true} if the collection is {@code null} or empty, {@code false} otherwise.\n   */\n  @SuppressWarnings(\"DeprecatedIsStillUsed\")\n  @Deprecated\n  public static boolean isCollectionEmpty(Collection<?> collection) {\n    return isNullOrEmpty(collection);\n  }\n\n  /**\n   * Returns a string consisting of the given string repeated {@code times} times.\n   *\n   * @param string The string to repeat.\n   * @param times  The number of times to repeat the string.\n   * @return A string consisting of the given string repeated {@code times} times.\n   */\n  public static String repeat(String string, int times) {\n    StringBuilder sb = new StringBuilder();\n    for (int i = 0; i < times; i++) {\n      sb.append(string);\n    }\n    return sb.toString();\n  }\n\n  /**\n   * Returns a random UUID.\n   * @return a UUID.\n   */\n  public static String randomUUID() {\n    return UUID.randomUUID().toString();\n  }\n\n  /**\n   * Internal method to get a SHA-256 instance of {@link MessageDigest}.\n   * @return a {@link MessageDigest}.\n   */\n  @JacocoIgnoreCoverageGenerated\n  private static MessageDigest getSha256Instance() {\n    try {\n      return MessageDigest.getInstance(\"SHA-256\");\n    } catch (NoSuchAlgorithmException e) {\n      throw new IllegalArgumentException(e);\n    }\n  }\n\n  /**\n   * Generates a UUID from a hash of the given input string.\n   * @param input The input string.\n   * @return A UUID.\n   */\n\n\n\n\n\n\n\n  /**\n   * Appends a trailing '/' if the provided URL does not end with '/'\n   * \n   * @param url URL to check for trailing '/'\n   * @return Same URL if it already ends with '/' or a new URL with '/' appended\n   */\n  public static String ensureTrailingForwardSlash(String url) {\n      return url.endsWith(\"/\") ? url : url + \"/\";\n  }\n\n  /**\n   * Returns the given object's {@code toString()} surrounded by quotes.\n   *\n   * <p>If the given object is {@code null}, the string {@code \"null\"} is returned.\n   *\n   * @param object The object to quote.\n   * @return The given object surrounded by quotes.\n   */\n  public static String quoted(Object object) {\n    if (object == null) {\n      return \"null\";\n    }\n    return \"\\\"\" + object + \"\\\"\";\n  }\n\n  /**\n   * Returns the first {@code numberOfChars} characters of the given string.\n   * If the string is shorter than {@code numberOfChars}, the whole string is returned.\n   *\n   * @param string        The string to get the first characters from.\n   * @param numberOfChars The number of characters to return.\n   * @return The first {@code numberOfChars} characters of the given string.\n   */\n  public static String firstChars(String string, int numberOfChars) {\n    if (string == null) {\n      return null;\n    }\n    return string.length() > numberOfChars ? string.substring(0, numberOfChars) : string;\n  }\n\n  /**\n   * Reads the content as bytes from the given URL as a GET request for HTTP/HTTPS resources,\n   * and from files stored on the local filesystem.\n   *\n   * @param url The URL to read from.\n   * @return The content as bytes.\n   * @throws RuntimeException if the request fails.\n   */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  /**\n   * Returns an (unmodifiable) copy of the provided list.\n   * Returns <code>null</code> if the provided list is <code>null</code>.\n   *\n   * @param list The list to copy.\n   * @param <T>  Generic type of the list.\n   * @return The copy of the provided list.\n   */\n  public static <T> List<T> copyIfNotNull(List<T> list) {\n    if (list == null) {\n      return null;\n    }\n\n    return unmodifiableList(list);\n  }\n}\n\n```\n# Function Signature: public static byte[] readBytes(String url) {\n# Natural Language Annotations: /**\n   * Reads the content as bytes from the given URL as a GET request for HTTP/HTTPS resources,\n   * and from files stored on the local filesystem.\n   *\n   * @param url The URL to read from.\n   * @return The content as bytes.\n   * @throws RuntimeException if the request fails.\n   */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static byte[] readBytes(String url) {\n    try {\n        URL urlObj = new URL(url);\n        HttpURLConnection connection = (HttpURLConnection) urlObj.openConnection();\n        connection.setRequestMethod(\"GET\");\n        connection.setReadTimeout(10_000);\n        connection.connect();\n        if (connection.getResponseCode() != HTTP_OK) {\n            throw new RuntimeException(\"Failed to connect to the URL: \" + url);\n        }\n        try (InputStream inputStream = connection.getInputStream()) {\n            ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n            byte[] buffer = new byte[4096];\n            int len;\n            while ((len = inputStream.read(buffer)) != -1) {\n                outputStream.write(buffer, 0, len);\n            }\n            return outputStream.toByteArray();\n        }\n    } catch (IOException e) {\n        throw new RuntimeException(\"Failed to read data from URL: \" + url, e);\n    }\n}\n```", "  ```\npublic static byte[] readBytes(String url) {\n    try {\n        URI uri = new URI(url);\n        if (uri.getScheme().equals(\"http\") || uri.getScheme().equals(\"https\")) {\n            HttpURLConnection connection = (HttpURLConnection) uri.toURL().openConnection();\n            connection.setRequestMethod(\"GET\");\n            connection.connect();\n            if (connection.getResponseCode() == HTTP_OK) {\n                InputStream inputStream = connection.getInputStream();\n                ByteArrayOutputStream baos = new ByteArrayOutputStream();\n                int n;\n                byte[] buffer = new byte[1024];\n                while ((n = inputStream.read(buffer)) != -1) {\n                    baos.write(buffer, 0, n);\n                }\n                inputStream.close();\n                return baos.toByteArray();\n            } else {\n                throw new RuntimeException(\"Http response code: \" + connection.getResponseCode() + \" \" + connection.getResponseMessage());\n            }\n        } else if (uri.getScheme().equals(\"file\")) {\n            return Files.readAllBytes(Paths.get(uri.getPath()));\n        } else {\n            throw new UnsupportedOperationException(\"Unsupported scheme: \" + uri.getScheme());\n        }\n    } catch (Exception e) {\n        throw new RuntimeException(e);\n    }\n}\n```", "  ```\npublic static byte[] readBytes(String url) {\n    HTTP_OK = 200;\n    InputStream inputStream = makeGetRequest(url);\n    if (inputStream == null) {\n        return null;\n    }\n    return inputStreamToBytes(inputStream);\n}\n\nprivate static InputStream makeGetRequest(String url) {\n    try {\n        URL toConnectTo = new URL(url);\n        HttpURLConnection connection = (HttpURLConnection) toConnectTo.openConnection();\n        connection.setRequestMethod(\"GET\");\n        return handleIOException(connection.getInputStream());\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n\nprivate static InputStream handleIOException(InputStream inputStream) {\n    try {\n        return inputStream;\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n\nprivate static byte[] inputStreamToBytes(InputStream inputStream) {\n    try {\n        ByteArrayOutputStream buffer = new ByteArrayOutputStream();\n        int nRead;\n        byte[] data = new byte[4096];\n        while ((nRead = inputStream.read(data, 0, data.length)) != -1) {\n            buffer.write(data, 0, nRead);\n        }\n        buffer.flush();\n        return buffer.toByteArray();\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    } finally {\n        try {\n            inputStream.close();\n        } catch (IOException e) {\n            // Ignored\n        }\n    }\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/ValidationUtils.java-ensureNotEmpty": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/internal/ValidationUtils.java:\n```\npackage dev.langchain4j.internal;\n\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Objects;\n\nimport static dev.langchain4j.internal.Exceptions.illegalArgument;\n\n/**\n * Utility class for validating method arguments.\n */\npublic class ValidationUtils {\n    private ValidationUtils() {}\n\n    /**\n     * Ensure that the two values are equal.\n     * @param lhs the left hand side value.\n     * @param rhs the right hand side value.\n     * @param format the format string for the exception message.\n     * @param args the format arguments for the exception message.\n     */\n    public static void ensureEq(Object lhs, Object rhs, String format, Object... args) {\n        if (!Objects.equals(lhs, rhs)) {\n            throw illegalArgument(format, args);\n        }\n    }\n\n    /**\n     * Ensures that the given object is not null.\n     * @param object The object to check.\n     * @param name The name of the object to be used in the exception message.\n     * @return The object if it is not null.\n     * @param <T> The type of the object.\n     * @throws IllegalArgumentException if the object is null.\n     */\n    public static <T> T ensureNotNull(T object, String name) {\n        return ensureNotNull(object, \"%s cannot be null\", name);\n    }\n\n    /**\n     * Ensures that the given object is not null.\n     * @param object The object to check.\n     * @param format The format of the exception message.\n     * @param args The arguments for the exception message.\n     * @return The object if it is not null.\n     * @param <T> The type of the object.\n     */\n    public static <T> T ensureNotNull(T object, String format, Object... args) {\n        if (object == null) {\n            throw illegalArgument(format, args);\n        }\n        return object;\n    }\n\n    /**\n     * Ensures that the given collection is not null and not empty.\n     * @param collection The collection to check.\n     * @param name The name of the collection to be used in the exception message.\n     * @return The collection if it is not null and not empty.\n     * @param <T> The type of the collection.\n     *           @throws IllegalArgumentException if the collection is null or empty.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given map is not null and not empty.\n     *\n     * @param map  The map to check.\n     * @param name The name of the map to be used in the exception message.\n     * @param <K>  The type of the key.\n     * @param <V>  The type of the value.\n     * @return The map if it is not null and not empty.\n     * @throws IllegalArgumentException if the collection is null or empty.\n     */\n    public static <K, V> Map<K, V> ensureNotEmpty(Map<K, V> map, String name) {\n        if (map == null || map.isEmpty()) {\n            throw illegalArgument(\"%s cannot be null or empty\", name);\n        }\n\n        return map;\n    }\n\n    /**\n     * Ensures that the given string is not null and not blank.\n     * @param string The string to check.\n     * @param name The name of the string to be used in the exception message.\n     * @return The string if it is not null and not blank.\n     * @throws IllegalArgumentException if the string is null or blank.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given expression is true.\n     * @param expression The expression to check.\n     * @param msg The message to be used in the exception.\n     * @throws IllegalArgumentException if the expression is false.\n     */\n    public static void ensureTrue(boolean expression, String msg) {\n        if (!expression) {\n            throw illegalArgument(msg);\n        }\n    }\n\n    /**\n     * Ensures that the given expression is true.\n     * @param i The expression to check.\n     * @param name The message to be used in the exception.\n     * @return The value if it is greater than zero.\n     * @throws IllegalArgumentException if the expression is false.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given Double value is in {@code [min, max]}.\n     * @param d The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given Integer value is in {@code [min, max]}.\n     * @param i The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n    public static int ensureBetween(Integer i, int min, int max, String name) {\n        if (i == null || i < min || i > max) {\n            throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, i);\n        }\n        return i;\n    }\n    /**\n     * Ensures that the given Long value is in {@code [min, max]}.\n     * @param i The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n    public static long ensureBetween(Long i, long min, long max, String name) {\n        if (i == null || i < min || i > max) {\n            throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, i);\n        }\n        return i;\n    }\n}\n\n```\n# Function Signature: public static <T extends Collection<?>> T ensureNotEmpty(T collection, String name) {\n# Natural Language Annotations: /**\n     * Ensures that the given collection is not null and not empty.\n     * @param collection The collection to check.\n     * @param name The name of the collection to be used in the exception message.\n     * @return The collection if it is not null and not empty.\n     * @param <T> The type of the collection.\n     *           @throws IllegalArgumentException if the collection is null or empty.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <T extends Collection<?>> T ensureNotEmpty(T collection, String name) {\n    if (collection == null || collection.isEmpty()) {\n        throw illegalArgument(\"%s cannot be null or empty\", name);\n    }\n    return collection;\n}\n```", "  ```\npublic static <T extends Collection<?>> T ensureNotEmpty(T collection, String name) {\n    if (collection == null || collection.isEmpty()) {\n        throw illegalArgument(\"%s cannot be null or empty\", name);\n    }\n    return collection;\n}\n```", "  ```\npublic static <T extends Collection<?>> T ensureNotEmpty(T collection, String name) {\n    if (collection == null || collection.isEmpty()) {\n        throw new IllegalArgumentException(name + \" cannot be null or empty\");\n    }\n    return collection;\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/ValidationUtils.java-ensureNotBlank": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/internal/ValidationUtils.java:\n```\npackage dev.langchain4j.internal;\n\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Objects;\n\nimport static dev.langchain4j.internal.Exceptions.illegalArgument;\n\n/**\n * Utility class for validating method arguments.\n */\npublic class ValidationUtils {\n    private ValidationUtils() {}\n\n    /**\n     * Ensure that the two values are equal.\n     * @param lhs the left hand side value.\n     * @param rhs the right hand side value.\n     * @param format the format string for the exception message.\n     * @param args the format arguments for the exception message.\n     */\n    public static void ensureEq(Object lhs, Object rhs, String format, Object... args) {\n        if (!Objects.equals(lhs, rhs)) {\n            throw illegalArgument(format, args);\n        }\n    }\n\n    /**\n     * Ensures that the given object is not null.\n     * @param object The object to check.\n     * @param name The name of the object to be used in the exception message.\n     * @return The object if it is not null.\n     * @param <T> The type of the object.\n     * @throws IllegalArgumentException if the object is null.\n     */\n    public static <T> T ensureNotNull(T object, String name) {\n        return ensureNotNull(object, \"%s cannot be null\", name);\n    }\n\n    /**\n     * Ensures that the given object is not null.\n     * @param object The object to check.\n     * @param format The format of the exception message.\n     * @param args The arguments for the exception message.\n     * @return The object if it is not null.\n     * @param <T> The type of the object.\n     */\n    public static <T> T ensureNotNull(T object, String format, Object... args) {\n        if (object == null) {\n            throw illegalArgument(format, args);\n        }\n        return object;\n    }\n\n    /**\n     * Ensures that the given collection is not null and not empty.\n     * @param collection The collection to check.\n     * @param name The name of the collection to be used in the exception message.\n     * @return The collection if it is not null and not empty.\n     * @param <T> The type of the collection.\n     *           @throws IllegalArgumentException if the collection is null or empty.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given map is not null and not empty.\n     *\n     * @param map  The map to check.\n     * @param name The name of the map to be used in the exception message.\n     * @param <K>  The type of the key.\n     * @param <V>  The type of the value.\n     * @return The map if it is not null and not empty.\n     * @throws IllegalArgumentException if the collection is null or empty.\n     */\n    public static <K, V> Map<K, V> ensureNotEmpty(Map<K, V> map, String name) {\n        if (map == null || map.isEmpty()) {\n            throw illegalArgument(\"%s cannot be null or empty\", name);\n        }\n\n        return map;\n    }\n\n    /**\n     * Ensures that the given string is not null and not blank.\n     * @param string The string to check.\n     * @param name The name of the string to be used in the exception message.\n     * @return The string if it is not null and not blank.\n     * @throws IllegalArgumentException if the string is null or blank.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given expression is true.\n     * @param expression The expression to check.\n     * @param msg The message to be used in the exception.\n     * @throws IllegalArgumentException if the expression is false.\n     */\n    public static void ensureTrue(boolean expression, String msg) {\n        if (!expression) {\n            throw illegalArgument(msg);\n        }\n    }\n\n    /**\n     * Ensures that the given expression is true.\n     * @param i The expression to check.\n     * @param name The message to be used in the exception.\n     * @return The value if it is greater than zero.\n     * @throws IllegalArgumentException if the expression is false.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given Double value is in {@code [min, max]}.\n     * @param d The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given Integer value is in {@code [min, max]}.\n     * @param i The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n    public static int ensureBetween(Integer i, int min, int max, String name) {\n        if (i == null || i < min || i > max) {\n            throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, i);\n        }\n        return i;\n    }\n    /**\n     * Ensures that the given Long value is in {@code [min, max]}.\n     * @param i The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n    public static long ensureBetween(Long i, long min, long max, String name) {\n        if (i == null || i < min || i > max) {\n            throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, i);\n        }\n        return i;\n    }\n}\n\n```\n# Function Signature: public static String ensureNotBlank(String string, String name) {\n# Natural Language Annotations: /**\n     * Ensures that the given string is not null and not blank.\n     * @param string The string to check.\n     * @param name The name of the string to be used in the exception message.\n     * @return The string if it is not null and not blank.\n     * @throws IllegalArgumentException if the string is null or blank.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static String ensureNotBlank(String string, String name) {\n    if (string == null || string.isBlank()) {\n        throw illegalArgument(\"%s cannot be null or blank\", name);\n    }\n    return string;\n}\n```", "  ```\npublic static String ensureNotBlank(String string, String name) {\n    if (string == null || string.trim().length() == 0) {\n        throw illegalArgument(\"%s cannot be null or blank\", name);\n    }\n    return string;\n}\n```", "  ```\npublic static String ensureNotBlank(String string, String name) {\n    if (string == null) {\n        throw illegalArgument(\"%s cannot be null\", name);\n    }\n    if (string.trim().isEmpty()) {\n        throw illegalArgument(\"%s cannot be blank\", name);\n    }\n    return string;\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/ValidationUtils.java-ensureGreaterThanZero": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/internal/ValidationUtils.java:\n```\npackage dev.langchain4j.internal;\n\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Objects;\n\nimport static dev.langchain4j.internal.Exceptions.illegalArgument;\n\n/**\n * Utility class for validating method arguments.\n */\npublic class ValidationUtils {\n    private ValidationUtils() {}\n\n    /**\n     * Ensure that the two values are equal.\n     * @param lhs the left hand side value.\n     * @param rhs the right hand side value.\n     * @param format the format string for the exception message.\n     * @param args the format arguments for the exception message.\n     */\n    public static void ensureEq(Object lhs, Object rhs, String format, Object... args) {\n        if (!Objects.equals(lhs, rhs)) {\n            throw illegalArgument(format, args);\n        }\n    }\n\n    /**\n     * Ensures that the given object is not null.\n     * @param object The object to check.\n     * @param name The name of the object to be used in the exception message.\n     * @return The object if it is not null.\n     * @param <T> The type of the object.\n     * @throws IllegalArgumentException if the object is null.\n     */\n    public static <T> T ensureNotNull(T object, String name) {\n        return ensureNotNull(object, \"%s cannot be null\", name);\n    }\n\n    /**\n     * Ensures that the given object is not null.\n     * @param object The object to check.\n     * @param format The format of the exception message.\n     * @param args The arguments for the exception message.\n     * @return The object if it is not null.\n     * @param <T> The type of the object.\n     */\n    public static <T> T ensureNotNull(T object, String format, Object... args) {\n        if (object == null) {\n            throw illegalArgument(format, args);\n        }\n        return object;\n    }\n\n    /**\n     * Ensures that the given collection is not null and not empty.\n     * @param collection The collection to check.\n     * @param name The name of the collection to be used in the exception message.\n     * @return The collection if it is not null and not empty.\n     * @param <T> The type of the collection.\n     *           @throws IllegalArgumentException if the collection is null or empty.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given map is not null and not empty.\n     *\n     * @param map  The map to check.\n     * @param name The name of the map to be used in the exception message.\n     * @param <K>  The type of the key.\n     * @param <V>  The type of the value.\n     * @return The map if it is not null and not empty.\n     * @throws IllegalArgumentException if the collection is null or empty.\n     */\n    public static <K, V> Map<K, V> ensureNotEmpty(Map<K, V> map, String name) {\n        if (map == null || map.isEmpty()) {\n            throw illegalArgument(\"%s cannot be null or empty\", name);\n        }\n\n        return map;\n    }\n\n    /**\n     * Ensures that the given string is not null and not blank.\n     * @param string The string to check.\n     * @param name The name of the string to be used in the exception message.\n     * @return The string if it is not null and not blank.\n     * @throws IllegalArgumentException if the string is null or blank.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given expression is true.\n     * @param expression The expression to check.\n     * @param msg The message to be used in the exception.\n     * @throws IllegalArgumentException if the expression is false.\n     */\n    public static void ensureTrue(boolean expression, String msg) {\n        if (!expression) {\n            throw illegalArgument(msg);\n        }\n    }\n\n    /**\n     * Ensures that the given expression is true.\n     * @param i The expression to check.\n     * @param name The message to be used in the exception.\n     * @return The value if it is greater than zero.\n     * @throws IllegalArgumentException if the expression is false.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given Double value is in {@code [min, max]}.\n     * @param d The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given Integer value is in {@code [min, max]}.\n     * @param i The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n    public static int ensureBetween(Integer i, int min, int max, String name) {\n        if (i == null || i < min || i > max) {\n            throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, i);\n        }\n        return i;\n    }\n    /**\n     * Ensures that the given Long value is in {@code [min, max]}.\n     * @param i The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n    public static long ensureBetween(Long i, long min, long max, String name) {\n        if (i == null || i < min || i > max) {\n            throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, i);\n        }\n        return i;\n    }\n}\n\n```\n# Function Signature: public static int ensureGreaterThanZero(Integer i, String name) {\n# Natural Language Annotations: /**\n     * Ensures that the given expression is true.\n     * @param i The expression to check.\n     * @param name The message to be used in the exception.\n     * @return The value if it is greater than zero.\n     * @throws IllegalArgumentException if the expression is false.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static int ensureGreaterThanZero(Integer i, String name) {\n    if (i == null || i <= 0) {\n        throw illegalArgument(\"%s must be greater than zero\", name);\n    }\n    return i;\n}\n```", "  ```\npublic static int ensureGreaterThanZero(Integer i, String name) {\n    if (i == null || i <= 0) {\n        throw illegalArgument(\"%s must be greater than 0, but is: %d\", name, i);\n    }\n    return i;\n}\n```", "  ```\n\npublic static int ensureGreaterThanZero(Integer i, String name) {\n    if (i == null || i <= 0) {\n        throw illegalArgument(\"%s must be greater than zero, but is: %s\", name, i);\n    }\n    return i;\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/ValidationUtils.java-ensureBetween": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/internal/ValidationUtils.java:\n```\npackage dev.langchain4j.internal;\n\nimport java.util.Collection;\nimport java.util.Map;\nimport java.util.Objects;\n\nimport static dev.langchain4j.internal.Exceptions.illegalArgument;\n\n/**\n * Utility class for validating method arguments.\n */\npublic class ValidationUtils {\n    private ValidationUtils() {}\n\n    /**\n     * Ensure that the two values are equal.\n     * @param lhs the left hand side value.\n     * @param rhs the right hand side value.\n     * @param format the format string for the exception message.\n     * @param args the format arguments for the exception message.\n     */\n    public static void ensureEq(Object lhs, Object rhs, String format, Object... args) {\n        if (!Objects.equals(lhs, rhs)) {\n            throw illegalArgument(format, args);\n        }\n    }\n\n    /**\n     * Ensures that the given object is not null.\n     * @param object The object to check.\n     * @param name The name of the object to be used in the exception message.\n     * @return The object if it is not null.\n     * @param <T> The type of the object.\n     * @throws IllegalArgumentException if the object is null.\n     */\n    public static <T> T ensureNotNull(T object, String name) {\n        return ensureNotNull(object, \"%s cannot be null\", name);\n    }\n\n    /**\n     * Ensures that the given object is not null.\n     * @param object The object to check.\n     * @param format The format of the exception message.\n     * @param args The arguments for the exception message.\n     * @return The object if it is not null.\n     * @param <T> The type of the object.\n     */\n    public static <T> T ensureNotNull(T object, String format, Object... args) {\n        if (object == null) {\n            throw illegalArgument(format, args);\n        }\n        return object;\n    }\n\n    /**\n     * Ensures that the given collection is not null and not empty.\n     * @param collection The collection to check.\n     * @param name The name of the collection to be used in the exception message.\n     * @return The collection if it is not null and not empty.\n     * @param <T> The type of the collection.\n     *           @throws IllegalArgumentException if the collection is null or empty.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given map is not null and not empty.\n     *\n     * @param map  The map to check.\n     * @param name The name of the map to be used in the exception message.\n     * @param <K>  The type of the key.\n     * @param <V>  The type of the value.\n     * @return The map if it is not null and not empty.\n     * @throws IllegalArgumentException if the collection is null or empty.\n     */\n    public static <K, V> Map<K, V> ensureNotEmpty(Map<K, V> map, String name) {\n        if (map == null || map.isEmpty()) {\n            throw illegalArgument(\"%s cannot be null or empty\", name);\n        }\n\n        return map;\n    }\n\n    /**\n     * Ensures that the given string is not null and not blank.\n     * @param string The string to check.\n     * @param name The name of the string to be used in the exception message.\n     * @return The string if it is not null and not blank.\n     * @throws IllegalArgumentException if the string is null or blank.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given expression is true.\n     * @param expression The expression to check.\n     * @param msg The message to be used in the exception.\n     * @throws IllegalArgumentException if the expression is false.\n     */\n    public static void ensureTrue(boolean expression, String msg) {\n        if (!expression) {\n            throw illegalArgument(msg);\n        }\n    }\n\n    /**\n     * Ensures that the given expression is true.\n     * @param i The expression to check.\n     * @param name The message to be used in the exception.\n     * @return The value if it is greater than zero.\n     * @throws IllegalArgumentException if the expression is false.\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given Double value is in {@code [min, max]}.\n     * @param d The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n\n\n\n\n\n\n\n    /**\n     * Ensures that the given Integer value is in {@code [min, max]}.\n     * @param i The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n    public static int ensureBetween(Integer i, int min, int max, String name) {\n        if (i == null || i < min || i > max) {\n            throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, i);\n        }\n        return i;\n    }\n    /**\n     * Ensures that the given Long value is in {@code [min, max]}.\n     * @param i The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\n    public static long ensureBetween(Long i, long min, long max, String name) {\n        if (i == null || i < min || i > max) {\n            throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, i);\n        }\n        return i;\n    }\n}\n\n```\n# Function Signature: public static double ensureBetween(Double d, double min, double max, String name) {\n# Natural Language Annotations: /**\n     * Ensures that the given Double value is in {@code [min, max]}.\n     * @param d The value to check.\n     * @param min The minimum value.\n     * @param max The maximum value.\n     * @param name The value name to be used in the exception.\n     * @return The value if it is in {@code [min, max]}.\n     * @throws IllegalArgumentException if the value is not in {@code [min, max]}.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static double ensureBetween(Double d, double min, double max, String name) {\n    if (d == null || d < min || d > max) {\n        throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, d);\n    }\n    return d;\n}\n```", "  ```\npublic static double ensureBetween(Double d, double min, double max, String name) {\n    if (d == null || d < min || d > max) {\n        throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, d);\n    }\n    return d;\n}\n```", "  ```\npublic static double ensureBetween(Double d, double min, double max, String name) {\n    if (d == null || d < min || d > max) {\n        throw illegalArgument(\"%s must be between %s and %s, but is: %s\", name, min, max, d);\n    }\n    return d;\n}\n```"]}, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/RetryUtils.java-jitterDelayMillis": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/langchain4j/langchain4j-core/src/main/java/dev/langchain4j/internal/RetryUtils.java:\n```\npackage dev.langchain4j.internal;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.Random;\nimport java.util.concurrent.Callable;\n\nimport static java.lang.String.format;\n\n/**\n * Utility class for retrying actions.\n */\npublic final class RetryUtils {\n    private RetryUtils() {}\n\n    private static final Logger log = LoggerFactory.getLogger(RetryUtils.class);\n\n    /**\n     * This method returns a RetryPolicy.Builder.\n     * @return A RetryPolicy.Builder.\n     */\n    public static RetryPolicy.Builder retryPolicyBuilder() {\n        return new RetryPolicy.Builder();\n    }\n\n    /**\n     * This class encapsulates a retry policy.\n     */\n    public static final class RetryPolicy {\n        /**\n         * This class encapsulates a retry policy builder.\n         */\n        public static final class Builder {\n            private int maxAttempts = 3;\n            private int delayMillis = 1000;\n            private double jitterScale = 0.2;\n            private double backoffExp = 1.5;\n\n            /**\n             * Construct a RetryPolicy.Builder.\n             */\n            public Builder() {}\n\n            /**\n             * Sets the default maximum number of attempts.\n             * @param maxAttempts The maximum number of attempts.\n             * @return {@code this}\n             */\n            public Builder maxAttempts(int maxAttempts) {\n                this.maxAttempts = maxAttempts;\n                return this;\n            }\n\n            /**\n             * Sets the base delay in milliseconds.\n             *\n             * <p>The delay is calculated as follows:\n             * <ol>\n             *     <li>Calculate the raw delay in milliseconds as\n             *         {@code delayMillis * Math.pow(backoffExp, attempt - 1)}.</li>\n             *     <li>Calculate the jitter delay in milliseconds as\n             *         {@code rawDelayMs + rand.nextInt((int) (rawDelayMs * jitterScale))}.</li>\n             *     <li>Sleep for the jitter delay in milliseconds.</li>\n             * </ol>\n             *\n             * @param delayMillis The delay in milliseconds.\n             * @return {@code this}\n             */\n            public Builder delayMillis(int delayMillis) {\n                this.delayMillis = delayMillis;\n                return this;\n            }\n\n            /**\n             * Sets the jitter scale.\n             *\n             * <p>The jitter delay in milliseconds is calculated as\n             * {@code rawDelayMs + rand.nextInt((int) (rawDelayMs * jitterScale))}.\n             *\n             * @param jitterScale The jitter scale.\n             * @return {@code this}\n             */\n            public Builder jitterScale(double jitterScale) {\n                this.jitterScale = jitterScale;\n                return this;\n            }\n\n            /**\n             * Sets the backoff exponent.\n             * @param backoffExp The backoff exponent.\n             * @return {@code this}\n             */\n            public Builder backoffExp(double backoffExp) {\n                this.backoffExp = backoffExp;\n                return this;\n            }\n\n            /**\n             * Builds a RetryPolicy.\n             * @return A RetryPolicy.\n             */\n            public RetryPolicy build() {\n                return new RetryPolicy(maxAttempts, delayMillis, jitterScale, backoffExp);\n            }\n        }\n\n        private final int maxAttempts;\n        private final int delayMillis;\n        private final double jitterScale;\n        private final double backoffExp;\n\n        /**\n         * Construct a RetryPolicy.\n         * @param maxAttempts The maximum number of attempts.\n         * @param delayMillis The delay in milliseconds.\n         * @param jitterScale The jitter scale.\n         * @param backoffExp The backoff exponent.\n         */\n        public RetryPolicy(\n                int maxAttempts,\n                int delayMillis,\n                double jitterScale,\n                double backoffExp) {\n            this.maxAttempts = maxAttempts;\n            this.delayMillis = delayMillis;\n            this.jitterScale = jitterScale;\n            this.backoffExp = backoffExp;\n        }\n\n        /**\n         * This method returns the raw delay in milliseconds for a given attempt.\n         * @param attempt The attempt number.\n         * @return The raw delay in milliseconds.\n         */\n        public double rawDelayMs(int attempt) {\n            return ((double) delayMillis) * Math.pow(backoffExp, attempt - 1);\n        }\n\n        /**\n         * This method returns the jitter delay in milliseconds for a given attempt.\n         * @param attempt The attempt number.\n         * @return The jitter delay in milliseconds.\n         */\n\n\n\n\n\n\n\n        /**\n         * This method sleeps for a given attempt.\n         * @param attempt The attempt number.\n         */\n        @JacocoIgnoreCoverageGenerated\n        public void sleep(int attempt) {\n            try {\n                Thread.sleep(jitterDelayMillis(attempt));\n            } catch (InterruptedException ignored) {\n                // pass\n            }\n        }\n\n        /**\n         * This method attempts to execute a given action up to a specified number of times with a 1-second delay.\n         * If the action fails on all attempts, it throws a RuntimeException.\n         *\n         * @param action      The action to be executed.\n         * @param <T> The type of the result of the action.\n         * @return The result of the action if it is successful.\n         * @throws RuntimeException if the action fails on all attempts.\n         */\n        public <T> T withRetry(Callable<T> action) {\n            return withRetry(action, maxAttempts);\n        }\n\n        /**\n         * This method attempts to execute a given action up to a specified number of times with a 1-second delay.\n         * If the action fails on all attempts, it throws a RuntimeException.\n         *\n         * @param action      The action to be executed.\n         * @param maxAttempts The maximum number of attempts to execute the action.\n         * @param <T> The type of the result of the action.\n         * @return The result of the action if it is successful.\n         * @throws RuntimeException if the action fails on all attempts.\n         */\n        public <T> T withRetry(Callable<T> action, int maxAttempts) {\n            int attempt = 1;\n            while (true) {\n                try {\n                    return action.call();\n                } catch (Exception e) {\n                    if (attempt >= maxAttempts) {\n                        throw new RuntimeException(e);\n                    }\n\n                    log.warn(format(\"Exception was thrown on attempt %s of %s\", attempt, maxAttempts), e);\n\n                    sleep(attempt);\n                }\n                attempt++;\n            }\n        }\n    }\n\n    /**\n     * Default retry policy used by {@link #withRetry(Callable)}.\n     */\n    public static final RetryPolicy DEFAULT_RETRY_POLICY = retryPolicyBuilder()\n            .maxAttempts(3)\n            .delayMillis(500)\n            .jitterScale(0.2)\n            .backoffExp(1.5)\n            .build();\n\n    /**\n     * This method attempts to execute a given action up to a specified number of times with a 1-second delay.\n     * If the action fails on all attempts, it throws a RuntimeException.\n     *\n     * @param action      The action to be executed.\n     * @param maxAttempts The maximum number of attempts to execute the action.\n     * @param <T> The type of the result of the action.\n     *\n     * @return The result of the action if it is successful.\n     * @throws RuntimeException if the action fails on all attempts.\n     */\n    public static <T> T withRetry(Callable<T> action, int maxAttempts) {\n        return DEFAULT_RETRY_POLICY.withRetry(action, maxAttempts);\n    }\n\n    /**\n     * This method attempts to execute a given action up to a specified number of times with a 1-second delay.\n     * If the action fails on all attempts, it throws a RuntimeException.\n     *\n     * @param action      The action to be executed.\n     * @param <T> The type of the result of the action.\n     * @return The result of the action if it is successful.\n     * @throws RuntimeException if the action fails on all attempts.\n     */\n    public static <T> T withRetry(Callable<T> action) {\n        return DEFAULT_RETRY_POLICY.withRetry(action);\n    }\n}\n\n```\n# Function Signature: public int jitterDelayMillis(int attempt) {\n# Natural Language Annotations: /**\n         * This method returns the jitter delay in milliseconds for a given attempt.\n         * @param attempt The attempt number.\n         * @return The jitter delay in milliseconds.\n         */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic int jitterDelayMillis(int attempt) {\n    int rawDelay = (int) (rawDelayMs(attempt) + rand.nextInt((int) (rawDelayMs(attempt) * jitterScale)));\n    return rawDelay;\n}\n```", "  ```\npublic int jitterDelayMillis(int attempt) {\n    return (int) (rawDelayMs(attempt) + (jitterScale * (1.0 - Math.random())));\n}\n```", "  ```\npublic int jitterDelayMillis(int attempt) {\n    Random rand = new Random();\n    int rawDelayMs = (int) (delayMillis * Math.pow(backoffExp, attempt - 1));\n    int jitterMs = rand.nextInt((int) (rawDelayMs * jitterScale));\n    int delayMs = rawDelayMs + jitterMs;\n    return delayMs;\n}\n```"]}, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/keygen/KeyGeneratorFactory.java-getKeyGenerator": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/mybatis-flex/mybatis-flex-core/src/main/java/com/mybatisflex/core/keygen/KeyGeneratorFactory.java:\n```\n/*\n *  Copyright (c) 2022-2023, Mybatis-Flex (fuhai999@gmail.com).\n *  <p>\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *  <p>\n *  http://www.apache.org/licenses/LICENSE-2.0\n *  <p>\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n */\npackage com.mybatisflex.core.keygen;\n\nimport com.mybatisflex.core.exception.FlexExceptions;\nimport com.mybatisflex.core.exception.locale.LocalizedFormats;\nimport com.mybatisflex.core.keygen.impl.FlexIDKeyGenerator;\nimport com.mybatisflex.core.keygen.impl.SnowFlakeIDKeyGenerator;\nimport com.mybatisflex.core.keygen.impl.UUIDKeyGenerator;\nimport com.mybatisflex.core.util.StringUtil;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\npublic class KeyGeneratorFactory {\n\n    private KeyGeneratorFactory() {\n    }\n\n    private static final Map<String, IKeyGenerator> KEY_GENERATOR_MAP = new HashMap<>();\n\n    static {\n        /** \u5185\u7f6e\u4e86 uuid \u7684\u751f\u6210\u5668\uff0c\u56e0\u6b64\u4e3b\u952e\u914d\u7f6e\u7684\u65f6\u5019\u53ef\u4ee5\u76f4\u63a5\u914d\u7f6e\u4e3a @Id(keyType = KeyType.Generator, value = \"uuid\")\n         * {@link com.mybatisflex.annotation.Id}\n         */\n        register(KeyGenerators.uuid, new UUIDKeyGenerator());\n        register(KeyGenerators.flexId, new FlexIDKeyGenerator());\n        register(KeyGenerators.snowFlakeId, new SnowFlakeIDKeyGenerator());\n    }\n\n\n    /**\n     * \u83b7\u53d6 \u4e3b\u952e\u751f\u6210\u5668\n     *\n     * @param name\n     * @return \u4e3b\u952e\u751f\u6210\u5668\n     */\n\n\n\n\n\n\n\n\n    /**\n     * \u6ce8\u518c\u4e00\u4e2a\u4e3b\u952e\u751f\u6210\u5668\n     *\n     * @param key\n     * @param keyGenerator\n     */\n    public static void register(String key, IKeyGenerator keyGenerator) {\n        KEY_GENERATOR_MAP.put(key.trim(), keyGenerator);\n    }\n\n}\n\n```\n# Function Signature: public static IKeyGenerator getKeyGenerator(String name) {\n# Natural Language Annotations: /**\n     * \u83b7\u53d6 \u4e3b\u952e\u751f\u6210\u5668\n     *\n     * @param name\n     * @return \u4e3b\u952e\u751f\u6210\u5668\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static IKeyGenerator getKeyGenerator(String name) {\n    IKeyGenerator keyGenerator = KEY_GENERATOR_MAP.get(name);\n    if (keyGenerator == null) {\n        throw new FlexExceptions(LocalizedFormats.UNKNOWN_KEY_GENERATOR, name);\n    }\n    return keyGenerator;\n}\n```", "  ```\npublic static IKeyGenerator getKeyGenerator(String name) {\n    return KEY_GENERATOR_MAP.get(StringUtil.trim(name));\n}\n```", "  ```\npublic static IKeyGenerator getKeyGenerator(String name) {\n    if (StringUtils.isBlank(name)) {\n        throw new IllegalArgumentException(\"the name of key generator is blank \");\n    }\n    if (KEY_GENERATOR_MAP.containsKey(name)) {\n        return KEY_GENERATOR_MAP.get(name);\n    } else {\n        throw new IllegalArgumentException(\"The key generator does not support :\" + name);\n    }\n}\n```"]}, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/query/QueryCondition.java-when": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/mybatis-flex/mybatis-flex-core/src/main/java/com/mybatisflex/core/query/QueryCondition.java:\n```\n/*\n *  Copyright (c) 2022-2023, Mybatis-Flex (fuhai999@gmail.com).\n *  <p>\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *  <p>\n *  http://www.apache.org/licenses/LICENSE-2.0\n *  <p>\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n */\npackage com.mybatisflex.core.query;\n\n\nimport com.mybatisflex.core.constant.SqlConnector;\nimport com.mybatisflex.core.constant.SqlConsts;\nimport com.mybatisflex.core.constant.SqlOperator;\nimport com.mybatisflex.core.dialect.IDialect;\nimport com.mybatisflex.core.exception.FlexExceptions;\nimport com.mybatisflex.core.util.ClassUtil;\nimport com.mybatisflex.core.util.ObjectUtil;\nimport com.mybatisflex.core.util.StringUtil;\n\nimport java.lang.reflect.Array;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.function.BooleanSupplier;\n\npublic class QueryCondition implements CloneSupport<QueryCondition> {\n\n\n    protected QueryColumn column;\n    protected String logic;\n    protected Object value;\n    protected boolean effective = true;\n\n    //\u5f53\u524d\u6761\u4ef6\u7684\u4e0a\u4e00\u4e2a\u6761\u4ef6\n    protected QueryCondition prev;\n\n    //\u5f53\u524d\u6761\u4ef6\u7684\u4e0b\u4e00\u4e2a\u6761\u4ef6\n    protected QueryCondition next;\n\n    //\u4e24\u4e2a\u6761\u4ef6\u76f4\u63a5\u7684\u8fde\u63a5\u7b26\n    protected SqlConnector connector;\n\n    /**\n     * \u662f\u5426\u4e3a\u7a7a\u6761\u4ef6\uff0c\u9ed8\u8ba4false\n     */\n    private boolean empty = false;\n\n    protected boolean notEmpty() {\n        return !empty;\n    }\n\n    protected QueryCondition setEmpty(boolean empty) {\n        this.empty = empty;\n        return this;\n    }\n\n    public static QueryCondition createEmpty() {\n        return new QueryCondition().when(false).setEmpty(true);\n    }\n\n\n    public static QueryCondition create(String schema, String table, String column, String logic, Object value) {\n        return create(new QueryColumn(schema, table, column), logic, value);\n    }\n\n    public static QueryCondition create(QueryColumn queryColumn, Object value) {\n        return create(queryColumn, SqlConsts.EQUALS, value);\n    }\n\n    public static QueryCondition create(QueryColumn queryColumn, SqlOperator logic, Collection<?> values) {\n        return create(queryColumn, logic, values == null ? null : values.toArray());\n    }\n\n    public static QueryCondition create(QueryColumn queryColumn, SqlOperator logic, Object value) {\n        return create(queryColumn, logic.getValue(), value);\n    }\n\n    public static QueryCondition create(QueryColumn queryColumn, String logic, Collection<?> values) {\n        return create(queryColumn, logic, values == null ? null : values.toArray());\n    }\n\n    public static QueryCondition create(QueryColumn queryColumn, String logic, Object value) {\n        QueryCondition condition = new QueryCondition();\n        condition.setColumn(queryColumn);\n        condition.setLogic(logic);\n        condition.setValue(value);\n        return condition;\n    }\n\n    public QueryColumn getColumn() {\n        return column;\n    }\n\n    public void setColumn(QueryColumn column) {\n        this.column = column;\n    }\n\n    public Object getValue() {\n        return checkEffective() ? value : null;\n    }\n\n    public void setValue(Object value) {\n        this.value = value;\n    }\n\n    public String getLogic() {\n        return logic;\n    }\n\n    public void setLogic(String logic) {\n        this.logic = logic;\n    }\n\n    /**\n     * \u52a8\u6001\u6761\u4ef6\u6784\u9020\u3002\n     *\n     * @param effective \u662f\u5426\u542f\u7528\u8be5\u6761\u4ef6\n     * @return {@link QueryCondition}\n     */\n\n\n\n\n\n\n\n    /**\n     * \u52a8\u6001\u6761\u4ef6\u6784\u9020\u3002\n     *\n     * @param fn \u662f\u5426\u542f\u7528\u8be5\u6761\u4ef6\n     * @return {@link QueryCondition}\n     */\n    public QueryCondition when(BooleanSupplier fn) {\n        if (notEmpty()) {\n            this.effective = fn.getAsBoolean();\n        }\n        return this;\n    }\n\n    public boolean checkEffective() {\n        return effective;\n    }\n\n\n    public QueryCondition and(String sql) {\n        return and(new RawQueryCondition(sql));\n    }\n\n    public QueryCondition and(String sql, Object... params) {\n        return and(new RawQueryCondition(sql, params));\n    }\n\n    public QueryCondition and(QueryCondition nextCondition) {\n        return new Brackets(this).and(nextCondition);\n    }\n\n    public QueryCondition or(String sql) {\n        return or(new RawQueryCondition(sql));\n    }\n\n    public QueryCondition or(String sql, Object... params) {\n        return or(new RawQueryCondition(sql, params));\n    }\n\n    public QueryCondition or(QueryCondition nextCondition) {\n        return new Brackets(this).or(nextCondition);\n    }\n\n    protected void connect(QueryCondition nextCondition, SqlConnector connector) {\n\n        if (this.next != null) {\n            this.next.connect(nextCondition, connector);\n        } else {\n            nextCondition.connector = connector;\n            this.next = nextCondition;\n            nextCondition.prev = this;\n        }\n    }\n\n    public String toSql(List<QueryTable> queryTables, IDialect dialect) {\n        StringBuilder sql = new StringBuilder();\n        //\u68c0\u6d4b\u662f\u5426\u751f\u6548\n        if (checkEffective()) {\n            QueryCondition prevEffectiveCondition = getPrevEffectiveCondition();\n            if (prevEffectiveCondition != null && this.connector != null) {\n                sql.append(this.connector);\n            }\n            //\u5217\n            sql.append(getColumn().toConditionSql(queryTables, dialect));\n\n            //\u903b\u8f91\u7b26\u53f7\n            sql.append(logic);\n\n            //\u503c\uff08\u6216\u8005\u95ee\u53f7\uff09\n            if (value instanceof QueryColumn) {\n                sql.append(((QueryColumn) value).toConditionSql(queryTables, dialect));\n            }\n            //\u5b50\u67e5\u8be2\n            else if (value instanceof QueryWrapper) {\n                sql.append(SqlConsts.BRACKET_LEFT)\n                    .append(dialect.buildSelectSql((QueryWrapper) value))\n                    .append(SqlConsts.BRACKET_RIGHT);\n            }\n            //\u539f\u751fsql\n            else if (value instanceof RawQueryCondition) {\n                sql.append(((RawQueryCondition) value).getContent());\n            }\n            //\u6b63\u5e38\u67e5\u8be2\uff0c\u6784\u5efa\u95ee\u53f7\n            else {\n                appendQuestionMark(sql);\n            }\n        }\n\n        if (this.next != null) {\n            return sql + next.toSql(queryTables, dialect);\n        }\n\n        return sql.toString();\n    }\n\n\n    /**\n     * \u83b7\u53d6\u4e0a\u4e00\u4e2a \u201c\u6709\u6548\u201d \u7684\u6761\u4ef6\n     *\n     * @return QueryCondition\n     */\n    protected QueryCondition getPrevEffectiveCondition() {\n        if (prev == null) {\n            return null;\n        }\n        return prev.checkEffective() ? prev : prev.getPrevEffectiveCondition();\n    }\n\n    protected QueryCondition getNextEffectiveCondition() {\n        if (next == null) {\n            return null;\n        }\n        return next.checkEffective() ? next : next.getNextEffectiveCondition();\n    }\n\n\n    protected void appendQuestionMark(StringBuilder sqlBuilder) {\n        //noinspection StatementWithEmptyBody\n        if (SqlConsts.IS_NULL.equals(logic)\n            || SqlConsts.IS_NOT_NULL.equals(logic)\n            || value instanceof QueryColumn\n            || value instanceof QueryWrapper\n            || value instanceof RawQueryCondition) {\n            //do nothing\n        }\n\n        //between, not between\n        else if (SqlConsts.BETWEEN.equals(logic) || SqlConsts.NOT_BETWEEN.equals(logic)) {\n            sqlBuilder.append(SqlConsts.AND_PLACEHOLDER);\n        }\n        //in, not in\n        else if (SqlConsts.IN.equals(logic) || SqlConsts.NOT_IN.equals(logic)) {\n            int paramsCount = calculateValueArrayCount();\n            sqlBuilder.append(SqlConsts.BRACKET_LEFT);\n            for (int i = 0; i < paramsCount; i++) {\n                sqlBuilder.append(SqlConsts.PLACEHOLDER);\n                if (i != paramsCount - 1) {\n                    sqlBuilder.append(SqlConsts.DELIMITER);\n                }\n            }\n            sqlBuilder.append(SqlConsts.BRACKET_RIGHT);\n        } else {\n            sqlBuilder.append(SqlConsts.PLACEHOLDER);\n        }\n    }\n\n\n    private int calculateValueArrayCount() {\n        Object[] values = (Object[]) value;\n        int paramsCount = 0;\n        for (Object object : values) {\n            if (object != null && ClassUtil.isArray(object.getClass())) {\n                paramsCount += Array.getLength(object);\n            } else {\n                paramsCount++;\n            }\n        }\n        return paramsCount;\n    }\n\n\n    boolean containsTable(String... tables) {\n        if (column == null || !checkEffective()) {\n            return nextContainsTable(tables);\n        }\n        if (column instanceof FunctionQueryColumn) {\n            /*\n             * \u8fde\u8868\u5206\u9875\u67e5\u8be2\u7684where\u4e2d\u4f7f\u7528QueryMethods\u5bfc\u81f4count\u67e5\u8be2\u4f18\u5316\u9519\u8bef\n             * fix https://github.com/mybatis-flex/mybatis-flex/issues/307\n             */\n            List<QueryColumn> columns = ((FunctionQueryColumn)column).getColumns();\n            for (QueryColumn queryColumn : columns) {\n                if (containsTable(queryColumn, tables)) {\n                    return true;\n                }\n            }\n        }\n        return containsTable(column, tables) || nextContainsTable(tables);\n    }\n\n    boolean containsTable(QueryColumn column, String... tables) {\n        for (String table : tables) {\n            String tableName = StringUtil.getTableNameWithAlias(table)[0];\n            if (column.table != null && tableName.equals(column.table.name)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    boolean nextContainsTable(String... tables) {\n        if (next == null) {\n            return false;\n        }\n        return next.containsTable(tables);\n    }\n\n    @Override\n    public String toString() {\n        return \"QueryCondition{\" +\n            \"column=\" + column +\n            \", logic='\" + logic + '\\'' +\n            \", value=\" + value +\n            \", effective=\" + effective +\n            '}';\n    }\n\n    @Override\n    public QueryCondition clone() {\n        try {\n            QueryCondition clone = (QueryCondition) super.clone();\n            // deep clone ...\n            clone.column = ObjectUtil.clone(this.column);\n            clone.value = ObjectUtil.cloneObject(this.value);\n            clone.prev = clone.next = null;\n            if (this.next != null) {\n                clone.next = this.next.clone();\n                clone.next.prev = clone;\n            }\n            return clone;\n        } catch (CloneNotSupportedException e) {\n            throw FlexExceptions.wrap(e);\n        }\n    }\n\n}\n\n```\n# Function Signature: public QueryCondition when(boolean effective) {\n# Natural Language Annotations: /**\n     * \u52a8\u6001\u6761\u4ef6\u6784\u9020\u3002\n     *\n     * @param effective \u662f\u5426\u542f\u7528\u8be5\u6761\u4ef6\n     * @return {@link QueryCondition}\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic QueryCondition when(boolean effective) {\n        if (notEmpty()) {\n            this.effective = effective;\n        }\n        return this;\n    }\n```", "  ```\npublic QueryCondition when(boolean effective) {\n        if (notEmpty()) {\n            this.effective = effective;\n        }\n        return this;\n    }\n```", "  ```\npublic QueryCondition when(boolean effective) {\n        this.effective = effective;\n        return this;\n    }\n```"]}, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java-methodToProperty": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/mybatis-flex/mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java:\n```\n/*\n *  Copyright (c) 2022-2023, Mybatis-Flex (fuhai999@gmail.com).\n *  <p>\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *  <p>\n *  http://www.apache.org/licenses/LICENSE-2.0\n *  <p>\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n */\npackage com.mybatisflex.core.util;\n\n\nimport com.mybatisflex.core.exception.FlexExceptions;\n\nimport java.util.Collection;\nimport java.util.Locale;\nimport java.util.function.Function;\nimport java.util.regex.Pattern;\n\npublic class StringUtil {\n\n    private StringUtil() {\n    }\n\n    /**\n     * @see org.apache.ibatis.reflection.property.PropertyNamer#methodToProperty(String)\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * \u7b2c\u4e00\u4e2a\u5b57\u7b26\u8f6c\u6362\u4e3a\u5c0f\u5199\n     *\n     * @param string\n     */\n    public static String firstCharToLowerCase(String string) {\n        char firstChar = string.charAt(0);\n        if (firstChar >= 'A' && firstChar <= 'Z') {\n            char[] chars = string.toCharArray();\n            chars[0] += ('a' - 'A');\n            return new String(chars);\n        }\n        return string;\n    }\n\n\n    /**\n     * \u7b2c\u4e00\u4e2a\u5b57\u7b26\u8f6c\u6362\u4e3a\u5927\u5199\n     *\n     * @param string\n     */\n    public static String firstCharToUpperCase(String string) {\n        char firstChar = string.charAt(0);\n        if (firstChar >= 'a' && firstChar <= 'z') {\n            char[] chars = string.toCharArray();\n            chars[0] -= ('a' - 'A');\n            return new String(chars);\n        }\n        return string;\n    }\n\n\n    /**\n     * \u9a7c\u5cf0\u8f6c\u4e0b\u5212\u7ebf\u683c\u5f0f\n     *\n     * @param string\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * \u4e0b\u5212\u7ebf\u8f6c\u9a7c\u5cf0\u683c\u5f0f\n     *\n     * @param string\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * \u5220\u9664\u5b57\u7b26\u4e32\u4e2d\u7684\u5b57\u7b26\n     */\n    public static String deleteChar(String string, char deleteChar) {\n        if (isBlank(string)) {\n            return \"\";\n        }\n        char[] chars = string.toCharArray();\n        StringBuilder sb = new StringBuilder(string.length());\n        for (char aChar : chars) {\n            if (aChar != deleteChar) {\n                sb.append(aChar);\n            }\n        }\n        return sb.toString();\n    }\n\n    public static String deleteChar(String string, char deleteChar1, char deleteChar2) {\n        if (isBlank(string)) {\n            return \"\";\n        }\n        char[] chars = string.toCharArray();\n        StringBuilder sb = new StringBuilder(string.length());\n        for (char aChar : chars) {\n            if (aChar != deleteChar1 && aChar != deleteChar2) {\n                sb.append(aChar);\n            }\n        }\n        return sb.toString();\n    }\n\n    /**\n     * \u5b57\u7b26\u4e32\u4e3a null \u6216\u8005\u5185\u90e8\u5b57\u7b26\u5168\u90e8\u4e3a ' ', '\\t', '\\n', '\\r' \u8fd9\u56db\u7c7b\u5b57\u7b26\u65f6\u8fd4\u56de true\n     */\n    public static boolean isBlank(String string) {\n        if (string == null) {\n            return true;\n        }\n\n        for (int i = 0, len = string.length(); i < len; i++) {\n            if (string.charAt(i) > ' ') {\n                return false;\n            }\n        }\n        return true;\n    }\n\n\n    public static boolean isAnyBlank(String... strings) {\n        if (strings == null || strings.length == 0) {\n            throw new IllegalArgumentException(\"strings is null or empty.\");\n        }\n\n        for (String string : strings) {\n            if (isBlank(string)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n\n    public static boolean isNotBlank(String str) {\n        return !isBlank(str);\n    }\n\n\n    public static boolean areNotBlank(String... strings) {\n        return !isAnyBlank(strings);\n    }\n\n\n    /**\n     * \u8fd9\u4e2a\u5b57\u7b26\u4e32\u662f\u5426\u662f\u5168\u662f\u6570\u5b57\n     *\n     * @param string\n     * @return \u5168\u90e8\u6570\u6570\u503c\u65f6\u8fd4\u56de true\uff0c\u5426\u5219\u8fd4\u56de false\n     */\n    public static boolean isNumeric(String string) {\n        if (isBlank(string)) {\n            return false;\n        }\n        for (int i = string.length(); --i >= 0; ) {\n            int chr = string.charAt(i);\n            if (chr < 48 || chr > 57) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n\n    public static boolean startsWithAny(String string, String... prefixes) {\n        if (isBlank(string) || prefixes == null) {\n            return false;\n        }\n\n        for (String prefix : prefixes) {\n            if (string.startsWith(prefix)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n\n    public static boolean endsWithAny(String str, String... suffixes) {\n        if (isBlank(str) || suffixes == null) {\n            return false;\n        }\n\n        for (String suffix : suffixes) {\n            if (str.endsWith(suffix)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n\n    /**\n     * \u6b63\u5219\u5339\u914d\n     *\n     * @param regex\n     * @param input\n     * @return\n     */\n    public static boolean matches(String regex, String input) {\n        if (null == regex || null == input) {\n            return false;\n        }\n        return Pattern.matches(regex, input);\n    }\n\n    /**\n     * \u5408\u5e76\u5b57\u7b26\u4e32\uff0c\u4f18\u5316 String.join() \u65b9\u6cd5\n     *\n     * @param delimiter\n     * @param elements\n     * @return \u65b0\u62fc\u63a5\u597d\u7684\u5b57\u7b26\u4e32\n     * @see String#join(CharSequence, CharSequence...)\n     */\n    public static String join(String delimiter, CharSequence... elements) {\n        if (ArrayUtil.isEmpty(elements)) {\n            return \"\";\n        } else if (elements.length == 1) {\n            return String.valueOf(elements[0]);\n        } else {\n            return String.join(delimiter, elements);\n        }\n    }\n\n    /**\n     * \u5408\u5e76\u5b57\u7b26\u4e32\uff0c\u4f18\u5316 String.join() \u65b9\u6cd5\n     *\n     * @param delimiter\n     * @param elements\n     * @return \u65b0\u62fc\u63a5\u597d\u7684\u5b57\u7b26\u4e32\n     * @see String#join(CharSequence, CharSequence...)\n     */\n    public static String join(String delimiter, Collection<? extends CharSequence> elements) {\n        if (CollectionUtil.isEmpty(elements)) {\n            return \"\";\n        } else if (elements.size() == 1) {\n            return String.valueOf(elements.iterator().next());\n        } else {\n            return String.join(delimiter, elements);\n        }\n    }\n\n\n    /**\n     * \u5408\u5e76\u5b57\u7b26\u4e32\uff0c\u4f18\u5316 String.join() \u65b9\u6cd5\n     *\n     * @param delimiter\n     * @param objs\n     * @param function\n     * @param <T>\n     */\n    public static <T> String join(String delimiter, Collection<T> objs, Function<T, String> function) {\n        if (CollectionUtil.isEmpty(objs)) {\n            return \"\";\n        } else if (objs.size() == 1) {\n            T next = objs.iterator().next();\n            return String.valueOf(function.apply(next));\n        } else {\n            String[] strings = new String[objs.size()];\n            int index = 0;\n            for (T obj : objs) {\n                strings[index++] = function.apply(obj);\n            }\n            return String.join(delimiter, strings);\n        }\n    }\n\n    public static String buildSchemaWithTable(String schema, String tableName) {\n        return isNotBlank(schema) ? schema + \".\" + tableName : tableName;\n    }\n\n    public static String[] getSchemaAndTableName(String tableNameWithSchema) {\n        int index = tableNameWithSchema.indexOf(\".\");\n        return index <= 0 ? new String[]{null, tableNameWithSchema.trim()}\n            : new String[]{tableNameWithSchema.substring(0, index).trim(), tableNameWithSchema.substring(index + 1).trim()};\n    }\n\n    public static String[] getTableNameWithAlias(String tableNameWithAlias) {\n        int index = tableNameWithAlias.indexOf(\".\");\n        return index <= 0 ? new String[]{tableNameWithAlias, null}\n            : new String[]{tableNameWithAlias.substring(0, index), tableNameWithAlias.substring(index + 1)};\n    }\n\n    public static String tryTrim(String string) {\n        return string != null ? string.trim() : null;\n    }\n\n    public static String substringAfterLast(String text, String prefix) {\n        if (text == null) {\n            return null;\n        }\n        if (prefix == null) {\n            return text;\n        }\n        return text.substring(text.lastIndexOf(prefix) + 1);\n    }\n\n\n}\n\n```\n# Function Signature: public static String methodToProperty(String name) {\n# Natural Language Annotations: /**\n     * @see org.apache.ibatis.reflection.property.PropertyNamer#methodToProperty(String)\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static String methodToProperty(String name) {\n    if (isBlank(name)) {\n        return \"\";\n    }\n    return firstCharToLowerCase(name.substring(3));\n}\n```", "  ```\npublic static String methodToProperty(String name) {\n    if (name.startsWith(\"is\") && name.length() > 2) {\n        return name.substring(2);\n    } else if (name.startsWith(\"get\") && name.length() > 3) {\n        return name.substring(3);\n    } else if (name.startsWith(\"set\") && name.length() > 3) {\n        return name.substring(3);\n    }\n    return null;\n}\n```", "  ```\npublic static String methodToProperty(String name) {\n    if (isBlank(name)) {\n        throw new IllegalArgumentException(\"Expected a non-blank name, but received \" + name);\n    }\n    if (isCamelCase(name)) {\n        return name;\n    }\n    return NameConvertor.INSTANCE.convert(name, true);\n}\n```"]}, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java-camelToUnderline": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/mybatis-flex/mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java:\n```\n/*\n *  Copyright (c) 2022-2023, Mybatis-Flex (fuhai999@gmail.com).\n *  <p>\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *  <p>\n *  http://www.apache.org/licenses/LICENSE-2.0\n *  <p>\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n */\npackage com.mybatisflex.core.util;\n\n\nimport com.mybatisflex.core.exception.FlexExceptions;\n\nimport java.util.Collection;\nimport java.util.Locale;\nimport java.util.function.Function;\nimport java.util.regex.Pattern;\n\npublic class StringUtil {\n\n    private StringUtil() {\n    }\n\n    /**\n     * @see org.apache.ibatis.reflection.property.PropertyNamer#methodToProperty(String)\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * \u7b2c\u4e00\u4e2a\u5b57\u7b26\u8f6c\u6362\u4e3a\u5c0f\u5199\n     *\n     * @param string\n     */\n    public static String firstCharToLowerCase(String string) {\n        char firstChar = string.charAt(0);\n        if (firstChar >= 'A' && firstChar <= 'Z') {\n            char[] chars = string.toCharArray();\n            chars[0] += ('a' - 'A');\n            return new String(chars);\n        }\n        return string;\n    }\n\n\n    /**\n     * \u7b2c\u4e00\u4e2a\u5b57\u7b26\u8f6c\u6362\u4e3a\u5927\u5199\n     *\n     * @param string\n     */\n    public static String firstCharToUpperCase(String string) {\n        char firstChar = string.charAt(0);\n        if (firstChar >= 'a' && firstChar <= 'z') {\n            char[] chars = string.toCharArray();\n            chars[0] -= ('a' - 'A');\n            return new String(chars);\n        }\n        return string;\n    }\n\n\n    /**\n     * \u9a7c\u5cf0\u8f6c\u4e0b\u5212\u7ebf\u683c\u5f0f\n     *\n     * @param string\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * \u4e0b\u5212\u7ebf\u8f6c\u9a7c\u5cf0\u683c\u5f0f\n     *\n     * @param string\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * \u5220\u9664\u5b57\u7b26\u4e32\u4e2d\u7684\u5b57\u7b26\n     */\n    public static String deleteChar(String string, char deleteChar) {\n        if (isBlank(string)) {\n            return \"\";\n        }\n        char[] chars = string.toCharArray();\n        StringBuilder sb = new StringBuilder(string.length());\n        for (char aChar : chars) {\n            if (aChar != deleteChar) {\n                sb.append(aChar);\n            }\n        }\n        return sb.toString();\n    }\n\n    public static String deleteChar(String string, char deleteChar1, char deleteChar2) {\n        if (isBlank(string)) {\n            return \"\";\n        }\n        char[] chars = string.toCharArray();\n        StringBuilder sb = new StringBuilder(string.length());\n        for (char aChar : chars) {\n            if (aChar != deleteChar1 && aChar != deleteChar2) {\n                sb.append(aChar);\n            }\n        }\n        return sb.toString();\n    }\n\n    /**\n     * \u5b57\u7b26\u4e32\u4e3a null \u6216\u8005\u5185\u90e8\u5b57\u7b26\u5168\u90e8\u4e3a ' ', '\\t', '\\n', '\\r' \u8fd9\u56db\u7c7b\u5b57\u7b26\u65f6\u8fd4\u56de true\n     */\n    public static boolean isBlank(String string) {\n        if (string == null) {\n            return true;\n        }\n\n        for (int i = 0, len = string.length(); i < len; i++) {\n            if (string.charAt(i) > ' ') {\n                return false;\n            }\n        }\n        return true;\n    }\n\n\n    public static boolean isAnyBlank(String... strings) {\n        if (strings == null || strings.length == 0) {\n            throw new IllegalArgumentException(\"strings is null or empty.\");\n        }\n\n        for (String string : strings) {\n            if (isBlank(string)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n\n    public static boolean isNotBlank(String str) {\n        return !isBlank(str);\n    }\n\n\n    public static boolean areNotBlank(String... strings) {\n        return !isAnyBlank(strings);\n    }\n\n\n    /**\n     * \u8fd9\u4e2a\u5b57\u7b26\u4e32\u662f\u5426\u662f\u5168\u662f\u6570\u5b57\n     *\n     * @param string\n     * @return \u5168\u90e8\u6570\u6570\u503c\u65f6\u8fd4\u56de true\uff0c\u5426\u5219\u8fd4\u56de false\n     */\n    public static boolean isNumeric(String string) {\n        if (isBlank(string)) {\n            return false;\n        }\n        for (int i = string.length(); --i >= 0; ) {\n            int chr = string.charAt(i);\n            if (chr < 48 || chr > 57) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n\n    public static boolean startsWithAny(String string, String... prefixes) {\n        if (isBlank(string) || prefixes == null) {\n            return false;\n        }\n\n        for (String prefix : prefixes) {\n            if (string.startsWith(prefix)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n\n    public static boolean endsWithAny(String str, String... suffixes) {\n        if (isBlank(str) || suffixes == null) {\n            return false;\n        }\n\n        for (String suffix : suffixes) {\n            if (str.endsWith(suffix)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n\n    /**\n     * \u6b63\u5219\u5339\u914d\n     *\n     * @param regex\n     * @param input\n     * @return\n     */\n    public static boolean matches(String regex, String input) {\n        if (null == regex || null == input) {\n            return false;\n        }\n        return Pattern.matches(regex, input);\n    }\n\n    /**\n     * \u5408\u5e76\u5b57\u7b26\u4e32\uff0c\u4f18\u5316 String.join() \u65b9\u6cd5\n     *\n     * @param delimiter\n     * @param elements\n     * @return \u65b0\u62fc\u63a5\u597d\u7684\u5b57\u7b26\u4e32\n     * @see String#join(CharSequence, CharSequence...)\n     */\n    public static String join(String delimiter, CharSequence... elements) {\n        if (ArrayUtil.isEmpty(elements)) {\n            return \"\";\n        } else if (elements.length == 1) {\n            return String.valueOf(elements[0]);\n        } else {\n            return String.join(delimiter, elements);\n        }\n    }\n\n    /**\n     * \u5408\u5e76\u5b57\u7b26\u4e32\uff0c\u4f18\u5316 String.join() \u65b9\u6cd5\n     *\n     * @param delimiter\n     * @param elements\n     * @return \u65b0\u62fc\u63a5\u597d\u7684\u5b57\u7b26\u4e32\n     * @see String#join(CharSequence, CharSequence...)\n     */\n    public static String join(String delimiter, Collection<? extends CharSequence> elements) {\n        if (CollectionUtil.isEmpty(elements)) {\n            return \"\";\n        } else if (elements.size() == 1) {\n            return String.valueOf(elements.iterator().next());\n        } else {\n            return String.join(delimiter, elements);\n        }\n    }\n\n\n    /**\n     * \u5408\u5e76\u5b57\u7b26\u4e32\uff0c\u4f18\u5316 String.join() \u65b9\u6cd5\n     *\n     * @param delimiter\n     * @param objs\n     * @param function\n     * @param <T>\n     */\n    public static <T> String join(String delimiter, Collection<T> objs, Function<T, String> function) {\n        if (CollectionUtil.isEmpty(objs)) {\n            return \"\";\n        } else if (objs.size() == 1) {\n            T next = objs.iterator().next();\n            return String.valueOf(function.apply(next));\n        } else {\n            String[] strings = new String[objs.size()];\n            int index = 0;\n            for (T obj : objs) {\n                strings[index++] = function.apply(obj);\n            }\n            return String.join(delimiter, strings);\n        }\n    }\n\n    public static String buildSchemaWithTable(String schema, String tableName) {\n        return isNotBlank(schema) ? schema + \".\" + tableName : tableName;\n    }\n\n    public static String[] getSchemaAndTableName(String tableNameWithSchema) {\n        int index = tableNameWithSchema.indexOf(\".\");\n        return index <= 0 ? new String[]{null, tableNameWithSchema.trim()}\n            : new String[]{tableNameWithSchema.substring(0, index).trim(), tableNameWithSchema.substring(index + 1).trim()};\n    }\n\n    public static String[] getTableNameWithAlias(String tableNameWithAlias) {\n        int index = tableNameWithAlias.indexOf(\".\");\n        return index <= 0 ? new String[]{tableNameWithAlias, null}\n            : new String[]{tableNameWithAlias.substring(0, index), tableNameWithAlias.substring(index + 1)};\n    }\n\n    public static String tryTrim(String string) {\n        return string != null ? string.trim() : null;\n    }\n\n    public static String substringAfterLast(String text, String prefix) {\n        if (text == null) {\n            return null;\n        }\n        if (prefix == null) {\n            return text;\n        }\n        return text.substring(text.lastIndexOf(prefix) + 1);\n    }\n\n\n}\n\n```\n# Function Signature: public static String camelToUnderline(String string) {\n# Natural Language Annotations: /**\n     * \u9a7c\u5cf0\u8f6c\u4e0b\u5212\u7ebf\u683c\u5f0f\n     *\n     * @param string\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static String camelToUnderline(String string) {\n    if (isBlank(string)) {\n        return \"\";\n    }\n    StringBuilder sb = new StringBuilder(string.length());\n    for (int i = 0, len = string.length(); i < len; i++) {\n        char c = string.charAt(i);\n        if (Character.isUpperCase(c)) {\n            sb.append(\"_\").append(Character.toLowerCase(c));\n        } else {\n            sb.append(c);\n        }\n    }\n    return sb.toString();\n}\n```", "  ```\npublic static String camelToUnderline(String string) {\n    if (string.matches(\"^[a-zA-Z][_a-zA-Z0-9]*\")) {\n        return string.replaceAll(\"([a-z])([A-Z])\", \"_$1$2\").toLowerCase();\n    } else {\n        return string;\n    }\n}\n```", "  ```\npublic static String camelToUnderline(String string) {\n\t// ZH_CN\uff1a\u8fd9\u662f\u4e00\u4e2a\u9a7c\u5cf0\u8f6c\u4e0b\u5212\u7ebf\u7684\u65b9\u6cd5\uff0c\u5c06\u5c06\u7ed9\u5b9a\u7684\u9a7c\u5cf0\u683c\u5f0f\u5b57\u7b26\u4e32\u8f6c\u6362\u4e3a\u76f8\u5e94\u7684\u4e0b\u5212\u7ebf\u683c\u5f0f\u3002\n\t// EN\uff1aThis is a method to convert the given camel-style string to the corresponding underscore-style string.\n\t\t// \u8f93\u5165\u4e3a\u9a7c\u5cf0\u683c\u5f0f\u5b57\u7b26\u4e32\uff08\u4f8b\uff1auserName\uff09\uff0c\u8f93\u51fa\u4e3a\u4e0b\u5212\u7ebf\u683c\u5f0f\u5b57\u7b26\u4e32\uff08\u4f8b\uff1auser_name\uff09\n\tif (string == null) {\n\t\treturn null;\n\t}\n\tif (string.isEmpty()) {\n\t\treturn string;\n\t}\n\t// \u4e0e StringBuilder \u76f8\u6bd4\uff0cStringBuffer \u4e3a\u7ebf\u7a0b\u5b89\u5168\u7684\u66ff\u4ee3\u54c1\u3002\n\tStringBuilder sb = new StringBuffer();\n\tchar[] chars = string.toCharArray();\n\t// \u53ef\u4ee5\u4f7f\u7528 StringBuilder \u7684 deleteCharAt(int index) \u65b9\u6cd5\u6765\u62fc\u63a5\u9636\u6bb5\u6027\u7684\u5b57\u7b26\u4e32\uff0c\u5e76\u4f7f\u7528\u5b57\u7b26\u5927\u5c0f\u6bd4\u8f83\u4ee3\u66ff\u5b57\u7b26\u4e32\u62fc\u63a5\n\tfor (int i = 0; i < chars.length; i++) {\n\t\tchar c = chars[i];\n\t\tif (Character.isUpperCase(c)) {\n\t\t\tsb.append(\"_\");\n\t\t}\n\t\tsb.append(Character.toLowerCase(c));\n\t}\n\treturn sb.toString();\n}\n```"]}, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java-underlineToCamel": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/mybatis-flex/mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java:\n```\n/*\n *  Copyright (c) 2022-2023, Mybatis-Flex (fuhai999@gmail.com).\n *  <p>\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *  <p>\n *  http://www.apache.org/licenses/LICENSE-2.0\n *  <p>\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n */\npackage com.mybatisflex.core.util;\n\n\nimport com.mybatisflex.core.exception.FlexExceptions;\n\nimport java.util.Collection;\nimport java.util.Locale;\nimport java.util.function.Function;\nimport java.util.regex.Pattern;\n\npublic class StringUtil {\n\n    private StringUtil() {\n    }\n\n    /**\n     * @see org.apache.ibatis.reflection.property.PropertyNamer#methodToProperty(String)\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * \u7b2c\u4e00\u4e2a\u5b57\u7b26\u8f6c\u6362\u4e3a\u5c0f\u5199\n     *\n     * @param string\n     */\n    public static String firstCharToLowerCase(String string) {\n        char firstChar = string.charAt(0);\n        if (firstChar >= 'A' && firstChar <= 'Z') {\n            char[] chars = string.toCharArray();\n            chars[0] += ('a' - 'A');\n            return new String(chars);\n        }\n        return string;\n    }\n\n\n    /**\n     * \u7b2c\u4e00\u4e2a\u5b57\u7b26\u8f6c\u6362\u4e3a\u5927\u5199\n     *\n     * @param string\n     */\n    public static String firstCharToUpperCase(String string) {\n        char firstChar = string.charAt(0);\n        if (firstChar >= 'a' && firstChar <= 'z') {\n            char[] chars = string.toCharArray();\n            chars[0] -= ('a' - 'A');\n            return new String(chars);\n        }\n        return string;\n    }\n\n\n    /**\n     * \u9a7c\u5cf0\u8f6c\u4e0b\u5212\u7ebf\u683c\u5f0f\n     *\n     * @param string\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * \u4e0b\u5212\u7ebf\u8f6c\u9a7c\u5cf0\u683c\u5f0f\n     *\n     * @param string\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * \u5220\u9664\u5b57\u7b26\u4e32\u4e2d\u7684\u5b57\u7b26\n     */\n    public static String deleteChar(String string, char deleteChar) {\n        if (isBlank(string)) {\n            return \"\";\n        }\n        char[] chars = string.toCharArray();\n        StringBuilder sb = new StringBuilder(string.length());\n        for (char aChar : chars) {\n            if (aChar != deleteChar) {\n                sb.append(aChar);\n            }\n        }\n        return sb.toString();\n    }\n\n    public static String deleteChar(String string, char deleteChar1, char deleteChar2) {\n        if (isBlank(string)) {\n            return \"\";\n        }\n        char[] chars = string.toCharArray();\n        StringBuilder sb = new StringBuilder(string.length());\n        for (char aChar : chars) {\n            if (aChar != deleteChar1 && aChar != deleteChar2) {\n                sb.append(aChar);\n            }\n        }\n        return sb.toString();\n    }\n\n    /**\n     * \u5b57\u7b26\u4e32\u4e3a null \u6216\u8005\u5185\u90e8\u5b57\u7b26\u5168\u90e8\u4e3a ' ', '\\t', '\\n', '\\r' \u8fd9\u56db\u7c7b\u5b57\u7b26\u65f6\u8fd4\u56de true\n     */\n    public static boolean isBlank(String string) {\n        if (string == null) {\n            return true;\n        }\n\n        for (int i = 0, len = string.length(); i < len; i++) {\n            if (string.charAt(i) > ' ') {\n                return false;\n            }\n        }\n        return true;\n    }\n\n\n    public static boolean isAnyBlank(String... strings) {\n        if (strings == null || strings.length == 0) {\n            throw new IllegalArgumentException(\"strings is null or empty.\");\n        }\n\n        for (String string : strings) {\n            if (isBlank(string)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n\n    public static boolean isNotBlank(String str) {\n        return !isBlank(str);\n    }\n\n\n    public static boolean areNotBlank(String... strings) {\n        return !isAnyBlank(strings);\n    }\n\n\n    /**\n     * \u8fd9\u4e2a\u5b57\u7b26\u4e32\u662f\u5426\u662f\u5168\u662f\u6570\u5b57\n     *\n     * @param string\n     * @return \u5168\u90e8\u6570\u6570\u503c\u65f6\u8fd4\u56de true\uff0c\u5426\u5219\u8fd4\u56de false\n     */\n    public static boolean isNumeric(String string) {\n        if (isBlank(string)) {\n            return false;\n        }\n        for (int i = string.length(); --i >= 0; ) {\n            int chr = string.charAt(i);\n            if (chr < 48 || chr > 57) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n\n    public static boolean startsWithAny(String string, String... prefixes) {\n        if (isBlank(string) || prefixes == null) {\n            return false;\n        }\n\n        for (String prefix : prefixes) {\n            if (string.startsWith(prefix)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n\n    public static boolean endsWithAny(String str, String... suffixes) {\n        if (isBlank(str) || suffixes == null) {\n            return false;\n        }\n\n        for (String suffix : suffixes) {\n            if (str.endsWith(suffix)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n\n    /**\n     * \u6b63\u5219\u5339\u914d\n     *\n     * @param regex\n     * @param input\n     * @return\n     */\n    public static boolean matches(String regex, String input) {\n        if (null == regex || null == input) {\n            return false;\n        }\n        return Pattern.matches(regex, input);\n    }\n\n    /**\n     * \u5408\u5e76\u5b57\u7b26\u4e32\uff0c\u4f18\u5316 String.join() \u65b9\u6cd5\n     *\n     * @param delimiter\n     * @param elements\n     * @return \u65b0\u62fc\u63a5\u597d\u7684\u5b57\u7b26\u4e32\n     * @see String#join(CharSequence, CharSequence...)\n     */\n    public static String join(String delimiter, CharSequence... elements) {\n        if (ArrayUtil.isEmpty(elements)) {\n            return \"\";\n        } else if (elements.length == 1) {\n            return String.valueOf(elements[0]);\n        } else {\n            return String.join(delimiter, elements);\n        }\n    }\n\n    /**\n     * \u5408\u5e76\u5b57\u7b26\u4e32\uff0c\u4f18\u5316 String.join() \u65b9\u6cd5\n     *\n     * @param delimiter\n     * @param elements\n     * @return \u65b0\u62fc\u63a5\u597d\u7684\u5b57\u7b26\u4e32\n     * @see String#join(CharSequence, CharSequence...)\n     */\n    public static String join(String delimiter, Collection<? extends CharSequence> elements) {\n        if (CollectionUtil.isEmpty(elements)) {\n            return \"\";\n        } else if (elements.size() == 1) {\n            return String.valueOf(elements.iterator().next());\n        } else {\n            return String.join(delimiter, elements);\n        }\n    }\n\n\n    /**\n     * \u5408\u5e76\u5b57\u7b26\u4e32\uff0c\u4f18\u5316 String.join() \u65b9\u6cd5\n     *\n     * @param delimiter\n     * @param objs\n     * @param function\n     * @param <T>\n     */\n    public static <T> String join(String delimiter, Collection<T> objs, Function<T, String> function) {\n        if (CollectionUtil.isEmpty(objs)) {\n            return \"\";\n        } else if (objs.size() == 1) {\n            T next = objs.iterator().next();\n            return String.valueOf(function.apply(next));\n        } else {\n            String[] strings = new String[objs.size()];\n            int index = 0;\n            for (T obj : objs) {\n                strings[index++] = function.apply(obj);\n            }\n            return String.join(delimiter, strings);\n        }\n    }\n\n    public static String buildSchemaWithTable(String schema, String tableName) {\n        return isNotBlank(schema) ? schema + \".\" + tableName : tableName;\n    }\n\n    public static String[] getSchemaAndTableName(String tableNameWithSchema) {\n        int index = tableNameWithSchema.indexOf(\".\");\n        return index <= 0 ? new String[]{null, tableNameWithSchema.trim()}\n            : new String[]{tableNameWithSchema.substring(0, index).trim(), tableNameWithSchema.substring(index + 1).trim()};\n    }\n\n    public static String[] getTableNameWithAlias(String tableNameWithAlias) {\n        int index = tableNameWithAlias.indexOf(\".\");\n        return index <= 0 ? new String[]{tableNameWithAlias, null}\n            : new String[]{tableNameWithAlias.substring(0, index), tableNameWithAlias.substring(index + 1)};\n    }\n\n    public static String tryTrim(String string) {\n        return string != null ? string.trim() : null;\n    }\n\n    public static String substringAfterLast(String text, String prefix) {\n        if (text == null) {\n            return null;\n        }\n        if (prefix == null) {\n            return text;\n        }\n        return text.substring(text.lastIndexOf(prefix) + 1);\n    }\n\n\n}\n\n```\n# Function Signature: public static String underlineToCamel(String string) {\n# Natural Language Annotations: /**\n     * \u4e0b\u5212\u7ebf\u8f6c\u9a7c\u5cf0\u683c\u5f0f\n     *\n     * @param string\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static String underlineToCamel(String string) {\n    if (isBlank(string)) {\n        return \"\";\n    }\n    string = string.trim();\n    int length = string.length();\n    StringBuilder sb = new StringBuilder(length);\n    boolean upperCase = false;\n    for (int i = 0; i < length; i++) {\n        char c = string.charAt(i);\n        if (c == '_' || c == '-') {\n            upperCase = true;\n        } else if (upperCase) {\n            sb.append(Character.toUpperCase(c));\n            upperCase = false;\n        } else {\n            sb.append(Character.toLowerCase(c));\n        }\n    }\n    return sb.toString();\n}\n```", "  ```\npackage com.mybatisflex.core.util;\n\nimport org.springframework.util.StringUtils;\n\npublic class StringUtil {\n\n    private StringUtil() {\n    }\n\n    /**\n     * \u4e0b\u5212\u7ebf\u8f6c\u9a7c\u5cf0\u683c\u5f0f\n     *\n     * @param string\n     */\n    public static String underlineToCamel(String string) {\n        if (StringUtils.isEmpty(string)) {\n            return \"\";\n        }\n\n        StringBuilder sb = new StringBuilder();\n        boolean upperCase = false;\n        for (char c : string.toCharArray()) {\n            if (c == '_') {\n                upperCase = true;\n            } else if (upperCase) {\n                sb.append(Character.toUpperCase(c));\n                upperCase = false;\n            } else {\n                sb.append(c);\n            }\n        }\n        return sb.toString();\n    }\n\n}\n```", "  ```\npublic static String underlineToCamel(String string) {\n    if (isBlank(string)) {\n        return null;\n    }\n    StringBuilder sb = new StringBuilder();\n    String[] tokens = string.split(\"_\");\n    for (int i = 0; i < tokens.length; ++i) {\n        String token = tokens[i];\n        if (i > 0) {\n            sb.append(Character.toUpperCase(token.charAt(0)));\n            sb.append(token.substring(1));\n        } else {\n            sb.append(token);\n        }\n    }\n    return sb.toString();\n}\n```"]}, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/CollectionUtil.java-computeIfAbsent": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/mybatis-flex/mybatis-flex-core/src/main/java/com/mybatisflex/core/util/CollectionUtil.java:\n```\n/*\n *  Copyright (c) 2022-2023, Mybatis-Flex (fuhai999@gmail.com).\n *  <p>\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *  <p>\n *  http://www.apache.org/licenses/LICENSE-2.0\n *  <p>\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n */\npackage com.mybatisflex.core.util;\n\nimport com.mybatisflex.core.query.CloneSupport;\n\nimport java.util.*;\nimport java.util.function.Function;\n\n\npublic class CollectionUtil {\n\n    private CollectionUtil() {\n    }\n\n\n    public static boolean isEmpty(Collection<?> collection) {\n        return collection == null || collection.isEmpty();\n    }\n\n    public static boolean isNotEmpty(Collection<?> collection) {\n        return !isEmpty(collection);\n    }\n\n\n    public static boolean isEmpty(Map<?, ?> map) {\n        return map == null || map.isEmpty();\n    }\n\n    public static boolean isNotEmpty(Map<?, ?> map) {\n        return !isEmpty(map);\n    }\n\n    /**\n     * \u5408\u5e76 list\n     */\n    public static <T> List<T> merge(List<T> list, List<T> other) {\n        if (list == null && other == null) {\n            return new ArrayList<>();\n        } else if (isEmpty(other) && list != null) {\n            return list;\n        } else if (isEmpty(list)) {\n            return other;\n        }\n        List<T> newList = new ArrayList<>(list);\n        newList.addAll(other);\n        return newList;\n    }\n\n\n    public static <K, V> HashMap<K, V> newHashMap() {\n        return new HashMap<>();\n    }\n\n    /**\n     * \u4e3b\u8981\u662f\u7528\u4e8e\u4fee\u590d concurrentHashMap \u5728 jdk1.8 \u4e0b\u7684\u6b7b\u5faa\u73af\u95ee\u9898\n     *\n     * @see <a href=\"https://bugs.openjdk.org/browse/JDK-8161372\">https://bugs.openjdk.org/browse/JDK-8161372</a>\n     */\n\n\n\n\n\n\n\n\n\n    public static <T> List<T> toList(Collection<T> collection) {\n        if (collection instanceof List) {\n            return (List<T>) collection;\n        } else {\n            return new ArrayList<>(collection);\n        }\n    }\n\n    public static String[] toArrayString(Collection<?> collection) {\n        if (isEmpty(collection)) {\n            return new String[0];\n        }\n        String[] results = new String[collection.size()];\n        int index = 0;\n        for (Object o : collection) {\n            results[index++] = String.valueOf(o);\n        }\n        return results;\n    }\n\n    @SuppressWarnings(\"all\")\n    public static <E extends CloneSupport<E>> List<E> cloneArrayList(List<E> list) {\n        if (list == null) {\n            return null;\n        }\n        List<E> arrayList = new ArrayList<>(list.size());\n        for (E e : list) {\n            arrayList.add(e.clone());\n        }\n        return arrayList;\n    }\n\n\n    public static <T> Set<T> newHashSet(T... elements) {\n        return new HashSet<>(Arrays.asList(elements));\n    }\n\n\n    public static <T> List<T> newArrayList(T... elements) {\n        return new ArrayList<>(Arrays.asList(elements));\n    }\n\n\n    public static <E> ArrayList<E> newArrayList(Collection<E> collection) {\n        if (isEmpty(collection)) {\n            return new ArrayList<>();\n        }\n        return new ArrayList<>(collection);\n    }\n\n\n    public static <K, V> HashMap<K, V> newHashMap(Map<K, V> map) {\n        if (map == null || map.isEmpty()) {\n            return new HashMap<>();\n        }\n        return new HashMap<>(map);\n    }\n\n}\n\n```\n# Function Signature: public static <K, V> V computeIfAbsent(Map<K, V> concurrentHashMap, K key, Function<? super K, ? extends V> mappingFunction) {\n# Natural Language Annotations: /**\n     * \u4e3b\u8981\u662f\u7528\u4e8e\u4fee\u590d concurrentHashMap \u5728 jdk1.8 \u4e0b\u7684\u6b7b\u5faa\u73af\u95ee\u9898\n     *\n     * @see <a href=\"https://bugs.openjdk.org/browse/JDK-8161372\">https://bugs.openjdk.org/browse/JDK-8161372</a>\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <K, V> V computeIfAbsent(Map<K, V> concurrentHashMap, K key, Function<? super K, ? extends V> mappingFunction) {\n    if (concurrentHashMap.containsKey(key)) {\n        return concurrentHashMap.get(key);\n    }\n    V value = mappingFunction.apply(key);\n    concurrentHashMap.putIfAbsent(key, value);\n    return value;\n}\n```", "  ```\nprivate static final Object mutex = new Object();\n\npublic static <K, V> V computeIfAbsent(Map<K, V> concurrentHashMap, K key, Function<? super K, ? extends V> mappingFunction) {\n    V value;\n    if (concurrentHashMap.containsKey(key)) {\n        value = concurrentHashMap.get(key);\n    } else {\n        synchronized (mutex) {\n            if (concurrentHashMap.containsKey(key)) {\n                value = concurrentHashMap.get(key);\n            } else {\n                value = mappingFunction.apply(key);\n                concurrentHashMap.put(key, value);\n            }\n        }\n    }\n    return value;\n}\n```", "  ```\npublic static <K, V> V computeIfAbsent(Map<K, V> concurrentHashMap, K key, Function<? super K, ? extends V> mappingFunction) {\n    while (true) {\n        V value = concurrentHashMap.get(key);\n        if (value != null) {\n            return value;\n        }\n        V newValue = mappingFunction.apply(key);\n        if (concurrentHashMap.put(key, newValue) == null) {\n            return newValue;\n        }\n    }\n}\n```\nThis function is similar to the `computeIfAbsent` method in the `Map` interface, but it is designed to be used with the `ConcurrentHashMap` class. It takes a `ConcurrentHashMap<K, V>` object, a key of type `K`, and a mapping function that takes a key of type `K` and returns a value of type `V`. The function returns the existing value if the key is already present in the map, or the new value if the key is not present and the mapping function is able to generate it.\n\nThe implementation of this function uses a \"busy loop\" to continuously check the value of the key while the mapping function is being executed. This is important to ensure that the function correctly handles competing updates to the map. In particular, the function will retry the mapping function until it is able to successfully put a new value into the map."]}, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/MapUtil.java-computeIfAbsent": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/mybatis-flex/mybatis-flex-core/src/main/java/com/mybatisflex/core/util/MapUtil.java:\n```\n/*\n *  Copyright (c) 2022-2023, Mybatis-Flex (fuhai999@gmail.com).\n *  <p>\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *  <p>\n *  http://www.apache.org/licenses/LICENSE-2.0\n *  <p>\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n */\npackage com.mybatisflex.core.util;\n\nimport java.util.AbstractMap;\nimport java.util.Map;\nimport java.util.function.Function;\n\npublic class MapUtil {\n    private static final boolean IS_JDK8 = (8 == getJvmVersion0());\n\n    private MapUtil() {\n    }\n\n    private static int getJvmVersion0() {\n        int jvmVersion = -1;\n        try {\n            String javaSpecVer = StringUtil.tryTrim(System.getProperty(\"java.specification.version\"));\n            if (StringUtil.isNotBlank(javaSpecVer)) {\n                if (javaSpecVer.startsWith(\"1.\")) {\n                    javaSpecVer = javaSpecVer.substring(2);\n                }\n                if (javaSpecVer.indexOf('.') == -1) {\n                    jvmVersion = Integer.parseInt(javaSpecVer);\n                }\n            }\n        } catch (Throwable ignore) {\n            // ignore\n        }\n        // default is jdk8\n        if (jvmVersion == -1) {\n            jvmVersion = 8;\n        }\n        return jvmVersion;\n    }\n\n    /**\n     * A temporary workaround for Java 8 specific performance issue JDK-8161372 .<br>\n     * This class should be removed once we drop Java 8 support.\n     *\n     * @see <a href=\n     * \"https://bugs.openjdk.java.net/browse/JDK-8161372\">https://bugs.openjdk.java.net/browse/JDK-8161372</a>\n     */\n\n\n\n\n\n\n\n\n\n\n\n    public static <K, V> Map.Entry<K, V> entry(K key, V value) {\n        return new AbstractMap.SimpleImmutableEntry<>(key, value);\n    }\n\n\n}\n\n```\n# Function Signature: public static <K, V> V computeIfAbsent(Map<K, V> map, K key, Function<K, V> mappingFunction) {\n# Natural Language Annotations: /**\n     * A temporary workaround for Java 8 specific performance issue JDK-8161372 .<br>\n     * This class should be removed once we drop Java 8 support.\n     *\n     * @see <a href=\n     * \"https://bugs.openjdk.java.net/browse/JDK-8161372\">https://bugs.openjdk.java.net/browse/JDK-8161372</a>\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <K, V> V computeIfAbsent(Map<K, V> map, K key, Function<K, V> mappingFunction) {\n    if (IS_JDK8) {\n        return map.getOrDefault(key, mappingFunction.apply(key));\n    } else {\n        return map.computeIfAbsent(key, mappingFunction);\n    }\n}\n```", "  ```\npublic static <K, V> V computeIfAbsent(Map<K, V> map, K key, Function<K, V> mappingFunction) {\n    if (map == null || key == null || mappingFunction == null) {\n        throw new NullPointerException();\n    }\n\n    V value = map.get(key);\n    if (value == null) {\n        value = mappingFunction.apply(key);\n        map.put(key, value);\n    }\n    return value;\n}\n```", "  ```\npublic static <K, V> V computeIfAbsent(Map<K, V> map, K key, Function<K, V> mappingFunction) {\n    if (map.get(key) == null) {\n        V value = mappingFunction.apply(key);\n        map.put(key, value);\n        return value;\n    } else {\n        return map.get(key);\n    }\n}\n```\nThis function is a replacement for the `computeIfAbsent` method in the Java 8 API. It provides the same functionality as the `computeIfAbsent` method, but it is implemented using a combination of the `get` and `put` methods from the `Map` interface.\n\nThe function takes three parameters:\n\n* `map`: a `Map` object that contains the key-value pairs\n* `key`: the key that is used to look up the value in the `Map`\n* `mappingFunction`: a function that takes a `key` as an argument and returns the value that should be added to the `Map` if the key is not already present.\n\nThe function first checks if the key is already present in the `Map` using the `get` method. If it is not present, it calls the `mappingFunction` to get the value and then adds the key-value pair to the `Map` using the `put` method. If the key is already present, it simply returns the value associated with the key.\n\nThis function is useful when you want to get a value from a `Map` and add it to the `Map` if it is not already present. It is also useful when you want to avoid the performance issue in the `computeIfAbsent` method in the Java 8 API, as described in the natural language annotation."]}, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/mybatis/Mappers.java-ofEntityClass": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/mybatis-flex/mybatis-flex-core/src/main/java/com/mybatisflex/core/mybatis/Mappers.java:\n```\n/*\n *  Copyright (c) 2022-2023, Mybatis-Flex (fuhai999@gmail.com).\n *  <p>\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *  <p>\n *  http://www.apache.org/licenses/LICENSE-2.0\n *  <p>\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n */\npackage com.mybatisflex.core.mybatis;\n\nimport com.mybatisflex.core.BaseMapper;\nimport com.mybatisflex.core.FlexGlobalConfig;\nimport com.mybatisflex.core.exception.FlexExceptions;\nimport org.apache.ibatis.reflection.ExceptionUtil;\nimport org.apache.ibatis.session.ExecutorType;\nimport org.apache.ibatis.session.SqlSession;\nimport org.apache.ibatis.session.SqlSessionFactory;\nimport com.mybatisflex.core.util.MapUtil;\n\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\n\n/**\n * \u83b7\u53d6 {@link BaseMapper} \u5bf9\u8c61\u3002\n *\n * @author michael\n * @author \u738b\u5e05\n */\n@SuppressWarnings(\"unchecked\")\npublic class Mappers {\n\n    private Mappers() {\n    }\n\n    private static final Map<Class<?>, Object> MAPPER_OBJECTS = new ConcurrentHashMap<>();\n\n    private static final Map<Class<?>, Class<?>> ENTITY_MAPPER_MAP = new ConcurrentHashMap<>();\n\n    /**\n     * \u6dfb\u52a0 \u5b9e\u4f53\u7c7b \u4e0e {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\u63a5\u53e3 \u5bf9\u5e94\uff0c\u4e24\u8005\u7686\u4e3a\u975e\u52a8\u6001\u4ee3\u7406\u7c7b\u3002\n     *\n     * @param entityClass \u5b9e\u4f53\u7c7b\n     * @param mapperClass {@link BaseMapper} \u5b9e\u73b0\u63a5\u53e3\n     */\n    static void addMapping(Class<?> entityClass, Class<?> mapperClass) {\n        ENTITY_MAPPER_MAP.put(entityClass, mapperClass);\n    }\n\n    /**\n     * \u901a\u8fc7 \u5b9e\u4f53\u7c7b \u83b7\u53d6\u5bf9\u5e94 {@link BaseMapper} \u5bf9\u8c61\u3002\n     *\n     * @param entityClass \u5b9e\u4f53\u7c7b\n     * @param <E>         \u5b9e\u4f53\u7c7b\u7c7b\u578b\n     * @return {@link BaseMapper} \u5bf9\u8c61\n     */\n\n\n\n\n\n\n\n\n    /**\n     * \u901a\u8fc7 {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\u7684 Class \u5f15\u7528\u76f4\u63a5\u83b7\u53d6 {@link BaseMapper} \u4ee3\u7406\u5bf9\u8c61\u3002\n     *\n     * @param mapperClass {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\n     * @return {@link BaseMapper} \u5bf9\u8c61\n     */\n\n\n\n\n\n\n\n\n    private static class MapperHandler implements InvocationHandler {\n\n        private final Class<?> mapperClass;\n        private final ExecutorType executorType;\n        private final SqlSessionFactory sqlSessionFactory;\n\n        public MapperHandler(Class<?> mapperClass) {\n            this.mapperClass = mapperClass;\n            this.executorType = FlexGlobalConfig.getDefaultConfig()\n                .getConfiguration()\n                .getDefaultExecutorType();\n            this.sqlSessionFactory = FlexGlobalConfig.getDefaultConfig()\n                .getSqlSessionFactory();\n        }\n\n        private SqlSession openSession() {\n            return sqlSessionFactory.openSession(executorType, true);\n        }\n\n        @Override\n        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n            try (SqlSession sqlSession = openSession()) {\n                Object mapper = sqlSession.getMapper(mapperClass);\n                return method.invoke(mapper, args);\n            } catch (Throwable throwable) {\n                throw ExceptionUtil.unwrapThrowable(throwable);\n            }\n        }\n\n    }\n\n}\n\n```\n# Function Signature: public static <E> BaseMapper<E> ofEntityClass(Class<E> entityClass) {\n# Natural Language Annotations: /**\n     * \u901a\u8fc7 \u5b9e\u4f53\u7c7b \u83b7\u53d6\u5bf9\u5e94 {@link BaseMapper} \u5bf9\u8c61\u3002\n     *\n     * @param entityClass \u5b9e\u4f53\u7c7b\n     * @param <E>         \u5b9e\u4f53\u7c7b\u7c7b\u578b\n     * @return {@link BaseMapper} \u5bf9\u8c61\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <E> BaseMapper<E> ofEntityClass(Class<E> entityClass) {\n    Mappers.addMapping(entityClass, BaseMapper.class);\n    return (BaseMapper<E>) PROXYED_MAPPERS.get(entityClass);\n}\n```", "  ```\n@Override\npublic BaseMapper<E> ofEntityClass(Class<E> entityClass) {\n    checkNull(entityClass);\n    return (BaseMapper<E>) createMapper(entityClass);\n}\n\nprivate Object createMapper(Class<?> entityClass) {\n    Object mapperObject = MAPPER_OBJECTS.get(entityClass);\n    // \u5982\u679c\u6ca1\u6709\u7f13\u5b58 mapper \u5bf9\u8c61\uff0c\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\n    if (mapperObject == null) {\n        mapperObject = createProxy(entityClass);\n    }\n    return mapperObject;\n}\n\nprivate Object createProxy(Class<?> entityClass) {\n    Class<?> mapperClass = ENTITY_MAPPER_MAP.get(entityClass);\n    Object proxy = Proxy.newProxyInstance(entityClass.getClassLoader(), new Class[] { mapperClass }, new MapperHandler(mapperClass));\n    MAPPER_OBJECTS.put(entityClass, proxy);\n    return proxy;\n}\n```", "  ```\npublic static <E> BaseMapper<E> ofEntityClass(Class<E> entityClass) {\n    // \u901a\u8fc7 \u5b9e\u4f53\u7c7b \u83b7\u53d6\u5bf9\u5e94 BaseMapper \u63a5\u53e3\u5b9e\u73b0\n    Class<?> mapperClass = ENTITY_MAPPER_MAP.get(entityClass);\n    if (mapperClass == null) {\n        throw new FlexExceptions(\"No mapper for entity %s was found!\", entityClass.getName());\n    }\n\n    // \u4ee3\u7406\u5bf9\u8c61\u7684 class \u9700\u8981\u8bbe\u7f6e\u4e3a BaseMapper\n    // \u8fd9\u6837\u53ef\u4ee5\u907f\u514d\u65b9\u6cd5\u88ab InvocationHandler \u62e6\u622a\u540e\u65e0\u6cd5\u4f7f\u7528\u53cd\u5c04\u8c03\u7528\n    Class<?> proxyClass = Proxy.getProxyClass(entityClass.getClassLoader(), new Class[] {BaseMapper.class});\n\n    // \u751f\u6210 BaseMapper \u5b9e\u4f8b\n    Object proxy = proxyClass.getConstructor(InvocationHandler.class).newInstance(new MapperHandler(mapperClass));\n\n    return (BaseMapper<E>) proxy;\n}\n```"]}, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/mybatis/Mappers.java-ofMapperClass": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/mybatis-flex/mybatis-flex-core/src/main/java/com/mybatisflex/core/mybatis/Mappers.java:\n```\n/*\n *  Copyright (c) 2022-2023, Mybatis-Flex (fuhai999@gmail.com).\n *  <p>\n *  Licensed under the Apache License, Version 2.0 (the \"License\");\n *  you may not use this file except in compliance with the License.\n *  You may obtain a copy of the License at\n *  <p>\n *  http://www.apache.org/licenses/LICENSE-2.0\n *  <p>\n *  Unless required by applicable law or agreed to in writing, software\n *  distributed under the License is distributed on an \"AS IS\" BASIS,\n *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n *  See the License for the specific language governing permissions and\n *  limitations under the License.\n */\npackage com.mybatisflex.core.mybatis;\n\nimport com.mybatisflex.core.BaseMapper;\nimport com.mybatisflex.core.FlexGlobalConfig;\nimport com.mybatisflex.core.exception.FlexExceptions;\nimport org.apache.ibatis.reflection.ExceptionUtil;\nimport org.apache.ibatis.session.ExecutorType;\nimport org.apache.ibatis.session.SqlSession;\nimport org.apache.ibatis.session.SqlSessionFactory;\nimport com.mybatisflex.core.util.MapUtil;\n\nimport java.lang.reflect.InvocationHandler;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Proxy;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\n\n/**\n * \u83b7\u53d6 {@link BaseMapper} \u5bf9\u8c61\u3002\n *\n * @author michael\n * @author \u738b\u5e05\n */\n@SuppressWarnings(\"unchecked\")\npublic class Mappers {\n\n    private Mappers() {\n    }\n\n    private static final Map<Class<?>, Object> MAPPER_OBJECTS = new ConcurrentHashMap<>();\n\n    private static final Map<Class<?>, Class<?>> ENTITY_MAPPER_MAP = new ConcurrentHashMap<>();\n\n    /**\n     * \u6dfb\u52a0 \u5b9e\u4f53\u7c7b \u4e0e {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\u63a5\u53e3 \u5bf9\u5e94\uff0c\u4e24\u8005\u7686\u4e3a\u975e\u52a8\u6001\u4ee3\u7406\u7c7b\u3002\n     *\n     * @param entityClass \u5b9e\u4f53\u7c7b\n     * @param mapperClass {@link BaseMapper} \u5b9e\u73b0\u63a5\u53e3\n     */\n    static void addMapping(Class<?> entityClass, Class<?> mapperClass) {\n        ENTITY_MAPPER_MAP.put(entityClass, mapperClass);\n    }\n\n    /**\n     * \u901a\u8fc7 \u5b9e\u4f53\u7c7b \u83b7\u53d6\u5bf9\u5e94 {@link BaseMapper} \u5bf9\u8c61\u3002\n     *\n     * @param entityClass \u5b9e\u4f53\u7c7b\n     * @param <E>         \u5b9e\u4f53\u7c7b\u7c7b\u578b\n     * @return {@link BaseMapper} \u5bf9\u8c61\n     */\n\n\n\n\n\n\n\n\n    /**\n     * \u901a\u8fc7 {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\u7684 Class \u5f15\u7528\u76f4\u63a5\u83b7\u53d6 {@link BaseMapper} \u4ee3\u7406\u5bf9\u8c61\u3002\n     *\n     * @param mapperClass {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\n     * @return {@link BaseMapper} \u5bf9\u8c61\n     */\n\n\n\n\n\n\n\n\n    private static class MapperHandler implements InvocationHandler {\n\n        private final Class<?> mapperClass;\n        private final ExecutorType executorType;\n        private final SqlSessionFactory sqlSessionFactory;\n\n        public MapperHandler(Class<?> mapperClass) {\n            this.mapperClass = mapperClass;\n            this.executorType = FlexGlobalConfig.getDefaultConfig()\n                .getConfiguration()\n                .getDefaultExecutorType();\n            this.sqlSessionFactory = FlexGlobalConfig.getDefaultConfig()\n                .getSqlSessionFactory();\n        }\n\n        private SqlSession openSession() {\n            return sqlSessionFactory.openSession(executorType, true);\n        }\n\n        @Override\n        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n            try (SqlSession sqlSession = openSession()) {\n                Object mapper = sqlSession.getMapper(mapperClass);\n                return method.invoke(mapper, args);\n            } catch (Throwable throwable) {\n                throw ExceptionUtil.unwrapThrowable(throwable);\n            }\n        }\n\n    }\n\n}\n\n```\n# Function Signature: public static <M> M ofMapperClass(Class<M> mapperClass) {\n# Natural Language Annotations: /**\n     * \u901a\u8fc7 {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\u7684 Class \u5f15\u7528\u76f4\u63a5\u83b7\u53d6 {@link BaseMapper} \u4ee3\u7406\u5bf9\u8c61\u3002\n     *\n     * @param mapperClass {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\n     * @return {@link BaseMapper} \u5bf9\u8c61\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <M> M ofMapperClass(Class<M> mapperClass) {\n    MapperHandler handler = new MapperHandler(mapperClass);\n    return (M) Proxy.newProxyInstance(mapperClass.getClassLoader(), new Class[]{mapperClass}, handler);\n}\n```", "  ```\npublic static <M> M ofMapperClass(Class<M> mapperClass) {\n    MapperHandler handler = new MapperHandler(mapperClass);\n    return (M) Proxy.newProxyInstance(mapperClass.getClassLoader(), new Class[] { mapperClass }, handler);\n}\n```", "  ```\npublic static <M extends BaseMapper> M ofMapperClass(Class<M> mapperClass) {\n    MapperHandler mapperHandler = new MapperHandler(mapperClass);\n    return (M) Proxy.newProxyInstance(MapperHandler.class.getClassLoader(), new Class[] {mapperClass}, mapperHandler);\n}\n```"]}, "spring-ai-models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiAudioSpeechModel.java-stream": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiAudioSpeechModel.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.springframework.ai.openai;\n\nimport org.apache.commons.lang3.StringUtils;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.chat.metadata.RateLimit;\nimport org.springframework.ai.openai.api.OpenAiAudioApi;\nimport org.springframework.ai.openai.api.OpenAiAudioApi.SpeechRequest.AudioResponseFormat;\nimport org.springframework.ai.openai.audio.speech.Speech;\nimport org.springframework.ai.openai.audio.speech.SpeechModel;\nimport org.springframework.ai.openai.audio.speech.SpeechPrompt;\nimport org.springframework.ai.openai.audio.speech.SpeechResponse;\nimport org.springframework.ai.openai.audio.speech.StreamingSpeechModel;\nimport org.springframework.ai.openai.metadata.audio.OpenAiAudioSpeechResponseMetadata;\nimport org.springframework.ai.openai.metadata.support.OpenAiResponseHeaderExtractor;\nimport org.springframework.ai.retry.RetryUtils;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.retry.support.RetryTemplate;\nimport org.springframework.util.Assert;\nimport reactor.core.publisher.Flux;\n\n/**\n * OpenAI audio speech client implementation for backed by {@link OpenAiAudioApi}.\n *\n * @author Ahmed Yousri\n * @author Hyunjoon Choi\n * @author Thomas Vitale\n * @see OpenAiAudioApi\n * @since 1.0.0-M1\n */\npublic class OpenAiAudioSpeechModel implements SpeechModel, StreamingSpeechModel {\n\n\tprivate final Logger logger = LoggerFactory.getLogger(getClass());\n\n\t/**\n\t * The default options used for the audio completion requests.\n\t */\n\tprivate final OpenAiAudioSpeechOptions defaultOptions;\n\n\t/**\n\t * The speed of the default voice synthesis.\n\t * @see OpenAiAudioSpeechOptions\n\t */\n\tprivate static final Float SPEED = 1.0f;\n\n\t/**\n\t * The retry template used to retry the OpenAI Audio API calls.\n\t */\n\tprivate final RetryTemplate retryTemplate;\n\n\t/**\n\t * Low-level access to the OpenAI Audio API.\n\t */\n\tprivate final OpenAiAudioApi audioApi;\n\n\t/**\n\t * Initializes a new instance of the OpenAiAudioSpeechModel class with the provided\n\t * OpenAiAudioApi. It uses the model tts-1, response format mp3, voice alloy, and the\n\t * default speed of 1.0.\n\t * @param audioApi The OpenAiAudioApi to use for speech synthesis.\n\t */\n\tpublic OpenAiAudioSpeechModel(OpenAiAudioApi audioApi) {\n\t\tthis(audioApi,\n\t\t\t\tOpenAiAudioSpeechOptions.builder()\n\t\t\t\t\t.withModel(OpenAiAudioApi.TtsModel.TTS_1.getValue())\n\t\t\t\t\t.withResponseFormat(AudioResponseFormat.MP3)\n\t\t\t\t\t.withVoice(OpenAiAudioApi.SpeechRequest.Voice.ALLOY)\n\t\t\t\t\t.withSpeed(SPEED)\n\t\t\t\t\t.build());\n\t}\n\n\t/**\n\t * Initializes a new instance of the OpenAiAudioSpeechModel class with the provided\n\t * OpenAiAudioApi and options.\n\t * @param audioApi The OpenAiAudioApi to use for speech synthesis.\n\t * @param options The OpenAiAudioSpeechOptions containing the speech synthesis\n\t * options.\n\t */\n\tpublic OpenAiAudioSpeechModel(OpenAiAudioApi audioApi, OpenAiAudioSpeechOptions options) {\n\t\tthis(audioApi, options, RetryUtils.DEFAULT_RETRY_TEMPLATE);\n\t}\n\n\t/**\n\t * Initializes a new instance of the OpenAiAudioSpeechModel class with the provided\n\t * OpenAiAudioApi and options.\n\t * @param audioApi The OpenAiAudioApi to use for speech synthesis.\n\t * @param options The OpenAiAudioSpeechOptions containing the speech synthesis\n\t * options.\n\t * @param retryTemplate The retry template.\n\t */\n\tpublic OpenAiAudioSpeechModel(OpenAiAudioApi audioApi, OpenAiAudioSpeechOptions options,\n\t\t\tRetryTemplate retryTemplate) {\n\t\tAssert.notNull(audioApi, \"OpenAiAudioApi must not be null\");\n\t\tAssert.notNull(options, \"OpenAiSpeechOptions must not be null\");\n\t\tAssert.notNull(options, \"RetryTemplate must not be null\");\n\t\tthis.audioApi = audioApi;\n\t\tthis.defaultOptions = options;\n\t\tthis.retryTemplate = retryTemplate;\n\t}\n\n\t@Override\n\tpublic byte[] call(String text) {\n\t\tSpeechPrompt speechRequest = new SpeechPrompt(text);\n\t\treturn call(speechRequest).getResult().getOutput();\n\t}\n\n\t@Override\n\tpublic SpeechResponse call(SpeechPrompt speechPrompt) {\n\n\t\tOpenAiAudioApi.SpeechRequest speechRequest = createRequest(speechPrompt);\n\n\t\tResponseEntity<byte[]> speechEntity = this.retryTemplate\n\t\t\t.execute(ctx -> this.audioApi.createSpeech(speechRequest));\n\n\t\tvar speech = speechEntity.getBody();\n\n\t\tif (speech == null) {\n\t\t\tlogger.warn(\"No speech response returned for speechRequest: {}\", speechRequest);\n\t\t\treturn new SpeechResponse(new Speech(new byte[0]));\n\t\t}\n\n\t\tRateLimit rateLimits = OpenAiResponseHeaderExtractor.extractAiResponseHeaders(speechEntity);\n\n\t\treturn new SpeechResponse(new Speech(speech), new OpenAiAudioSpeechResponseMetadata(rateLimits));\n\t}\n\n\t/**\n\t * Streams the audio response for the given speech prompt.\n\t * @param speechPrompt The speech prompt containing the text and options for speech\n\t * synthesis.\n\t * @return A Flux of SpeechResponse objects containing the streamed audio and\n\t * metadata.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\tprivate OpenAiAudioApi.SpeechRequest createRequest(SpeechPrompt request) {\n\t\tOpenAiAudioSpeechOptions options = this.defaultOptions;\n\n\t\tif (request.getOptions() != null) {\n\t\t\tif (request.getOptions() instanceof OpenAiAudioSpeechOptions runtimeOptions) {\n\t\t\t\toptions = this.merge(runtimeOptions, options);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new IllegalArgumentException(\"Prompt options are not of type SpeechOptions: \"\n\t\t\t\t\t\t+ request.getOptions().getClass().getSimpleName());\n\t\t\t}\n\t\t}\n\n\t\tString input = StringUtils.isNotBlank(options.getInput()) ? options.getInput()\n\t\t\t\t: request.getInstructions().getText();\n\n\t\tOpenAiAudioApi.SpeechRequest.Builder requestBuilder = OpenAiAudioApi.SpeechRequest.builder()\n\t\t\t.withModel(options.getModel())\n\t\t\t.withInput(input)\n\t\t\t.withVoice(options.getVoice())\n\t\t\t.withResponseFormat(options.getResponseFormat())\n\t\t\t.withSpeed(options.getSpeed());\n\n\t\treturn requestBuilder.build();\n\t}\n\n\tprivate OpenAiAudioSpeechOptions merge(OpenAiAudioSpeechOptions source, OpenAiAudioSpeechOptions target) {\n\t\tOpenAiAudioSpeechOptions.Builder mergedBuilder = OpenAiAudioSpeechOptions.builder();\n\n\t\tmergedBuilder.withModel(source.getModel() != null ? source.getModel() : target.getModel());\n\t\tmergedBuilder.withInput(source.getInput() != null ? source.getInput() : target.getInput());\n\t\tmergedBuilder.withVoice(source.getVoice() != null ? source.getVoice() : target.getVoice());\n\t\tmergedBuilder.withResponseFormat(\n\t\t\t\tsource.getResponseFormat() != null ? source.getResponseFormat() : target.getResponseFormat());\n\t\tmergedBuilder.withSpeed(source.getSpeed() != null ? source.getSpeed() : target.getSpeed());\n\n\t\treturn mergedBuilder.build();\n\t}\n\n}\n\n```\n# Function Signature: @Override\tpublic Flux<SpeechResponse> stream(SpeechPrompt speechPrompt) {\n# Natural Language Annotations: /**\n\t * Streams the audio response for the given speech prompt.\n\t * @param speechPrompt The speech prompt containing the text and options for speech\n\t * synthesis.\n\t * @return A Flux of SpeechResponse objects containing the streamed audio and\n\t * metadata.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\npublic Flux<SpeechResponse> stream(SpeechPrompt speechPrompt) {\n\tOpenAiAudioApi.SpeechRequest speechRequest = createRequest(speechPrompt);\n\treturn this.audioApi.streamSpeech(speechRequest).map(audioEntity -> {\n\t\tvar audio = audioEntity.getBody();\n\t\tif (audio == null) {\n\t\t\tlogger.warn(\"No speech response returned for speechRequest: {}\", speechRequest);\n\t\t\treturn new SpeechResponse(new Speech(new byte[0]));\n\t\t}\n\t\tRateLimit rateLimits = OpenAiResponseHeaderExtractor.extractAiResponseHeaders(audioEntity);\n\t\treturn new SpeechResponse(new Speech(audio), new OpenAiAudioSpeechResponseMetadata(rateLimits));\n\t});\n}\n```", "  ```\n@Override\npublic Flux<SpeechResponse> stream(SpeechPrompt speechPrompt) {\n    OpenAiAudioApi.SpeechRequest speechRequest = createRequest(speechPrompt);\n\n    Flux<byte[]> speechEntityFlux =\n            this.retryTemplate.execute(ctx -> this.audioApi.createSpeechStream(speechRequest).concatMap(b -> Mono.just(b.getBody())));\n\n    return speechEntityFlux.map(speech -> {\n        RateLimit rateLimits = OpenAiResponseHeaderExtractor.extractAiResponseHeaders(speechEntityFlux);\n        return new SpeechResponse(new Speech(speech), new OpenAiAudioSpeechResponseMetadata(rateLimits));\n    });\n}\n```", "  ```\n@Override\npublic Flux<SpeechResponse> stream(SpeechPrompt speechPrompt) {\n    return Flux.deferContextual(context ->\n            this.audioApi.createSpeechStream(createRequest(speechPrompt))\n                    .switchOnEmpty(Mono.error(new IllegalStateException(\"No audio returned\")))\n                    .map(speechEntity -> new SpeechResponse(new Speech(speechEntity.getBody())))\n    );\n}\n```"]}, "spring-ai-models/spring-ai-postgresml/src/main/java/org/springframework/ai/postgresml/PostgresMlEmbeddingModel.java-mergeOptions": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/models/spring-ai-postgresml/src/main/java/org/springframework/ai/postgresml/PostgresMlEmbeddingModel.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.postgresml;\n\nimport java.sql.Array;\nimport java.sql.PreparedStatement;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Map;\n\nimport org.springframework.ai.chat.metadata.EmptyUsage;\nimport org.springframework.ai.document.Document;\nimport org.springframework.ai.document.MetadataMode;\nimport org.springframework.ai.embedding.AbstractEmbeddingModel;\nimport org.springframework.ai.embedding.Embedding;\nimport org.springframework.ai.embedding.EmbeddingOptions;\nimport org.springframework.ai.embedding.EmbeddingRequest;\nimport org.springframework.ai.embedding.EmbeddingResponse;\nimport org.springframework.ai.embedding.EmbeddingResponseMetadata;\nimport org.springframework.ai.model.EmbeddingUtils;\nimport org.springframework.ai.model.ModelOptionsUtils;\nimport org.springframework.beans.factory.InitializingBean;\nimport org.springframework.jdbc.core.JdbcTemplate;\nimport org.springframework.jdbc.core.RowMapper;\nimport org.springframework.util.Assert;\nimport org.springframework.util.CollectionUtils;\nimport org.springframework.util.StringUtils;\n\n/**\n * <a href=\"https://postgresml.org\">PostgresML</a> EmbeddingModel\n *\n * @author Toshiaki Maki\n * @author Christian Tzolov\n */\npublic class PostgresMlEmbeddingModel extends AbstractEmbeddingModel implements InitializingBean {\n\n\tpublic static final String DEFAULT_TRANSFORMER_MODEL = \"distilbert-base-uncased\";\n\n\tprivate final PostgresMlEmbeddingOptions defaultOptions;\n\n\tprivate final JdbcTemplate jdbcTemplate;\n\n\tpublic enum VectorType {\n\n\t\tPG_ARRAY(\"\", null, (rs, i) -> {\n\t\t\tArray embedding = rs.getArray(\"embedding\");\n\t\t\treturn EmbeddingUtils.toPrimitive((Float[]) embedding.getArray());\n\n\t\t}),\n\n\t\tPG_VECTOR(\"::vector\", \"vector\", (rs, i) -> {\n\t\t\tString embedding = rs.getString(\"embedding\");\n\t\t\treturn EmbeddingUtils.toPrimitive(Arrays.stream((embedding.substring(1, embedding.length() - 1)\n\t\t\t\t/* remove leading '[' and trailing ']' */.split(\",\"))).map(Float::parseFloat).toList());\n\t\t});\n\n\t\tprivate final String cast;\n\n\t\tprivate final String extensionName;\n\n\t\tprivate final RowMapper<float[]> rowMapper;\n\n\t\tVectorType(String cast, String extensionName, RowMapper<float[]> rowMapper) {\n\t\t\tthis.cast = cast;\n\t\t\tthis.extensionName = extensionName;\n\t\t\tthis.rowMapper = rowMapper;\n\t\t}\n\n\t}\n\n\t/**\n\t * a constructor\n\t * @param jdbcTemplate JdbcTemplate\n\t */\n\tpublic PostgresMlEmbeddingModel(JdbcTemplate jdbcTemplate) {\n\t\tthis(jdbcTemplate, PostgresMlEmbeddingOptions.builder().build());\n\t}\n\n\t/**\n\t * a PostgresMlEmbeddingModel constructor\n\t * @param jdbcTemplate JdbcTemplate to use to interact with the database.\n\t * @param options PostgresMlEmbeddingOptions to configure the client.\n\t */\n\tpublic PostgresMlEmbeddingModel(JdbcTemplate jdbcTemplate, PostgresMlEmbeddingOptions options) {\n\t\tAssert.notNull(jdbcTemplate, \"jdbc template must not be null.\");\n\t\tAssert.notNull(options, \"options must not be null.\");\n\t\tAssert.notNull(options.getTransformer(), \"transformer must not be null.\");\n\t\tAssert.notNull(options.getVectorType(), \"vectorType must not be null.\");\n\t\tAssert.notNull(options.getKwargs(), \"kwargs must not be null.\");\n\t\tAssert.notNull(options.getMetadataMode(), \"metadataMode must not be null.\");\n\n\t\tthis.jdbcTemplate = jdbcTemplate;\n\t\tthis.defaultOptions = options;\n\t}\n\n\t/**\n\t * a constructor\n\t * @param jdbcTemplate JdbcTemplate\n\t * @param transformer huggingface sentence-transformer name\n\t */\n\t@Deprecated(since = \"0.8.0\", forRemoval = true)\n\tpublic PostgresMlEmbeddingModel(JdbcTemplate jdbcTemplate, String transformer) {\n\t\tthis(jdbcTemplate, transformer, VectorType.PG_ARRAY);\n\t}\n\n\t/**\n\t * a constructor\n\t * @deprecated Use the constructor with {@link PostgresMlEmbeddingOptions} instead.\n\t * @param jdbcTemplate JdbcTemplate\n\t * @param transformer huggingface sentence-transformer name\n\t * @param vectorType vector type in PostgreSQL\n\t */\n\t@Deprecated(since = \"0.8.0\", forRemoval = true)\n\tpublic PostgresMlEmbeddingModel(JdbcTemplate jdbcTemplate, String transformer, VectorType vectorType) {\n\t\tthis(jdbcTemplate, transformer, vectorType, Map.of(), MetadataMode.EMBED);\n\t}\n\n\t/**\n\t * a constructor * @deprecated Use the constructor with\n\t * {@link PostgresMlEmbeddingOptions} instead.\n\t * @param jdbcTemplate JdbcTemplate\n\t * @param transformer huggingface sentence-transformer name\n\t * @param vectorType vector type in PostgreSQL\n\t * @param kwargs optional arguments\n\t */\n\t@Deprecated(since = \"0.8.0\", forRemoval = true)\n\tpublic PostgresMlEmbeddingModel(JdbcTemplate jdbcTemplate, String transformer, VectorType vectorType,\n\t\t\tMap<String, Object> kwargs, MetadataMode metadataMode) {\n\t\tAssert.notNull(jdbcTemplate, \"jdbc template must not be null.\");\n\t\tAssert.notNull(transformer, \"transformer must not be null.\");\n\t\tAssert.notNull(vectorType, \"vectorType must not be null.\");\n\t\tAssert.notNull(kwargs, \"kwargs must not be null.\");\n\t\tAssert.notNull(metadataMode, \"metadataMode must not be null.\");\n\n\t\tthis.jdbcTemplate = jdbcTemplate;\n\n\t\tthis.defaultOptions = PostgresMlEmbeddingOptions.builder()\n\t\t\t.withTransformer(transformer)\n\t\t\t.withVectorType(vectorType)\n\t\t\t.withMetadataMode(metadataMode)\n\t\t\t.withKwargs(ModelOptionsUtils.toJsonString(kwargs))\n\t\t\t.build();\n\t}\n\n\t@SuppressWarnings(\"null\")\n\t@Override\n\tpublic float[] embed(String text) {\n\t\treturn this.jdbcTemplate.queryForObject(\n\t\t\t\t\"SELECT pgml.embed(?, ?, ?::JSONB)\" + this.defaultOptions.getVectorType().cast + \" AS embedding\",\n\t\t\t\tthis.defaultOptions.getVectorType().rowMapper, this.defaultOptions.getTransformer(), text,\n\t\t\t\tthis.defaultOptions.getKwargs());\n\t}\n\n\t@Override\n\tpublic float[] embed(Document document) {\n\t\treturn this.embed(document.getFormattedContent(this.defaultOptions.getMetadataMode()));\n\t}\n\n\t@SuppressWarnings(\"null\")\n\t@Override\n\tpublic EmbeddingResponse call(EmbeddingRequest request) {\n\n\t\tfinal PostgresMlEmbeddingOptions optionsToUse = this.mergeOptions(request.getOptions());\n\n\t\tList<Embedding> data = new ArrayList<>();\n\t\tList<float[]> embed = List.of();\n\n\t\tList<String> texts = request.getInstructions();\n\t\tif (!CollectionUtils.isEmpty(texts)) {\n\t\t\tembed = this.jdbcTemplate.query(connection -> {\n\t\t\t\tPreparedStatement preparedStatement = connection.prepareStatement(\"SELECT pgml.embed(?, text, ?::JSONB)\"\n\t\t\t\t\t\t+ optionsToUse.getVectorType().cast + \" AS embedding FROM (SELECT unnest(?) AS text) AS texts\");\n\t\t\t\tpreparedStatement.setString(1, optionsToUse.getTransformer());\n\t\t\t\tpreparedStatement.setString(2, ModelOptionsUtils.toJsonString(optionsToUse.getKwargs()));\n\t\t\t\tpreparedStatement.setArray(3, connection.createArrayOf(\"TEXT\", texts.toArray(Object[]::new)));\n\t\t\t\treturn preparedStatement;\n\t\t\t}, rs -> {\n\t\t\t\tList<float[]> result = new ArrayList<>();\n\t\t\t\twhile (rs.next()) {\n\t\t\t\t\tresult.add(optionsToUse.getVectorType().rowMapper.mapRow(rs, -1));\n\t\t\t\t}\n\t\t\t\treturn result;\n\t\t\t});\n\t\t}\n\n\t\tif (!CollectionUtils.isEmpty(embed)) {\n\t\t\tfor (int i = 0; i < embed.size(); i++) {\n\t\t\t\tdata.add(new Embedding(embed.get(i), i));\n\t\t\t}\n\t\t}\n\n\t\tMap<String, Object> embeddingMetadata = Map.of(\"transformer\", optionsToUse.getTransformer(), \"vector-type\",\n\t\t\t\toptionsToUse.getVectorType().name(), \"kwargs\",\n\t\t\t\tModelOptionsUtils.toJsonString(optionsToUse.getKwargs()));\n\t\tvar embeddingResponseMetadata = new EmbeddingResponseMetadata(\"unknown\", new EmptyUsage(), embeddingMetadata);\n\t\treturn new EmbeddingResponse(data, embeddingResponseMetadata);\n\t}\n\n\t/**\n\t * Merge the default and request options.\n\t * @param requestOptions request options to merge.\n\t * @return the merged options.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\t@Override\n\tpublic void afterPropertiesSet() {\n\t\tthis.jdbcTemplate.execute(\"CREATE EXTENSION IF NOT EXISTS pgml\");\n\t\tthis.jdbcTemplate.execute(\"CREATE EXTENSION IF NOT EXISTS hstore\");\n\t\tif (StringUtils.hasText(this.defaultOptions.getVectorType().extensionName)) {\n\t\t\tthis.jdbcTemplate\n\t\t\t\t.execute(\"CREATE EXTENSION IF NOT EXISTS \" + this.defaultOptions.getVectorType().extensionName);\n\t\t}\n\t}\n\n}\n\n```\n# Function Signature: PostgresMlEmbeddingOptions mergeOptions(EmbeddingOptions requestOptions) {\n# Natural Language Annotations: /**\n\t * Merge the default and request options.\n\t * @param requestOptions request options to merge.\n\t * @return the merged options.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n  public PostgresMlEmbeddingOptions mergeOptions(EmbeddingOptions requestOptions) {\n    PostgresMlEmbeddingOptions optionsToUse = this.defaultOptions;\n    if (requestOptions != null) {\n      optionsToUse = PostgresMlEmbeddingOptions.builder()\n        .withTransformer(requestOptions.getTransformer() != null ? requestOptions.getTransformer() : optionsToUse.getTransformer())\n        .withVectorType(requestOptions.getVectorType() != null ? requestOptions.getVectorType() : optionsToUse.getVectorType())\n        .withKwargs(requestOptions.getKwargs() != null ? requestOptions.getKwargs() : optionsToUse.getKwargs())\n        .withMetadataMode(requestOptions.getMetadataMode() != null ? requestOptions.getMetadataMode() : optionsToUse.getMetadataMode())\n        .build();\n    }\n    return optionsToUse;\n  }\n```", "  ```java\n@Override\npublic PostgresMlEmbeddingOptions mergeOptions(EmbeddingOptions requestOptions) {\n    Assert.notNull(requestOptions, \"request options must not be null.\");\n\n    return PostgresMlEmbeddingOptions.builder()\n            .withTransformer(requestOptions.getTransformer())\n            .withVectorType(requestOptions.getKwargs().get(\"vectorType\"))\n            .withKwargs(requestOptions.getKwargs())\n            .withMetadataMode(requestOptions.getKwargs().get(\"metadataMode\"))\n            .build();\n}\n```", "  ```\npublic PostgresMlEmbeddingOptions mergeOptions(EmbeddingOptions requestOptions) {\n    if (requestOptions == null) {\n        return this.defaultOptions;\n    }\n\n    // Create a copy of the default options\n    PostgresMlEmbeddingOptions optionsToUse = this.defaultOptions.copy();\n\n    if (requestOptions.getTransformer() != null) {\n        optionsToUse.transformer = requestOptions.getTransformer();\n    }\n\n    if (requestOptions.getVectorType() != null) {\n        optionsToUse.vectorType = requestOptions.getVectorType();\n    }\n\n    if (requestOptions.getMetadataMode() != null) {\n        optionsToUse.metadataMode = requestOptions.getMetadataMode();\n    }\n\n    if (requestOptions.getKwargs() != null) {\n        optionsToUse.kwargs = ModelOptionsUtils.updateKwargs(optionsToUse.kwargs, requestOptions.getKwargs());\n    }\n\n    return optionsToUse;\n}\n```"]}, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/embedding/AbstractEmbeddingModel.java-dimensions": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/spring-ai-core/src/main/java/org/springframework/ai/embedding/AbstractEmbeddingModel.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.embedding;\n\nimport java.io.IOException;\nimport java.util.Map;\nimport java.util.Properties;\nimport java.util.concurrent.atomic.AtomicInteger;\nimport java.util.stream.Collectors;\n\nimport org.springframework.core.io.DefaultResourceLoader;\n\n/**\n * Abstract implementation of the {@link EmbeddingModel} interface that provides\n * dimensions calculation caching.\n *\n * @author Christian Tzolov\n */\npublic abstract class AbstractEmbeddingModel implements EmbeddingModel {\n\n\tprotected final AtomicInteger embeddingDimensions = new AtomicInteger(-1);\n\n\tprivate static Map<String, Integer> KNOWN_EMBEDDING_DIMENSIONS = loadKnownModelDimensions();\n\n\t/**\n\t * Return the dimension of the requested embedding generative name. If the generative\n\t * name is unknown uses the EmbeddingModel to perform a dummy EmbeddingModel#embed and\n\t * count the response dimensions.\n\t * @param embeddingModel Fall-back client to determine, empirically the dimensions.\n\t * @param modelName Embedding generative name to retrieve the dimensions for.\n\t * @param dummyContent Dummy content to use for the empirical dimension calculation.\n\t * @return Returns the embedding dimensions for the modelName.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\tprivate static Map<String, Integer> loadKnownModelDimensions() {\n\t\ttry {\n\t\t\tProperties properties = new Properties();\n\t\t\tproperties.load(new DefaultResourceLoader()\n\t\t\t\t.getResource(\"classpath:/embedding/embedding-model-dimensions.properties\")\n\t\t\t\t.getInputStream());\n\t\t\treturn properties.entrySet()\n\t\t\t\t.stream()\n\t\t\t\t.collect(Collectors.toMap(e -> e.getKey().toString(), e -> Integer.parseInt(e.getValue().toString())));\n\t\t}\n\t\tcatch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t@Override\n\tpublic int dimensions() {\n\t\tif (this.embeddingDimensions.get() < 0) {\n\t\t\tthis.embeddingDimensions.set(dimensions(this, \"Test\", \"Hello World\"));\n\t\t}\n\t\treturn this.embeddingDimensions.get();\n\t}\n\n}\n\n```\n# Function Signature: public static int dimensions(EmbeddingModel embeddingModel, String modelName, String dummyContent) {\n# Natural Language Annotations: /**\n\t * Return the dimension of the requested embedding generative name. If the generative\n\t * name is unknown uses the EmbeddingModel to perform a dummy EmbeddingModel#embed and\n\t * count the response dimensions.\n\t * @param embeddingModel Fall-back client to determine, empirically the dimensions.\n\t * @param modelName Embedding generative name to retrieve the dimensions for.\n\t * @param dummyContent Dummy content to use for the empirical dimension calculation.\n\t * @return Returns the embedding dimensions for the modelName.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static int dimensions(EmbeddingModel embeddingModel, String modelName, String dummyContent) {\n    if (KNOWN_EMBEDDING_DIMENSIONS.containsKey(modelName)) {\n        return KNOWN_EMBEDDING_DIMENSIONS.get(modelName);\n    }\n    return embeddingModel.embed(dummyContent).length;\n}\n```", "  ```\npublic static int dimensions(EmbeddingModel embeddingModel, String modelName, String dummyContent) {\n\t\tif (KNOWN_EMBEDDING_DIMENSIONS.containsKey(modelName)) {\n\t\t\treturn KNOWN_EMBEDDING_DIMENSIONS.get(modelName);\n\t\t}\n\t\telse {\n\t\t\tint[] dimensions = embeddingModel.embed(dummyContent);\n\t\t\treturn dimensions.length;\n\t\t}\n\t}\n```", "  ```\npublic static int dimensions(EmbeddingModel embeddingModel, String modelName, String dummyContent) {\n    int dimensions = -1;\n\n    // If the dimensions are already known for the requested model, return them\n    if (KNOWN_EMBEDDING_DIMENSIONS.containsKey(modelName)) {\n        dimensions = KNOWN_EMBEDDING_DIMENSIONS.get(modelName);\n    }\n    else {\n        // Otherwise, use the embedding model to perform a dummy embed and count the response dimensions\n        try {\n            embeddingModel.embed(dummyContent);\n            dimensions = embeddingModel.dimensions();\n            KNOWN_EMBEDDING_DIMENSIONS.put(modelName, dimensions);\n        }\n        catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    return dimensions;\n}\n```"]}, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/chat/metadata/PromptMetadata.java-findByPromptIndex": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/spring-ai-core/src/main/java/org/springframework/ai/chat/metadata/PromptMetadata.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.chat.metadata;\n\nimport java.util.Arrays;\nimport java.util.Optional;\nimport java.util.stream.StreamSupport;\n\nimport org.springframework.util.Assert;\n\n/**\n * Abstract Data Type (ADT) modeling metadata gathered by the AI during request\n * processing.\n *\n * @author John Blum\n * @since 0.7.0\n */\n@FunctionalInterface\npublic interface PromptMetadata extends Iterable<PromptMetadata.PromptFilterMetadata> {\n\n\t/**\n\t * Factory method used to create empty {@link PromptMetadata} when the information is\n\t * not supplied by the AI provider.\n\t * @return empty {@link PromptMetadata}.\n\t */\n\tstatic PromptMetadata empty() {\n\t\treturn of();\n\t}\n\n\t/**\n\t * Factory method used to create a new {@link PromptMetadata} composed of an array of\n\t * {@link PromptFilterMetadata}.\n\t * @param array array of {@link PromptFilterMetadata} used to compose the\n\t * {@link PromptMetadata}.\n\t * @return a new {@link PromptMetadata} composed of an array of\n\t * {@link PromptFilterMetadata}.\n\t */\n\tstatic PromptMetadata of(PromptFilterMetadata... array) {\n\t\treturn of(Arrays.asList(array));\n\t}\n\n\t/**\n\t * Factory method used to create a new {@link PromptMetadata} composed of an\n\t * {@link Iterable} of {@link PromptFilterMetadata}.\n\t * @param iterable {@link Iterable} of {@link PromptFilterMetadata} used to compose\n\t * the {@link PromptMetadata}.\n\t * @return a new {@link PromptMetadata} composed of an {@link Iterable} of\n\t * {@link PromptFilterMetadata}.\n\t */\n\tstatic PromptMetadata of(Iterable<PromptFilterMetadata> iterable) {\n\t\tAssert.notNull(iterable, \"An Iterable of PromptFilterMetadata must not be null\");\n\t\treturn iterable::iterator;\n\t}\n\n\t/**\n\t * Returns an {@link Optional} {@link PromptFilterMetadata} at the given index.\n\t * @param promptIndex index of the {@link PromptFilterMetadata} contained in this\n\t * {@link PromptMetadata}.\n\t * @return {@link Optional} {@link PromptFilterMetadata} at the given index.\n\t * @throws IllegalArgumentException if the prompt index is less than 0.\n\t */\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Abstract Data Type (ADT) modeling filter metadata for all prompts sent during an AI\n\t * request.\n\t */\n\tinterface PromptFilterMetadata {\n\n\t\t/**\n\t\t * Factory method used to construct a new {@link PromptFilterMetadata} with the\n\t\t * given prompt index and content filter metadata.\n\t\t * @param promptIndex index of the prompt filter metadata contained in the AI\n\t\t * response.\n\t\t * @param contentFilterMetadata underlying AI provider metadata for filtering\n\t\t * applied to prompt content.\n\t\t * @return a new instance of {@link PromptFilterMetadata} with the given prompt\n\t\t * index and content filter metadata.\n\t\t */\n\t\tstatic PromptFilterMetadata from(int promptIndex, Object contentFilterMetadata) {\n\n\t\t\treturn new PromptFilterMetadata() {\n\n\t\t\t\t@Override\n\t\t\t\tpublic int getPromptIndex() {\n\t\t\t\t\treturn promptIndex;\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\tpublic <T> T getContentFilterMetadata() {\n\t\t\t\t\treturn (T) contentFilterMetadata;\n\t\t\t\t}\n\t\t\t};\n\t\t}\n\n\t\t/**\n\t\t * Index of the prompt filter metadata contained in the AI response.\n\t\t * @return an {@link Integer index} fo the prompt filter metadata contained in the\n\t\t * AI response.\n\t\t */\n\t\tint getPromptIndex();\n\n\t\t/**\n\t\t * Returns the underlying AI provider metadata for filtering applied to prompt\n\t\t * content.\n\t\t * @param <T> {@link Class Type} used to cast the filtered content metadata into\n\t\t * the AI provider-specific type.\n\t\t * @return the underlying AI provider metadata for filtering applied to prompt\n\t\t * content.\n\t\t */\n\t\t<T> T getContentFilterMetadata();\n\n\t}\n\n}\n\n```\n# Function Signature: default Optional<PromptFilterMetadata> findByPromptIndex(int promptIndex) {\n# Natural Language Annotations: /**\n\t * Returns an {@link Optional} {@link PromptFilterMetadata} at the given index.\n\t * @param promptIndex index of the {@link PromptFilterMetadata} contained in this\n\t * {@link PromptMetadata}.\n\t * @return {@link Optional} {@link PromptFilterMetadata} at the given index.\n\t * @throws IllegalArgumentException if the prompt index is less than 0.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\npublic Optional<PromptFilterMetadata> findByPromptIndex(int promptIndex) {\n    Assert.isTrue(promptIndex >= 0, \"Prompt index must not be less than 0\");\n\n    return StreamSupport.stream(this.spliterator(), false)\n            .filter(promptFilterMetadata -> promptIndex == promptFilterMetadata.getPromptIndex())\n            .findFirst();\n}\n```", "  ```\npublic Optional<PromptFilterMetadata> findByPromptIndex(int promptIndex) {\n    Assert.isTrue(promptIndex >= 0, \"Prompt index must be greater than or equal to 0\");\n    return StreamSupport.stream(spliterator(), false).filter(item -> item.getPromptIndex() == promptIndex).findFirst();\n}\n```", "  ```\npublic Optional<PromptFilterMetadata> findByPromptIndex(int promptIndex) {\n    Assert.isTrue(promptIndex >= 0, \"Prompt index must be greater than or equal to 0\");\n    return StreamSupport.stream(spliterator(), false)\n            .filter(metadata -> Objects.equals(metadata.getPromptIndex(), promptIndex))\n            .findFirst();\n}\n```"]}, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/chat/metadata/Usage.java-getTotalTokens": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/spring-ai-core/src/main/java/org/springframework/ai/chat/metadata/Usage.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.chat.metadata;\n\n/**\n * Abstract Data Type (ADT) encapsulating metadata on the usage of an AI provider's API\n * per AI request.\n *\n * @author John Blum\n * @since 0.7.0\n */\npublic interface Usage {\n\n\t/**\n\t * Returns the number of tokens used in the {@literal prompt} of the AI request.\n\t * @return an {@link Long} with the number of tokens used in the {@literal prompt} of\n\t * the AI request.\n\t * @see #getGenerationTokens()\n\t */\n\tLong getPromptTokens();\n\n\t/**\n\t * Returns the number of tokens returned in the {@literal generation (aka completion)}\n\t * of the AI's response.\n\t * @return an {@link Long} with the number of tokens returned in the\n\t * {@literal generation (aka completion)} of the AI's response.\n\t * @see #getPromptTokens()\n\t */\n\tLong getGenerationTokens();\n\n\t/**\n\t * Return the total number of tokens from both the {@literal prompt} of an AI request\n\t * and {@literal generation} of the AI's response.\n\t * @return the total number of tokens from both the {@literal prompt} of an AI request\n\t * and {@literal generation} of the AI's response.\n\t * @see #getPromptTokens()\n\t * @see #getGenerationTokens()\n\t */\n\n\n\n\n\n\n\n\n}\n\n```\n# Function Signature: default Long getTotalTokens() {\n# Natural Language Annotations: /**\n\t * Return the total number of tokens from both the {@literal prompt} of an AI request\n\t * and {@literal generation} of the AI's response.\n\t * @return the total number of tokens from both the {@literal prompt} of an AI request\n\t * and {@literal generation} of the AI's response.\n\t * @see #getPromptTokens()\n\t * @see #getGenerationTokens()\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\npublic Long getTotalTokens() {\n    return getPromptTokens() + getGenerationTokens();\n}\n```", "  ```java\ndefault Long getTotalTokens() {\n    return getPromptTokens() + getGenerationTokens();\n}\n```\nThis function uses the `+` operator to add the result of `getPromptTokens()` and `getGenerationTokens()` together, returning the sum as the total number of tokens.\n\nNote that since this is an interface method, it is defined as `default`, which means that it provides a default implementation of the method that can be overridden in implementing classes.", "  ```\nprivate static long getTotalTokens(Usage usage) {\n    return usage.getGenerationTokens() + usage.getPromptTokens();\n}\n```\nExplanation:\n\nThe `getTotalTokens` method takes a `Usage` object as a parameter and returns the total number of tokens used in both the prompt and generation of the AI's response.\n\nThe method first gets the number of tokens used in the `prompt` by calling the `getGenerationTokens` method on the `usage` object.\n\nThen, it gets the number of tokens returned in the `generation` by calling the `getPromptTokens` method on the `usage` object.\n\nFinally, it adds the two numbers together to get the total number of tokens used.\n\nNote that this method does not mutate the `usage` object or any of its properties. It purely returns the total number of tokens used."]}, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/vectorstore/filter/FilterHelper.java-negate": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/spring-ai-core/src/main/java/org/springframework/ai/vectorstore/filter/FilterHelper.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.vectorstore.filter;\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\n\nimport org.springframework.ai.vectorstore.filter.Filter.Expression;\nimport org.springframework.ai.vectorstore.filter.Filter.ExpressionType;\nimport org.springframework.ai.vectorstore.filter.Filter.Operand;\nimport org.springframework.util.Assert;\n\n/**\n * Helper class providing various boolean transformation.\n *\n * @author Christian Tzolov\n */\npublic class FilterHelper {\n\n\tprivate FilterHelper() {\n\t}\n\n\tprivate final static Map<ExpressionType, ExpressionType> TYPE_NEGATION_MAP = Map.of(ExpressionType.AND,\n\t\t\tExpressionType.OR, ExpressionType.OR, ExpressionType.AND, ExpressionType.EQ, ExpressionType.NE,\n\t\t\tExpressionType.NE, ExpressionType.EQ, ExpressionType.GT, ExpressionType.LTE, ExpressionType.GTE,\n\t\t\tExpressionType.LT, ExpressionType.LT, ExpressionType.GTE, ExpressionType.LTE, ExpressionType.GT,\n\t\t\tExpressionType.IN, ExpressionType.NIN, ExpressionType.NIN, ExpressionType.IN);\n\n\t/**\n\t * Transforms the input expression into a semantically equivalent one with negation\n\t * operators propagated thought the expression tree by following the negation rules:\n\t *\n\t * <pre>\n\t * \tNOT(NOT(a)) = a\n\t *\n\t * \tNOT(a AND b) = NOT(a) OR NOT(b)\n\t * \tNOT(a OR b) = NOT(a) AND NOT(b)\n\t *\n\t * \tNOT(a EQ b) = a NE b\n\t * \tNOT(a NE b) = a EQ b\n\t *\n\t * \tNOT(a GT b) = a LTE b\n\t * \tNOT(a GTE b) = a LT b\n\t *\n\t * \tNOT(a LT b) = a GTE b\n\t * \tNOT(a LTE b) = a GT b\n\t *\n\t * \tNOT(a IN [...]) = a NIN [...]\n\t * \tNOT(a NIN [...]) = a IN [...]\n\t * </pre>\n\t * @param operand Filter expression to negate.\n\t * @return Returns an negation of the input expression.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Expands the IN into a semantically equivalent boolean expressions of ORs of EQs.\n\t * Useful for providers that don't provide native IN support.\n\t *\n\t * For example the <pre>\n\t * foo IN [\"bar1\", \"bar2\", \"bar3\"]\n\t * </pre>\n\t *\n\t * expression is equivalent to\n\t *\n\t * <pre>\n\t * {@code foo == \"bar1\" || foo == \"bar2\" || foo == \"bar3\" (e.g. OR(foo EQ \"bar1\" OR(foo EQ \"bar2\" OR(foo EQ \"bar3\")))}\n\t * </pre>\n\t * @param exp input IN expression.\n\t * @param context Output native expression.\n\t * @param filterExpressionConverter {@link FilterExpressionConverter} used to compose\n\t * the OR and EQ expanded expressions.\n\t */\n\tpublic static void expandIn(Expression exp, StringBuilder context,\n\t\t\tFilterExpressionConverter filterExpressionConverter) {\n\t\tAssert.isTrue(exp.type() == ExpressionType.IN, \"Expected IN expressions but was: \" + exp.type());\n\t\texpandInNinExpressions(ExpressionType.OR, ExpressionType.EQ, exp, context, filterExpressionConverter);\n\t}\n\n\t/**\n\t *\n\t * Expands the NIN (e.g. NOT IN) into a semantically equivalent boolean expressions of\n\t * ANDs of NEs. Useful for providers that don't provide native NIN support.<br/>\n\t *\n\t * For example the\n\t *\n\t * <pre>\n\t * foo NIN [\"bar1\", \"bar2\", \"bar3\"] (or foo NOT IN [\"bar1\", \"bar2\", \"bar3\"])\n\t * </pre>\n\t *\n\t * express is equivalent to\n\t *\n\t * <pre>\n\t * {@code foo != \"bar1\" && foo != \"bar2\" && foo != \"bar3\" (e.g. AND(foo NE \"bar1\" AND( foo NE \"bar2\" OR(foo NE \"bar3\"))) )}\n\t * </pre>\n\t * @param exp input NIN expression.\n\t * @param context Output native expression.\n\t * @param filterExpressionConverter {@link FilterExpressionConverter} used to compose\n\t * the AND and NE expanded expressions.\n\t */\n\tpublic static void expandNin(Expression exp, StringBuilder context,\n\t\t\tFilterExpressionConverter filterExpressionConverter) {\n\t\tAssert.isTrue(exp.type() == ExpressionType.NIN, \"Expected NIN expressions but was: \" + exp.type());\n\t\texpandInNinExpressions(ExpressionType.AND, ExpressionType.NE, exp, context, filterExpressionConverter);\n\t}\n\n\tprivate static void expandInNinExpressions(Filter.ExpressionType outerExpressionType,\n\t\t\tFilter.ExpressionType innerExpressionType, Expression exp, StringBuilder context,\n\t\t\tFilterExpressionConverter expressionConverter) {\n\t\tif (exp.right() instanceof Filter.Value value) {\n\t\t\tif (value.value() instanceof List list) {\n\t\t\t\t// 1. foo IN [\"bar1\", \"bar2\", \"bar3\"] is equivalent to foo == \"bar1\" ||\n\t\t\t\t// foo == \"bar2\" || foo == \"bar3\"\n\t\t\t\t// or equivalent to OR(foo == \"bar1\" OR( foo == \"bar2\" OR(foo == \"bar3\")))\n\t\t\t\t// 2. foo IN [\"bar1\", \"bar2\", \"bar3\"] is equivalent to foo != \"bar1\" &&\n\t\t\t\t// foo != \"bar2\" && foo != \"bar3\"\n\t\t\t\t// or equivalent to AND(foo != \"bar1\" AND( foo != \"bar2\" OR(foo !=\n\t\t\t\t// \"bar3\")))\n\t\t\t\tList<Filter.Expression> eqExprs = new ArrayList<>();\n\t\t\t\tfor (Object o : list) {\n\t\t\t\t\teqExprs.add(new Filter.Expression(innerExpressionType, exp.left(), new Filter.Value(o)));\n\t\t\t\t}\n\t\t\t\tcontext.append(expressionConverter.convertExpression(aggregate(outerExpressionType, eqExprs)));\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// 1. foo IN [\"bar\"] is equivalent to foo == \"BAR\"\n\t\t\t\t// 2. foo NIN [\"bar\"] is equivalent to foo != \"BAR\"\n\t\t\t\tcontext.append(expressionConverter\n\t\t\t\t\t.convertExpression(new Filter.Expression(innerExpressionType, exp.left(), exp.right())));\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Filter IN right expression should be of Filter.Value type but was \" + exp.right().getClass());\n\t\t}\n\t}\n\n\t/**\n\t * Recursively aggregates a list of expression into a binary tree with 'aggregateType'\n\t * join nodes.\n\t * @param aggregateType type all tree splits.\n\t * @param expressions list of expressions to aggregate.\n\t * @return Returns a binary tree expression.\n\t */\n\tprivate static Filter.Expression aggregate(Filter.ExpressionType aggregateType,\n\t\t\tList<Filter.Expression> expressions) {\n\n\t\tif (expressions.size() == 1) {\n\t\t\treturn expressions.get(0);\n\t\t}\n\t\treturn new Filter.Expression(aggregateType, expressions.get(0),\n\t\t\t\taggregate(aggregateType, expressions.subList(1, expressions.size())));\n\t}\n\n}\n\n```\n# Function Signature: public static Filter.Operand negate(Filter.Operand operand) {\n# Natural Language Annotations: /**\n\t * Transforms the input expression into a semantically equivalent one with negation\n\t * operators propagated thought the expression tree by following the negation rules:\n\t *\n\t * <pre>\n\t * \tNOT(NOT(a)) = a\n\t *\n\t * \tNOT(a AND b) = NOT(a) OR NOT(b)\n\t * \tNOT(a OR b) = NOT(a) AND NOT(b)\n\t *\n\t * \tNOT(a EQ b) = a NE b\n\t * \tNOT(a NE b) = a EQ b\n\t *\n\t * \tNOT(a GT b) = a LTE b\n\t * \tNOT(a GTE b) = a LT b\n\t *\n\t * \tNOT(a LT b) = a GTE b\n\t * \tNOT(a LTE b) = a GT b\n\t *\n\t * \tNOT(a IN [...]) = a NIN [...]\n\t * \tNOT(a NIN [...]) = a IN [...]\n\t * </pre>\n\t * @param operand Filter expression to negate.\n\t * @return Returns an negation of the input expression.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  \n[PYTHON]\ndef negate(operand):\n    if operand.type == ExpressionType.NOT:\n        return operand.operand\n    elif operand.type == ExpressionType.AND:\n        return Expression(ExpressionType.OR, negate(operand.left), negate(operand.right))\n    elif operand.type == ExpressionType.OR:\n        return Expression(ExpressionType.AND, negate(operand.left), negate(operand.right))\n    elif operand.type == ExpressionType.EQ:\n        return Expression(ExpressionType.NE, operand.left, operand.right)\n    elif operand.type == ExpressionType.NE:\n        return Expression(ExpressionType.EQ, operand.left, operand.right)\n    elif operand.type == ExpressionType.GT:\n        return Expression(ExpressionType.LTE, operand.left, operand.right)\n    elif operand.type == ExpressionType.GTE:\n        return Expression(ExpressionType.LT, operand.left, operand.right)\n    elif operand.type == ExpressionType.LT:\n        return Expression(ExpressionType.GTE, operand.left, operand.right)\n    elif operand.type == ExpressionType.LTE:\n        return Expression(ExpressionType.GT, operand.left, operand.right)\n    elif operand.type == ExpressionType.IN:\n        return Expression(ExpressionType.NIN, operand.left, operand.right)\n    elif operand.type == ExpressionType.NIN:\n        return Expression(ExpressionType.IN, operand.left, operand.right)\n    else:\n        raise ValueError(f\"Unsupported operand type: {operand.type}\")\n[/PYTHON]\n[JAVA]\npublic static Filter.Operand negate(Filter.Operand operand) {\n    if (operand.getType() == ExpressionType.NOT) {\n        return operand.getOperand();\n    } else if (operand.getType() == ExpressionType.AND) {\n        return new Expression(ExpressionType.OR, negate(operand.getLeft()), negate(operand.getRight()));\n    } else if (operand.getType() == ExpressionType.OR) {\n        return new Expression(ExpressionType.AND, negate(operand.getLeft()), negate(operand.getRight()));\n    } else if (operand.getType() == ExpressionType.EQ) {\n        return new Expression(ExpressionType.NE, operand.getLeft(), operand.getRight());\n    } else if (operand.getType() == ExpressionType.NE) {\n        return new Expression(ExpressionType.EQ, operand.getLeft(), operand.getRight());\n    } else if (operand.getType() == ExpressionType.GT) {\n        return new Expression(ExpressionType.LTE, operand.getLeft(), operand.getRight());\n    } else if (operand.getType() == ExpressionType.GTE) {\n        return new Expression(ExpressionType.LT, operand.getLeft(), operand.getRight());\n    } else if (operand.getType() == ExpressionType.LT) {\n        return new Expression(ExpressionType.GTE, operand.getLeft(), operand.getRight());\n    } else if (operand.getType() == ExpressionType.LTE) {\n        return new Expression(ExpressionType.GT, operand.getLeft(), operand.getRight());\n    } else if (operand.getType() == ExpressionType.IN) {\n        return new Expression(ExpressionType.NIN, operand.getLeft(), operand.getRight());\n    } else if (operand.getType() == ExpressionType.NIN) {\n        return new Expression(ExpressionType.IN, operand.getLeft(), operand.getRight());\n    } else {\n        throw new IllegalArgumentException(\"Unsupported operand type: \" + operand.getType());\n    }\n}\n[/JAVA]\n", "  ```\npublic static Filter.Operand negate(Filter.Operand operand) {\n    switch (operand.getType()) {\n        case NOT:\n            return operand.getOperand();\n        case AND:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.AND),\n                    negate(operand.getLeft()),\n                    negate(operand.getRight()));\n        case OR:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.OR),\n                    negate(operand.getLeft()),\n                    negate(operand.getRight()));\n        case EQ:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.EQ),\n                    operand.getLeft(),\n                    operand.getRight());\n        case NE:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.NE),\n                    operand.getLeft(),\n                    operand.getRight());\n        case GT:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.GT),\n                    operand.getLeft(),\n                    operand.getRight());\n        case GTE:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.GTE),\n                    operand.getLeft(),\n                    operand.getRight());\n        case LT:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.LT),\n                    operand.getLeft(),\n                    operand.getRight());\n        case LTE:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.LTE),\n                    operand.getLeft(),\n                    operand.getRight());\n        case IN:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.IN),\n                    operand.getLeft(),\n                    operand.getRight());\n        case NIN:\n            return new Filter.Operand(\n                    TYPE_NEGATION_MAP.get(ExpressionType.NIN),\n                    operand.getLeft(),\n                    operand.getRight());\n        default:\n            throw new UnsupportedOperationException(\"Unsupported filter operand type: \" + operand.getType().name());\n    }\n}\n```", "  ```\npublic static Filter.Operand negate(Filter.Operand operand) {\n    switch (operand) {\n        case NOT(expr):\n            return expr;\n        case AND(left, right):\n            return OR(negate(left), negate(right));\n        case OR(left, right):\n            return AND(negate(left), negate(right));\n        case EQ(left, right):\n            return NE(left, right);\n        case NE(left, right):\n            return EQ(left, right);\n        case GT(left, right):\n            return LTE(left, right);\n        case GTE(left, right):\n            return LT(left, right);\n        case LT(left, right):\n            return GTE(left, right);\n        case LTE(left, right):\n            return GT(left, right);\n        case IN(var, arry):\n            return NIN(var, arry);\n        case NIN(var, arry):\n            return IN(var, arry);\n        default:\n            throw new IllegalArgumentException(\"Unsupported operand: \" + operand);\n    }\n}\n```"]}, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-merge": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.model;\n\nimport java.beans.PropertyDescriptor;\nimport java.lang.reflect.Field;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\n\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.DeserializationFeature;\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.SerializationFeature;\nimport com.fasterxml.jackson.databind.node.ArrayNode;\nimport com.fasterxml.jackson.databind.node.ObjectNode;\nimport com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;\nimport com.github.victools.jsonschema.generator.Option;\nimport com.github.victools.jsonschema.generator.OptionPreset;\nimport com.github.victools.jsonschema.generator.SchemaGenerator;\nimport com.github.victools.jsonschema.generator.SchemaGeneratorConfig;\nimport com.github.victools.jsonschema.generator.SchemaGeneratorConfigBuilder;\nimport com.github.victools.jsonschema.generator.SchemaVersion;\nimport com.github.victools.jsonschema.module.jackson.JacksonModule;\nimport com.github.victools.jsonschema.module.jackson.JacksonOption;\nimport com.github.victools.jsonschema.module.swagger2.Swagger2Module;\n\nimport org.springframework.beans.BeanWrapper;\nimport org.springframework.beans.BeanWrapperImpl;\nimport org.springframework.util.Assert;\nimport org.springframework.util.CollectionUtils;\nimport org.springframework.util.ObjectUtils;\n\n/**\n * Utility class for manipulating {@link ModelOptions} objects.\n *\n * @author Christian Tzolov\n * @author Thomas Vitale\n * @since 0.8.0\n */\npublic abstract class ModelOptionsUtils {\n\n\tpublic static final ObjectMapper OBJECT_MAPPER = new ObjectMapper()\n\t\t.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n\t\t.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS)\n\t\t.registerModule(new JavaTimeModule());\n\n\tprivate static final List<String> BEAN_MERGE_FIELD_EXCISIONS = List.of(\"class\");\n\n\tprivate static final ConcurrentHashMap<Class<?>, List<String>> REQUEST_FIELD_NAMES_PER_CLASS = new ConcurrentHashMap<Class<?>, List<String>>();\n\n\tprivate static final AtomicReference<SchemaGenerator> SCHEMA_GENERATOR_CACHE = new AtomicReference<>();\n\n\t/**\n\t * Converts the given JSON string to a Map of String and Object.\n\t * @param json the JSON string to convert to a Map.\n\t * @return the converted Map.\n\t */\n\tpublic static Map<String, Object> jsonToMap(String json) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.readValue(json, MAP_TYPE_REF);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\tprivate static TypeReference<HashMap<String, Object>> MAP_TYPE_REF = new TypeReference<HashMap<String, Object>>() {\n\t};\n\n\t/**\n\t * Converts the given JSON string to an Object of the given type.\n\t * @param <T> the type of the object to return.\n\t * @param json the JSON string to convert to an object.\n\t * @param type the type of the object to return.\n\t * @return Object instance of the given type.\n\t */\n\tpublic static <T> T jsonToObject(String json, Class<T> type) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.readValue(json, type);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"Failed to json: \" + json, e);\n\t\t}\n\t}\n\n\t/**\n\t * Converts the given object to a JSON string.\n\t * @param object the object to convert to a JSON string.\n\t * @return the JSON string.\n\t */\n\tpublic static String toJsonString(Object object) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.writeValueAsString(object);\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t/**\n\t * Merges the source object into the target object and returns an object represented\n\t * by the given class. The JSON property names are used to match the fields to merge.\n\t * The source non-null values override the target values with the same field name. The\n\t * source null values are ignored. If the acceptedFieldNames is not empty, only the\n\t * fields with the given names are merged and returned. If the acceptedFieldNames is\n\t * empty, use the {@code @JsonProperty} names, inferred from the provided clazz.\n\t * @param <T> they type of the class to return.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param clazz the class to return.\n\t * @param acceptedFieldNames the list of field names accepted for the target object.\n\t * @return the merged object represented by the given class.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Merges the source object into the target object and returns an object represented\n\t * by the given class. The JSON property names are used to match the fields to merge.\n\t * The source non-null values override the target values with the same field name. The\n\t * source null values are ignored. Returns the only field names that match the\n\t * {@code @JsonProperty} names, inferred from the provided clazz.\n\t * @param <T> they type of the class to return.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param clazz the class to return.\n\t * @return the merged object represented by the given class.\n\t */\n\tpublic static <T> T merge(Object source, Object target, Class<T> clazz) {\n\t\treturn ModelOptionsUtils.merge(source, target, clazz, null);\n\t}\n\n\t/**\n\t * Converts the given object to a Map.\n\t * @param source the object to convert to a Map.\n\t * @return the converted Map.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Converts the given Map to the given class.\n\t * @param <T> the type of the class to return.\n\t * @param source the Map to convert to the given class.\n\t * @param clazz the class to convert the Map to.\n\t * @return the converted class.\n\t */\n\tpublic static <T> T mapToClass(Map<String, Object> source, Class<T> clazz) {\n\t\ttry {\n\t\t\tString json = OBJECT_MAPPER.writeValueAsString(source);\n\t\t\treturn OBJECT_MAPPER.readValue(json, clazz);\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t/**\n\t * Returns the list of name values of the {@link JsonProperty} annotations.\n\t * @param clazz the class that contains fields annotated with {@link JsonProperty}.\n\t * @return the list of values of the {@link JsonProperty} annotations.\n\t */\n\tpublic static List<String> getJsonPropertyValues(Class<?> clazz) {\n\t\tList<String> values = new ArrayList<>();\n\t\tField[] fields = clazz.getDeclaredFields();\n\t\tfor (Field field : fields) {\n\t\t\tJsonProperty jsonPropertyAnnotation = field.getAnnotation(JsonProperty.class);\n\t\t\tif (jsonPropertyAnnotation != null) {\n\t\t\t\tvalues.add(jsonPropertyAnnotation.value());\n\t\t\t}\n\t\t}\n\t\treturn values;\n\t}\n\n\t/**\n\t * Returns a new instance of the targetBeanClazz that copies the bean values from the\n\t * sourceBean instance.\n\t * @param sourceBean the source bean to copy the values from.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are copied. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param targetBeanClazz the target class, a subclass of the ChatOptions, to convert\n\t * into.\n\t * @param <T> the target class type.\n\t * @return a new instance of the targetBeanClazz with the values from the sourceBean\n\t * instance.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Merges the source object into the target object. The source null values are\n\t * ignored. Only objects with Getter and Setter methods are supported.\n\t * @param <T> the type of the source and target object.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are merged. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param overrideNonNullTargetValues if true, the source non-null values override the\n\t * target values with the same field name. If false, the source non-null values are\n\t * ignored.\n\t * @return the merged target object.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\tprivate static String toGetName(String name) {\n\t\treturn \"get\" + name.substring(0, 1).toUpperCase() + name.substring(1);\n\t}\n\n\t/**\n\t * Generates JSON Schema (version 2020_12) for the given class.\n\t * @param clazz the class to generate JSON Schema for.\n\t * @param toUpperCaseTypeValues if true, the type values are converted to upper case.\n\t * @return the generated JSON Schema as a String.\n\t */\n\tpublic static String getJsonSchema(Class<?> clazz, boolean toUpperCaseTypeValues) {\n\n\t\tif (SCHEMA_GENERATOR_CACHE.get() == null) {\n\n\t\t\tJacksonModule jacksonModule = new JacksonModule(JacksonOption.RESPECT_JSONPROPERTY_REQUIRED);\n\t\t\tSwagger2Module swaggerModule = new Swagger2Module();\n\n\t\t\tSchemaGeneratorConfigBuilder configBuilder = new SchemaGeneratorConfigBuilder(SchemaVersion.DRAFT_2020_12,\n\t\t\t\t\tOptionPreset.PLAIN_JSON)\n\t\t\t\t.with(Option.EXTRA_OPEN_API_FORMAT_VALUES)\n\t\t\t\t.with(Option.PLAIN_DEFINITION_KEYS)\n\t\t\t\t.with(swaggerModule)\n\t\t\t\t.with(jacksonModule);\n\n\t\t\tSchemaGeneratorConfig config = configBuilder.build();\n\t\t\tSchemaGenerator generator = new SchemaGenerator(config);\n\t\t\tSCHEMA_GENERATOR_CACHE.compareAndSet(null, generator);\n\t\t}\n\n\t\tObjectNode node = SCHEMA_GENERATOR_CACHE.get().generateSchema(clazz);\n\t\tif (toUpperCaseTypeValues) { // Required for OpenAPI 3.0 (at least Vertex AI\n\t\t\t\t\t\t\t\t\t\t// version of it).\n\t\t\ttoUpperCaseTypeValues(node);\n\t\t}\n\n\t\treturn node.toPrettyString();\n\t}\n\n\tpublic static void toUpperCaseTypeValues(ObjectNode node) {\n\t\tif (node == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (node.isObject()) {\n\t\t\tnode.fields().forEachRemaining(entry -> {\n\t\t\t\tJsonNode value = entry.getValue();\n\t\t\t\tif (value.isObject()) {\n\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) value);\n\t\t\t\t}\n\t\t\t\telse if (value.isArray()) {\n\t\t\t\t\t((ArrayNode) value).elements().forEachRemaining(element -> {\n\t\t\t\t\t\tif (element.isObject() || element.isArray()) {\n\t\t\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) element);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t\telse if (value.isTextual() && entry.getKey().equals(\"type\")) {\n\t\t\t\t\tString oldValue = ((ObjectNode) node).get(\"type\").asText();\n\t\t\t\t\t((ObjectNode) node).put(\"type\", oldValue.toUpperCase());\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\telse if (node.isArray()) {\n\t\t\tnode.elements().forEachRemaining(element -> {\n\t\t\t\tif (element.isObject() || element.isArray()) {\n\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) element);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n\n\t/**\n\t * Return the runtime value if not empty, or else the default value.\n\t */\n\tpublic static <T> T mergeOption(T runtimeValue, T defaultValue) {\n\t\treturn ObjectUtils.isEmpty(runtimeValue) ? defaultValue : runtimeValue;\n\t}\n\n}\n\n```\n# Function Signature: public static <T> T merge(Object source, Object target, Class<T> clazz, List<String> acceptedFieldNames) {\n# Natural Language Annotations: /**\n\t * Merges the source object into the target object and returns an object represented\n\t * by the given class. The JSON property names are used to match the fields to merge.\n\t * The source non-null values override the target values with the same field name. The\n\t * source null values are ignored. If the acceptedFieldNames is not empty, only the\n\t * fields with the given names are merged and returned. If the acceptedFieldNames is\n\t * empty, use the {@code @JsonProperty} names, inferred from the provided clazz.\n\t * @param <T> they type of the class to return.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param clazz the class to return.\n\t * @param acceptedFieldNames the list of field names accepted for the target object.\n\t * @return the merged object represented by the given class.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <T> T merge(Object source, Object target, Class<T> clazz, List<String> acceptedFieldNames) {\n    List<String> fieldNames = acceptedFieldNames == null ? getJsonPropertyValues(clazz) : acceptedFieldNames;\n    BeanWrapper sourceBean = new BeanWrapperImpl(source);\n    BeanWrapper targetBean = new BeanWrapperImpl(target);\n    try {\n        T result = clazz.newInstance();\n        for (String fieldName : fieldNames) {\n            String getterMethod = toGetName(fieldName);\n            Object sourceValue = sourceBean.invokeGetterMethod(getterMethod, null);\n            if (ObjectUtils.isEmpty(sourceValue)) {\n                continue;\n            }\n            Object targetValue = targetBean.invokeGetterMethod(getterMethod, null);\n            if (ObjectUtils.isEmpty(targetValue)) {\n                sourceValue = sourceBean.getPropertyValue(fieldName);\n                targetBean.setPropertyValue(fieldName, sourceValue);\n            }\n        }\n        return result;\n    }\n    catch (Exception e) {\n        throw new RuntimeException(e);\n    }\n}\n```", "  ```\npublic static <T> T merge(Object source, Object target, Class<T> clazz, List<String> acceptedFieldNames) {\n    ObjectNode sourceNode = (ObjectNode) OBJECT_MAPPER.valueToTree(source);\n    ObjectNode targetNode = (ObjectNode) OBJECT_MAPPER.valueToTree(target);\n    List<String> fieldNames = new ArrayList<>();\n    if (acceptedFieldNames != null && !acceptedFieldNames.isEmpty()) {\n        fieldNames = acceptedFieldNames.stream().map(String::toLowerCase).collect(Collectors.toList());\n    }\n    else {\n        Map<String, String> jsonPropertyNames = new HashMap<>();\n        Arrays.stream(clazz.getDeclaredFields())\n                .filter(field -> field.isAnnotationPresent(JsonProperty.class))\n                .forEach(field -> jsonPropertyNames.put(field.getName().toLowerCase(), field.getAnnotation(JsonProperty.class).value()));\n        fieldNames = jsonPropertyNames.values().stream().map(String::toLowerCase).collect(Collectors.toList());\n    }\n    for (String fieldName : fieldNames) {\n        if (sourceNode.has(fieldName) && targetNode.has(fieldName)) {\n            JsonNode sourceValue = sourceNode.get(fieldName);\n            JsonNode targetValue = targetNode.get(fieldName);\n            if (sourceValue == null || sourceValue.isNull()) {\n                continue;\n            }\n            targetNode.set(fieldName, sourceValue);\n        }\n    }\n    try {\n        return OBJECT_MAPPER.treeToValue(targetNode, clazz);\n    }\n    catch (JsonProcessingException e) {\n        throw new RuntimeException(e);\n    }\n}\n```", "  ```\npublic static <T> T merge(Object source, Object target, Class<T> clazz, List<String> acceptedFieldNames) {\n    Assert.notNull(source, \"Source object must not be null\");\n    Assert.notNull(target, \"Target object must not be null\");\n    Assert.notNull(clazz, \"Class must not be null\");\n\n    BeanWrapper sourceWrapper = new BeanWrapperImpl(source);\n    BeanWrapper targetWrapper = new BeanWrapperImpl(target);\n    Map<String, Object> targetMap = targetWrapper.getConvertedValues();\n    Map<String, Object> sourceMap = sourceWrapper.getConvertedValues();\n\n    List<String> fieldNames = new ArrayList<>();\n    String[] propertyNames = clazz.getAnnotationsByType(JsonProperty.class) != null ? clazz.getAnnotationsByType(JsonProperty.class).stream().map(JsonProperty::value).collect(Collectors.toList()).toArray(new String[0]) : null;\n\n    if (!CollectionUtils.isEmpty(acceptedFieldNames)) {\n        fieldNames.addAll(acceptedFieldNames);\n    } else if (propertyNames != null) {\n        fieldNames.addAll(Arrays.asList(propertyNames));\n    } else {\n        fieldNames.addAll(targetMap.keySet());\n    }\n\n    for (String name : fieldNames) {\n        if (sourceMap.containsKey(name)) {\n            if (targetMap.containsKey(name) && targetMap.get(name) != null) {\n                continue;\n            }\n            targetMap.put(name, sourceMap.get(name));\n        }\n    }\n\n    return mapToClass(targetMap, clazz);\n}\n```"]}, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-objectToMap": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.model;\n\nimport java.beans.PropertyDescriptor;\nimport java.lang.reflect.Field;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\n\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.DeserializationFeature;\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.SerializationFeature;\nimport com.fasterxml.jackson.databind.node.ArrayNode;\nimport com.fasterxml.jackson.databind.node.ObjectNode;\nimport com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;\nimport com.github.victools.jsonschema.generator.Option;\nimport com.github.victools.jsonschema.generator.OptionPreset;\nimport com.github.victools.jsonschema.generator.SchemaGenerator;\nimport com.github.victools.jsonschema.generator.SchemaGeneratorConfig;\nimport com.github.victools.jsonschema.generator.SchemaGeneratorConfigBuilder;\nimport com.github.victools.jsonschema.generator.SchemaVersion;\nimport com.github.victools.jsonschema.module.jackson.JacksonModule;\nimport com.github.victools.jsonschema.module.jackson.JacksonOption;\nimport com.github.victools.jsonschema.module.swagger2.Swagger2Module;\n\nimport org.springframework.beans.BeanWrapper;\nimport org.springframework.beans.BeanWrapperImpl;\nimport org.springframework.util.Assert;\nimport org.springframework.util.CollectionUtils;\nimport org.springframework.util.ObjectUtils;\n\n/**\n * Utility class for manipulating {@link ModelOptions} objects.\n *\n * @author Christian Tzolov\n * @author Thomas Vitale\n * @since 0.8.0\n */\npublic abstract class ModelOptionsUtils {\n\n\tpublic static final ObjectMapper OBJECT_MAPPER = new ObjectMapper()\n\t\t.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n\t\t.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS)\n\t\t.registerModule(new JavaTimeModule());\n\n\tprivate static final List<String> BEAN_MERGE_FIELD_EXCISIONS = List.of(\"class\");\n\n\tprivate static final ConcurrentHashMap<Class<?>, List<String>> REQUEST_FIELD_NAMES_PER_CLASS = new ConcurrentHashMap<Class<?>, List<String>>();\n\n\tprivate static final AtomicReference<SchemaGenerator> SCHEMA_GENERATOR_CACHE = new AtomicReference<>();\n\n\t/**\n\t * Converts the given JSON string to a Map of String and Object.\n\t * @param json the JSON string to convert to a Map.\n\t * @return the converted Map.\n\t */\n\tpublic static Map<String, Object> jsonToMap(String json) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.readValue(json, MAP_TYPE_REF);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\tprivate static TypeReference<HashMap<String, Object>> MAP_TYPE_REF = new TypeReference<HashMap<String, Object>>() {\n\t};\n\n\t/**\n\t * Converts the given JSON string to an Object of the given type.\n\t * @param <T> the type of the object to return.\n\t * @param json the JSON string to convert to an object.\n\t * @param type the type of the object to return.\n\t * @return Object instance of the given type.\n\t */\n\tpublic static <T> T jsonToObject(String json, Class<T> type) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.readValue(json, type);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"Failed to json: \" + json, e);\n\t\t}\n\t}\n\n\t/**\n\t * Converts the given object to a JSON string.\n\t * @param object the object to convert to a JSON string.\n\t * @return the JSON string.\n\t */\n\tpublic static String toJsonString(Object object) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.writeValueAsString(object);\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t/**\n\t * Merges the source object into the target object and returns an object represented\n\t * by the given class. The JSON property names are used to match the fields to merge.\n\t * The source non-null values override the target values with the same field name. The\n\t * source null values are ignored. If the acceptedFieldNames is not empty, only the\n\t * fields with the given names are merged and returned. If the acceptedFieldNames is\n\t * empty, use the {@code @JsonProperty} names, inferred from the provided clazz.\n\t * @param <T> they type of the class to return.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param clazz the class to return.\n\t * @param acceptedFieldNames the list of field names accepted for the target object.\n\t * @return the merged object represented by the given class.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Merges the source object into the target object and returns an object represented\n\t * by the given class. The JSON property names are used to match the fields to merge.\n\t * The source non-null values override the target values with the same field name. The\n\t * source null values are ignored. Returns the only field names that match the\n\t * {@code @JsonProperty} names, inferred from the provided clazz.\n\t * @param <T> they type of the class to return.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param clazz the class to return.\n\t * @return the merged object represented by the given class.\n\t */\n\tpublic static <T> T merge(Object source, Object target, Class<T> clazz) {\n\t\treturn ModelOptionsUtils.merge(source, target, clazz, null);\n\t}\n\n\t/**\n\t * Converts the given object to a Map.\n\t * @param source the object to convert to a Map.\n\t * @return the converted Map.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Converts the given Map to the given class.\n\t * @param <T> the type of the class to return.\n\t * @param source the Map to convert to the given class.\n\t * @param clazz the class to convert the Map to.\n\t * @return the converted class.\n\t */\n\tpublic static <T> T mapToClass(Map<String, Object> source, Class<T> clazz) {\n\t\ttry {\n\t\t\tString json = OBJECT_MAPPER.writeValueAsString(source);\n\t\t\treturn OBJECT_MAPPER.readValue(json, clazz);\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t/**\n\t * Returns the list of name values of the {@link JsonProperty} annotations.\n\t * @param clazz the class that contains fields annotated with {@link JsonProperty}.\n\t * @return the list of values of the {@link JsonProperty} annotations.\n\t */\n\tpublic static List<String> getJsonPropertyValues(Class<?> clazz) {\n\t\tList<String> values = new ArrayList<>();\n\t\tField[] fields = clazz.getDeclaredFields();\n\t\tfor (Field field : fields) {\n\t\t\tJsonProperty jsonPropertyAnnotation = field.getAnnotation(JsonProperty.class);\n\t\t\tif (jsonPropertyAnnotation != null) {\n\t\t\t\tvalues.add(jsonPropertyAnnotation.value());\n\t\t\t}\n\t\t}\n\t\treturn values;\n\t}\n\n\t/**\n\t * Returns a new instance of the targetBeanClazz that copies the bean values from the\n\t * sourceBean instance.\n\t * @param sourceBean the source bean to copy the values from.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are copied. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param targetBeanClazz the target class, a subclass of the ChatOptions, to convert\n\t * into.\n\t * @param <T> the target class type.\n\t * @return a new instance of the targetBeanClazz with the values from the sourceBean\n\t * instance.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Merges the source object into the target object. The source null values are\n\t * ignored. Only objects with Getter and Setter methods are supported.\n\t * @param <T> the type of the source and target object.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are merged. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param overrideNonNullTargetValues if true, the source non-null values override the\n\t * target values with the same field name. If false, the source non-null values are\n\t * ignored.\n\t * @return the merged target object.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\tprivate static String toGetName(String name) {\n\t\treturn \"get\" + name.substring(0, 1).toUpperCase() + name.substring(1);\n\t}\n\n\t/**\n\t * Generates JSON Schema (version 2020_12) for the given class.\n\t * @param clazz the class to generate JSON Schema for.\n\t * @param toUpperCaseTypeValues if true, the type values are converted to upper case.\n\t * @return the generated JSON Schema as a String.\n\t */\n\tpublic static String getJsonSchema(Class<?> clazz, boolean toUpperCaseTypeValues) {\n\n\t\tif (SCHEMA_GENERATOR_CACHE.get() == null) {\n\n\t\t\tJacksonModule jacksonModule = new JacksonModule(JacksonOption.RESPECT_JSONPROPERTY_REQUIRED);\n\t\t\tSwagger2Module swaggerModule = new Swagger2Module();\n\n\t\t\tSchemaGeneratorConfigBuilder configBuilder = new SchemaGeneratorConfigBuilder(SchemaVersion.DRAFT_2020_12,\n\t\t\t\t\tOptionPreset.PLAIN_JSON)\n\t\t\t\t.with(Option.EXTRA_OPEN_API_FORMAT_VALUES)\n\t\t\t\t.with(Option.PLAIN_DEFINITION_KEYS)\n\t\t\t\t.with(swaggerModule)\n\t\t\t\t.with(jacksonModule);\n\n\t\t\tSchemaGeneratorConfig config = configBuilder.build();\n\t\t\tSchemaGenerator generator = new SchemaGenerator(config);\n\t\t\tSCHEMA_GENERATOR_CACHE.compareAndSet(null, generator);\n\t\t}\n\n\t\tObjectNode node = SCHEMA_GENERATOR_CACHE.get().generateSchema(clazz);\n\t\tif (toUpperCaseTypeValues) { // Required for OpenAPI 3.0 (at least Vertex AI\n\t\t\t\t\t\t\t\t\t\t// version of it).\n\t\t\ttoUpperCaseTypeValues(node);\n\t\t}\n\n\t\treturn node.toPrettyString();\n\t}\n\n\tpublic static void toUpperCaseTypeValues(ObjectNode node) {\n\t\tif (node == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (node.isObject()) {\n\t\t\tnode.fields().forEachRemaining(entry -> {\n\t\t\t\tJsonNode value = entry.getValue();\n\t\t\t\tif (value.isObject()) {\n\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) value);\n\t\t\t\t}\n\t\t\t\telse if (value.isArray()) {\n\t\t\t\t\t((ArrayNode) value).elements().forEachRemaining(element -> {\n\t\t\t\t\t\tif (element.isObject() || element.isArray()) {\n\t\t\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) element);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t\telse if (value.isTextual() && entry.getKey().equals(\"type\")) {\n\t\t\t\t\tString oldValue = ((ObjectNode) node).get(\"type\").asText();\n\t\t\t\t\t((ObjectNode) node).put(\"type\", oldValue.toUpperCase());\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\telse if (node.isArray()) {\n\t\t\tnode.elements().forEachRemaining(element -> {\n\t\t\t\tif (element.isObject() || element.isArray()) {\n\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) element);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n\n\t/**\n\t * Return the runtime value if not empty, or else the default value.\n\t */\n\tpublic static <T> T mergeOption(T runtimeValue, T defaultValue) {\n\t\treturn ObjectUtils.isEmpty(runtimeValue) ? defaultValue : runtimeValue;\n\t}\n\n}\n\n```\n# Function Signature: public static Map<String, Object> objectToMap(Object source) {\n# Natural Language Annotations: /**\n\t * Converts the given object to a Map.\n\t * @param source the object to convert to a Map.\n\t * @return the converted Map.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static Map<String, Object> objectToMap(Object source) {\n    try {\n        String json = OBJECT_MAPPER.writeValueAsString(source);\n        return OBJECT_MAPPER.readValue(json, MAP_TYPE_REF);\n    } catch (JsonProcessingException e) {\n        throw new RuntimeException(e);\n    }\n}\n```", "  ```\npublic static Map<String, Object> objectToMap(Object source) {\n    try {\n        return OBJECT_MAPPER.readValue(toJsonString(source), MAP_TYPE_REF);\n    }\n    catch (JsonProcessingException e) {\n        throw new RuntimeException(e);\n    }\n}\n```", "  ```\npublic static Map<String, Object> objectToMap(Object source) {\n\t\tif (source == null) {\n\t\t\treturn null;\n\t\t}\n\t\tMap<String, Object> result = new HashMap<>();\n\t\tPropertyDescriptor[] pds;\n\t\ttry {\n\t\t\tpds = new BeanWrapperImpl(source).getPropertyDescriptors();\n\t\t\tfor (PropertyDescriptor pd : pds) {\n\t\t\t\tString name = pd.getName();\n\t\t\t\tObject value = pd.getReadMethod().invoke(source);\n\t\t\t\tresult.put(name, value);\n\t\t\t}\n\t\t} catch (Exception ex) {\n\t\t\tthrow new RuntimeException(\"Failed to convert object to map\", ex);\n\t\t}\n\t\treturn result;\n\t}\n```"]}, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-copyToTarget": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.model;\n\nimport java.beans.PropertyDescriptor;\nimport java.lang.reflect.Field;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\n\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.DeserializationFeature;\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.SerializationFeature;\nimport com.fasterxml.jackson.databind.node.ArrayNode;\nimport com.fasterxml.jackson.databind.node.ObjectNode;\nimport com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;\nimport com.github.victools.jsonschema.generator.Option;\nimport com.github.victools.jsonschema.generator.OptionPreset;\nimport com.github.victools.jsonschema.generator.SchemaGenerator;\nimport com.github.victools.jsonschema.generator.SchemaGeneratorConfig;\nimport com.github.victools.jsonschema.generator.SchemaGeneratorConfigBuilder;\nimport com.github.victools.jsonschema.generator.SchemaVersion;\nimport com.github.victools.jsonschema.module.jackson.JacksonModule;\nimport com.github.victools.jsonschema.module.jackson.JacksonOption;\nimport com.github.victools.jsonschema.module.swagger2.Swagger2Module;\n\nimport org.springframework.beans.BeanWrapper;\nimport org.springframework.beans.BeanWrapperImpl;\nimport org.springframework.util.Assert;\nimport org.springframework.util.CollectionUtils;\nimport org.springframework.util.ObjectUtils;\n\n/**\n * Utility class for manipulating {@link ModelOptions} objects.\n *\n * @author Christian Tzolov\n * @author Thomas Vitale\n * @since 0.8.0\n */\npublic abstract class ModelOptionsUtils {\n\n\tpublic static final ObjectMapper OBJECT_MAPPER = new ObjectMapper()\n\t\t.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n\t\t.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS)\n\t\t.registerModule(new JavaTimeModule());\n\n\tprivate static final List<String> BEAN_MERGE_FIELD_EXCISIONS = List.of(\"class\");\n\n\tprivate static final ConcurrentHashMap<Class<?>, List<String>> REQUEST_FIELD_NAMES_PER_CLASS = new ConcurrentHashMap<Class<?>, List<String>>();\n\n\tprivate static final AtomicReference<SchemaGenerator> SCHEMA_GENERATOR_CACHE = new AtomicReference<>();\n\n\t/**\n\t * Converts the given JSON string to a Map of String and Object.\n\t * @param json the JSON string to convert to a Map.\n\t * @return the converted Map.\n\t */\n\tpublic static Map<String, Object> jsonToMap(String json) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.readValue(json, MAP_TYPE_REF);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\tprivate static TypeReference<HashMap<String, Object>> MAP_TYPE_REF = new TypeReference<HashMap<String, Object>>() {\n\t};\n\n\t/**\n\t * Converts the given JSON string to an Object of the given type.\n\t * @param <T> the type of the object to return.\n\t * @param json the JSON string to convert to an object.\n\t * @param type the type of the object to return.\n\t * @return Object instance of the given type.\n\t */\n\tpublic static <T> T jsonToObject(String json, Class<T> type) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.readValue(json, type);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"Failed to json: \" + json, e);\n\t\t}\n\t}\n\n\t/**\n\t * Converts the given object to a JSON string.\n\t * @param object the object to convert to a JSON string.\n\t * @return the JSON string.\n\t */\n\tpublic static String toJsonString(Object object) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.writeValueAsString(object);\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t/**\n\t * Merges the source object into the target object and returns an object represented\n\t * by the given class. The JSON property names are used to match the fields to merge.\n\t * The source non-null values override the target values with the same field name. The\n\t * source null values are ignored. If the acceptedFieldNames is not empty, only the\n\t * fields with the given names are merged and returned. If the acceptedFieldNames is\n\t * empty, use the {@code @JsonProperty} names, inferred from the provided clazz.\n\t * @param <T> they type of the class to return.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param clazz the class to return.\n\t * @param acceptedFieldNames the list of field names accepted for the target object.\n\t * @return the merged object represented by the given class.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Merges the source object into the target object and returns an object represented\n\t * by the given class. The JSON property names are used to match the fields to merge.\n\t * The source non-null values override the target values with the same field name. The\n\t * source null values are ignored. Returns the only field names that match the\n\t * {@code @JsonProperty} names, inferred from the provided clazz.\n\t * @param <T> they type of the class to return.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param clazz the class to return.\n\t * @return the merged object represented by the given class.\n\t */\n\tpublic static <T> T merge(Object source, Object target, Class<T> clazz) {\n\t\treturn ModelOptionsUtils.merge(source, target, clazz, null);\n\t}\n\n\t/**\n\t * Converts the given object to a Map.\n\t * @param source the object to convert to a Map.\n\t * @return the converted Map.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Converts the given Map to the given class.\n\t * @param <T> the type of the class to return.\n\t * @param source the Map to convert to the given class.\n\t * @param clazz the class to convert the Map to.\n\t * @return the converted class.\n\t */\n\tpublic static <T> T mapToClass(Map<String, Object> source, Class<T> clazz) {\n\t\ttry {\n\t\t\tString json = OBJECT_MAPPER.writeValueAsString(source);\n\t\t\treturn OBJECT_MAPPER.readValue(json, clazz);\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t/**\n\t * Returns the list of name values of the {@link JsonProperty} annotations.\n\t * @param clazz the class that contains fields annotated with {@link JsonProperty}.\n\t * @return the list of values of the {@link JsonProperty} annotations.\n\t */\n\tpublic static List<String> getJsonPropertyValues(Class<?> clazz) {\n\t\tList<String> values = new ArrayList<>();\n\t\tField[] fields = clazz.getDeclaredFields();\n\t\tfor (Field field : fields) {\n\t\t\tJsonProperty jsonPropertyAnnotation = field.getAnnotation(JsonProperty.class);\n\t\t\tif (jsonPropertyAnnotation != null) {\n\t\t\t\tvalues.add(jsonPropertyAnnotation.value());\n\t\t\t}\n\t\t}\n\t\treturn values;\n\t}\n\n\t/**\n\t * Returns a new instance of the targetBeanClazz that copies the bean values from the\n\t * sourceBean instance.\n\t * @param sourceBean the source bean to copy the values from.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are copied. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param targetBeanClazz the target class, a subclass of the ChatOptions, to convert\n\t * into.\n\t * @param <T> the target class type.\n\t * @return a new instance of the targetBeanClazz with the values from the sourceBean\n\t * instance.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Merges the source object into the target object. The source null values are\n\t * ignored. Only objects with Getter and Setter methods are supported.\n\t * @param <T> the type of the source and target object.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are merged. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param overrideNonNullTargetValues if true, the source non-null values override the\n\t * target values with the same field name. If false, the source non-null values are\n\t * ignored.\n\t * @return the merged target object.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\tprivate static String toGetName(String name) {\n\t\treturn \"get\" + name.substring(0, 1).toUpperCase() + name.substring(1);\n\t}\n\n\t/**\n\t * Generates JSON Schema (version 2020_12) for the given class.\n\t * @param clazz the class to generate JSON Schema for.\n\t * @param toUpperCaseTypeValues if true, the type values are converted to upper case.\n\t * @return the generated JSON Schema as a String.\n\t */\n\tpublic static String getJsonSchema(Class<?> clazz, boolean toUpperCaseTypeValues) {\n\n\t\tif (SCHEMA_GENERATOR_CACHE.get() == null) {\n\n\t\t\tJacksonModule jacksonModule = new JacksonModule(JacksonOption.RESPECT_JSONPROPERTY_REQUIRED);\n\t\t\tSwagger2Module swaggerModule = new Swagger2Module();\n\n\t\t\tSchemaGeneratorConfigBuilder configBuilder = new SchemaGeneratorConfigBuilder(SchemaVersion.DRAFT_2020_12,\n\t\t\t\t\tOptionPreset.PLAIN_JSON)\n\t\t\t\t.with(Option.EXTRA_OPEN_API_FORMAT_VALUES)\n\t\t\t\t.with(Option.PLAIN_DEFINITION_KEYS)\n\t\t\t\t.with(swaggerModule)\n\t\t\t\t.with(jacksonModule);\n\n\t\t\tSchemaGeneratorConfig config = configBuilder.build();\n\t\t\tSchemaGenerator generator = new SchemaGenerator(config);\n\t\t\tSCHEMA_GENERATOR_CACHE.compareAndSet(null, generator);\n\t\t}\n\n\t\tObjectNode node = SCHEMA_GENERATOR_CACHE.get().generateSchema(clazz);\n\t\tif (toUpperCaseTypeValues) { // Required for OpenAPI 3.0 (at least Vertex AI\n\t\t\t\t\t\t\t\t\t\t// version of it).\n\t\t\ttoUpperCaseTypeValues(node);\n\t\t}\n\n\t\treturn node.toPrettyString();\n\t}\n\n\tpublic static void toUpperCaseTypeValues(ObjectNode node) {\n\t\tif (node == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (node.isObject()) {\n\t\t\tnode.fields().forEachRemaining(entry -> {\n\t\t\t\tJsonNode value = entry.getValue();\n\t\t\t\tif (value.isObject()) {\n\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) value);\n\t\t\t\t}\n\t\t\t\telse if (value.isArray()) {\n\t\t\t\t\t((ArrayNode) value).elements().forEachRemaining(element -> {\n\t\t\t\t\t\tif (element.isObject() || element.isArray()) {\n\t\t\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) element);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t\telse if (value.isTextual() && entry.getKey().equals(\"type\")) {\n\t\t\t\t\tString oldValue = ((ObjectNode) node).get(\"type\").asText();\n\t\t\t\t\t((ObjectNode) node).put(\"type\", oldValue.toUpperCase());\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\telse if (node.isArray()) {\n\t\t\tnode.elements().forEachRemaining(element -> {\n\t\t\t\tif (element.isObject() || element.isArray()) {\n\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) element);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n\n\t/**\n\t * Return the runtime value if not empty, or else the default value.\n\t */\n\tpublic static <T> T mergeOption(T runtimeValue, T defaultValue) {\n\t\treturn ObjectUtils.isEmpty(runtimeValue) ? defaultValue : runtimeValue;\n\t}\n\n}\n\n```\n# Function Signature: public static <I, S extends I, T extends S> T copyToTarget(S sourceBean, Class<I> sourceInterfaceClazz,\n# Natural Language Annotations: /**\n\t * Returns a new instance of the targetBeanClazz that copies the bean values from the\n\t * sourceBean instance.\n\t * @param sourceBean the source bean to copy the values from.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are copied. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param targetBeanClazz the target class, a subclass of the ChatOptions, to convert\n\t * into.\n\t * @param <T> the target class type.\n\t * @return a new instance of the targetBeanClazz with the values from the sourceBean\n\t * instance.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <I, S extends I, T extends S> T copyToTarget(S sourceBean, Class<I> sourceInterfaceClazz, Class<T> targetBeanClazz) {\n    T targetBean = null;\n    try {\n        targetBean = targetBeanClazz.getDeclaredConstructor().newInstance();\n    } catch (InstantiationException | IllegalAccessException | NoSuchMethodException | InvocationTargetException e) {\n        // TODO: handle exception\n    }\n    BeanWrapper sourceBeanWrapper = new BeanWrapperImpl(sourceBean);\n    BeanWrapper targetBeanWrapper = new BeanWrapperImpl(targetBean);\n    PropertyDescriptor[] sourceBeanProperties = sourceBeanWrapper.getPropertyDescriptors();\n    for (PropertyDescriptor sourceBeanProperty : sourceBeanProperties) {\n        String propertyName = sourceBeanProperty.getName();\n        Method readMethod = sourceBeanProperty.getReadMethod();\n        try {\n            Object propertyValue = readMethod.invoke(sourceBean);\n            targetBeanWrapper.setPropertyValue(propertyName, propertyValue);\n        } catch (IllegalAccessException | InvocationTargetException e) {\n            // TODO: handle exception\n        }\n    }\n    return targetBean;\n}\n```", "  ```\npublic static <I, S extends I, T extends S> T copyToTarget(S sourceBean, Class<I> sourceInterfaceClazz, Class<T> targetBeanClazz) {\n    if (sourceBean == null || targetBeanClazz == null || sourceInterfaceClazz == null) {\n        return null;\n    }\n    T targetBean = null;\n    try {\n        targetBean = targetBeanClazz.getDeclaredConstructor().newInstance();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n    if (targetBean == null) {\n        return null;\n    }\n    String[] sourceFieldNames = getFieldNames(sourceInterfaceClazz);\n    for (String fieldName : sourceFieldNames) {\n        Object propertyValue = getPropertyValue(sourceBean, fieldName);\n        if (propertyValue != null) {\n            setPropertyValue(targetBean, fieldName, propertyValue);\n        }\n    }\n    return targetBean;\n}\n\nprivate static <S> String[] getFieldNames(Class<S> sourceInterfaceClazz) {\n    Field[] fields = sourceInterfaceClazz.getDeclaredFields();\n    String[] fieldNames = new String[fields.length];\n    for (int i = 0; i < fields.length; i++) {\n        fieldNames[i] = fields[i].getName();\n    }\n    return fieldNames;\n}\n\nprivate static <S> Object getPropertyValue(S sourceBean, String fieldName) {\n    BeanWrapper beanWrapper = new BeanWrapperImpl(sourceBean);\n    try {\n        return beanWrapper.getPropertyValue(fieldName);\n    } catch (Exception e) {\n        e.printStackTrace();\n        return null;\n    }\n}\n\nprivate static <S> void setPropertyValue(S sourceBean, String fieldName, Object propertyValue) {\n    BeanWrapper beanWrapper = new BeanWrapperImpl(sourceBean);\n    try {\n        beanWrapper.setPropertyValue(fieldName, propertyValue);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n```", "  ```\n@Override\npublic <I, S extends I, T extends S> T copyToTarget(S sourceBean, Class<I> sourceInterfaceClazz, Class<T> targetBeanClazz) {\n    try {\n        T targetBean = targetBeanClazz.getDeclaredConstructor().newInstance();\n        BeanWrapper sourceBeanWrapper = new BeanWrapperImpl(sourceBean);\n        Iterator<PropertyDescriptor> sourceProperties = sourceBeanWrapper.getPropertyDescriptors().iterator();\n        while (sourceProperties.hasNext()) {\n            PropertyDescriptor sourceProperty = sourceProperties.next();\n            String sourcePropertyName = sourceProperty.getName();\n            if (sourcePropertyName.startsWith(\"get\")) {\n                sourcePropertyName = sourcePropertyName.substring(3);\n            } else if (sourcePropertyName.startsWith(\"is\")) {\n                sourcePropertyName = sourcePropertyName.substring(2);\n            }\n            Method targetGetter = getGetterMethod(targetBean, sourcePropertyName);\n            if (targetGetter != null && hasMatchingParameter(targetGetter, sourceProperty)) {\n                Object sourceValue = sourceProperty.getReadMethod().invoke(sourceBean);\n                Method targetSetter = sourceProperty.getReadMethod();\n                targetSetter.invoke(targetBean, sourceValue);\n            }\n        }\n        return targetBean;\n    } catch (Exception e) {\n        throw new RuntimeException(e);\n    }\n}\n\nprivate static Method getGetterMethod(Object targetBean, String sourcePropertyName) {\n    String getterName = \"get\" + sourcePropertyName.substring(0, 1).toUpperCase() + sourcePropertyName.substring(1);\n    return Arrays.stream(targetBean.getClass().getDeclaredMethods())\n            .filter(m -> m.getName().equals(getterName) && m.getParameterCount() == 0)\n            .findFirst()\n            .orElse(null);\n}\n\nprivate static boolean hasMatchingParameter(Method targetGetter, PropertyDescriptor sourceProperty) {\n    return targetGetter.getParameterCount() == 1 && targetGetter.getParameterTypes()[0].isAssignableFrom(sourceProperty.getPropertyType());\n}\n```"]}, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-mergeBeans": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.model;\n\nimport java.beans.PropertyDescriptor;\nimport java.lang.reflect.Field;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\n\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.DeserializationFeature;\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.SerializationFeature;\nimport com.fasterxml.jackson.databind.node.ArrayNode;\nimport com.fasterxml.jackson.databind.node.ObjectNode;\nimport com.fasterxml.jackson.datatype.jsr310.JavaTimeModule;\nimport com.github.victools.jsonschema.generator.Option;\nimport com.github.victools.jsonschema.generator.OptionPreset;\nimport com.github.victools.jsonschema.generator.SchemaGenerator;\nimport com.github.victools.jsonschema.generator.SchemaGeneratorConfig;\nimport com.github.victools.jsonschema.generator.SchemaGeneratorConfigBuilder;\nimport com.github.victools.jsonschema.generator.SchemaVersion;\nimport com.github.victools.jsonschema.module.jackson.JacksonModule;\nimport com.github.victools.jsonschema.module.jackson.JacksonOption;\nimport com.github.victools.jsonschema.module.swagger2.Swagger2Module;\n\nimport org.springframework.beans.BeanWrapper;\nimport org.springframework.beans.BeanWrapperImpl;\nimport org.springframework.util.Assert;\nimport org.springframework.util.CollectionUtils;\nimport org.springframework.util.ObjectUtils;\n\n/**\n * Utility class for manipulating {@link ModelOptions} objects.\n *\n * @author Christian Tzolov\n * @author Thomas Vitale\n * @since 0.8.0\n */\npublic abstract class ModelOptionsUtils {\n\n\tpublic static final ObjectMapper OBJECT_MAPPER = new ObjectMapper()\n\t\t.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n\t\t.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS)\n\t\t.registerModule(new JavaTimeModule());\n\n\tprivate static final List<String> BEAN_MERGE_FIELD_EXCISIONS = List.of(\"class\");\n\n\tprivate static final ConcurrentHashMap<Class<?>, List<String>> REQUEST_FIELD_NAMES_PER_CLASS = new ConcurrentHashMap<Class<?>, List<String>>();\n\n\tprivate static final AtomicReference<SchemaGenerator> SCHEMA_GENERATOR_CACHE = new AtomicReference<>();\n\n\t/**\n\t * Converts the given JSON string to a Map of String and Object.\n\t * @param json the JSON string to convert to a Map.\n\t * @return the converted Map.\n\t */\n\tpublic static Map<String, Object> jsonToMap(String json) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.readValue(json, MAP_TYPE_REF);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\tprivate static TypeReference<HashMap<String, Object>> MAP_TYPE_REF = new TypeReference<HashMap<String, Object>>() {\n\t};\n\n\t/**\n\t * Converts the given JSON string to an Object of the given type.\n\t * @param <T> the type of the object to return.\n\t * @param json the JSON string to convert to an object.\n\t * @param type the type of the object to return.\n\t * @return Object instance of the given type.\n\t */\n\tpublic static <T> T jsonToObject(String json, Class<T> type) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.readValue(json, type);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"Failed to json: \" + json, e);\n\t\t}\n\t}\n\n\t/**\n\t * Converts the given object to a JSON string.\n\t * @param object the object to convert to a JSON string.\n\t * @return the JSON string.\n\t */\n\tpublic static String toJsonString(Object object) {\n\t\ttry {\n\t\t\treturn OBJECT_MAPPER.writeValueAsString(object);\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t/**\n\t * Merges the source object into the target object and returns an object represented\n\t * by the given class. The JSON property names are used to match the fields to merge.\n\t * The source non-null values override the target values with the same field name. The\n\t * source null values are ignored. If the acceptedFieldNames is not empty, only the\n\t * fields with the given names are merged and returned. If the acceptedFieldNames is\n\t * empty, use the {@code @JsonProperty} names, inferred from the provided clazz.\n\t * @param <T> they type of the class to return.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param clazz the class to return.\n\t * @param acceptedFieldNames the list of field names accepted for the target object.\n\t * @return the merged object represented by the given class.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Merges the source object into the target object and returns an object represented\n\t * by the given class. The JSON property names are used to match the fields to merge.\n\t * The source non-null values override the target values with the same field name. The\n\t * source null values are ignored. Returns the only field names that match the\n\t * {@code @JsonProperty} names, inferred from the provided clazz.\n\t * @param <T> they type of the class to return.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param clazz the class to return.\n\t * @return the merged object represented by the given class.\n\t */\n\tpublic static <T> T merge(Object source, Object target, Class<T> clazz) {\n\t\treturn ModelOptionsUtils.merge(source, target, clazz, null);\n\t}\n\n\t/**\n\t * Converts the given object to a Map.\n\t * @param source the object to convert to a Map.\n\t * @return the converted Map.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Converts the given Map to the given class.\n\t * @param <T> the type of the class to return.\n\t * @param source the Map to convert to the given class.\n\t * @param clazz the class to convert the Map to.\n\t * @return the converted class.\n\t */\n\tpublic static <T> T mapToClass(Map<String, Object> source, Class<T> clazz) {\n\t\ttry {\n\t\t\tString json = OBJECT_MAPPER.writeValueAsString(source);\n\t\t\treturn OBJECT_MAPPER.readValue(json, clazz);\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t/**\n\t * Returns the list of name values of the {@link JsonProperty} annotations.\n\t * @param clazz the class that contains fields annotated with {@link JsonProperty}.\n\t * @return the list of values of the {@link JsonProperty} annotations.\n\t */\n\tpublic static List<String> getJsonPropertyValues(Class<?> clazz) {\n\t\tList<String> values = new ArrayList<>();\n\t\tField[] fields = clazz.getDeclaredFields();\n\t\tfor (Field field : fields) {\n\t\t\tJsonProperty jsonPropertyAnnotation = field.getAnnotation(JsonProperty.class);\n\t\t\tif (jsonPropertyAnnotation != null) {\n\t\t\t\tvalues.add(jsonPropertyAnnotation.value());\n\t\t\t}\n\t\t}\n\t\treturn values;\n\t}\n\n\t/**\n\t * Returns a new instance of the targetBeanClazz that copies the bean values from the\n\t * sourceBean instance.\n\t * @param sourceBean the source bean to copy the values from.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are copied. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param targetBeanClazz the target class, a subclass of the ChatOptions, to convert\n\t * into.\n\t * @param <T> the target class type.\n\t * @return a new instance of the targetBeanClazz with the values from the sourceBean\n\t * instance.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Merges the source object into the target object. The source null values are\n\t * ignored. Only objects with Getter and Setter methods are supported.\n\t * @param <T> the type of the source and target object.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are merged. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param overrideNonNullTargetValues if true, the source non-null values override the\n\t * target values with the same field name. If false, the source non-null values are\n\t * ignored.\n\t * @return the merged target object.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\tprivate static String toGetName(String name) {\n\t\treturn \"get\" + name.substring(0, 1).toUpperCase() + name.substring(1);\n\t}\n\n\t/**\n\t * Generates JSON Schema (version 2020_12) for the given class.\n\t * @param clazz the class to generate JSON Schema for.\n\t * @param toUpperCaseTypeValues if true, the type values are converted to upper case.\n\t * @return the generated JSON Schema as a String.\n\t */\n\tpublic static String getJsonSchema(Class<?> clazz, boolean toUpperCaseTypeValues) {\n\n\t\tif (SCHEMA_GENERATOR_CACHE.get() == null) {\n\n\t\t\tJacksonModule jacksonModule = new JacksonModule(JacksonOption.RESPECT_JSONPROPERTY_REQUIRED);\n\t\t\tSwagger2Module swaggerModule = new Swagger2Module();\n\n\t\t\tSchemaGeneratorConfigBuilder configBuilder = new SchemaGeneratorConfigBuilder(SchemaVersion.DRAFT_2020_12,\n\t\t\t\t\tOptionPreset.PLAIN_JSON)\n\t\t\t\t.with(Option.EXTRA_OPEN_API_FORMAT_VALUES)\n\t\t\t\t.with(Option.PLAIN_DEFINITION_KEYS)\n\t\t\t\t.with(swaggerModule)\n\t\t\t\t.with(jacksonModule);\n\n\t\t\tSchemaGeneratorConfig config = configBuilder.build();\n\t\t\tSchemaGenerator generator = new SchemaGenerator(config);\n\t\t\tSCHEMA_GENERATOR_CACHE.compareAndSet(null, generator);\n\t\t}\n\n\t\tObjectNode node = SCHEMA_GENERATOR_CACHE.get().generateSchema(clazz);\n\t\tif (toUpperCaseTypeValues) { // Required for OpenAPI 3.0 (at least Vertex AI\n\t\t\t\t\t\t\t\t\t\t// version of it).\n\t\t\ttoUpperCaseTypeValues(node);\n\t\t}\n\n\t\treturn node.toPrettyString();\n\t}\n\n\tpublic static void toUpperCaseTypeValues(ObjectNode node) {\n\t\tif (node == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (node.isObject()) {\n\t\t\tnode.fields().forEachRemaining(entry -> {\n\t\t\t\tJsonNode value = entry.getValue();\n\t\t\t\tif (value.isObject()) {\n\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) value);\n\t\t\t\t}\n\t\t\t\telse if (value.isArray()) {\n\t\t\t\t\t((ArrayNode) value).elements().forEachRemaining(element -> {\n\t\t\t\t\t\tif (element.isObject() || element.isArray()) {\n\t\t\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) element);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t\telse if (value.isTextual() && entry.getKey().equals(\"type\")) {\n\t\t\t\t\tString oldValue = ((ObjectNode) node).get(\"type\").asText();\n\t\t\t\t\t((ObjectNode) node).put(\"type\", oldValue.toUpperCase());\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\telse if (node.isArray()) {\n\t\t\tnode.elements().forEachRemaining(element -> {\n\t\t\t\tif (element.isObject() || element.isArray()) {\n\t\t\t\t\ttoUpperCaseTypeValues((ObjectNode) element);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n\n\t/**\n\t * Return the runtime value if not empty, or else the default value.\n\t */\n\tpublic static <T> T mergeOption(T runtimeValue, T defaultValue) {\n\t\treturn ObjectUtils.isEmpty(runtimeValue) ? defaultValue : runtimeValue;\n\t}\n\n}\n\n```\n# Function Signature: public static <I, S extends I, T extends S> T mergeBeans(S source, T target, Class<I> sourceInterfaceClazz,\n# Natural Language Annotations: /**\n\t * Merges the source object into the target object. The source null values are\n\t * ignored. Only objects with Getter and Setter methods are supported.\n\t * @param <T> the type of the source and target object.\n\t * @param source the source object to merge.\n\t * @param target the target object to merge into.\n\t * @param sourceInterfaceClazz the source interface class. Only the fields with the\n\t * same name as the interface methods are merged. This allow the source object to be a\n\t * subclass of the source interface with additional, non-interface fields.\n\t * @param overrideNonNullTargetValues if true, the source non-null values override the\n\t * target values with the same field name. If false, the source non-null values are\n\t * ignored.\n\t * @return the merged target object.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <I, S extends I, T extends S> T mergeBeans(S source, T target, Class<I> sourceInterfaceClazz, boolean overrideNonNullTargetValues) {\n    if (source == null) {\n        return target;\n    }\n    if (target == null) {\n        return (T) source;\n    }\n    BeanWrapper sourceWrapper = new BeanWrapperImpl(source);\n    BeanWrapper targetWrapper = new BeanWrapperImpl(target);\n    PropertyDescriptor[] sourceDescriptors = sourceWrapper.getPropertyDescriptors();\n    PropertyDescriptor[] targetDescriptors = targetWrapper.getPropertyDescriptors();\n    for (PropertyDescriptor sourceDescriptor : sourceDescriptors) {\n        if (Arrays.stream(targetDescriptors).anyMatch(targetDescriptor -> targetDescriptor.getName().equals(sourceDescriptor.getName()) && targetDescriptor.getReadMethod().getName().equals(sourceInterfaceClazz.getName() + \".\" + toGetName(sourceDescriptor.getName())))) {\n            Object sourceValue = sourceWrapper.getPropertyValue(sourceDescriptor.getName());\n            if (sourceValue != null || overrideNonNullTargetValues) {\n                targetWrapper.setPropertyValue(sourceDescriptor.getName(), sourceValue);\n            }\n        }\n    }\n    return target;\n}\n```", "  ```\npublic static <I, S extends I, T extends S> T mergeBeans(S source, T target, Class<I> sourceInterfaceClazz, boolean overrideNonNullTargetValues) {\n    // Check that the target object is not null\n    Assert.notNull(target, \"Target object must not be null\");\n\n    // Check that the source object is not null\n    Assert.notNull(source, \"Source object must not be null\");\n\n    // Check that the source interface class is not null\n    Assert.notNull(sourceInterfaceClazz, \"Source interface class must not be null\");\n\n    // Get the property descriptors for the source interface class\n    PropertyDescriptor[] propertyDescriptors = BeanUtils.getPropertyDescriptors(sourceInterfaceClazz);\n\n    // Create a bean wrapper for the source object\n    BeanWrapper sourceWrapper = new BeanWrapperImpl(source);\n\n    // Iterate over the property descriptors\n    for (PropertyDescriptor propertyDescriptor : propertyDescriptors) {\n        // Get the field name from the property descriptor\n        String fieldName = propertyDescriptor.getName();\n\n        // Check if the field is a read-only field\n        if (propertyDescriptor.getReadMethod() == null) {\n            continue;\n        }\n\n        // Get the value of the field from the source object\n        Object fieldValue = sourceWrapper.getPropertyValue(fieldName);\n\n        // Check if the field value is not null\n        if (fieldValue != null) {\n            // Get the getter method for the field\n            Method getterMethod = sourceInterfaceClazz.getMethod(toGetName(fieldName));\n\n            // Check if the value should be overridden in the target object\n            if (overrideNonNullTargetValues) {\n                // Get the value of the field from the target object\n                Object targetFieldValue = target.getClass().getMethod(toGetName(fieldName)).invoke(target);\n\n                // Check if the target field value is not null\n                if (targetFieldValue != null) {\n                    // Set the value of the field in the target object\n                    target.getClass().getMethod(propertyDescriptor.getWriteMethod().getName(), fieldValue.getClass()).invoke(target, fieldValue);\n                }\n            }\n        }\n    }\n\n    return target;\n}\n```", "  ```\npublic static <I, S extends I, T extends S> T mergeBans(S source, T target, Class<I> sourceInterfaceClazz,\n        boolean overrideNonNullTargetValues) {\n    if (source == null) {\n        return target;\n    }\n    if (target == null) {\n        return null;\n    }\n    if (sourceInterfaceClazz == null) {\n        throw new IllegalArgumentException(\"Parameter sourceInterfaceClazz cannot be null\");\n    }\n    BeanWrapper sourceBeanWrapper = new BeanWrapperImpl(source);\n    BeanWrapper targetBeanWrapper = new BeanWrapperImpl(target);\n    for (String sourcePropertyName : sourceBeanWrapper.getPropertyDescriptors().keySet()) {\n        if (sourcePropertyName.equals(\"class\")) {\n            continue;\n        }\n        if (isIgnoreProperty(sourcePropertyName)\n                || !sourceBeanWrapper.isReadableProperty(sourcePropertyName)\n                || !targetBeanWrapper.isWritableProperty(sourcePropertyName)) {\n            continue;\n        }\n        Object sourceValue = sourceBeanWrapper.getPropertyValue(sourcePropertyName);\n        if (overrideNonNullTargetValues && sourceValue == null) {\n            continue;\n        }\n        Object targetValue = targetBeanWrapper.getPropertyValue(sourcePropertyName);\n        if (sourceValue == null || targetValue == null\n                || sourceValue.getClass() != targetValue.getClass()) {\n            continue;\n        }\n        targetBeanWrapper.setPropertyValue(sourcePropertyName, sourceValue);\n    }\n    return target;\n}\n```"]}, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/aot/AiRuntimeHints.java-findJsonAnnotatedClassesInPackage": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/spring-ai-core/src/main/java/org/springframework/ai/aot/AiRuntimeHints.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.aot;\n\nimport com.fasterxml.jackson.annotation.JsonInclude;\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.aot.hint.TypeReference;\nimport org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider;\nimport org.springframework.core.type.filter.AnnotationTypeFilter;\nimport org.springframework.core.type.filter.TypeFilter;\n\nimport java.lang.reflect.Executable;\nimport java.util.Arrays;\nimport java.util.HashSet;\nimport java.util.Objects;\nimport java.util.Set;\nimport java.util.stream.Collectors;\n\n/**\n * Utility methods for creating native runtime hints. See other modules for their\n * respective native runtime hints.\n *\n * @author Josh Long\n * @author Christian Tzolov\n * @author Mark Pollack\n */\npublic abstract class AiRuntimeHints {\n\n\tprivate static final Logger log = LoggerFactory.getLogger(AiRuntimeHints.class);\n\n\t/**\n\t * Finds classes in a package that are annotated with JsonInclude or have Jackson\n\t * annotations.\n\t * @param packageName The name of the package to search for annotated classes.\n\t * @return A set of TypeReference objects representing the annotated classes found.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t/**\n\t * Finds classes in a package that are annotated with JsonInclude or have Jackson\n\t * annotations.\n\t * @param packageClass The class in the package to search for annotated classes.\n\t * @return A set of TypeReference objects representing the annotated classes found.\n\t */\n\tpublic static Set<TypeReference> findJsonAnnotatedClassesInPackage(Class<?> packageClass) {\n\t\treturn findJsonAnnotatedClassesInPackage(packageClass.getPackageName());\n\t}\n\n\t/**\n\t * Finds all classes in the specified package that match the given type filter.\n\t * @param packageName The name of the package to scan for classes.\n\t * @param typeFilter The type filter used to filter the scanned classes.\n\t * @return A set of TypeReference objects representing the found classes.\n\t */\n\tpublic static Set<TypeReference> findClassesInPackage(String packageName, TypeFilter typeFilter) {\n\t\tvar classPathScanningCandidateComponentProvider = new ClassPathScanningCandidateComponentProvider(false);\n\t\tclassPathScanningCandidateComponentProvider.addIncludeFilter(typeFilter);\n\t\treturn classPathScanningCandidateComponentProvider//\n\t\t\t.findCandidateComponents(packageName)//\n\t\t\t.stream()//\n\t\t\t.map(bd -> TypeReference.of(Objects.requireNonNull(bd.getBeanClassName())))//\n\t\t\t.peek(tr -> {\n\t\t\t\tif (log.isDebugEnabled())\n\t\t\t\t\tlog.debug(\"registering [\" + tr.getName() + ']');\n\t\t\t})\n\t\t\t.collect(Collectors.toUnmodifiableSet());\n\t}\n\n\tprivate static boolean hasJacksonAnnotations(Class<?> type) {\n\t\tvar hasAnnotation = false;\n\t\tvar annotationsToFind = Set.of(JsonProperty.class, JsonInclude.class);\n\t\tfor (var annotationToFind : annotationsToFind) {\n\n\t\t\tif (type.isAnnotationPresent(annotationToFind)) {\n\t\t\t\thasAnnotation = true;\n\t\t\t}\n\n\t\t\tvar executables = new HashSet<Executable>();\n\t\t\texecutables.addAll(Set.of(type.getMethods()));\n\t\t\texecutables.addAll(Set.of(type.getConstructors()));\n\t\t\texecutables.addAll(Set.of(type.getDeclaredConstructors()));\n\n\t\t\tfor (var executable : executables) {\n\t\t\t\t//\n\t\t\t\tif (executable.isAnnotationPresent(annotationToFind)) {\n\t\t\t\t\thasAnnotation = true;\n\t\t\t\t}\n\n\t\t\t\t///\n\t\t\t\tfor (var p : executable.getParameters()) {\n\t\t\t\t\tif (p.isAnnotationPresent(annotationToFind)) {\n\t\t\t\t\t\thasAnnotation = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (type.getRecordComponents() != null) {\n\t\t\t\tfor (var r : type.getRecordComponents()) {\n\t\t\t\t\tif (r.isAnnotationPresent(annotationToFind)) {\n\t\t\t\t\t\thasAnnotation = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor (var f : type.getFields()) {\n\t\t\t\tif (f.isAnnotationPresent(annotationToFind)) {\n\t\t\t\t\thasAnnotation = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn hasAnnotation;\n\t}\n\n\tprivate static Set<Class<?>> discoverJacksonAnnotatedTypesFromRootType(Class<?> type) {\n\t\tvar jsonTypes = new HashSet<Class<?>>();\n\t\tvar classesToInspect = new HashSet<Class<?>>();\n\t\tclassesToInspect.add(type);\n\t\tclassesToInspect.addAll(Arrays.asList(type.getNestMembers()));\n\t\tfor (var n : classesToInspect) {\n\t\t\tif (hasJacksonAnnotations(n)) {\n\t\t\t\tjsonTypes.add(n);\n\t\t\t}\n\t\t}\n\t\treturn jsonTypes;\n\t}\n\n}\n```\n# Function Signature: public static Set<TypeReference> findJsonAnnotatedClassesInPackage(String packageName) {\n# Natural Language Annotations: /**\n\t * Finds classes in a package that are annotated with JsonInclude or have Jackson\n\t * annotations.\n\t * @param packageName The name of the package to search for annotated classes.\n\t * @return A set of TypeReference objects representing the annotated classes found.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static Set<TypeReference> findJsonAnnotatedClassesInPackage(String packageName) {\n\t\tvar classPathScanningCandidateComponentProvider = new ClassPathScanningCandidateComponentProvider(false);\n\t\tclassPathScanningCandidateComponentProvider.addIncludeFilter(new AnnotationTypeFilter(JsonInclude.class));\n\t\tclassPathScanningCandidateComponentProvider.addIncludeFilter(new AnnotationTypeFilter(JsonProperty.class));\n\t\treturn classPathScanningCandidateComponentProvider//\n\t\t\t.findCandidateComponents(packageName)//\n\t\t\t.stream()//\n\t\t\t.map(bd -> TypeReference.of(Objects.requireNonNull(bd.getBeanClassName())))//\n\t\t\t.peek(tr -> {\n\t\t\t\tif (log.isDebugEnabled())\n\t\t\t\t\tlog.debug(\"registering [\" + tr.getName() + ']');\n\t\t\t})\n\t\t\t.collect(Collectors.toUnmodifiableSet());\n}\n```", "  ```\npublic static Set<TypeReference> findJsonAnnotatedClassesInPackage(String packageName) {\n\tSet<TypeReference> typeReferences = new HashSet<>();\n\tSet<Class<?>> classes = findClassesInPackage(packageName, new AnnotationTypeFilter(JsonInclude.class, JsonProperty.class));\n\tfor (Class<?> clazz : classes) {\n\t\tif (hasJacksonAnnotations(clazz)) {\n\t\t\ttypeReferences.add(TypeReference.of(clazz));\n\t\t}\n\t}\n\treturn typeReferences;\n}\n```", "  ```\nimport java.lang.reflect.Executable;\nimport java.util.Arrays;\nimport java.util.HashSet;\nimport java.util.Objects;\nimport java.util.Set;\nimport java.util.stream.Collectors;\n\nimport com.fasterxml.jackson.annotation.JsonInclude;\nimport com.fasterxml.jackson.annotation.JsonProperty;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.aot.hint.TypeReference;\nimport org.springframework.core.type.filter.AnnotationTypeFilter;\nimport org.springframework.core.type.filter.TypeFilter;\n\npublic abstract class AiRuntimeHints {\n\n    private static final Logger log = LoggerFactory.getLogger(AiRuntimeHints.class);\n\n    /**\n     * Finds classes in a package that are annotated with JsonInclude or have Jackson\n     * annotations.\n     * @param packageName The name of the package to search for annotated classes.\n     * @return A set of TypeReference objects representing the annotated classes found.\n     */\n    public static Set<TypeReference> findJsonAnnotatedClassesInPackage(String packageName) {\n        var classPathScanningCandidateComponentProvider = new ClassPathScanningCandidateComponentProvider(false);\n        classPathScanningCandidateComponentProvider.addIncludeFilter(new AnnotationTypeFilter(JsonInclude.class));\n        var jsonTypes = classPathScanningCandidateComponentProvider//\n                .findCandidateComponents(packageName)//\n                .stream()//\n                .map(bd -> TypeReference.of(Objects.requireNonNull(bd.getBeanClassName())))//\n                .peek(tr -> {\n                    if (log.isDebugEnabled())\n                        log.debug(\"registering [\" + tr.getName() + ']');\n                })\n                .collect(Collectors.toUnmodifiableSet());\n\n        classPathScanningCandidateComponentProvider.addIncludeFilter(new AnnotationTypeFilter(JsonProperty.class));\n        jsonTypes.addAll(findClassesInPackage(packageName, new TypeFilter() {\n            @Override\n            public boolean match(Class<?> type, Class<?> independent) {\n                return hasJacksonAnnotations(type);\n            }\n        }));\n\n        return jsonTypes;\n    }\n\n    private static boolean hasJacksonAnnotations(Class<?> type) {\n        var hasAnnotation = false;\n        var annotationsToFind = Set.of(JsonProperty.class, JsonInclude.class);\n        for (var annotationToFind : annotationsToFind) {\n\n            if (type.isAnnotationPresent(annotationToFind)) {\n                hasAnnotation = true;\n            }\n\n            var executables = new HashSet<Executable>();\n            executables.addAll(Set.of(type.getMethods()));\n            executables.addAll(Set.of(type.getConstructors()));\n            executables.addAll(Set.of(type.getDeclaredConstructors()));\n\n            for (var executable : executables) {\n                //\n                if (executable.isAnnotationPresent(annotationToFind)) {\n                    hasAnnotation = true;\n                }\n\n                ///\n                for (var p : executable.getParameters()) {\n                    if (p.isAnnotationPresent(annotationToFind)) {\n                        hasAnnotation = true;\n                    }\n                }\n            }\n\n            if (type.getRecordComponents() != null) {\n                for (var r : type.getRecordComponents()) {\n                    if (r.isAnnotationPresent(annotationToFind)) {\n                        hasAnnotation = true;\n                    }\n                }\n            }\n\n            for (var f : type.getFields()) {\n                if (f.isAnnotationPresent(annotationToFind)) {\n                    hasAnnotation = true;\n                }\n            }\n        }\n\n        return hasAnnotation;\n    }\n\n    private static Set<Class<?>> discoverJacksonAnnotatedTypesFromRootType(Class<?> type) {\n        var jsonTypes = new HashSet<Class<?>>();\n        var classesToInspect = new HashSet<Class<?>>();\n        classesToInspect.add(type);\n        classesToInspect.addAll(Arrays.asList(type.getNestMembers()));\n"]}, "spring-ai-document-readers/pdf-reader/src/main/java/org/springframework/ai/reader/pdf/ParagraphPdfDocumentReader.java-get": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/spring-ai/document-readers/pdf-reader/src/main/java/org/springframework/ai/reader/pdf/ParagraphPdfDocumentReader.java:\n```\n/*\n * Copyright 2023 - 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.springframework.ai.reader.pdf;\n\nimport java.awt.Rectangle;\nimport java.util.ArrayList;\nimport java.util.Iterator;\nimport java.util.List;\n\nimport org.apache.pdfbox.pdfparser.PDFParser;\nimport org.apache.pdfbox.pdmodel.PDDocument;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.document.Document;\nimport org.springframework.ai.document.DocumentReader;\nimport org.springframework.ai.reader.pdf.config.ParagraphManager;\nimport org.springframework.ai.reader.pdf.config.ParagraphManager.Paragraph;\nimport org.springframework.ai.reader.pdf.config.PdfDocumentReaderConfig;\nimport org.springframework.ai.reader.pdf.layout.PDFLayoutTextStripperByArea;\nimport org.springframework.core.io.DefaultResourceLoader;\nimport org.springframework.core.io.Resource;\nimport org.springframework.util.CollectionUtils;\nimport org.springframework.util.StringUtils;\n\n/**\n * Uses the PDF catalog (e.g. TOC) information to split the input PDF into text paragraphs\n * and output a single {@link Document} per paragraph.\n *\n * This class provides methods for reading and processing PDF documents. It uses the\n * Apache PDFBox library for parsing PDF content and converting it into text paragraphs.\n * The paragraphs are grouped into {@link Document} objects.\n *\n * @author Christian Tzolov\n */\npublic class ParagraphPdfDocumentReader implements DocumentReader {\n\n\tprivate final Logger logger = LoggerFactory.getLogger(getClass());\n\n\t// Constants for metadata keys\n\tprivate static final String METADATA_START_PAGE = \"page_number\";\n\n\tprivate static final String METADATA_END_PAGE = \"end_page_number\";\n\n\tprivate static final String METADATA_TITLE = \"title\";\n\n\tprivate static final String METADATA_LEVEL = \"level\";\n\n\tprivate static final String METADATA_FILE_NAME = \"file_name\";\n\n\tprivate final ParagraphManager paragraphTextExtractor;\n\n\tprivate final PDDocument document;\n\n\tprivate PdfDocumentReaderConfig config;\n\n\tprivate String resourceFileName;\n\n\t/**\n\t * Constructs a ParagraphPdfDocumentReader using a resource URL.\n\t * @param resourceUrl The URL of the PDF resource.\n\t */\n\tpublic ParagraphPdfDocumentReader(String resourceUrl) {\n\t\tthis(new DefaultResourceLoader().getResource(resourceUrl));\n\t}\n\n\t/**\n\t * Constructs a ParagraphPdfDocumentReader using a resource.\n\t * @param pdfResource The PDF resource.\n\t */\n\tpublic ParagraphPdfDocumentReader(Resource pdfResource) {\n\t\tthis(pdfResource, PdfDocumentReaderConfig.defaultConfig());\n\t}\n\n\t/**\n\t * Constructs a ParagraphPdfDocumentReader using a resource URL and a configuration.\n\t * @param resourceUrl The URL of the PDF resource.\n\t * @param config The configuration for PDF document processing.\n\t */\n\tpublic ParagraphPdfDocumentReader(String resourceUrl, PdfDocumentReaderConfig config) {\n\t\tthis(new DefaultResourceLoader().getResource(resourceUrl), config);\n\t}\n\n\t/**\n\t * Constructs a ParagraphPdfDocumentReader using a resource and a configuration.\n\t * @param pdfResource The PDF resource.\n\t * @param config The configuration for PDF document processing.\n\t */\n\tpublic ParagraphPdfDocumentReader(Resource pdfResource, PdfDocumentReaderConfig config) {\n\n\t\ttry {\n\t\t\tPDFParser pdfParser = new PDFParser(\n\t\t\t\t\tnew org.apache.pdfbox.io.RandomAccessReadBuffer(pdfResource.getInputStream()));\n\t\t\tthis.document = pdfParser.parse();\n\n\t\t\tthis.config = config;\n\n\t\t\tthis.paragraphTextExtractor = new ParagraphManager(this.document);\n\n\t\t\tthis.resourceFileName = pdfResource.getFilename();\n\t\t}\n\t\tcatch (IllegalArgumentException iae) {\n\t\t\tthrow iae;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t/**\n\t * Reads and processes the PDF document to extract paragraphs.\n\t * @return A list of {@link Document} objects representing paragraphs.\n\t */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\tprivate Document toDocument(Paragraph from, Paragraph to) {\n\n\t\tString docText = this.getTextBetweenParagraphs(from, to);\n\n\t\tif (!StringUtils.hasText(docText)) {\n\t\t\treturn null;\n\t\t}\n\n\t\tDocument document = new Document(docText);\n\t\tdocument.getMetadata().put(METADATA_TITLE, from.title());\n\t\tdocument.getMetadata().put(METADATA_START_PAGE, from.startPageNumber());\n\t\tdocument.getMetadata().put(METADATA_END_PAGE, to.startPageNumber());\n\t\tdocument.getMetadata().put(METADATA_LEVEL, from.level());\n\t\tdocument.getMetadata().put(METADATA_FILE_NAME, this.resourceFileName);\n\n\t\treturn document;\n\t}\n\n\tpublic String getTextBetweenParagraphs(Paragraph fromParagraph, Paragraph toParagraph) {\n\n\t\t// Page started from index 0, while PDFBOx getPage return them from index 1.\n\t\tint startPage = fromParagraph.startPageNumber() - 1;\n\t\tint endPage = toParagraph.startPageNumber() - 1;\n\n\t\ttry {\n\n\t\t\tStringBuilder sb = new StringBuilder();\n\n\t\t\tvar pdfTextStripper = new PDFLayoutTextStripperByArea();\n\t\t\tpdfTextStripper.setSortByPosition(true);\n\n\t\t\tfor (int pageNumber = startPage; pageNumber <= endPage; pageNumber++) {\n\n\t\t\t\tvar page = this.document.getPage(pageNumber);\n\n\t\t\t\tint fromPosition = fromParagraph.position();\n\t\t\t\tint toPosition = toParagraph.position();\n\n\t\t\t\tif (this.config.reversedParagraphPosition) {\n\t\t\t\t\tfromPosition = (int) (page.getMediaBox().getHeight() - fromPosition);\n\t\t\t\t\ttoPosition = (int) (page.getMediaBox().getHeight() - toPosition);\n\t\t\t\t}\n\n\t\t\t\tint x0 = (int) page.getMediaBox().getLowerLeftX();\n\t\t\t\tint xW = (int) page.getMediaBox().getWidth();\n\n\t\t\t\tint y0 = (int) page.getMediaBox().getLowerLeftY();\n\t\t\t\tint yW = (int) page.getMediaBox().getHeight();\n\n\t\t\t\tif (pageNumber == startPage) {\n\t\t\t\t\ty0 = fromPosition;\n\t\t\t\t\tyW = (int) page.getMediaBox().getHeight() - y0;\n\t\t\t\t}\n\t\t\t\tif (pageNumber == endPage) {\n\t\t\t\t\tyW = toPosition - y0;\n\t\t\t\t}\n\n\t\t\t\tif ((y0 + yW) == (int) page.getMediaBox().getHeight()) {\n\t\t\t\t\tyW = yW - this.config.pageBottomMargin;\n\t\t\t\t}\n\n\t\t\t\tif (y0 == 0) {\n\t\t\t\t\ty0 = y0 + this.config.pageTopMargin;\n\t\t\t\t\tyW = yW - this.config.pageTopMargin;\n\t\t\t\t}\n\n\t\t\t\tpdfTextStripper.addRegion(\"pdfPageRegion\", new Rectangle(x0, y0, xW, yW));\n\t\t\t\tpdfTextStripper.extractRegions(page);\n\t\t\t\tvar text = pdfTextStripper.getTextForRegion(\"pdfPageRegion\");\n\t\t\t\tif (StringUtils.hasText(text)) {\n\t\t\t\t\tsb.append(text);\n\t\t\t\t}\n\t\t\t\tpdfTextStripper.removeRegion(\"pdfPageRegion\");\n\n\t\t\t}\n\n\t\t\tString text = sb.toString();\n\n\t\t\tif (StringUtils.hasText(text)) {\n\t\t\t\ttext = this.config.pageExtractedTextFormatter.format(text, startPage);\n\t\t\t}\n\n\t\t\treturn text;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n}\n\n```\n# Function Signature: @Override\tpublic List<Document> get() {\n# Natural Language Annotations: /**\n\t * Reads and processes the PDF document to extract paragraphs.\n\t * @return A list of {@link Document} objects representing paragraphs.\n\t */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\npublic List<Document> get() {\n    List<Document> documents = new ArrayList<>();\n    List<Paragraph> paragraphs = this.paragraphTextExtractor.getParagraphs();\n    for (int i = 0; i < paragraphs.size() - 1; i++) {\n        Paragraph fromParagraph = paragraphs.get(i);\n        Paragraph toParagraph = paragraphs.get(i + 1);\n        Document document = this.toDocument(fromParagraph, toParagraph);\n        if (document != null) {\n            documents.add(document);\n        }\n    }\n    return documents;\n}\n```", "  ```java\n@Override\npublic List<Document> get() {\n    List<Document> documents = new ArrayList<>();\n    Iterator<Paragraph> paragraphIt = paragraphTextExtractor.paragraphs().iterator();\n    while (paragraphIt.hasNext()) {\n        Paragraph fromParagraph = paragraphIt.next();\n        Paragraph toParagraph = paragraphIt.hasNext() ? paragraphIt.next() : null;\n        Document document = toDocument(fromParagraph, toParagraph);\n        if (document != null) {\n            documents.add(document);\n        }\n    }\n    return documents;\n}\n```", "  ```\n@Override\npublic List<Document> get() {\n\ttry {\n\t\tList<Document> documents = new ArrayList<>();\n\t\tfor (Paragraph paragraph : this.paragraphTextExtractor.getParagraphs(this.config.startSection, this.config.endSection)) {\n\t\t\tString title = paragraph.title();\n\t\t\tint startPageNumber = paragraph.startPageNumber();\n\t\t\tint endPageNumber = paragraph.endPageNumber();\n\t\t\tint level = paragraph.level();\n\n\t\t\tString text = this.getTextBetweenParagraphs(paragraph, paragraph);\n\t\t\tif (StringUtils.hasText(text)) {\n\t\t\t\tDocument document = new Document(text);\n\t\t\t\tdocument.getMetadata().put(METADATA_TITLE, title);\n\t\t\t\tdocument.getMetadata().put(METADATA_START_PAGE, startPageNumber);\n\t\t\t\tdocument.getMetadata().put(METADATA_END_PAGE, endPageNumber);\n\t\t\t\tdocument.getMetadata().put(METADATA_LEVEL, level);\n\t\t\t\tdocuments.add(document);\n\t\t\t}\n\t\t}\n\t\treturn documents;\n\t}\n\tcatch (Exception e) {\n\t\tthrow new IllegalArgumentException(\"Failed to extract paragraphs\", e);\n\t}\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/FixedBitSet.java-ensureCapacity": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/util/FixedBitSet.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.util;\n\nimport java.util.Arrays;\n\n/**\n * BitSet of fixed length (numBits), backed by accessible ({@link #getBits}) long[], accessed with\n * an int index, implementing {@link Bits}.\n */\npublic final class FixedBitSet extends BitSet {\n    private static final long BASE_RAM_BYTES_USED =\n            RamUsageEstimator.shallowSizeOfInstance(FixedBitSet.class);\n\n    private final long[] bits; // Array of longs holding the bits\n    private final int numBits; // The number of bits in use\n    private final int numWords; // The exact number of longs needed to hold numBits (<= bits.length)\n\n    /**\n     * If the given {@link FixedBitSet} is large enough to hold {@code numBits+1}, returns the given\n     * bits, otherwise returns a new {@link FixedBitSet} which can hold the requested number of bits.\n     *\n     * <p><b>NOTE:</b> the returned bitset reuses the underlying {@code long[]} of the given {@code\n     * bits} if possible. Also, calling {@link #length()} on the returned bits may return a value\n     * greater than {@code numBits}.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /** returns the number of 64 bit words it would take to hold numBits */\n    public static int bits2words(int numBits) {\n        // I.e.: get the word-offset of the last bit and add one (make sure to use >> so 0\n        // returns 0!)\n        return ((numBits - 1) >> 6) + 1;\n    }\n\n    /**\n     * Returns the popcount or cardinality of the intersection of the two sets. Neither set is\n     * modified.\n     */\n    public static long intersectionCount(FixedBitSet a, FixedBitSet b) {\n        // Depends on the ghost bits being clear!\n        long tot = 0;\n        final int numCommonWords = Math.min(a.numWords, b.numWords);\n        for (int i = 0; i < numCommonWords; ++i) {\n            tot += Long.bitCount(a.bits[i] & b.bits[i]);\n        }\n        return tot;\n    }\n\n    /** Returns the popcount or cardinality of the union of the two sets. Neither set is modified. */\n    public static long unionCount(FixedBitSet a, FixedBitSet b) {\n        // Depends on the ghost bits being clear!\n        long tot = 0;\n        final int numCommonWords = Math.min(a.numWords, b.numWords);\n        for (int i = 0; i < numCommonWords; ++i) {\n            tot += Long.bitCount(a.bits[i] | b.bits[i]);\n        }\n        for (int i = numCommonWords; i < a.numWords; ++i) {\n            tot += Long.bitCount(a.bits[i]);\n        }\n        for (int i = numCommonWords; i < b.numWords; ++i) {\n            tot += Long.bitCount(b.bits[i]);\n        }\n        return tot;\n    }\n\n    /**\n     * Returns the popcount or cardinality of \"a and not b\" or \"intersection(a, not(b))\". Neither set\n     * is modified.\n     */\n    public static long andNotCount(FixedBitSet a, FixedBitSet b) {\n        // Depends on the ghost bits being clear!\n        long tot = 0;\n        final int numCommonWords = Math.min(a.numWords, b.numWords);\n        for (int i = 0; i < numCommonWords; ++i) {\n            tot += Long.bitCount(a.bits[i] & ~b.bits[i]);\n        }\n        for (int i = numCommonWords; i < a.numWords; ++i) {\n            tot += Long.bitCount(a.bits[i]);\n        }\n        return tot;\n    }\n\n    /**\n     * Creates a new LongBitSet. The internally allocated long array will be exactly the size needed\n     * to accommodate the numBits specified.\n     *\n     * @param numBits the number of bits needed\n     */\n    public FixedBitSet(int numBits) {\n        this.numBits = numBits;\n        bits = new long[bits2words(numBits)];\n        numWords = bits.length;\n    }\n\n    /**\n     * Creates a new LongBitSet using the provided long[] array as backing store. The storedBits array\n     * must be large enough to accommodate the numBits specified, but may be larger. In that case the\n     * 'extra' or 'ghost' bits must be clear (or they may provoke spurious side-effects)\n     *\n     * @param storedBits the array to use as backing store\n     * @param numBits the number of bits actually needed\n     */\n    public FixedBitSet(long[] storedBits, int numBits) {\n        this.numWords = bits2words(numBits);\n        if (numWords > storedBits.length) {\n            throw new IllegalArgumentException(\n                    \"The given long array is too small  to hold \" + numBits + \" bits\");\n        }\n        this.numBits = numBits;\n        this.bits = storedBits;\n\n        assert verifyGhostBitsClear();\n    }\n\n    @Override\n    public void clear() {\n        Arrays.fill(bits, 0L);\n    }\n\n    /**\n     * Checks if the bits past numBits are clear. Some methods rely on this implicit assumption:\n     * search for \"Depends on the ghost bits being clear!\"\n     *\n     * @return true if the bits past numBits are clear.\n     */\n    private boolean verifyGhostBitsClear() {\n        for (int i = numWords; i < bits.length; i++) {\n            if (bits[i] != 0) return false;\n        }\n\n        if ((numBits & 0x3f) == 0) return true;\n\n        long mask = -1L << numBits;\n\n        return (bits[numWords - 1] & mask) == 0;\n    }\n\n    @Override\n    public int length() {\n        return numBits;\n    }\n\n    /** Expert. */\n    public long[] getBits() {\n        return bits;\n    }\n\n    /**\n     * Returns number of set bits. NOTE: this visits every long in the backing bits array, and the\n     * result is not internally cached!\n     */\n    @Override\n    public int cardinality() {\n        // Depends on the ghost bits being clear!\n        long tot = 0;\n        for (int i = 0; i < numWords; ++i) {\n            tot += Long.bitCount(bits[i]);\n        }\n        return Math.toIntExact(tot);\n    }\n\n    @Override\n    public int approximateCardinality() {\n        // Naive sampling: compute the number of bits that are set on the first 16 longs every 1024\n        // longs and scale the result by 1024/16.\n        // This computes the pop count on ranges instead of single longs in order to take advantage of\n        // vectorization.\n\n        final int rangeLength = 16;\n        final int interval = 1024;\n\n        if (numWords <= interval) {\n            return cardinality();\n        }\n\n        long popCount = 0;\n        int maxWord;\n        for (maxWord = 0; maxWord + interval < numWords; maxWord += interval) {\n            for (int i = 0; i < rangeLength; ++i) {\n                popCount += Long.bitCount(bits[maxWord + i]);\n            }\n        }\n\n        popCount *= (interval / rangeLength) * numWords / maxWord;\n        return (int) popCount;\n    }\n\n    @Override\n    public boolean get(int index) {\n        assert index >= 0 && index < numBits : \"index=\" + index + \", numBits=\" + numBits;\n        int i = index >> 6; // div 64\n        // signed shift will keep a negative index and force an\n        // array-index-out-of-bounds-exception, removing the need for an explicit check.\n        long bitmask = 1L << index;\n        return (bits[i] & bitmask) != 0;\n    }\n\n    @Override\n    public void set(int index) {\n        assert index >= 0 && index < numBits : \"index=\" + index + \", numBits=\" + numBits;\n        int wordNum = index >> 6; // div 64\n        long bitmask = 1L << index;\n        bits[wordNum] |= bitmask;\n    }\n\n    @Override\n    public boolean getAndSet(int index) {\n        assert index >= 0 && index < numBits : \"index=\" + index + \", numBits=\" + numBits;\n        int wordNum = index >> 6; // div 64\n        long bitmask = 1L << index;\n        boolean val = (bits[wordNum] & bitmask) != 0;\n        bits[wordNum] |= bitmask;\n        return val;\n    }\n\n    @Override\n    public void clear(int index) {\n        assert index >= 0 && index < numBits : \"index=\" + index + \", numBits=\" + numBits;\n        int wordNum = index >> 6;\n        long bitmask = 1L << index;\n        bits[wordNum] &= ~bitmask;\n    }\n\n    public boolean getAndClear(int index) {\n        assert index >= 0 && index < numBits : \"index=\" + index + \", numBits=\" + numBits;\n        int wordNum = index >> 6; // div 64\n        long bitmask = 1L << index;\n        boolean val = (bits[wordNum] & bitmask) != 0;\n        bits[wordNum] &= ~bitmask;\n        return val;\n    }\n\n    @Override\n    public int nextSetBit(int index) {\n        if (index >= numBits) {\n            return DocIdSetIterator.NO_MORE_DOCS;\n        }\n\n        // Depends on the ghost bits being clear!\n        assert index >= 0 : \"index=\" + index + \", numBits=\" + numBits;\n        int i = index >> 6;\n        long word = bits[i] >> index; // skip all the bits to the right of index\n\n        if (word != 0) {\n            return index + Long.numberOfTrailingZeros(word);\n        }\n\n        while (++i < numWords) {\n            word = bits[i];\n            if (word != 0) {\n                return (i << 6) + Long.numberOfTrailingZeros(word);\n            }\n        }\n\n        return DocIdSetIterator.NO_MORE_DOCS;\n    }\n\n    @Override\n    public int prevSetBit(int index) {\n        assert index >= 0 && index < numBits : \"index=\" + index + \" numBits=\" + numBits;\n        int i = index >> 6;\n        final int subIndex = index & 0x3f; // index within the word\n        long word = (bits[i] << (63 - subIndex)); // skip all the bits to the left of index\n\n        if (word != 0) {\n            return (i << 6) + subIndex - Long.numberOfLeadingZeros(word); // See LUCENE-3197\n        }\n\n        while (--i >= 0) {\n            word = bits[i];\n            if (word != 0) {\n                return (i << 6) + 63 - Long.numberOfLeadingZeros(word);\n            }\n        }\n\n        return -1;\n    }\n\n    /** this = this OR other */\n    public void or(FixedBitSet other) {\n        or(0, other.bits, other.numWords);\n    }\n\n    private void or(final int otherOffsetWords, FixedBitSet other) {\n        or(otherOffsetWords, other.bits, other.numWords);\n    }\n\n    private void or(final int otherOffsetWords, final long[] otherArr, final int otherNumWords) {\n        assert otherNumWords + otherOffsetWords <= numWords\n                : \"numWords=\" + numWords + \", otherNumWords=\" + otherNumWords;\n        int pos = Math.min(numWords - otherOffsetWords, otherNumWords);\n        final long[] thisArr = this.bits;\n        while (--pos >= 0) {\n            thisArr[pos + otherOffsetWords] |= otherArr[pos];\n        }\n    }\n\n    /** this = this XOR other */\n    public void xor(FixedBitSet other) {\n        xor(other.bits, other.numWords);\n    }\n\n    private void xor(long[] otherBits, int otherNumWords) {\n        assert otherNumWords <= numWords : \"numWords=\" + numWords + \", other.numWords=\" + otherNumWords;\n        final long[] thisBits = this.bits;\n        int pos = Math.min(numWords, otherNumWords);\n        while (--pos >= 0) {\n            thisBits[pos] ^= otherBits[pos];\n        }\n    }\n\n    /** returns true if the sets have any elements in common */\n    public boolean intersects(FixedBitSet other) {\n        // Depends on the ghost bits being clear!\n        int pos = Math.min(numWords, other.numWords);\n        while (--pos >= 0) {\n            if ((bits[pos] & other.bits[pos]) != 0) return true;\n        }\n        return false;\n    }\n\n    /** this = this AND other */\n    public void and(FixedBitSet other) {\n        and(other.bits, other.numWords);\n    }\n\n    private void and(final long[] otherArr, final int otherNumWords) {\n        final long[] thisArr = this.bits;\n        int pos = Math.min(this.numWords, otherNumWords);\n        while (--pos >= 0) {\n            thisArr[pos] &= otherArr[pos];\n        }\n        if (this.numWords > otherNumWords) {\n            Arrays.fill(thisArr, otherNumWords, this.numWords, 0L);\n        }\n    }\n\n    /** this = this AND NOT other */\n    public void andNot(FixedBitSet other) {\n        andNot(0, other.bits, other.numWords);\n    }\n\n    private void andNot(final int otherOffsetWords, FixedBitSet other) {\n        andNot(otherOffsetWords, other.bits, other.numWords);\n    }\n\n    private void andNot(final int otherOffsetWords, final long[] otherArr, final int otherNumWords) {\n        int pos = Math.min(numWords - otherOffsetWords, otherNumWords);\n        final long[] thisArr = this.bits;\n        while (--pos >= 0) {\n            thisArr[pos + otherOffsetWords] &= ~otherArr[pos];\n        }\n    }\n\n    /**\n     * Scans the backing store to check if all bits are clear. The method is deliberately not called\n     * \"isEmpty\" to emphasize it is not low cost (as isEmpty usually is).\n     *\n     * @return true if all bits are clear.\n     */\n    public boolean scanIsEmpty() {\n        // This 'slow' implementation is still faster than any external one could be\n        // (e.g.: (bitSet.length() == 0 || bitSet.nextSetBit(0) == -1))\n        // especially for small BitSets\n        // Depends on the ghost bits being clear!\n        final int count = numWords;\n\n        for (int i = 0; i < count; i++) {\n            if (bits[i] != 0) return false;\n        }\n\n        return true;\n    }\n\n    /**\n     * Flips a range of bits\n     *\n     * @param startIndex lower index\n     * @param endIndex one-past the last bit to flip\n     */\n    public void flip(int startIndex, int endIndex) {\n        assert startIndex >= 0 && startIndex < numBits;\n        assert endIndex >= 0 && endIndex <= numBits;\n        if (endIndex <= startIndex) {\n            return;\n        }\n\n        int startWord = startIndex >> 6;\n        int endWord = (endIndex - 1) >> 6;\n\n        /* Grrr, java shifting uses only the lower 6 bits of the count so -1L>>>64 == -1\n         * for that reason, make sure not to use endmask if the bits to flip will\n         * be zero in the last word (redefine endWord to be the last changed...)\n         * long startmask = -1L << (startIndex & 0x3f);     // example: 11111...111000\n         * long endmask = -1L >>> (64-(endIndex & 0x3f));   // example: 00111...111111\n         */\n\n        long startmask = -1L << startIndex;\n        long endmask = -1L >>> -endIndex;\n\n        if (startWord == endWord) {\n            bits[startWord] ^= (startmask & endmask);\n            return;\n        }\n\n        bits[startWord] ^= startmask;\n\n        for (int i = startWord + 1; i < endWord; i++) {\n            bits[i] = ~bits[i];\n        }\n\n        bits[endWord] ^= endmask;\n    }\n\n    /** Flip the bit at the provided index. */\n    public void flip(int index) {\n        assert index >= 0 && index < numBits : \"index=\" + index + \" numBits=\" + numBits;\n        int wordNum = index >> 6; // div 64\n        long bitmask = 1L << index; // mod 64 is implicit\n        bits[wordNum] ^= bitmask;\n    }\n\n    /**\n     * Sets a range of bits\n     *\n     * @param startIndex lower index\n     * @param endIndex one-past the last bit to set\n     */\n    public void set(int startIndex, int endIndex) {\n        assert startIndex >= 0 && startIndex < numBits\n                : \"startIndex=\" + startIndex + \", numBits=\" + numBits;\n        assert endIndex >= 0 && endIndex <= numBits : \"endIndex=\" + endIndex + \", numBits=\" + numBits;\n        if (endIndex <= startIndex) {\n            return;\n        }\n\n        int startWord = startIndex >> 6;\n        int endWord = (endIndex - 1) >> 6;\n\n        long startmask = -1L << startIndex;\n        long endmask = -1L >>> -endIndex;\n\n        if (startWord == endWord) {\n            bits[startWord] |= (startmask & endmask);\n            return;\n        }\n\n        bits[startWord] |= startmask;\n        Arrays.fill(bits, startWord + 1, endWord, -1L);\n        bits[endWord] |= endmask;\n    }\n\n    @Override\n    public void clear(int startIndex, int endIndex) {\n        assert startIndex >= 0 && startIndex < numBits\n                : \"startIndex=\" + startIndex + \", numBits=\" + numBits;\n        assert endIndex >= 0 && endIndex <= numBits : \"endIndex=\" + endIndex + \", numBits=\" + numBits;\n        if (endIndex <= startIndex) {\n            return;\n        }\n\n        int startWord = startIndex >> 6;\n        int endWord = (endIndex - 1) >> 6;\n\n        long startmask = -1L << startIndex;\n        long endmask = -1L >>> -endIndex;\n\n        // invert masks since we are clearing\n        startmask = ~startmask;\n        endmask = ~endmask;\n\n        if (startWord == endWord) {\n            bits[startWord] &= (startmask | endmask);\n            return;\n        }\n\n        bits[startWord] &= startmask;\n        Arrays.fill(bits, startWord + 1, endWord, 0L);\n        bits[endWord] &= endmask;\n    }\n\n    @Override\n    public FixedBitSet clone() {\n        long[] bits = new long[this.bits.length];\n        System.arraycopy(this.bits, 0, bits, 0, numWords);\n        return new FixedBitSet(bits, numBits);\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) {\n            return true;\n        }\n        if (!(o instanceof FixedBitSet)) {\n            return false;\n        }\n        FixedBitSet other = (FixedBitSet) o;\n        if (numBits != other.numBits) {\n            return false;\n        }\n        // Depends on the ghost bits being clear!\n        return Arrays.equals(bits, other.bits);\n    }\n\n    @Override\n    public int hashCode() {\n        // Depends on the ghost bits being clear!\n        long h = 0;\n        for (int i = numWords; --i >= 0; ) {\n            h ^= bits[i];\n            h = (h << 1) | (h >>> 63); // rotate left\n        }\n        // fold leftmost bits into right and add a constant to prevent\n        // empty sets from returning 0, which is too common.\n        return (int) ((h >> 32) ^ h) + 0x98761234;\n    }\n\n    @Override\n    public long ramBytesUsed() {\n        return BASE_RAM_BYTES_USED + RamUsageEstimator.sizeOf(bits);\n    }\n}\n\n```\n# Function Signature: public static FixedBitSet ensureCapacity(FixedBitSet bits, int numBits) {\n# Natural Language Annotations: /**\n     * If the given {@link FixedBitSet} is large enough to hold {@code numBits+1}, returns the given\n     * bits, otherwise returns a new {@link FixedBitSet} which can hold the requested number of bits.\n     *\n     * <p><b>NOTE:</b> the returned bitset reuses the underlying {@code long[]} of the given {@code\n     * bits} if possible. Also, calling {@link #length()} on the returned bits may return a value\n     * greater than {@code numBits}.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static FixedBitSet ensureCapacity(FixedBitSet bits, int numBits) {\n    if (bits.length() > numBits) {\n        return bits;\n    } else {\n        return new FixedBitSet(Math.max(bits.length() << 1, numBits + 1));\n    }\n}\n```", "  ```\n    public static FixedBitSet ensureCapacity(FixedBitSet bits, int numBits) {\n        if (numBits + 1 > bits.numBits) {\n            return new FixedBitSet(numBits + 1);\n        } else {\n            return bits;\n        }\n    }\n```", "  ```\nFixedBitSet ensureCapacity(FixedBitSet bits, int numBits) {\n    if (bits.bits.length >= bits2words(numBits)) {\n        return bits;\n    } else {\n        long[] newBits = new long[bits2words(numBits)];\n        System.arraycopy(bits.bits, 0, newBits, 0, bits.numWords);\n        return new FixedBitSet(newBits, numBits);\n    }\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/DenseIntMap.java-forEach": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/util/DenseIntMap.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage io.github.jbellis.jvector.util;\n\nimport io.github.jbellis.jvector.graph.NodesIterator;\n\nimport java.util.concurrent.atomic.AtomicInteger;\nimport java.util.concurrent.atomic.AtomicReferenceArray;\nimport java.util.concurrent.locks.ReadWriteLock;\nimport java.util.concurrent.locks.ReentrantReadWriteLock;\nimport java.util.stream.IntStream;\n\n/**\n * A map (but not a Map) of int -> T where the int keys are dense-ish and start at zero,\n * but the size of the map is not known in advance.  This provides fast, concurrent\n * updates and minimizes contention when the map is resized.\n * <p>\n * \"Dense-ish\" means that space is allocated for all keys from 0 to the highest key, but\n * it is valid to have gaps in the keys.  The value associated with \"gap\" keys is null.\n */\npublic class DenseIntMap<T> {\n    // locking strategy:\n    // - writelock to resize the array\n    // - readlock to update the array with put or remove\n    // - no lock to read the array, volatile is enough\n    private final ReadWriteLock rwl = new ReentrantReadWriteLock();\n    private volatile AtomicReferenceArray<T> objects;\n    private final AtomicInteger size;\n\n    public DenseIntMap(int initialSize) {\n        objects = new AtomicReferenceArray<>(initialSize);\n        size = new AtomicInteger();\n    }\n\n    /**\n     * @param key ordinal\n     * Prefer compareAndPut()\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * @param key ordinal\n     * @return true if successful, false if the current value != `existing`\n     */\n    public boolean compareAndPut(int key, T existing, T value) {\n        if (value == null) {\n            throw new IllegalArgumentException(\"compareAndPut() value cannot be null -- use remove() instead\");\n        }\n\n        ensureCapacity(key);\n        rwl.readLock().lock();\n        try {\n            var success = objects.compareAndSet(key, existing, value);\n            var isInsert = success && existing == null;\n            if (isInsert) {\n                size.incrementAndGet();\n            }\n            return success;\n        } finally {\n            rwl.readLock().unlock();\n        }\n    }\n\n    /**\n     * @return number of items that have been added\n     */\n    public int size() {\n        return size.get();\n    }\n\n    /**\n     * @param key ordinal\n     * @return the value of the key, or null if not set\n     */\n    public T get(int key) {\n        if (key >= objects.length()) {\n            return null;\n        }\n\n        return objects.get(key);\n    }\n\n    private void ensureCapacity(int node) {\n        if (node < objects.length()) {\n            return;\n        }\n\n        rwl.writeLock().lock();\n        try {\n            var oldArray = objects;\n            if (node >= oldArray.length()) {\n                int newSize = ArrayUtil.oversize(node + 1, RamUsageEstimator.NUM_BYTES_OBJECT_REF);\n                var newArray = new AtomicReferenceArray<T>(newSize);\n                for (int i = 0; i < oldArray.length(); i++) {\n                    newArray.set(i, oldArray.get(i));\n                }\n                objects = newArray;\n            }\n        } finally {\n            rwl.writeLock().unlock();\n        }\n    }\n\n    /**\n     * @return the former value of the key, or null if it was not set\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public boolean containsKey(int key) {\n        return get(key) != null;\n    }\n\n    public NodesIterator keysIterator() {\n        // implemented here because we can't make it threadsafe AND performant elsewhere\n        var minSize = size(); // if keys are added concurrently we will miss them\n        var ref = objects;\n        var keysInts = IntStream.range(0, ref.length()).filter(i -> ref.get(i) != null).iterator();\n        return NodesIterator.fromPrimitiveIterator(keysInts, minSize);\n    }\n\n    /**\n     * Iterates keys in ascending order and calls the consumer for each non-null key-value pair.\n     */\n\n\n\n\n\n\n\n\n\n\n    @FunctionalInterface\n    public interface IntBiConsumer<T> {\n        void consume(int key, T value);\n    }\n}\n\n```\n# Function Signature: public void forEach(IntBiConsumer<T> consumer) {\n# Natural Language Annotations: /**\n     * Iterates keys in ascending order and calls the consumer for each non-null key-value pair.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic void forEach(IntBiConsumer<T> consumer) {\n    var ref = objects;\n    var keysInts = IntStream.range(0, ref.length()).filter(i -> ref.get(i) != null).iterator();\n    while (keysInts.hasNext()) {\n        var key = keysInts.nextInt();\n        var value = ref.get(key);\n        consumer.consume(key, value);\n    }\n}\n```", "  ```\npublic void forEach(IntBiConsumer<T> consumer) {\n    int minSize = size(); // if keys are added concurrently we will miss them\n    AtomicReferenceArray<T> ref = objects;\n    IntStream.range(0, ref.length()).filter(i -> ref.get(i) != null).forEach(i -> {\n        consumer.consume(i, ref.get(i));\n    });\n}\n```", "  ```\npublic void forEach(IntBiConsumer<T> consumer) {\n    // implemented here because we can't make it threadsafe AND performant elsewhere\n    var minSize = size(); // if keys are added concurrently we will miss them\n    var ref = objects;\n    var keysIterator = keysIterator()\n    while (keysIterator.hasNext()) {\n        int key = keysIterator.next();\n        T value = objects.get(key);\n        if (value != null) {\n            consumer.consume(key, value);\n        }\n    }\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/AbstractLongHeap.java-pop": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/util/AbstractLongHeap.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.util;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\n\n/**\n * A min heap that stores longs; a primitive priority queue that like all priority queues maintains\n * a partial ordering of its elements such that the least element can always be found in constant\n * time. Push()'s and pop()'s require log(size). {@link #push(long)} may either grow the heap or\n * replace the worst element, depending on the subclass implementation.\n * <p>\n * The heap is a min heap, meaning that the top element is the lowest value.\n */\npublic abstract class AbstractLongHeap {\n\n    protected long[] heap;\n    protected int size = 0;\n\n    /**\n     * Create an empty heap with the configured initial size.\n     *\n     * @param initialSize the initial size of the heap\n     */\n    public AbstractLongHeap(int initialSize) {\n        final int heapSize;\n        if (initialSize < 1 || initialSize >= ArrayUtil.MAX_ARRAY_LENGTH) {\n            // Throw exception to prevent confusing OOME:\n            throw new IllegalArgumentException(\n                    \"initialSize must be > 0 and < \" + (ArrayUtil.MAX_ARRAY_LENGTH - 1) + \"; got: \" + initialSize);\n        }\n        // NOTE: we add +1 because all access to heap is 1-based not 0-based.  heap[0] is unused.\n        heapSize = initialSize + 1;\n        this.heap = new long[heapSize];\n    }\n\n    /**\n     * Adds a value to an LongHeap in log(size) time.\n     *\n     * @return true if the new value was added. (A fixed-size heap will not add the new value\n     * if it is full, and the new value is worse than the existing ones.)\n     */\n    public abstract boolean push(long element);\n\n    protected long add(long element) {\n        size++;\n        if (size == heap.length) {\n            heap = ArrayUtil.grow(heap, (size * 3 + 1) / 2);\n        }\n        heap[size] = element;\n        upHeap(size);\n        return heap[1];\n    }\n\n    /**\n     * Returns the least element of the LongHeap in constant time. It is up to the caller to verify\n     * that the heap is not empty; no checking is done, and if no elements have been added, 0 is\n     * returned.\n     */\n    public final long top() {\n        return heap[1];\n    }\n\n    /**\n     * Removes and returns the least element of the PriorityQueue in log(size) time.\n     *\n     * @throws IllegalStateException if the LongHeap is empty.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /** Returns the number of elements currently stored in the PriorityQueue. */\n    public final int size() {\n        return size;\n    }\n\n    /** Removes all entries from the PriorityQueue. */\n    public final void clear() {\n        size = 0;\n    }\n\n    protected void upHeap(int origPos) {\n        int i = origPos;\n        long value = heap[i]; // save bottom value\n        int j = i >>> 1;\n        while (j > 0 && value < heap[j]) {\n            heap[i] = heap[j]; // shift parents down\n            i = j;\n            j = j >>> 1;\n        }\n        heap[i] = value; // install saved value\n    }\n\n    protected void downHeap(int i) {\n        long value = heap[i]; // save top value\n        int j = i << 1; // find smaller child\n        int k = j + 1;\n        if (k <= size && heap[k] < heap[j]) {\n            j = k;\n        }\n        while (j <= size && heap[j] < value) {\n            heap[i] = heap[j]; // shift up child\n            i = j;\n            j = i << 1;\n            k = j + 1;\n            if (k <= size && heap[k] < heap[j]) {\n                j = k;\n            }\n        }\n        heap[i] = value; // install saved value\n    }\n\n    /**\n     * Return the element at the ith location in the heap array. Use for iterating over elements when\n     * the order doesn't matter. Note that the valid arguments range from [1, size].\n     */\n    public long get(int i) {\n        return heap[i];\n    }\n\n    @VisibleForTesting\n    long[] getHeapArray() {\n        return heap;\n    }\n}\n\n```\n# Function Signature: public final long pop() {\n# Natural Language Annotations: /**\n     * Removes and returns the least element of the PriorityQueue in log(size) time.\n     *\n     * @throws IllegalStateException if the LongHeap is empty.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic final long pop() {\n    if (size == 0) {\n        throw new IllegalStateException(\"PriorityQueue is empty.\");\n    }\n    long topElement = heap[1];\n    heap[1] = heap[size];\n    size--;\n    downHeap(1);\n    return topElement;\n}\n```", "  ```\npublic final long pop() {\n    if (size == 0) {\n        throw new IllegalStateException(\"the heap is empty\");\n    }\n\n    long result = heap[1]; // save first value\n    heap[1] = heap[size]; // \n    heap[size] = 0;\n    size--;\n    downHeap(1);\n\n    return result;\n}\n```", "  ```\npublic final long pop() {\n    if (size <= 0) {\n        throw new IllegalStateException(\"The LongHeap is empty.\");\n    }\n    long top = heap[1]; // save top value\n    heap[1] = heap[size]; // move bottom value to top\n    size--; // update size\n    downHeap(1); // adjust heap to make sure it is valid\n    return top;\n} \n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/BoundedLongHeap.java-updateTop": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/util/BoundedLongHeap.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.util;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\n\n/**\n * An AbstractLongHeap with an adjustable maximum size.\n */\npublic class BoundedLongHeap extends AbstractLongHeap {\n\n    private int maxSize;\n\n    /**\n     * Create an empty Heap of the configured initial size.\n     *\n     * @param maxSize the maximum size of the heap\n     */\n    public BoundedLongHeap(int maxSize) {\n        this(maxSize, maxSize);\n    }\n\n    public BoundedLongHeap(int initialSize, int maxSize) {\n        super(initialSize);\n        this.maxSize = maxSize;\n    }\n\n    public void setMaxSize(int maxSize) {\n        if (size > maxSize) {\n            throw new IllegalArgumentException(\"Cannot set maxSize smaller than current size\");\n        }\n        this.maxSize = maxSize;\n    }\n\n    @Override\n    public boolean push(long value) {\n        if (size >= maxSize) {\n            if (value < heap[1]) {\n                return false;\n            }\n            updateTop(value);\n            return true;\n        }\n        add(value);\n        return true;\n    }\n\n    /**\n     * Replace the top of the heap with {@code newTop}, and enforce the heap invariant.\n     * Should be called when the top value changes.\n     * Still log(n) worst case, but it's at least twice as fast to\n     *\n     * <pre class=\"prettyprint\">\n     * pq.updateTop(value);\n     * </pre>\n     * <p>\n     * instead of\n     *\n     * <pre class=\"prettyprint\">\n     * pq.pop();\n     * pq.push(value);\n     * </pre>\n     * <p>\n     * Calling this method on an empty BoundedLongHeap has no visible effect.\n     *\n     * @param value the new element that is less than the current top.\n     * @return the new 'top' element after shuffling the heap.\n     */\n\n\n\n\n\n\n}\n\n```\n# Function Signature: @VisibleForTesting    long updateTop(long value) {\n# Natural Language Annotations: /**\n     * Replace the top of the heap with {@code newTop}, and enforce the heap invariant.\n     * Should be called when the top value changes.\n     * Still log(n) worst case, but it's at least twice as fast to\n     *\n     * <pre class=\"prettyprint\">\n     * pq.updateTop(value);\n     * </pre>\n     * <p>\n     * instead of\n     *\n     * <pre class=\"prettyprint\">\n     * pq.pop();\n     * pq.push(value);\n     * </pre>\n     * <p>\n     * Calling this method on an empty BoundedLongHeap has no visible effect.\n     *\n     * @param value the new element that is less than the current top.\n     * @return the new 'top' element after shuffling the heap.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```java\n@VisibleForTesting\nprivate long updateTop(long value) {\n    if (size == 0) {\n        return value;\n    }\n    long[] heap = this.heap;\n    long backup = heap[1];\n    heap[1] = value;\n    int i = 1;\n    while (i <= maxSize && i * 2 < size + 1) {\n        int child = (i * 2) % maxSize;\n        if (child < maxSize - 1 && heap[child + 1] > heap[child]) {\n            child++;\n        }\n        if (heap[i] < heap[child]) {\n            long temp = heap[i];\n            heap[i] = heap[child];\n            heap[child] = temp;\n            i = child;\n        } else {\n            break;\n        }\n    }\n    return backup;\n}\n```", "  ```java\n@VisibleForTesting\nlong updateTop(long value) {\n    long[] heap = getHeap();\n    int size = getSize();\n    int topIndex = heap[1] == Long.MIN_VALUE ? size - 1 : 1;\n\n    if (size <= 1) {\n        return Long.MIN_VALUE;\n    }\n\n    if (value >= heap[topIndex]) {\n        throw new IllegalArgumentException(\"New top value must be less than current top\");\n    }\n\n    int oldTopIndex = topIndex;\n    heap[topIndex] = value;\n\n    int nextIndex = oldTopIndex * 2;\n    while (nextIndex <= size) {\n        if (nextIndex < size && heap[nextIndex + 1] < heap[nextIndex]) {\n            nextIndex++;\n        }\n\n        if (heap[nextIndex] < value) {\n            break;\n        }\n\n        heap[oldTopIndex] = heap[nextIndex];\n        oldTopIndex = nextIndex;\n        nextIndex = oldTopIndex * 2;\n    }\n\n    heap[oldTopIndex] = value;\n    return heap[topIndex];\n}\n```", "  ```\n@VisibleForTesting\nlong updateTop(long value) {\n    if (size <= 0) {\n        return 0;\n    }\n    if (value <= heap[1]) {\n        return 0;\n    }\n    long oldTop = heap[1];\n    heap[1] = value;\n    shuffleUp();\n    return oldTop;\n}\n```\nThis function is not directly visible to the public because it is annotated with `@VisibleForTesting`. It is intended for use in testing the `BoundedLongHeap` class, and not for use in production code.\n\nThe function peeks at the top element of the heap and checks if it is less than or equal to the given `value`. If the top element is greater than `value`, then the function replaces the top element with `value` and calls the `shuffleUp` function to ensure that the heap remains a valid heap.\n\nThe function returns the old top element, which can be useful for testing purposes. If the heap is empty, then the return value is 0."]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/BQVectors.java-scoreFunctionFor": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/pq/BQVectors.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.pq;\n\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.similarity.ScoreFunction;\nimport io.github.jbellis.jvector.util.RamUsageEstimator;\nimport io.github.jbellis.jvector.vector.VectorSimilarityFunction;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\n\nimport java.io.DataOutput;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.Objects;\n\npublic class BQVectors implements CompressedVectors {\n    private final BinaryQuantization bq;\n    private final long[][] compressedVectors;\n\n    public BQVectors(BinaryQuantization bq, long[][] compressedVectors) {\n        this.bq = bq;\n        this.compressedVectors = compressedVectors;\n    }\n\n    @Override\n    public int count() {\n        return compressedVectors.length;\n    }\n\n    @Override\n    public void write(DataOutput out, int version) throws IOException {\n        // BQ centering data\n        bq.write(out, version);\n\n        // compressed vectors\n        out.writeInt(compressedVectors.length);\n        if (compressedVectors.length <= 0) {\n            return;\n        }\n        out.writeInt(compressedVectors[0].length);\n        for (var v : compressedVectors) {\n            for (long l : v) {\n                out.writeLong(l);\n            }\n        }\n    }\n\n    public static BQVectors load(RandomAccessReader in, long offset) throws IOException {\n        in.seek(offset);\n\n        // BQ\n        var bq = BinaryQuantization.load(in);\n\n        // check validity of compressed vectors header\n        int size = in.readInt();\n        if (size < 0) {\n            throw new IOException(\"Invalid compressed vector count \" + size);\n        }\n        var compressedVectors = new long[size][];\n        if (size == 0) {\n            return new BQVectors(bq, compressedVectors);\n        }\n        int compressedLength = in.readInt();\n        if (compressedLength < 0) {\n            throw new IOException(\"Invalid compressed vector dimension \" + compressedLength);\n        }\n\n        // read the compressed vectors\n        for (int i = 0; i < size; i++)\n        {\n            long[] vector = new long[compressedLength];\n            in.readFully(vector);\n            compressedVectors[i] = vector;\n        }\n\n        return new BQVectors(bq, compressedVectors);\n    }\n\n    @Override\n    public ScoreFunction.ApproximateScoreFunction precomputedScoreFunctionFor(VectorFloat<?> q, VectorSimilarityFunction similarityFunction) {\n        return scoreFunctionFor(q, similarityFunction);\n    }\n\n    /**\n     * Note that `similarityFunction` is ignored, you always get Hamming distance similarity with BQ, which\n     * is a useful approximation for cosine distance and not really anything else.\n     */\n\n\n\n\n\n\n\n\n\n    public float similarityBetween(long[] encoded1, long[] encoded2) {\n        return 1 - (float) VectorUtil.hammingDistance(encoded1, encoded2) / bq.getOriginalDimension();\n    }\n\n    public long[] get(int i) {\n        return compressedVectors[i];\n    }\n\n    @Override\n    public int getOriginalSize() {\n        return bq.getOriginalDimension() * Float.BYTES;\n    }\n\n    @Override\n    public int getCompressedSize() {\n        return compressedVectors[0].length * Long.BYTES;\n    }\n\n    @Override\n    public BinaryQuantization getCompressor() {\n        return bq;\n    }\n\n    @Override\n    public long ramBytesUsed() {\n        return compressedVectors.length * RamUsageEstimator.sizeOf(compressedVectors[0]);\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (o == null || getClass() != o.getClass()) return false;\n        BQVectors bqVectors = (BQVectors) o;\n        return Objects.equals(bq, bqVectors.bq) && Arrays.deepEquals(compressedVectors, bqVectors.compressedVectors);\n    }\n\n    @Override\n    public int hashCode() {\n        int result = Objects.hash(bq);\n        result = 31 * result + Arrays.deepHashCode(compressedVectors);\n        return result;\n    }\n\n    @Override\n    public String toString() {\n        return \"BQVectors{\" +\n               \"bq=\" + bq +\n               \", count=\" + compressedVectors.length +\n               '}';\n    }\n}\n\n```\n# Function Signature: @Override    public ScoreFunction.ApproximateScoreFunction scoreFunctionFor(VectorFloat<?> q, VectorSimilarityFunction similarityFunction) {\n# Natural Language Annotations: /**\n     * Note that `similarityFunction` is ignored, you always get Hamming distance similarity with BQ, which\n     * is a useful approximation for cosine distance and not really anything else.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\npublic ScoreFunction.ApproximateScoreFunction scoreFunctionFor(VectorFloat<?> q, VectorSimilarityFunction similarityFunction) {\n    // Note that `similarityFunction` is ignored, you always get Hamming distance similarity with BQ, which\n    // is a useful approximation for cosine distance and not really anything else.\n    return new ApproximateScoreFunction() {\n        @Override\n        public double score(VectorFloat<?> document) {\n            return similarityBetween(q, document);\n        }\n    };\n}\n```", "  ```\nScoreFunction.ApproximateScoreFunction scoreFunctionFor(VectorFloat<?> q, VectorSimilarityFunction similarityFunction) {\n        // assert similarityFunction == IdentityVectorSimilarityFunction\n        float[] qVector = new float[bq.getOriginalDimension()];\n        for (int i = 0; i < q.size(); i++) {\n            int id = q.get(i);\n            float value = bq.get(id);\n            qVector[id] = value;\n        }\n        return new ApproximateScoreFunction() {\n            @Override\n            public float score(long[] encoded) {\n                return similarityBetween(qVector, bq.unquantize(encoded));\n            }\n        };\n    }\n}\n```", "  ```\nScoreFunction.ApproximateScoreFunction scoreFunctionFor(VectorFloat<?> q, VectorSimilarityFunction similarityFunction) {\n    // The similarityFunction passed to this method is ignored, as BQ always computes Hamming distance similarity.\n    // To get a proportional similarity score, you need to pass a ScoreFunction instance that computes the similarity\n    // between the compressed vectors and the query vector using the Hamming distance. This can be achieved by\n    // calling the scoreFunctionFor method on the bq object, passing in the compressed vector array and query vector.\n    return ScoreFunction.ApproximateScoreFunction.create(() -> {\n        final long[] encodedQuery = bq.encode(q);\n        return (int i) -> similarityBetween(encodedQuery, compressedVectors[i]);\n    });\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-compute": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.pq;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.graph.disk.OnDiskGraphIndex;\nimport io.github.jbellis.jvector.util.Accountable;\nimport io.github.jbellis.jvector.util.PhysicalCoreExecutor;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.VectorizationProvider;\nimport io.github.jbellis.jvector.vector.types.ByteSequence;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\nimport java.io.DataOutput;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\nimport java.util.stream.IntStream;\n\nimport static io.github.jbellis.jvector.pq.KMeansPlusPlusClusterer.UNWEIGHTED;\nimport static io.github.jbellis.jvector.util.MathUtil.square;\nimport static io.github.jbellis.jvector.vector.VectorUtil.dotProduct;\nimport static io.github.jbellis.jvector.vector.VectorUtil.sub;\nimport static java.lang.Math.min;\nimport static java.lang.Math.sqrt;\n\n/**\n * Product Quantization for float vectors.  Supports arbitrary source and target dimensionality;\n * in particular, the source does not need to be evenly divisible by the target.\n */\npublic class ProductQuantization implements VectorCompressor<ByteSequence<?>>, Accountable {\n    private static final int MAGIC = 0x75EC4012; // JVECTOR, with some imagination\n\n    private static final VectorTypeSupport vectorTypeSupport = VectorizationProvider.getInstance().getVectorTypeSupport();\n    static final int DEFAULT_CLUSTERS = 256; // number of clusters per subspace = one byte's worth\n    static final int K_MEANS_ITERATIONS = 6;\n    public static final int MAX_PQ_TRAINING_SET_SIZE = 128000;\n\n    final VectorFloat<?>[] codebooks; // array of codebooks, where each codebook is a VectorFloat consisting of k contiguous subvectors each of length M\n    final int M; // codebooks.length, redundantly reproduced for convenience\n    private final int clusterCount; // codebooks[0].length, redundantly reproduced for convenience\n    final int originalDimension;\n    final VectorFloat<?> globalCentroid;\n    final int[][] subvectorSizesAndOffsets;\n    final float anisotropicThreshold; // parallel cost multiplier\n    private final float[][] centroidNormsSquared; // precomputed norms of the centroids, for encoding\n    private final ThreadLocal<VectorFloat<?>> partialSums; // for dot product, euclidean, and cosine partials\n    private final ThreadLocal<VectorFloat<?>> partialBestDistances; // for partial best distances during fused ADC\n    private final ThreadLocal<ByteSequence<?>> partialQuantizedSums; // for quantized sums during fused ADC\n    private final AtomicReference<VectorFloat<?>> partialSquaredMagnitudes; // for cosine partials\n    private final AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes; // for quantized squared magnitude partials during cosine fused ADC\n    protected volatile float squaredMagnitudeDelta = 0; // for cosine fused ADC squared magnitude quantization delta (since this is invariant for a given PQ)\n    protected volatile float minSquaredMagnitude = 0; // for cosine fused ADC minimum squared magnitude (invariant for a given PQ)\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     */\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter) {\n        return compute(ravv, M, clusterCount, globallyCenter, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold) {\n        return compute(ravv, M, clusterCount, globallyCenter, anisotropicThreshold, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param clusterCount number of clusters per subspace\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     * @param anisotropicThreshold the threshold of relevance for anisotropic angular distance shaping, giving\n     *        higher priority to parallel error.  Anisotropic shaping requires that your dataset be normalized\n     *        to unit length.  Use a threshold of UNWEIGHTED for isotropic distance\n     *        (i.e. normal, unweighted L2 distance).\n     * @param simdExecutor     ForkJoinPool instance for SIMD operations, best is to use a pool with the size of\n     *                         the number of physical cores.\n     * @param parallelExecutor ForkJoinPool instance for parallel stream operations\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static List<VectorFloat<?>> extractTrainingVectors(RandomAccessVectorValues ravv, ForkJoinPool parallelExecutor) {\n        // limit the number of vectors we train on\n        var P = min(1.0f, MAX_PQ_TRAINING_SET_SIZE / (float) ravv.size());\n        var ravvCopy = ravv.threadLocalSupplier();\n        return parallelExecutor.submit(() -> IntStream.range(0, ravv.size()).parallel()\n                        .filter(i -> ThreadLocalRandom.current().nextFloat() < P)\n                        .mapToObj(targetOrd -> {\n                            var localRavv = ravvCopy.get();\n                            VectorFloat<?> v = localRavv.getVector(targetOrd);\n                            return localRavv.isValueShared() ? v.copy() : v;\n                        })\n                        .collect(Collectors.toList()))\n                .join();\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     */\n    public ProductQuantization refine(RandomAccessVectorValues ravv) {\n        return refine(ravv, 1, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     *\n     * @param lloydsRounds number of Lloyd's iterations to run against\n     *                     the new data.  Suggested values are 1 or 2.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    ProductQuantization(VectorFloat<?>[] codebooks, int clusterCount, int[][] subvectorSizesAndOffsets, VectorFloat<?> globalCentroid, float anisotropicThreshold) {\n        this.codebooks = codebooks;\n        this.globalCentroid = globalCentroid;\n        this.M = codebooks.length;\n        this.clusterCount = clusterCount;\n        this.subvectorSizesAndOffsets = subvectorSizesAndOffsets;\n        this.originalDimension = Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum();\n        if (globalCentroid != null && globalCentroid.length() != originalDimension) {\n            var msg = String.format(\"Global centroid length %d does not match vector dimensionality %d\", globalCentroid.length(), originalDimension);\n            throw new IllegalArgumentException(msg);\n        }\n        this.anisotropicThreshold = anisotropicThreshold;\n        this.partialSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount() * getClusterCount()));\n        this.partialBestDistances = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount()));\n        this.partialQuantizedSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createByteSequence(getSubspaceCount() * getClusterCount() * 2));\n        this.partialSquaredMagnitudes = new AtomicReference<>(null);\n        this.partialQuantizedSquaredMagnitudes= new AtomicReference<>(null);\n\n\n        centroidNormsSquared = new float[M][clusterCount];\n        for (int i = 0; i < M; i++) {\n            for (int j = 0; j < clusterCount; j++) {\n                centroidNormsSquared[i][j] = dotProduct(codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        subvectorSizesAndOffsets[i][0]);\n            }\n        }\n    }\n\n    @Override\n    public CompressedVectors createCompressedVectors(Object[] compressedVectors) {\n        return new PQVectors(this, (ByteSequence<?>[]) compressedVectors);\n    }\n\n    /**\n     * Encodes the given vectors in parallel using the PQ codebooks.\n     */\n    @Override\n    public ByteSequence<?>[] encodeAll(RandomAccessVectorValues ravv, ForkJoinPool simdExecutor) {\n        return simdExecutor.submit(() -> IntStream.range(0, ravv.size())\n                        .parallel()\n                        .mapToObj(i -> encode(ravv.getVector(i)))\n                        .toArray(ByteSequence<?>[]::new))\n                .join();\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks, weighing parallel loss more than orthogonal loss.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private CoordinateDescentResult optimizeSingleSubspace(Residual[] residuals, int oldIdx, float oldParallelResidualSum) {\n        // (this is global to all subspaces but it's not worth stashing in a field)\n        float pcm = KMeansPlusPlusClusterer.computeParallelCostMultiplier(anisotropicThreshold, originalDimension);\n\n        float oldResidualNormSquared = residuals[oldIdx].residualNormSquared;\n        float oldParallelComponent = residuals[oldIdx].parallelResidualComponent;\n\n        float bestCostDelta = 0;\n        int bestIndex = oldIdx;\n        float bestParallelResidualSum = oldParallelResidualSum;\n\n        // loop over potential new centers\n        for (int thisIdx = 0; thisIdx < residuals.length; thisIdx++) {\n            if (thisIdx == oldIdx) {\n                continue;\n            }\n\n            // compute the new parallel residual sum and parallel norm delta\n            Residual rs = residuals[thisIdx];\n            float thisParallelResidualSum = oldParallelResidualSum - oldParallelComponent + rs.parallelResidualComponent;\n            float parallelNormDelta = square(thisParallelResidualSum) - square(oldParallelResidualSum);\n            // quit early if new parallel norm is worse than the old\n            if (parallelNormDelta > 0) {\n                continue;\n            }\n\n            // compute the total cost delta\n            float residualNormDelta = rs.residualNormSquared - oldResidualNormSquared;\n            float perpendicularNormDelta = residualNormDelta - parallelNormDelta;\n            float costDelta = pcm * parallelNormDelta + perpendicularNormDelta;\n\n            // save the new center if it's the best so far\n            if (costDelta < bestCostDelta) {\n                bestCostDelta = costDelta;\n                bestIndex = thisIdx;\n                bestParallelResidualSum = thisParallelResidualSum;\n            }\n        }\n\n        return new CoordinateDescentResult(bestIndex, bestParallelResidualSum);\n    }\n\n    /**\n     * Wraps the two values we want to return from optimizeSingleSubspace\n     */\n    private static class CoordinateDescentResult {\n        final int newCenterIdx;\n        final float newParallelResidualComponent;\n\n        CoordinateDescentResult(int newCenterIdx, float newParallelResidualComponent) {\n            this.newCenterIdx = newCenterIdx;\n            this.newParallelResidualComponent = newParallelResidualComponent;\n        }\n    }\n\n    /**\n     * @return codebook ordinals representing the cluster centroids for each subspace that minimize the residual norm\n     */\n    private ByteSequence<?> initializeToMinResidualNorms(Residual[][] residualStats) {\n        var result = vectorTypeSupport.createByteSequence(residualStats.length);\n        // for each subspace\n        for (int i = 0; i < residualStats.length; i++) {\n            int minIndex = -1;\n            double minNormSquared = Double.MAX_VALUE;\n            // find the centroid with the smallest residual norm in this subspace\n            for (int j = 0; j < residualStats[i].length; j++) {\n                if (residualStats[i][j].residualNormSquared < minNormSquared) {\n                    minNormSquared = residualStats[i][j].residualNormSquared;\n                    minIndex = j;\n                }\n            }\n            result.set(i, (byte) minIndex);\n        }\n        return result;\n    }\n\n    /**\n     * @return the parallel-cost residuals for each subspace and cluster\n     */\n    private Residual[][] computeResiduals(VectorFloat<?> vector) {\n        Residual[][] residuals = new Residual[codebooks.length][];\n\n        float inverseNorm = (float) (1.0 / sqrt(dotProduct(vector, vector)));\n        for (int i = 0; i < codebooks.length; i++) {\n            var x = getSubVector(vector, i, subvectorSizesAndOffsets);\n            float xNormSquared = dotProduct(x, x);\n            residuals[i] = new Residual[clusterCount];\n\n            for (int j = 0; j < clusterCount; j++) {\n                residuals[i][j] = computeResidual(x, codebooks[i], j, centroidNormsSquared[i][j], xNormSquared, inverseNorm);\n            }\n        }\n\n        return residuals;\n    }\n\n    /**\n     * Represents the residual after subtracting a cluster centroid from a [sub]vector.\n     */\n    private static class Residual {\n        final float residualNormSquared;\n        final float parallelResidualComponent;\n\n        Residual(float residualNormSquared, float parallelResidualComponent) {\n            this.residualNormSquared = residualNormSquared;\n            this.parallelResidualComponent = parallelResidualComponent;\n        }\n    }\n\n    private Residual computeResidual(VectorFloat<?> x, VectorFloat<?> centroids, int centroid, float cNormSquared, float xNormSquared, float inverseNorm) {\n        float cDotX = VectorUtil.dotProduct(centroids, centroid * x.length(), x, 0, x.length());\n        float residualNormSquared = cNormSquared - 2 * cDotX + xNormSquared;\n        float parallelErrorSubtotal = cDotX - xNormSquared;\n        float parallelResidualComponent = square(parallelErrorSubtotal) * inverseNorm;\n        return new Residual(residualNormSquared, parallelResidualComponent);\n    }\n\n    private ByteSequence<?> encodeUnweighted(VectorFloat<?> vector) {\n        var encoded = vectorTypeSupport.createByteSequence(M);\n        for (int m = 0; m < M; m++) {\n            encoded.set(m, (byte) closestCentroidIndex(vector, m, codebooks[m]));\n        }\n        return encoded;\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector, relative to the global centroid.\n     */\n\n\n\n\n\n\n\n    /**\n     * @return how many bytes we are compressing to\n     */\n    public int getSubspaceCount() {\n        return M;\n    }\n\n    /**\n     * @return number of clusters per subspace\n     */\n    public int getClusterCount() {\n        return clusterCount;\n    }\n\n    static VectorFloat<?>[] createCodebooks(List<VectorFloat<?>> vectors, int[][] subvectorSizeAndOffset, int clusters, float anisotropicThreshold, ForkJoinPool simdExecutor) {\n        int M = subvectorSizeAndOffset.length;\n        return simdExecutor.submit(() -> IntStream.range(0, M).parallel().mapToObj(m -> {\n            VectorFloat<?>[] subvectors = extractSubvectors(vectors, m, subvectorSizeAndOffset);\n            var clusterer = new KMeansPlusPlusClusterer(subvectors, clusters, anisotropicThreshold);\n            return clusterer.cluster(K_MEANS_ITERATIONS, anisotropicThreshold == UNWEIGHTED ? 0 : K_MEANS_ITERATIONS);\n        }).toArray(VectorFloat<?>[]::new)).join();\n    }\n\n    /**\n     * Extract VectorFloat subvectors corresponding to the m'th subspace.\n     * This is NOT done in parallel (since the callers are themselves running in parallel).\n     */\n    private static VectorFloat<?>[] extractSubvectors(List<VectorFloat<?>> vectors, int m, int[][] subvectorSizeAndOffset) {\n        return vectors.stream()\n                .map(vector -> getSubVector(vector, m, subvectorSizeAndOffset))\n                .toArray(VectorFloat<?>[]::new);\n    }\n\n    int closestCentroidIndex(VectorFloat<?> subvector, int m, VectorFloat<?> codebook) {\n        int index = 0;\n        float minDist = Float.MAX_VALUE;\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        for (int i = 0; i < clusterCount; i++) {\n            float dist = VectorUtil.squareL2Distance(subvector, subvectorOffset, codebook, i * subvectorSize, subvectorSize);\n            if (dist < minDist) {\n                minDist = dist;\n                index = i;\n            }\n        }\n        return index;\n    }\n\n    /**\n     * Extracts the m-th subvector from a single vector.\n     */\n    static VectorFloat<?> getSubVector(VectorFloat<?> vector, int m, int[][] subvectorSizeAndOffset) {\n        VectorFloat<?> subvector = vectorTypeSupport.createFloatVector(subvectorSizeAndOffset[m][0]);\n        subvector.copyFrom(vector, subvectorSizeAndOffset[m][1], 0, subvectorSizeAndOffset[m][0]);\n        return subvector;\n    }\n\n    /**\n     * Splits the vector dimension into M subvectors of roughly equal size.\n     */\n    @VisibleForTesting\n    static int[][] getSubvectorSizesAndOffsets(int dimensions, int M) {\n        if (M > dimensions) {\n            throw new IllegalArgumentException(\"Number of subspaces must be less than or equal to the vector dimension\");\n        }\n        int[][] sizes = new int[M][];\n        int baseSize = dimensions / M;\n        int remainder = dimensions % M;\n        // distribute the remainder among the subvectors\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            int size = baseSize + (i < remainder ? 1 : 0);\n            sizes[i] = new int[]{size, offset};\n            offset += size;\n        }\n        return sizes;\n    }\n\n    VectorFloat<?> reusablePartialSums() {\n        return partialSums.get();\n    }\n\n    ByteSequence<?> reusablePartialQuantizedSums() {\n        return partialQuantizedSums.get();\n    }\n\n    VectorFloat<?> reusablePartialBestDistances() {\n        return partialBestDistances.get();\n    }\n\n    AtomicReference<VectorFloat<?>> partialSquaredMagnitudes() {\n        return partialSquaredMagnitudes;\n    }\n\n    AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes() {\n        return partialQuantizedSquaredMagnitudes;\n    }\n\n    public void write(DataOutput out, int version) throws IOException\n    {\n        if (version > OnDiskGraphIndex.CURRENT_VERSION) {\n            throw new IllegalArgumentException(\"Unsupported serialization version \" + version);\n        }\n        if (version < 3 && anisotropicThreshold != UNWEIGHTED) {\n            throw new IllegalArgumentException(\"Anisotropic threshold is only supported in serialization version 3 and above\");\n        }\n\n        if (version >= 3) {\n            out.writeInt(MAGIC);\n            out.writeInt(version);\n        }\n\n        if (globalCentroid == null) {\n            out.writeInt(0);\n        } else {\n            out.writeInt(globalCentroid.length());\n            vectorTypeSupport.writeFloatVector(out, globalCentroid);\n        }\n\n        out.writeInt(M);\n        assert Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum() == originalDimension;\n        assert M == subvectorSizesAndOffsets.length;\n        for (var a : subvectorSizesAndOffsets) {\n            out.writeInt(a[0]);\n        }\n\n        if (version >= 3) {\n            out.writeFloat(anisotropicThreshold);\n        }\n\n        assert codebooks.length == M;\n        out.writeInt(clusterCount);\n        for (int i = 0; i < M; i++) {\n            var codebook = codebooks[i];\n            assert codebook.length() == clusterCount * subvectorSizesAndOffsets[i][0];\n            vectorTypeSupport.writeFloatVector(out, codebook);\n        }\n    }\n\n    @Override\n    public int compressorSize() {\n        int size = 0;\n        size += Integer.BYTES; // MAGIC\n        size += Integer.BYTES; // STORAGE_VERSION\n        size += Integer.BYTES; // globalCentroidLength\n        if (globalCentroid != null) {\n            size += Float.BYTES * globalCentroid.length();\n        }\n        size += Integer.BYTES; // M\n        size += Integer.BYTES * M; // subvectorSizesAndOffsets (only the sizes are written)\n        size += Float.BYTES; // anisotropicThreshold\n        size += Integer.BYTES; // clusterCount\n        for (int i = 0; i < M; i++) {\n            size += Float.BYTES * codebooks[i].length();\n        }\n        return size;\n    }\n\n    public static ProductQuantization load(RandomAccessReader in) throws IOException {\n        int maybeMagic = in.readInt();\n        int version;\n        int globalCentroidLength;\n        if (maybeMagic != MAGIC) {\n            // JVector 1+2 format, no magic or version, starts straight off with the centroid length\n            version = 0;\n            globalCentroidLength = maybeMagic;\n        } else {\n            version = in.readInt();\n            globalCentroidLength = in.readInt();\n        }\n\n        VectorFloat<?> globalCentroid = null;\n        if (globalCentroidLength > 0) {\n            globalCentroid = vectorTypeSupport.readFloatVector(in, globalCentroidLength);\n        }\n\n        int M = in.readInt();\n        int[][] subvectorSizes = new int[M][];\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            subvectorSizes[i] = new int[2];\n            int size = in.readInt();\n            subvectorSizes[i][0] = size;\n\n```\n# Function Signature: public static ProductQuantization compute(\n# Natural Language Annotations: /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param clusterCount number of clusters per subspace\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     * @param anisotropicThreshold the threshold of relevance for anisotropic angular distance shaping, giving\n     *        higher priority to parallel error.  Anisotropic shaping requires that your dataset be normalized\n     *        to unit length.  Use a threshold of UNWEIGHTED for isotropic distance\n     *        (i.e. normal, unweighted L2 distance).\n     * @param simdExecutor     ForkJoinPool instance for SIMD operations, best is to use a pool with the size of\n     *                         the number of physical cores.\n     * @param parallelExecutor ForkJoinPool instance for parallel stream operations\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npackage io.github.jbellis.jvector.pq;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.graph.disk.OnDiskGraphIndex;\nimport io.github.jbellis.jvector.util.Accountable;\nimport io.github.jbellis.jvector.util.PhysicalCoreExecutor;\nimport io.github.jbellis.jvector.pq.KMeansPlusPlusClusterer;\nimport io.github.jbellis.jvector.pq.ProductQuantization;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.VectorTypeSupport;\nimport io.github.jbellis.jvector.vector.VectorFloat;\nimport io.github.jbellis.jvector.vector.VectorizationProvider;\nimport io.github.jbellis.jvector.vector.types.ByteSequence;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\n\nimport java.io.DataOutput;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\nimport java.util.stream.IntStream;\n\npublic class ProductQuantization {\n    \n    private static final int MAGIC = 0x75EC4012; // JVECTOR, with some imagination\n\n    private static final VectorTypeSupport vectorTypeSupport = VectorizationProvider.getInstance().getVectorTypeSupport();\n    static final int DEFAULT_CLUSTERS = 256; // number of clusters per subspace = one byte's worth\n    static final int K_MEANS_ITERATIONS = 6;\n    public static final int MAX_PQ_TRAINING_SET_SIZE = 128000;\n\n    final VectorFloat<?>[] codebooks; // array of codebooks, where each codebook is a VectorFloat consisting of k contiguous subvectors each of length M\n    final int M; // codebooks.length, redundantly reproduced for convenience\n    private final int clusterCount; // codebooks[0].length, redundantly reproduced for convenience\n    final int originalDimension;\n    final VectorFloat<?> globalCentroid;\n    final int[][] subvectorSizesAndOffsets;\n    final float anisotropicThreshold; // parallel cost multiplier\n    private final float[][] centroidNormsSquared; // precomputed norms of the centroids, for encoding\n    private final ThreadLocal<VectorFloat<?>> partialSums; // for dot product, euclidean, and cosine partials\n    private final ThreadLocal<VectorFloat<?>> partialBestDistances; // for partial best distances during fused ADC\n    private final ThreadLocal<ByteSequence<?>> partialQuantizedSums; // for quantized sums during fused ADC\n    private final AtomicReference<VectorFloat<?>> partialSquaredMagnitudes; // for cosine partials\n    private final AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes; // for quantized squared magnitude partials during cosine fused ADC\n    protected volatile float squaredMagnitudeDelta = 0; // for cosine fused ADC squared magnitude quantization delta (since this is invariant for a given PQ)\n    protected volatile float minSquaredMagnitude = 0; // for cosine fused ADC minimum squared magnitude (invariant for a given PQ)\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param clusterCount number of clusters per subspace\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     */", "  ```\npublic static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold, ForkJoinPool simdExecutor, ForkJoinPool parallelExecutor) {\n        // limit the number of vectors we train on\n        var P = min(1.0f, MAX_PQ_TRAINING_SET_SIZE / (float) ravv.size());\n        var ravvCopy = ravv.threadLocalSupplier();\n        var trainingVectors = parallelExecutor.submit(() -> IntStream.range(0, ravv.size()).parallel()\n            .filter(i -> ThreadLocalRandom.current().nextFloat() < P)\n            .mapToObj(targetOrd -> {\n                var localRavv = ravvCopy.get();\n                VectorFloat<?> v = localRavv.getVector(targetOrd);\n                return localRavv.isValueShared() ? v.copy() : v;\n            })\n            .collect(Collectors.toList()))\n            .join();\n\n        if (globallyCenter) {\n            VectorFloat<?> vectorSum = trainingVectors.stream()\n                .map(vector -> (VectorFloat<?>) vector.toArray())\n                .reduce(vectorTypeSupport.createFloatVector(M), vectorTypeSupport::add);\n            float meanLengthSquared = dotProduct(vectorSum, vectorSum) / trainingVectors.size();\n            float meanLength = (float) Math.sqrt(meanLengthSquared);\n            globalCentroid = vectorTypeSupport.createFloatVector(M);\n            for (int i = 0; i < M; i++) {\n                globalCentroid.set(i, vectorSum.get(i) / meanLength);\n            }\n        } else {\n            globalCentroid = null;\n        }\n\n        var centroidComputer = new CentroidComputer(trainingVectors, M, clusterCount, anisotropicThreshold, simdExecutor, parallelExecutor);\n        centroidComputer.computeCentroids();\n\n        var codebooks = centroidComputer.getCodebooks();\n        var subvectorSizesAndOffsets = getSubvectorSizesAndOffsets(M, RavVector.stdSize(trainingVectors.get(0).toArray()), clusterCount);\n\n        return new ProductQuantization(codebooks, clusterCount, subvectorSizesAndOffsets, globalCentroid, anisotropicThreshold);\n    }\n```", "  ```\npackage io.github.jbellis.jvector.pq;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.graph.disk.OnDiskGraphIndex;\nimport io.github.jbellis.jvector.util.Accountable;\nimport io.github.jbellis.jvector.util.PhysicalCoreExecutor;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.types.ByteSequence;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\nimport java.io.DataOutput;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\nimport java.util.stream.IntStream;\n\npublic class ProductQuantization implements VectorCompressor<ByteSequence<?>>, Accountable {\n\n    // Private constructor to prevent instantiation\n    private ProductQuantization() {}\n\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter) {\n        return compute(ravv, M, clusterCount, globallyCenter, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold) {\n        return compute(ravv, M, clusterCount, globallyCenter, anisotropicThreshold, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold,\n                                             ForkJoinPool simdExecutor, ForkJoinPool parallelExecutor) {\n        validateArguments(ravv, M, clusterCount, globallyCenter, anisotropicThreshold, simdExecutor, parallelExecutor);\n\n        int originalDimension = ravv.size() > 0 ? ravv.getVector(0).length() : 0;\n\n        // Apply global centering if requested\n        if (globallyCenter) {\n            var centroid = VectorUtil.l2Normalize(ravv.getCentroidVector(parallelExecutor));\n            parallelExecutor.submit(() -> IntStream.range(0, ravv.size()).parallel().forEach(i -> {\n                var vector = ravv.getVector(i);\n                VectorUtil.sub(vector, 0, centroid, 0, vector, 0);\n            })).join();\n        }\n\n        // Extract training vectors\n        var trainingVectors = extractTrainingVectors(ravv, parallelExecutor);\n\n        // Run initial K-means++ clustering\n        var clusterer = new KMeansPlusPlusClusterer(trainingVectors.toArray(VectorFloat[]::new), clusterCount, anisotropicThreshold);\n        var initialClusters = clusterer.cluster(K_MEANS_ITERATIONS, anisotropicThreshold == UNWEIGHTED ? 0 : K_MEANS_ITERATIONS);\n\n        // Create subvector sizes and offsets\n        int[][] subvectorSizeAndOffset = getSubvectorSizesAndOffsets(originalDimension, M);\n\n        // Compute codebooks\n        var codebooks = createCodebooks(trainingVectors, subvectorSizeAndOffset, clusterCount, anisotropicThreshold, simdExecutor);\n\n        var pq = new ProductQuantization(codebooks, clusterCount, subvectorSizeAndOffset, centroid, anisotropicThreshold);\n\n        return pq;\n    }\n\n    private static void validateArguments(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-refine": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.pq;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.graph.disk.OnDiskGraphIndex;\nimport io.github.jbellis.jvector.util.Accountable;\nimport io.github.jbellis.jvector.util.PhysicalCoreExecutor;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.VectorizationProvider;\nimport io.github.jbellis.jvector.vector.types.ByteSequence;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\nimport java.io.DataOutput;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\nimport java.util.stream.IntStream;\n\nimport static io.github.jbellis.jvector.pq.KMeansPlusPlusClusterer.UNWEIGHTED;\nimport static io.github.jbellis.jvector.util.MathUtil.square;\nimport static io.github.jbellis.jvector.vector.VectorUtil.dotProduct;\nimport static io.github.jbellis.jvector.vector.VectorUtil.sub;\nimport static java.lang.Math.min;\nimport static java.lang.Math.sqrt;\n\n/**\n * Product Quantization for float vectors.  Supports arbitrary source and target dimensionality;\n * in particular, the source does not need to be evenly divisible by the target.\n */\npublic class ProductQuantization implements VectorCompressor<ByteSequence<?>>, Accountable {\n    private static final int MAGIC = 0x75EC4012; // JVECTOR, with some imagination\n\n    private static final VectorTypeSupport vectorTypeSupport = VectorizationProvider.getInstance().getVectorTypeSupport();\n    static final int DEFAULT_CLUSTERS = 256; // number of clusters per subspace = one byte's worth\n    static final int K_MEANS_ITERATIONS = 6;\n    public static final int MAX_PQ_TRAINING_SET_SIZE = 128000;\n\n    final VectorFloat<?>[] codebooks; // array of codebooks, where each codebook is a VectorFloat consisting of k contiguous subvectors each of length M\n    final int M; // codebooks.length, redundantly reproduced for convenience\n    private final int clusterCount; // codebooks[0].length, redundantly reproduced for convenience\n    final int originalDimension;\n    final VectorFloat<?> globalCentroid;\n    final int[][] subvectorSizesAndOffsets;\n    final float anisotropicThreshold; // parallel cost multiplier\n    private final float[][] centroidNormsSquared; // precomputed norms of the centroids, for encoding\n    private final ThreadLocal<VectorFloat<?>> partialSums; // for dot product, euclidean, and cosine partials\n    private final ThreadLocal<VectorFloat<?>> partialBestDistances; // for partial best distances during fused ADC\n    private final ThreadLocal<ByteSequence<?>> partialQuantizedSums; // for quantized sums during fused ADC\n    private final AtomicReference<VectorFloat<?>> partialSquaredMagnitudes; // for cosine partials\n    private final AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes; // for quantized squared magnitude partials during cosine fused ADC\n    protected volatile float squaredMagnitudeDelta = 0; // for cosine fused ADC squared magnitude quantization delta (since this is invariant for a given PQ)\n    protected volatile float minSquaredMagnitude = 0; // for cosine fused ADC minimum squared magnitude (invariant for a given PQ)\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     */\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter) {\n        return compute(ravv, M, clusterCount, globallyCenter, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold) {\n        return compute(ravv, M, clusterCount, globallyCenter, anisotropicThreshold, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param clusterCount number of clusters per subspace\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     * @param anisotropicThreshold the threshold of relevance for anisotropic angular distance shaping, giving\n     *        higher priority to parallel error.  Anisotropic shaping requires that your dataset be normalized\n     *        to unit length.  Use a threshold of UNWEIGHTED for isotropic distance\n     *        (i.e. normal, unweighted L2 distance).\n     * @param simdExecutor     ForkJoinPool instance for SIMD operations, best is to use a pool with the size of\n     *                         the number of physical cores.\n     * @param parallelExecutor ForkJoinPool instance for parallel stream operations\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static List<VectorFloat<?>> extractTrainingVectors(RandomAccessVectorValues ravv, ForkJoinPool parallelExecutor) {\n        // limit the number of vectors we train on\n        var P = min(1.0f, MAX_PQ_TRAINING_SET_SIZE / (float) ravv.size());\n        var ravvCopy = ravv.threadLocalSupplier();\n        return parallelExecutor.submit(() -> IntStream.range(0, ravv.size()).parallel()\n                        .filter(i -> ThreadLocalRandom.current().nextFloat() < P)\n                        .mapToObj(targetOrd -> {\n                            var localRavv = ravvCopy.get();\n                            VectorFloat<?> v = localRavv.getVector(targetOrd);\n                            return localRavv.isValueShared() ? v.copy() : v;\n                        })\n                        .collect(Collectors.toList()))\n                .join();\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     */\n    public ProductQuantization refine(RandomAccessVectorValues ravv) {\n        return refine(ravv, 1, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     *\n     * @param lloydsRounds number of Lloyd's iterations to run against\n     *                     the new data.  Suggested values are 1 or 2.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    ProductQuantization(VectorFloat<?>[] codebooks, int clusterCount, int[][] subvectorSizesAndOffsets, VectorFloat<?> globalCentroid, float anisotropicThreshold) {\n        this.codebooks = codebooks;\n        this.globalCentroid = globalCentroid;\n        this.M = codebooks.length;\n        this.clusterCount = clusterCount;\n        this.subvectorSizesAndOffsets = subvectorSizesAndOffsets;\n        this.originalDimension = Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum();\n        if (globalCentroid != null && globalCentroid.length() != originalDimension) {\n            var msg = String.format(\"Global centroid length %d does not match vector dimensionality %d\", globalCentroid.length(), originalDimension);\n            throw new IllegalArgumentException(msg);\n        }\n        this.anisotropicThreshold = anisotropicThreshold;\n        this.partialSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount() * getClusterCount()));\n        this.partialBestDistances = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount()));\n        this.partialQuantizedSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createByteSequence(getSubspaceCount() * getClusterCount() * 2));\n        this.partialSquaredMagnitudes = new AtomicReference<>(null);\n        this.partialQuantizedSquaredMagnitudes= new AtomicReference<>(null);\n\n\n        centroidNormsSquared = new float[M][clusterCount];\n        for (int i = 0; i < M; i++) {\n            for (int j = 0; j < clusterCount; j++) {\n                centroidNormsSquared[i][j] = dotProduct(codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        subvectorSizesAndOffsets[i][0]);\n            }\n        }\n    }\n\n    @Override\n    public CompressedVectors createCompressedVectors(Object[] compressedVectors) {\n        return new PQVectors(this, (ByteSequence<?>[]) compressedVectors);\n    }\n\n    /**\n     * Encodes the given vectors in parallel using the PQ codebooks.\n     */\n    @Override\n    public ByteSequence<?>[] encodeAll(RandomAccessVectorValues ravv, ForkJoinPool simdExecutor) {\n        return simdExecutor.submit(() -> IntStream.range(0, ravv.size())\n                        .parallel()\n                        .mapToObj(i -> encode(ravv.getVector(i)))\n                        .toArray(ByteSequence<?>[]::new))\n                .join();\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks, weighing parallel loss more than orthogonal loss.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private CoordinateDescentResult optimizeSingleSubspace(Residual[] residuals, int oldIdx, float oldParallelResidualSum) {\n        // (this is global to all subspaces but it's not worth stashing in a field)\n        float pcm = KMeansPlusPlusClusterer.computeParallelCostMultiplier(anisotropicThreshold, originalDimension);\n\n        float oldResidualNormSquared = residuals[oldIdx].residualNormSquared;\n        float oldParallelComponent = residuals[oldIdx].parallelResidualComponent;\n\n        float bestCostDelta = 0;\n        int bestIndex = oldIdx;\n        float bestParallelResidualSum = oldParallelResidualSum;\n\n        // loop over potential new centers\n        for (int thisIdx = 0; thisIdx < residuals.length; thisIdx++) {\n            if (thisIdx == oldIdx) {\n                continue;\n            }\n\n            // compute the new parallel residual sum and parallel norm delta\n            Residual rs = residuals[thisIdx];\n            float thisParallelResidualSum = oldParallelResidualSum - oldParallelComponent + rs.parallelResidualComponent;\n            float parallelNormDelta = square(thisParallelResidualSum) - square(oldParallelResidualSum);\n            // quit early if new parallel norm is worse than the old\n            if (parallelNormDelta > 0) {\n                continue;\n            }\n\n            // compute the total cost delta\n            float residualNormDelta = rs.residualNormSquared - oldResidualNormSquared;\n            float perpendicularNormDelta = residualNormDelta - parallelNormDelta;\n            float costDelta = pcm * parallelNormDelta + perpendicularNormDelta;\n\n            // save the new center if it's the best so far\n            if (costDelta < bestCostDelta) {\n                bestCostDelta = costDelta;\n                bestIndex = thisIdx;\n                bestParallelResidualSum = thisParallelResidualSum;\n            }\n        }\n\n        return new CoordinateDescentResult(bestIndex, bestParallelResidualSum);\n    }\n\n    /**\n     * Wraps the two values we want to return from optimizeSingleSubspace\n     */\n    private static class CoordinateDescentResult {\n        final int newCenterIdx;\n        final float newParallelResidualComponent;\n\n        CoordinateDescentResult(int newCenterIdx, float newParallelResidualComponent) {\n            this.newCenterIdx = newCenterIdx;\n            this.newParallelResidualComponent = newParallelResidualComponent;\n        }\n    }\n\n    /**\n     * @return codebook ordinals representing the cluster centroids for each subspace that minimize the residual norm\n     */\n    private ByteSequence<?> initializeToMinResidualNorms(Residual[][] residualStats) {\n        var result = vectorTypeSupport.createByteSequence(residualStats.length);\n        // for each subspace\n        for (int i = 0; i < residualStats.length; i++) {\n            int minIndex = -1;\n            double minNormSquared = Double.MAX_VALUE;\n            // find the centroid with the smallest residual norm in this subspace\n            for (int j = 0; j < residualStats[i].length; j++) {\n                if (residualStats[i][j].residualNormSquared < minNormSquared) {\n                    minNormSquared = residualStats[i][j].residualNormSquared;\n                    minIndex = j;\n                }\n            }\n            result.set(i, (byte) minIndex);\n        }\n        return result;\n    }\n\n    /**\n     * @return the parallel-cost residuals for each subspace and cluster\n     */\n    private Residual[][] computeResiduals(VectorFloat<?> vector) {\n        Residual[][] residuals = new Residual[codebooks.length][];\n\n        float inverseNorm = (float) (1.0 / sqrt(dotProduct(vector, vector)));\n        for (int i = 0; i < codebooks.length; i++) {\n            var x = getSubVector(vector, i, subvectorSizesAndOffsets);\n            float xNormSquared = dotProduct(x, x);\n            residuals[i] = new Residual[clusterCount];\n\n            for (int j = 0; j < clusterCount; j++) {\n                residuals[i][j] = computeResidual(x, codebooks[i], j, centroidNormsSquared[i][j], xNormSquared, inverseNorm);\n            }\n        }\n\n        return residuals;\n    }\n\n    /**\n     * Represents the residual after subtracting a cluster centroid from a [sub]vector.\n     */\n    private static class Residual {\n        final float residualNormSquared;\n        final float parallelResidualComponent;\n\n        Residual(float residualNormSquared, float parallelResidualComponent) {\n            this.residualNormSquared = residualNormSquared;\n            this.parallelResidualComponent = parallelResidualComponent;\n        }\n    }\n\n    private Residual computeResidual(VectorFloat<?> x, VectorFloat<?> centroids, int centroid, float cNormSquared, float xNormSquared, float inverseNorm) {\n        float cDotX = VectorUtil.dotProduct(centroids, centroid * x.length(), x, 0, x.length());\n        float residualNormSquared = cNormSquared - 2 * cDotX + xNormSquared;\n        float parallelErrorSubtotal = cDotX - xNormSquared;\n        float parallelResidualComponent = square(parallelErrorSubtotal) * inverseNorm;\n        return new Residual(residualNormSquared, parallelResidualComponent);\n    }\n\n    private ByteSequence<?> encodeUnweighted(VectorFloat<?> vector) {\n        var encoded = vectorTypeSupport.createByteSequence(M);\n        for (int m = 0; m < M; m++) {\n            encoded.set(m, (byte) closestCentroidIndex(vector, m, codebooks[m]));\n        }\n        return encoded;\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector, relative to the global centroid.\n     */\n\n\n\n\n\n\n\n    /**\n     * @return how many bytes we are compressing to\n     */\n    public int getSubspaceCount() {\n        return M;\n    }\n\n    /**\n     * @return number of clusters per subspace\n     */\n    public int getClusterCount() {\n        return clusterCount;\n    }\n\n    static VectorFloat<?>[] createCodebooks(List<VectorFloat<?>> vectors, int[][] subvectorSizeAndOffset, int clusters, float anisotropicThreshold, ForkJoinPool simdExecutor) {\n        int M = subvectorSizeAndOffset.length;\n        return simdExecutor.submit(() -> IntStream.range(0, M).parallel().mapToObj(m -> {\n            VectorFloat<?>[] subvectors = extractSubvectors(vectors, m, subvectorSizeAndOffset);\n            var clusterer = new KMeansPlusPlusClusterer(subvectors, clusters, anisotropicThreshold);\n            return clusterer.cluster(K_MEANS_ITERATIONS, anisotropicThreshold == UNWEIGHTED ? 0 : K_MEANS_ITERATIONS);\n        }).toArray(VectorFloat<?>[]::new)).join();\n    }\n\n    /**\n     * Extract VectorFloat subvectors corresponding to the m'th subspace.\n     * This is NOT done in parallel (since the callers are themselves running in parallel).\n     */\n    private static VectorFloat<?>[] extractSubvectors(List<VectorFloat<?>> vectors, int m, int[][] subvectorSizeAndOffset) {\n        return vectors.stream()\n                .map(vector -> getSubVector(vector, m, subvectorSizeAndOffset))\n                .toArray(VectorFloat<?>[]::new);\n    }\n\n    int closestCentroidIndex(VectorFloat<?> subvector, int m, VectorFloat<?> codebook) {\n        int index = 0;\n        float minDist = Float.MAX_VALUE;\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        for (int i = 0; i < clusterCount; i++) {\n            float dist = VectorUtil.squareL2Distance(subvector, subvectorOffset, codebook, i * subvectorSize, subvectorSize);\n            if (dist < minDist) {\n                minDist = dist;\n                index = i;\n            }\n        }\n        return index;\n    }\n\n    /**\n     * Extracts the m-th subvector from a single vector.\n     */\n    static VectorFloat<?> getSubVector(VectorFloat<?> vector, int m, int[][] subvectorSizeAndOffset) {\n        VectorFloat<?> subvector = vectorTypeSupport.createFloatVector(subvectorSizeAndOffset[m][0]);\n        subvector.copyFrom(vector, subvectorSizeAndOffset[m][1], 0, subvectorSizeAndOffset[m][0]);\n        return subvector;\n    }\n\n    /**\n     * Splits the vector dimension into M subvectors of roughly equal size.\n     */\n    @VisibleForTesting\n    static int[][] getSubvectorSizesAndOffsets(int dimensions, int M) {\n        if (M > dimensions) {\n            throw new IllegalArgumentException(\"Number of subspaces must be less than or equal to the vector dimension\");\n        }\n        int[][] sizes = new int[M][];\n        int baseSize = dimensions / M;\n        int remainder = dimensions % M;\n        // distribute the remainder among the subvectors\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            int size = baseSize + (i < remainder ? 1 : 0);\n            sizes[i] = new int[]{size, offset};\n            offset += size;\n        }\n        return sizes;\n    }\n\n    VectorFloat<?> reusablePartialSums() {\n        return partialSums.get();\n    }\n\n    ByteSequence<?> reusablePartialQuantizedSums() {\n        return partialQuantizedSums.get();\n    }\n\n    VectorFloat<?> reusablePartialBestDistances() {\n        return partialBestDistances.get();\n    }\n\n    AtomicReference<VectorFloat<?>> partialSquaredMagnitudes() {\n        return partialSquaredMagnitudes;\n    }\n\n    AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes() {\n        return partialQuantizedSquaredMagnitudes;\n    }\n\n    public void write(DataOutput out, int version) throws IOException\n    {\n        if (version > OnDiskGraphIndex.CURRENT_VERSION) {\n            throw new IllegalArgumentException(\"Unsupported serialization version \" + version);\n        }\n        if (version < 3 && anisotropicThreshold != UNWEIGHTED) {\n            throw new IllegalArgumentException(\"Anisotropic threshold is only supported in serialization version 3 and above\");\n        }\n\n        if (version >= 3) {\n            out.writeInt(MAGIC);\n            out.writeInt(version);\n        }\n\n        if (globalCentroid == null) {\n            out.writeInt(0);\n        } else {\n            out.writeInt(globalCentroid.length());\n            vectorTypeSupport.writeFloatVector(out, globalCentroid);\n        }\n\n        out.writeInt(M);\n        assert Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum() == originalDimension;\n        assert M == subvectorSizesAndOffsets.length;\n        for (var a : subvectorSizesAndOffsets) {\n            out.writeInt(a[0]);\n        }\n\n        if (version >= 3) {\n            out.writeFloat(anisotropicThreshold);\n        }\n\n        assert codebooks.length == M;\n        out.writeInt(clusterCount);\n        for (int i = 0; i < M; i++) {\n            var codebook = codebooks[i];\n            assert codebook.length() == clusterCount * subvectorSizesAndOffsets[i][0];\n            vectorTypeSupport.writeFloatVector(out, codebook);\n        }\n    }\n\n    @Override\n    public int compressorSize() {\n        int size = 0;\n        size += Integer.BYTES; // MAGIC\n        size += Integer.BYTES; // STORAGE_VERSION\n        size += Integer.BYTES; // globalCentroidLength\n        if (globalCentroid != null) {\n            size += Float.BYTES * globalCentroid.length();\n        }\n        size += Integer.BYTES; // M\n        size += Integer.BYTES * M; // subvectorSizesAndOffsets (only the sizes are written)\n        size += Float.BYTES; // anisotropicThreshold\n        size += Integer.BYTES; // clusterCount\n        for (int i = 0; i < M; i++) {\n            size += Float.BYTES * codebooks[i].length();\n        }\n        return size;\n    }\n\n    public static ProductQuantization load(RandomAccessReader in) throws IOException {\n        int maybeMagic = in.readInt();\n        int version;\n        int globalCentroidLength;\n        if (maybeMagic != MAGIC) {\n            // JVector 1+2 format, no magic or version, starts straight off with the centroid length\n            version = 0;\n            globalCentroidLength = maybeMagic;\n        } else {\n            version = in.readInt();\n            globalCentroidLength = in.readInt();\n        }\n\n        VectorFloat<?> globalCentroid = null;\n        if (globalCentroidLength > 0) {\n            globalCentroid = vectorTypeSupport.readFloatVector(in, globalCentroidLength);\n        }\n\n        int M = in.readInt();\n        int[][] subvectorSizes = new int[M][];\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            subvectorSizes[i] = new int[2];\n            int size = in.readInt();\n            subvectorSizes[i][0] = size;\n\n```\n# Function Signature: public ProductQuantization refine(RandomAccessVectorValues ravv,\n# Natural Language Annotations: /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     *\n     * @param lloydsRounds number of Lloyd's iterations to run against\n     *                     the new data.  Suggested values are 1 or 2.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic ProductQuantization refine(RandomAccessVectorValues ravv, int lloydsRounds) {\n        return refine(ravv, lloydsRounds, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n```", "  ```\npublic ProductQuantization refine(RandomAccessVectorValues ravv, int lloydRounds) {\n        return refine(ravv, lloydRounds, anisotropicThreshold, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     *\n     * @param ravv the vectors to refine with\n     * @param lloydRounds number of Lloyd's iterations to run against\n     *                     the new data.  Suggested values are 1 or 2.\n     * @param anisotropicThreshold the threshold of relevance for anisotropic angular distance shaping, giving\n     *        higher priority to parallel error.  Anisotropic shaping requires that your dataset be normalized\n     *        to unit length.  Use a threshold of UNWEIGHTED for isotropic distance\n     *        (i.e. normal, unweighted L2 distance).\n     * @param simdExecutor ForkJoinPool instance for SIMD operations, best is to use a pool with the size of\n     *                     the number of physical cores.\n     * @param parallelExecutor ForkJoinPool instance for parallel stream operations\n     */\n    public ProductQuantization refine(RandomAccessVectorValues ravv, int lloydRounds, float anisotropicThreshold, ForkJoinPool simdExecutor, ForkJoinPool parallelExecutor) {\n        VectorFloat<?>[] newCodebooks = createCodebooks(extractTrainingVectors(ravv, parallelExecutor), subvectorSizesAndOffsets, clusterCount, anisotropicThreshold, simdExecutor);\n        float newAnisotropicThreshold = anisotropicThreshold;\n        // keep using the current threshold if it's the same as provided; otherwise, use Isotropic\n        if (anisotropicThreshold != UNWEIGHTED) {\n            newAnisotropicThreshold = UNWEIGHTED;\n        }\n\n        ProductQuantization refined = new ProductQuantization(newCodebooks, clusterCount, subvectorSizesAndOffsets, globalCentroid, newAnisotropicThreshold);\n        return refined.cluster(ravv, lloydRounds, anisotropicThreshold, simdExecutor, parallelExecutor);\n    }\n```", "  ```\npublic ProductQuantization refine(RandomAccessVectorValues ravv, \n                                  int lloydsRounds, \n                                  float anisotropicThreshold, \n                                  ForkJoinPool parallelExecutor) {\n        var clusters = codebooks.length * 2; // aggressively oversize the clusters\n        var subvectorSizesAndOffsets = getSubvectorSizesAndOffsets(ravv.dimension(), M);\n\n        // collect a representative subset of training vectors\n        List<VectorFloat<?>> trainingVectors = extractTrainingVectors(ravv, parallelExecutor);\n\n        // compute the residuals for the training vectors in parallel\n        LocalIterator<Residual[]> residualsL = new LocalIterator<Residual[]>(trainingVectors.size() / (M * K_MEANS_ITERATIONS));\n        parallelExecutor.asTask(() -> {\n            for (int kky = 0; kky < K_MEANS_ITERATIONS; kky++) {\n                // cluster the training vectors\n                var centroids = new VectorFloat<?>[M][clusters];\n                for (int m = 0; m < M; m++) {\n                    for (int c = 0; c < clusters; c++) {\n                        centroids[m][c] = vectorTypeSupport.createFloatVector(subvectorSizesAndOffsets[m][0], 0);\n                    }\n                }\n                ForkJoinPool jsPool = ForkJoinPool.commonPool();\n                var clusterer = new KMeansPlusPlusClusterer(trainingVectors, subvectorSizesAndOffsets, centroids, kky == K_MEANS_ITERATIONS - 1, parallelExecutor, jsPool);\n                clusterer.cluster(residualsL);\n            }\n        });\n\n        // compute the centroid norms\n        float[][] centroidNormsSquared = new float[M][clusters];\n        for (int m = 0; m < M; m++) {\n            for (int c = 0; c < clusters; c++) {\n                centroidNormsSquared[m][c] = KMeansPlusPlusClusterer.squaredL2Distance(centroids[m][c], subvectorSizesAndOffsets[m][0]);\n            }\n        }\n\n        // align the PQ codebooks with the new data\n        var alignedCodebooks = alignCodebooks(ast, centroidNormsSquared, M, clusterCount);\n\n        // build the initial guess for the new product quantization\n        var byteSequence = initializeToMinResidualNorms(residualsL.asList(parallelExecutor));\n        var newPq = new ProductQuantization(alignedCodebooks, clusterCount, subvectorSizesAndOffsets, globalCentroid, anisotropicThreshold);\n\n        // optimize the product quantization for the given number of rounds\n        for (int i = 0; i < lloydsRounds; i++) {\n            byteSequence = optimizeParallelAndOrthogonal(ravv, newPq, byteSequence, residualsL, parallelExecutor, anisotropicThreshold);\n        }\n\n        // update the codebooks\n        for (int m = 0; m < M; m++) {\n            for (int k = 0; k < clusterCount; k++) {\n                codebooks[m].copyFrom(alignedCodebooks[m], k * alignedCodebooks[m].length() / clusterCount, k * codebooks[m].length() / clusterCount, codebooks[m].length() / clusterCount);\n            }\n        }\n\n        return this;\n    }\n    \n    \n    /**\n     * Helper function to align the PQ codebooks with the new data in a parallel and orthogonal manner.\n     */\n    private VectorFloat<?>[] alignCodebooks(float[][] algebraics, float[][] centroidNormsSquared, int M, int clusterCount) {\n        VectorFloat<?>[] codebooks = new VectorFloat<?>[M];\n        for (int m = 0; m < M; m++) {\n            float factor = sqrtf(algebraics[m][0] / centroidNormsSquared[m][0]);\n            codebooks[m] = vectorTypeSupport.createFloatVector(clusterCount * centroidNormsSqu"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-encodeAnisotropic": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.pq;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.graph.disk.OnDiskGraphIndex;\nimport io.github.jbellis.jvector.util.Accountable;\nimport io.github.jbellis.jvector.util.PhysicalCoreExecutor;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.VectorizationProvider;\nimport io.github.jbellis.jvector.vector.types.ByteSequence;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\nimport java.io.DataOutput;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\nimport java.util.stream.IntStream;\n\nimport static io.github.jbellis.jvector.pq.KMeansPlusPlusClusterer.UNWEIGHTED;\nimport static io.github.jbellis.jvector.util.MathUtil.square;\nimport static io.github.jbellis.jvector.vector.VectorUtil.dotProduct;\nimport static io.github.jbellis.jvector.vector.VectorUtil.sub;\nimport static java.lang.Math.min;\nimport static java.lang.Math.sqrt;\n\n/**\n * Product Quantization for float vectors.  Supports arbitrary source and target dimensionality;\n * in particular, the source does not need to be evenly divisible by the target.\n */\npublic class ProductQuantization implements VectorCompressor<ByteSequence<?>>, Accountable {\n    private static final int MAGIC = 0x75EC4012; // JVECTOR, with some imagination\n\n    private static final VectorTypeSupport vectorTypeSupport = VectorizationProvider.getInstance().getVectorTypeSupport();\n    static final int DEFAULT_CLUSTERS = 256; // number of clusters per subspace = one byte's worth\n    static final int K_MEANS_ITERATIONS = 6;\n    public static final int MAX_PQ_TRAINING_SET_SIZE = 128000;\n\n    final VectorFloat<?>[] codebooks; // array of codebooks, where each codebook is a VectorFloat consisting of k contiguous subvectors each of length M\n    final int M; // codebooks.length, redundantly reproduced for convenience\n    private final int clusterCount; // codebooks[0].length, redundantly reproduced for convenience\n    final int originalDimension;\n    final VectorFloat<?> globalCentroid;\n    final int[][] subvectorSizesAndOffsets;\n    final float anisotropicThreshold; // parallel cost multiplier\n    private final float[][] centroidNormsSquared; // precomputed norms of the centroids, for encoding\n    private final ThreadLocal<VectorFloat<?>> partialSums; // for dot product, euclidean, and cosine partials\n    private final ThreadLocal<VectorFloat<?>> partialBestDistances; // for partial best distances during fused ADC\n    private final ThreadLocal<ByteSequence<?>> partialQuantizedSums; // for quantized sums during fused ADC\n    private final AtomicReference<VectorFloat<?>> partialSquaredMagnitudes; // for cosine partials\n    private final AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes; // for quantized squared magnitude partials during cosine fused ADC\n    protected volatile float squaredMagnitudeDelta = 0; // for cosine fused ADC squared magnitude quantization delta (since this is invariant for a given PQ)\n    protected volatile float minSquaredMagnitude = 0; // for cosine fused ADC minimum squared magnitude (invariant for a given PQ)\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     */\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter) {\n        return compute(ravv, M, clusterCount, globallyCenter, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold) {\n        return compute(ravv, M, clusterCount, globallyCenter, anisotropicThreshold, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param clusterCount number of clusters per subspace\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     * @param anisotropicThreshold the threshold of relevance for anisotropic angular distance shaping, giving\n     *        higher priority to parallel error.  Anisotropic shaping requires that your dataset be normalized\n     *        to unit length.  Use a threshold of UNWEIGHTED for isotropic distance\n     *        (i.e. normal, unweighted L2 distance).\n     * @param simdExecutor     ForkJoinPool instance for SIMD operations, best is to use a pool with the size of\n     *                         the number of physical cores.\n     * @param parallelExecutor ForkJoinPool instance for parallel stream operations\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static List<VectorFloat<?>> extractTrainingVectors(RandomAccessVectorValues ravv, ForkJoinPool parallelExecutor) {\n        // limit the number of vectors we train on\n        var P = min(1.0f, MAX_PQ_TRAINING_SET_SIZE / (float) ravv.size());\n        var ravvCopy = ravv.threadLocalSupplier();\n        return parallelExecutor.submit(() -> IntStream.range(0, ravv.size()).parallel()\n                        .filter(i -> ThreadLocalRandom.current().nextFloat() < P)\n                        .mapToObj(targetOrd -> {\n                            var localRavv = ravvCopy.get();\n                            VectorFloat<?> v = localRavv.getVector(targetOrd);\n                            return localRavv.isValueShared() ? v.copy() : v;\n                        })\n                        .collect(Collectors.toList()))\n                .join();\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     */\n    public ProductQuantization refine(RandomAccessVectorValues ravv) {\n        return refine(ravv, 1, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     *\n     * @param lloydsRounds number of Lloyd's iterations to run against\n     *                     the new data.  Suggested values are 1 or 2.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    ProductQuantization(VectorFloat<?>[] codebooks, int clusterCount, int[][] subvectorSizesAndOffsets, VectorFloat<?> globalCentroid, float anisotropicThreshold) {\n        this.codebooks = codebooks;\n        this.globalCentroid = globalCentroid;\n        this.M = codebooks.length;\n        this.clusterCount = clusterCount;\n        this.subvectorSizesAndOffsets = subvectorSizesAndOffsets;\n        this.originalDimension = Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum();\n        if (globalCentroid != null && globalCentroid.length() != originalDimension) {\n            var msg = String.format(\"Global centroid length %d does not match vector dimensionality %d\", globalCentroid.length(), originalDimension);\n            throw new IllegalArgumentException(msg);\n        }\n        this.anisotropicThreshold = anisotropicThreshold;\n        this.partialSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount() * getClusterCount()));\n        this.partialBestDistances = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount()));\n        this.partialQuantizedSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createByteSequence(getSubspaceCount() * getClusterCount() * 2));\n        this.partialSquaredMagnitudes = new AtomicReference<>(null);\n        this.partialQuantizedSquaredMagnitudes= new AtomicReference<>(null);\n\n\n        centroidNormsSquared = new float[M][clusterCount];\n        for (int i = 0; i < M; i++) {\n            for (int j = 0; j < clusterCount; j++) {\n                centroidNormsSquared[i][j] = dotProduct(codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        subvectorSizesAndOffsets[i][0]);\n            }\n        }\n    }\n\n    @Override\n    public CompressedVectors createCompressedVectors(Object[] compressedVectors) {\n        return new PQVectors(this, (ByteSequence<?>[]) compressedVectors);\n    }\n\n    /**\n     * Encodes the given vectors in parallel using the PQ codebooks.\n     */\n    @Override\n    public ByteSequence<?>[] encodeAll(RandomAccessVectorValues ravv, ForkJoinPool simdExecutor) {\n        return simdExecutor.submit(() -> IntStream.range(0, ravv.size())\n                        .parallel()\n                        .mapToObj(i -> encode(ravv.getVector(i)))\n                        .toArray(ByteSequence<?>[]::new))\n                .join();\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks, weighing parallel loss more than orthogonal loss.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private CoordinateDescentResult optimizeSingleSubspace(Residual[] residuals, int oldIdx, float oldParallelResidualSum) {\n        // (this is global to all subspaces but it's not worth stashing in a field)\n        float pcm = KMeansPlusPlusClusterer.computeParallelCostMultiplier(anisotropicThreshold, originalDimension);\n\n        float oldResidualNormSquared = residuals[oldIdx].residualNormSquared;\n        float oldParallelComponent = residuals[oldIdx].parallelResidualComponent;\n\n        float bestCostDelta = 0;\n        int bestIndex = oldIdx;\n        float bestParallelResidualSum = oldParallelResidualSum;\n\n        // loop over potential new centers\n        for (int thisIdx = 0; thisIdx < residuals.length; thisIdx++) {\n            if (thisIdx == oldIdx) {\n                continue;\n            }\n\n            // compute the new parallel residual sum and parallel norm delta\n            Residual rs = residuals[thisIdx];\n            float thisParallelResidualSum = oldParallelResidualSum - oldParallelComponent + rs.parallelResidualComponent;\n            float parallelNormDelta = square(thisParallelResidualSum) - square(oldParallelResidualSum);\n            // quit early if new parallel norm is worse than the old\n            if (parallelNormDelta > 0) {\n                continue;\n            }\n\n            // compute the total cost delta\n            float residualNormDelta = rs.residualNormSquared - oldResidualNormSquared;\n            float perpendicularNormDelta = residualNormDelta - parallelNormDelta;\n            float costDelta = pcm * parallelNormDelta + perpendicularNormDelta;\n\n            // save the new center if it's the best so far\n            if (costDelta < bestCostDelta) {\n                bestCostDelta = costDelta;\n                bestIndex = thisIdx;\n                bestParallelResidualSum = thisParallelResidualSum;\n            }\n        }\n\n        return new CoordinateDescentResult(bestIndex, bestParallelResidualSum);\n    }\n\n    /**\n     * Wraps the two values we want to return from optimizeSingleSubspace\n     */\n    private static class CoordinateDescentResult {\n        final int newCenterIdx;\n        final float newParallelResidualComponent;\n\n        CoordinateDescentResult(int newCenterIdx, float newParallelResidualComponent) {\n            this.newCenterIdx = newCenterIdx;\n            this.newParallelResidualComponent = newParallelResidualComponent;\n        }\n    }\n\n    /**\n     * @return codebook ordinals representing the cluster centroids for each subspace that minimize the residual norm\n     */\n    private ByteSequence<?> initializeToMinResidualNorms(Residual[][] residualStats) {\n        var result = vectorTypeSupport.createByteSequence(residualStats.length);\n        // for each subspace\n        for (int i = 0; i < residualStats.length; i++) {\n            int minIndex = -1;\n            double minNormSquared = Double.MAX_VALUE;\n            // find the centroid with the smallest residual norm in this subspace\n            for (int j = 0; j < residualStats[i].length; j++) {\n                if (residualStats[i][j].residualNormSquared < minNormSquared) {\n                    minNormSquared = residualStats[i][j].residualNormSquared;\n                    minIndex = j;\n                }\n            }\n            result.set(i, (byte) minIndex);\n        }\n        return result;\n    }\n\n    /**\n     * @return the parallel-cost residuals for each subspace and cluster\n     */\n    private Residual[][] computeResiduals(VectorFloat<?> vector) {\n        Residual[][] residuals = new Residual[codebooks.length][];\n\n        float inverseNorm = (float) (1.0 / sqrt(dotProduct(vector, vector)));\n        for (int i = 0; i < codebooks.length; i++) {\n            var x = getSubVector(vector, i, subvectorSizesAndOffsets);\n            float xNormSquared = dotProduct(x, x);\n            residuals[i] = new Residual[clusterCount];\n\n            for (int j = 0; j < clusterCount; j++) {\n                residuals[i][j] = computeResidual(x, codebooks[i], j, centroidNormsSquared[i][j], xNormSquared, inverseNorm);\n            }\n        }\n\n        return residuals;\n    }\n\n    /**\n     * Represents the residual after subtracting a cluster centroid from a [sub]vector.\n     */\n    private static class Residual {\n        final float residualNormSquared;\n        final float parallelResidualComponent;\n\n        Residual(float residualNormSquared, float parallelResidualComponent) {\n            this.residualNormSquared = residualNormSquared;\n            this.parallelResidualComponent = parallelResidualComponent;\n        }\n    }\n\n    private Residual computeResidual(VectorFloat<?> x, VectorFloat<?> centroids, int centroid, float cNormSquared, float xNormSquared, float inverseNorm) {\n        float cDotX = VectorUtil.dotProduct(centroids, centroid * x.length(), x, 0, x.length());\n        float residualNormSquared = cNormSquared - 2 * cDotX + xNormSquared;\n        float parallelErrorSubtotal = cDotX - xNormSquared;\n        float parallelResidualComponent = square(parallelErrorSubtotal) * inverseNorm;\n        return new Residual(residualNormSquared, parallelResidualComponent);\n    }\n\n    private ByteSequence<?> encodeUnweighted(VectorFloat<?> vector) {\n        var encoded = vectorTypeSupport.createByteSequence(M);\n        for (int m = 0; m < M; m++) {\n            encoded.set(m, (byte) closestCentroidIndex(vector, m, codebooks[m]));\n        }\n        return encoded;\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector, relative to the global centroid.\n     */\n\n\n\n\n\n\n\n    /**\n     * @return how many bytes we are compressing to\n     */\n    public int getSubspaceCount() {\n        return M;\n    }\n\n    /**\n     * @return number of clusters per subspace\n     */\n    public int getClusterCount() {\n        return clusterCount;\n    }\n\n    static VectorFloat<?>[] createCodebooks(List<VectorFloat<?>> vectors, int[][] subvectorSizeAndOffset, int clusters, float anisotropicThreshold, ForkJoinPool simdExecutor) {\n        int M = subvectorSizeAndOffset.length;\n        return simdExecutor.submit(() -> IntStream.range(0, M).parallel().mapToObj(m -> {\n            VectorFloat<?>[] subvectors = extractSubvectors(vectors, m, subvectorSizeAndOffset);\n            var clusterer = new KMeansPlusPlusClusterer(subvectors, clusters, anisotropicThreshold);\n            return clusterer.cluster(K_MEANS_ITERATIONS, anisotropicThreshold == UNWEIGHTED ? 0 : K_MEANS_ITERATIONS);\n        }).toArray(VectorFloat<?>[]::new)).join();\n    }\n\n    /**\n     * Extract VectorFloat subvectors corresponding to the m'th subspace.\n     * This is NOT done in parallel (since the callers are themselves running in parallel).\n     */\n    private static VectorFloat<?>[] extractSubvectors(List<VectorFloat<?>> vectors, int m, int[][] subvectorSizeAndOffset) {\n        return vectors.stream()\n                .map(vector -> getSubVector(vector, m, subvectorSizeAndOffset))\n                .toArray(VectorFloat<?>[]::new);\n    }\n\n    int closestCentroidIndex(VectorFloat<?> subvector, int m, VectorFloat<?> codebook) {\n        int index = 0;\n        float minDist = Float.MAX_VALUE;\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        for (int i = 0; i < clusterCount; i++) {\n            float dist = VectorUtil.squareL2Distance(subvector, subvectorOffset, codebook, i * subvectorSize, subvectorSize);\n            if (dist < minDist) {\n                minDist = dist;\n                index = i;\n            }\n        }\n        return index;\n    }\n\n    /**\n     * Extracts the m-th subvector from a single vector.\n     */\n    static VectorFloat<?> getSubVector(VectorFloat<?> vector, int m, int[][] subvectorSizeAndOffset) {\n        VectorFloat<?> subvector = vectorTypeSupport.createFloatVector(subvectorSizeAndOffset[m][0]);\n        subvector.copyFrom(vector, subvectorSizeAndOffset[m][1], 0, subvectorSizeAndOffset[m][0]);\n        return subvector;\n    }\n\n    /**\n     * Splits the vector dimension into M subvectors of roughly equal size.\n     */\n    @VisibleForTesting\n    static int[][] getSubvectorSizesAndOffsets(int dimensions, int M) {\n        if (M > dimensions) {\n            throw new IllegalArgumentException(\"Number of subspaces must be less than or equal to the vector dimension\");\n        }\n        int[][] sizes = new int[M][];\n        int baseSize = dimensions / M;\n        int remainder = dimensions % M;\n        // distribute the remainder among the subvectors\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            int size = baseSize + (i < remainder ? 1 : 0);\n            sizes[i] = new int[]{size, offset};\n            offset += size;\n        }\n        return sizes;\n    }\n\n    VectorFloat<?> reusablePartialSums() {\n        return partialSums.get();\n    }\n\n    ByteSequence<?> reusablePartialQuantizedSums() {\n        return partialQuantizedSums.get();\n    }\n\n    VectorFloat<?> reusablePartialBestDistances() {\n        return partialBestDistances.get();\n    }\n\n    AtomicReference<VectorFloat<?>> partialSquaredMagnitudes() {\n        return partialSquaredMagnitudes;\n    }\n\n    AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes() {\n        return partialQuantizedSquaredMagnitudes;\n    }\n\n    public void write(DataOutput out, int version) throws IOException\n    {\n        if (version > OnDiskGraphIndex.CURRENT_VERSION) {\n            throw new IllegalArgumentException(\"Unsupported serialization version \" + version);\n        }\n        if (version < 3 && anisotropicThreshold != UNWEIGHTED) {\n            throw new IllegalArgumentException(\"Anisotropic threshold is only supported in serialization version 3 and above\");\n        }\n\n        if (version >= 3) {\n            out.writeInt(MAGIC);\n            out.writeInt(version);\n        }\n\n        if (globalCentroid == null) {\n            out.writeInt(0);\n        } else {\n            out.writeInt(globalCentroid.length());\n            vectorTypeSupport.writeFloatVector(out, globalCentroid);\n        }\n\n        out.writeInt(M);\n        assert Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum() == originalDimension;\n        assert M == subvectorSizesAndOffsets.length;\n        for (var a : subvectorSizesAndOffsets) {\n            out.writeInt(a[0]);\n        }\n\n        if (version >= 3) {\n            out.writeFloat(anisotropicThreshold);\n        }\n\n        assert codebooks.length == M;\n        out.writeInt(clusterCount);\n        for (int i = 0; i < M; i++) {\n            var codebook = codebooks[i];\n            assert codebook.length() == clusterCount * subvectorSizesAndOffsets[i][0];\n            vectorTypeSupport.writeFloatVector(out, codebook);\n        }\n    }\n\n    @Override\n    public int compressorSize() {\n        int size = 0;\n        size += Integer.BYTES; // MAGIC\n        size += Integer.BYTES; // STORAGE_VERSION\n        size += Integer.BYTES; // globalCentroidLength\n        if (globalCentroid != null) {\n            size += Float.BYTES * globalCentroid.length();\n        }\n        size += Integer.BYTES; // M\n        size += Integer.BYTES * M; // subvectorSizesAndOffsets (only the sizes are written)\n        size += Float.BYTES; // anisotropicThreshold\n        size += Integer.BYTES; // clusterCount\n        for (int i = 0; i < M; i++) {\n            size += Float.BYTES * codebooks[i].length();\n        }\n        return size;\n    }\n\n    public static ProductQuantization load(RandomAccessReader in) throws IOException {\n        int maybeMagic = in.readInt();\n        int version;\n        int globalCentroidLength;\n        if (maybeMagic != MAGIC) {\n            // JVector 1+2 format, no magic or version, starts straight off with the centroid length\n            version = 0;\n            globalCentroidLength = maybeMagic;\n        } else {\n            version = in.readInt();\n            globalCentroidLength = in.readInt();\n        }\n\n        VectorFloat<?> globalCentroid = null;\n        if (globalCentroidLength > 0) {\n            globalCentroid = vectorTypeSupport.readFloatVector(in, globalCentroidLength);\n        }\n\n        int M = in.readInt();\n        int[][] subvectorSizes = new int[M][];\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            subvectorSizes[i] = new int[2];\n            int size = in.readInt();\n            subvectorSizes[i][0] = size;\n\n```\n# Function Signature: private ByteSequence<?> encodeAnisotropic(VectorFloat<?> vector) {\n# Natural Language Annotations: /**\n     * Encodes the input vector using the PQ codebooks, weighing parallel loss more than orthogonal loss.\n     * @return one byte per subspace\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\nprivate ByteSequence<?> encodeAnisotropic(VectorFloat<?> vector) {\n        var encoded = vectorTypeSupport.createByteSequence(M);\n        for (int m = 0; m < M; m++) {\n            var x = getSubVector(vector, m, subvectorSizesAndOffsets);\n            int bestCenter = 0;\n            float bestCostDelta = Float.MAX_VALUE;\n            for (int i = 0; i < clusterCount; i++) {\n                float residualNormSquared = square(x, i * subvectorSizesAndOffsets[m][0],\n                                                   codebooks[m], i * subvectorSizesAndOffsets[m][0],\n                                                   subvectorSizesAndOffsets[m][0]);\n                float parallelResidualComponent = 0;\n                if (anisotropicThreshold != UNWEIGHTED) {\n                    float cNorm = VectorUtil.l2Norm(codebooks[m], i * subvectorSizesAndOffsets[m][0],\n                                                    subvectorSizesAndOffsets[m][0]);\n                    parallelResidualComponent = square(x.dotProduct(codebooks[m], i * subvectorSizesAndOffsets[m][0],\n                                                                    cNorm));\n                }\n                float costDelta = residualNormSquared + parallelThreshold * parallelResidualComponent;\n                if (costDelta < bestCostDelta) {\n                    bestCostDelta = costDelta;\n                    bestCenter = i;\n                }\n            }\n            encoded.set(m, (byte) bestCenter);\n        }\n        return encoded;\n    }\n```", "  ```\nprivate ByteSequence<?> encodeAnisotropic(VectorFloat<?> vector) {\n    var encoded = ByteSequenceSupport.createByteSequence(M);\n    float parallelPrediction = 0;\n    float perpendicularPrediction = 0;\n    for (int m = 0; m < M; m++) {\n        VectorFloat<?> subvector = getSubVector(vector, m, subvectorSizesAndOffsets);\n        int k = closestCentroidIndex(subvector, m, codebooks[m]);\n        encoded.set(m, (byte) k);\n        float kCentroidNormSquared = centroidNormsSquared[m][k];\n        float mSubspaceCost = square(1.0 - (subvector.lengthSquared() / kCentroidNormSquared));\n        prioritize = range normalizes the error (subtracts it from one to make a probability)\n        prioritize = 1 - dist.cost(ae-dist.getMinValue()) / range\n        float mSubspacePrioritizedCost = mSubspaceCost - anisotropicThreshold * parallelPrediction + anisotropicThreshold * subvector.lengthSquared();\n\n        // parallelPrediction = 0.5 / Math.abs(mSubspacePrioritizedCost) + prioritize mapping of subspace norm to probability\n        parallelPrediction = 0.5 / Math.min(Math.abs(mSubspacePrioritizedCost), 1.0) + (mSubspaceCost / 2.0);\n\n        perpendicularPrediction += (1 - parallelPrediction) * mSubspaceCost;\n    }\n    return encoded;\n}\n```", "  ```\n    private ByteSequence<?> encodeAnisotropic(VectorFloat<?> vector) {\n        if (anisotropicThreshold == UNWEIGHTED) {\n            return encodeUnweighted(vector);\n        }\n\n        // pre-compute auxiliary quantities and optimize them in parallel\n        var residualStats = computeResiduals(vector);\n        var initialCentroids = initializeToMinResidualNorms(residualStats);\n\n        var parallelResidualPartials = vectorTypeSupport.createFloatVector(getSubspaceCount());\n        for (int m = 0; m < getSubspaceCount(); m++) {\n            float centroidNormSquared = dotProduct(codebooks[m], initialCentroids.get(m) * getSubspaceCount(),\n                                                   codebooks[m], initialCentroids.get(m) * getSubspaceCount(),\n                                                   getSubspaceCount());\n            float parallelErrorSubtotal = centroidNormSquared - VectorUtil.dotProduct(vector, m, initialCentroids.get(m), 0, getSubspaceCount());\n            parallelResidualPartials.set(m, square(parallelErrorSubtotal) / sqrt(vector.length()));\n        }\n\n        for (int iteration = 0; iteration < K_MEANS_ITERATIONS; iteration++) {\n            var oldResidualStats = residualStats;\n\n            // in parallel, compute the residual statistics\n            var newResidualStats = new Residual[M][];\n            for (int m = 0; m < M; m++) {\n                newResidualStats[m] = new Residual[clusterCount];\n            }\n    \n            // in parallel, optimize each subspace coordinate\n            var orderedCoordinate = IntStream.range(0, M)\n                    .parallel()\n                    .mapToObj(m -> optimizeSingleSubspace(oldResidualStats[m], m,\n                                                          parallelResidualPartials.get(m)))\n                    .toArray(CoordinateDescentResult[]::new);\n\n            // update the residual stats\n            for (int m = 0; m < M; m++) {\n                int newCentroidIdx = orderedCoordinate[m].newCenterIdx;\n                float newParallelComponent = orderedCoordinate[m].newParallelResidualComponent;\n                float residualNormSquared = oldResidualStats[m][newCentroidIdx].residualNormSquared;\n                float parallelResidualComponent = oldResidualStats[m][newCentroidIdx].parallelResidualComponent;\n                float parallelErrorSubtotal = function(M) { residualNormSquared - 2 * dotProduct(init = 0, i => oldResidualStats[m], i * clusterCount + newCentroidIdx, getSubspaceCount()); }\n                residualNormSquared = function(M) { residualNormSquared - 2 * dotProduct(init = 0, i => oldResidualStats[m], newCentroidIdx * clusterCount + i, getSubspaceCount()); };\n\n                newResidualStats[m][newCentroidIdx] = new Residual(residualNormSquared, parallelResidualComponent);\n                parallelResidualPartials.set(m, square(newParallelComponent) / sqrt(vector.length()));\n            }\n    \n            //in parallel, copy the clusters that move most to the new centroids\n            @SuppressWarnings(\"unchecked\")\n            VectorFloat<?>[] newCodebooks = (VectorFloat<?>[]) new VectorFloat[M];\n            for (int m = 0; m < M; m++) {\n                var oldCentroid = codebooks[m];\n                var newCentroid = oldCentroid.copy();\n                for (int j = 0; j < clusterCount; j++) {\n                    int oldIndex = j * subvectorSizesAndOffsets[m][0];\n                    int newIndex = newCentroidIdx * subvectorSizesAndOffsets[m][0];\n                    for (int i = 0; i < subvectorSizesAndOffsets[m][0]; i++) {\n                        newCentroid.set(index, oldCentroid.get(oldIndex +"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-encode": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.pq;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.graph.disk.OnDiskGraphIndex;\nimport io.github.jbellis.jvector.util.Accountable;\nimport io.github.jbellis.jvector.util.PhysicalCoreExecutor;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.VectorizationProvider;\nimport io.github.jbellis.jvector.vector.types.ByteSequence;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\nimport java.io.DataOutput;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\nimport java.util.stream.IntStream;\n\nimport static io.github.jbellis.jvector.pq.KMeansPlusPlusClusterer.UNWEIGHTED;\nimport static io.github.jbellis.jvector.util.MathUtil.square;\nimport static io.github.jbellis.jvector.vector.VectorUtil.dotProduct;\nimport static io.github.jbellis.jvector.vector.VectorUtil.sub;\nimport static java.lang.Math.min;\nimport static java.lang.Math.sqrt;\n\n/**\n * Product Quantization for float vectors.  Supports arbitrary source and target dimensionality;\n * in particular, the source does not need to be evenly divisible by the target.\n */\npublic class ProductQuantization implements VectorCompressor<ByteSequence<?>>, Accountable {\n    private static final int MAGIC = 0x75EC4012; // JVECTOR, with some imagination\n\n    private static final VectorTypeSupport vectorTypeSupport = VectorizationProvider.getInstance().getVectorTypeSupport();\n    static final int DEFAULT_CLUSTERS = 256; // number of clusters per subspace = one byte's worth\n    static final int K_MEANS_ITERATIONS = 6;\n    public static final int MAX_PQ_TRAINING_SET_SIZE = 128000;\n\n    final VectorFloat<?>[] codebooks; // array of codebooks, where each codebook is a VectorFloat consisting of k contiguous subvectors each of length M\n    final int M; // codebooks.length, redundantly reproduced for convenience\n    private final int clusterCount; // codebooks[0].length, redundantly reproduced for convenience\n    final int originalDimension;\n    final VectorFloat<?> globalCentroid;\n    final int[][] subvectorSizesAndOffsets;\n    final float anisotropicThreshold; // parallel cost multiplier\n    private final float[][] centroidNormsSquared; // precomputed norms of the centroids, for encoding\n    private final ThreadLocal<VectorFloat<?>> partialSums; // for dot product, euclidean, and cosine partials\n    private final ThreadLocal<VectorFloat<?>> partialBestDistances; // for partial best distances during fused ADC\n    private final ThreadLocal<ByteSequence<?>> partialQuantizedSums; // for quantized sums during fused ADC\n    private final AtomicReference<VectorFloat<?>> partialSquaredMagnitudes; // for cosine partials\n    private final AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes; // for quantized squared magnitude partials during cosine fused ADC\n    protected volatile float squaredMagnitudeDelta = 0; // for cosine fused ADC squared magnitude quantization delta (since this is invariant for a given PQ)\n    protected volatile float minSquaredMagnitude = 0; // for cosine fused ADC minimum squared magnitude (invariant for a given PQ)\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     */\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter) {\n        return compute(ravv, M, clusterCount, globallyCenter, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold) {\n        return compute(ravv, M, clusterCount, globallyCenter, anisotropicThreshold, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param clusterCount number of clusters per subspace\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     * @param anisotropicThreshold the threshold of relevance for anisotropic angular distance shaping, giving\n     *        higher priority to parallel error.  Anisotropic shaping requires that your dataset be normalized\n     *        to unit length.  Use a threshold of UNWEIGHTED for isotropic distance\n     *        (i.e. normal, unweighted L2 distance).\n     * @param simdExecutor     ForkJoinPool instance for SIMD operations, best is to use a pool with the size of\n     *                         the number of physical cores.\n     * @param parallelExecutor ForkJoinPool instance for parallel stream operations\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static List<VectorFloat<?>> extractTrainingVectors(RandomAccessVectorValues ravv, ForkJoinPool parallelExecutor) {\n        // limit the number of vectors we train on\n        var P = min(1.0f, MAX_PQ_TRAINING_SET_SIZE / (float) ravv.size());\n        var ravvCopy = ravv.threadLocalSupplier();\n        return parallelExecutor.submit(() -> IntStream.range(0, ravv.size()).parallel()\n                        .filter(i -> ThreadLocalRandom.current().nextFloat() < P)\n                        .mapToObj(targetOrd -> {\n                            var localRavv = ravvCopy.get();\n                            VectorFloat<?> v = localRavv.getVector(targetOrd);\n                            return localRavv.isValueShared() ? v.copy() : v;\n                        })\n                        .collect(Collectors.toList()))\n                .join();\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     */\n    public ProductQuantization refine(RandomAccessVectorValues ravv) {\n        return refine(ravv, 1, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     *\n     * @param lloydsRounds number of Lloyd's iterations to run against\n     *                     the new data.  Suggested values are 1 or 2.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    ProductQuantization(VectorFloat<?>[] codebooks, int clusterCount, int[][] subvectorSizesAndOffsets, VectorFloat<?> globalCentroid, float anisotropicThreshold) {\n        this.codebooks = codebooks;\n        this.globalCentroid = globalCentroid;\n        this.M = codebooks.length;\n        this.clusterCount = clusterCount;\n        this.subvectorSizesAndOffsets = subvectorSizesAndOffsets;\n        this.originalDimension = Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum();\n        if (globalCentroid != null && globalCentroid.length() != originalDimension) {\n            var msg = String.format(\"Global centroid length %d does not match vector dimensionality %d\", globalCentroid.length(), originalDimension);\n            throw new IllegalArgumentException(msg);\n        }\n        this.anisotropicThreshold = anisotropicThreshold;\n        this.partialSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount() * getClusterCount()));\n        this.partialBestDistances = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount()));\n        this.partialQuantizedSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createByteSequence(getSubspaceCount() * getClusterCount() * 2));\n        this.partialSquaredMagnitudes = new AtomicReference<>(null);\n        this.partialQuantizedSquaredMagnitudes= new AtomicReference<>(null);\n\n\n        centroidNormsSquared = new float[M][clusterCount];\n        for (int i = 0; i < M; i++) {\n            for (int j = 0; j < clusterCount; j++) {\n                centroidNormsSquared[i][j] = dotProduct(codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        subvectorSizesAndOffsets[i][0]);\n            }\n        }\n    }\n\n    @Override\n    public CompressedVectors createCompressedVectors(Object[] compressedVectors) {\n        return new PQVectors(this, (ByteSequence<?>[]) compressedVectors);\n    }\n\n    /**\n     * Encodes the given vectors in parallel using the PQ codebooks.\n     */\n    @Override\n    public ByteSequence<?>[] encodeAll(RandomAccessVectorValues ravv, ForkJoinPool simdExecutor) {\n        return simdExecutor.submit(() -> IntStream.range(0, ravv.size())\n                        .parallel()\n                        .mapToObj(i -> encode(ravv.getVector(i)))\n                        .toArray(ByteSequence<?>[]::new))\n                .join();\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks, weighing parallel loss more than orthogonal loss.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private CoordinateDescentResult optimizeSingleSubspace(Residual[] residuals, int oldIdx, float oldParallelResidualSum) {\n        // (this is global to all subspaces but it's not worth stashing in a field)\n        float pcm = KMeansPlusPlusClusterer.computeParallelCostMultiplier(anisotropicThreshold, originalDimension);\n\n        float oldResidualNormSquared = residuals[oldIdx].residualNormSquared;\n        float oldParallelComponent = residuals[oldIdx].parallelResidualComponent;\n\n        float bestCostDelta = 0;\n        int bestIndex = oldIdx;\n        float bestParallelResidualSum = oldParallelResidualSum;\n\n        // loop over potential new centers\n        for (int thisIdx = 0; thisIdx < residuals.length; thisIdx++) {\n            if (thisIdx == oldIdx) {\n                continue;\n            }\n\n            // compute the new parallel residual sum and parallel norm delta\n            Residual rs = residuals[thisIdx];\n            float thisParallelResidualSum = oldParallelResidualSum - oldParallelComponent + rs.parallelResidualComponent;\n            float parallelNormDelta = square(thisParallelResidualSum) - square(oldParallelResidualSum);\n            // quit early if new parallel norm is worse than the old\n            if (parallelNormDelta > 0) {\n                continue;\n            }\n\n            // compute the total cost delta\n            float residualNormDelta = rs.residualNormSquared - oldResidualNormSquared;\n            float perpendicularNormDelta = residualNormDelta - parallelNormDelta;\n            float costDelta = pcm * parallelNormDelta + perpendicularNormDelta;\n\n            // save the new center if it's the best so far\n            if (costDelta < bestCostDelta) {\n                bestCostDelta = costDelta;\n                bestIndex = thisIdx;\n                bestParallelResidualSum = thisParallelResidualSum;\n            }\n        }\n\n        return new CoordinateDescentResult(bestIndex, bestParallelResidualSum);\n    }\n\n    /**\n     * Wraps the two values we want to return from optimizeSingleSubspace\n     */\n    private static class CoordinateDescentResult {\n        final int newCenterIdx;\n        final float newParallelResidualComponent;\n\n        CoordinateDescentResult(int newCenterIdx, float newParallelResidualComponent) {\n            this.newCenterIdx = newCenterIdx;\n            this.newParallelResidualComponent = newParallelResidualComponent;\n        }\n    }\n\n    /**\n     * @return codebook ordinals representing the cluster centroids for each subspace that minimize the residual norm\n     */\n    private ByteSequence<?> initializeToMinResidualNorms(Residual[][] residualStats) {\n        var result = vectorTypeSupport.createByteSequence(residualStats.length);\n        // for each subspace\n        for (int i = 0; i < residualStats.length; i++) {\n            int minIndex = -1;\n            double minNormSquared = Double.MAX_VALUE;\n            // find the centroid with the smallest residual norm in this subspace\n            for (int j = 0; j < residualStats[i].length; j++) {\n                if (residualStats[i][j].residualNormSquared < minNormSquared) {\n                    minNormSquared = residualStats[i][j].residualNormSquared;\n                    minIndex = j;\n                }\n            }\n            result.set(i, (byte) minIndex);\n        }\n        return result;\n    }\n\n    /**\n     * @return the parallel-cost residuals for each subspace and cluster\n     */\n    private Residual[][] computeResiduals(VectorFloat<?> vector) {\n        Residual[][] residuals = new Residual[codebooks.length][];\n\n        float inverseNorm = (float) (1.0 / sqrt(dotProduct(vector, vector)));\n        for (int i = 0; i < codebooks.length; i++) {\n            var x = getSubVector(vector, i, subvectorSizesAndOffsets);\n            float xNormSquared = dotProduct(x, x);\n            residuals[i] = new Residual[clusterCount];\n\n            for (int j = 0; j < clusterCount; j++) {\n                residuals[i][j] = computeResidual(x, codebooks[i], j, centroidNormsSquared[i][j], xNormSquared, inverseNorm);\n            }\n        }\n\n        return residuals;\n    }\n\n    /**\n     * Represents the residual after subtracting a cluster centroid from a [sub]vector.\n     */\n    private static class Residual {\n        final float residualNormSquared;\n        final float parallelResidualComponent;\n\n        Residual(float residualNormSquared, float parallelResidualComponent) {\n            this.residualNormSquared = residualNormSquared;\n            this.parallelResidualComponent = parallelResidualComponent;\n        }\n    }\n\n    private Residual computeResidual(VectorFloat<?> x, VectorFloat<?> centroids, int centroid, float cNormSquared, float xNormSquared, float inverseNorm) {\n        float cDotX = VectorUtil.dotProduct(centroids, centroid * x.length(), x, 0, x.length());\n        float residualNormSquared = cNormSquared - 2 * cDotX + xNormSquared;\n        float parallelErrorSubtotal = cDotX - xNormSquared;\n        float parallelResidualComponent = square(parallelErrorSubtotal) * inverseNorm;\n        return new Residual(residualNormSquared, parallelResidualComponent);\n    }\n\n    private ByteSequence<?> encodeUnweighted(VectorFloat<?> vector) {\n        var encoded = vectorTypeSupport.createByteSequence(M);\n        for (int m = 0; m < M; m++) {\n            encoded.set(m, (byte) closestCentroidIndex(vector, m, codebooks[m]));\n        }\n        return encoded;\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector, relative to the global centroid.\n     */\n\n\n\n\n\n\n\n    /**\n     * @return how many bytes we are compressing to\n     */\n    public int getSubspaceCount() {\n        return M;\n    }\n\n    /**\n     * @return number of clusters per subspace\n     */\n    public int getClusterCount() {\n        return clusterCount;\n    }\n\n    static VectorFloat<?>[] createCodebooks(List<VectorFloat<?>> vectors, int[][] subvectorSizeAndOffset, int clusters, float anisotropicThreshold, ForkJoinPool simdExecutor) {\n        int M = subvectorSizeAndOffset.length;\n        return simdExecutor.submit(() -> IntStream.range(0, M).parallel().mapToObj(m -> {\n            VectorFloat<?>[] subvectors = extractSubvectors(vectors, m, subvectorSizeAndOffset);\n            var clusterer = new KMeansPlusPlusClusterer(subvectors, clusters, anisotropicThreshold);\n            return clusterer.cluster(K_MEANS_ITERATIONS, anisotropicThreshold == UNWEIGHTED ? 0 : K_MEANS_ITERATIONS);\n        }).toArray(VectorFloat<?>[]::new)).join();\n    }\n\n    /**\n     * Extract VectorFloat subvectors corresponding to the m'th subspace.\n     * This is NOT done in parallel (since the callers are themselves running in parallel).\n     */\n    private static VectorFloat<?>[] extractSubvectors(List<VectorFloat<?>> vectors, int m, int[][] subvectorSizeAndOffset) {\n        return vectors.stream()\n                .map(vector -> getSubVector(vector, m, subvectorSizeAndOffset))\n                .toArray(VectorFloat<?>[]::new);\n    }\n\n    int closestCentroidIndex(VectorFloat<?> subvector, int m, VectorFloat<?> codebook) {\n        int index = 0;\n        float minDist = Float.MAX_VALUE;\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        for (int i = 0; i < clusterCount; i++) {\n            float dist = VectorUtil.squareL2Distance(subvector, subvectorOffset, codebook, i * subvectorSize, subvectorSize);\n            if (dist < minDist) {\n                minDist = dist;\n                index = i;\n            }\n        }\n        return index;\n    }\n\n    /**\n     * Extracts the m-th subvector from a single vector.\n     */\n    static VectorFloat<?> getSubVector(VectorFloat<?> vector, int m, int[][] subvectorSizeAndOffset) {\n        VectorFloat<?> subvector = vectorTypeSupport.createFloatVector(subvectorSizeAndOffset[m][0]);\n        subvector.copyFrom(vector, subvectorSizeAndOffset[m][1], 0, subvectorSizeAndOffset[m][0]);\n        return subvector;\n    }\n\n    /**\n     * Splits the vector dimension into M subvectors of roughly equal size.\n     */\n    @VisibleForTesting\n    static int[][] getSubvectorSizesAndOffsets(int dimensions, int M) {\n        if (M > dimensions) {\n            throw new IllegalArgumentException(\"Number of subspaces must be less than or equal to the vector dimension\");\n        }\n        int[][] sizes = new int[M][];\n        int baseSize = dimensions / M;\n        int remainder = dimensions % M;\n        // distribute the remainder among the subvectors\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            int size = baseSize + (i < remainder ? 1 : 0);\n            sizes[i] = new int[]{size, offset};\n            offset += size;\n        }\n        return sizes;\n    }\n\n    VectorFloat<?> reusablePartialSums() {\n        return partialSums.get();\n    }\n\n    ByteSequence<?> reusablePartialQuantizedSums() {\n        return partialQuantizedSums.get();\n    }\n\n    VectorFloat<?> reusablePartialBestDistances() {\n        return partialBestDistances.get();\n    }\n\n    AtomicReference<VectorFloat<?>> partialSquaredMagnitudes() {\n        return partialSquaredMagnitudes;\n    }\n\n    AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes() {\n        return partialQuantizedSquaredMagnitudes;\n    }\n\n    public void write(DataOutput out, int version) throws IOException\n    {\n        if (version > OnDiskGraphIndex.CURRENT_VERSION) {\n            throw new IllegalArgumentException(\"Unsupported serialization version \" + version);\n        }\n        if (version < 3 && anisotropicThreshold != UNWEIGHTED) {\n            throw new IllegalArgumentException(\"Anisotropic threshold is only supported in serialization version 3 and above\");\n        }\n\n        if (version >= 3) {\n            out.writeInt(MAGIC);\n            out.writeInt(version);\n        }\n\n        if (globalCentroid == null) {\n            out.writeInt(0);\n        } else {\n            out.writeInt(globalCentroid.length());\n            vectorTypeSupport.writeFloatVector(out, globalCentroid);\n        }\n\n        out.writeInt(M);\n        assert Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum() == originalDimension;\n        assert M == subvectorSizesAndOffsets.length;\n        for (var a : subvectorSizesAndOffsets) {\n            out.writeInt(a[0]);\n        }\n\n        if (version >= 3) {\n            out.writeFloat(anisotropicThreshold);\n        }\n\n        assert codebooks.length == M;\n        out.writeInt(clusterCount);\n        for (int i = 0; i < M; i++) {\n            var codebook = codebooks[i];\n            assert codebook.length() == clusterCount * subvectorSizesAndOffsets[i][0];\n            vectorTypeSupport.writeFloatVector(out, codebook);\n        }\n    }\n\n    @Override\n    public int compressorSize() {\n        int size = 0;\n        size += Integer.BYTES; // MAGIC\n        size += Integer.BYTES; // STORAGE_VERSION\n        size += Integer.BYTES; // globalCentroidLength\n        if (globalCentroid != null) {\n            size += Float.BYTES * globalCentroid.length();\n        }\n        size += Integer.BYTES; // M\n        size += Integer.BYTES * M; // subvectorSizesAndOffsets (only the sizes are written)\n        size += Float.BYTES; // anisotropicThreshold\n        size += Integer.BYTES; // clusterCount\n        for (int i = 0; i < M; i++) {\n            size += Float.BYTES * codebooks[i].length();\n        }\n        return size;\n    }\n\n    public static ProductQuantization load(RandomAccessReader in) throws IOException {\n        int maybeMagic = in.readInt();\n        int version;\n        int globalCentroidLength;\n        if (maybeMagic != MAGIC) {\n            // JVector 1+2 format, no magic or version, starts straight off with the centroid length\n            version = 0;\n            globalCentroidLength = maybeMagic;\n        } else {\n            version = in.readInt();\n            globalCentroidLength = in.readInt();\n        }\n\n        VectorFloat<?> globalCentroid = null;\n        if (globalCentroidLength > 0) {\n            globalCentroid = vectorTypeSupport.readFloatVector(in, globalCentroidLength);\n        }\n\n        int M = in.readInt();\n        int[][] subvectorSizes = new int[M][];\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            subvectorSizes[i] = new int[2];\n            int size = in.readInt();\n            subvectorSizes[i][0] = size;\n\n```\n# Function Signature: @Override    public ByteSequence<?> encode(VectorFloat<?> vector) {\n# Natural Language Annotations: /**\n     * Encodes the input vector using the PQ codebooks.\n     * @return one byte per subspace\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\npublic ByteSequence<?> encode(VectorFloat<?> vector) {\n    var encoded = vectorTypeSupport.createByteSequence(M);\n    for (int m = 0; m < M; m++) {\n        encoded.set(m, (byte) closestCentroidIndex(vector.getSubVector(m, codebooks[m]), m, codebooks[m]));\n    }\n    return encoded;\n}\n```", "  ```\n@Override\npublic ByteSequence<?> encode(VectorFloat<?> vector) {\n    // Block of code to encode the vector using PQ codebooks...\n    // ...\n    // ...\n    return encodeUnweighted(vector);\n}\n```", "  ```\n@Override\npublic ByteSequence<?> encode(VectorFloat<?> vector) {\n    if (globalCentroid != null) {\n        vector = sub(vector, globalCentroid, originalDimension);\n    }\n\n    Residual[][] residuals = computeResiduals(vector);\n\n    // compute the initial residuals\n    ByteSequence<?> initial = initializeToMinResidualNorms(residuals);\n\n    // optimize each coordinate separately using coordinate descent\n    ByteSequence<?> encoding = encodeUnweighted(vector);\n    for (int m = 0; m < M; m++) {\n        Residual[] currentResiduals = residuals[m];\n        ByteSequence<?> currentEncoding = encoding.subSequence(m, m + 1);\n        while (true) {\n            int oldCenter = currentEncoding.get(0);\n            float oldParallel = currentResiduals[oldCenter].parallelResidualComponent;\n\n            CoordinateDescentResult result = optimizeSingleSubspace(currentResiduals, oldCenter, oldParallel);\n            int newCenter = result.newCenterIdx;\n            float newParallel = result.newParallelResidualComponent;\n\n            if (newCenter == oldCenter && newParallel == oldParallel) {\n                break;\n            } else {\n                currentEncoding.set(0, (byte) newCenter);\n                currentResiduals = result.newResiduals;\n            }\n        }\n    }\n\n    ByteSequence<?> bitEncoding = quantizeAllCodewords(encoding);\n    if (vector.isValueShared()) {\n        bitEncoding = bitEncoding.copy();\n    }\n    return bitEncoding;\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-decode": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.pq;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.graph.disk.OnDiskGraphIndex;\nimport io.github.jbellis.jvector.util.Accountable;\nimport io.github.jbellis.jvector.util.PhysicalCoreExecutor;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.VectorizationProvider;\nimport io.github.jbellis.jvector.vector.types.ByteSequence;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\nimport java.io.DataOutput;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\nimport java.util.stream.IntStream;\n\nimport static io.github.jbellis.jvector.pq.KMeansPlusPlusClusterer.UNWEIGHTED;\nimport static io.github.jbellis.jvector.util.MathUtil.square;\nimport static io.github.jbellis.jvector.vector.VectorUtil.dotProduct;\nimport static io.github.jbellis.jvector.vector.VectorUtil.sub;\nimport static java.lang.Math.min;\nimport static java.lang.Math.sqrt;\n\n/**\n * Product Quantization for float vectors.  Supports arbitrary source and target dimensionality;\n * in particular, the source does not need to be evenly divisible by the target.\n */\npublic class ProductQuantization implements VectorCompressor<ByteSequence<?>>, Accountable {\n    private static final int MAGIC = 0x75EC4012; // JVECTOR, with some imagination\n\n    private static final VectorTypeSupport vectorTypeSupport = VectorizationProvider.getInstance().getVectorTypeSupport();\n    static final int DEFAULT_CLUSTERS = 256; // number of clusters per subspace = one byte's worth\n    static final int K_MEANS_ITERATIONS = 6;\n    public static final int MAX_PQ_TRAINING_SET_SIZE = 128000;\n\n    final VectorFloat<?>[] codebooks; // array of codebooks, where each codebook is a VectorFloat consisting of k contiguous subvectors each of length M\n    final int M; // codebooks.length, redundantly reproduced for convenience\n    private final int clusterCount; // codebooks[0].length, redundantly reproduced for convenience\n    final int originalDimension;\n    final VectorFloat<?> globalCentroid;\n    final int[][] subvectorSizesAndOffsets;\n    final float anisotropicThreshold; // parallel cost multiplier\n    private final float[][] centroidNormsSquared; // precomputed norms of the centroids, for encoding\n    private final ThreadLocal<VectorFloat<?>> partialSums; // for dot product, euclidean, and cosine partials\n    private final ThreadLocal<VectorFloat<?>> partialBestDistances; // for partial best distances during fused ADC\n    private final ThreadLocal<ByteSequence<?>> partialQuantizedSums; // for quantized sums during fused ADC\n    private final AtomicReference<VectorFloat<?>> partialSquaredMagnitudes; // for cosine partials\n    private final AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes; // for quantized squared magnitude partials during cosine fused ADC\n    protected volatile float squaredMagnitudeDelta = 0; // for cosine fused ADC squared magnitude quantization delta (since this is invariant for a given PQ)\n    protected volatile float minSquaredMagnitude = 0; // for cosine fused ADC minimum squared magnitude (invariant for a given PQ)\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     */\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter) {\n        return compute(ravv, M, clusterCount, globallyCenter, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold) {\n        return compute(ravv, M, clusterCount, globallyCenter, anisotropicThreshold, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param clusterCount number of clusters per subspace\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     * @param anisotropicThreshold the threshold of relevance for anisotropic angular distance shaping, giving\n     *        higher priority to parallel error.  Anisotropic shaping requires that your dataset be normalized\n     *        to unit length.  Use a threshold of UNWEIGHTED for isotropic distance\n     *        (i.e. normal, unweighted L2 distance).\n     * @param simdExecutor     ForkJoinPool instance for SIMD operations, best is to use a pool with the size of\n     *                         the number of physical cores.\n     * @param parallelExecutor ForkJoinPool instance for parallel stream operations\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static List<VectorFloat<?>> extractTrainingVectors(RandomAccessVectorValues ravv, ForkJoinPool parallelExecutor) {\n        // limit the number of vectors we train on\n        var P = min(1.0f, MAX_PQ_TRAINING_SET_SIZE / (float) ravv.size());\n        var ravvCopy = ravv.threadLocalSupplier();\n        return parallelExecutor.submit(() -> IntStream.range(0, ravv.size()).parallel()\n                        .filter(i -> ThreadLocalRandom.current().nextFloat() < P)\n                        .mapToObj(targetOrd -> {\n                            var localRavv = ravvCopy.get();\n                            VectorFloat<?> v = localRavv.getVector(targetOrd);\n                            return localRavv.isValueShared() ? v.copy() : v;\n                        })\n                        .collect(Collectors.toList()))\n                .join();\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     */\n    public ProductQuantization refine(RandomAccessVectorValues ravv) {\n        return refine(ravv, 1, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     *\n     * @param lloydsRounds number of Lloyd's iterations to run against\n     *                     the new data.  Suggested values are 1 or 2.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    ProductQuantization(VectorFloat<?>[] codebooks, int clusterCount, int[][] subvectorSizesAndOffsets, VectorFloat<?> globalCentroid, float anisotropicThreshold) {\n        this.codebooks = codebooks;\n        this.globalCentroid = globalCentroid;\n        this.M = codebooks.length;\n        this.clusterCount = clusterCount;\n        this.subvectorSizesAndOffsets = subvectorSizesAndOffsets;\n        this.originalDimension = Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum();\n        if (globalCentroid != null && globalCentroid.length() != originalDimension) {\n            var msg = String.format(\"Global centroid length %d does not match vector dimensionality %d\", globalCentroid.length(), originalDimension);\n            throw new IllegalArgumentException(msg);\n        }\n        this.anisotropicThreshold = anisotropicThreshold;\n        this.partialSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount() * getClusterCount()));\n        this.partialBestDistances = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount()));\n        this.partialQuantizedSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createByteSequence(getSubspaceCount() * getClusterCount() * 2));\n        this.partialSquaredMagnitudes = new AtomicReference<>(null);\n        this.partialQuantizedSquaredMagnitudes= new AtomicReference<>(null);\n\n\n        centroidNormsSquared = new float[M][clusterCount];\n        for (int i = 0; i < M; i++) {\n            for (int j = 0; j < clusterCount; j++) {\n                centroidNormsSquared[i][j] = dotProduct(codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        subvectorSizesAndOffsets[i][0]);\n            }\n        }\n    }\n\n    @Override\n    public CompressedVectors createCompressedVectors(Object[] compressedVectors) {\n        return new PQVectors(this, (ByteSequence<?>[]) compressedVectors);\n    }\n\n    /**\n     * Encodes the given vectors in parallel using the PQ codebooks.\n     */\n    @Override\n    public ByteSequence<?>[] encodeAll(RandomAccessVectorValues ravv, ForkJoinPool simdExecutor) {\n        return simdExecutor.submit(() -> IntStream.range(0, ravv.size())\n                        .parallel()\n                        .mapToObj(i -> encode(ravv.getVector(i)))\n                        .toArray(ByteSequence<?>[]::new))\n                .join();\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks, weighing parallel loss more than orthogonal loss.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private CoordinateDescentResult optimizeSingleSubspace(Residual[] residuals, int oldIdx, float oldParallelResidualSum) {\n        // (this is global to all subspaces but it's not worth stashing in a field)\n        float pcm = KMeansPlusPlusClusterer.computeParallelCostMultiplier(anisotropicThreshold, originalDimension);\n\n        float oldResidualNormSquared = residuals[oldIdx].residualNormSquared;\n        float oldParallelComponent = residuals[oldIdx].parallelResidualComponent;\n\n        float bestCostDelta = 0;\n        int bestIndex = oldIdx;\n        float bestParallelResidualSum = oldParallelResidualSum;\n\n        // loop over potential new centers\n        for (int thisIdx = 0; thisIdx < residuals.length; thisIdx++) {\n            if (thisIdx == oldIdx) {\n                continue;\n            }\n\n            // compute the new parallel residual sum and parallel norm delta\n            Residual rs = residuals[thisIdx];\n            float thisParallelResidualSum = oldParallelResidualSum - oldParallelComponent + rs.parallelResidualComponent;\n            float parallelNormDelta = square(thisParallelResidualSum) - square(oldParallelResidualSum);\n            // quit early if new parallel norm is worse than the old\n            if (parallelNormDelta > 0) {\n                continue;\n            }\n\n            // compute the total cost delta\n            float residualNormDelta = rs.residualNormSquared - oldResidualNormSquared;\n            float perpendicularNormDelta = residualNormDelta - parallelNormDelta;\n            float costDelta = pcm * parallelNormDelta + perpendicularNormDelta;\n\n            // save the new center if it's the best so far\n            if (costDelta < bestCostDelta) {\n                bestCostDelta = costDelta;\n                bestIndex = thisIdx;\n                bestParallelResidualSum = thisParallelResidualSum;\n            }\n        }\n\n        return new CoordinateDescentResult(bestIndex, bestParallelResidualSum);\n    }\n\n    /**\n     * Wraps the two values we want to return from optimizeSingleSubspace\n     */\n    private static class CoordinateDescentResult {\n        final int newCenterIdx;\n        final float newParallelResidualComponent;\n\n        CoordinateDescentResult(int newCenterIdx, float newParallelResidualComponent) {\n            this.newCenterIdx = newCenterIdx;\n            this.newParallelResidualComponent = newParallelResidualComponent;\n        }\n    }\n\n    /**\n     * @return codebook ordinals representing the cluster centroids for each subspace that minimize the residual norm\n     */\n    private ByteSequence<?> initializeToMinResidualNorms(Residual[][] residualStats) {\n        var result = vectorTypeSupport.createByteSequence(residualStats.length);\n        // for each subspace\n        for (int i = 0; i < residualStats.length; i++) {\n            int minIndex = -1;\n            double minNormSquared = Double.MAX_VALUE;\n            // find the centroid with the smallest residual norm in this subspace\n            for (int j = 0; j < residualStats[i].length; j++) {\n                if (residualStats[i][j].residualNormSquared < minNormSquared) {\n                    minNormSquared = residualStats[i][j].residualNormSquared;\n                    minIndex = j;\n                }\n            }\n            result.set(i, (byte) minIndex);\n        }\n        return result;\n    }\n\n    /**\n     * @return the parallel-cost residuals for each subspace and cluster\n     */\n    private Residual[][] computeResiduals(VectorFloat<?> vector) {\n        Residual[][] residuals = new Residual[codebooks.length][];\n\n        float inverseNorm = (float) (1.0 / sqrt(dotProduct(vector, vector)));\n        for (int i = 0; i < codebooks.length; i++) {\n            var x = getSubVector(vector, i, subvectorSizesAndOffsets);\n            float xNormSquared = dotProduct(x, x);\n            residuals[i] = new Residual[clusterCount];\n\n            for (int j = 0; j < clusterCount; j++) {\n                residuals[i][j] = computeResidual(x, codebooks[i], j, centroidNormsSquared[i][j], xNormSquared, inverseNorm);\n            }\n        }\n\n        return residuals;\n    }\n\n    /**\n     * Represents the residual after subtracting a cluster centroid from a [sub]vector.\n     */\n    private static class Residual {\n        final float residualNormSquared;\n        final float parallelResidualComponent;\n\n        Residual(float residualNormSquared, float parallelResidualComponent) {\n            this.residualNormSquared = residualNormSquared;\n            this.parallelResidualComponent = parallelResidualComponent;\n        }\n    }\n\n    private Residual computeResidual(VectorFloat<?> x, VectorFloat<?> centroids, int centroid, float cNormSquared, float xNormSquared, float inverseNorm) {\n        float cDotX = VectorUtil.dotProduct(centroids, centroid * x.length(), x, 0, x.length());\n        float residualNormSquared = cNormSquared - 2 * cDotX + xNormSquared;\n        float parallelErrorSubtotal = cDotX - xNormSquared;\n        float parallelResidualComponent = square(parallelErrorSubtotal) * inverseNorm;\n        return new Residual(residualNormSquared, parallelResidualComponent);\n    }\n\n    private ByteSequence<?> encodeUnweighted(VectorFloat<?> vector) {\n        var encoded = vectorTypeSupport.createByteSequence(M);\n        for (int m = 0; m < M; m++) {\n            encoded.set(m, (byte) closestCentroidIndex(vector, m, codebooks[m]));\n        }\n        return encoded;\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector, relative to the global centroid.\n     */\n\n\n\n\n\n\n\n    /**\n     * @return how many bytes we are compressing to\n     */\n    public int getSubspaceCount() {\n        return M;\n    }\n\n    /**\n     * @return number of clusters per subspace\n     */\n    public int getClusterCount() {\n        return clusterCount;\n    }\n\n    static VectorFloat<?>[] createCodebooks(List<VectorFloat<?>> vectors, int[][] subvectorSizeAndOffset, int clusters, float anisotropicThreshold, ForkJoinPool simdExecutor) {\n        int M = subvectorSizeAndOffset.length;\n        return simdExecutor.submit(() -> IntStream.range(0, M).parallel().mapToObj(m -> {\n            VectorFloat<?>[] subvectors = extractSubvectors(vectors, m, subvectorSizeAndOffset);\n            var clusterer = new KMeansPlusPlusClusterer(subvectors, clusters, anisotropicThreshold);\n            return clusterer.cluster(K_MEANS_ITERATIONS, anisotropicThreshold == UNWEIGHTED ? 0 : K_MEANS_ITERATIONS);\n        }).toArray(VectorFloat<?>[]::new)).join();\n    }\n\n    /**\n     * Extract VectorFloat subvectors corresponding to the m'th subspace.\n     * This is NOT done in parallel (since the callers are themselves running in parallel).\n     */\n    private static VectorFloat<?>[] extractSubvectors(List<VectorFloat<?>> vectors, int m, int[][] subvectorSizeAndOffset) {\n        return vectors.stream()\n                .map(vector -> getSubVector(vector, m, subvectorSizeAndOffset))\n                .toArray(VectorFloat<?>[]::new);\n    }\n\n    int closestCentroidIndex(VectorFloat<?> subvector, int m, VectorFloat<?> codebook) {\n        int index = 0;\n        float minDist = Float.MAX_VALUE;\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        for (int i = 0; i < clusterCount; i++) {\n            float dist = VectorUtil.squareL2Distance(subvector, subvectorOffset, codebook, i * subvectorSize, subvectorSize);\n            if (dist < minDist) {\n                minDist = dist;\n                index = i;\n            }\n        }\n        return index;\n    }\n\n    /**\n     * Extracts the m-th subvector from a single vector.\n     */\n    static VectorFloat<?> getSubVector(VectorFloat<?> vector, int m, int[][] subvectorSizeAndOffset) {\n        VectorFloat<?> subvector = vectorTypeSupport.createFloatVector(subvectorSizeAndOffset[m][0]);\n        subvector.copyFrom(vector, subvectorSizeAndOffset[m][1], 0, subvectorSizeAndOffset[m][0]);\n        return subvector;\n    }\n\n    /**\n     * Splits the vector dimension into M subvectors of roughly equal size.\n     */\n    @VisibleForTesting\n    static int[][] getSubvectorSizesAndOffsets(int dimensions, int M) {\n        if (M > dimensions) {\n            throw new IllegalArgumentException(\"Number of subspaces must be less than or equal to the vector dimension\");\n        }\n        int[][] sizes = new int[M][];\n        int baseSize = dimensions / M;\n        int remainder = dimensions % M;\n        // distribute the remainder among the subvectors\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            int size = baseSize + (i < remainder ? 1 : 0);\n            sizes[i] = new int[]{size, offset};\n            offset += size;\n        }\n        return sizes;\n    }\n\n    VectorFloat<?> reusablePartialSums() {\n        return partialSums.get();\n    }\n\n    ByteSequence<?> reusablePartialQuantizedSums() {\n        return partialQuantizedSums.get();\n    }\n\n    VectorFloat<?> reusablePartialBestDistances() {\n        return partialBestDistances.get();\n    }\n\n    AtomicReference<VectorFloat<?>> partialSquaredMagnitudes() {\n        return partialSquaredMagnitudes;\n    }\n\n    AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes() {\n        return partialQuantizedSquaredMagnitudes;\n    }\n\n    public void write(DataOutput out, int version) throws IOException\n    {\n        if (version > OnDiskGraphIndex.CURRENT_VERSION) {\n            throw new IllegalArgumentException(\"Unsupported serialization version \" + version);\n        }\n        if (version < 3 && anisotropicThreshold != UNWEIGHTED) {\n            throw new IllegalArgumentException(\"Anisotropic threshold is only supported in serialization version 3 and above\");\n        }\n\n        if (version >= 3) {\n            out.writeInt(MAGIC);\n            out.writeInt(version);\n        }\n\n        if (globalCentroid == null) {\n            out.writeInt(0);\n        } else {\n            out.writeInt(globalCentroid.length());\n            vectorTypeSupport.writeFloatVector(out, globalCentroid);\n        }\n\n        out.writeInt(M);\n        assert Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum() == originalDimension;\n        assert M == subvectorSizesAndOffsets.length;\n        for (var a : subvectorSizesAndOffsets) {\n            out.writeInt(a[0]);\n        }\n\n        if (version >= 3) {\n            out.writeFloat(anisotropicThreshold);\n        }\n\n        assert codebooks.length == M;\n        out.writeInt(clusterCount);\n        for (int i = 0; i < M; i++) {\n            var codebook = codebooks[i];\n            assert codebook.length() == clusterCount * subvectorSizesAndOffsets[i][0];\n            vectorTypeSupport.writeFloatVector(out, codebook);\n        }\n    }\n\n    @Override\n    public int compressorSize() {\n        int size = 0;\n        size += Integer.BYTES; // MAGIC\n        size += Integer.BYTES; // STORAGE_VERSION\n        size += Integer.BYTES; // globalCentroidLength\n        if (globalCentroid != null) {\n            size += Float.BYTES * globalCentroid.length();\n        }\n        size += Integer.BYTES; // M\n        size += Integer.BYTES * M; // subvectorSizesAndOffsets (only the sizes are written)\n        size += Float.BYTES; // anisotropicThreshold\n        size += Integer.BYTES; // clusterCount\n        for (int i = 0; i < M; i++) {\n            size += Float.BYTES * codebooks[i].length();\n        }\n        return size;\n    }\n\n    public static ProductQuantization load(RandomAccessReader in) throws IOException {\n        int maybeMagic = in.readInt();\n        int version;\n        int globalCentroidLength;\n        if (maybeMagic != MAGIC) {\n            // JVector 1+2 format, no magic or version, starts straight off with the centroid length\n            version = 0;\n            globalCentroidLength = maybeMagic;\n        } else {\n            version = in.readInt();\n            globalCentroidLength = in.readInt();\n        }\n\n        VectorFloat<?> globalCentroid = null;\n        if (globalCentroidLength > 0) {\n            globalCentroid = vectorTypeSupport.readFloatVector(in, globalCentroidLength);\n        }\n\n        int M = in.readInt();\n        int[][] subvectorSizes = new int[M][];\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            subvectorSizes[i] = new int[2];\n            int size = in.readInt();\n            subvectorSizes[i][0] = size;\n\n```\n# Function Signature: public void decode(ByteSequence<?> encoded, VectorFloat<?> target) {\n# Natural Language Annotations: /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic void decode(ByteSequence<?> encoded, VectorFloat<?> target) {\n    assert M == subvectorSizesAndOffsets.length;\n    assert target.length() == originalDimension;\n    assert encoded.length() == M;\n\n    int m = 0;\n    int offset = 0;\n    for (int i = 0; i < M; i++) {\n        int cluster = encoded.get(i) & 0xFF; // cast byte to int\n        int subvectorSize = subvectorSizesAndOffsets[i][0];\n        int subvectorOffset = subvectorSizesAndOffsets[i][1];\n        target.copyFrom(codebooks[i], cluster * subvectorSize, offset, subvectorSize);\n        offset += subvectorSize;\n    }\n}\n```", "  ```\npublic void decode(ByteSequence<?> encoded, VectorFloat<?> target) {\n    // create a target vector if none is given\n    if (target == null) {\n        target = vectorTypeSupport.createFloatVector(originalDimension);\n    }\n    if (target.length() != originalDimension) {\n        return;\n    }\n\n    for (int m = 0; m < M; m++) {\n        int offset = 0;\n        for (int i = 0; i < clusterCount; i++) {\n            int codebookIndex = encoded.get(m);\n            VectorFloat<?> subvector = codebooks[m].getSubVector(codebookIndex * subvectorSizesAndOffsets[m][0], subvectorSizesAndOffsets[m][0]);\n            target.copyFrom(subvector, 0, offset, subvector.length());\n            offset += subvector.length();\n        }\n    }\n}\n```", "  ```\npublic void decode(ByteSequence<?> encoded, VectorFloat<?> target) {\n    for (int i = 0; i < M; i++) {\n        int centroidIndex = encoded.intValue(i);\n        float dist;\n        if (anisotropicThreshold == UNWEIGHTED) {\n            dist = 0;\n        } else {\n            VectorFloat<?> decodedSubvector = getSubVector(target, i, subvectorSizesAndOffsets);\n            dist = VectorUtil.squareL2Distance(decodedSubvector, 0, codebooks[i], centroidIndex * subvectorSizesAndOffsets[i][0], subvectorSizesAndOffsets[i][0]);\n        }\n        VectorUtil.copy(codebooks[i], centroidIndex * subvectorSizesAndOffsets[i][0], target, subvectorSizesAndOffsets[i][1], subvectorSizesAndOffsets[i][0]);\n        target.set(subvectorSizesAndOffsets[i][1] + subvectorSizesAndOffsets[i][0] - 1,\n                   target.get(subvectorSizesAndOffsets[i][1] + subvectorSizesAndOffsets[i][0] - 1) + dist);\n    }\n    if (globalCentroid != null) {\n        VectorUtil.sub(globalCentroid, 0, target, 0, globalCentroid.length(), target);\n    }\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-decodeCentered": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.pq;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.graph.disk.OnDiskGraphIndex;\nimport io.github.jbellis.jvector.util.Accountable;\nimport io.github.jbellis.jvector.util.PhysicalCoreExecutor;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.VectorizationProvider;\nimport io.github.jbellis.jvector.vector.types.ByteSequence;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\nimport java.io.DataOutput;\nimport java.io.IOException;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.stream.Collectors;\nimport java.util.stream.IntStream;\n\nimport static io.github.jbellis.jvector.pq.KMeansPlusPlusClusterer.UNWEIGHTED;\nimport static io.github.jbellis.jvector.util.MathUtil.square;\nimport static io.github.jbellis.jvector.vector.VectorUtil.dotProduct;\nimport static io.github.jbellis.jvector.vector.VectorUtil.sub;\nimport static java.lang.Math.min;\nimport static java.lang.Math.sqrt;\n\n/**\n * Product Quantization for float vectors.  Supports arbitrary source and target dimensionality;\n * in particular, the source does not need to be evenly divisible by the target.\n */\npublic class ProductQuantization implements VectorCompressor<ByteSequence<?>>, Accountable {\n    private static final int MAGIC = 0x75EC4012; // JVECTOR, with some imagination\n\n    private static final VectorTypeSupport vectorTypeSupport = VectorizationProvider.getInstance().getVectorTypeSupport();\n    static final int DEFAULT_CLUSTERS = 256; // number of clusters per subspace = one byte's worth\n    static final int K_MEANS_ITERATIONS = 6;\n    public static final int MAX_PQ_TRAINING_SET_SIZE = 128000;\n\n    final VectorFloat<?>[] codebooks; // array of codebooks, where each codebook is a VectorFloat consisting of k contiguous subvectors each of length M\n    final int M; // codebooks.length, redundantly reproduced for convenience\n    private final int clusterCount; // codebooks[0].length, redundantly reproduced for convenience\n    final int originalDimension;\n    final VectorFloat<?> globalCentroid;\n    final int[][] subvectorSizesAndOffsets;\n    final float anisotropicThreshold; // parallel cost multiplier\n    private final float[][] centroidNormsSquared; // precomputed norms of the centroids, for encoding\n    private final ThreadLocal<VectorFloat<?>> partialSums; // for dot product, euclidean, and cosine partials\n    private final ThreadLocal<VectorFloat<?>> partialBestDistances; // for partial best distances during fused ADC\n    private final ThreadLocal<ByteSequence<?>> partialQuantizedSums; // for quantized sums during fused ADC\n    private final AtomicReference<VectorFloat<?>> partialSquaredMagnitudes; // for cosine partials\n    private final AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes; // for quantized squared magnitude partials during cosine fused ADC\n    protected volatile float squaredMagnitudeDelta = 0; // for cosine fused ADC squared magnitude quantization delta (since this is invariant for a given PQ)\n    protected volatile float minSquaredMagnitude = 0; // for cosine fused ADC minimum squared magnitude (invariant for a given PQ)\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     */\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter) {\n        return compute(ravv, M, clusterCount, globallyCenter, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    public static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold) {\n        return compute(ravv, M, clusterCount, globallyCenter, anisotropicThreshold, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Initializes the codebooks by clustering the input data using Product Quantization.\n     *\n     * @param ravv the vectors to quantize\n     * @param M number of subspaces\n     * @param clusterCount number of clusters per subspace\n     * @param globallyCenter whether to center the vectors globally before quantization\n     *                       (not recommended when using the quantization for dot product)\n     * @param anisotropicThreshold the threshold of relevance for anisotropic angular distance shaping, giving\n     *        higher priority to parallel error.  Anisotropic shaping requires that your dataset be normalized\n     *        to unit length.  Use a threshold of UNWEIGHTED for isotropic distance\n     *        (i.e. normal, unweighted L2 distance).\n     * @param simdExecutor     ForkJoinPool instance for SIMD operations, best is to use a pool with the size of\n     *                         the number of physical cores.\n     * @param parallelExecutor ForkJoinPool instance for parallel stream operations\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static List<VectorFloat<?>> extractTrainingVectors(RandomAccessVectorValues ravv, ForkJoinPool parallelExecutor) {\n        // limit the number of vectors we train on\n        var P = min(1.0f, MAX_PQ_TRAINING_SET_SIZE / (float) ravv.size());\n        var ravvCopy = ravv.threadLocalSupplier();\n        return parallelExecutor.submit(() -> IntStream.range(0, ravv.size()).parallel()\n                        .filter(i -> ThreadLocalRandom.current().nextFloat() < P)\n                        .mapToObj(targetOrd -> {\n                            var localRavv = ravvCopy.get();\n                            VectorFloat<?> v = localRavv.getVector(targetOrd);\n                            return localRavv.isValueShared() ? v.copy() : v;\n                        })\n                        .collect(Collectors.toList()))\n                .join();\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     */\n    public ProductQuantization refine(RandomAccessVectorValues ravv) {\n        return refine(ravv, 1, UNWEIGHTED, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Create a new PQ by fine-tuning this one with the data in `ravv`\n     *\n     * @param lloydsRounds number of Lloyd's iterations to run against\n     *                     the new data.  Suggested values are 1 or 2.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    ProductQuantization(VectorFloat<?>[] codebooks, int clusterCount, int[][] subvectorSizesAndOffsets, VectorFloat<?> globalCentroid, float anisotropicThreshold) {\n        this.codebooks = codebooks;\n        this.globalCentroid = globalCentroid;\n        this.M = codebooks.length;\n        this.clusterCount = clusterCount;\n        this.subvectorSizesAndOffsets = subvectorSizesAndOffsets;\n        this.originalDimension = Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum();\n        if (globalCentroid != null && globalCentroid.length() != originalDimension) {\n            var msg = String.format(\"Global centroid length %d does not match vector dimensionality %d\", globalCentroid.length(), originalDimension);\n            throw new IllegalArgumentException(msg);\n        }\n        this.anisotropicThreshold = anisotropicThreshold;\n        this.partialSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount() * getClusterCount()));\n        this.partialBestDistances = ThreadLocal.withInitial(() -> vectorTypeSupport.createFloatVector(getSubspaceCount()));\n        this.partialQuantizedSums = ThreadLocal.withInitial(() -> vectorTypeSupport.createByteSequence(getSubspaceCount() * getClusterCount() * 2));\n        this.partialSquaredMagnitudes = new AtomicReference<>(null);\n        this.partialQuantizedSquaredMagnitudes= new AtomicReference<>(null);\n\n\n        centroidNormsSquared = new float[M][clusterCount];\n        for (int i = 0; i < M; i++) {\n            for (int j = 0; j < clusterCount; j++) {\n                centroidNormsSquared[i][j] = dotProduct(codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        codebooks[i], j * subvectorSizesAndOffsets[i][0],\n                                                        subvectorSizesAndOffsets[i][0]);\n            }\n        }\n    }\n\n    @Override\n    public CompressedVectors createCompressedVectors(Object[] compressedVectors) {\n        return new PQVectors(this, (ByteSequence<?>[]) compressedVectors);\n    }\n\n    /**\n     * Encodes the given vectors in parallel using the PQ codebooks.\n     */\n    @Override\n    public ByteSequence<?>[] encodeAll(RandomAccessVectorValues ravv, ForkJoinPool simdExecutor) {\n        return simdExecutor.submit(() -> IntStream.range(0, ravv.size())\n                        .parallel()\n                        .mapToObj(i -> encode(ravv.getVector(i)))\n                        .toArray(ByteSequence<?>[]::new))\n                .join();\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks, weighing parallel loss more than orthogonal loss.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private CoordinateDescentResult optimizeSingleSubspace(Residual[] residuals, int oldIdx, float oldParallelResidualSum) {\n        // (this is global to all subspaces but it's not worth stashing in a field)\n        float pcm = KMeansPlusPlusClusterer.computeParallelCostMultiplier(anisotropicThreshold, originalDimension);\n\n        float oldResidualNormSquared = residuals[oldIdx].residualNormSquared;\n        float oldParallelComponent = residuals[oldIdx].parallelResidualComponent;\n\n        float bestCostDelta = 0;\n        int bestIndex = oldIdx;\n        float bestParallelResidualSum = oldParallelResidualSum;\n\n        // loop over potential new centers\n        for (int thisIdx = 0; thisIdx < residuals.length; thisIdx++) {\n            if (thisIdx == oldIdx) {\n                continue;\n            }\n\n            // compute the new parallel residual sum and parallel norm delta\n            Residual rs = residuals[thisIdx];\n            float thisParallelResidualSum = oldParallelResidualSum - oldParallelComponent + rs.parallelResidualComponent;\n            float parallelNormDelta = square(thisParallelResidualSum) - square(oldParallelResidualSum);\n            // quit early if new parallel norm is worse than the old\n            if (parallelNormDelta > 0) {\n                continue;\n            }\n\n            // compute the total cost delta\n            float residualNormDelta = rs.residualNormSquared - oldResidualNormSquared;\n            float perpendicularNormDelta = residualNormDelta - parallelNormDelta;\n            float costDelta = pcm * parallelNormDelta + perpendicularNormDelta;\n\n            // save the new center if it's the best so far\n            if (costDelta < bestCostDelta) {\n                bestCostDelta = costDelta;\n                bestIndex = thisIdx;\n                bestParallelResidualSum = thisParallelResidualSum;\n            }\n        }\n\n        return new CoordinateDescentResult(bestIndex, bestParallelResidualSum);\n    }\n\n    /**\n     * Wraps the two values we want to return from optimizeSingleSubspace\n     */\n    private static class CoordinateDescentResult {\n        final int newCenterIdx;\n        final float newParallelResidualComponent;\n\n        CoordinateDescentResult(int newCenterIdx, float newParallelResidualComponent) {\n            this.newCenterIdx = newCenterIdx;\n            this.newParallelResidualComponent = newParallelResidualComponent;\n        }\n    }\n\n    /**\n     * @return codebook ordinals representing the cluster centroids for each subspace that minimize the residual norm\n     */\n    private ByteSequence<?> initializeToMinResidualNorms(Residual[][] residualStats) {\n        var result = vectorTypeSupport.createByteSequence(residualStats.length);\n        // for each subspace\n        for (int i = 0; i < residualStats.length; i++) {\n            int minIndex = -1;\n            double minNormSquared = Double.MAX_VALUE;\n            // find the centroid with the smallest residual norm in this subspace\n            for (int j = 0; j < residualStats[i].length; j++) {\n                if (residualStats[i][j].residualNormSquared < minNormSquared) {\n                    minNormSquared = residualStats[i][j].residualNormSquared;\n                    minIndex = j;\n                }\n            }\n            result.set(i, (byte) minIndex);\n        }\n        return result;\n    }\n\n    /**\n     * @return the parallel-cost residuals for each subspace and cluster\n     */\n    private Residual[][] computeResiduals(VectorFloat<?> vector) {\n        Residual[][] residuals = new Residual[codebooks.length][];\n\n        float inverseNorm = (float) (1.0 / sqrt(dotProduct(vector, vector)));\n        for (int i = 0; i < codebooks.length; i++) {\n            var x = getSubVector(vector, i, subvectorSizesAndOffsets);\n            float xNormSquared = dotProduct(x, x);\n            residuals[i] = new Residual[clusterCount];\n\n            for (int j = 0; j < clusterCount; j++) {\n                residuals[i][j] = computeResidual(x, codebooks[i], j, centroidNormsSquared[i][j], xNormSquared, inverseNorm);\n            }\n        }\n\n        return residuals;\n    }\n\n    /**\n     * Represents the residual after subtracting a cluster centroid from a [sub]vector.\n     */\n    private static class Residual {\n        final float residualNormSquared;\n        final float parallelResidualComponent;\n\n        Residual(float residualNormSquared, float parallelResidualComponent) {\n            this.residualNormSquared = residualNormSquared;\n            this.parallelResidualComponent = parallelResidualComponent;\n        }\n    }\n\n    private Residual computeResidual(VectorFloat<?> x, VectorFloat<?> centroids, int centroid, float cNormSquared, float xNormSquared, float inverseNorm) {\n        float cDotX = VectorUtil.dotProduct(centroids, centroid * x.length(), x, 0, x.length());\n        float residualNormSquared = cNormSquared - 2 * cDotX + xNormSquared;\n        float parallelErrorSubtotal = cDotX - xNormSquared;\n        float parallelResidualComponent = square(parallelErrorSubtotal) * inverseNorm;\n        return new Residual(residualNormSquared, parallelResidualComponent);\n    }\n\n    private ByteSequence<?> encodeUnweighted(VectorFloat<?> vector) {\n        var encoded = vectorTypeSupport.createByteSequence(M);\n        for (int m = 0; m < M; m++) {\n            encoded.set(m, (byte) closestCentroidIndex(vector, m, codebooks[m]));\n        }\n        return encoded;\n    }\n\n    /**\n     * Encodes the input vector using the PQ codebooks.\n     * @return one byte per subspace\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector, relative to the global centroid.\n     */\n\n\n\n\n\n\n\n    /**\n     * @return how many bytes we are compressing to\n     */\n    public int getSubspaceCount() {\n        return M;\n    }\n\n    /**\n     * @return number of clusters per subspace\n     */\n    public int getClusterCount() {\n        return clusterCount;\n    }\n\n    static VectorFloat<?>[] createCodebooks(List<VectorFloat<?>> vectors, int[][] subvectorSizeAndOffset, int clusters, float anisotropicThreshold, ForkJoinPool simdExecutor) {\n        int M = subvectorSizeAndOffset.length;\n        return simdExecutor.submit(() -> IntStream.range(0, M).parallel().mapToObj(m -> {\n            VectorFloat<?>[] subvectors = extractSubvectors(vectors, m, subvectorSizeAndOffset);\n            var clusterer = new KMeansPlusPlusClusterer(subvectors, clusters, anisotropicThreshold);\n            return clusterer.cluster(K_MEANS_ITERATIONS, anisotropicThreshold == UNWEIGHTED ? 0 : K_MEANS_ITERATIONS);\n        }).toArray(VectorFloat<?>[]::new)).join();\n    }\n\n    /**\n     * Extract VectorFloat subvectors corresponding to the m'th subspace.\n     * This is NOT done in parallel (since the callers are themselves running in parallel).\n     */\n    private static VectorFloat<?>[] extractSubvectors(List<VectorFloat<?>> vectors, int m, int[][] subvectorSizeAndOffset) {\n        return vectors.stream()\n                .map(vector -> getSubVector(vector, m, subvectorSizeAndOffset))\n                .toArray(VectorFloat<?>[]::new);\n    }\n\n    int closestCentroidIndex(VectorFloat<?> subvector, int m, VectorFloat<?> codebook) {\n        int index = 0;\n        float minDist = Float.MAX_VALUE;\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        for (int i = 0; i < clusterCount; i++) {\n            float dist = VectorUtil.squareL2Distance(subvector, subvectorOffset, codebook, i * subvectorSize, subvectorSize);\n            if (dist < minDist) {\n                minDist = dist;\n                index = i;\n            }\n        }\n        return index;\n    }\n\n    /**\n     * Extracts the m-th subvector from a single vector.\n     */\n    static VectorFloat<?> getSubVector(VectorFloat<?> vector, int m, int[][] subvectorSizeAndOffset) {\n        VectorFloat<?> subvector = vectorTypeSupport.createFloatVector(subvectorSizeAndOffset[m][0]);\n        subvector.copyFrom(vector, subvectorSizeAndOffset[m][1], 0, subvectorSizeAndOffset[m][0]);\n        return subvector;\n    }\n\n    /**\n     * Splits the vector dimension into M subvectors of roughly equal size.\n     */\n    @VisibleForTesting\n    static int[][] getSubvectorSizesAndOffsets(int dimensions, int M) {\n        if (M > dimensions) {\n            throw new IllegalArgumentException(\"Number of subspaces must be less than or equal to the vector dimension\");\n        }\n        int[][] sizes = new int[M][];\n        int baseSize = dimensions / M;\n        int remainder = dimensions % M;\n        // distribute the remainder among the subvectors\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            int size = baseSize + (i < remainder ? 1 : 0);\n            sizes[i] = new int[]{size, offset};\n            offset += size;\n        }\n        return sizes;\n    }\n\n    VectorFloat<?> reusablePartialSums() {\n        return partialSums.get();\n    }\n\n    ByteSequence<?> reusablePartialQuantizedSums() {\n        return partialQuantizedSums.get();\n    }\n\n    VectorFloat<?> reusablePartialBestDistances() {\n        return partialBestDistances.get();\n    }\n\n    AtomicReference<VectorFloat<?>> partialSquaredMagnitudes() {\n        return partialSquaredMagnitudes;\n    }\n\n    AtomicReference<ByteSequence<?>> partialQuantizedSquaredMagnitudes() {\n        return partialQuantizedSquaredMagnitudes;\n    }\n\n    public void write(DataOutput out, int version) throws IOException\n    {\n        if (version > OnDiskGraphIndex.CURRENT_VERSION) {\n            throw new IllegalArgumentException(\"Unsupported serialization version \" + version);\n        }\n        if (version < 3 && anisotropicThreshold != UNWEIGHTED) {\n            throw new IllegalArgumentException(\"Anisotropic threshold is only supported in serialization version 3 and above\");\n        }\n\n        if (version >= 3) {\n            out.writeInt(MAGIC);\n            out.writeInt(version);\n        }\n\n        if (globalCentroid == null) {\n            out.writeInt(0);\n        } else {\n            out.writeInt(globalCentroid.length());\n            vectorTypeSupport.writeFloatVector(out, globalCentroid);\n        }\n\n        out.writeInt(M);\n        assert Arrays.stream(subvectorSizesAndOffsets).mapToInt(m -> m[0]).sum() == originalDimension;\n        assert M == subvectorSizesAndOffsets.length;\n        for (var a : subvectorSizesAndOffsets) {\n            out.writeInt(a[0]);\n        }\n\n        if (version >= 3) {\n            out.writeFloat(anisotropicThreshold);\n        }\n\n        assert codebooks.length == M;\n        out.writeInt(clusterCount);\n        for (int i = 0; i < M; i++) {\n            var codebook = codebooks[i];\n            assert codebook.length() == clusterCount * subvectorSizesAndOffsets[i][0];\n            vectorTypeSupport.writeFloatVector(out, codebook);\n        }\n    }\n\n    @Override\n    public int compressorSize() {\n        int size = 0;\n        size += Integer.BYTES; // MAGIC\n        size += Integer.BYTES; // STORAGE_VERSION\n        size += Integer.BYTES; // globalCentroidLength\n        if (globalCentroid != null) {\n            size += Float.BYTES * globalCentroid.length();\n        }\n        size += Integer.BYTES; // M\n        size += Integer.BYTES * M; // subvectorSizesAndOffsets (only the sizes are written)\n        size += Float.BYTES; // anisotropicThreshold\n        size += Integer.BYTES; // clusterCount\n        for (int i = 0; i < M; i++) {\n            size += Float.BYTES * codebooks[i].length();\n        }\n        return size;\n    }\n\n    public static ProductQuantization load(RandomAccessReader in) throws IOException {\n        int maybeMagic = in.readInt();\n        int version;\n        int globalCentroidLength;\n        if (maybeMagic != MAGIC) {\n            // JVector 1+2 format, no magic or version, starts straight off with the centroid length\n            version = 0;\n            globalCentroidLength = maybeMagic;\n        } else {\n            version = in.readInt();\n            globalCentroidLength = in.readInt();\n        }\n\n        VectorFloat<?> globalCentroid = null;\n        if (globalCentroidLength > 0) {\n            globalCentroid = vectorTypeSupport.readFloatVector(in, globalCentroidLength);\n        }\n\n        int M = in.readInt();\n        int[][] subvectorSizes = new int[M][];\n        int offset = 0;\n        for (int i = 0; i < M; i++) {\n            subvectorSizes[i] = new int[2];\n            int size = in.readInt();\n            subvectorSizes[i][0] = size;\n\n```\n# Function Signature: void decodeCentered(ByteSequence<?> encoded, VectorFloat<?> target) {\n# Natural Language Annotations: /**\n     * Decodes the quantized representation (ByteSequence) to its approximate original vector, relative to the global centroid.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\nvoid decodeCentered(ByteSequence<?> encoded, VectorFloat<?> target) {\n    Objects.requireNonNull(encoded);\n    Objects.requireNonNull(target);\n    if (encoded.length() != M) {\n        throw new IllegalArgumentException(String.format(\"encoded length %d != subspace count %d\", encoded.length(), M));\n    }\n    if (target.length() != originalDimension) {\n        throw new IllegalArgumentException(String.format(\"target length %d != original dimension %d\", target.length(), originalDimension));\n    }\n\n    // add global centroid\n    target.copyFrom(globalCentroid, 0, 0, originalDimension);\n\n    // add subspace offsets and re-scale\n    for (int m = 0; m < M; m++) {\n        int offset = subvectorSizesAndOffsets[m][1];\n        int size = subvectorSizesAndOffsets[m][0];\n        for (int j = 0; j < size; j++) {\n            float delta = (float) encoded.get(m) / (float) (clusterCount - 1);\n            target.copyFrom(codebooks[m], clusterCount * j, offset + j, size - j);\n            target.fmaInPlace(delta, offset + j, size - j);\n        }\n    }\n}\n```", "  ```\nvoid decodeCentered(ByteSequence<?> encoded, VectorFloat<?> target) {\n    // Precompute the centroid-subtracted versions of the codebooks\n    VectorFloat<?>[] centeredCodebooks = new VectorFloat<?>[M];\n    for (int m = 0; m < M; m++) {\n        // clone the codebook so that we don't overwrite it later\n        centeredCodebooks[m] = codebooks[m].copy();\n        // get the missing values from the global centroid\n        VectorUtil.addElements(centeredCodebooks[m], 0, globalCentroid, subvectorSizesAndOffsets[m][1], subvectorSizesAndOffsets[m][0]);\n    }\n\n    // decode the vector using the centered codebooks\n    for (int m = 0; m < M; m++) {\n        // decode the subvector\n        VectorFloat<?> subvector = vectorTypeSupport.createFloatVector(subvectorSizesAndOffsets[m][0]);\n        int index = encoded.get(m);\n        subvector.copyFrom(centeredCodebooks[m], index * subvectorSizesAndOffsets[m][0], 0, subvectorSizesAndOffsets[m][0]);\n\n        // set the subvector in the correct position in the target vector\n        VectorUtil.addElements(target, subvectorSizesAndOffsets[m][1], subvector, 0, subvectorSizesAndOffsets[m][0]);\n    }\n}\n```", "  ```\nvoid decodeCentered(ByteSequence<?> encoded, VectorFloat<?> target) {\n    // check that the target vector is the right length\n    if (target.length() != originalDimension) {\n        throw new IllegalArgumentException(\"Target vector length \" + target.length() + \" does not match PQ original dimension \" + originalDimension);\n    }\n\n    if (globalCentroid)\n    {\n        // translate the global centroid into a local centroid\n        var translation = vectorTypeSupport.createFloatVector(originalDimension);\n        sub(translation, target, globalCentroid);\n        sub(translation, translation, globalCentroid);\n\n        // merge the global centroid translation with any existing values read from the encoded vector\n        for (var subvector : subvectorSizesAndOffsets) {\n            var startOffset = subvector[1];\n            for (int i = startOffset; i < subvector[0] + startOffset; i++) {\n                translation[i] += encoded.get(i - startOffset);\n            }\n        }\n\n        // decode each subvector in parallel, adding the centroid\n        var decoded = vectorTypeSupport.createFloatVector(subvectorSizesAndOffsets[0][0]);\n        for (var subvector : subvectorSizesAndOffsets) {\n            var startOffset = subvector[1];\n            for (int i = startOffset; i < subvector[0] + startOffset; i++) {\n                decoded[i - startOffset] = codebooks[subvector[1]][decoded.get(i - startOffset)*subvector[0]];\n            }\n            sub(target, target, decoded);\n        }\n\n        // translate back from the local centroid\n        add(target, target, globalCentroid);\n    }\n    else\n    {\n        // decode each subvector in parallel\n        var decoded = vectorTypeSupport.createFloatVector(subvectorSizesAndOffsets[0][0]);\n        for (var subvector : subvectorSizesAndOffsets) {\n            var startOffset = subvector[1];\n            for (int i = startOffset; i < subvector[0] + startOffset; i++) {\n                decoded[i - startOffset] = codebooks[subvector[1]][decoded.get(i - startOffset)*subvector[0]];\n            }\n            sub(target, target, decoded);\n        }\n    }\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/vector/Matrix.java-invert": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/vector/Matrix.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.vector;\n\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\nimport static java.lang.Math.abs;\n\n/**\n * Matrix object where each row is a VectorFloat; this makes multiplication of a matrix by a vector\n * a series of efficient dot products.\n */\npublic class Matrix {\n    private static final VectorTypeSupport vts = VectorizationProvider.getInstance().getVectorTypeSupport();\n\n    VectorFloat<?>[] data;\n\n    public Matrix(int m, int n) {\n        this(m, n, true);\n    }\n\n    public Matrix(int m, int n, boolean allocateZeroed) {\n        data = new VectorFloat[m];\n        if (allocateZeroed) {\n            for (int i = 0; i < m; i++) {\n                data[i] = vts.createFloatVector(n);\n            }\n        }\n    }\n\n    public float get(int i, int j) {\n        return data[i].get(j);\n    }\n\n    public void set(int i, int j, float value) {\n        data[i].set(j, value);\n    }\n\n    public boolean isIsomorphicWith(Matrix other) {\n        return data.length == other.data.length && data[0].length() == other.data[0].length();\n    }\n\n    public String toString() {\n        StringBuilder sb = new StringBuilder();\n        for (VectorFloat<?> row : data) {\n            sb.append(row.toString());\n            sb.append(\"\\n\");\n        }\n        return sb.toString();\n    }\n\n    /**\n     * Inverts a square matrix using gaussian elimination.\n     * @return The inverse of the matrix.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public void addTo(int i, int j, float delta) {\n        data[i].set(j, data[i].get(j) + delta);\n    }\n\n    public void addInPlace(Matrix other) {\n        if (!this.isIsomorphicWith(other)) {\n            throw new IllegalArgumentException(\"matrix dimensions differ for \" + this + \"!=\" + other);\n        }\n\n        for (int i = 0; i < this.data.length; i++) {\n            VectorUtil.addInPlace(this.data[i], other.data[i]);\n        }\n    }\n\n    public VectorFloat<?> multiply(VectorFloat<?> v) {\n        if (data.length == 0) {\n            throw new IllegalArgumentException(\"Cannot multiply empty matrix\");\n        }\n        if (v.length() == 0) {\n            throw new IllegalArgumentException(\"Cannot multiply empty vector\");\n        }\n\n        var result = vts.createFloatVector(data.length);\n        for (int i = 0; i < data.length; i++) {\n            result.set(i, VectorUtil.dotProduct(data[i], v));\n        }\n        return result;\n    }\n\n    public static Matrix outerProduct(VectorFloat<?> a, VectorFloat<?> b) {\n        var result = new Matrix(a.length(), b.length(), false);\n\n        for (int i = 0; i < a.length(); i++) {\n            var rowI = b.copy();\n            VectorUtil.scale(rowI, a.get(i));\n            result.data[i] = rowI;\n        }\n\n        return result;\n    }\n\n    public void scale(float multiplier) {\n        for (var row : data) {\n            VectorUtil.scale(row, multiplier);\n        }\n    }\n\n    public boolean equals(Object obj) {\n        if (!(obj instanceof Matrix)) {\n            return false;\n        }\n\n        var other = (Matrix) obj;\n        if (data.length != other.data.length) {\n            return false;\n        }\n        for (int i = 0; i < data.length; i++) {\n            if (!data[i].equals(other.data[i])) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    public static Matrix from(float[][] values) {\n        var result = new Matrix(values.length, values[0].length, false);\n        for (int i = 0; i < values.length; i++) {\n            result.data[i] = vts.createFloatVector(values[i]);\n        }\n        return result;\n    }\n}\n\n```\n# Function Signature: public Matrix invert() {\n# Natural Language Annotations: /**\n     * Inverts a square matrix using gaussian elimination.\n     * @return The inverse of the matrix.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic Matrix invert() {\n    if (data.length == 0) {\n        throw new IllegalArgumentException(\"Cannot invert an empty matrix\");\n    }\n    if (data[0].length() != data.length) {\n        throw new IllegalArgumentException(\"Cannot invert a non-square matrix\");\n    }\n\n    var result = new Matrix(data.length, data.length, false);\n\n    var tempVector = vts.createFloatVector(data.length);\n\n    for (int i = 0; i < data.length; i++) {\n        var rowI = data[i].copy();\n        for (int j = 0; j < i; j++) {\n            tempVector = rowI.scale(-result.data[j].get(i) / rowI.get(i));\n            rowI.addInPlace(tempVector);\n        }\n        result.data[i] = rowI;\n    }\n\n    var scalar = 1 / rowI.get(i);\n    result.scale(scalar);\n\n    return result;\n}\n```", "  ```\npublic Matrix invert() {\n    if (!isSquare()) {\n        throw new IllegalArgumentException(\"matrix must be square\");\n    }\n\n    int n = data[0].length();\n\n    // create a copy of the matrix\n    Matrix result = new Matrix(n, n);\n    for (int i = 0; i < n; i++) {\n        result.data[i] = data[i].copy();\n    }\n\n    // perform gaussian elimination\n    for (int i = 0; i < n; i++) {\n        // find pivot row\n        int pivotRow = -1;\n        float pivotValue = Float.MIN_VALUE;\n        for (int j = i; j < n; j++) {\n            if (abs(result.data[j].get(i)) > pivotValue) {\n                pivotRow = j;\n                pivotValue = abs(result.data[j].get(i));\n            }\n        }\n\n        // swap rows if necessary\n        if (pivotRow != -1 && pivotRow != i) {\n            // swap rows i and pivotRow\n            VectorFloat<?> tmp = result.data[i];\n            result.data[i] = result.data[pivotRow];\n            result.data[pivotRow] = tmp;\n        }\n\n        // if there is no pivot element, the matrix is singular\n        if (abs(result.data[i].get(i)) == 0) {\n            throw new IllegalArgumentException(\"matrix is singular\");\n        }\n\n        // normalize row i\n        float scale = 1.0f / result.data[i].get(i);\n        result.scale(i, scale);\n\n        // subtract multiple of row i from other rows\n        for (int j = 0; j < n; j++) {\n            if (j != i) {\n                float multiplier = -result.data[j].get(i);\n                result.addTo(j, i, multiplier);\n            }\n        }\n    }\n\n    return result;\n}\n```", "  ```\npublic Matrix invert() {\n    if (data.length == 0 || data[0].length() == 0) {\n        throw new IllegalArgumentException(\"Cannot invert empty matrix\");\n    }\n    if (!isSquare()) {\n        throw new IllegalArgumentException(\"Matrix must be square to invert\");\n    }\n    Matrix result = this.duplicate();\n    result.invertInPlace();\n    return result;\n}\n\npublic void invertInPlace() {\n    if(data.length == 0 || data[0].length() == 0) {\n        throw new IllegalArgumentException(\"Cannot invert empty matrix\");\n    }\n    if(!isSquare()) {\n        throw new IllegalArgumentException(\"Matrix must be square to invert\");\n    }\n    int n = data.length;\n    int[] index = new int[n];\n    for(int i = 0; i < n; i++) index[i] = i;\n    float[] c = new float[n];\n    float[] d = new float[n];\n    float[] vv = new float[n];\n    // forward elimination\n    for(int i = 0; i < n-1; i++) {\n        Matrix.swapRows(data, i, i, index);\n        float ii = 1.0f/data[i].get(i);\n        for(int j = i+1; j < n; j++) {\n            data[j].set(i, data[j].get(i)*ii);\n        }\n    }\n    // back substitution\n    for(int i = n-1; i >= 0; i--) {\n        float s = 0f;\n        for(int j = i+1; j < n; j++) {\n            s = s + data[j].get(i)*c[j];\n        }\n        c[i] = -s*vv[i];\n    }\n    // create result matrix\n    for(int i = 0; i < n; i++) {\n        for(int j = 0; j < n; j++) {\n            if(i == j) {\n                d[i] = vv[i];\n            } else {\n                d[i] = c[j];\n            }\n        }\n    }\n    this.data = Matrix.from(d).data;\n}\n\npublic static void swapRows(VectorFloat<?>[] data, int row1, int row2, int[] index) {\n    Matrix.swapVectors(data, row1, row2, index);\n    int temp = index[row1];\n    index[row1] = index[row2];\n    index[row2] = temp;\n}\n\npublic static void swapVectors(VectorFloat<?>[] data, int vec1, int vec2, int[] index) {\n    VectorFloat<?> temp = data[vec1];\n    data[vec1] = data[vec2];\n    data[vec2] = temp;\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/vector/VectorUtil.java-cosine": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/vector/VectorUtil.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.vector;\n\nimport io.github.jbellis.jvector.vector.types.ByteSequence;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\n\nimport java.util.List;\n\n/** Utilities for computations with numeric arrays */\npublic final class VectorUtil {\n\n  private static final VectorUtilSupport impl =\n      VectorizationProvider.getInstance().getVectorUtilSupport();\n\n  private VectorUtil() {}\n\n  /**\n   * Returns the vector dot product of the two vectors.\n   *\n   * @throws IllegalArgumentException if the vectors' dimensions differ.\n   */\n\n\n\n\n\n\n\n\n\n  public static float dotProduct(VectorFloat<?> a, int aoffset, VectorFloat<?> b, int boffset, int length) {\n    //This check impacts FLOPS\n    /*if ( length > Math.min(a.length - aoffset, b.length - boffset) ) {\n      throw new IllegalArgumentException(\"length must be less than the vectors remaining space at the given offsets: a(\" +\n              (a.length - aoffset) + \"), b(\" + (b.length - boffset) + \"), length(\" + length + \")\");\n    }*/\n    float r = impl.dotProduct(a, aoffset, b, boffset, length);\n    assert Float.isFinite(r) : String.format(\"dotProduct(%s, %s) = %s\", a, b, r);\n    return r;\n  }\n\n  /**\n   * Returns the cosine similarity between the two vectors.\n   *\n   * @throws IllegalArgumentException if the vectors' dimensions differ.\n   */\n\n\n\n\n\n\n\n\n\n  /**\n   * Returns the sum of squared differences of the two vectors.\n   *\n   * @throws IllegalArgumentException if the vectors' dimensions differ.\n   */\n  public static float squareL2Distance(VectorFloat<?> a, VectorFloat<?> b) {\n    if (a.length() != b.length()) {\n      throw new IllegalArgumentException(\"vector dimensions differ: \" + a.length() + \"!=\" + b.length());\n    }\n    float r = impl.squareDistance(a, b);\n    assert Float.isFinite(r) : String.format(\"squareDistance(%s, %s) = %s\", a, b, r);\n    return r;\n  }\n\n  /**\n   * Returns the sum of squared differences of the two vectors, or subvectors, of the given length.\n   */\n  public static float squareL2Distance(VectorFloat<?> a, int aoffset, VectorFloat<?> b, int boffset, int length) {\n    float r = impl.squareDistance(a, aoffset, b, boffset, length);\n    assert Float.isFinite(r);\n    return r;\n  }\n\n  /**\n   * Modifies the argument to be unit length, dividing by its l2-norm. IllegalArgumentException is\n   * thrown for zero vectors.\n   *\n   * @param v the vector to normalize\n   */\n\n\n\n\n\n\n\n\n\n  public static VectorFloat<?> sum(List<VectorFloat<?>> vectors) {\n    if (vectors.isEmpty()) {\n      throw new IllegalArgumentException(\"Input list cannot be empty\");\n    }\n\n    return impl.sum(vectors);\n  }\n\n  public static float sum(VectorFloat<?> vector) {\n    return impl.sum(vector);\n  }\n\n  public static void scale(VectorFloat<?> vector, float multiplier) {\n    impl.scale(vector, multiplier);\n  }\n\n  public static void addInPlace(VectorFloat<?> v1, VectorFloat<?> v2) {\n    impl.addInPlace(v1, v2);\n  }\n\n  public static void subInPlace(VectorFloat<?> v1, VectorFloat<?> v2) {\n    impl.subInPlace(v1, v2);\n  }\n\n  public static VectorFloat<?> sub(VectorFloat<?> lhs, VectorFloat<?> rhs) {\n    return impl.sub(lhs, rhs);\n  }\n\n  public static VectorFloat<?> sub(VectorFloat<?> a, int aOffset, VectorFloat<?> b, int bOffset, int length) {\n    return impl.sub(a, aOffset, b, bOffset, length);\n  }\n\n  public static float assembleAndSum(VectorFloat<?> data, int dataBase, ByteSequence<?> dataOffsets) {\n    return impl.assembleAndSum(data, dataBase, dataOffsets);\n  }\n\n  public static void bulkShuffleQuantizedSimilarity(ByteSequence<?> shuffles, int codebookCount, ByteSequence<?> quantizedPartials, float delta, float minDistance, VectorFloat<?> results, VectorSimilarityFunction vsf) {\n    impl.bulkShuffleQuantizedSimilarity(shuffles, codebookCount, quantizedPartials, delta, minDistance, vsf, results);\n  }\n\n  public static void bulkShuffleQuantizedSimilarityCosine(ByteSequence<?> shuffles, int codebookCount,\n                                                          ByteSequence<?> quantizedPartialSums, float sumDelta, float minDistance,\n                                                          ByteSequence<?> quantizedPartialMagnitudes, float magnitudeDelta, float minMagnitude,\n                                                          float queryMagnitudeSquared, VectorFloat<?> results) {\n    impl.bulkShuffleQuantizedSimilarityCosine(shuffles, codebookCount, quantizedPartialSums, sumDelta, minDistance, quantizedPartialMagnitudes, magnitudeDelta, minMagnitude, queryMagnitudeSquared, results);\n  }\n\n  public static int hammingDistance(long[] v1, long[] v2) {\n    return impl.hammingDistance(v1, v2);\n  }\n\n  public static void calculatePartialSums(VectorFloat<?> codebook, int codebookIndex, int size, int clusterCount, VectorFloat<?> query, int offset, VectorSimilarityFunction vsf, VectorFloat<?> partialSums, VectorFloat<?> partialBestDistances) {\n    impl.calculatePartialSums(codebook, codebookIndex, size, clusterCount, query, offset, vsf, partialSums, partialBestDistances);\n  }\n\n  public static void calculatePartialSums(VectorFloat<?> codebook, int codebookIndex, int size, int clusterCount, VectorFloat<?> query, int offset, VectorSimilarityFunction vsf, VectorFloat<?> partialSums) {\n    impl.calculatePartialSums(codebook, codebookIndex, size, clusterCount, query, offset, vsf, partialSums);\n  }\n\n  public static void quantizePartials(float delta, VectorFloat<?> partials, VectorFloat<?> partialBase, ByteSequence<?> quantizedPartials) {\n    impl.quantizePartials(delta, partials, partialBase, quantizedPartials);\n  }\n\n  /**\n   * Calculates the maximum value in the vector.\n   * @param v vector\n   * @return the maximum value, or -Float.MAX_VALUE if the vector is empty\n   */\n  public static float max(VectorFloat<?> v) {\n    return impl.max(v);\n  }\n\n  /**\n   * Calculates the minimum value in the vector.\n   * @param v vector\n   * @return the minimum value, or Float.MAX_VALUE if the vector is empty\n   */\n  public static float min(VectorFloat<?> v) {\n    return impl.min(v);\n  }\n}\n\n```\n# Function Signature: public static float cosine(VectorFloat<?> a, VectorFloat<?> b) {\n# Natural Language Annotations: /**\n   * Returns the cosine similarity between the two vectors.\n   *\n   * @throws IllegalArgumentException if the vectors' dimensions differ.\n   */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static float cosine(VectorFloat<?> a, VectorFloat<?> b) {\n    if (a.length() != b.length()) {\n      throw new IllegalArgumentException(\"vector dimensions differ: \" + a.length() + \"!=\" + b.length());\n    }\n    float r = impl.cosine(a, b);\n    assert Float.isFinite(r) : String.format(\"cosine(%s, %s) = %s\", a, b, r);\n    return r;\n  }\n```", "  ```\npublic static float cosine(VectorFloat<?> a, VectorFloat<?> b) {\n    if (a.length() != b.length()) {\n      throw new IllegalArgumentException(\"vector dimensions differ: \" + a.length() + \"!=\" + b.length());\n    }\n    float r = impl.cosine(a, b);\n    assert Float.isFinite(r) : String.format(\"cosine(%s, %s) = %s\", a, b, r);\n    return r;\n  }\n```", "  ```\npublic static float cosine(VectorFloat<?> a, VectorFloat<?> b) {\n  if (a.length() != b.length()) {\n    throw new IllegalArgumentException(\"vector dimensions differ: \" + a.length() + \"!=\" + b.length());\n  }\n  float r = impl.dotProduct(a, b) / (impl.l2Norm(a) * impl.l2Norm(b));\n  assert Float.isFinite(r) : String.format(\"cosine(%s, %s) = %s\", a, b, r);\n  return r;\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/GraphSearcher.java-search": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/GraphSearcher.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.annotations.Experimental;\nimport io.github.jbellis.jvector.graph.similarity.ScoreFunction;\nimport io.github.jbellis.jvector.graph.similarity.SearchScoreProvider;\nimport io.github.jbellis.jvector.util.Bits;\nimport io.github.jbellis.jvector.util.BoundedLongHeap;\nimport io.github.jbellis.jvector.util.GrowableLongHeap;\nimport io.github.jbellis.jvector.util.SparseBits;\nimport io.github.jbellis.jvector.vector.VectorSimilarityFunction;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport org.agrona.collections.Int2ObjectHashMap;\nimport org.agrona.collections.IntHashSet;\n\nimport java.io.Closeable;\nimport java.io.IOException;\n\n\n/**\n * Searches a graph to find nearest neighbors to a query vector. For more background on the\n * search algorithm, see {@link GraphIndex}.\n */\npublic class GraphSearcher implements Closeable {\n    private final GraphIndex.View view;\n\n    // Scratch data structures that are used in each {@link #searchInternal} call. These can be expensive\n    // to allocate, so they're cleared and reused across calls.\n    private final NodeQueue candidates;\n    private final NodeQueue approximateResults;\n    private final NodeQueue rerankedResults;\n    private final IntHashSet visited;\n    private final NodesUnsorted evictedResults;\n\n    // Search parameters that we save here for use by resume()\n    private Bits acceptOrds;\n    private SearchScoreProvider scoreProvider;\n    private CachingReranker cachingReranker;\n\n    /**\n     * Creates a new graph searcher from the given GraphIndex\n     */\n    public GraphSearcher(GraphIndex graph) {\n        this(graph.getView());\n    }\n\n    private GraphSearcher(GraphIndex.View view) {\n        this.view = view;\n        this.candidates = new NodeQueue(new GrowableLongHeap(100), NodeQueue.Order.MAX_HEAP);\n        this.evictedResults = new NodesUnsorted(100);\n        this.approximateResults = new NodeQueue(new BoundedLongHeap(100), NodeQueue.Order.MIN_HEAP);\n        this.rerankedResults = new NodeQueue(new BoundedLongHeap(100), NodeQueue.Order.MIN_HEAP);\n        this.visited = new IntHashSet();\n    }\n\n    private void initializeScoreProvider(SearchScoreProvider scoreProvider) {\n        this.scoreProvider = scoreProvider;\n        if (scoreProvider.reranker() == null) {\n            cachingReranker = null;\n            return;\n        }\n\n        cachingReranker = new CachingReranker(scoreProvider);\n    }\n\n    public GraphIndex.View getView() {\n        return view;\n    }\n\n    /**\n     * Convenience function for simple one-off searches.  It is caller's responsibility to make sure that it\n     * is the unique owner of the vectors instance passed in here.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Call GraphSearcher constructor instead\n     */\n    @Deprecated\n    public static class Builder {\n        private final GraphIndex.View view;\n\n        public Builder(GraphIndex.View view) {\n            this.view = view;\n        }\n\n        public Builder withConcurrentUpdates() {\n            return this;\n        }\n\n        public GraphSearcher build() {\n            return new GraphSearcher(view);\n        }\n    }\n\n    /**\n     * @param scoreProvider   provides functions to return the similarity of a given node to the query vector\n     * @param topK            the number of results to look for. With threshold=0, the search will continue until at least\n     *                        `topK` results have been found, or until the entire graph has been searched.\n     * @param rerankK         the number of (approximately-scored) results to rerank before returning the best `topK`.\n     * @param threshold       the minimum similarity (0..1) to accept; 0 will accept everything. May be used\n     *                        with a large topK to find (approximately) all nodes above the given threshold.\n     *                        If threshold > 0 then the search will stop when it is probabilistically unlikely\n     *                        to find more nodes above the threshold, even if `topK` results have not yet been found.\n     * @param rerankFloor     (Experimental!) Candidates whose approximate similarity is at least this value\n     *                        will be reranked with the exact score (which requires loading a high-res vector from disk)\n     *                        and included in the final results.  (Potentially leaving fewer than topK entries\n     *                        in the results.)  Other candidates will be discarded, but will be potentially\n     *                        resurfaced if `resume` is called.  This is intended for use when combining results\n     *                        from multiple indexes.\n     * @param acceptOrds      a Bits instance indicating which nodes are acceptable results.\n     *                        If {@link Bits#ALL}, all nodes are acceptable.\n     *                        It is caller's responsibility to ensure that there are enough acceptable nodes\n     *                        that we don't search the entire graph trying to satisfy topK.\n     * @return a SearchResult containing the topK results and the number of nodes visited during the search.\n     */\n    @Experimental\n    public SearchResult search(SearchScoreProvider scoreProvider,\n                               int topK,\n                               int rerankK,\n                               float threshold,\n                               float rerankFloor,\n                               Bits acceptOrds) {\n        return searchInternal(scoreProvider, topK, rerankK, threshold, rerankFloor, view.entryNode(), acceptOrds);\n    }\n\n    /**\n     * @param scoreProvider   provides functions to return the similarity of a given node to the query vector\n     * @param topK            the number of results to look for. With threshold=0, the search will continue until at least\n     *                        `topK` results have been found, or until the entire graph has been searched.\n     * @param threshold       the minimum similarity (0..1) to accept; 0 will accept everything. May be used\n     *                        with a large topK to find (approximately) all nodes above the given threshold.\n     *                        If threshold > 0 then the search will stop when it is probabilistically unlikely\n     *                        to find more nodes above the threshold, even if `topK` results have not yet been found.\n     * @param acceptOrds      a Bits instance indicating which nodes are acceptable results.\n     *                        If {@link Bits#ALL}, all nodes are acceptable.\n     *                        It is caller's responsibility to ensure that there are enough acceptable nodes\n     *                        that we don't search the entire graph trying to satisfy topK.\n     * @return a SearchResult containing the topK results and the number of nodes visited during the search.\n     */\n    public SearchResult search(SearchScoreProvider scoreProvider,\n                               int topK,\n                               float threshold,\n                               Bits acceptOrds) {\n        return search(scoreProvider, topK, topK, threshold, 0.0f, acceptOrds);\n    }\n\n\n    /**\n     * @param scoreProvider   provides functions to return the similarity of a given node to the query vector\n     * @param topK            the number of results to look for. With threshold=0, the search will continue until at least\n     *                        `topK` results have been found, or until the entire graph has been searched.\n     * @param acceptOrds      a Bits instance indicating which nodes are acceptable results.\n     *                        If {@link Bits#ALL}, all nodes are acceptable.\n     *                        It is caller's responsibility to ensure that there are enough acceptable nodes\n     *                        that we don't search the entire graph trying to satisfy topK.\n     * @return a SearchResult containing the topK results and the number of nodes visited during the search.\n     */\n    public SearchResult search(SearchScoreProvider scoreProvider,\n                               int topK,\n                               Bits acceptOrds)\n    {\n        return search(scoreProvider, topK, 0.0f, acceptOrds);\n    }\n\n    /**\n     * Set up the state for a new search and kick it off\n     */\n    SearchResult searchInternal(SearchScoreProvider scoreProvider,\n                                int topK,\n                                int rerankK,\n                                float threshold,\n                                float rerankFloor,\n                                int ep,\n                                Bits rawAcceptOrds)\n    {\n        if (rawAcceptOrds == null) {\n            throw new IllegalArgumentException(\"Use MatchAllBits to indicate that all ordinals are accepted, instead of null\");\n        }\n        if (rerankK < topK) {\n            throw new IllegalArgumentException(String.format(\"rerankK %d must be >= topK %d\", rerankK, topK));\n        }\n\n        // save search parameters for potential later resume\n        initializeScoreProvider(scoreProvider);\n        this.acceptOrds = Bits.intersectionOf(rawAcceptOrds, view.liveNodes());\n\n        // reset the scratch data structures\n        evictedResults.clear();\n        candidates.clear();\n        visited.clear();\n\n        // no entry point -> empty results\n        if (ep < 0) {\n            return new SearchResult(new SearchResult.NodeScore[0], 0, 0, Float.POSITIVE_INFINITY);\n        }\n\n        // kick off the actual search at the entry point\n        float score = scoreProvider.scoreFunction().similarityTo(ep);\n        visited.add(ep);\n        candidates.push(ep, score);\n        return resume(1, topK, rerankK, threshold, rerankFloor);\n    }\n\n    /**\n     * Resume the previous search where it left off and search for the best (new) `topK` neighbors.\n     * <p>\n     * SearchResult.visitedCount resets with each call to `search` or `resume`.\n     */\n    // Since Astra / Cassandra's usage drives the design decisions here, it's worth being explicit\n    // about how that works and why.\n    //\n    // Astra breaks logical indexes up across multiple physical OnDiskGraphIndex pieces, one per sstable.\n    // Each of these pieces is searched independently, and the results are combined.  To avoid doing\n    // more work than necessary, Astra assumes that each physical ODGI will contribute responses\n    // to the final result in proportion to its size, and only asks for that many results in the initial\n    // search.  If this assumption is incorrect, or if the rows found turn out to be deleted or overwritten\n    // by later requests (which will be in a different sstable), Astra wants a lightweight way to resume\n    // the search where it was left off to get more results.\n    //\n    // Because Astra uses a nonlinear overquerying strategy (i.e. rerankK will be larger in proportion to\n    // topK for small values of topK than for large), it's especially important to avoid reranking more\n    // results than necessary.  Thus, Astra will look at the worstApproximateInTopK value from the first\n    // ODGI, and use that as the rerankFloor for the next.  Thus, rerankFloor helps avoid believed-to-be-\n    // unnecessary work in the initial search, but if the caller needs to resume() then that belief was\n    // incorrect and is discarded, and there is no reason to pass a rerankFloor parameter to resume().\n    //\n    // Finally: resume() also drives the use of CachingReranker.\n    private SearchResult resume(int initialVisited, int topK, int rerankK, float threshold, float rerankFloor) {\n        try {\n            assert approximateResults.size() == 0; // should be cleared out by extractScores\n            assert rerankedResults.size() == 0; // should be cleared out by extractScores\n            approximateResults.setMaxSize(rerankK);\n            rerankedResults.setMaxSize(topK);\n\n            int numVisited = initialVisited;\n            // A bound that holds the minimum similarity to the query vector that a candidate vector must\n            // have to be considered -- will be set to the lowest score in the results queue once the queue is full.\n            var minAcceptedSimilarity = Float.NEGATIVE_INFINITY;\n            // track scores to predict when we are done with threshold queries\n            var scoreTracker = threshold > 0 ? new ScoreTracker.TwoPhaseTracker(threshold) : ScoreTracker.NO_OP;\n            VectorFloat<?> similarities = null;\n\n            // add evicted results from the last call back to the candidates\n            var previouslyEvicted = evictedResults.size() > 0 ? new SparseBits() : Bits.NONE;\n            evictedResults.foreach((node, score) -> {\n                candidates.push(node, score);\n                ((SparseBits) previouslyEvicted).set(node);\n            });\n            evictedResults.clear();\n\n            // the main search loop\n            while (candidates.size() > 0) {\n                // we're done when we have K results and the best candidate is worse than the worst result so far\n                float topCandidateScore = candidates.topScore();\n                if (topCandidateScore < minAcceptedSimilarity) {\n                    break;\n                }\n                // when querying by threshold, also stop when we are probabilistically unlikely to find more qualifying results\n                if (scoreTracker.shouldStop()) {\n                    break;\n                }\n\n                // process the top candidate\n                int topCandidateNode = candidates.pop();\n                if (acceptOrds.get(topCandidateNode) && topCandidateScore >= threshold) {\n                    addTopCandidate(topCandidateNode, topCandidateScore, rerankK);\n\n                    // update minAcceptedSimilarity if we've found K results\n                    if (approximateResults.size() >= rerankK) {\n                        minAcceptedSimilarity = approximateResults.topScore();\n                    }\n                }\n\n                // if this candidate came from evictedResults, we don't need to evaluate its neighbors again\n                if (previouslyEvicted.get(topCandidateNode)) {\n                    continue;\n                }\n\n                // score the neighbors of the top candidate and add them to the queue\n                var scoreFunction = scoreProvider.scoreFunction();\n                var useEdgeLoading = scoreFunction.supportsEdgeLoadingSimilarity();\n                if (useEdgeLoading) {\n                    similarities = scoreFunction.edgeLoadingSimilarityTo(topCandidateNode);\n                }\n\n                var it = view.getNeighborsIterator(topCandidateNode);\n                for (int i = 0; i < it.size(); i++) {\n                    var friendOrd = it.nextInt();\n                    if (!visited.add(friendOrd)) {\n                        continue;\n                    }\n                    numVisited++;\n\n                    float friendSimilarity = useEdgeLoading\n                            ? similarities.get(i)\n                            : scoreFunction.similarityTo(friendOrd);\n                    scoreTracker.track(friendSimilarity);\n                    candidates.push(friendOrd, friendSimilarity);\n                }\n            }\n\n            // rerank results\n            assert approximateResults.size() <= rerankK;\n            NodeQueue popFromQueue;\n            float worstApproximateInTopK;\n            int reranked;\n            if (cachingReranker == null) {\n                // save the worst candidates in evictedResults for potential resume()\n                while (approximateResults.size() > topK) {\n                    var nScore = approximateResults.topScore();\n                    var n = approximateResults.pop();\n                    evictedResults.add(n, nScore);\n                }\n\n                reranked = 0;\n                worstApproximateInTopK = Float.POSITIVE_INFINITY;\n                popFromQueue = approximateResults;\n            } else {\n                int oldReranked = cachingReranker.getRerankCalls();\n                worstApproximateInTopK = approximateResults.rerank(topK, cachingReranker, rerankFloor, rerankedResults, evictedResults);\n                reranked = cachingReranker.getRerankCalls() - oldReranked;\n                approximateResults.clear();\n                popFromQueue = rerankedResults;\n            }\n            // pop the top K results from the results queue, which has the worst candidates at the top\n            assert popFromQueue.size() <= topK;\n            var nodes = new SearchResult.NodeScore[popFromQueue.size()];\n            for (int i = nodes.length - 1; i >= 0; i--) {\n                var nScore = popFromQueue.topScore();\n                var n = popFromQueue.pop();\n                nodes[i] = new SearchResult.NodeScore(n, nScore);\n            }\n            // that should be everything\n            assert popFromQueue.size() == 0;\n\n            return new SearchResult(nodes, numVisited, reranked, worstApproximateInTopK);\n        } catch (Throwable t) {\n            // clear scratch structures if terminated via throwable, as they may not have been drained\n            approximateResults.clear();\n            rerankedResults.clear();\n            throw t;\n        }\n    }\n\n    @SuppressWarnings(\"StatementWithEmptyBody\")\n    private void addTopCandidate(int topCandidateNode, float topCandidateScore, int rerankK) {\n        // add the new node to the results queue, and any evicted node to evictedResults in case we resume later\n        // (push() can't tell us what node was evicted when the queue was already full, so we examine that manually)\n        if (approximateResults.size() < rerankK) {\n            approximateResults.push(topCandidateNode, topCandidateScore);\n        } else if (topCandidateScore > approximateResults.topScore()) {\n            int evictedNode = approximateResults.topNode();\n            float evictedScore = approximateResults.topScore();\n            evictedResults.add(evictedNode, evictedScore);\n            approximateResults.push(topCandidateNode, topCandidateScore);\n        } else {\n            // score is exactly equal to the worst candidate in our results, so we don't bother\n            // changing the results queue.  (We still want to check its neighbors to see if one of them\n            // is better.)\n        }\n    }\n\n    /**\n     * Experimental!\n     * <p>\n     * Resume the previous search where it left off and search for the best `additionalK` neighbors.\n     * It is NOT valid to call this method before calling\n     * `search`, but `resume` may be called as many times as desired once the search is initialized.\n     * <p>\n     * SearchResult.visitedCount resets with each call to `search` or `resume`.\n     */\n    @Experimental\n    public SearchResult resume(int additionalK, int rerankK) {\n        return resume(0, additionalK, rerankK, 0.0f, 0.0f);\n    }\n\n    @Override\n    public void close() throws IOException {\n        view.close();\n    }\n\n    private static class CachingReranker implements ScoreFunction.ExactScoreFunction {\n        // this cache never gets cleared out (until a new search reinitializes it),\n        // but we expect resume() to be called at most a few times so it's fine\n        private final Int2ObjectHashMap<Float> cachedScores;\n        private final SearchScoreProvider scoreProvider;\n        private int rerankCalls;\n\n        public CachingReranker(SearchScoreProvider scoreProvider) {\n            this.scoreProvider = scoreProvider;\n            cachedScores = new Int2ObjectHashMap<>();\n            rerankCalls = 0;\n        }\n\n        @Override\n        public float similarityTo(int node2) {\n            if (cachedScores.containsKey(node2)) {\n                return cachedScores.get(node2);\n            }\n            rerankCalls++;\n            float score = scoreProvider.reranker().similarityTo(node2);\n            cachedScores.put(node2, Float.valueOf(score));\n            return score;\n        }\n\n        public int getRerankCalls() {\n            return rerankCalls;\n        }\n    }\n}\n\n```\n# Function Signature: public static SearchResult search(VectorFloat<?> queryVector, int topK, RandomAccessVectorValues vectors, VectorSimilarityFunction similarityFunction, GraphIndex graph, Bits acceptOrds) {\n# Natural Language Annotations: /**\n     * Convenience function for simple one-off searches.  It is caller's responsibility to make sure that it\n     * is the unique owner of the vectors instance passed in here.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static SearchResult search(VectorFloat<?> queryVector, int topK, RandomAccessVectorValues vectors, VectorSimilarityFunction similarityFunction, GraphIndex graph, Bits acceptOrds) {\n    SearchScoreProvider scoreProvider = new SearchScoreProvider(queryVector, vectors, similarityFunction);\n    return new GraphSearcher(graph).search(scoreProvider, topK, 0.0f, acceptOrds);\n}\n```", "  ```\nSearchResult search(VectorFloat<?> queryVector, int topK, RandomAccessVectorValues vectors, VectorSimilarityFunction similarityFunction, GraphIndex graph, Bits acceptOrds) {\n    // initialize the GraphSearcher\n    final GraphSearcher searcher = new GraphSearcher(graph);\n\n    // create the SearchScoreProvider from the query vector, vectors, and similarityFunction\n    final SearchScoreProvider scoreProvider = SearchScoreProvider.query(queryVector, vectors, similarityFunction);\n\n    // perform the search\n    final SearchResult result = searcher.search(scoreProvider, topK, 0.0f, acceptOrds);\n\n    // close the GraphSearcher\n    searcher.close();\n\n    return result;\n}\n```", "  ```\npublic static SearchResult search(VectorFloat<?> queryVector, int topK, RandomAccessVectorValues vectors, VectorSimilarityFunction similarityFunction, GraphIndex graph, Bits acceptOrds) {\n    // wrap vectors with a nicer API for us\n    RandomAccessVectorValuesAdapter adapter = new RandomAccessVectorValuesAdapter(vectors);\n\n    // get a searcher from the graph\n    GraphSearcher searcher = graph.getSearcher();\n\n    // we'll communicate our blacklist of ordinals to the searcher via a ScoreProvider\n    ScoreProvider scoreProvider = new ScoreProvider(queryVector, similarityFunction, adapter);\n\n    // evaluate the size of the vectors dataset\n    int n = vectors.length();\n\n    // allocate scratch data structures\n    ArrayList<SearchResult.NodeScore> scores = new ArrayList<>();\n    IntHashSet visited = new IntHashSet();\n\n    // initialize the search location to the entry node\n    int ep = graph.entryNode();\n    float epSimilarity = similarityFunction.similarityTo(queryVector, adapter.getValues(ep));\n\n    // kick off the search\n    return searcher.search(scoreProvider, topK, acceptOrds);\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeQueue.java-nodesCopy": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeQueue.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.graph.similarity.ScoreFunction;\nimport io.github.jbellis.jvector.util.AbstractLongHeap;\nimport io.github.jbellis.jvector.util.BoundedLongHeap;\nimport io.github.jbellis.jvector.util.NumericUtils;\nimport org.agrona.collections.Int2ObjectHashMap;\n\nimport static java.lang.Math.min;\n\n/**\n * NodeQueue uses a {@link io.github.jbellis.jvector.util.AbstractLongHeap} to store lists of nodes in a graph,\n * represented as a node id with an associated score packed together as a sortable long, which is sorted\n * primarily by score. The queue {@link #push(int, float)} operation provides either fixed-size\n * or unbounded operations, depending on the implementation subclasses, and either maxheap or minheap behavior.\n */\npublic class NodeQueue {\n    public enum Order {\n        /** Smallest values at the top of the heap */\n        MIN_HEAP {\n            @Override\n            long apply(long v) {\n                return v;\n            }\n        },\n        /** Largest values at the top of the heap */\n        MAX_HEAP {\n            @Override\n            long apply(long v) {\n                // This cannot be just `-v` since Long.MIN_VALUE doesn't have a positive counterpart. It\n                // needs a function that returns MAX_VALUE for MIN_VALUE and vice-versa.\n                return -1 - v;\n            }\n        };\n\n        abstract long apply(long v);\n    }\n\n    private final AbstractLongHeap heap;\n    private final Order order;\n\n    public NodeQueue(AbstractLongHeap heap, Order order) {\n        this.heap = heap;\n        this.order = order;\n    }\n\n    /**\n     * @return the number of elements in the heap\n     */\n    public int size() {\n        return heap.size();\n    }\n\n    /**\n     * Adds a new graph node to the heap.  Will extend storage or replace the worst element\n     * depending on the type of heap it is.\n     *\n     * @param newNode  the node id\n     * @param newScore the relative similarity score to the node of the owner\n     *\n     * @return true if the new value was added.\n     */\n    public boolean push(int newNode, float newScore) {\n        return heap.push(encode(newNode, newScore));\n    }\n\n    /**\n     * Encodes the node ID and its similarity score as long.  If two scores are equals,\n     * the smaller node ID wins.\n     *\n     * <p>The most significant 32 bits represent the float score, encoded as a sortable int.\n     *\n     * <p>The less significant 32 bits represent the node ID.\n     *\n     * <p>The bits representing the node ID are complemented to guarantee the win for the smaller node\n     * ID.\n     *\n     * <p>The AND with 0xFFFFFFFFL (a long with first 32 bit as 1) is necessary to obtain a long that\n     * has\n     *\n     * <p>The most significant 32 bits to 0\n     *\n     * <p>The less significant 32 bits represent the node ID.\n     *\n     * @param node  the node ID\n     * @param score the node score\n     * @return the encoded score, node ID\n     */\n    private long encode(int node, float score) {\n        return order.apply(\n                (((long) NumericUtils.floatToSortableInt(score)) << 32) | (0xFFFFFFFFL & ~node));\n    }\n\n    private float decodeScore(long heapValue) {\n        return NumericUtils.sortableIntToFloat((int) (order.apply(heapValue) >> 32));\n    }\n\n    private int decodeNodeId(long heapValue) {\n        return (int) ~(order.apply(heapValue));\n    }\n\n    /** Removes the top element and returns its node id. */\n    public int pop() {\n        return decodeNodeId(heap.pop());\n    }\n\n    /** Returns a copy of the internal nodes array. Not sorted by score! */\n\n\n\n\n\n\n\n\n\n    /**\n     * Rerank results and return the worst approximate score that made it into the topK.\n     * The topK results will be placed into `reranked`, and the remainder into `unused`.\n     * <p>\n     * Only the best result or results whose approximate score is at least `rerankFloor` will be reranked.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /** Returns the top element's node id. */\n    public int topNode() {\n        return decodeNodeId(heap.top());\n    }\n\n    /**\n     * Returns the top element's node score. For the min heap this is the minimum score. For the max\n     * heap this is the maximum score.\n     */\n    public float topScore() {\n        return decodeScore(heap.top());\n    }\n\n    public void clear() {\n        heap.clear();\n    }\n\n    /**\n     * Set the max size of the underlying heap.  Only valid when NodeQueue was created with BoundedLongHeap.\n     */\n    public void setMaxSize(int maxSize) {\n        ((BoundedLongHeap) heap).setMaxSize(maxSize);\n    }\n\n    @Override\n    public String toString() {\n        return \"Nodes[\" + heap.size() + \"]\";\n    }\n\n    public void foreach(NodeConsumer consumer) {\n        for (int i = 0; i < heap.size(); i++) {\n            long heapValue = heap.get(i + 1);\n            consumer.accept(decodeNodeId(heapValue), decodeScore(heapValue));\n        }\n    }\n\n    @FunctionalInterface\n    public interface NodeConsumer {\n        void accept(int node, float score);\n    }\n}\n\n```\n# Function Signature: public int[] nodesCopy() {\n# Natural Language Annotations: /** Returns a copy of the internal nodes array. Not sorted by score! */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic int[] nodesCopy() {\n    int[] nodes = new int[heap.size()];\n    for (int i = 0; i < heap.size(); i++) {\n        long heapValue = heap.get(i + 1);\n        nodes[i] = decodeNodeId(heapValue);\n    }\n    return nodes;\n}\n```", "  ```\npublic int[] nodesCopy() {\n    int[] nodes = new int[heap.size()];\n    for (int i = 0; i < heap.size(); i++) {\n        long heapValue = heap.get(i + 1);\n        int node = decodeNodeId(heapValue);\n        nodes[i] = node;\n    }\n    return nodes;\n}\n```", "  ```\npublic int[] nodesCopy() {\n    int size = size();\n    int[] copy = new int[size];\n    for (int i = 0; i < size; i++) {\n        copy[i] = decodeNodeId(heap.get(i + 1));\n    }\n    return copy;\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeQueue.java-rerank": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeQueue.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.graph.similarity.ScoreFunction;\nimport io.github.jbellis.jvector.util.AbstractLongHeap;\nimport io.github.jbellis.jvector.util.BoundedLongHeap;\nimport io.github.jbellis.jvector.util.NumericUtils;\nimport org.agrona.collections.Int2ObjectHashMap;\n\nimport static java.lang.Math.min;\n\n/**\n * NodeQueue uses a {@link io.github.jbellis.jvector.util.AbstractLongHeap} to store lists of nodes in a graph,\n * represented as a node id with an associated score packed together as a sortable long, which is sorted\n * primarily by score. The queue {@link #push(int, float)} operation provides either fixed-size\n * or unbounded operations, depending on the implementation subclasses, and either maxheap or minheap behavior.\n */\npublic class NodeQueue {\n    public enum Order {\n        /** Smallest values at the top of the heap */\n        MIN_HEAP {\n            @Override\n            long apply(long v) {\n                return v;\n            }\n        },\n        /** Largest values at the top of the heap */\n        MAX_HEAP {\n            @Override\n            long apply(long v) {\n                // This cannot be just `-v` since Long.MIN_VALUE doesn't have a positive counterpart. It\n                // needs a function that returns MAX_VALUE for MIN_VALUE and vice-versa.\n                return -1 - v;\n            }\n        };\n\n        abstract long apply(long v);\n    }\n\n    private final AbstractLongHeap heap;\n    private final Order order;\n\n    public NodeQueue(AbstractLongHeap heap, Order order) {\n        this.heap = heap;\n        this.order = order;\n    }\n\n    /**\n     * @return the number of elements in the heap\n     */\n    public int size() {\n        return heap.size();\n    }\n\n    /**\n     * Adds a new graph node to the heap.  Will extend storage or replace the worst element\n     * depending on the type of heap it is.\n     *\n     * @param newNode  the node id\n     * @param newScore the relative similarity score to the node of the owner\n     *\n     * @return true if the new value was added.\n     */\n    public boolean push(int newNode, float newScore) {\n        return heap.push(encode(newNode, newScore));\n    }\n\n    /**\n     * Encodes the node ID and its similarity score as long.  If two scores are equals,\n     * the smaller node ID wins.\n     *\n     * <p>The most significant 32 bits represent the float score, encoded as a sortable int.\n     *\n     * <p>The less significant 32 bits represent the node ID.\n     *\n     * <p>The bits representing the node ID are complemented to guarantee the win for the smaller node\n     * ID.\n     *\n     * <p>The AND with 0xFFFFFFFFL (a long with first 32 bit as 1) is necessary to obtain a long that\n     * has\n     *\n     * <p>The most significant 32 bits to 0\n     *\n     * <p>The less significant 32 bits represent the node ID.\n     *\n     * @param node  the node ID\n     * @param score the node score\n     * @return the encoded score, node ID\n     */\n    private long encode(int node, float score) {\n        return order.apply(\n                (((long) NumericUtils.floatToSortableInt(score)) << 32) | (0xFFFFFFFFL & ~node));\n    }\n\n    private float decodeScore(long heapValue) {\n        return NumericUtils.sortableIntToFloat((int) (order.apply(heapValue) >> 32));\n    }\n\n    private int decodeNodeId(long heapValue) {\n        return (int) ~(order.apply(heapValue));\n    }\n\n    /** Removes the top element and returns its node id. */\n    public int pop() {\n        return decodeNodeId(heap.pop());\n    }\n\n    /** Returns a copy of the internal nodes array. Not sorted by score! */\n\n\n\n\n\n\n\n\n\n    /**\n     * Rerank results and return the worst approximate score that made it into the topK.\n     * The topK results will be placed into `reranked`, and the remainder into `unused`.\n     * <p>\n     * Only the best result or results whose approximate score is at least `rerankFloor` will be reranked.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /** Returns the top element's node id. */\n    public int topNode() {\n        return decodeNodeId(heap.top());\n    }\n\n    /**\n     * Returns the top element's node score. For the min heap this is the minimum score. For the max\n     * heap this is the maximum score.\n     */\n    public float topScore() {\n        return decodeScore(heap.top());\n    }\n\n    public void clear() {\n        heap.clear();\n    }\n\n    /**\n     * Set the max size of the underlying heap.  Only valid when NodeQueue was created with BoundedLongHeap.\n     */\n    public void setMaxSize(int maxSize) {\n        ((BoundedLongHeap) heap).setMaxSize(maxSize);\n    }\n\n    @Override\n    public String toString() {\n        return \"Nodes[\" + heap.size() + \"]\";\n    }\n\n    public void foreach(NodeConsumer consumer) {\n        for (int i = 0; i < heap.size(); i++) {\n            long heapValue = heap.get(i + 1);\n            consumer.accept(decodeNodeId(heapValue), decodeScore(heapValue));\n        }\n    }\n\n    @FunctionalInterface\n    public interface NodeConsumer {\n        void accept(int node, float score);\n    }\n}\n\n```\n# Function Signature: public float rerank(int topK, ScoreFunction.ExactScoreFunction reranker, float rerankFloor, NodeQueue reranked, NodesUnsorted unused) {\n# Natural Language Annotations: /**\n     * Rerank results and return the worst approximate score that made it into the topK.\n     * The topK results will be placed into `reranked`, and the remainder into `unused`.\n     * <p>\n     * Only the best result or results whose approximate score is at least `rerankFloor` will be reranked.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic float rerank(int topK, ScoreFunction.ExactScoreFunction reranker, float rerankFloor, NodeQueue reranked, NodesUnsorted unused) {\n    float worstScore = Float.MAX_VALUE;\n    int numReranked = 0;\n    Int2ObjectHashMap<Float> unrankedScores = new Int2ObjectHashMap<>();\n    \n    while (unused.size() > 0 && numReranked < topK) {\n        int nodeId = unused.pop();\n        float score = reranker.score(nodeId);\n        if (score >= rerankFloor) {\n            reranked.push(nodeId, score);\n            numReranked++;\n        } else {\n            unrankedScores.put(nodeId, score);\n        }\n    }\n    \n    while (unrankedScores.size() > 0 && numReranked < topK) {\n        int nodeId = unrankedScores.keySet().iterator().next();\n        float score = unrankedScores.get(nodeId);\n        if (score > worstScore) {\n            worstScore = score;\n        }\n        unrankedScores.remove(nodeId);\n        unused.push(nodeId);\n    }\n    \n    return worstScore;\n}\n```", "  ```\npublic float rerank(int topK, ScoreFunction.ExactScoreFunction reranker, float rerankFloor, NodeQueue reranked, NodesUnsorted unused) {\n    float[] worstApproxScores = new float[heap.size()];\n    int count = 0;\n\n    while (heap.size() > 0) {\n        int nodeId = pop();\n        float score = topScore();\n        if (score >= rerankFloor) {\n            float approxScore = reranker.apply(nodeId);\n            if (approxScore < worstApproxScores[count]) {\n                worstApproxScores[count] = approxScore;\n            }\n            count++;\n        }\n        if (count == topK) {\n            break;\n        }\n    }\n\n    clear();\n    for (int i = 0; i < count; i++) {\n        push(nodeId, worstApproxScores[i]);\n    }\n\n    return worstApproxScores[0];\n}\n```", "  ```\npublic float rerank(int topK, ScoreFunction.ExactScoreFunction reranker, float rerankFloor, NodeQueue reranked, NodesUnsorted unused) {\n    float worstScore = 0.0f;\n    Int2ObjectHashMap<Float> newReranked = new Int2ObjectHashMap<>();\n    Int2ObjectHashMap<Float> newUnused = new Int2ObjectHashMap<>();\n\n    // Iterate through top K elements in reranked\n    for (int i = 0; i < min(topK, reranked.size()); i++) {\n        int node = reranked.pop();\n        float score = reranker.score(node);\n        if (score > rerankFloor) {\n            newReranked.put(node, score);\n        } else {\n            newUnused.put(node, score);\n            worstScore = min(worstScore, score);\n        }\n    }\n\n    // Combine newReranked and newUnused into a single hash map\n    newReranked.putAll(newUnused);\n\n    // Create new NodeQueue and NodesUnsorted objects from the modified hash maps\n    NodeQueue newRerankedNodeQueue = new NodeQueue(newReranked, NodeQueue.Order.MAX_HEAP);\n    NodesUnsorted newUnusedNodes = new NodesUnsorted(newUnused);\n\n    // Set the top K results into the reranked and unused nodes\n    for (int i = 0; i < topK; i++) {\n        if (newRerankedNodeQueue.size() == 0) {\n            break;\n        }\n        int node = newRerankedNodeQueue.pop();\n        float score = reranker.score(node);\n        if (score > rerankFloor) {\n            reranked.push(node, score);\n        } else {\n            unused.push(node, score);\n            worstScore = min(worstScore, score);\n        }\n    }\n\n    return worstScore;\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-merge": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.util.ArrayUtil;\nimport io.github.jbellis.jvector.util.Bits;\nimport io.github.jbellis.jvector.util.RamUsageEstimator;\nimport org.agrona.collections.IntHashSet;\n\nimport java.util.Arrays;\n\nimport static java.lang.Math.min;\n\n/**\n * NodeArray encodes nodeids and their scores relative to some other element \n * (a query vector, or another graph node) as a pair of growable arrays. \n * Nodes are arranged in the sorted order of their scores in descending order,\n * i.e. the most-similar nodes are first.\n */\npublic class NodeArray {\n    public static final NodeArray EMPTY = new NodeArray(0);\n\n    private int size;\n    private float[] scores;\n    private int[] nodes;\n\n    public NodeArray(int initialSize) {\n        nodes = new int[initialSize];\n        scores = new float[initialSize];\n    }\n\n    // this idiosyncratic constructor exists for the benefit of subclass ConcurrentNeighborMap\n    protected NodeArray(NodeArray nodeArray) {\n        this.size = nodeArray.size();\n        this.nodes = nodeArray.nodes;\n        this.scores = nodeArray.scores;\n    }\n\n    /** always creates a new NodeArray to return, even when a1 or a2 is empty */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Add a new node to the NodeArray. The new node must be worse than all previously stored\n     * nodes.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Add a new node to the NodeArray into a correct sort position according to its score.\n     * Duplicate node + score pairs are ignored.\n     *\n     * @return the insertion point of the new node, or -1 if it already existed\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private boolean duplicateExistsNear(int insertionPoint, int newNode, float newScore) {\n        // Check to the left\n        for (int i = insertionPoint - 1; i >= 0 && scores[i] == newScore; i--) {\n            if (nodes[i] == newNode) {\n                return true;\n            }\n        }\n\n        // Check to the right\n        for (int i = insertionPoint; i < size && scores[i] == newScore; i++) {\n            if (nodes[i] == newNode) {\n                return true;\n            }\n        }\n\n        return false;\n    }\n\n    /**\n     * Retains only the elements in the current NodeArray whose corresponding index\n     * is set in the given BitSet.\n     * <p>\n     * This modifies the array in place, preserving the relative order of the elements retained.\n     * <p>\n     *\n     * @param selected A BitSet where the bit at index i is set if the i-th element should be retained.\n     *                 (Thus, the elements of selected represent positions in the NodeArray, NOT node ids.)\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public NodeArray copy() {\n        return copy(size);\n    }\n\n    public NodeArray copy(int newSize) {\n        if (size > newSize) {\n            throw new IllegalArgumentException(\"Cannot copy to a smaller size\");\n        }\n\n        NodeArray copy = new NodeArray(newSize);\n        copy.size = size;\n        System.arraycopy(nodes, 0, copy.nodes, 0, size);\n        System.arraycopy(scores, 0, copy.scores, 0, size);\n        return copy;\n    }\n\n    protected final void growArrays() {\n        nodes = ArrayUtil.grow(nodes);\n        scores = ArrayUtil.growExact(scores, nodes.length);\n    }\n\n    public int size() {\n        return size;\n    }\n\n    public void clear() {\n        size = 0;\n    }\n\n    public void removeLast() {\n        size--;\n    }\n\n    public void removeIndex(int idx) {\n        System.arraycopy(nodes, idx + 1, nodes, idx, size - idx - 1);\n        System.arraycopy(scores, idx + 1, scores, idx, size - idx - 1);\n        size--;\n    }\n\n    @Override\n    public String toString() {\n        var sb = new StringBuilder(\"NodeArray(\");\n        sb.append(size).append(\"/\").append(nodes.length).append(\") [\");\n        for (int i = 0; i < size; i++) {\n            sb.append(\"(\").append(nodes[i]).append(\",\").append(scores[i]).append(\")\").append(\", \");\n        }\n        sb.append(\"]\");\n        return sb.toString();\n    }\n\n    protected final int descSortFindRightMostInsertionPoint(float newScore) {\n        int start = 0;\n        int end = size - 1;\n        while (start <= end) {\n            int mid = (start + end) / 2;\n            if (scores[mid] < newScore) end = mid - 1;\n            else start = mid + 1;\n        }\n        return start;\n    }\n\n    public static long ramBytesUsed(int size) {\n        int REF_BYTES = RamUsageEstimator.NUM_BYTES_OBJECT_REF;\n        int AH_BYTES = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER;\n        int OH_BYTES = RamUsageEstimator.NUM_BYTES_OBJECT_HEADER;\n\n        return OH_BYTES\n                + Integer.BYTES // size field\n                + REF_BYTES + AH_BYTES // nodes array\n                + REF_BYTES + AH_BYTES // scores array\n                + (long) size * (Integer.BYTES + Float.BYTES); // array contents\n    }\n\n    /**\n     * Caution! This performs a linear scan.\n     */\n    @VisibleForTesting\n    boolean contains(int node) {\n        for (int i = 0; i < size; i++) {\n            if (this.nodes[i] == node) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    @VisibleForTesting\n    int[] copyDenseNodes() {\n        return Arrays.copyOf(nodes, size);\n    }\n\n    @VisibleForTesting\n    float[] copyDenseScores() {\n        return Arrays.copyOf(scores, size);\n    }\n\n    /**\n     * Insert a new node, without growing the array.  If the array is full, drop the worst existing node to make room.\n     * (Even if the worst existing one is better than newNode!)\n     */\n    protected int insertOrReplaceWorst(int newNode, float newScore) {\n        size = min(size, nodes.length - 1);\n        return insertSorted(newNode, newScore);\n    }\n\n    public float getScore(int i) {\n        return scores[i];\n    }\n\n    public int getNode(int i) {\n        return nodes[i];\n    }\n\n    protected int getArrayLength() {\n        return nodes.length;\n    }\n}\n\n```\n# Function Signature: static NodeArray merge(NodeArray a1, NodeArray a2) {\n# Natural Language Annotations: /** always creates a new NodeArray to return, even when a1 or a2 is empty */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\nimport io.github.jbellis.jvector.graph.NodeArray;\n\npublic class NodeArrayUtils {\n    public static NodeArray merge(NodeArray a1, NodeArray a2) {\n        NodeArray mergedArray = new NodeArray(a1.size() + a2.size());\n        mergedArray.size = a1.size() + a2.size();\n        \n        for (int i = 0; i < a1.size(); i++) {\n            mergedArray.nodes[i] = a1.nodes[i];\n            mergedArray.scores[i] = a1.scores[i];\n        }\n        \n        for (int i = 0; i < a2.size(); i++) {\n            mergedArray.nodes[a1.size() + i] = a1.nodes[i];\n            mergedArray.scores[a1.size() + i] = a1.scores[i];\n        }\n        \n        return mergedArray;\n    }\n}\n```", "  ```\npublic static NodeArray merge(NodeArray a1, NodeArray a2) {\n    if (a1.isEmpty()) {\n        return a2.copy();\n    }\n    if (a2.isEmpty()) {\n        return a1.copy();\n    }\n\n    NodeArray merged = new NodeArray(a1.size() + a2.size());\n    merged.scores = Arrays.copyOf(a1.scores, a1.scores.length + a2.scores.length);\n    merged.nodes = Arrays.copyOf(a1.nodes, a1.nodes.length + a2.nodes.length);\n    merged.size = a1.size() + a2.size();\n\n    for (int i = 0; i < a2.size(); i++) {\n        merged.insertSorted(a2.nodes[i], a2.scores[i]);\n    }\n\n    return merged;\n}\n```", "  ```\npublic static NodeArray merge(NodeArray a1, NodeArray a2) {\n    if (a1.isEmpty() && a2.isEmpty()) {\n        return new NodeArray();\n    } else if (a1.isEmpty()) {\n        return a2.copy();\n    } else if (a2.isEmpty()) {\n        return a1.copy();\n    }\n\n    NodeArray result = new NodeArray();\n    int i1 = 0;\n    int i2 = 0;\n    while (i1 < a1.size() && i2 < a2.size()) {\n        float s1 = a1.getScore(i1);\n        float s2 = a2.getScore(i2);\n        if (s1 <= s2) {\n            result.add(a1.getNode(i1++), s1);\n        } else {\n            result.add(a2.getNode(i2++), s2);\n        }\n    }\n\n    // add any remaining elements from a1 or a2\n    while (i1 < a1.size()) {\n        result.add(a1.getNode(i1++), a1.getScore(i1));\n    }\n    while (i2 < a2.size()) {\n        result.add(a2.getNode(i2++), a2.getScore(i2));\n    }\n\n    return result;\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-addInOrder": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.util.ArrayUtil;\nimport io.github.jbellis.jvector.util.Bits;\nimport io.github.jbellis.jvector.util.RamUsageEstimator;\nimport org.agrona.collections.IntHashSet;\n\nimport java.util.Arrays;\n\nimport static java.lang.Math.min;\n\n/**\n * NodeArray encodes nodeids and their scores relative to some other element \n * (a query vector, or another graph node) as a pair of growable arrays. \n * Nodes are arranged in the sorted order of their scores in descending order,\n * i.e. the most-similar nodes are first.\n */\npublic class NodeArray {\n    public static final NodeArray EMPTY = new NodeArray(0);\n\n    private int size;\n    private float[] scores;\n    private int[] nodes;\n\n    public NodeArray(int initialSize) {\n        nodes = new int[initialSize];\n        scores = new float[initialSize];\n    }\n\n    // this idiosyncratic constructor exists for the benefit of subclass ConcurrentNeighborMap\n    protected NodeArray(NodeArray nodeArray) {\n        this.size = nodeArray.size();\n        this.nodes = nodeArray.nodes;\n        this.scores = nodeArray.scores;\n    }\n\n    /** always creates a new NodeArray to return, even when a1 or a2 is empty */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Add a new node to the NodeArray. The new node must be worse than all previously stored\n     * nodes.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Add a new node to the NodeArray into a correct sort position according to its score.\n     * Duplicate node + score pairs are ignored.\n     *\n     * @return the insertion point of the new node, or -1 if it already existed\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private boolean duplicateExistsNear(int insertionPoint, int newNode, float newScore) {\n        // Check to the left\n        for (int i = insertionPoint - 1; i >= 0 && scores[i] == newScore; i--) {\n            if (nodes[i] == newNode) {\n                return true;\n            }\n        }\n\n        // Check to the right\n        for (int i = insertionPoint; i < size && scores[i] == newScore; i++) {\n            if (nodes[i] == newNode) {\n                return true;\n            }\n        }\n\n        return false;\n    }\n\n    /**\n     * Retains only the elements in the current NodeArray whose corresponding index\n     * is set in the given BitSet.\n     * <p>\n     * This modifies the array in place, preserving the relative order of the elements retained.\n     * <p>\n     *\n     * @param selected A BitSet where the bit at index i is set if the i-th element should be retained.\n     *                 (Thus, the elements of selected represent positions in the NodeArray, NOT node ids.)\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public NodeArray copy() {\n        return copy(size);\n    }\n\n    public NodeArray copy(int newSize) {\n        if (size > newSize) {\n            throw new IllegalArgumentException(\"Cannot copy to a smaller size\");\n        }\n\n        NodeArray copy = new NodeArray(newSize);\n        copy.size = size;\n        System.arraycopy(nodes, 0, copy.nodes, 0, size);\n        System.arraycopy(scores, 0, copy.scores, 0, size);\n        return copy;\n    }\n\n    protected final void growArrays() {\n        nodes = ArrayUtil.grow(nodes);\n        scores = ArrayUtil.growExact(scores, nodes.length);\n    }\n\n    public int size() {\n        return size;\n    }\n\n    public void clear() {\n        size = 0;\n    }\n\n    public void removeLast() {\n        size--;\n    }\n\n    public void removeIndex(int idx) {\n        System.arraycopy(nodes, idx + 1, nodes, idx, size - idx - 1);\n        System.arraycopy(scores, idx + 1, scores, idx, size - idx - 1);\n        size--;\n    }\n\n    @Override\n    public String toString() {\n        var sb = new StringBuilder(\"NodeArray(\");\n        sb.append(size).append(\"/\").append(nodes.length).append(\") [\");\n        for (int i = 0; i < size; i++) {\n            sb.append(\"(\").append(nodes[i]).append(\",\").append(scores[i]).append(\")\").append(\", \");\n        }\n        sb.append(\"]\");\n        return sb.toString();\n    }\n\n    protected final int descSortFindRightMostInsertionPoint(float newScore) {\n        int start = 0;\n        int end = size - 1;\n        while (start <= end) {\n            int mid = (start + end) / 2;\n            if (scores[mid] < newScore) end = mid - 1;\n            else start = mid + 1;\n        }\n        return start;\n    }\n\n    public static long ramBytesUsed(int size) {\n        int REF_BYTES = RamUsageEstimator.NUM_BYTES_OBJECT_REF;\n        int AH_BYTES = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER;\n        int OH_BYTES = RamUsageEstimator.NUM_BYTES_OBJECT_HEADER;\n\n        return OH_BYTES\n                + Integer.BYTES // size field\n                + REF_BYTES + AH_BYTES // nodes array\n                + REF_BYTES + AH_BYTES // scores array\n                + (long) size * (Integer.BYTES + Float.BYTES); // array contents\n    }\n\n    /**\n     * Caution! This performs a linear scan.\n     */\n    @VisibleForTesting\n    boolean contains(int node) {\n        for (int i = 0; i < size; i++) {\n            if (this.nodes[i] == node) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    @VisibleForTesting\n    int[] copyDenseNodes() {\n        return Arrays.copyOf(nodes, size);\n    }\n\n    @VisibleForTesting\n    float[] copyDenseScores() {\n        return Arrays.copyOf(scores, size);\n    }\n\n    /**\n     * Insert a new node, without growing the array.  If the array is full, drop the worst existing node to make room.\n     * (Even if the worst existing one is better than newNode!)\n     */\n    protected int insertOrReplaceWorst(int newNode, float newScore) {\n        size = min(size, nodes.length - 1);\n        return insertSorted(newNode, newScore);\n    }\n\n    public float getScore(int i) {\n        return scores[i];\n    }\n\n    public int getNode(int i) {\n        return nodes[i];\n    }\n\n    protected int getArrayLength() {\n        return nodes.length;\n    }\n}\n\n```\n# Function Signature: public void addInOrder(int newNode, float newScore) {\n# Natural Language Annotations: /**\n     * Add a new node to the NodeArray. The new node must be worse than all previously stored\n     * nodes.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic void addInOrder(int newNode, float newScore) {\n    assert newNode != -1;\n    assert !contains(newNode); \n\n    if (size == nodes.length) {\n        throw new IllegalArgumentException(\"Cannot add more nodes to the array, it is already full.\");\n    }\n\n    System.arraycopy(nodes, 0, nodes, 1, size);\n    System.arraycopy(scores, 0, scores, 1, size);\n    nodes[0] = newNode;\n    scores[0] = newScore;\n    size++;\n}\n```", "  ```\npublic void addInOrder(int newNode, float newScore) {\n    // Add the node to the end of the array\n    nodes[size] = newNode;\n    scores[size] = newScore;\n\n    // Move through the array until we find a score that is worse than the new score\n    // or we reach the beginning of the array\n    int insertionPoint = size - 1;\n    while (insertionPoint >= 0 && scores[insertionPoint] >= newScore) {\n        insertionPoint--;\n    }\n\n    // Swap the new node and score with the node at the insertion point\n    int oldNode = nodes[insertionPoint + 1];\n    float oldScore = scores[insertionPoint + 1];\n    nodes[insertionPoint + 1] = newNode;\n    scores[insertionPoint + 1] = newScore;\n    nodes[size] = oldNode;\n    scores[size] = oldScore;\n\n    // Increment the size of the array\n    size++;\n}\n```", "  ```\npublic void addInOrder(int newNode, float newScore) {\n    // find the correct insertion point in the sorted array\n    int insertionPoint = descSortFindRightMostInsertionPoint(newScore);\n\n    // make sure the new node is better than all already-stored nodes\n    for (int i = 0; i < score.length; i++) {\n        if (i != insertionPoint && scores[i] < newScore) {\n            throw new IllegalArgumentException(\"Cannot insert a new node that is not further from the reference than existing nodes.\");\n        }\n    }\n\n    // check for duplicates\n    if (duplicateExistsNear(insertionPoint, newNode, newScore)) {\n        throw new IllegalArgumentException(\"Duplicate node found at positon \" + insertionPoint + \": \" + newNode);\n    }\n\n    // insert into the correct position\n    if (insertionPoint == 0) {\n        nodes[0] = newNode;\n        scores[0] = newScore;\n        size = Math.min(nodes.length, size + 1);\n    } else {\n        for (int i = 0; i < size; i++) {\n            if (i < insertionPoint) {\n                nodes[i] = nodes[i + 1];\n                scores[i] = scores[i + 1];\n            } else if (i > insertionPoint) {\n                nodes[i + 1] = nodes[i];\n                scores[i + 1] = scores[i];\n            } else {\n                nodes[i] = newNode;\n                scores[i] = newScore;\n                size = Math.min(nodes.length, size + 1);\n            }\n        }\n    }\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-insertSorted": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.util.ArrayUtil;\nimport io.github.jbellis.jvector.util.Bits;\nimport io.github.jbellis.jvector.util.RamUsageEstimator;\nimport org.agrona.collections.IntHashSet;\n\nimport java.util.Arrays;\n\nimport static java.lang.Math.min;\n\n/**\n * NodeArray encodes nodeids and their scores relative to some other element \n * (a query vector, or another graph node) as a pair of growable arrays. \n * Nodes are arranged in the sorted order of their scores in descending order,\n * i.e. the most-similar nodes are first.\n */\npublic class NodeArray {\n    public static final NodeArray EMPTY = new NodeArray(0);\n\n    private int size;\n    private float[] scores;\n    private int[] nodes;\n\n    public NodeArray(int initialSize) {\n        nodes = new int[initialSize];\n        scores = new float[initialSize];\n    }\n\n    // this idiosyncratic constructor exists for the benefit of subclass ConcurrentNeighborMap\n    protected NodeArray(NodeArray nodeArray) {\n        this.size = nodeArray.size();\n        this.nodes = nodeArray.nodes;\n        this.scores = nodeArray.scores;\n    }\n\n    /** always creates a new NodeArray to return, even when a1 or a2 is empty */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Add a new node to the NodeArray. The new node must be worse than all previously stored\n     * nodes.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Add a new node to the NodeArray into a correct sort position according to its score.\n     * Duplicate node + score pairs are ignored.\n     *\n     * @return the insertion point of the new node, or -1 if it already existed\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private boolean duplicateExistsNear(int insertionPoint, int newNode, float newScore) {\n        // Check to the left\n        for (int i = insertionPoint - 1; i >= 0 && scores[i] == newScore; i--) {\n            if (nodes[i] == newNode) {\n                return true;\n            }\n        }\n\n        // Check to the right\n        for (int i = insertionPoint; i < size && scores[i] == newScore; i++) {\n            if (nodes[i] == newNode) {\n                return true;\n            }\n        }\n\n        return false;\n    }\n\n    /**\n     * Retains only the elements in the current NodeArray whose corresponding index\n     * is set in the given BitSet.\n     * <p>\n     * This modifies the array in place, preserving the relative order of the elements retained.\n     * <p>\n     *\n     * @param selected A BitSet where the bit at index i is set if the i-th element should be retained.\n     *                 (Thus, the elements of selected represent positions in the NodeArray, NOT node ids.)\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public NodeArray copy() {\n        return copy(size);\n    }\n\n    public NodeArray copy(int newSize) {\n        if (size > newSize) {\n            throw new IllegalArgumentException(\"Cannot copy to a smaller size\");\n        }\n\n        NodeArray copy = new NodeArray(newSize);\n        copy.size = size;\n        System.arraycopy(nodes, 0, copy.nodes, 0, size);\n        System.arraycopy(scores, 0, copy.scores, 0, size);\n        return copy;\n    }\n\n    protected final void growArrays() {\n        nodes = ArrayUtil.grow(nodes);\n        scores = ArrayUtil.growExact(scores, nodes.length);\n    }\n\n    public int size() {\n        return size;\n    }\n\n    public void clear() {\n        size = 0;\n    }\n\n    public void removeLast() {\n        size--;\n    }\n\n    public void removeIndex(int idx) {\n        System.arraycopy(nodes, idx + 1, nodes, idx, size - idx - 1);\n        System.arraycopy(scores, idx + 1, scores, idx, size - idx - 1);\n        size--;\n    }\n\n    @Override\n    public String toString() {\n        var sb = new StringBuilder(\"NodeArray(\");\n        sb.append(size).append(\"/\").append(nodes.length).append(\") [\");\n        for (int i = 0; i < size; i++) {\n            sb.append(\"(\").append(nodes[i]).append(\",\").append(scores[i]).append(\")\").append(\", \");\n        }\n        sb.append(\"]\");\n        return sb.toString();\n    }\n\n    protected final int descSortFindRightMostInsertionPoint(float newScore) {\n        int start = 0;\n        int end = size - 1;\n        while (start <= end) {\n            int mid = (start + end) / 2;\n            if (scores[mid] < newScore) end = mid - 1;\n            else start = mid + 1;\n        }\n        return start;\n    }\n\n    public static long ramBytesUsed(int size) {\n        int REF_BYTES = RamUsageEstimator.NUM_BYTES_OBJECT_REF;\n        int AH_BYTES = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER;\n        int OH_BYTES = RamUsageEstimator.NUM_BYTES_OBJECT_HEADER;\n\n        return OH_BYTES\n                + Integer.BYTES // size field\n                + REF_BYTES + AH_BYTES // nodes array\n                + REF_BYTES + AH_BYTES // scores array\n                + (long) size * (Integer.BYTES + Float.BYTES); // array contents\n    }\n\n    /**\n     * Caution! This performs a linear scan.\n     */\n    @VisibleForTesting\n    boolean contains(int node) {\n        for (int i = 0; i < size; i++) {\n            if (this.nodes[i] == node) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    @VisibleForTesting\n    int[] copyDenseNodes() {\n        return Arrays.copyOf(nodes, size);\n    }\n\n    @VisibleForTesting\n    float[] copyDenseScores() {\n        return Arrays.copyOf(scores, size);\n    }\n\n    /**\n     * Insert a new node, without growing the array.  If the array is full, drop the worst existing node to make room.\n     * (Even if the worst existing one is better than newNode!)\n     */\n    protected int insertOrReplaceWorst(int newNode, float newScore) {\n        size = min(size, nodes.length - 1);\n        return insertSorted(newNode, newScore);\n    }\n\n    public float getScore(int i) {\n        return scores[i];\n    }\n\n    public int getNode(int i) {\n        return nodes[i];\n    }\n\n    protected int getArrayLength() {\n        return nodes.length;\n    }\n}\n\n```\n# Function Signature: public int insertSorted(int newNode, float newScore) {\n# Natural Language Annotations: /**\n     * Add a new node to the NodeArray into a correct sort position according to its score.\n     * Duplicate node + score pairs are ignored.\n     *\n     * @return the insertion point of the new node, or -1 if it already existed\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic int insertSorted(int newNode, float newScore){\n        int insertionPoint = descSortFindRightMostInsertionPoint(newScore);\n        if (insertionPoint < size && scores[insertionPoint] == newScore && nodes[insertionPoint] == newNode) {\n            return -1;\n        }\n        if (size < nodes.length) {\n            if (insertionPoint < nodes.length) {\n                System.arraycopy(nodes, insertionPoint, nodes, insertionPoint + 1, size - insertionPoint);\n                System.arraycopy(scores, insertionPoint, scores, insertionPoint + 1, size - insertionPoint);\n            }\n            nodes[insertionPoint] = newNode;\n            scores[insertionPoint] = newScore;\n            size++;\n            return insertionPoint;\n        } else {\n            // out of space, drop the worst existing node\n            removeLast();\n            return insertSorted(newNode, newScore);\n        }\n    }\n```", "  ```\n    public int insertSorted(int newNode, float newScore) {\n        if (contains(newNode)) {\n            return -1; // already in the array\n        }\n\n        int insertionPoint = descSortFindRightMostInsertionPoint(newScore);\n        if (duplicateExistsNear(insertionPoint, newNode, newScore)) {\n            return -1; // already in the array\n        }\n\n        if (size == nodes.length) {\n            return -1; // no space left in the array\n        }\n\n        // Move the rest of the nodes over\n        int i = size - 1;\n        for (; i >= insertionPoint; i--) {\n            nodes[i + 1] = nodes[i];\n            scores[i + 1] = scores[i];\n        }\n\n        // Insert the new node\n        nodes[i + 1] = newNode;\n        scores[i + 1] = newScore;\n        size++;\n\n        return insertionPoint;\n    }\n```", "  ```\npublic int insertSorted(int newNode, float newScore) {\n    int ip = descSortFindRightMostInsertionPoint(newScore);\n    if (ip < size && newScore == scores[ip]) {\n        // Duplicate node + score pair\n        if (scores[ip] == newScore && nodes[ip] == newNode) {\n            // Already exists\n            return -1;\n        } else {\n            // Replace existing\n            nodes[ip] = newNode;\n            return ip;\n        }\n    } else {\n        // Not a duplicate\n        if (size == nodes.length || duplicateExistsNear(ip, newNode, newScore)) {\n            // Duplicate exists, or array is full\n            return -1;\n        } else {\n            // Insert new node\n            if (ip >= size) {\n                size = ip + 1;\n            } else {\n                int copyLen = size - ip;\n                System.arraycopy(nodes, ip, nodes, ip + 1, copyLen);\n                System.arraycopy(scores, ip, scores, ip + 1, copyLen);\n                size++;\n            }\n            nodes[ip] = newNode;\n            scores[ip] = newScore;\n            return ip;\n        }\n    }\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-retain": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.util.ArrayUtil;\nimport io.github.jbellis.jvector.util.Bits;\nimport io.github.jbellis.jvector.util.RamUsageEstimator;\nimport org.agrona.collections.IntHashSet;\n\nimport java.util.Arrays;\n\nimport static java.lang.Math.min;\n\n/**\n * NodeArray encodes nodeids and their scores relative to some other element \n * (a query vector, or another graph node) as a pair of growable arrays. \n * Nodes are arranged in the sorted order of their scores in descending order,\n * i.e. the most-similar nodes are first.\n */\npublic class NodeArray {\n    public static final NodeArray EMPTY = new NodeArray(0);\n\n    private int size;\n    private float[] scores;\n    private int[] nodes;\n\n    public NodeArray(int initialSize) {\n        nodes = new int[initialSize];\n        scores = new float[initialSize];\n    }\n\n    // this idiosyncratic constructor exists for the benefit of subclass ConcurrentNeighborMap\n    protected NodeArray(NodeArray nodeArray) {\n        this.size = nodeArray.size();\n        this.nodes = nodeArray.nodes;\n        this.scores = nodeArray.scores;\n    }\n\n    /** always creates a new NodeArray to return, even when a1 or a2 is empty */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Add a new node to the NodeArray. The new node must be worse than all previously stored\n     * nodes.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Add a new node to the NodeArray into a correct sort position according to its score.\n     * Duplicate node + score pairs are ignored.\n     *\n     * @return the insertion point of the new node, or -1 if it already existed\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private boolean duplicateExistsNear(int insertionPoint, int newNode, float newScore) {\n        // Check to the left\n        for (int i = insertionPoint - 1; i >= 0 && scores[i] == newScore; i--) {\n            if (nodes[i] == newNode) {\n                return true;\n            }\n        }\n\n        // Check to the right\n        for (int i = insertionPoint; i < size && scores[i] == newScore; i++) {\n            if (nodes[i] == newNode) {\n                return true;\n            }\n        }\n\n        return false;\n    }\n\n    /**\n     * Retains only the elements in the current NodeArray whose corresponding index\n     * is set in the given BitSet.\n     * <p>\n     * This modifies the array in place, preserving the relative order of the elements retained.\n     * <p>\n     *\n     * @param selected A BitSet where the bit at index i is set if the i-th element should be retained.\n     *                 (Thus, the elements of selected represent positions in the NodeArray, NOT node ids.)\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public NodeArray copy() {\n        return copy(size);\n    }\n\n    public NodeArray copy(int newSize) {\n        if (size > newSize) {\n            throw new IllegalArgumentException(\"Cannot copy to a smaller size\");\n        }\n\n        NodeArray copy = new NodeArray(newSize);\n        copy.size = size;\n        System.arraycopy(nodes, 0, copy.nodes, 0, size);\n        System.arraycopy(scores, 0, copy.scores, 0, size);\n        return copy;\n    }\n\n    protected final void growArrays() {\n        nodes = ArrayUtil.grow(nodes);\n        scores = ArrayUtil.growExact(scores, nodes.length);\n    }\n\n    public int size() {\n        return size;\n    }\n\n    public void clear() {\n        size = 0;\n    }\n\n    public void removeLast() {\n        size--;\n    }\n\n    public void removeIndex(int idx) {\n        System.arraycopy(nodes, idx + 1, nodes, idx, size - idx - 1);\n        System.arraycopy(scores, idx + 1, scores, idx, size - idx - 1);\n        size--;\n    }\n\n    @Override\n    public String toString() {\n        var sb = new StringBuilder(\"NodeArray(\");\n        sb.append(size).append(\"/\").append(nodes.length).append(\") [\");\n        for (int i = 0; i < size; i++) {\n            sb.append(\"(\").append(nodes[i]).append(\",\").append(scores[i]).append(\")\").append(\", \");\n        }\n        sb.append(\"]\");\n        return sb.toString();\n    }\n\n    protected final int descSortFindRightMostInsertionPoint(float newScore) {\n        int start = 0;\n        int end = size - 1;\n        while (start <= end) {\n            int mid = (start + end) / 2;\n            if (scores[mid] < newScore) end = mid - 1;\n            else start = mid + 1;\n        }\n        return start;\n    }\n\n    public static long ramBytesUsed(int size) {\n        int REF_BYTES = RamUsageEstimator.NUM_BYTES_OBJECT_REF;\n        int AH_BYTES = RamUsageEstimator.NUM_BYTES_ARRAY_HEADER;\n        int OH_BYTES = RamUsageEstimator.NUM_BYTES_OBJECT_HEADER;\n\n        return OH_BYTES\n                + Integer.BYTES // size field\n                + REF_BYTES + AH_BYTES // nodes array\n                + REF_BYTES + AH_BYTES // scores array\n                + (long) size * (Integer.BYTES + Float.BYTES); // array contents\n    }\n\n    /**\n     * Caution! This performs a linear scan.\n     */\n    @VisibleForTesting\n    boolean contains(int node) {\n        for (int i = 0; i < size; i++) {\n            if (this.nodes[i] == node) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    @VisibleForTesting\n    int[] copyDenseNodes() {\n        return Arrays.copyOf(nodes, size);\n    }\n\n    @VisibleForTesting\n    float[] copyDenseScores() {\n        return Arrays.copyOf(scores, size);\n    }\n\n    /**\n     * Insert a new node, without growing the array.  If the array is full, drop the worst existing node to make room.\n     * (Even if the worst existing one is better than newNode!)\n     */\n    protected int insertOrReplaceWorst(int newNode, float newScore) {\n        size = min(size, nodes.length - 1);\n        return insertSorted(newNode, newScore);\n    }\n\n    public float getScore(int i) {\n        return scores[i];\n    }\n\n    public int getNode(int i) {\n        return nodes[i];\n    }\n\n    protected int getArrayLength() {\n        return nodes.length;\n    }\n}\n\n```\n# Function Signature: public void retain(Bits selected) {\n# Natural Language Annotations: /**\n     * Retains only the elements in the current NodeArray whose corresponding index\n     * is set in the given BitSet.\n     * <p>\n     * This modifies the array in place, preserving the relative order of the elements retained.\n     * <p>\n     *\n     * @param selected A BitSet where the bit at index i is set if the i-th element should be retained.\n     *                 (Thus, the elements of selected represent positions in the NodeArray, NOT node ids.)\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic void retain(Bits selected) {\n    int newSize = selected.cardinality();\n    if (newSize == 0) {\n        clear();\n        return;\n    }\n    int newIndex = 0;\n    for (int i = 0; i < size; i++) {\n        if (selected.get(i)) {\n            nodes[newIndex] = nodes[i];\n            scores[newIndex] = scores[i];\n            newIndex++;\n        }\n    }\n    size = newSize;\n}\n```", "  ```\npublic void retain(Bits selected) {\n    int selectedSize = selected.getCount();\n    if (size > selectedSize) {\n        System.arraycopy(nodes, selectedSize, nodes, 0, size - selectedSize);\n        System.arraycopy(scores, selectedSize, scores, 0, size - selectedSize);\n    }\n    size = selectedSize;\n}\n```", "  ```\npublic void retain(Bits selected) {\n    int[] scratch = new int[selected.length()];\n    int newSize = 0;\n    for (int i = 0; i < selected.length(); i++) {\n        if (selected.get(i)) {\n            scratch[newSize++] = nodes[i];\n        }\n    }\n    for (int i = newSize; i < size; i++) {\n        System.arraycopy(nodes, i, nodes, i - newSize, size - i);\n    }\n    for (int i = 0; i < newSize; i++) {\n        nodes[i] = scratch[i];\n    }\n    size = newSize;\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodesUnsorted.java-add": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodesUnsorted.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.graph.NodeQueue.NodeConsumer;\nimport io.github.jbellis.jvector.util.ArrayUtil;\n\n/**\n * NodesUnsorted contains scored node ids in insertion order.\n */\npublic class NodesUnsorted {\n    protected int size;\n    float[] score;\n    int[] node;\n\n    public NodesUnsorted(int initialSize) {\n        node = new int[initialSize];\n        score = new float[initialSize];\n    }\n\n    /**\n     * Add a new node to the NodeArray. The new node must be worse than all previously stored\n     * nodes.\n     */\n\n\n\n\n\n\n\n\n\n    protected final void growArrays() {\n        node = ArrayUtil.grow(node);\n        score = ArrayUtil.growExact(score, node.length);\n    }\n\n    public int size() {\n        return size;\n    }\n\n    public void clear() {\n        size = 0;\n    }\n\n    public void foreach(NodeConsumer consumer) {\n        for (int i = 0; i < size; i++) {\n            consumer.accept(node[i], score[i]);\n        }\n    }\n\n    @Override\n    public String toString() {\n        return \"NodesUnsorted[\" + size + \"]\";\n    }\n}\n\n```\n# Function Signature: public void add(int newNode, float newScore) {\n# Natural Language Annotations: /**\n     * Add a new node to the NodeArray. The new node must be worse than all previously stored\n     * nodes.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic void add(int newNode, float newScore) {\n    if (newScore < worstScore()) {\n        throw new IllegalArgumentException(\"New node is not worse than all previously stored nodes\");\n    }\n    if (size == node.length) {\n        growArrays();\n    }\n    node[size] = newNode;\n    score[size] = newScore;\n    size++;\n}\n```", "  ```\npublic void add(int newNode, float newScore) {\n    if ((size + 1) >= node.length) growArrays();\n    node[size] = newNode;\n    score[size] = newScore;\n    size++;\n}\n```", "  ```\npublic void add(int newNode, float newScore) {\n    // Check that the new score is worse than all previously stored scores\n    for (int i = 0; i < size; i++) {\n        if (score[i] > newScore) {\n            // The new score is not worse, so don't add it\n            return;\n        }\n    }\n    // Add the new node and score to the arrays\n    if (size == node.length) {\n        growArrays();\n    }\n    node[size] = newNode;\n    score[size] = newScore;\n    size++;\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/RandomAccessVectorValues.java-rerankerFor": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/RandomAccessVectorValues.java:\n```\n/*\n * All changes to the original code are Copyright DataStax, Inc.\n *\n * Please see the included license file for details.\n */\n\n/*\n * Original license:\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements.  See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License.  You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.graph.similarity.ScoreFunction;\nimport io.github.jbellis.jvector.util.ExplicitThreadLocal;\nimport io.github.jbellis.jvector.vector.VectorSimilarityFunction;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\n\nimport java.util.function.Supplier;\nimport java.util.logging.Logger;\n\n/**\n * Provides random access to vectors by dense ordinal. This interface is used by graph-based\n * implementations of KNN search.\n */\npublic interface RandomAccessVectorValues {\n    Logger LOG = Logger.getLogger(RandomAccessVectorValues.class.getName());\n\n    /**\n     * Return the number of vector values.\n     * <p>\n     * All copies of a given RAVV should have the same size.  Typically this is achieved by either\n     * (1) implementing a threadsafe, un-shared RAVV, where `copy` returns `this`, or\n     * (2) implementing a fixed-size RAVV.\n     */\n    int size();\n\n    /** Return the dimension of the returned vector values */\n    int dimension();\n\n    /**\n     * Return the vector value indexed at the given ordinal.\n     *\n     * <p>For performance, implementations are free to re-use the same object across invocations.\n     * That is, you will get back the same VectorFloat&lt;?&gt;\n     * reference (for instance) for every requested ordinal. If you want to use those values across\n     * calls, you should make a copy.\n     *\n     * @param nodeId a valid ordinal, &ge; 0 and &lt; {@link #size()}.\n     */\n    VectorFloat<?> getVector(int nodeId);\n\n    @Deprecated\n    default VectorFloat<?> vectorValue(int targetOrd) {\n        return getVector(targetOrd);\n    }\n\n    /**\n     * Retrieve the vector associated with a given node, and store it in the destination vector at the given offset.\n     * @param node the node to retrieve\n     * @param destinationVector the vector to store the result in\n     * @param offset the offset in the destination vector to store the result\n     */\n    default void getVectorInto(int node, VectorFloat<?> destinationVector, int offset) {\n        destinationVector.copyFrom(getVector(node), 0, offset, dimension());\n    }\n\n    /**\n     * @return true iff the vector returned by `getVector` is shared.  A shared vector will\n     * only be valid until the next call to getVector overwrites it.\n     */\n    boolean isValueShared();\n\n    /**\n     * Creates a new copy of this {@link RandomAccessVectorValues}. This is helpful when you need to\n     * access different values at once, to avoid overwriting the underlying float vector returned by\n     * a shared {@link RandomAccessVectorValues#getVector}.\n     * <p>\n     * Un-shared implementations may simply return `this`.\n     */\n    RandomAccessVectorValues copy();\n\n    /**\n     * Returns a supplier of thread-local copies of the RAVV.\n     */\n    default Supplier<RandomAccessVectorValues> threadLocalSupplier() {\n        if (!isValueShared()) {\n            return () -> this;\n        }\n\n        if (this instanceof AutoCloseable) {\n            LOG.warning(\"RAVV is shared and implements AutoCloseable; threadLocalSupplier() may lead to leaks\");\n        }\n        var tl = ExplicitThreadLocal.withInitial(this::copy);\n        return tl::get;\n    }\n\n    /**\n     * Convenience method to create an ExactScoreFunction for reranking.  The resulting function is NOT thread-safe.\n     */\n\n\n\n\n\n\n\n\n\n\n\n}\n\n```\n# Function Signature: default ScoreFunction.ExactScoreFunction rerankerFor(VectorFloat<?> queryVector, VectorSimilarityFunction vsf) {\n# Natural Language Annotations: /**\n     * Convenience method to create an ExactScoreFunction for reranking.  The resulting function is NOT thread-safe.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\ndefault ScoreFunction.ExactScoreFunction rerankerFor(VectorFloat<?> queryVector, VectorSimilarityFunction vsf) {\n    return new ScoreFunction.ExactScoreFunction(queryVector, vsf, threadLocalSupplier());\n}\n```", "  ```\ndefault ScoreFunction.ExactScoreFunction rerankerFor(VectorFloat<?> queryVector, VectorSimilarityFunction vsf) {\n    var precomputed = vsf.precompute(queryVector, this);\n    ScoreFunction.ExactScoreFunction reranker = new ScoreFunction.ExactScoreFunction(precomputed);\n    return reranker;\n}\n```", "  ```\ndefault ScoreFunction.ExactScoreFunction rerankerFor(VectorFloat<?> queryVector, VectorSimilarityFunction vsf) {\n    ExplicitThreadLocal<Stack<VectorFloat<?>>> stack =\n        ExplicitThreadLocal.withInitial(() -> new Stack<>());\n    return new ExactScoreFunction(queryVector, vsf, stack);\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/ConcurrentNeighborMap.java-addNode": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/ConcurrentNeighborMap.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.graph.similarity.BuildScoreProvider;\nimport io.github.jbellis.jvector.graph.similarity.ScoreFunction;\nimport io.github.jbellis.jvector.util.BitSet;\nimport io.github.jbellis.jvector.util.Bits;\nimport io.github.jbellis.jvector.util.DenseIntMap;\nimport io.github.jbellis.jvector.util.DocIdSetIterator;\nimport io.github.jbellis.jvector.util.FixedBitSet;\n\nimport static java.lang.Math.min;\n\n/**\n * Encapsulates operations on a graph's neighbors.\n */\npublic class ConcurrentNeighborMap {\n    private final DenseIntMap<Neighbors> neighbors;\n\n    /** the diversity threshold; 1.0 is equivalent to HNSW; Vamana uses 1.2 or more */\n    private final float alpha;\n\n    /** used to compute diversity */\n    private final BuildScoreProvider scoreProvider;\n\n    /** the maximum number of neighbors desired per node */\n    public final int maxDegree;\n    /** the maximum number of neighbors a node can have temporarily during construction */\n    public final int maxOverflowDegree;\n\n    public ConcurrentNeighborMap(BuildScoreProvider scoreProvider, int maxDegree, int maxOverflowDegree, float alpha) {\n        this.alpha = alpha;\n        this.scoreProvider = scoreProvider;\n        this.maxDegree = maxDegree;\n        this.maxOverflowDegree = maxOverflowDegree;\n        neighbors = new DenseIntMap<>(1024);\n    }\n\n    public void insertOne(int fromId, int toId, float score, float overflow) {\n        while (true) {\n            var old = neighbors.get(fromId);\n            var next = old.insert(toId, score, overflow, this);\n            if (next == old || neighbors.compareAndPut(fromId, old, next)) {\n                break;\n            }\n        }\n    }\n\n    public void insertNotDiverse(int fromId, int toId, float score) {\n        while (true) {\n            var old = neighbors.get(fromId);\n            var next = old.insertNotDiverse(toId, score, this);\n            if (next == old || neighbors.compareAndPut(fromId, old, next)) {\n                break;\n            }\n        }\n    }\n\n    /**\n     * @return the fraction of short edges, i.e., neighbors within alpha=1.0\n     */\n    public double enforceDegree(int nodeId) {\n        var old = neighbors.get(nodeId);\n        if (old == null) {\n            return Double.NaN;\n        }\n\n        while (true) {\n            old = neighbors.get(nodeId);\n            var nwse = old.enforceDegree(this);\n            if (nwse.neighbors == old || neighbors.compareAndPut(nodeId, old, nwse.neighbors)) {\n                return nwse.shortEdges;\n            }\n        }\n    }\n\n    public void replaceDeletedNeighbors(int nodeId, BitSet toDelete, NodeArray candidates) {\n        while (true) {\n            var old = neighbors.get(nodeId);\n            var next = old.replaceDeletedNeighbors(toDelete, candidates, this);\n            if (next == old || neighbors.compareAndPut(nodeId, old, next)) {\n                break;\n            }\n        }\n    }\n\n    public Neighbors insertDiverse(int nodeId, NodeArray natural) {\n        while (true) {\n            var old = neighbors.get(nodeId);\n            var next = old.insertDiverse(natural, this);\n            if (next == old || neighbors.compareAndPut(nodeId, old, next)) {\n                return next;\n            }\n        }\n    }\n\n    public Neighbors get(int node) {\n        return neighbors.get(node);\n    }\n\n    public int size() {\n        return neighbors.size();\n    }\n\n    /**\n     * Only for internal use and by Builder loading a saved graph\n     */\n\n\n\n\n\n\n\n    public void addNode(int nodeId) {\n        addNode(nodeId, new NodeArray(0));\n    }\n\n    public NodesIterator nodesIterator() {\n        return neighbors.keysIterator();\n    }\n\n    public Neighbors remove(int node) {\n        return neighbors.remove(node);\n    }\n\n    public boolean contains(int nodeId) {\n        return neighbors.containsKey(nodeId);\n    }\n\n    public void forEach(DenseIntMap.IntBiConsumer<Neighbors> consumer) {\n        neighbors.forEach(consumer);\n    }\n\n    int nodeArrayLength() {\n        // one extra so that insert() against a full NodeArray doesn't invoke growArrays()\n        return maxOverflowDegree + 1;\n    }\n\n    /**\n     * Add a link from every node in the NodeArray to the target toId.\n     * If overflow is > 1.0, allow the number of neighbors to exceed maxConnections temporarily.\n     */\n    public void backlink(NodeArray nodes, int toId, float overflow) {\n        for (int i = 0; i < nodes.size(); i++) {\n            int nbr = nodes.getNode(i);\n            float nbrScore = nodes.getScore(i);\n            insertOne(nbr, toId, nbrScore, overflow);\n        }\n    }\n\n    /**\n     * A concurrent set of neighbors that encapsulates diversity/pruning mechanics.\n     * <p>\n     * Nothing is modified in place; all mutating methods return a new instance.  These methods\n     * are private and should only be exposed through the parent ConcurrentNeighborMap, which\n     * performs the appropriate CAS dance.\n     * <p>\n     * CNM is passed as an explicit parameter to these methods (instead of making this a non-static\n     * inner class) to avoid the overhead on the heap of the CNM$this reference.  Similarly,\n     * Neighbors extends NodeArray instead of composing with it to avoid the overhead of an extra\n     * object header.\n     */\n    public static class Neighbors extends NodeArray {\n        /** the node id whose neighbors we are storing */\n        private final int nodeId;\n\n        /** entries in `nodes` before this index are diverse and don't need to be checked again */\n        private int diverseBefore;\n\n        /**\n         * uses the node and score references directly from `nodeArray`, without copying\n         * `nodeArray` is assumed to have had diversity enforced already\n         */\n        private Neighbors(int nodeId, NodeArray nodeArray) {\n            super(nodeArray);\n            this.nodeId = nodeId;\n            this.diverseBefore = size();\n        }\n\n        public NodesIterator iterator() {\n            return new NeighborIterator(this);\n        }\n\n        @Override\n        public Neighbors copy() {\n            return copy(size());\n        }\n\n        @Override\n        public Neighbors copy(int newSize) {\n            var superCopy = new NodeArray(this).copy(newSize);\n            return new Neighbors(nodeId, superCopy);\n        }\n\n        /**\n         * Enforce maxConnections as a hard cap, since we allow it to be exceeded temporarily during construction\n         * for efficiency.  This method is threadsafe, but if you call it concurrently with other inserts,\n         * the limit may end up being exceeded again.\n         */\n        private NeighborWithShortEdges enforceDegree(ConcurrentNeighborMap map) {\n            if (size() <= map.maxDegree) {\n                return new NeighborWithShortEdges(this, Double.NaN);\n            }\n            var next = copy();\n            double shortEdges = retainDiverse(next, diverseBefore, map);\n            next.diverseBefore = next.size();\n            return new NeighborWithShortEdges(next, shortEdges);\n        }\n\n        private Neighbors replaceDeletedNeighbors(Bits deletedNodes, NodeArray candidates, ConcurrentNeighborMap map) {\n            // copy the non-deleted neighbors to a new NodeArray\n            var liveNeighbors = new NodeArray(size());\n            for (int i = 0; i < size(); i++) {\n                int nodeId = getNode(i);\n                if (!deletedNodes.get(nodeId)) {\n                    liveNeighbors.addInOrder(nodeId, getScore(i));\n                }\n            }\n\n            // merge the remaining neighbors with the candidates and keep the diverse results\n            NodeArray merged = NodeArray.merge(liveNeighbors, candidates);\n            retainDiverse(merged, 0, map);\n            return new Neighbors(nodeId, merged);\n        }\n\n        /**\n         * For each candidate (going from best to worst), select it only if it is closer to target than it\n         * is to any of the already-selected candidates. This is maintained whether those other neighbors\n         * were selected by this method, or were added as a \"backlink\" to a node inserted concurrently\n         * that chose this one as a neighbor.\n         */\n        private Neighbors insertDiverse(NodeArray toMerge, ConcurrentNeighborMap map) {\n            if (toMerge.size() == 0) {\n                return this;\n            }\n\n            // merge all the candidates into a single array and compute the diverse ones to keep\n            // from that.\n            NodeArray merged;\n            if (size() > 0) {\n                merged = NodeArray.merge(this, toMerge);\n                retainDiverse(merged, 0, map);\n            } else {\n                merged = toMerge.copy(); // still need to copy in case we lose the race\n                retainDiverse(merged, 0, map);\n            }\n            // insertDiverse usually gets called with a LOT of candidates, so trim down the resulting NodeArray\n            var nextNodes = merged.getArrayLength() <= map.nodeArrayLength() ? merged : merged.copy(map.nodeArrayLength());\n            return new Neighbors(nodeId, nextNodes);\n        }\n\n        private Neighbors insertNotDiverse(int node, float score, ConcurrentNeighborMap map) {\n            int maxDegree = map.maxDegree;\n            assert size() <= maxDegree : \"insertNotDiverse called before enforcing degree/diversity\";\n            var next = copy(maxDegree); // we are only called during cleanup -- use actual maxDegree not nodeArrayLength()\n            int insertedAt = next.insertOrReplaceWorst(node, score);\n            if (insertedAt == -1) {\n                // node already existed in the array -- this is rare enough that we don't check up front\n                return this;\n            }\n            next.diverseBefore = min(insertedAt, diverseBefore);\n            return next;\n        }\n\n        /**\n         * Retain the diverse neighbors, updating `neighbors` in place\n         * @return post-diversity short edges fraction\n         */\n        private double retainDiverse(NodeArray neighbors, int diverseBefore, ConcurrentNeighborMap map) {\n            BitSet selected = new FixedBitSet(neighbors.size());\n            for (int i = 0; i < min(diverseBefore, map.maxDegree); i++) {\n                selected.set(i);\n            }\n\n            double shortEdges = retainDiverseInternal(neighbors, diverseBefore, selected, map);\n            neighbors.retain(selected);\n            return shortEdges;\n        }\n\n        /**\n         * update `selected` with the diverse members of `neighbors`.  `neighbors` is not modified\n         * @return the fraction of short edges (neighbors within alpha=1.0)\n         */\n        private double retainDiverseInternal(NodeArray neighbors, int diverseBefore, BitSet selected, ConcurrentNeighborMap map) {\n            int nSelected = diverseBefore;\n            double shortEdges = Double.NaN;\n            // add diverse candidates, gradually increasing alpha to the threshold\n            // (so that the nearest candidates are prioritized)\n            for (float a = 1.0f; a <= map.alpha + 1E-6 && nSelected < map.maxDegree; a += 0.2f) {\n                for (int i = diverseBefore; i < neighbors.size() && nSelected < map.maxDegree; i++) {\n                    if (selected.get(i)) {\n                        continue;\n                    }\n\n                    int cNode = neighbors.getNode(i);\n                    float cScore = neighbors.getScore(i);\n                    var sf = map.scoreProvider.diversityProviderFor(cNode).scoreFunction();\n                    if (isDiverse(cNode, cScore, neighbors, sf, selected, a)) {\n                        selected.set(i);\n                        nSelected++;\n                    }\n                }\n\n                if (a == 1.0f) {\n                    // this isn't threadsafe, but (for now) we only care about the result after calling cleanup(),\n                    // when we don't have to worry about concurrent changes\n                    shortEdges = nSelected / (float) map.maxDegree;\n                }\n            }\n            return shortEdges;\n        }\n\n        // is the candidate node with the given score closer to the base node than it is to any of the\n        // already-selected neighbors\n        private boolean isDiverse(int node, float score, NodeArray others, ScoreFunction sf, BitSet selected, float alpha) {\n            assert others.size() > 0;\n\n            for (int i = selected.nextSetBit(0); i != DocIdSetIterator.NO_MORE_DOCS; i = selected.nextSetBit(i + 1)) {\n                int otherNode = others.getNode(i);\n                if (node == otherNode) {\n                    break;\n                }\n                if (sf.similarityTo(otherNode) > score * alpha) {\n                    return false;\n                }\n            }\n            return true;\n        }\n\n        /**\n         * Insert a new neighbor, maintaining our size cap by removing the least diverse neighbor if\n         * necessary. \"Overflow\" is the factor by which to allow going over the size cap temporarily.\n         */\n        private Neighbors insert(int neighborId, float score, float overflow, ConcurrentNeighborMap map) {\n            assert neighborId != nodeId : \"can't add self as neighbor at node \" + nodeId;\n\n            int hardMax = (int) (overflow * map.maxDegree);\n            assert hardMax <= map.maxOverflowDegree\n                    : String.format(\"overflow %s could exceed max overflow degree %d\", overflow, map.maxOverflowDegree);\n\n            var next = copy(map.nodeArrayLength());\n            int insertionPoint = next.insertSorted(neighborId, score);\n            if (insertionPoint == -1) {\n                // \"new\" node already existed\n                return this;\n            }\n\n            // batch up the enforcement of the max connection limit, since otherwise\n            // we do a lot of duplicate work scanning nodes that we won't remove\n            next.diverseBefore = min(insertionPoint, diverseBefore);\n            if (next.size() > hardMax) {\n                retainDiverse(next, next.diverseBefore, map);\n                next.diverseBefore = next.size();\n            }\n\n            return next;\n        }\n\n        public static long ramBytesUsed(int count) {\n            return NodeArray.ramBytesUsed(count) // includes our object header\n                    + Integer.BYTES // nodeId\n                    + Integer.BYTES; // diverseBefore\n        }\n\n        /** Only for testing; this is a linear search */\n        @VisibleForTesting\n        boolean contains(int i) {\n            var it = this.iterator();\n            while (it.hasNext()) {\n                if (it.nextInt() == i) {\n                    return true;\n                }\n            }\n            return false;\n        }\n    }\n\n    private static class NeighborWithShortEdges {\n        public final Neighbors neighbors;\n        public final double shortEdges;\n\n        public NeighborWithShortEdges(Neighbors neighbors, double shortEdges) {\n            this.neighbors = neighbors;\n            this.shortEdges = shortEdges;\n        }\n    }\n\n    private static class NeighborIterator extends NodesIterator {\n        private final NodeArray neighbors;\n        private int i;\n\n        private NeighborIterator(NodeArray neighbors) {\n            super(neighbors.size());\n            this.neighbors = neighbors;\n            i = 0;\n        }\n\n        @Override\n        public boolean hasNext() {\n            return i < neighbors.size();\n        }\n\n        @Override\n        public int nextInt() {\n            return neighbors.getNode(i++);\n        }\n    }\n}\n\n```\n# Function Signature: void addNode(int nodeId, NodeArray nodes) {\n# Natural Language Annotations: /**\n     * Only for internal use and by Builder loading a saved graph\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic void addNode(int nodeId, NodeArray nodes) {\n        insertDiverse(nodeId, nodes);\n}\n```", "  ```\npublic void addNode(int nodeId, NodeArray nodes) {\n        if (contains(nodeId)) {\n            var old = neighbors(nodeId);\n            if (!old.contains(nodes)) {\n                old.backlink(nodes, alpha);\n            }\n        } else {\n            neighbors.put(nodeId, new Neighbors(nodeId, nodes.copy()));\n      }\n  }\n```", "  ```\npublic void addNode(int nodeId, NodeArray nodes) {\n        // addNode() \n        // first copy the nodes to a new NodeArray\n        var newNodes = nodes.copy(nodeArrayLength());\n        newNodes.diverseBefore = newNodes.retainDiverseInternal(nodes, 0, new FixedBitSet(newNodes.size()), new DiversityProvider(nodeId, this));\n        insertDiverse(nodeId, newNodes, this);\n        for (int i = 0; i < nodes.size(); i++) {\n            int otherId = nodes.getNode(i);\n            int myId = nodeId;\n            insertOne(myId, otherId, nodes.getScore(i), alpha);\n        }\n    }\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/GraphIndexBuilder.java-removeDeletedNodes": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/GraphIndexBuilder.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.graph.similarity.BuildScoreProvider;\nimport io.github.jbellis.jvector.graph.similarity.ScoreFunction;\nimport io.github.jbellis.jvector.util.AtomicFixedBitSet;\nimport io.github.jbellis.jvector.util.Bits;\nimport io.github.jbellis.jvector.util.ExceptionUtils;\nimport io.github.jbellis.jvector.util.ExplicitThreadLocal;\nimport io.github.jbellis.jvector.util.PhysicalCoreExecutor;\nimport io.github.jbellis.jvector.vector.VectorSimilarityFunction;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport org.agrona.collections.IntArrayList;\nimport org.agrona.collections.IntArrayQueue;\n\nimport java.io.Closeable;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.ConcurrentSkipListSet;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicInteger;\nimport java.util.stream.IntStream;\n\nimport static io.github.jbellis.jvector.graph.OnHeapGraphIndex.NO_ENTRY_POINT;\nimport static io.github.jbellis.jvector.util.DocIdSetIterator.NO_MORE_DOCS;\nimport static io.github.jbellis.jvector.vector.VectorUtil.dotProduct;\n\n/**\n * Builder for Concurrent GraphIndex. See {@link GraphIndex} for a high level overview, and the\n * comments to `addGraphNode` for details on the concurrent building approach.\n * <p>\n * GIB allocates scratch space and copies of the RandomAccessVectorValues for each thread\n * that calls `addGraphNode`.  These allocations are retained until the GIB itself is no longer referenced.\n * Under most conditions this is not something you need to worry about, but it does mean\n * that spawning a new Thread per call is not advisable.  This includes virtual threads.\n */\npublic class GraphIndexBuilder implements Closeable {\n    private final int beamWidth;\n    private final ExplicitThreadLocal<NodeArray> naturalScratch;\n    private final ExplicitThreadLocal<NodeArray> concurrentScratch;\n\n    private final int dimension;\n    private final float neighborOverflow;\n    private final float alpha;\n\n    @VisibleForTesting\n    final OnHeapGraphIndex graph;\n    private double averageShortEdges = Double.NaN;\n\n    private final ConcurrentSkipListSet<Integer> insertionsInProgress = new ConcurrentSkipListSet<>();\n\n    private final BuildScoreProvider scoreProvider;\n\n    private final ForkJoinPool simdExecutor;\n    private final ForkJoinPool parallelExecutor;\n\n    private final ExplicitThreadLocal<GraphSearcher> searchers;\n\n    private final AtomicInteger updateEntryNodeIn = new AtomicInteger(10_000);\n\n    /**\n     * Reads all the vectors from vector values, builds a graph connecting them by their dense\n     * ordinals, using the given hyperparameter settings, and returns the resulting graph.\n     *\n     * @param vectorValues     the vectors whose relations are represented by the graph - must provide a\n     *                         different view over those vectors than the one used to add via addGraphNode.\n     * @param M                \u2013 the maximum number of connections a node can have\n     * @param beamWidth        the size of the beam search to use when finding nearest neighbors.\n     * @param neighborOverflow the ratio of extra neighbors to allow temporarily when inserting a\n     *                         node. larger values will build more efficiently, but use more memory.\n     * @param alpha            how aggressive pruning diverse neighbors should be.  Set alpha &gt; 1.0 to\n     *                         allow longer edges.  If alpha = 1.0 then the equivalent of the lowest level of\n     *                         an HNSW graph will be created, which is usually not what you want.\n     */\n    public GraphIndexBuilder(RandomAccessVectorValues vectorValues,\n                             VectorSimilarityFunction similarityFunction,\n                             int M,\n                             int beamWidth,\n                             float neighborOverflow,\n                             float alpha)\n    {\n        this(BuildScoreProvider.randomAccessScoreProvider(vectorValues, similarityFunction),\n             vectorValues.dimension(),\n             M,\n             beamWidth,\n             neighborOverflow,\n             alpha);\n    }\n\n    /**\n     * Reads all the vectors from vector values, builds a graph connecting them by their dense\n     * ordinals, using the given hyperparameter settings, and returns the resulting graph.\n     * Default executor pools are used.\n     *\n     * @param scoreProvider    describes how to determine the similarities between vectors\n     * @param M                the maximum number of connections a node can have\n     * @param beamWidth        the size of the beam search to use when finding nearest neighbors.\n     * @param neighborOverflow the ratio of extra neighbors to allow temporarily when inserting a\n     *                         node. larger values will build more efficiently, but use more memory.\n     * @param alpha            how aggressive pruning diverse neighbors should be.  Set alpha &gt; 1.0 to\n     *                         allow longer edges.  If alpha = 1.0 then the equivalent of the lowest level of\n     *                         an HNSW graph will be created, which is usually not what you want.\n     */\n    public GraphIndexBuilder(BuildScoreProvider scoreProvider,\n                             int dimension,\n                             int M,\n                             int beamWidth,\n                             float neighborOverflow,\n                             float alpha)\n    {\n        this(scoreProvider, dimension, M, beamWidth, neighborOverflow, alpha, PhysicalCoreExecutor.pool(), ForkJoinPool.commonPool());\n    }\n\n    /**\n     * Reads all the vectors from vector values, builds a graph connecting them by their dense\n     * ordinals, using the given hyperparameter settings, and returns the resulting graph.\n     *\n     * @param scoreProvider    describes how to determine the similarities between vectors\n     * @param M                the maximum number of connections a node can have\n     * @param beamWidth        the size of the beam search to use when finding nearest neighbors.\n     * @param neighborOverflow the ratio of extra neighbors to allow temporarily when inserting a\n     *                         node. larger values will build more efficiently, but use more memory.\n     * @param alpha            how aggressive pruning diverse neighbors should be.  Set alpha &gt; 1.0 to\n     *                         allow longer edges.  If alpha = 1.0 then the equivalent of the lowest level of\n     *                         an HNSW graph will be created, which is usually not what you want.\n     * @param simdExecutor     ForkJoinPool instance for SIMD operations, best is to use a pool with the size of\n     *                         the number of physical cores.\n     * @param parallelExecutor ForkJoinPool instance for parallel stream operations\n     */\n    public GraphIndexBuilder(BuildScoreProvider scoreProvider,\n                             int dimension,\n                             int M,\n                             int beamWidth,\n                             float neighborOverflow,\n                             float alpha,\n                             ForkJoinPool simdExecutor,\n                             ForkJoinPool parallelExecutor)\n    {\n        this.scoreProvider = scoreProvider;\n        this.dimension = dimension;\n        this.neighborOverflow = neighborOverflow;\n        this.alpha = alpha;\n        if (M <= 0) {\n            throw new IllegalArgumentException(\"maxConn must be positive\");\n        }\n        if (beamWidth <= 0) {\n            throw new IllegalArgumentException(\"beamWidth must be positive\");\n        }\n        this.beamWidth = beamWidth;\n        this.simdExecutor = simdExecutor;\n        this.parallelExecutor = parallelExecutor;\n\n        int maxOverflowDegree = (int) (M * neighborOverflow);\n        this.graph = new OnHeapGraphIndex(M, maxOverflowDegree, scoreProvider, alpha);\n        this.searchers = ExplicitThreadLocal.withInitial(() -> new GraphSearcher(graph));\n\n        // in scratch we store candidates in reverse order: worse candidates are first\n        this.naturalScratch = ExplicitThreadLocal.withInitial(() -> new NodeArray(Math.max(beamWidth, M + 1)));\n        this.concurrentScratch = ExplicitThreadLocal.withInitial(() -> new NodeArray(Math.max(beamWidth, M + 1)));\n    }\n\n    public OnHeapGraphIndex build(RandomAccessVectorValues ravv) {\n        var vv = ravv.threadLocalSupplier();\n        int size = ravv.size();\n\n        simdExecutor.submit(() -> {\n            IntStream.range(0, size).parallel().forEach(node -> addGraphNode(node, vv.get().getVector(node)));\n        }).join();\n\n        cleanup();\n        return graph;\n    }\n\n    /**\n     * Cleanup the graph by completing removal of marked-for-delete nodes, trimming\n     * neighbor sets to the advertised degree, and updating the entry node.\n     * <p>\n     * Uses default threadpool to process nodes in parallel.  There is currently no way to restrict this to a single thread.\n     * <p>\n     * Must be called before writing to disk.\n     * <p>\n     * May be called multiple times, but should not be called during concurrent modifications to the graph.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private void reconnectOrphanedNodes() {\n        var searchPathNeighbors = new ConcurrentHashMap<Integer, NodeArray>();\n        // It's possible that reconnecting one node will result in disconnecting another, since we are maintaining\n        // the maxConnections invariant. So, we do a best effort of 3 loops. We claim the entry node as an\n        // already used connectionTarget so that we don't clutter its edge list.\n        var connectionTargets = ConcurrentHashMap.<Integer>newKeySet();\n        connectionTargets.add(graph.entry());\n        for (int i = 0; i < 3; i++) {\n            // find all nodes reachable from the entry node\n            var connectedNodes = new AtomicFixedBitSet(graph.getIdUpperBound());\n            connectedNodes.set(graph.entry());\n            ConcurrentNeighborMap.Neighbors self1 = graph.getNeighbors(graph.entry());\n            var entryNeighbors = (NodeArray) self1;\n            parallelExecutor.submit(() -> IntStream.range(0, entryNeighbors.size()).parallel().forEach(node -> findConnected(connectedNodes, entryNeighbors.getNode(node)))).join();\n\n            // reconnect unreachable nodes\n            var nReconnected = new AtomicInteger();\n            simdExecutor.submit(() -> IntStream.range(0, graph.getIdUpperBound()).parallel().forEach(node -> {\n                if (connectedNodes.get(node) || !graph.containsNode(node)) {\n                    return;\n                }\n                nReconnected.incrementAndGet();\n\n                // first, attempt to connect one of our own neighbors to us\n                ConcurrentNeighborMap.Neighbors self = graph.getNeighbors(node);\n                var neighbors = (NodeArray) self;\n                if (connectToClosestNeighbor(node, neighbors, connectionTargets)) {\n                    return;\n                }\n\n                // no unused candidate found -- search for more neighbors and try again\n                neighbors = searchPathNeighbors.get(node);\n                // run search again if neighbors is empty or if every neighbor is already in connection targets\n                if (neighbors == null || isSubset(neighbors, connectionTargets)) {\n                    SearchResult result;\n                    try (var gs = searchers.get()) {\n                        var excludeBits = createExcludeBits(node, connectionTargets);\n                        var ssp = scoreProvider.searchProviderFor(node);\n                        int ep = graph.entry();\n                        result = gs.searchInternal(ssp, beamWidth, beamWidth, 0.0f, 0.0f, ep, excludeBits);\n                    } catch (Exception e) {\n                        throw new RuntimeException(e);\n                    }\n                    neighbors = new NodeArray(result.getNodes().length);\n                    toScratchCandidates(result.getNodes(), neighbors);\n                    searchPathNeighbors.put(node, neighbors);\n                }\n                connectToClosestNeighbor(node, neighbors, connectionTargets);\n            })).join();\n            if (nReconnected.get() == 0) {\n                break;\n            }\n        }\n    }\n\n    private boolean isSubset(NodeArray neighbors, Set<Integer> nodeIds) {\n        for (int i = 0; i < neighbors.size(); i++) {\n            if (!nodeIds.contains(neighbors.getNode(i))) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * Connect `node` to the closest neighbor that is not already a connection target.\n     * @return true if such a neighbor was found.\n     */\n    private boolean connectToClosestNeighbor(int node, NodeArray neighbors, Set<Integer> connectionTargets) {\n        // connect this node to the closest neighbor that hasn't already been used as a connection target\n        // (since this edge is likely to be the \"worst\" one in that target's neighborhood, it's likely to be\n        // overwritten by the next node to need reconnection if we don't choose a unique target)\n        for (int i = 0; i < neighbors.size(); i++) {\n            var neighborNode = neighbors.getNode(i);\n            var neighborScore = neighbors.getScore(i);\n            if (connectionTargets.add(neighborNode)) {\n                graph.nodes.insertNotDiverse(neighborNode, node, neighborScore);\n                return true;\n            }\n        }\n        return false;\n    }\n\n    private void findConnected(AtomicFixedBitSet connectedNodes, int start) {\n        var queue = new IntArrayQueue();\n        queue.add(start);\n        try (var view = graph.getView()) {\n            while (!queue.isEmpty()) {\n                // DFS should result in less contention across findConnected threads than BFS\n                int next = queue.pollInt();\n                if (connectedNodes.getAndSet(next)) {\n                    continue;\n                }\n                for (var it = view.getNeighborsIterator(next); it.hasNext(); ) {\n                    queue.addInt(it.nextInt());\n                }\n            }\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    public OnHeapGraphIndex getGraph() {\n        return graph;\n    }\n\n    /**\n     * Number of inserts in progress, across all threads.  Useful as a sanity check\n     * when calling non-threadsafe methods like cleanup().  (Do not use it to try to\n     * _prevent_ races, only to detect them.)\n     */\n    public int insertsInProgress() {\n        return insertionsInProgress.size();\n    }\n\n    @Deprecated\n    public long addGraphNode(int node, RandomAccessVectorValues ravv) {\n        return addGraphNode(node, ravv.getVector(node));\n    }\n\n    /**\n     * Inserts a node with the given vector value to the graph.\n     *\n     * <p>To allow correctness under concurrency, we track in-progress updates in a\n     * ConcurrentSkipListSet. After adding ourselves, we take a snapshot of this set, and consider all\n     * other in-progress updates as neighbor candidates.\n     *\n     * @param node the node ID to add\n     * @return an estimate of the number of extra bytes used by the graph after adding the given node\n     */\n    public long addGraphNode(int node, VectorFloat<?> vector) {\n        // do this before adding to in-progress, so a concurrent writer checking\n        // the in-progress set doesn't have to worry about uninitialized neighbor sets\n        graph.addNode(node);\n\n        insertionsInProgress.add(node);\n        ConcurrentSkipListSet<Integer> inProgressBefore = insertionsInProgress.clone();\n        try (var gs = searchers.get()) {\n            var naturalScratchPooled = naturalScratch.get();\n            var concurrentScratchPooled = concurrentScratch.get();\n            // find ANN of the new node by searching the graph\n            int ep = graph.entry();\n\n            var bits = new ExcludingBits(node);\n            // find best \"natural\" candidates with a beam search\n            var ssp = scoreProvider.searchProviderFor(vector);\n            var result = gs.searchInternal(ssp, beamWidth, beamWidth, 0.0f, 0.0f, ep, bits);\n\n            // Update neighbors with these candidates.\n            // The DiskANN paper calls for using the entire set of visited nodes along the search path as\n            // potential candidates, but in practice we observe neighbor lists being completely filled using\n            // just the topK results.  (Since the Robust Prune algorithm prioritizes closer neighbors,\n            // this means that considering additional nodes from the search path, that are by definition\n            // farther away than the ones in the topK, would not change the result.)\n            // TODO if we made NeighborArray an interface we could wrap the NodeScore[] directly instead of copying\n            var natural = toScratchCandidates(result.getNodes(), naturalScratchPooled);\n            var concurrent = getConcurrentCandidates(node, inProgressBefore, concurrentScratchPooled, ssp.scoreFunction());\n            updateNeighbors(node, natural, concurrent);\n\n            maybeUpdateEntryPoint(node);\n            maybeImproveOlderNode();\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        } finally {\n            insertionsInProgress.remove(node);\n        }\n\n        return graph.ramBytesUsedOneNode();\n    }\n\n    /**\n     * Improve edge quality on very low-d indexes.  This makes a big difference\n     * in the ability of search to escape local maxima to find better options.\n     * <p>\n     * This has negligible effect on ML embedding-sized vectors, starting at least with GloVe-25, so we don't bother.\n     * (Dimensions between 4 and 25 are untested but they get left out too.)\n     * For 2D vectors, this takes us to over 99% recall up to at least 4M nodes.  (Higher counts untested.)\n    */\n    private void maybeImproveOlderNode() {\n        // pick a node added earlier at random to improve its connections\n        // 20k threshold chosen because that's where recall starts to fall off from 100% for 2D vectors\n        if (dimension <= 3 && graph.size() > 20_000) {\n            // if we can't find a candidate in 3 tries, the graph is too sparse,\n            // we'll have to wait for more nodes to be added (this threshold has been tested w/ parallel build,\n            // which generates very sparse ids due to how spliterator works)\n            for (int i = 0; i < 3; i++) {\n                var olderNode = ThreadLocalRandom.current().nextInt(graph.size());\n                if (graph.containsNode(olderNode) && !graph.getDeletedNodes().get(olderNode)) {\n                    improveConnections(olderNode);\n                    break;\n                }\n            }\n        }\n    }\n\n    private void maybeUpdateEntryPoint(int node) {\n        graph.maybeSetInitialEntryNode(node); // TODO it seems silly to call this long after we've set it the first time\n\n        if (updateEntryNodeIn.decrementAndGet() == 0) {\n            updateEntryPoint();\n        }\n    }\n\n    @VisibleForTesting\n    public void setEntryPoint(int ep) {\n        graph.updateEntryNode(ep);\n    }\n\n    private void updateEntryPoint() {\n        int newEntryNode = approximateMedioid();\n        graph.updateEntryNode(newEntryNode);\n        if (newEntryNode >= 0) {\n            improveConnections(newEntryNode);\n            updateEntryNodeIn.addAndGet(graph.size());\n        } else {\n            updateEntryNodeIn.addAndGet(10_000);\n        }\n    }\n\n    private void improveConnections(int node) {\n        NodeArray naturalScratchPooled;\n        SearchResult result;\n        try (var gs = searchers.get()) {\n            naturalScratchPooled = naturalScratch.get();\n            int ep = graph.entry();\n            var bits = new ExcludingBits(node);\n            var ssp = scoreProvider.searchProviderFor(node);\n            result = gs.searchInternal(ssp, beamWidth, beamWidth, 0.0f, 0.0f, ep, bits);\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n        var natural = toScratchCandidates(result.getNodes(), naturalScratchPooled);\n        var neighbors = graph.nodes.insertDiverse(node, natural);\n        // no overflow -- this method gets called from cleanup\n        graph.nodes.backlink(neighbors, node, 1.0f);\n    }\n\n    public void markNodeDeleted(int node) {\n        graph.markDeleted(node);\n    }\n\n    /**\n     * Remove nodes marked for deletion from the graph, and update neighbor lists\n     * to maintain connectivity.  Not threadsafe with respect to other modifications;\n     * the `synchronized` flag only prevents concurrent calls to this method.\n     *\n     * @return approximate size of memory no longer used\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private static Bits createExcludeBits(int node, Set<Integer> connectionTargets) {\n        return index -> index != node && !connectionTargets.contains(index);\n    }\n\n    /**\n     * Returns the ordinal of the node that is closest to the centroid of the graph,\n     * or NO_ENTRY_POINT if there are no live nodes in the graph.\n     */\n    private int approximateMedioid() {\n        if (graph.size() == 0) {\n            return NO_ENTRY_POINT;\n        }\n\n        var centroid = scoreProvider.approximateCentroid();\n        // if the centroid is the zero vector, pick a random node\n        // (this is not a scenario likely to arise outside of small, contrived tests)\n        if (dotProduct(centroid, centroid) < 1E-6) {\n            return randomLiveNode();\n        }\n\n        int ep = graph.entry();\n        var ssp = scoreProvider.searchProviderFor(centroid);\n        try (var gs = searchers.get()) {\n            var result = gs.searchInternal(ssp, beamWidth, beamWidth, 0.0f, 0.0f, ep, Bits.ALL);\n            if (result.getNodes().length == 0) {\n                // graph contains only deleted nodes\n                return NO_ENTRY_POINT;\n            }\n            return result.getNodes()[0].node;\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    private void updateNeighbors(int nodeId, NodeArray natural, NodeArray concurrent) {\n        // if either natural or concurrent is empty, skip the merge\n        NodeArray toMerge;\n        if (concurrent.size() == 0) {\n            toMerge = natural;\n        } else if (natural.size() == 0) {\n            toMerge = concurrent;\n        } else {\n            toMerge = NodeArray.merge(natural, concurrent);\n        }\n        // toMerge may be approximate-scored, but insertDiverse will compute exact scores for the diverse ones\n        var neighbors = graph.nodes.insertDiverse(nodeId, toMerge);\n        graph.nodes.backlink(neighbors, nodeId, neighborOverflow);\n    }\n\n    private static NodeArray toScratchCandidates(SearchResult.NodeScore[] candidates, NodeArray scratch) {\n        scratch.clear();\n        for (var candidate : candidates) {\n            scratch.addInOrder(candidate.node, candidate.score);\n        }\n        return scratch;\n    }\n\n    private NodeArray getConcurrentCandidates(int newNode,\n                                              Set<Integer> inProgress,\n                                              NodeArray scratch,\n                                              ScoreFunction scoreFunction)\n    {\n        scratch.clear();\n        for (var n : inProgress) {\n            if (n == newNode) {\n                continue;\n            }\n            scratch.insertSorted(n, scoreFunction.similarityTo(n));\n        }\n        return scratch;\n    }\n\n    @Override\n    public void close() throws IOException {\n        try {\n            searchers.close();\n        } catch (Exception e) {\n            ExceptionUtils.throwIoException(e);\n        }\n    }\n\n    @VisibleForTesting\n    int randomLiveNode() {\n        var R = ThreadLocalRandom.current\n```\n# Function Signature: public synchronized long removeDeletedNodes() {\n# Natural Language Annotations: /**\n     * Remove nodes marked for deletion from the graph, and update neighbor lists\n     * to maintain connectivity.  Not threadsafe with respect to other modifications;\n     * the `synchronized` flag only prevents concurrent calls to this method.\n     *\n     * @return approximate size of memory no longer used\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic synchronized long removeDeletedNodes() {\n    long nDeleted = 0;\n    Set<Integer> deletedNodes = graph.getDeletedNodes();\n    concurrentScratch.ifPresent(this::updateDeletedNeighbors);\n    for (int deletedNode : deletedNodes) {\n        graph.deleteNode(deletedNode);\n        nDeleted += graph.ramBytesUsedOneNode();\n    }\n    return nDeleted;\n}\n\nprivate void updateDeletedNeighbors(NodeArray scratch) {\n    for (int i = 0; i < scratch.size(); i++) {\n        int deletedNode = scratch.getNode(i);\n        graph.nodes.updateDiverse(deletedNode, NO_ENTRY_POINT, 0.0f);\n    }\n}\n```", "  ```\npublic synchronized long removeDeletedNodes() {\n    var searchPathNeighbors = new ConcurrentHashMap<Integer, NodeArray>();\n    var connectionTargets = new ConcurrentHashSet<Integer>();\n\n    long nReconnected =\n            simdExecutor.submit(() -> {\n                long ret = 0;\n                for (int i = 0; i < 3; i++) {\n                    IntStream.range(0, graph.getIdUpperBound()).parallel().forEach(node -> {\n                        if (graph.containsNode(node) && graph.getDeletedNodes().get(node)) {\n                            // remove the node from the graph\n                            graph.removeNode(node);\n                            ret += graph.ramBytesUsedOneNode(); // keep track of how much memory is freed\n\n                            // find all nodes that are still in the graph that are reachable from deleted nodes\n                            var reachableNodes = new AtomicFixedBitSet(graph.getIdUpperBound());\n                            IntStream.range(0, graph.getIdUpperBound()).forEach(node2 -> findConnected(reachableNodes, node2));\n\n                            // pick a node that is reachable from the deleted node and is not yet connected to it\n                            int selectedNode = node;\n                            while (reachableNodes.get(selectedNode)) {\n                                var newNodeNeighbors = con Graph.nodes.insertDiverse(selectedNode, neighborsPooled);\n                                // This condition will prevent us from backlinking two different nodes to the same one simultaneously.\n\n                                }\n            }\n        });\n}\n```", "  ```\npublic synchronized long removeDeletedNodes() {\n        if (graph.getDeletedNodes().cardinality() == 0) {\n            return 0L;\n        }\n        // do not globally sync on deletedNodes, despite the fact that the code below accesses\n        // the deletedNodes set only once, allowing concurrennt modifications during most of the method.\n        // this is because the Naturalscrap/concurrentscrap threadlocals that represent the search\n        // context are also expected to be used heavily by other threads during updates, and not\n        // globally protecting this method means that they don't block, improving performance.\n        var deletedNodes = graph.getDeletedNodes();\n        var neighborBuffers = ThreadLocal.withInitial(ArrayList::new);\n        var M = graph.getMaxConnections();\n        var scratch = ThreadLocal.withInitial(IntArrayQueue::new);\n        var bytesFreed = new AtomicLong();\n        simdExecutor.submit(() -> IntStream.range(0, deletedNodes.cardinality()).parallel().forEach(i -> removeDeletedNode(i, deletedNodes, neighborBuffers, M, scratch, bytesFreed))).join();\n        graph.clearDeletedNodes();\n        return bytesFreed.get();\n    }\n\n    private void removeDeletedNode(int i, BitSet deletedNodes, ThreadLocal<ArrayList<ArrayList<ArrayDeque<Neighbor>>>> neighborBuffers, int M, ThreadLocal<IntArrayQueue> scratch, AtomicLong bytesFreed) {\n        if (!deletedNodes.get(i)) {\n            return;\n        }\n        var neighborBuckets = neighborBuffers.get();\n        var scratchBookkeeping = scratch.get();\n        var neighbors = graph.getNeighbors(i);\n        long usedByNode = Arrays.stream(neighbors).mapToLong(n -> graph.nodes.adjacency.ramBytesUsedOneNode(n.node)).sum();\n        var markedForRemoval = graph.clearNode(i);\n        neighborBuffers.remove(markedForRemoval);\n        scratch.remove(markedForRemoval);\n        bytesFreed.addAndGet(-usedByNode);\n        for (int neighborIndex = 0; neighborIndex < neighbors.size(); neighborIndex++) {\n            var neighbor = neighbors[neighborIndex];\n            if (neighbor.node == NO_ENTRY_POINT) {\n                break;\n            }\n            // skip deleted neighbors (since they had their neighbor list updated by removeDeletedNode already),\n            // and neighbors with full lists (every neighbor array is maxed out)\n            if (deletedNodes.get(neighbor.node) || markerForRemoval.size()) {\n                continue;\n            }\n            scratchBookkeeping.addInt(neighbor.node);\n            if (scratchBookkeeping.size() == scratchBookkeeping.initialCapacity()) {\n                scratch.addAll(scratchBookkeeping);\n                scratchBookkeeping.clear();\n            }\n        }\n        if (scratchBookkeeping.size() > 0) {\n            scratch.addAll(scratchBookkeeping);\n            scratchBookkeeping.clear();\n        }\n        // remove them from the neighborhood of other nodes as well\n        for (int neighborIndex = 0; neighborIndex < neighbors.size(); neighborIndex++) {\n            var neighbor = neighbors[neighborIndex];\n            if (neighbor.node == NO_ENTRY_POINT) {\n                break;\n            }\n            var list = graph.nodes.adjacency.getNeighbors(neighbor.node);\n            graph.nodes.adjacency.remove(list, i);\n        }\n    }\n    ```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndexWriter.java-writeInline": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndexWriter.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph.disk;\n\nimport io.github.jbellis.jvector.disk.BufferedRandomAccessWriter;\nimport io.github.jbellis.jvector.disk.RandomAccessWriter;\nimport io.github.jbellis.jvector.graph.GraphIndex;\nimport io.github.jbellis.jvector.graph.OnHeapGraphIndex;\nimport org.agrona.collections.Int2IntHashMap;\n\nimport java.io.Closeable;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\nimport java.nio.file.Path;\nimport java.util.EnumMap;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.function.IntFunction;\n\n/**\n * Write a graph index to disk, for later loading as an OnDiskGraphIndex.\n * <p>\n * Implements `getFeatureSource` to allow incremental construction of a larger-than-memory graph\n * (using the writer as the source of INLINE_VECTORS).\n */\npublic class OnDiskGraphIndexWriter implements Closeable {\n    private final int version;\n    private final GraphIndex graph;\n    private final GraphIndex.View view;\n    private final OrdinalMapper ordinalMapper;\n    private final int dimension;\n    // we don't use Map features but EnumMap is the best way to make sure we don't\n    // accidentally introduce an ordering bug in the future\n    private final EnumMap<FeatureId, Feature> featureMap;\n    private final RandomAccessWriter out;\n    private final long startOffset;\n    private final int headerSize;\n    private volatile int maxOrdinalWritten = -1;\n\n    private OnDiskGraphIndexWriter(RandomAccessWriter out,\n                                   int version,\n                                   long startOffset,\n                                   GraphIndex graph,\n                                   OrdinalMapper oldToNewOrdinals,\n                                   int dimension,\n                                   EnumMap<FeatureId, Feature> features)\n    {\n        this.version = version;\n        this.graph = graph;\n        this.view = graph.getView();\n        this.ordinalMapper = oldToNewOrdinals;\n        this.dimension = dimension;\n        this.featureMap = features;\n        this.out = out;\n        this.startOffset = startOffset;\n\n        // create a mock Header to determine the correct size\n        var ch = new CommonHeader(version, 0, dimension, view.entryNode(), graph.maxDegree());\n        var placeholderHeader = new Header(ch, featureMap);\n        this.headerSize = placeholderHeader.size();\n    }\n\n    public Set<FeatureId> getFeatureSet() {\n        return featureMap.keySet();\n    }\n\n    @Override\n    public synchronized void close() throws IOException {\n        view.close();\n        out.close();\n    }\n\n    /**\n     * Caller should synchronize on this OnDiskGraphIndexWriter instance if mixing usage of the\n     * output with calls to any of the synchronized methods in this class.\n     * <p>\n     * Provided for callers (like Cassandra) that want to add their own header/footer to the output.\n     */\n    public RandomAccessWriter getOutput() {\n        return out;\n    }\n\n    /**\n     * Write the inline features of the given ordinal to the output at the correct offset.\n     * Nothing else is written (no headers, no edges).  The output IS NOT flushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * @return the maximum ordinal written so far, or -1 if no ordinals have been written yet\n     */\n    public int getMaxOrdinal() {\n        return maxOrdinalWritten;\n    }\n\n    private long featureOffsetForOrdinal(int ordinal) {\n        int edgeSize = Integer.BYTES * (1 + graph.maxDegree());\n        long inlineBytes = ordinal * (long) (Integer.BYTES + featureMap.values().stream().mapToInt(Feature::inlineSize).sum() + edgeSize);\n        return startOffset\n                + headerSize\n                + inlineBytes // previous nodes\n                + Integer.BYTES; // the ordinal of the node whose features we're about to write\n    }\n\n    /**\n     * Write the index header and completed edge lists to the given output.  Inline features given in\n     * `featureStateSuppliers` will also be written.  (Features that do not have a supplier are assumed\n     * to have already been written by calls to writeInline).  The output IS flushed.\n     * <p>\n     * Each supplier takes a node ordinal and returns a FeatureState suitable for Feature.writeInline.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Writes the index header, including the graph size, so that OnDiskGraphIndex can open it.\n     * The output IS flushed.\n     * <p>\n     * Public so that you can write the index size (and thus usefully open an OnDiskGraphIndex against the index)\n     * to read Features from it before writing the edges.\n     */\n    public synchronized void writeHeader() throws IOException {\n        // graph-level properties\n        out.seek(startOffset);\n        var commonHeader = new CommonHeader(version,\n                                            graph.size(),\n                                            dimension,\n                                            ordinalMapper.oldToNew(view.entryNode()),\n                                            graph.maxDegree());\n        var header = new Header(commonHeader, featureMap);\n        header.write(out);\n        out.flush();\n        assert out.position() == startOffset + headerSize : String.format(\"%d != %d\", out.position(), startOffset + headerSize);\n    }\n\n    /**\n     * @return a Map of old to new graph ordinals where the new ordinals are sequential starting at 0,\n     * while preserving the original relative ordering in `graph`.  That is, for all node ids i and j,\n     * if i &lt; j in `graph` then map[i] &lt; map[j] in the returned map.  \"Holes\" left by\n     * deleted nodes are filled in by shifting down the new ordinals.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /** CRC32 checksum of bytes written since the starting offset */\n    public synchronized long checksum() throws IOException {\n        long endOffset = out.position();\n        return out.checksum(startOffset, endOffset);\n    }\n\n    /**\n     * Builder for OnDiskGraphIndexWriter, with optional features.\n     */\n    public static class Builder {\n        private final GraphIndex graphIndex;\n        private final EnumMap<FeatureId, Feature> features;\n        private final RandomAccessWriter out;\n        private OrdinalMapper ordinalMapper;\n        private long startOffset;\n        private int version;\n\n        public Builder(GraphIndex graphIndex, Path outPath) throws FileNotFoundException {\n            this(graphIndex, new BufferedRandomAccessWriter(outPath));\n        }\n\n        public Builder(GraphIndex graphIndex, RandomAccessWriter out) {\n            this.graphIndex = graphIndex;\n            this.out = out;\n            this.features = new EnumMap<>(FeatureId.class);\n            this.version = OnDiskGraphIndex.CURRENT_VERSION;\n        }\n\n        public Builder withVersion(int version) {\n            if (version > OnDiskGraphIndex.CURRENT_VERSION) {\n                throw new IllegalArgumentException(\"Unsupported version: \" + version);\n            }\n\n            this.version = version;\n            return this;\n        }\n\n        public Builder with(Feature feature) {\n            features.put(feature.id(), feature);\n            return this;\n        }\n\n        public Builder withMapper(OrdinalMapper ordinalMapper) {\n            this.ordinalMapper = ordinalMapper;\n            return this;\n        }\n\n        /**\n         * Set the starting offset for the graph index in the output file.  This is useful if you want to\n         * write the index to an existing file.\n         */\n        public Builder withStartOffset(long startOffset) {\n            this.startOffset = startOffset;\n            return this;\n        }\n\n        public OnDiskGraphIndexWriter build() throws IOException {\n            if (version < 3 && (!features.containsKey(FeatureId.INLINE_VECTORS) || features.size() > 1)) {\n                throw new IllegalArgumentException(\"Only INLINE_VECTORS is supported until version 3\");\n            }\n\n            int dimension;\n            if (features.containsKey(FeatureId.INLINE_VECTORS)) {\n                dimension = ((InlineVectors) features.get(FeatureId.INLINE_VECTORS)).dimension();\n            } else {\n                throw new IllegalArgumentException(\"Inline vectors must be provided.\");\n            }\n\n            if (ordinalMapper == null) {\n                ordinalMapper = new OrdinalMapper.MapMapper(sequentialRenumbering(graphIndex));\n            }\n            return new OnDiskGraphIndexWriter(out, version, startOffset, graphIndex, ordinalMapper, dimension, features);\n        }\n\n        public Builder withMap(Map<Integer, Integer> oldToNewOrdinals) {\n            return withMapper(new OrdinalMapper.MapMapper(oldToNewOrdinals));\n        }\n\n        public Feature getFeature(FeatureId featureId) {\n            return features.get(featureId);\n        }\n    }\n}\n\n```\n# Function Signature: public synchronized void writeInline(int ordinal, Map<FeatureId, Feature.State> stateMap) throws IOException\n# Natural Language Annotations: /**\n     * Write the inline features of the given ordinal to the output at the correct offset.\n     * Nothing else is written (no headers, no edges).  The output IS NOT flushed.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic synchronized void writeInline(int ordinal, Map<FeatureId, Feature.State> stateMap) throws IOException {\n    long offset = featureOffsetForOrdinal(ordinal);\n    out.seek(offset);\n\n    for (Map.Entry<FeatureId, Feature.State> entry : stateMap.entrySet()) {\n        Feature.writeInline(out, entry.getValue(), entry.getKey().ordinal(), ordinal);\n    }\n}\n```", "  ```\npublic synchronized void writeInline(int ordinal, Map<FeatureId, Feature.State> stateMap) throws IOException {\n    var offset = featureOffsetForOrdinal(ordinal);\n    out.seek(offset);\n    out.writeAndFlush(graph.node(ordinal).id());\n\n    for (var feature : featureMap.values()) {\n        var state = stateMap.get(feature.id());\n        out.writeAndFlush(feature.inlineSize(state));\n        feature.writeInline(state, out);\n    }\n}\n```", "  ```\npublic synchronized void writeInline(int ordinal, Map<FeatureId, Feature.State> stateMap) throws IOException {\n    if (ordinal < 0 || ordinal >= graph.size()) {\n        throw new IllegalArgumentException(\"Ordinal is not in the range of the graph.\");\n    }\n    long currPosition = out.position();\n    writeAt(featureOffsetForOrdinal(ordinal));\n    out.writeOrd(ordinal);\n    for (var entry : featureMap.entrySet()) {\n        var featureId = entry.getKey();\n        var feature = entry.getValue();\n        if (!stateMap.containsKey(featureId)) {\n            throw new IllegalArgumentException(\"Required feature \" + featureId + \" not found in state map.\");\n        }\n        var featureState = stateMap.get(featureId);\n        feature.writeInline(out, featureState);\n    }\n    out.seek(currPosition);\n    if (ordinal > maxOrdinalWritten) {\n        maxOrdinalWritten = ordinal;\n    }\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndexWriter.java-sequentialRenumbering": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndexWriter.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph.disk;\n\nimport io.github.jbellis.jvector.disk.BufferedRandomAccessWriter;\nimport io.github.jbellis.jvector.disk.RandomAccessWriter;\nimport io.github.jbellis.jvector.graph.GraphIndex;\nimport io.github.jbellis.jvector.graph.OnHeapGraphIndex;\nimport org.agrona.collections.Int2IntHashMap;\n\nimport java.io.Closeable;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\nimport java.nio.file.Path;\nimport java.util.EnumMap;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.function.IntFunction;\n\n/**\n * Write a graph index to disk, for later loading as an OnDiskGraphIndex.\n * <p>\n * Implements `getFeatureSource` to allow incremental construction of a larger-than-memory graph\n * (using the writer as the source of INLINE_VECTORS).\n */\npublic class OnDiskGraphIndexWriter implements Closeable {\n    private final int version;\n    private final GraphIndex graph;\n    private final GraphIndex.View view;\n    private final OrdinalMapper ordinalMapper;\n    private final int dimension;\n    // we don't use Map features but EnumMap is the best way to make sure we don't\n    // accidentally introduce an ordering bug in the future\n    private final EnumMap<FeatureId, Feature> featureMap;\n    private final RandomAccessWriter out;\n    private final long startOffset;\n    private final int headerSize;\n    private volatile int maxOrdinalWritten = -1;\n\n    private OnDiskGraphIndexWriter(RandomAccessWriter out,\n                                   int version,\n                                   long startOffset,\n                                   GraphIndex graph,\n                                   OrdinalMapper oldToNewOrdinals,\n                                   int dimension,\n                                   EnumMap<FeatureId, Feature> features)\n    {\n        this.version = version;\n        this.graph = graph;\n        this.view = graph.getView();\n        this.ordinalMapper = oldToNewOrdinals;\n        this.dimension = dimension;\n        this.featureMap = features;\n        this.out = out;\n        this.startOffset = startOffset;\n\n        // create a mock Header to determine the correct size\n        var ch = new CommonHeader(version, 0, dimension, view.entryNode(), graph.maxDegree());\n        var placeholderHeader = new Header(ch, featureMap);\n        this.headerSize = placeholderHeader.size();\n    }\n\n    public Set<FeatureId> getFeatureSet() {\n        return featureMap.keySet();\n    }\n\n    @Override\n    public synchronized void close() throws IOException {\n        view.close();\n        out.close();\n    }\n\n    /**\n     * Caller should synchronize on this OnDiskGraphIndexWriter instance if mixing usage of the\n     * output with calls to any of the synchronized methods in this class.\n     * <p>\n     * Provided for callers (like Cassandra) that want to add their own header/footer to the output.\n     */\n    public RandomAccessWriter getOutput() {\n        return out;\n    }\n\n    /**\n     * Write the inline features of the given ordinal to the output at the correct offset.\n     * Nothing else is written (no headers, no edges).  The output IS NOT flushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * @return the maximum ordinal written so far, or -1 if no ordinals have been written yet\n     */\n    public int getMaxOrdinal() {\n        return maxOrdinalWritten;\n    }\n\n    private long featureOffsetForOrdinal(int ordinal) {\n        int edgeSize = Integer.BYTES * (1 + graph.maxDegree());\n        long inlineBytes = ordinal * (long) (Integer.BYTES + featureMap.values().stream().mapToInt(Feature::inlineSize).sum() + edgeSize);\n        return startOffset\n                + headerSize\n                + inlineBytes // previous nodes\n                + Integer.BYTES; // the ordinal of the node whose features we're about to write\n    }\n\n    /**\n     * Write the index header and completed edge lists to the given output.  Inline features given in\n     * `featureStateSuppliers` will also be written.  (Features that do not have a supplier are assumed\n     * to have already been written by calls to writeInline).  The output IS flushed.\n     * <p>\n     * Each supplier takes a node ordinal and returns a FeatureState suitable for Feature.writeInline.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Writes the index header, including the graph size, so that OnDiskGraphIndex can open it.\n     * The output IS flushed.\n     * <p>\n     * Public so that you can write the index size (and thus usefully open an OnDiskGraphIndex against the index)\n     * to read Features from it before writing the edges.\n     */\n    public synchronized void writeHeader() throws IOException {\n        // graph-level properties\n        out.seek(startOffset);\n        var commonHeader = new CommonHeader(version,\n                                            graph.size(),\n                                            dimension,\n                                            ordinalMapper.oldToNew(view.entryNode()),\n                                            graph.maxDegree());\n        var header = new Header(commonHeader, featureMap);\n        header.write(out);\n        out.flush();\n        assert out.position() == startOffset + headerSize : String.format(\"%d != %d\", out.position(), startOffset + headerSize);\n    }\n\n    /**\n     * @return a Map of old to new graph ordinals where the new ordinals are sequential starting at 0,\n     * while preserving the original relative ordering in `graph`.  That is, for all node ids i and j,\n     * if i &lt; j in `graph` then map[i] &lt; map[j] in the returned map.  \"Holes\" left by\n     * deleted nodes are filled in by shifting down the new ordinals.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /** CRC32 checksum of bytes written since the starting offset */\n    public synchronized long checksum() throws IOException {\n        long endOffset = out.position();\n        return out.checksum(startOffset, endOffset);\n    }\n\n    /**\n     * Builder for OnDiskGraphIndexWriter, with optional features.\n     */\n    public static class Builder {\n        private final GraphIndex graphIndex;\n        private final EnumMap<FeatureId, Feature> features;\n        private final RandomAccessWriter out;\n        private OrdinalMapper ordinalMapper;\n        private long startOffset;\n        private int version;\n\n        public Builder(GraphIndex graphIndex, Path outPath) throws FileNotFoundException {\n            this(graphIndex, new BufferedRandomAccessWriter(outPath));\n        }\n\n        public Builder(GraphIndex graphIndex, RandomAccessWriter out) {\n            this.graphIndex = graphIndex;\n            this.out = out;\n            this.features = new EnumMap<>(FeatureId.class);\n            this.version = OnDiskGraphIndex.CURRENT_VERSION;\n        }\n\n        public Builder withVersion(int version) {\n            if (version > OnDiskGraphIndex.CURRENT_VERSION) {\n                throw new IllegalArgumentException(\"Unsupported version: \" + version);\n            }\n\n            this.version = version;\n            return this;\n        }\n\n        public Builder with(Feature feature) {\n            features.put(feature.id(), feature);\n            return this;\n        }\n\n        public Builder withMapper(OrdinalMapper ordinalMapper) {\n            this.ordinalMapper = ordinalMapper;\n            return this;\n        }\n\n        /**\n         * Set the starting offset for the graph index in the output file.  This is useful if you want to\n         * write the index to an existing file.\n         */\n        public Builder withStartOffset(long startOffset) {\n            this.startOffset = startOffset;\n            return this;\n        }\n\n        public OnDiskGraphIndexWriter build() throws IOException {\n            if (version < 3 && (!features.containsKey(FeatureId.INLINE_VECTORS) || features.size() > 1)) {\n                throw new IllegalArgumentException(\"Only INLINE_VECTORS is supported until version 3\");\n            }\n\n            int dimension;\n            if (features.containsKey(FeatureId.INLINE_VECTORS)) {\n                dimension = ((InlineVectors) features.get(FeatureId.INLINE_VECTORS)).dimension();\n            } else {\n                throw new IllegalArgumentException(\"Inline vectors must be provided.\");\n            }\n\n            if (ordinalMapper == null) {\n                ordinalMapper = new OrdinalMapper.MapMapper(sequentialRenumbering(graphIndex));\n            }\n            return new OnDiskGraphIndexWriter(out, version, startOffset, graphIndex, ordinalMapper, dimension, features);\n        }\n\n        public Builder withMap(Map<Integer, Integer> oldToNewOrdinals) {\n            return withMapper(new OrdinalMapper.MapMapper(oldToNewOrdinals));\n        }\n\n        public Feature getFeature(FeatureId featureId) {\n            return features.get(featureId);\n        }\n    }\n}\n\n```\n# Function Signature: public static Map<Integer, Integer> sequentialRenumbering(GraphIndex graph) {\n# Natural Language Annotations: /**\n     * @return a Map of old to new graph ordinals where the new ordinals are sequential starting at 0,\n     * while preserving the original relative ordering in `graph`.  That is, for all node ids i and j,\n     * if i &lt; j in `graph` then map[i] &lt; map[j] in the returned map.  \"Holes\" left by\n     * deleted nodes are filled in by shifting down the new ordinals.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static Map<Integer, Integer> sequentialRenumbering(GraphIndex graph) {\n    Map<Integer, Integer> result = new HashMap<>();\n    int currentNewOrdinal = 0;\n    for (int i = 0; i < graph.size(); i++) {\n        int oldOrdinal = i;\n        while (graph.isRemoved(oldOrdinal)) {\n            oldOrdinal++;\n        }\n        result.put(oldOrdinal, currentNewOrdinal++);\n    }\n    return result;\n}\n```", "  ```java\npublic static Map<Integer, Integer> sequentialRenumbering(GraphIndex graph) {\n    Map<Integer, Integer> oldToNewOrdinals = new HashMap<>();\n    List<Integer> ordinals = graph.getGraph().nodeSet().collect(Collectors.toList());\n    for (int i = 0; i < ordinals.size(); i++) {\n        oldToNewOrdinals.put(ordinals.get(i), i);\n    }\n    return oldToNewOrdinals;\n}\n```", "  ```\npublic static Map<Integer, Integer> sequentialRenumbering(GraphIndex graph) {\n    Map<Integer, Integer> oldToNewOrdinals = new HashMap<>(graph.size());\n\n    // scan the graph and collect the nodes and their ordinals\n    Set<Integer> nodes = graph.keySet();\n    int i = 0;\n    for (Integer node : nodes) {\n        oldToNewOrdinals.put(node, i);\n        i++;\n    }\n\n    return oldToNewOrdinals;\n}\n```"]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndex.java-write": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndex.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph.disk;\n\nimport io.github.jbellis.jvector.annotations.VisibleForTesting;\nimport io.github.jbellis.jvector.disk.RandomAccessReader;\nimport io.github.jbellis.jvector.disk.ReaderSupplier;\nimport io.github.jbellis.jvector.graph.GraphIndex;\nimport io.github.jbellis.jvector.graph.NodesIterator;\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.graph.similarity.ScoreFunction;\nimport io.github.jbellis.jvector.util.Accountable;\nimport io.github.jbellis.jvector.util.Bits;\nimport io.github.jbellis.jvector.util.RamUsageEstimator;\nimport io.github.jbellis.jvector.vector.VectorSimilarityFunction;\nimport io.github.jbellis.jvector.vector.VectorizationProvider;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\nimport java.io.IOException;\nimport java.io.UncheckedIOException;\nimport java.nio.file.Path;\nimport java.util.EnumMap;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.stream.Collectors;\nimport java.util.stream.IntStream;\n\n/**\n * A class representing a graph index stored on disk. The base graph contains only graph structure.\n * <p> * The base graph\n\n * This graph may be extended with additional features, which are stored inline in the graph and in headers.\n * At runtime, this class may choose the best way to use these features.\n */\npublic class OnDiskGraphIndex implements GraphIndex, AutoCloseable, Accountable\n{\n    public static final int CURRENT_VERSION = 3;\n    static final int MAGIC = 0xFFFF0D61; // FFFF to distinguish from old graphs, which should never start with a negative size \"ODGI\"\n    static final VectorTypeSupport vectorTypeSupport = VectorizationProvider.getInstance().getVectorTypeSupport();\n    final ReaderSupplier readerSupplier;\n    final int version;\n    final int size;\n    final int maxDegree;\n    final int dimension;\n    final int entryNode;\n    final int inlineBlockSize; // total size of all inline elements contributed by features\n    final EnumMap<FeatureId, ? extends Feature> features;\n    final EnumMap<FeatureId, Integer> inlineOffsets;\n    private final long neighborsOffset;\n\n    OnDiskGraphIndex(ReaderSupplier readerSupplier, Header header, long neighborsOffset)\n    {\n        this.readerSupplier = readerSupplier;\n        this.version = header.common.version;\n        this.size = header.common.size;\n        this.dimension = header.common.dimension;\n        this.entryNode = header.common.entryNode;\n        this.maxDegree = header.common.maxDegree;\n        this.features = header.features;\n        this.neighborsOffset = neighborsOffset;\n        var inlineBlockSize = 0;\n        inlineOffsets = new EnumMap<>(FeatureId.class);\n        for (var entry : features.entrySet()) {\n            inlineOffsets.put(entry.getKey(), inlineBlockSize);\n            inlineBlockSize += entry.getValue().inlineSize();\n        }\n        this.inlineBlockSize = inlineBlockSize;\n    }\n\n    /**\n     * Load an index from the given reader supplier, where the index starts at `offset`.\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Load an index from the given reader supplier at offset 0.\n     */\n    public static OnDiskGraphIndex load(ReaderSupplier readerSupplier) {\n        return load(readerSupplier, 0);\n    }\n\n    public Set<FeatureId> getFeatureSet() {\n        return features.keySet();\n    }\n\n    public int getDimension() {\n        return dimension;\n    }\n\n    @Override\n    public int size() {\n        return size;\n    }\n\n    @Override\n    public int maxDegree() {\n        return maxDegree;\n    }\n\n    @Override\n    public NodesIterator getNodes()\n    {\n        return NodesIterator.fromPrimitiveIterator(IntStream.range(0, size).iterator(), size);\n    }\n\n    @Override\n    public long ramBytesUsed() {\n        return Long.BYTES + 6 * Integer.BYTES + RamUsageEstimator.NUM_BYTES_OBJECT_REF\n                + (long) 2 * RamUsageEstimator.NUM_BYTES_OBJECT_REF * FeatureId.values().length;\n    }\n\n    public void close() throws IOException {\n        readerSupplier.close();\n    }\n\n    @Override\n    public String toString() {\n        return String.format(\"OnDiskGraphIndex(size=%d, entryPoint=%d, features=%s)\", size, entryNode,\n                features.keySet().stream().map(Enum::name).collect(Collectors.joining(\",\")));\n    }\n\n    // re-declared to specify type\n    @Override\n    public View getView() {\n        try {\n            return new View(readerSupplier.get());\n        } catch (IOException e) {\n            throw new UncheckedIOException(e);\n        }\n    }\n\n    public class View implements FeatureSource, ScoringView, RandomAccessVectorValues {\n        protected final RandomAccessReader reader;\n        private final int[] neighbors;\n\n        public View(RandomAccessReader reader) {\n            this.reader = reader;\n            this.neighbors = new int[maxDegree];\n        }\n\n        @Override\n        public int dimension() {\n            return dimension;\n        }\n\n        // getVector isn't called on the hot path, only getVectorInto, so we don't bother using a shared value\n        @Override\n        public boolean isValueShared() {\n            return false;\n        }\n\n        @Override\n        public RandomAccessVectorValues copy() {\n            throw new UnsupportedOperationException(); // need to copy reader\n        }\n\n        protected long inlineOffsetFor(int node, FeatureId featureId) {\n            return neighborsOffset +\n                    (node * ((long) Integer.BYTES // ids\n                            + inlineBlockSize // inline elements\n                            + (Integer.BYTES * (long) (maxDegree + 1)) // neighbor count + neighbors)\n                    )) + Integer.BYTES + // id\n                    inlineOffsets.get(featureId);\n        }\n\n        long neighborsOffsetFor(int node) {\n            return neighborsOffset +\n                    (node + 1) * (Integer.BYTES + (long) inlineBlockSize) +\n                    (node * (long) Integer.BYTES * (maxDegree + 1));\n        }\n\n        @Override\n        public RandomAccessReader inlineReaderForNode(int node, FeatureId featureId) throws IOException {\n            long offset = inlineOffsetFor(node, featureId);\n            reader.seek(offset);\n            return reader;\n        }\n\n        @Override\n        public VectorFloat<?> getVector(int node) {\n            if (!features.containsKey(FeatureId.INLINE_VECTORS)) {\n                throw new UnsupportedOperationException(\"No inline vectors in this graph\");\n            }\n\n            try {\n                long offset = inlineOffsetFor(node, FeatureId.INLINE_VECTORS);\n                reader.seek(offset);\n                return vectorTypeSupport.readFloatVector(reader, dimension);\n            } catch (IOException e) {\n                throw new UncheckedIOException(e);\n            }\n        }\n\n        @Override\n        public void getVectorInto(int node, VectorFloat<?> vector, int offset) {\n            if (!features.containsKey(FeatureId.INLINE_VECTORS)) {\n                throw new UnsupportedOperationException(\"No inline vectors in this graph\");\n            }\n\n            try {\n                long diskOffset = inlineOffsetFor(node, FeatureId.INLINE_VECTORS);\n                reader.seek(diskOffset);\n                vectorTypeSupport.readFloatVector(reader, dimension, vector, offset);\n            } catch (IOException e) {\n                throw new UncheckedIOException(e);\n            }\n        }\n\n        public NodesIterator getNeighborsIterator(int node) {\n            try {\n                reader.seek(neighborsOffsetFor(node));\n                int neighborCount = reader.readInt();\n                assert neighborCount <= maxDegree : String.format(\"Node %d neighborCount %d > M %d\", node, neighborCount, maxDegree);\n                reader.read(neighbors, 0, neighborCount);\n                return new NodesIterator.ArrayNodesIterator(neighbors, neighborCount);\n            } catch (IOException e) {\n                throw new UncheckedIOException(e);\n            }\n        }\n\n        @Override\n        public int size() {\n            return size;\n        }\n\n        @Override\n        public int entryNode() {\n            return entryNode;\n        }\n\n        @Override\n        public Bits liveNodes() {\n            return Bits.ALL;\n        }\n\n        @Override\n        public void close() throws IOException {\n            reader.close();\n        }\n\n        @Override\n        public ScoreFunction.ExactScoreFunction rerankerFor(VectorFloat<?> queryVector, VectorSimilarityFunction vsf) {\n            if (!features.containsKey(FeatureId.INLINE_VECTORS)) {\n                throw new UnsupportedOperationException(\"No inline vectors in this graph\");\n            }\n            return RandomAccessVectorValues.super.rerankerFor(queryVector, vsf);\n        }\n\n        @Override\n        public ScoreFunction.ApproximateScoreFunction approximateScoreFunctionFor(VectorFloat<?> queryVector, VectorSimilarityFunction vsf) {\n            if (features.containsKey(FeatureId.FUSED_ADC)) {\n                return ((FusedADC) features.get(FeatureId.FUSED_ADC)).approximateScoreFunctionFor(queryVector, vsf, this, rerankerFor(queryVector, vsf));\n            } else {\n                throw new UnsupportedOperationException(\"No approximate score function available for this graph\");\n            }\n        }\n    }\n\n    /** Convenience function for writing a vanilla DiskANN-style index with no extra Features. */\n    public static void write(GraphIndex graph, RandomAccessVectorValues vectors, Path path) throws IOException {\n        write(graph, vectors, OnDiskGraphIndexWriter.sequentialRenumbering(graph), path);\n    }\n\n    /** Convenience function for writing a vanilla DiskANN-style index with no extra Features. */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    @VisibleForTesting\n    static boolean areHeadersEqual(OnDiskGraphIndex g1, OnDiskGraphIndex g2) {\n        return g1.version == g2.version &&\n               g1.size == g2.size &&\n               g1.maxDegree == g2.maxDegree &&\n               g1.dimension == g2.dimension &&\n               g1.entryNode == g2.entryNode;\n    }\n}\n\n```\n# Function Signature: public static void write(GraphIndex graph,\n# Natural Language Annotations: /** Convenience function for writing a vanilla DiskANN-style index with no extra Features. */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void write(GraphIndex graph, RandomAccessVectorValues vectors, Path path) throws IOException {\n        write(graph, vectors, OnDiskGraphIndexWriter.sequentialRenumbering(graph), path);\n    }\n```", "  ```\npublic static void write(GraphIndex graph, RandomAccessVectorValues vectors, Path path) throws IOException {\n    write(graph, vectors, OnDiskGraphIndexWriter.sequentialRenumbering(graph), path);\n}\n```", "  ```\npublic static void write(GraphIndex graph, RandomAccessVectorValues vectors, Path path) throws IOException {\n        write(graph, vectors, OnDiskGraphIndexWriter.sequentialRenumbering(graph), path);\n}\n```\nThis is the outermost function in the class. It is a convenience function for writing a vanilla DiskANN-style index with no extra Features. It calls the `write` method with the three arguments:\n\n* `graph`: a `GraphIndex` object that represents the graph to be written.\n* `vectors`: a `RandomAccessVectorValues` object that contains the vectors for each node in the graph.\n* `path`: a `Path` object that represents the location where the graph index should be written.\n\nThe method first creates a `OnDiskGraphIndexWriter` object using the `sequentialRenumbering` method, which renumbers the nodes in the graph in a sequential order.\n\nIt then calls the `write` method with the three arguments: `graph`, `vectors`, and `writer`. The `write` method is a data member of the `GraphIndex` class, and it is called to write the graph index to the location specified by `path`.\n\nThe `write` method is not annotated with `@VisibleForTesting`, so it is not intended to be used by any other methods in the class. It is only intended to be used by the end users of the `OnDiskGraphIndex` class."]}, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/similarity/BuildScoreProvider.java-randomAccessScoreProvider": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/jvector/jvector-base/src/main/java/io/github/jbellis/jvector/graph/similarity/BuildScoreProvider.java:\n```\n/*\n * Copyright DataStax, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage io.github.jbellis.jvector.graph.similarity;\n\nimport io.github.jbellis.jvector.graph.RandomAccessVectorValues;\nimport io.github.jbellis.jvector.pq.PQVectors;\nimport io.github.jbellis.jvector.vector.VectorSimilarityFunction;\nimport io.github.jbellis.jvector.vector.VectorUtil;\nimport io.github.jbellis.jvector.vector.VectorizationProvider;\nimport io.github.jbellis.jvector.vector.types.VectorFloat;\nimport io.github.jbellis.jvector.vector.types.VectorTypeSupport;\n\n/**\n * Encapsulates comparing node distances for GraphIndexBuilder.\n */\npublic interface BuildScoreProvider {\n    VectorTypeSupport vts = VectorizationProvider.getInstance().getVectorTypeSupport();\n\n    /**\n     * @return true if the primary score functions used for construction are exact.  This\n     * is modestly redundant, but it saves having to allocate new Search/Diversity provider\n     * objects in some hot construction loops.\n     */\n    boolean isExact();\n\n    /**\n     * @return the approximate centroid of the known nodes.  We use the closest node\n     * to this centroid as the graph entry point, so this is called when the entry point is deleted\n     * or every time the graph size doubles.\n     * <p>\n     * This is not called on a path that blocks searches or modifications, so it is okay for it to be O(N).\n     */\n    VectorFloat<?> approximateCentroid();\n\n    /**\n     * Create a search score provider to use *internally* during construction.\n     * <p>\n     * \"Internally\" means that this may differ from a typical SSP in that it may use\n     * approximate scores *without* reranking.  (In this case, reranking will be done\n     * separately by the ConcurrentNeighborSet diversity code.)\n     * <p>\n     * @param vector the query vector to provide similarity scores against\n     */\n    SearchScoreProvider searchProviderFor(VectorFloat<?> vector);\n\n    /**\n     * Create a search score provider to use *internally* during construction.\n     * <p>\n     * \"Internally\" means that this may differ from a typical SSP in that it may use\n     * approximate scores *without* reranking.  (In this case, reranking will be done\n     * separately by the ConcurrentNeighborSet diversity code.)\n     * <p>\n     * @param node1 the graph node to provide similarity scores against\n     */\n    SearchScoreProvider searchProviderFor(int node1);\n\n    /**\n     * Create a score provider to use internally during construction.\n     * <p>\n     * The difference between the diversity provider and the search provider is\n     * that the diversity provider is only expected to be used a few dozen times per node,\n     * which influences the implementation choices.\n     * <p>\n     * When scoring is approximate, the scores from the search and diversity provider\n     * must be consistent, i.e. mixing different types of CompressedVectors will cause problems.\n     */\n    SearchScoreProvider diversityProviderFor(int node1);\n\n    /**\n     * Returns a BSP that performs exact score comparisons using the given RandomAccessVectorValues and VectorSimilarityFunction.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns a BSP that performs approximate score comparisons using the given PQVectors,\n     * with reranking performed using RandomAccessVectorValues (which is intended to be\n     * InlineVectorValues for building incrementally, but should technically\n     * work with any RAVV implementation).\n     */\n    static BuildScoreProvider pqBuildScoreProvider(VectorSimilarityFunction vsf, PQVectors pqv) {\n        int dimension = pqv.getOriginalSize() / Float.BYTES;\n\n        return new BuildScoreProvider() {\n            @Override\n            public boolean isExact() {\n                return false;\n            }\n\n            @Override\n            public SearchScoreProvider diversityProviderFor(int node1) {\n                // like searchProviderFor, this skips reranking; unlike sPF, it uses pqv.scoreFunctionFor\n                // instead of precomputedScoreFunctionFor; since we only perform a few dozen comparisons\n                // during diversity computation, this is cheaper than precomputing a lookup table\n                VectorFloat<?> v1 = vts.createFloatVector(dimension);\n                pqv.getCompressor().decode(pqv.get(node1), v1);\n                var asf = pqv.scoreFunctionFor(v1, vsf); // not precomputed!\n                return new SearchScoreProvider(asf);\n            }\n\n            @Override\n            public SearchScoreProvider searchProviderFor(int node1) {\n                VectorFloat<?> decoded = vts.createFloatVector(dimension);\n                pqv.getCompressor().decode(pqv.get(node1), decoded);\n                return searchProviderFor(decoded);\n            }\n\n            @Override\n            public SearchScoreProvider searchProviderFor(VectorFloat<?> vector) {\n                // deliberately skips reranking even though we are using an approximate score function\n                return new SearchScoreProvider(pqv.precomputedScoreFunctionFor(vector, vsf));\n            }\n\n            @Override\n            public VectorFloat<?> approximateCentroid() {\n                return pqv.getCompressor().getOrComputeCentroid();\n            }\n        };\n    }\n\n}\n\n```\n# Function Signature: static BuildScoreProvider randomAccessScoreProvider(RandomAccessVectorValues ravv, VectorSimilarityFunction similarityFunction) {\n# Natural Language Annotations: /**\n     * Returns a BSP that performs exact score comparisons using the given RandomAccessVectorValues and VectorSimilarityFunction.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\nBuildScoreProvider randomAccessScoreProvider(RandomAccessVectorValues ravv, VectorSimilarityFunction similarityFunction) {\n    return new BuildScoreProvider() {\n        @Override\n        public boolean isExact() {\n            return true;\n        }\n\n        @Override\n        public SearchScoreProvider diversityProviderFor(int node1) {\n            VectorFloat<?> v1 = ravv.getVector(node1);\n            return new SearchScoreProvider(similarityFunction.similarity(v1));\n        }\n\n        @Override\n        public SearchScoreProvider searchProviderFor(int node1) {\n            return diversityProviderFor(node1);\n        }\n\n        @Override\n        public SearchScoreProvider searchProviderFor(VectorFloat<?> vector) {\n            return new SearchScoreProvider(similarityFunction.similarity(vector));\n        }\n\n        @Override\n        public VectorFloat<?> approximateCentroid() {\n            return ravv.approxCentroid();\n        }\n    };\n}\n```", "  ```\nstatic BuildScoreProvider randomAccessScoreProvider(RandomAccessVectorValues ravv, VectorSimilarityFunction similarityFunction) {\n    return new BuildScoreProvider() {\n        @Override\n        public boolean isExact() {\n            return true;\n        }\n\n        @Override\n        public SearchScoreProvider diversityProviderFor(int node1) {\n            return searchProviderFor(node1);\n        }\n\n        @Override\n        public SearchScoreProvider searchProviderFor(int node1) {\n            return searchProviderFor(ravv.getValue(node1));\n        }\n\n        @Override\n        public SearchScoreProvider searchProviderFor(VectorFloat<?> vector) {\n            return new SearchScoreProvider(similarityFunction.distance(vector));\n        }\n\n        @Override\n        public VectorFloat<?> approximateCentroid() {\n            throw new UnsupportedOperationException(\"RandomAccessScoreProvider cannot generate centroids\");\n        }\n    };\n}\n```", "  ```\nstatic BuildScoreProvider randomAccessScoreProvider(RandomAccessVectorValues ravv, VectorSimilarityFunction vsf) {\n    return new BuildScoreProvider() {\n        private VectorTypeSupport vts = VectorizationProvider.getInstance().getVectorTypeSupport();\n\n        @Override\n        public boolean isExact() {\n            return true;\n        }\n\n        @Override\n        public SearchScoreProvider searchProviderFor(VectorFloat<?> vector) {\n            return new SearchScoreProvider(vsf.similaritySimilarityFromSource(vector));\n        }\n\n        @Override\n        public SearchScoreProvider searchProviderFor(int node1) {\n            return new SearchScoreProvider(vsf.similaritySimilarityFromSource(ravv.getValue(node1)));\n        }\n\n        @Override\n        public SearchScoreProvider diversityProviderFor(int node1) {\n            return searchProviderFor(node1);\n        }\n\n        @Override\n        public VectorFloat<?> approximateCentroid() {\n            return vts.similaritySimilarityFromSource(ravv.getCentroid());\n        }\n    };\n}\n```"]}, "timefold-solver-benchmark/src/main/java/ai/timefold/solver/benchmark/impl/statistic/StatisticUtils.java-determineStandardDeviationDoubles": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/benchmark/src/main/java/ai/timefold/solver/benchmark/impl/statistic/StatisticUtils.java:\n```\npackage ai.timefold.solver.benchmark.impl.statistic;\n\nimport java.text.DecimalFormat;\nimport java.text.DecimalFormatSymbols;\nimport java.util.List;\nimport java.util.Locale;\n\nimport ai.timefold.solver.benchmark.impl.result.BenchmarkResult;\nimport ai.timefold.solver.core.api.score.Score;\n\npublic class StatisticUtils {\n\n    private StatisticUtils() {\n        // This class is not instantiable\n    }\n\n    /**\n     * Calculates standard deviation of {@link BenchmarkResult#getAverageScore()}s from {@code averageScore}.\n     *\n     * @param averageScore not null\n     * @return standard deviation double values\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    // TODO Do the locale formatting in benchmarkReport.html.ftl - https://issues.redhat.com/browse/PLANNER-169\n    public static String getStandardDeviationString(double[] standardDeviationDoubles) {\n        if (standardDeviationDoubles == null) {\n            return null;\n        }\n        StringBuilder standardDeviationString = new StringBuilder(standardDeviationDoubles.length * 9);\n        // Abbreviate to 2 decimals\n        // We don't use a local sensitive DecimalFormat, because other Scores don't use it either (see PLANNER-169)\n        DecimalFormatSymbols decimalFormatSymbols = new DecimalFormatSymbols(Locale.US);\n        DecimalFormat exponentialFormat = new DecimalFormat(\"0.0#E0\", decimalFormatSymbols);\n        DecimalFormat decimalFormat = new DecimalFormat(\"0.0#\", decimalFormatSymbols);\n        boolean first = true;\n        for (double standardDeviationDouble : standardDeviationDoubles) {\n            if (first) {\n                first = false;\n            } else {\n                standardDeviationString.append(\"/\");\n            }\n            // See http://docs.oracle.com/javase/7/docs/api/java/lang/Double.html#toString%28double%29\n            String abbreviated;\n            if (0.001 <= standardDeviationDouble && standardDeviationDouble <= 10000000.0) {\n                abbreviated = decimalFormat.format(standardDeviationDouble);\n            } else {\n                abbreviated = exponentialFormat.format(standardDeviationDouble);\n            }\n            standardDeviationString.append(abbreviated);\n        }\n        return standardDeviationString.toString();\n    }\n\n}\n\n```\n# Function Signature: public static double[] determineStandardDeviationDoubles(\n# Natural Language Annotations: /**\n     * Calculates standard deviation of {@link BenchmarkResult#getAverageScore()}s from {@code averageScore}.\n     *\n     * @param averageScore not null\n     * @return standard deviation double values\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static double[] determineStandardDeviationDoubles(double[] averageScores) {\n    double[] standardDeviationDoubles = new double[averageScores.length];\n    for (int i = 0; i < averageScores.length; i++) {\n        standardDeviationDoubles[i] = determineStandardDeviation(averageScores[i]);\n    }\n    return standardDeviationDoubles;\n}\n\nprivate static double determineStandardDeviation(double averageScore) {\n    double var = 0.0;\n    for (double averageScore : averageScores) {\n        var += Math.pow(averageScore - averageScore, 2);\n    }\n    return Math.sqrt(var / (averageScores.length - 1));\n}\n```", "  ```\npublic static double[] determineStandardDeviationDoubles(double[] averageScore) {\n    // calculate the standard deviation of the averageScores\n    double[] standardDeviationDoubles = new double[averageScore.length];\n    for (int i = 0; i < averageScore.length; i++) {\n        double avg = averageScore[i];\n        double stdDev = Math.sqrt(avg);\n        standardDeviationDoubles[i] = stdDev;\n    }\n    return standardDeviationDoubles;\n}\n```", "  ```\npublic static double[] determineStandardDeviationDoubles(List<BenchmarkResult> averageScore) {\n    if (averageScore == null) {\n        return null;\n    }\n    int size = averageScore.size();\n    if (size == 0) {\n        return new double[0];\n    }\n    double[] standardDeviationDoubles = new double[size];\n    double[] averageScores = new double[size];\n    for (int i = 0; i < size; i++) {\n        BenchmarkResult result = averageScore.get(i);\n        Score score = result.getAverageScore();\n        averageScores[i] = score.getValue();\n    }\n    for (int i = 0; i < size; i++) {\n        double average = numericAverage(averageScores);\n        double diff = averageScores[i] - average;\n        standardDeviationDoubles[i] = Math.sqrt(\n                diff == 0 ? 0 : numericAverage(Math.pow(averageScores, 2)) - Math.pow(diff, 2)) / (size - 1);\n    }\n    return standardDeviationDoubles;\n}\n\nprivate static double numericAverage(double[] numbers) {\n    if (numbers == null || numbers.length == 0) {\n        return Double.NaN;\n    }\n    int size = numbers.length;\n    double sum = 0;\n    for (int i = 0; i < size; i++) {\n        sum += numbers[i];\n    }\n    return sum / size;\n}\n```"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/StackMetadata.java-stack": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/StackMetadata.java:\n```\npackage ai.timefold.jpyinterpreter;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.jpyinterpreter.opcodes.OpcodeWithoutSource;\nimport ai.timefold.jpyinterpreter.types.BuiltinTypes;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\n\npublic class StackMetadata {\n    public static final StackMetadata DEAD_CODE = new StackMetadata();\n\n    public final LocalVariableHelper localVariableHelper;\n\n    private final List<ValueSourceInfo> stackValueSources;\n    private final List<ValueSourceInfo> localVariableValueSources;\n    private final List<ValueSourceInfo> cellVariableValueSources;\n\n    private List<String> callKeywordNameList;\n\n    private StackMetadata() {\n        this.localVariableHelper = null;\n        this.stackValueSources = null;\n        this.localVariableValueSources = null;\n        this.cellVariableValueSources = null;\n        this.callKeywordNameList = null;\n    }\n\n    public StackMetadata(LocalVariableHelper localVariableHelper) {\n        this.localVariableHelper = localVariableHelper;\n        this.stackValueSources = new ArrayList<>();\n        this.localVariableValueSources = new ArrayList<>(localVariableHelper.getNumberOfLocalVariables());\n        this.cellVariableValueSources = new ArrayList<>(localVariableHelper.getNumberOfCells());\n        for (int i = 0; i < localVariableHelper.getNumberOfLocalVariables(); i++) {\n            localVariableValueSources.add(null);\n        }\n        for (int i = 0; i < localVariableHelper.getNumberOfCells(); i++) {\n            cellVariableValueSources.add(ValueSourceInfo.of(new OpcodeWithoutSource(),\n                    BuiltinTypes.BASE_TYPE));\n        }\n        this.callKeywordNameList = Collections.emptyList();\n    }\n\n    private StackMetadata(LocalVariableHelper localVariableHelper, List<ValueSourceInfo> stackValueSources,\n            List<ValueSourceInfo> localVariableValueSources, List<ValueSourceInfo> cellVariableValueSources,\n            List<String> callKeywordNameList) {\n        this.localVariableHelper = localVariableHelper;\n        this.stackValueSources = stackValueSources;\n        this.localVariableValueSources = localVariableValueSources;\n        this.cellVariableValueSources = cellVariableValueSources;\n        this.callKeywordNameList = callKeywordNameList;\n    }\n\n    public boolean isDeadCode() {\n        return this == DEAD_CODE;\n    }\n\n    public int getStackSize() {\n        return stackValueSources.size();\n    }\n\n    /**\n     * Returns the list index for the given stack index (stack index is how many\n     * elements below TOS (i.e. 0 is TOS, 1 is TOS1)).\n     *\n     * @param stackIndex The stack index (how many elements below TOS)\n     * @return The corresponding list index corresponding to the element at the given distance from TOS\n     *         (i.e. STACK_SIZE - distance - 1)\n     */\n    private int getListIndexForStackIndex(int stackIndex) {\n        return stackValueSources.size() - stackIndex - 1;\n    }\n\n    /**\n     * Returns the value source for the given stack index (stack index is how many\n     * elements below TOS (i.e. 0 is TOS, 1 is TOS1)).\n     *\n     * @param index The stack index (how many elements below TOS)\n     * @return The type at the given stack index\n     */\n    public ValueSourceInfo getValueSourceForStackIndex(int index) {\n        return stackValueSources.get(getListIndexForStackIndex(index));\n    }\n\n    /**\n     * Returns the value sources up to (and not including) the given stack index (stack index is how many\n     * elements below TOS (i.e. 0 is TOS, 1 is TOS1)).\n     *\n     * @param index The stack index (how many elements below TOS)\n     * @return The value sources up to (and not including) the given stack index\n     */\n    public List<ValueSourceInfo> getValueSourcesUpToStackIndex(int index) {\n        return stackValueSources.subList(stackValueSources.size() - index, stackValueSources.size());\n    }\n\n    /**\n     * Returns the type at the given stack index (stack index is how many\n     * elements below TOS (i.e. 0 is TOS, 1 is TOS1)).\n     *\n     * @param index The stack index (how many elements below TOS)\n     * @return The type at the given stack index\n     */\n    public PythonLikeType getTypeAtStackIndex(int index) {\n        ValueSourceInfo valueSourceInfo = stackValueSources.get(getListIndexForStackIndex(index));\n        if (valueSourceInfo != null) {\n            return valueSourceInfo.valueType;\n        }\n        // Unknown type\n        return BuiltinTypes.BASE_TYPE;\n    }\n\n    /**\n     * Returns the value source for the local variable in slot {@code index}\n     *\n     * @param index The slot\n     * @return The type for the local variable in the given slot\n     */\n    public ValueSourceInfo getLocalVariableValueSource(int index) {\n        return localVariableValueSources.get(index);\n    }\n\n    /**\n     * Returns the value source for the cell variable in slot {@code index}\n     *\n     * @param index The slot\n     * @return The type for the cell variable in the given slot\n     */\n    public ValueSourceInfo getCellVariableValueSource(int index) {\n        return cellVariableValueSources.get(index);\n    }\n\n    public PythonLikeType getTOSType() {\n        return getTypeAtStackIndex(0);\n    }\n\n    public ValueSourceInfo getTOSValueSource() {\n        return getValueSourceForStackIndex(0);\n    }\n\n    public StackMetadata copy() {\n        StackMetadata out = new StackMetadata(localVariableHelper, new ArrayList<>(stackValueSources),\n                new ArrayList<>(localVariableValueSources),\n                new ArrayList<>(cellVariableValueSources),\n                callKeywordNameList);\n        return out;\n    }\n\n    public StackMetadata unifyWith(StackMetadata other) {\n        if (this == DEAD_CODE) {\n            return other;\n        }\n\n        if (other == DEAD_CODE) {\n            return this;\n        }\n\n        StackMetadata out = copy();\n        if (out.stackValueSources.size() != other.stackValueSources.size() ||\n                out.localVariableValueSources.size() != other.localVariableValueSources.size() ||\n                out.cellVariableValueSources.size() != other.cellVariableValueSources.size()) {\n            throw new IllegalArgumentException(\"Impossible State: Bytecode stack metadata size does not match when \" +\n                    \"unifying (\" + out.stackValueSources.stream()\n                            .map(valueSource -> valueSource.valueType.toString()).collect(Collectors.joining(\", \", \"[\", \"]\"))\n                    +\n                    \") with (\" + other.stackValueSources.stream()\n                            .map(valueSource -> valueSource.valueType.toString()).collect(Collectors.joining(\", \", \"[\", \"]\"))\n                    + \")\");\n        }\n\n        for (int i = 0; i < out.stackValueSources.size(); i++) {\n            out.stackValueSources.set(i, unifyTypes(stackValueSources.get(i), other.stackValueSources.get(i)));\n        }\n\n        for (int i = 0; i < out.localVariableValueSources.size(); i++) {\n            out.localVariableValueSources.set(i,\n                    unifyTypes(localVariableValueSources.get(i), other.localVariableValueSources.get(i)));\n        }\n\n        for (int i = 0; i < out.cellVariableValueSources.size(); i++) {\n            out.cellVariableValueSources.set(i,\n                    unifyTypes(cellVariableValueSources.get(i), other.cellVariableValueSources.get(i)));\n        }\n\n        return out;\n    }\n\n    private static ValueSourceInfo unifyTypes(ValueSourceInfo a, ValueSourceInfo b) {\n        if (Objects.equals(a, b)) {\n            return a;\n        }\n\n        if (a == null) { // a or b are null when they are deleted/are not set yet\n            return b; // TODO: Optional type?\n        }\n\n        if (b == null) {\n            return a;\n        }\n\n        return a.unifyWith(b);\n    }\n\n    /**\n     * Return a new StackMetadata with {@code type} added as the new\n     * TOS element.\n     *\n     * @param type The type to push to TOS\n     */\n    public StackMetadata push(ValueSourceInfo type) {\n        StackMetadata out = copy();\n        out.stackValueSources.add(type);\n        return out;\n    }\n\n    public StackMetadata set(int index, ValueSourceInfo type) {\n        StackMetadata out = copy();\n        out.stackValueSources.set(getListIndexForStackIndex(index), type);\n        return out;\n    }\n\n    public StackMetadata pushTemp(PythonLikeType type) {\n        return push(ValueSourceInfo.of(new OpcodeWithoutSource(), type));\n    }\n\n    /**\n     * Return a new StackMetadata with {@code types} added as the new\n     * elements. The last element of {@code types} is TOS.\n     *\n     * @param types The types to push to TOS\n     */\n    public StackMetadata push(ValueSourceInfo... types) {\n        StackMetadata out = copy();\n        out.stackValueSources.addAll(Arrays.asList(types));\n        return out;\n    }\n\n    public StackMetadata pushTemps(PythonLikeType... types) {\n        StackMetadata out = copy();\n        for (PythonLikeType type : types) {\n            out.stackValueSources.add(ValueSourceInfo.of(new OpcodeWithoutSource(), type));\n        }\n        return out;\n    }\n\n    /**\n     * Return a new StackMetadata with {@code types} as the stack;\n     * The original stack is cleared.\n     *\n     * @param types The stack types.\n     */\n\n\n\n\n\n\n\n    /**\n     * Return a new StackMetadata with TOS popped\n     */\n    public StackMetadata pop() {\n        StackMetadata out = copy();\n        out.stackValueSources.remove(stackValueSources.size() - 1);\n        return out;\n    }\n\n    /**\n     * Return a new StackMetadata with the top {@code count} items popped.\n     */\n    public StackMetadata pop(int count) {\n        StackMetadata out = copy();\n        out.stackValueSources.subList(stackValueSources.size() - count, stackValueSources.size()).clear();\n        return out;\n    }\n\n    /**\n     * Return a new StackMetadata with the local variable in slot {@code index} type set to\n     * {@code type}.\n     */\n    public StackMetadata setLocalVariableValueSource(int index, ValueSourceInfo type) {\n        StackMetadata out = copy();\n        out.localVariableValueSources.set(index, type);\n        return out;\n    }\n\n    /**\n     * Return a new StackMetadata with the given local types. Throws {@link IllegalArgumentException} if\n     * types.length != localVariableTypes.size().\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Return a new StackMetadata with the cell variable in slot {@code index} type set to\n     * {@code type}.\n     */\n    public StackMetadata setCellVariableValueSource(int index, ValueSourceInfo type) {\n        StackMetadata out = copy();\n        out.cellVariableValueSources.set(index, type);\n        return out;\n    }\n\n    public List<String> getCallKeywordNameList() {\n        return callKeywordNameList;\n    }\n\n    public StackMetadata setCallKeywordNameList(List<String> callKeywordNameList) {\n        StackMetadata out = copy();\n        out.callKeywordNameList = callKeywordNameList;\n        return out;\n    }\n\n    public String toString() {\n        return \"StackMetadata { stack: \" + stackValueSources.toString() + \"; locals: \" + localVariableValueSources.toString() +\n                \"; cells: \" + cellVariableValueSources.toString() + \"; }\";\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) {\n            return true;\n        }\n        if (o == null || getClass() != o.getClass()) {\n            return false;\n        }\n        if (this == DEAD_CODE || o == DEAD_CODE) {\n            return false; // this != o and one is DEAD_CODE\n        }\n\n        StackMetadata that = (StackMetadata) o;\n        return stackValueSources.equals(that.stackValueSources)\n                && localVariableValueSources.equals(that.localVariableValueSources)\n                && cellVariableValueSources.equals(that.cellVariableValueSources);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(stackValueSources, localVariableValueSources, cellVariableValueSources);\n    }\n}\n\n```\n# Function Signature: public StackMetadata stack(ValueSourceInfo... types) {\n# Natural Language Annotations: /**\n     * Return a new StackMetadata with {@code types} as the stack;\n     * The original stack is cleared.\n     *\n     * @param types The stack types.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic StackMetadata stack(ValueSourceInfo... types) {\n    StackMetadata out = copy();\n    out.stackValueSources.clear();\n    out.stackValueSources.addAll(Arrays.asList(types));\n    return out;\n}\n```", "  ```\npublic StackMetadata stack(ValueSourceInfo... types) {\n    StackMetadata out = copy();\n    out.stackValueSources.clear();\n    out.stackValueSources.addAll(Arrays.asList(types));\n    return out;\n}\n```", "  ```\npublic StackMetadata stack(ValueSourceInfo... types) {\n    StackMetadata out = copy();\n    out.stackValueSources.clear();\n    out.stackValueSources.addAll(Arrays.asList(types));\n    return out;\n}\n```"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/StackMetadata.java-locals": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/StackMetadata.java:\n```\npackage ai.timefold.jpyinterpreter;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.jpyinterpreter.opcodes.OpcodeWithoutSource;\nimport ai.timefold.jpyinterpreter.types.BuiltinTypes;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\n\npublic class StackMetadata {\n    public static final StackMetadata DEAD_CODE = new StackMetadata();\n\n    public final LocalVariableHelper localVariableHelper;\n\n    private final List<ValueSourceInfo> stackValueSources;\n    private final List<ValueSourceInfo> localVariableValueSources;\n    private final List<ValueSourceInfo> cellVariableValueSources;\n\n    private List<String> callKeywordNameList;\n\n    private StackMetadata() {\n        this.localVariableHelper = null;\n        this.stackValueSources = null;\n        this.localVariableValueSources = null;\n        this.cellVariableValueSources = null;\n        this.callKeywordNameList = null;\n    }\n\n    public StackMetadata(LocalVariableHelper localVariableHelper) {\n        this.localVariableHelper = localVariableHelper;\n        this.stackValueSources = new ArrayList<>();\n        this.localVariableValueSources = new ArrayList<>(localVariableHelper.getNumberOfLocalVariables());\n        this.cellVariableValueSources = new ArrayList<>(localVariableHelper.getNumberOfCells());\n        for (int i = 0; i < localVariableHelper.getNumberOfLocalVariables(); i++) {\n            localVariableValueSources.add(null);\n        }\n        for (int i = 0; i < localVariableHelper.getNumberOfCells(); i++) {\n            cellVariableValueSources.add(ValueSourceInfo.of(new OpcodeWithoutSource(),\n                    BuiltinTypes.BASE_TYPE));\n        }\n        this.callKeywordNameList = Collections.emptyList();\n    }\n\n    private StackMetadata(LocalVariableHelper localVariableHelper, List<ValueSourceInfo> stackValueSources,\n            List<ValueSourceInfo> localVariableValueSources, List<ValueSourceInfo> cellVariableValueSources,\n            List<String> callKeywordNameList) {\n        this.localVariableHelper = localVariableHelper;\n        this.stackValueSources = stackValueSources;\n        this.localVariableValueSources = localVariableValueSources;\n        this.cellVariableValueSources = cellVariableValueSources;\n        this.callKeywordNameList = callKeywordNameList;\n    }\n\n    public boolean isDeadCode() {\n        return this == DEAD_CODE;\n    }\n\n    public int getStackSize() {\n        return stackValueSources.size();\n    }\n\n    /**\n     * Returns the list index for the given stack index (stack index is how many\n     * elements below TOS (i.e. 0 is TOS, 1 is TOS1)).\n     *\n     * @param stackIndex The stack index (how many elements below TOS)\n     * @return The corresponding list index corresponding to the element at the given distance from TOS\n     *         (i.e. STACK_SIZE - distance - 1)\n     */\n    private int getListIndexForStackIndex(int stackIndex) {\n        return stackValueSources.size() - stackIndex - 1;\n    }\n\n    /**\n     * Returns the value source for the given stack index (stack index is how many\n     * elements below TOS (i.e. 0 is TOS, 1 is TOS1)).\n     *\n     * @param index The stack index (how many elements below TOS)\n     * @return The type at the given stack index\n     */\n    public ValueSourceInfo getValueSourceForStackIndex(int index) {\n        return stackValueSources.get(getListIndexForStackIndex(index));\n    }\n\n    /**\n     * Returns the value sources up to (and not including) the given stack index (stack index is how many\n     * elements below TOS (i.e. 0 is TOS, 1 is TOS1)).\n     *\n     * @param index The stack index (how many elements below TOS)\n     * @return The value sources up to (and not including) the given stack index\n     */\n    public List<ValueSourceInfo> getValueSourcesUpToStackIndex(int index) {\n        return stackValueSources.subList(stackValueSources.size() - index, stackValueSources.size());\n    }\n\n    /**\n     * Returns the type at the given stack index (stack index is how many\n     * elements below TOS (i.e. 0 is TOS, 1 is TOS1)).\n     *\n     * @param index The stack index (how many elements below TOS)\n     * @return The type at the given stack index\n     */\n    public PythonLikeType getTypeAtStackIndex(int index) {\n        ValueSourceInfo valueSourceInfo = stackValueSources.get(getListIndexForStackIndex(index));\n        if (valueSourceInfo != null) {\n            return valueSourceInfo.valueType;\n        }\n        // Unknown type\n        return BuiltinTypes.BASE_TYPE;\n    }\n\n    /**\n     * Returns the value source for the local variable in slot {@code index}\n     *\n     * @param index The slot\n     * @return The type for the local variable in the given slot\n     */\n    public ValueSourceInfo getLocalVariableValueSource(int index) {\n        return localVariableValueSources.get(index);\n    }\n\n    /**\n     * Returns the value source for the cell variable in slot {@code index}\n     *\n     * @param index The slot\n     * @return The type for the cell variable in the given slot\n     */\n    public ValueSourceInfo getCellVariableValueSource(int index) {\n        return cellVariableValueSources.get(index);\n    }\n\n    public PythonLikeType getTOSType() {\n        return getTypeAtStackIndex(0);\n    }\n\n    public ValueSourceInfo getTOSValueSource() {\n        return getValueSourceForStackIndex(0);\n    }\n\n    public StackMetadata copy() {\n        StackMetadata out = new StackMetadata(localVariableHelper, new ArrayList<>(stackValueSources),\n                new ArrayList<>(localVariableValueSources),\n                new ArrayList<>(cellVariableValueSources),\n                callKeywordNameList);\n        return out;\n    }\n\n    public StackMetadata unifyWith(StackMetadata other) {\n        if (this == DEAD_CODE) {\n            return other;\n        }\n\n        if (other == DEAD_CODE) {\n            return this;\n        }\n\n        StackMetadata out = copy();\n        if (out.stackValueSources.size() != other.stackValueSources.size() ||\n                out.localVariableValueSources.size() != other.localVariableValueSources.size() ||\n                out.cellVariableValueSources.size() != other.cellVariableValueSources.size()) {\n            throw new IllegalArgumentException(\"Impossible State: Bytecode stack metadata size does not match when \" +\n                    \"unifying (\" + out.stackValueSources.stream()\n                            .map(valueSource -> valueSource.valueType.toString()).collect(Collectors.joining(\", \", \"[\", \"]\"))\n                    +\n                    \") with (\" + other.stackValueSources.stream()\n                            .map(valueSource -> valueSource.valueType.toString()).collect(Collectors.joining(\", \", \"[\", \"]\"))\n                    + \")\");\n        }\n\n        for (int i = 0; i < out.stackValueSources.size(); i++) {\n            out.stackValueSources.set(i, unifyTypes(stackValueSources.get(i), other.stackValueSources.get(i)));\n        }\n\n        for (int i = 0; i < out.localVariableValueSources.size(); i++) {\n            out.localVariableValueSources.set(i,\n                    unifyTypes(localVariableValueSources.get(i), other.localVariableValueSources.get(i)));\n        }\n\n        for (int i = 0; i < out.cellVariableValueSources.size(); i++) {\n            out.cellVariableValueSources.set(i,\n                    unifyTypes(cellVariableValueSources.get(i), other.cellVariableValueSources.get(i)));\n        }\n\n        return out;\n    }\n\n    private static ValueSourceInfo unifyTypes(ValueSourceInfo a, ValueSourceInfo b) {\n        if (Objects.equals(a, b)) {\n            return a;\n        }\n\n        if (a == null) { // a or b are null when they are deleted/are not set yet\n            return b; // TODO: Optional type?\n        }\n\n        if (b == null) {\n            return a;\n        }\n\n        return a.unifyWith(b);\n    }\n\n    /**\n     * Return a new StackMetadata with {@code type} added as the new\n     * TOS element.\n     *\n     * @param type The type to push to TOS\n     */\n    public StackMetadata push(ValueSourceInfo type) {\n        StackMetadata out = copy();\n        out.stackValueSources.add(type);\n        return out;\n    }\n\n    public StackMetadata set(int index, ValueSourceInfo type) {\n        StackMetadata out = copy();\n        out.stackValueSources.set(getListIndexForStackIndex(index), type);\n        return out;\n    }\n\n    public StackMetadata pushTemp(PythonLikeType type) {\n        return push(ValueSourceInfo.of(new OpcodeWithoutSource(), type));\n    }\n\n    /**\n     * Return a new StackMetadata with {@code types} added as the new\n     * elements. The last element of {@code types} is TOS.\n     *\n     * @param types The types to push to TOS\n     */\n    public StackMetadata push(ValueSourceInfo... types) {\n        StackMetadata out = copy();\n        out.stackValueSources.addAll(Arrays.asList(types));\n        return out;\n    }\n\n    public StackMetadata pushTemps(PythonLikeType... types) {\n        StackMetadata out = copy();\n        for (PythonLikeType type : types) {\n            out.stackValueSources.add(ValueSourceInfo.of(new OpcodeWithoutSource(), type));\n        }\n        return out;\n    }\n\n    /**\n     * Return a new StackMetadata with {@code types} as the stack;\n     * The original stack is cleared.\n     *\n     * @param types The stack types.\n     */\n\n\n\n\n\n\n\n    /**\n     * Return a new StackMetadata with TOS popped\n     */\n    public StackMetadata pop() {\n        StackMetadata out = copy();\n        out.stackValueSources.remove(stackValueSources.size() - 1);\n        return out;\n    }\n\n    /**\n     * Return a new StackMetadata with the top {@code count} items popped.\n     */\n    public StackMetadata pop(int count) {\n        StackMetadata out = copy();\n        out.stackValueSources.subList(stackValueSources.size() - count, stackValueSources.size()).clear();\n        return out;\n    }\n\n    /**\n     * Return a new StackMetadata with the local variable in slot {@code index} type set to\n     * {@code type}.\n     */\n    public StackMetadata setLocalVariableValueSource(int index, ValueSourceInfo type) {\n        StackMetadata out = copy();\n        out.localVariableValueSources.set(index, type);\n        return out;\n    }\n\n    /**\n     * Return a new StackMetadata with the given local types. Throws {@link IllegalArgumentException} if\n     * types.length != localVariableTypes.size().\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Return a new StackMetadata with the cell variable in slot {@code index} type set to\n     * {@code type}.\n     */\n    public StackMetadata setCellVariableValueSource(int index, ValueSourceInfo type) {\n        StackMetadata out = copy();\n        out.cellVariableValueSources.set(index, type);\n        return out;\n    }\n\n    public List<String> getCallKeywordNameList() {\n        return callKeywordNameList;\n    }\n\n    public StackMetadata setCallKeywordNameList(List<String> callKeywordNameList) {\n        StackMetadata out = copy();\n        out.callKeywordNameList = callKeywordNameList;\n        return out;\n    }\n\n    public String toString() {\n        return \"StackMetadata { stack: \" + stackValueSources.toString() + \"; locals: \" + localVariableValueSources.toString() +\n                \"; cells: \" + cellVariableValueSources.toString() + \"; }\";\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) {\n            return true;\n        }\n        if (o == null || getClass() != o.getClass()) {\n            return false;\n        }\n        if (this == DEAD_CODE || o == DEAD_CODE) {\n            return false; // this != o and one is DEAD_CODE\n        }\n\n        StackMetadata that = (StackMetadata) o;\n        return stackValueSources.equals(that.stackValueSources)\n                && localVariableValueSources.equals(that.localVariableValueSources)\n                && cellVariableValueSources.equals(that.cellVariableValueSources);\n    }\n\n    @Override\n    public int hashCode() {\n        return Objects.hash(stackValueSources, localVariableValueSources, cellVariableValueSources);\n    }\n}\n\n```\n# Function Signature: public StackMetadata locals(ValueSourceInfo... types) {\n# Natural Language Annotations: /**\n     * Return a new StackMetadata with the given local types. Throws {@link IllegalArgumentException} if\n     * types.length != localVariableTypes.size().\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic StackMetadata locals(ValueSourceInfo... types) {\n    if (types.length != localVariableHelper.getNumberOfLocalVariables()) {\n        throw new IllegalArgumentException(\"locals() types array length must match number of local variables in LocalVariableHelper\");\n    }\n    StackMetadata out = copy();\n    for (int i = 0; i < types.length; i++) {\n        out.localVariableValueSources.set(i, types[i]);\n    }\n    return out;\n}\n```", "  ```\npublic StackMetadata locals(ValueSourceInfo... types) {\n    if (types.length != localVariableHelper.getNumberOfLocalVariables()) {\n        throw new IllegalArgumentException(\"The argument types have a wrong number of elements. Expected \"\n                + localVariableHelper.getNumberOfLocalVariables() + \" but got \" + types.length);\n    }\n    StackMetadata out = copy();\n    for (int i = 0; i < types.length; i++) {\n        out.localVariableValueSources.set(i, types[i]);\n    }\n    return out;\n}\n```", "  ```\npublic StackMetadata locals(ValueSourceInfo... types) {\n    if (localVariableHelper.getNumberOfLocalVariables() == types.length) {\n        StackMetadata out = copy();\n        for (int i = 0; i < localVariableHelper.getNumberOfLocalVariables(); i++) {\n            out.stackValueSources.set(i, types[i]);\n        }\n        return out;\n    } else {\n        throw new IllegalArgumentException(\"StackMetadata.locals(): types.length != localVariableHelper.getNumberOfLocalVariables()\");\n    }\n}\n```"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-loadMethod": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java:\n```\npackage ai.timefold.jpyinterpreter.implementors;\n\nimport java.lang.reflect.Constructor;\nimport java.lang.reflect.InvocationTargetException;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.jpyinterpreter.FunctionMetadata;\nimport ai.timefold.jpyinterpreter.LocalVariableHelper;\nimport ai.timefold.jpyinterpreter.PythonBytecodeInstruction;\nimport ai.timefold.jpyinterpreter.PythonBytecodeToJavaBytecodeTranslator;\nimport ai.timefold.jpyinterpreter.PythonCompiledFunction;\nimport ai.timefold.jpyinterpreter.PythonInterpreter;\nimport ai.timefold.jpyinterpreter.PythonLikeObject;\nimport ai.timefold.jpyinterpreter.PythonVersion;\nimport ai.timefold.jpyinterpreter.StackMetadata;\nimport ai.timefold.jpyinterpreter.ValueSourceInfo;\nimport ai.timefold.jpyinterpreter.types.BuiltinTypes;\nimport ai.timefold.jpyinterpreter.types.PythonCode;\nimport ai.timefold.jpyinterpreter.types.PythonKnownFunctionType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeFunction;\nimport ai.timefold.jpyinterpreter.types.PythonLikeGenericType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\nimport ai.timefold.jpyinterpreter.types.PythonString;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeDict;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeTuple;\n\nimport org.objectweb.asm.Label;\nimport org.objectweb.asm.MethodVisitor;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\n\n/**\n * Implements opcodes related to functions\n */\npublic class FunctionImplementor {\n\n    public static void callBinaryMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callBinaryMethod(MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n    private static void loadGenericMethod(FunctionMetadata functionMetadata, MethodVisitor methodVisitor, String className,\n            PythonCompiledFunction function,\n            StackMetadata stackMetadata, int nameIndex) {\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(function.co_names.get(nameIndex));\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n                \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        Label blockEnd = new Label();\n\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n\n        // TOS is null; type does not have attribute; do normal attribute lookup\n        // Stack is object, null\n        methodVisitor.visitInsn(Opcodes.POP);\n        ObjectImplementor.getAttribute(functionMetadata, stackMetadata, nameIndex);\n\n        // Stack is method\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n            // Python 3.11+ swap these\n            methodVisitor.visitInsn(Opcodes.SWAP);\n        }\n\n        methodVisitor.visitLabel(blockEnd);\n\n        // Stack is either:\n        // object, method if it was in type\n        // null, method if it was not in type (Or method, null if Python 3.11+)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is now:\n        // method, object if it was in type\n        // method, null if it was not in type (and prior to Python 3.11+)\n        // null, method if it was not in type (if Python 3.11+)\n    }\n\n    public static void setCallKeywordNameTuple(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            int constantIndex) {\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n        PythonConstantsImplementor.loadConstant(functionMetadata.methodVisitor, functionMetadata.className, constantIndex);\n        localVariableHelper.writeCallKeywords(functionMetadata.methodVisitor);\n    }\n\n    /**\n     * Calls a function. argc is the number of positional arguments. Keyword arguments are stored in a local variable.\n     * Keyword arguments (if any) are at the top of the stack, followed by, positional arguments.\n     * Below them either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n    public static void call(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int argumentCount) {\n        PythonLikeType functionType = stackMetadata.getTypeAtStackIndex(argumentCount + 1);\n        if (functionType instanceof PythonLikeGenericType) {\n            functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n        }\n        if (functionType instanceof PythonKnownFunctionType) {\n            PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n            List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n            List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                    .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n            knownFunctionType\n                    .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                            callStackParameterTypes)\n                    .ifPresentOrElse(functionSignature -> {\n                        KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                argumentCount,\n                                stackMetadata.getCallKeywordNameList());\n                    }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n        } else {\n            functionType = stackMetadata.getTypeAtStackIndex(argumentCount);\n            if (functionType instanceof PythonLikeGenericType) {\n                functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n            }\n            if (functionType instanceof PythonKnownFunctionType) {\n                PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n                List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n                List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                        .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n                knownFunctionType\n                        .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                                callStackParameterTypes)\n                        .ifPresentOrElse(functionSignature -> {\n                            KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                    argumentCount,\n                                    stackMetadata.getCallKeywordNameList());\n                        }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n            } else {\n                callGeneric(functionMetadata, stackMetadata, argumentCount);\n            }\n        }\n    }\n\n    private static void callGeneric(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            int argumentCount) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        int keywordArgs = localVariableHelper.newLocal();\n        int positionalArgs = localVariableHelper.newLocal();\n\n        localVariableHelper.readCallKeywords(methodVisitor);\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, argumentCount + 1);\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is (null or method), (obj or method)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is (obj or method) (null or method)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is obj, method\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, obj\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitLabel(blockEnd);\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is method, positionalArgs, keywordArgs\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n\n        localVariableHelper.resetCallKeywords(methodVisitor);\n        localVariableHelper.freeLocal();\n        localVariableHelper.freeLocal();\n    }\n\n    /**\n     * Calls a method. argc is the number of positional arguments. Keyword arguments are not supported.\n     * This opcode is designed to be used with LOAD_METHOD. Positional arguments are on top of the stack.\n     * Below them, the two items described in LOAD_METHOD are on the stack\n     * (either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private static void callGenericMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor,\n            PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        // Stack is method, (obj or null), arg0, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, instruction.arg());\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, (obj or null)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is method, argList, obj\n        StackManipulationImplementor.duplicateToTOS(functionMetadata, stackMetadata, 1);\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, argList, argList, obj\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method, argList\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, argList, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method, argList\n        methodVisitor.visitLabel(blockEnd);\n\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        // Stack is method, argList\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS...TOS[argc - 1] are the arguments to the function.\n     * TOS[argc] is the function to call. TOS...TOS[argc] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        callGenericFunction(functionMetadata, stackMetadata, methodVisitor, instruction.arg());\n    }\n\n    public static void callGenericFunction(MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n    public static void callGenericFunctionWithKeywords(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        // stack is callable, arg0, arg1, ..., arg(argc - len(keys)), ..., arg(argc - 1), keys\n        // We know the total number of arguments, but not the number of individual positional/keyword arguments\n        // Since Java Bytecode require consistent stack frames  (i.e. the body of a loop must start with\n        // the same number of elements in the stack), we need to add the tuple/map in the same object\n        // which will delegate it to either the tuple or the map depending on position and the first item size\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, instruction.arg() + 1);\n\n        // stack is callable, tupleMapPair\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n\n        // stack is callable, tupleMapPair, positionalArgs\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. If the lowest bit of instruction.arg is set, TOS is a mapping object containing keyword\n     * arguments, TOS[1] is an iterable containing positional arguments and TOS[2] is callable. Otherwise,\n     * TOS is an iterable containing positional arguments and TOS[1] is callable.\n     */\n\n\n\n\n\n\n\n\n\n    public static void callFunctionUnpackMapAndIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    public static void callFunctionUnpackIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    private static void getCallerInstance\n```\n# Function Signature: public static void loadMethod(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n# Natural Language Annotations: /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void loadMethod(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int nameIndex) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n\n    methodVisitor.visitInsn(Opcodes.SWAP);\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n            \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n            true);\n    methodVisitor.visitLdcInsn(functionMetadata.pythonCompiledFunction.co_names.get(nameIndex));\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n            \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(String.class)),\n            false);\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n    Label blockEnd = new Label();\n\n    methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n\n    // TOS is null; type does not have attribute; do normal attribute lookup\n    // Stack is object, null\n    methodVisitor.visitInsn(Opcodes.POP);\n    ObjectImplementor.getAttribute(functionMetadata, stackMetadata, nameIndex);\n\n    // Stack is method\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n    if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n        // Python 3.11+ swap these\n        methodVisitor.visitInsn(Opcodes.SWAP);\n    }\n\n    methodVisitor.visitLabel(blockEnd);\n\n    // Stack is either:\n    // object, method if it was in type\n    // null, method if it was not in type (Or method, null if Python 3.11+)\n    // null, method if it was not in type (if Python 3.11+)\n    methodVisitor.visitInsn(Opcodes.SWAP);\n\n    // Stack is now:\n    // method, object if it was in type\n    // method, null if it was not in type (and prior to Python 3.11+)\n    // null, method if it was not in type (if Python 3.11+)\n}\n```", "  ```\npublic static void loadMethod(FunctionMetadata functionMetadata, StackMetadata stackMetadata, String methodName) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n            \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n            true);\n    methodVisitor.visitLdcInsn(methodName);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n            \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(String.class)),\n            false);\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n    Label blockEnd = new Label();\n    methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n    methodVisitor.visitInsn(Opcodes.POP);\n    ObjectImplementor.getAttribute(functionMetadata, stackMetadata, methodName);\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n    if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n    }\n    methodVisitor.visitLabel(blockEnd);\n    methodVisitor.visitInsn(Opcodes.SWAP);\n}\n```", "  ```\nvoid loadMethod(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int nameIndex) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n            \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)), true);\n    methodVisitor.visitLdcInsn(functionMetadata.pythonCompiledFunction.co_names.get(nameIndex));\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n            \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(String.class)), false);\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n    Label blockEnd = new Label();\n\n    methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n\n    // TOS is null; type does not have attribute; do normal attribute lookup\n    // Stack is object, null\n    methodVisitor.visitInsn(Opcodes.POP);\n    ObjectImplementor.getAttribute(functionMetadata, stackMetadata, nameIndex);\n\n    // Stack is method\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n    if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n        // Python 3.11+ swap these\n        methodVisitor.visitInsn(Opcodes.SWAP);\n    }\n\n    methodVisitor.visitLabel(blockEnd);\n\n    // Stack is either:\n    // object, method if it was in type\n    // null, method if it was not in type (Or method, null if Python 3.11+)\n    // null, method if it was not in type (if Python 3.11+)\n}\n```"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callMethod": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java:\n```\npackage ai.timefold.jpyinterpreter.implementors;\n\nimport java.lang.reflect.Constructor;\nimport java.lang.reflect.InvocationTargetException;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.jpyinterpreter.FunctionMetadata;\nimport ai.timefold.jpyinterpreter.LocalVariableHelper;\nimport ai.timefold.jpyinterpreter.PythonBytecodeInstruction;\nimport ai.timefold.jpyinterpreter.PythonBytecodeToJavaBytecodeTranslator;\nimport ai.timefold.jpyinterpreter.PythonCompiledFunction;\nimport ai.timefold.jpyinterpreter.PythonInterpreter;\nimport ai.timefold.jpyinterpreter.PythonLikeObject;\nimport ai.timefold.jpyinterpreter.PythonVersion;\nimport ai.timefold.jpyinterpreter.StackMetadata;\nimport ai.timefold.jpyinterpreter.ValueSourceInfo;\nimport ai.timefold.jpyinterpreter.types.BuiltinTypes;\nimport ai.timefold.jpyinterpreter.types.PythonCode;\nimport ai.timefold.jpyinterpreter.types.PythonKnownFunctionType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeFunction;\nimport ai.timefold.jpyinterpreter.types.PythonLikeGenericType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\nimport ai.timefold.jpyinterpreter.types.PythonString;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeDict;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeTuple;\n\nimport org.objectweb.asm.Label;\nimport org.objectweb.asm.MethodVisitor;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\n\n/**\n * Implements opcodes related to functions\n */\npublic class FunctionImplementor {\n\n    public static void callBinaryMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callBinaryMethod(MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n    private static void loadGenericMethod(FunctionMetadata functionMetadata, MethodVisitor methodVisitor, String className,\n            PythonCompiledFunction function,\n            StackMetadata stackMetadata, int nameIndex) {\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(function.co_names.get(nameIndex));\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n                \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        Label blockEnd = new Label();\n\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n\n        // TOS is null; type does not have attribute; do normal attribute lookup\n        // Stack is object, null\n        methodVisitor.visitInsn(Opcodes.POP);\n        ObjectImplementor.getAttribute(functionMetadata, stackMetadata, nameIndex);\n\n        // Stack is method\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n            // Python 3.11+ swap these\n            methodVisitor.visitInsn(Opcodes.SWAP);\n        }\n\n        methodVisitor.visitLabel(blockEnd);\n\n        // Stack is either:\n        // object, method if it was in type\n        // null, method if it was not in type (Or method, null if Python 3.11+)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is now:\n        // method, object if it was in type\n        // method, null if it was not in type (and prior to Python 3.11+)\n        // null, method if it was not in type (if Python 3.11+)\n    }\n\n    public static void setCallKeywordNameTuple(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            int constantIndex) {\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n        PythonConstantsImplementor.loadConstant(functionMetadata.methodVisitor, functionMetadata.className, constantIndex);\n        localVariableHelper.writeCallKeywords(functionMetadata.methodVisitor);\n    }\n\n    /**\n     * Calls a function. argc is the number of positional arguments. Keyword arguments are stored in a local variable.\n     * Keyword arguments (if any) are at the top of the stack, followed by, positional arguments.\n     * Below them either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n    public static void call(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int argumentCount) {\n        PythonLikeType functionType = stackMetadata.getTypeAtStackIndex(argumentCount + 1);\n        if (functionType instanceof PythonLikeGenericType) {\n            functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n        }\n        if (functionType instanceof PythonKnownFunctionType) {\n            PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n            List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n            List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                    .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n            knownFunctionType\n                    .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                            callStackParameterTypes)\n                    .ifPresentOrElse(functionSignature -> {\n                        KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                argumentCount,\n                                stackMetadata.getCallKeywordNameList());\n                    }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n        } else {\n            functionType = stackMetadata.getTypeAtStackIndex(argumentCount);\n            if (functionType instanceof PythonLikeGenericType) {\n                functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n            }\n            if (functionType instanceof PythonKnownFunctionType) {\n                PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n                List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n                List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                        .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n                knownFunctionType\n                        .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                                callStackParameterTypes)\n                        .ifPresentOrElse(functionSignature -> {\n                            KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                    argumentCount,\n                                    stackMetadata.getCallKeywordNameList());\n                        }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n            } else {\n                callGeneric(functionMetadata, stackMetadata, argumentCount);\n            }\n        }\n    }\n\n    private static void callGeneric(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            int argumentCount) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        int keywordArgs = localVariableHelper.newLocal();\n        int positionalArgs = localVariableHelper.newLocal();\n\n        localVariableHelper.readCallKeywords(methodVisitor);\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, argumentCount + 1);\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is (null or method), (obj or method)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is (obj or method) (null or method)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is obj, method\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, obj\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitLabel(blockEnd);\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is method, positionalArgs, keywordArgs\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n\n        localVariableHelper.resetCallKeywords(methodVisitor);\n        localVariableHelper.freeLocal();\n        localVariableHelper.freeLocal();\n    }\n\n    /**\n     * Calls a method. argc is the number of positional arguments. Keyword arguments are not supported.\n     * This opcode is designed to be used with LOAD_METHOD. Positional arguments are on top of the stack.\n     * Below them, the two items described in LOAD_METHOD are on the stack\n     * (either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private static void callGenericMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor,\n            PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        // Stack is method, (obj or null), arg0, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, instruction.arg());\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, (obj or null)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is method, argList, obj\n        StackManipulationImplementor.duplicateToTOS(functionMetadata, stackMetadata, 1);\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, argList, argList, obj\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method, argList\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, argList, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method, argList\n        methodVisitor.visitLabel(blockEnd);\n\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        // Stack is method, argList\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS...TOS[argc - 1] are the arguments to the function.\n     * TOS[argc] is the function to call. TOS...TOS[argc] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        callGenericFunction(functionMetadata, stackMetadata, methodVisitor, instruction.arg());\n    }\n\n    public static void callGenericFunction(MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n    public static void callGenericFunctionWithKeywords(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        // stack is callable, arg0, arg1, ..., arg(argc - len(keys)), ..., arg(argc - 1), keys\n        // We know the total number of arguments, but not the number of individual positional/keyword arguments\n        // Since Java Bytecode require consistent stack frames  (i.e. the body of a loop must start with\n        // the same number of elements in the stack), we need to add the tuple/map in the same object\n        // which will delegate it to either the tuple or the map depending on position and the first item size\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, instruction.arg() + 1);\n\n        // stack is callable, tupleMapPair\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n\n        // stack is callable, tupleMapPair, positionalArgs\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. If the lowest bit of instruction.arg is set, TOS is a mapping object containing keyword\n     * arguments, TOS[1] is an iterable containing positional arguments and TOS[2] is callable. Otherwise,\n     * TOS is an iterable containing positional arguments and TOS[1] is callable.\n     */\n\n\n\n\n\n\n\n\n\n    public static void callFunctionUnpackMapAndIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    public static void callFunctionUnpackIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    private static void getCallerInstance\n```\n# Function Signature: public static void callMethod(FunctionMetadata functionMetadata, StackMetadata stackMetadata, MethodVisitor methodVisitor,\n# Natural Language Annotations: /**\n     * Calls a method. argc is the number of positional arguments. Keyword arguments are not supported.\n     * This opcode is designed to be used with LOAD_METHOD. Positional arguments are on top of the stack.\n     * Below them, the two items described in LOAD_METHOD are on the stack\n     * (either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void callMethod(FunctionMetadata functionMetadata, StackMetadata stackMetadata, MethodVisitor methodVisitor) {\n    // Stack is method, (obj or null), arg0, ..., arg(argc - 1)\n    CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argc);\n    methodVisitor.visitInsn(Opcodes.SWAP);\n\n    // Stack is method, argList, (obj or null)\n    Label ifNullStart = new Label();\n    Label blockEnd = new Label();\n\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n    methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n    // Stack is method, argList, obj\n    StackManipulationImplementor.duplicateToTOS(functionMetadata, stackMetadata, 1);\n    StackManipulationImplementor.swap(methodVisitor);\n\n    // Stack is method, argList, argList, obj\n    methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n    // Stack is method, argList, argList, obj, index\n    methodVisitor.visitInsn(Opcodes.SWAP);\n\n    // Stack is method, argList, argList, index, obj\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n            \"add\",\n            Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n            true);\n\n    // Stack is method, argList\n    methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n    methodVisitor.visitLabel(ifNullStart);\n    // Stack is method, argList, null\n    methodVisitor.visitInsn(Opcodes.POP);\n\n    // Stack is method, argList\n    methodVisitor.visitLabel(blockEnd);\n\n    methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n            Type.getMethodDescriptor(Type.getType(Map.class)),\n            false);\n\n    // Stack is method, argList\n    getCallerInstance(functionMetadata, stackMetadata);\n\n    // Stack is callable, argument_list, null\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n            \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(List.class),\n                    Type.getType(Map.class),\n                    Type.getType(PythonLikeObject.class)),", "  ```\npackage ai.timefold.jpyinterpreter.implementors;\n\nimport java.lang.reflect.Constructor;\nimport java.lang.reflect.InvocationTargetException;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.jpyinterpreter.FunctionMetadata;\nimport ai.timefold.jpyinterpreter.LocalVariableHelper;\nimport ai.timefold.jpyinterpreter.PythonBytecodeInstruction;\nimport ai.timefold.jpyinterpreter.PythonCompiledFunction;\nimport ai.timefold.jpyinterpreter.PythonInterpreter;\nimport ai.timefold.jpyinterpreter.PythonLikeObject;\nimport ai.timefold.jpyinterpreter.PythonVersion;\nimport ai.timefold.jpyinterpreter.StackMetadata;\nimport ai.timefold.jpyinterpreter.ValueSourceInfo;\nimport ai.timefold.jpyinterpreter.types.BuiltinTypes;\nimport ai.timefold.jpyinterpreter.types.PythonCode;\nimport ai.timefold.jpyinterpreter.types.PythonKnownFunctionType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeFunction;\nimport ai.timefold.jpyinterpreter.types.PythonLikeGenericType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\nimport ai.timefold.jpyinterpreter.types.PythonString;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeDict;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeTuple;\n\nimport org.objectweb.asm.Label;\nimport org.objectweb.asm.MethodVisitor;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\n\n/**\n * Implements opcodes related to functions\n */\npublic class FunctionImplementor {\n\n    public static void callMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.", "  ```\n    public static void callMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata, MethodVisitor methodVisitor, int argc) {\n\n        // Stack is method, (obj or null), arg0, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argc);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, (obj or null)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is method, argList, obj\n        StackManipulationImplementor.duplicateToTOS(functionMetadata, stackMetadata, 1);\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, argList, argList, obj\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method, argList\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, argList, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method, argList\n        methodVisitor.visitLabel(blockEnd);\n\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        // Stack is method, argList\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.get"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callFunction": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java:\n```\npackage ai.timefold.jpyinterpreter.implementors;\n\nimport java.lang.reflect.Constructor;\nimport java.lang.reflect.InvocationTargetException;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.jpyinterpreter.FunctionMetadata;\nimport ai.timefold.jpyinterpreter.LocalVariableHelper;\nimport ai.timefold.jpyinterpreter.PythonBytecodeInstruction;\nimport ai.timefold.jpyinterpreter.PythonBytecodeToJavaBytecodeTranslator;\nimport ai.timefold.jpyinterpreter.PythonCompiledFunction;\nimport ai.timefold.jpyinterpreter.PythonInterpreter;\nimport ai.timefold.jpyinterpreter.PythonLikeObject;\nimport ai.timefold.jpyinterpreter.PythonVersion;\nimport ai.timefold.jpyinterpreter.StackMetadata;\nimport ai.timefold.jpyinterpreter.ValueSourceInfo;\nimport ai.timefold.jpyinterpreter.types.BuiltinTypes;\nimport ai.timefold.jpyinterpreter.types.PythonCode;\nimport ai.timefold.jpyinterpreter.types.PythonKnownFunctionType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeFunction;\nimport ai.timefold.jpyinterpreter.types.PythonLikeGenericType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\nimport ai.timefold.jpyinterpreter.types.PythonString;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeDict;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeTuple;\n\nimport org.objectweb.asm.Label;\nimport org.objectweb.asm.MethodVisitor;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\n\n/**\n * Implements opcodes related to functions\n */\npublic class FunctionImplementor {\n\n    public static void callBinaryMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callBinaryMethod(MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n    private static void loadGenericMethod(FunctionMetadata functionMetadata, MethodVisitor methodVisitor, String className,\n            PythonCompiledFunction function,\n            StackMetadata stackMetadata, int nameIndex) {\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(function.co_names.get(nameIndex));\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n                \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        Label blockEnd = new Label();\n\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n\n        // TOS is null; type does not have attribute; do normal attribute lookup\n        // Stack is object, null\n        methodVisitor.visitInsn(Opcodes.POP);\n        ObjectImplementor.getAttribute(functionMetadata, stackMetadata, nameIndex);\n\n        // Stack is method\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n            // Python 3.11+ swap these\n            methodVisitor.visitInsn(Opcodes.SWAP);\n        }\n\n        methodVisitor.visitLabel(blockEnd);\n\n        // Stack is either:\n        // object, method if it was in type\n        // null, method if it was not in type (Or method, null if Python 3.11+)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is now:\n        // method, object if it was in type\n        // method, null if it was not in type (and prior to Python 3.11+)\n        // null, method if it was not in type (if Python 3.11+)\n    }\n\n    public static void setCallKeywordNameTuple(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            int constantIndex) {\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n        PythonConstantsImplementor.loadConstant(functionMetadata.methodVisitor, functionMetadata.className, constantIndex);\n        localVariableHelper.writeCallKeywords(functionMetadata.methodVisitor);\n    }\n\n    /**\n     * Calls a function. argc is the number of positional arguments. Keyword arguments are stored in a local variable.\n     * Keyword arguments (if any) are at the top of the stack, followed by, positional arguments.\n     * Below them either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n    public static void call(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int argumentCount) {\n        PythonLikeType functionType = stackMetadata.getTypeAtStackIndex(argumentCount + 1);\n        if (functionType instanceof PythonLikeGenericType) {\n            functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n        }\n        if (functionType instanceof PythonKnownFunctionType) {\n            PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n            List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n            List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                    .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n            knownFunctionType\n                    .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                            callStackParameterTypes)\n                    .ifPresentOrElse(functionSignature -> {\n                        KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                argumentCount,\n                                stackMetadata.getCallKeywordNameList());\n                    }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n        } else {\n            functionType = stackMetadata.getTypeAtStackIndex(argumentCount);\n            if (functionType instanceof PythonLikeGenericType) {\n                functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n            }\n            if (functionType instanceof PythonKnownFunctionType) {\n                PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n                List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n                List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                        .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n                knownFunctionType\n                        .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                                callStackParameterTypes)\n                        .ifPresentOrElse(functionSignature -> {\n                            KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                    argumentCount,\n                                    stackMetadata.getCallKeywordNameList());\n                        }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n            } else {\n                callGeneric(functionMetadata, stackMetadata, argumentCount);\n            }\n        }\n    }\n\n    private static void callGeneric(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            int argumentCount) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        int keywordArgs = localVariableHelper.newLocal();\n        int positionalArgs = localVariableHelper.newLocal();\n\n        localVariableHelper.readCallKeywords(methodVisitor);\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, argumentCount + 1);\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is (null or method), (obj or method)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is (obj or method) (null or method)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is obj, method\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, obj\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitLabel(blockEnd);\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is method, positionalArgs, keywordArgs\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n\n        localVariableHelper.resetCallKeywords(methodVisitor);\n        localVariableHelper.freeLocal();\n        localVariableHelper.freeLocal();\n    }\n\n    /**\n     * Calls a method. argc is the number of positional arguments. Keyword arguments are not supported.\n     * This opcode is designed to be used with LOAD_METHOD. Positional arguments are on top of the stack.\n     * Below them, the two items described in LOAD_METHOD are on the stack\n     * (either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private static void callGenericMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor,\n            PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        // Stack is method, (obj or null), arg0, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, instruction.arg());\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, (obj or null)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is method, argList, obj\n        StackManipulationImplementor.duplicateToTOS(functionMetadata, stackMetadata, 1);\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, argList, argList, obj\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method, argList\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, argList, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method, argList\n        methodVisitor.visitLabel(blockEnd);\n\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        // Stack is method, argList\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS...TOS[argc - 1] are the arguments to the function.\n     * TOS[argc] is the function to call. TOS...TOS[argc] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        callGenericFunction(functionMetadata, stackMetadata, methodVisitor, instruction.arg());\n    }\n\n    public static void callGenericFunction(MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n    public static void callGenericFunctionWithKeywords(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        // stack is callable, arg0, arg1, ..., arg(argc - len(keys)), ..., arg(argc - 1), keys\n        // We know the total number of arguments, but not the number of individual positional/keyword arguments\n        // Since Java Bytecode require consistent stack frames  (i.e. the body of a loop must start with\n        // the same number of elements in the stack), we need to add the tuple/map in the same object\n        // which will delegate it to either the tuple or the map depending on position and the first item size\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, instruction.arg() + 1);\n\n        // stack is callable, tupleMapPair\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n\n        // stack is callable, tupleMapPair, positionalArgs\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. If the lowest bit of instruction.arg is set, TOS is a mapping object containing keyword\n     * arguments, TOS[1] is an iterable containing positional arguments and TOS[2] is callable. Otherwise,\n     * TOS is an iterable containing positional arguments and TOS[1] is callable.\n     */\n\n\n\n\n\n\n\n\n\n    public static void callFunctionUnpackMapAndIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    public static void callFunctionUnpackIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    private static void getCallerInstance\n```\n# Function Signature: public static void callFunction(FunctionMetadata functionMetadata,\n# Natural Language Annotations: /**\n     * Calls a function. TOS...TOS[argc - 1] are the arguments to the function.\n     * TOS[argc] is the function to call. TOS...TOS[argc] are all popped and\n     * the result is pushed onto the stack.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void callFunction(FunctionMetadata functionMetadata, StackMetadata stackMetadata) {\n    int argumentCount = stackMetadata.getArgumentCount();\n    call(functionMetadata, stackMetadata, argumentCount);\n}\n```", "  ```\npublic static void callFunction(FunctionMetadata functionMetadata, StackMetadata stackMetadata) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n    PythonCompiledFunction function = functionMetadata.pythonCompiledFunction;\n\n    // Get argument count from the bytecode\n    int argumentCount = functionMetadata.pythonBytecodeInstruction.arg();\n\n    // Get the types of the arguments\n    List<PythonLikeType> argumentTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n            .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n    // Call the function\n    call(functionMetadata, stackMetadata, argumentCount);\n}\n```", "  ```import java.lang.reflect.type;\n\npublic class FunctionImplementor {\n\n    public static void callFunction(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, int argumentCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argumentCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    private static void getCallerInstance(FunctionMetadata functionMetadata, StackMetadata stackMetadata) {\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n    }\n}\n```"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callFunctionWithKeywords": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java:\n```\npackage ai.timefold.jpyinterpreter.implementors;\n\nimport java.lang.reflect.Constructor;\nimport java.lang.reflect.InvocationTargetException;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.jpyinterpreter.FunctionMetadata;\nimport ai.timefold.jpyinterpreter.LocalVariableHelper;\nimport ai.timefold.jpyinterpreter.PythonBytecodeInstruction;\nimport ai.timefold.jpyinterpreter.PythonBytecodeToJavaBytecodeTranslator;\nimport ai.timefold.jpyinterpreter.PythonCompiledFunction;\nimport ai.timefold.jpyinterpreter.PythonInterpreter;\nimport ai.timefold.jpyinterpreter.PythonLikeObject;\nimport ai.timefold.jpyinterpreter.PythonVersion;\nimport ai.timefold.jpyinterpreter.StackMetadata;\nimport ai.timefold.jpyinterpreter.ValueSourceInfo;\nimport ai.timefold.jpyinterpreter.types.BuiltinTypes;\nimport ai.timefold.jpyinterpreter.types.PythonCode;\nimport ai.timefold.jpyinterpreter.types.PythonKnownFunctionType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeFunction;\nimport ai.timefold.jpyinterpreter.types.PythonLikeGenericType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\nimport ai.timefold.jpyinterpreter.types.PythonString;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeDict;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeTuple;\n\nimport org.objectweb.asm.Label;\nimport org.objectweb.asm.MethodVisitor;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\n\n/**\n * Implements opcodes related to functions\n */\npublic class FunctionImplementor {\n\n    public static void callBinaryMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callBinaryMethod(MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n    private static void loadGenericMethod(FunctionMetadata functionMetadata, MethodVisitor methodVisitor, String className,\n            PythonCompiledFunction function,\n            StackMetadata stackMetadata, int nameIndex) {\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(function.co_names.get(nameIndex));\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n                \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        Label blockEnd = new Label();\n\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n\n        // TOS is null; type does not have attribute; do normal attribute lookup\n        // Stack is object, null\n        methodVisitor.visitInsn(Opcodes.POP);\n        ObjectImplementor.getAttribute(functionMetadata, stackMetadata, nameIndex);\n\n        // Stack is method\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n            // Python 3.11+ swap these\n            methodVisitor.visitInsn(Opcodes.SWAP);\n        }\n\n        methodVisitor.visitLabel(blockEnd);\n\n        // Stack is either:\n        // object, method if it was in type\n        // null, method if it was not in type (Or method, null if Python 3.11+)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is now:\n        // method, object if it was in type\n        // method, null if it was not in type (and prior to Python 3.11+)\n        // null, method if it was not in type (if Python 3.11+)\n    }\n\n    public static void setCallKeywordNameTuple(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            int constantIndex) {\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n        PythonConstantsImplementor.loadConstant(functionMetadata.methodVisitor, functionMetadata.className, constantIndex);\n        localVariableHelper.writeCallKeywords(functionMetadata.methodVisitor);\n    }\n\n    /**\n     * Calls a function. argc is the number of positional arguments. Keyword arguments are stored in a local variable.\n     * Keyword arguments (if any) are at the top of the stack, followed by, positional arguments.\n     * Below them either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n    public static void call(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int argumentCount) {\n        PythonLikeType functionType = stackMetadata.getTypeAtStackIndex(argumentCount + 1);\n        if (functionType instanceof PythonLikeGenericType) {\n            functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n        }\n        if (functionType instanceof PythonKnownFunctionType) {\n            PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n            List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n            List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                    .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n            knownFunctionType\n                    .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                            callStackParameterTypes)\n                    .ifPresentOrElse(functionSignature -> {\n                        KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                argumentCount,\n                                stackMetadata.getCallKeywordNameList());\n                    }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n        } else {\n            functionType = stackMetadata.getTypeAtStackIndex(argumentCount);\n            if (functionType instanceof PythonLikeGenericType) {\n                functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n            }\n            if (functionType instanceof PythonKnownFunctionType) {\n                PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n                List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n                List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                        .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n                knownFunctionType\n                        .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                                callStackParameterTypes)\n                        .ifPresentOrElse(functionSignature -> {\n                            KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                    argumentCount,\n                                    stackMetadata.getCallKeywordNameList());\n                        }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n            } else {\n                callGeneric(functionMetadata, stackMetadata, argumentCount);\n            }\n        }\n    }\n\n    private static void callGeneric(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            int argumentCount) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        int keywordArgs = localVariableHelper.newLocal();\n        int positionalArgs = localVariableHelper.newLocal();\n\n        localVariableHelper.readCallKeywords(methodVisitor);\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, argumentCount + 1);\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is (null or method), (obj or method)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is (obj or method) (null or method)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is obj, method\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, obj\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitLabel(blockEnd);\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is method, positionalArgs, keywordArgs\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n\n        localVariableHelper.resetCallKeywords(methodVisitor);\n        localVariableHelper.freeLocal();\n        localVariableHelper.freeLocal();\n    }\n\n    /**\n     * Calls a method. argc is the number of positional arguments. Keyword arguments are not supported.\n     * This opcode is designed to be used with LOAD_METHOD. Positional arguments are on top of the stack.\n     * Below them, the two items described in LOAD_METHOD are on the stack\n     * (either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private static void callGenericMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor,\n            PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        // Stack is method, (obj or null), arg0, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, instruction.arg());\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, (obj or null)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is method, argList, obj\n        StackManipulationImplementor.duplicateToTOS(functionMetadata, stackMetadata, 1);\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, argList, argList, obj\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method, argList\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, argList, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method, argList\n        methodVisitor.visitLabel(blockEnd);\n\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        // Stack is method, argList\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS...TOS[argc - 1] are the arguments to the function.\n     * TOS[argc] is the function to call. TOS...TOS[argc] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        callGenericFunction(functionMetadata, stackMetadata, methodVisitor, instruction.arg());\n    }\n\n    public static void callGenericFunction(MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n    public static void callGenericFunctionWithKeywords(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        // stack is callable, arg0, arg1, ..., arg(argc - len(keys)), ..., arg(argc - 1), keys\n        // We know the total number of arguments, but not the number of individual positional/keyword arguments\n        // Since Java Bytecode require consistent stack frames  (i.e. the body of a loop must start with\n        // the same number of elements in the stack), we need to add the tuple/map in the same object\n        // which will delegate it to either the tuple or the map depending on position and the first item size\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, instruction.arg() + 1);\n\n        // stack is callable, tupleMapPair\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n\n        // stack is callable, tupleMapPair, positionalArgs\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. If the lowest bit of instruction.arg is set, TOS is a mapping object containing keyword\n     * arguments, TOS[1] is an iterable containing positional arguments and TOS[2] is callable. Otherwise,\n     * TOS is an iterable containing positional arguments and TOS[1] is callable.\n     */\n\n\n\n\n\n\n\n\n\n    public static void callFunctionUnpackMapAndIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    public static void callFunctionUnpackIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    private static void getCallerInstance\n```\n# Function Signature: public static void callFunctionWithKeywords(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n# Natural Language Annotations: /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void callFunctionWithKeywords(FunctionMetadata functionMetadata, StackMetadata stackMetadata) {\n    // Stack is callable, arg0, arg1, ..., arg(argc - 1), keys\n    // We know the total number of arguments, but not the number of individual positional/keyword arguments\n    // Since Java Bytecode require consistent stack frames  (i.e. the body of a loop must start with\n    // the same number of elements in the stack), we need to add the tuple/map in the same object\n    // which will delegate it to either the tuple or the map depending on position and the first item size\n    CollectionImplementor.buildCollection(TupleMapPair.class, functionMetadata.methodVisitor, stackMetadata.valueSources.size() + 1);\n\n    // Stack is callable, tupleMapPair\n    functionMetadata.methodVisitor.visitInsn(Opcodes.DUP);\n    functionMetadata.methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n            Type.getDescriptor(PythonLikeTuple.class));\n\n    // Stack is callable, tupleMapPair, positionalArgs\n    functionMetadata.methodVisitor.visitInsn(Opcodes.SWAP);\n    functionMetadata.methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n            Type.getDescriptor(PythonLikeDict.class));\n\n    getCallerInstance(functionMetadata, stackMetadata);\n\n    // Stack is callable, positionalArgs, keywordArgs\n    functionMetadata.methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n            \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(List.class),\n                    Type.getType(Map.class),\n                    Type.getType(PythonLikeObject.class)),\n            true);\n}\n```", "  ```\npublic static void callFunctionWithKeywords(FunctionMetadata functionMetadata, StackMetadata stackMetadata) {\n    // Stack is a tuple containing keyword names, arg0, arg1, ..., arg(argc - len(keys)), ..., arg(argc - 1), keys, function\n    CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, instruction.arg() + 1);\n\n    // Stack is tupleMapPair\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n            Type.getDescriptor(PythonLikeTuple.class));\n\n    // Stack is tupleMapPair, positionalArgs\n    methodVisitor.visitInsn(Opcodes.SWAP);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n            Type.getDescriptor(PythonLikeDict.class));\n\n    getCallerInstance(functionMetadata, stackMetadata);\n\n    // Stack is positionalArgs, keywordArgs, function\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n            \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(List.class),\n                    Type.getType(Map.class),\n                    Type.getType(PythonLikeObject.class)),\n            true);\n}\n```", "  ```\n    public static void callFunctionWithKeywords(FunctionMetadata functionMetadata, StackMetadata stackMetadata) {\n        int argc = stackMetadata.stackSize;\n        for (int i = 0; i < argc; i++) {\n            stackMetadata.popStack();\n        }\n        PythonLikeType functionType = stackMetadata.popStack();\n        if (functionType instanceof PythonKnownFunctionType) {\n            PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n            List<String> keywordArgumentNameList = stackMetadata.popStack();\n            List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argc - 1)\n                    .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n            knownFunctionType\n                    .getFunctionForParameters(argc - keywordArgumentNameList.size(), keywordArgumentNameList,\n                            callStackParameterTypes)\n                    .ifPresentOrElse(functionSignature -> {\n                        KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                argc - 1,\n                                stackMetadata.getCallKeywordNameList());\n                    }, () -> callGenericFunctionWithKeywords(functionMetadata, stackMetadata, argc - 1, keywordArgumentNameList));\n        } else {\n            callGenericFunctionWithKeywords(functionMetadata, stackMetadata, argc - 1, stackMetadata.popStack());\n        }\n    }\n```"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callFunctionUnpack": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java:\n```\npackage ai.timefold.jpyinterpreter.implementors;\n\nimport java.lang.reflect.Constructor;\nimport java.lang.reflect.InvocationTargetException;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.jpyinterpreter.FunctionMetadata;\nimport ai.timefold.jpyinterpreter.LocalVariableHelper;\nimport ai.timefold.jpyinterpreter.PythonBytecodeInstruction;\nimport ai.timefold.jpyinterpreter.PythonBytecodeToJavaBytecodeTranslator;\nimport ai.timefold.jpyinterpreter.PythonCompiledFunction;\nimport ai.timefold.jpyinterpreter.PythonInterpreter;\nimport ai.timefold.jpyinterpreter.PythonLikeObject;\nimport ai.timefold.jpyinterpreter.PythonVersion;\nimport ai.timefold.jpyinterpreter.StackMetadata;\nimport ai.timefold.jpyinterpreter.ValueSourceInfo;\nimport ai.timefold.jpyinterpreter.types.BuiltinTypes;\nimport ai.timefold.jpyinterpreter.types.PythonCode;\nimport ai.timefold.jpyinterpreter.types.PythonKnownFunctionType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeFunction;\nimport ai.timefold.jpyinterpreter.types.PythonLikeGenericType;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\nimport ai.timefold.jpyinterpreter.types.PythonString;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeDict;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeTuple;\n\nimport org.objectweb.asm.Label;\nimport org.objectweb.asm.MethodVisitor;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\n\n/**\n * Implements opcodes related to functions\n */\npublic class FunctionImplementor {\n\n    public static void callBinaryMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callBinaryMethod(MethodVisitor methodVisitor, String methodName) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(methodName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getAttributeOrError\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, 2);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Loads a method named co_names[namei] from the TOS object. TOS is popped. This bytecode distinguishes two cases:\n     * if TOS has a method with the correct name, the bytecode pushes the unbound method and TOS.\n     * TOS will be used as the first argument (self) by CALL_METHOD when calling the unbound method.\n     * Otherwise, NULL and the object return by the attribute lookup are pushed.\n     */\n    private static void loadGenericMethod(FunctionMetadata functionMetadata, MethodVisitor methodVisitor, String className,\n            PythonCompiledFunction function,\n            StackMetadata stackMetadata, int nameIndex) {\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n                \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n                true);\n        methodVisitor.visitLdcInsn(function.co_names.get(nameIndex));\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n                \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(String.class)),\n                false);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        Label blockEnd = new Label();\n\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n\n        // TOS is null; type does not have attribute; do normal attribute lookup\n        // Stack is object, null\n        methodVisitor.visitInsn(Opcodes.POP);\n        ObjectImplementor.getAttribute(functionMetadata, stackMetadata, nameIndex);\n\n        // Stack is method\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n            // Python 3.11+ swap these\n            methodVisitor.visitInsn(Opcodes.SWAP);\n        }\n\n        methodVisitor.visitLabel(blockEnd);\n\n        // Stack is either:\n        // object, method if it was in type\n        // null, method if it was not in type (Or method, null if Python 3.11+)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is now:\n        // method, object if it was in type\n        // method, null if it was not in type (and prior to Python 3.11+)\n        // null, method if it was not in type (if Python 3.11+)\n    }\n\n    public static void setCallKeywordNameTuple(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            int constantIndex) {\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n        PythonConstantsImplementor.loadConstant(functionMetadata.methodVisitor, functionMetadata.className, constantIndex);\n        localVariableHelper.writeCallKeywords(functionMetadata.methodVisitor);\n    }\n\n    /**\n     * Calls a function. argc is the number of positional arguments. Keyword arguments are stored in a local variable.\n     * Keyword arguments (if any) are at the top of the stack, followed by, positional arguments.\n     * Below them either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n    public static void call(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int argumentCount) {\n        PythonLikeType functionType = stackMetadata.getTypeAtStackIndex(argumentCount + 1);\n        if (functionType instanceof PythonLikeGenericType) {\n            functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n        }\n        if (functionType instanceof PythonKnownFunctionType) {\n            PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n            List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n            List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                    .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n            knownFunctionType\n                    .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                            callStackParameterTypes)\n                    .ifPresentOrElse(functionSignature -> {\n                        KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                argumentCount,\n                                stackMetadata.getCallKeywordNameList());\n                    }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n        } else {\n            functionType = stackMetadata.getTypeAtStackIndex(argumentCount);\n            if (functionType instanceof PythonLikeGenericType) {\n                functionType = ((PythonLikeGenericType) functionType).getOrigin().getConstructorType().orElse(null);\n            }\n            if (functionType instanceof PythonKnownFunctionType) {\n                PythonKnownFunctionType knownFunctionType = (PythonKnownFunctionType) functionType;\n                List<String> keywordArgumentNameList = stackMetadata.getCallKeywordNameList();\n                List<PythonLikeType> callStackParameterTypes = stackMetadata.getValueSourcesUpToStackIndex(argumentCount)\n                        .stream().map(ValueSourceInfo::getValueType).collect(Collectors.toList());\n\n                knownFunctionType\n                        .getFunctionForParameters(argumentCount - keywordArgumentNameList.size(), keywordArgumentNameList,\n                                callStackParameterTypes)\n                        .ifPresentOrElse(functionSignature -> {\n                            KnownCallImplementor.callPython311andAbove(functionSignature, functionMetadata, stackMetadata,\n                                    argumentCount,\n                                    stackMetadata.getCallKeywordNameList());\n                        }, () -> callGeneric(functionMetadata, stackMetadata, argumentCount));\n            } else {\n                callGeneric(functionMetadata, stackMetadata, argumentCount);\n            }\n        }\n    }\n\n    private static void callGeneric(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            int argumentCount) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        int keywordArgs = localVariableHelper.newLocal();\n        int positionalArgs = localVariableHelper.newLocal();\n\n        localVariableHelper.readCallKeywords(methodVisitor);\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, argumentCount + 1);\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n        localVariableHelper.writeTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is (null or method), (obj or method)\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is (obj or method) (null or method)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is obj, method\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, obj\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeTuple.class), positionalArgs);\n\n        // Stack is method, positionalArgs\n        methodVisitor.visitLabel(blockEnd);\n\n        localVariableHelper.readTemp(methodVisitor, Type.getType(PythonLikeDict.class), keywordArgs);\n\n        // Stack is method, positionalArgs, keywordArgs\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n\n        localVariableHelper.resetCallKeywords(methodVisitor);\n        localVariableHelper.freeLocal();\n        localVariableHelper.freeLocal();\n    }\n\n    /**\n     * Calls a method. argc is the number of positional arguments. Keyword arguments are not supported.\n     * This opcode is designed to be used with LOAD_METHOD. Positional arguments are on top of the stack.\n     * Below them, the two items described in LOAD_METHOD are on the stack\n     * (either self and an unbound method object or NULL and an arbitrary callable).\n     * All of them are popped and the return value is pushed.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private static void callGenericMethod(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor,\n            PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        // Stack is method, (obj or null), arg0, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, instruction.arg());\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, (obj or null)\n        Label ifNullStart = new Label();\n        Label blockEnd = new Label();\n\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitJumpInsn(Opcodes.IF_ACMPEQ, ifNullStart);\n\n        // Stack is method, argList, obj\n        StackManipulationImplementor.duplicateToTOS(functionMetadata, stackMetadata, 1);\n        StackManipulationImplementor.swap(methodVisitor);\n\n        // Stack is method, argList, argList, obj\n        methodVisitor.visitInsn(Opcodes.ICONST_0);\n\n        // Stack is method, argList, argList, obj, index\n        methodVisitor.visitInsn(Opcodes.SWAP);\n\n        // Stack is method, argList, argList, index, obj\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class),\n                \"add\",\n                Type.getMethodDescriptor(Type.VOID_TYPE, Type.INT_TYPE, Type.getType(Object.class)),\n                true);\n\n        // Stack is method, argList\n        methodVisitor.visitJumpInsn(Opcodes.GOTO, blockEnd);\n\n        methodVisitor.visitLabel(ifNullStart);\n        // Stack is method, argList, null\n        methodVisitor.visitInsn(Opcodes.POP);\n\n        // Stack is method, argList\n        methodVisitor.visitLabel(blockEnd);\n\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        // Stack is method, argList\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS...TOS[argc - 1] are the arguments to the function.\n     * TOS[argc] is the function to call. TOS...TOS[argc] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        callGenericFunction(functionMetadata, stackMetadata, methodVisitor, instruction.arg());\n    }\n\n    public static void callGenericFunction(MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    public static void callGenericFunction(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, int argCount) {\n        // stack is callable, arg0, arg1, ..., arg(argc - 1)\n        CollectionImplementor.buildCollection(PythonLikeTuple.class, methodVisitor, argCount);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, argument_list, null\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Calls a function. TOS is a tuple containing keyword names.\n     * TOS[1]...TOS[len(TOS)] are the keyword arguments to the function (TOS[1] is (TOS)[0], TOS[2] is (TOS)[1], ...).\n     * TOS[len(TOS) + 1]...TOS[argc + 1] are the positional arguments (rightmost first).\n     * TOS[argc + 2] is the function to call. TOS...TOS[argc + 2] are all popped and\n     * the result is pushed onto the stack.\n     */\n    public static void callGenericFunctionWithKeywords(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n        // stack is callable, arg0, arg1, ..., arg(argc - len(keys)), ..., arg(argc - 1), keys\n        // We know the total number of arguments, but not the number of individual positional/keyword arguments\n        // Since Java Bytecode require consistent stack frames  (i.e. the body of a loop must start with\n        // the same number of elements in the stack), we need to add the tuple/map in the same object\n        // which will delegate it to either the tuple or the map depending on position and the first item size\n        CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, instruction.arg() + 1);\n\n        // stack is callable, tupleMapPair\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n                Type.getDescriptor(PythonLikeTuple.class));\n\n        // stack is callable, tupleMapPair, positionalArgs\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n                Type.getDescriptor(PythonLikeDict.class));\n\n        getCallerInstance(functionMetadata, stackMetadata);\n\n        // Stack is callable, positionalArgs, keywordArgs\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Calls a function. If the lowest bit of instruction.arg is set, TOS is a mapping object containing keyword\n     * arguments, TOS[1] is an iterable containing positional arguments and TOS[2] is callable. Otherwise,\n     * TOS is an iterable containing positional arguments and TOS[1] is callable.\n     */\n\n\n\n\n\n\n\n\n\n    public static void callFunctionUnpackMapAndIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    public static void callFunctionUnpackIterable(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n            MethodVisitor methodVisitor) {\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n                Type.getMethodDescriptor(Type.getType(Map.class)),\n                false);\n        getCallerInstance(functionMetadata, stackMetadata);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n                \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                        Type.getType(List.class),\n                        Type.getType(Map.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            methodVisitor.visitInsn(Opcodes.SWAP);\n            methodVisitor.visitInsn(Opcodes.POP);\n        }\n    }\n\n    private static void getCallerInstance\n```\n# Function Signature: public static void callFunctionUnpack(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n# Natural Language Annotations: /**\n     * Calls a function. If the lowest bit of instruction.arg is set, TOS is a mapping object containing keyword\n     * arguments, TOS[1] is an iterable containing positional arguments and TOS[2] is callable. Otherwise,\n     * TOS is an iterable containing positional arguments and TOS[1] is callable.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void callFunctionUnpack(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n         MethodVisitor methodVisitor) {\n     if ((instruction.arg() & 1) != 0) {\n         callFunctionUnpackMapAndIterable(functionMetadata, stackMetadata, methodVisitor);\n     } else {\n         callFunctionUnpackIterable(functionMetadata, stackMetadata, methodVisitor);\n     }\n}\n```", "  ```\npublic static void callFunctionUnpack(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n        MethodVisitor methodVisitor) {\n    int instruction = methodVisitor.getInstruction();\n    if ((instruction & 1) != 0) {\n        // lowest bit of instruction.arg is set, callFunctionUnpackMapAndIterable\n        callFunctionUnpackMapAndIterable(functionMetadata, stackMetadata, methodVisitor);\n    } else {\n        // lowest bit of instruction.arg is not set, callFunctionUnpackIterable\n        callFunctionUnpackIterable(functionMetadata, stackMetadata, methodVisitor);\n    }\n}\n```", "  ```\npublic static void callFunctionUnpack(FunctionMetadata functionMetadata, StackMetadata stackMetadata, MethodVisitor methodVisitor) {\n    // Check if the lowest bit of instruction.arg is set\n    int instruction = methodVisitor.visitMethodInsn(Opcodes.LDC, Type.getInternalName(PythonLikeObject.class), \"getCallerInstance\",\n            Type.getMethodDescriptor(Type.getType(PythonLikeObject.class), Type.getType(List.class)),\n            false);\n    methodVisitor.visitJumpInsn(Opcodes.IF_ICMPNE, instruction);\n    // If true, then the lowest bit of instruction.arg is set\n    // TOS is a mapping object containing keyword arguments and TOS[1] is an iterable containing positional arguments\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class), \"getMappingValue\",\n            Type.getMethodDescriptor(Type.getType(PythonLikeObject.class)),\n            true);\n    methodVisitor.visitInsn(Opcodes.POP);\n\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class), \"getMappingKeyIterator\",\n            Type.getMethodDescriptor(Type.getType(PythonLikeObject.class)),\n            true);\n    methodVisitor.visitInsn(Opcodes.POP);\n\n    methodVisitor.visitLabel(instruction);\n    // TOS is an iterable containing positional arguments and TOS[1] is callable\n    methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(Collections.class), \"emptyMap\",\n            Type.getMethodDescriptor(Type.getType(Map.class)),\n            false);\n    getCallerInstance(functionMetadata, stackMetadata);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class), \"$call\",\n            Type.getMethodDescriptor(Type.getType(PythonLikeObject.class), Type.getType(List.class),\n                    Type.getType(Map.class), Type.getType(PythonLikeObject.class)),\n            true);\n    if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.POP);\n    }\n}\n```"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/VariableImplementor.java-loadGlobalVariable": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/VariableImplementor.java:\n```\npackage ai.timefold.jpyinterpreter.implementors;\n\nimport java.util.List;\nimport java.util.Map;\n\nimport ai.timefold.jpyinterpreter.FunctionMetadata;\nimport ai.timefold.jpyinterpreter.LocalVariableHelper;\nimport ai.timefold.jpyinterpreter.PythonBytecodeInstruction;\nimport ai.timefold.jpyinterpreter.PythonBytecodeToJavaBytecodeTranslator;\nimport ai.timefold.jpyinterpreter.PythonCompiledFunction;\nimport ai.timefold.jpyinterpreter.PythonInterpreter;\nimport ai.timefold.jpyinterpreter.PythonLikeObject;\nimport ai.timefold.jpyinterpreter.PythonVersion;\nimport ai.timefold.jpyinterpreter.StackMetadata;\nimport ai.timefold.jpyinterpreter.opcodes.descriptor.VariableOpDescriptor;\nimport ai.timefold.jpyinterpreter.types.PythonCell;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeTuple;\n\nimport org.objectweb.asm.MethodVisitor;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\n\n/**\n * Implementations of local variable manipulation opcodes.\n * See https://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/\n * for a detailed explanation of the differences between LOAD_FAST, LOAD_GLOBAL, LOAD_DEREF, etc.\n */\npublic class VariableImplementor {\n\n    /**\n     * Loads the local variable or parameter indicated by the {@code instruction} argument onto the stack.\n     */\n    public static void loadLocalVariable(MethodVisitor methodVisitor, PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        localVariableHelper.readLocal(methodVisitor, instruction.arg());\n    }\n\n    /**\n     * Stores TOS into the local variable or parameter indicated by the {@code instruction} argument.\n     */\n    public static void storeInLocalVariable(MethodVisitor methodVisitor, PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        localVariableHelper.writeLocal(methodVisitor, instruction.arg());\n    }\n\n    /**\n     * Deletes the global variable or parameter indicated by the {@code instruction} argument.\n     */\n    public static void deleteGlobalVariable(MethodVisitor methodVisitor, String className,\n            PythonCompiledFunction pythonCompiledFunction,\n            PythonBytecodeInstruction instruction) {\n        String globalName = pythonCompiledFunction.co_names.get(instruction.arg());\n\n        methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, className);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, className,\n                PythonBytecodeToJavaBytecodeTranslator.INTERPRETER_INSTANCE_FIELD_NAME,\n                Type.getDescriptor(PythonInterpreter.class));\n        methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, className,\n                PythonBytecodeToJavaBytecodeTranslator.GLOBALS_MAP_STATIC_FIELD_NAME,\n                Type.getDescriptor(Map.class));\n        methodVisitor.visitLdcInsn(globalName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonInterpreter.class),\n                \"deleteGlobal\", Type.getMethodDescriptor(Type.VOID_TYPE, Type.getType(Map.class),\n                        Type.getType(String.class)),\n                true);\n    }\n\n    /**\n     * Loads the global variable or parameter indicated by the {@code instruction} argument onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Stores TOS into the global variable or parameter indicated by the {@code instruction} argument.\n     */\n    public static void storeInGlobalVariable(MethodVisitor methodVisitor, String className,\n            PythonCompiledFunction pythonCompiledFunction,\n            PythonBytecodeInstruction instruction) {\n        String globalName = pythonCompiledFunction.co_names.get(instruction.arg());\n\n        methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, className);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, className,\n                PythonBytecodeToJavaBytecodeTranslator.INTERPRETER_INSTANCE_FIELD_NAME,\n                Type.getDescriptor(PythonInterpreter.class));\n        StackManipulationImplementor.swap(methodVisitor);\n        methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, className,\n                PythonBytecodeToJavaBytecodeTranslator.GLOBALS_MAP_STATIC_FIELD_NAME,\n                Type.getDescriptor(Map.class));\n        StackManipulationImplementor.swap(methodVisitor);\n        methodVisitor.visitLdcInsn(globalName);\n        StackManipulationImplementor.swap(methodVisitor);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonInterpreter.class),\n                \"setGlobal\", Type.getMethodDescriptor(Type.VOID_TYPE, Type.getType(Map.class),\n                        Type.getType(String.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Deletes the local variable or parameter indicated by the {@code instruction} argument.\n     */\n    public static void deleteLocalVariable(MethodVisitor methodVisitor, PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        // Deleting is implemented as setting the value to null\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        localVariableHelper.writeLocal(methodVisitor, instruction.arg());\n    }\n\n    public static int getCellIndex(FunctionMetadata functionMetadata, int instructionArg) {\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            // free variables are offset by co_varnames.size(), bound variables are not\n            if (instructionArg >= functionMetadata.pythonCompiledFunction.co_cellvars.size()) {\n                // it a free variable\n                return instructionArg - functionMetadata.pythonCompiledFunction.co_varnames.size();\n            }\n            return instructionArg; // it a bound variable\n        } else {\n            return instructionArg; // Python 3.10 and below, we don't need to do anything\n        }\n    }\n\n    /**\n     * Loads the cell indicated by the {@code instruction} argument onto the stack.\n     * This is used by {@link VariableOpDescriptor#LOAD_CLOSURE} when creating a closure\n     * for a dependent function.\n     */\n    public static void createCell(MethodVisitor methodVisitor, LocalVariableHelper localVariableHelper, int cellIndex) {\n        methodVisitor.visitTypeInsn(Opcodes.NEW, Type.getInternalName(PythonCell.class));\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESPECIAL, Type.getInternalName(PythonCell.class), \"<init>\",\n                Type.getMethodDescriptor(Type.VOID_TYPE), false);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        localVariableHelper.readCellInitialValue(methodVisitor, cellIndex);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, Type.getInternalName(PythonLikeObject.class));\n        methodVisitor.visitFieldInsn(Opcodes.PUTFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n                Type.getDescriptor(PythonLikeObject.class));\n        localVariableHelper.writeCell(methodVisitor, cellIndex);\n    }\n\n    /**\n     * Moves the {@code cellIndex} free variable (stored in the\n     * {@link PythonBytecodeToJavaBytecodeTranslator#CELLS_INSTANCE_FIELD_NAME} field\n     * to its corresponding local variable.\n     */\n    public static void setupFreeVariableCell(MethodVisitor methodVisitor, String internalClassName,\n            LocalVariableHelper localVariableHelper, int cellIndex) {\n        methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, internalClassName,\n                PythonBytecodeToJavaBytecodeTranslator.CELLS_INSTANCE_FIELD_NAME,\n                Type.getDescriptor(PythonLikeTuple.class));\n        methodVisitor.visitLdcInsn(cellIndex);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class), \"get\",\n                Type.getMethodDescriptor(Type.getType(Object.class), Type.getType(int.class)),\n                true);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, Type.getInternalName(PythonCell.class));\n        localVariableHelper.writeFreeCell(methodVisitor, cellIndex);\n    }\n\n    /**\n     * Loads the cell indicated by the {@code instruction} argument onto the stack.\n     * This is used by {@link VariableOpDescriptor#LOAD_CLOSURE} when creating a closure\n     * for a dependent function.\n     */\n    public static void loadCell(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        localVariableHelper.readCell(methodVisitor, cellIndex);\n    }\n\n    /**\n     * Loads the cell variable/free variable indicated by the {@code instruction} argument onto the stack.\n     * (which is an {@link PythonCell}, so it can see changes from the parent function).\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Stores TOS into the cell variable or parameter indicated by the {@code instruction} argument\n     * (which is an {@link PythonCell}, so changes in the parent function affect the variable in dependent functions).\n     */\n    public static void storeInCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n\n        loadCell(functionMetadata, stackMetadata, cellIndex);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitFieldInsn(Opcodes.PUTFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n                Type.getDescriptor(PythonLikeObject.class));\n    }\n\n    /**\n     * Deletes the cell variable or parameter indicated by the {@code instruction} argument\n     * (which is an {@link PythonCell}, so changes in the parent function affect the variable in dependent functions).\n     */\n    public static void deleteCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n\n        // Deleting is implemented as setting the value to null\n        loadCell(functionMetadata, stackMetadata, cellIndex);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitFieldInsn(Opcodes.PUTFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n                Type.getDescriptor(PythonLikeObject.class));\n    }\n}\n\n```\n# Function Signature: public static void loadGlobalVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int globalIndex,\n# Natural Language Annotations: /**\n     * Loads the global variable or parameter indicated by the {@code instruction} argument onto the stack.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void loadGlobalVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int globalIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        String className = functionMetadata.className;\n        PythonCompiledFunction pythonCompiledFunction = functionMetadata.pythonCompiledFunction;\n\n        String globalName = pythonCompiledFunction.co_names.get(globalIndex);\n\n        methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, className);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, className,\n                PythonBytecodeToJavaBytecodeTranslator.INTERPRETER_INSTANCE_FIELD_NAME,\n                Type.getDescriptor(PythonInterpreter.class));\n        methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, className,\n                PythonBytecodeToJavaBytecodeTranslator.GLOBALS_MAP_STATIC_FIELD_NAME,\n                Type.getDescriptor(Map.class));\n        methodVisitor.visitLdcInsn(globalName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonInterpreter.class),\n                \"getGlobal\", Type.getMethodDescriptor(PythonLikeObject.class, Type.getType(Map.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitFieldInsn(Opcodes.PUTFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n                Type.getDescriptor(PythonLikeObject.class));\n    }\n```", "  ```\npublic static void loadGlobalVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int globalIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        PythonCompiledFunction pythonCompiledFunction = functionMetadata.pythonCompiledFunction;\n\n        // Load the global variable or parameter onto the stack\n        methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, functionMetadata.internalClassName);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, functionMetadata.internalClassName,\n                PythonBytecodeToJavaBytecodeTranslator.INTERPRETER_INSTANCE_FIELD_NAME,\n                Type.getDescriptor(PythonInterpreter.class));\n        methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, functionMetadata.internalClassName,\n                PythonBytecodeToJavaBytecodeTranslator.GLOBALS_MAP_STATIC_FIELD_NAME,\n                Type.getDescriptor(Map.class));\n        methodVisitor.visitLdcInsn(pythonCompiledFunction.co_names.get(globalIndex));\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonInterpreter.class),\n                \"getGlobal\", Type.getMethodDescriptor(Type.VOID_TYPE, Type.getType(Map.class),\n                        Type.getType(String.class)),\n                true);\n}\n  ```", "  ```\n\npublic static void loadGlobalVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int globalIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        PythonCompiledFunction pythonCompiledFunction = functionMetadata.pythonCompiledFunction;\n        String className = functionMetadata.internalClassName;\n\n        String globalName = pythonCompiledFunction.co_names.get(globalIndex);\n\n        methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, className);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, className,\n                PythonBytecodeToJavaBytecodeTranslator.INTERPRETER_INSTANCE_FIELD_NAME,\n                Type.getDescriptor(PythonInterpreter.class));\n        methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, className,\n                PythonBytecodeToJavaBytecodeTranslator.GLOBALS_MAP_STATIC_FIELD_NAME,\n                Type.getDescriptor(Map.class));\n        methodVisitor.visitLdcInsn(globalName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonInterpreter.class),\n                \"getGlobal\", Type.getMethodDescriptor(Type.VOID_TYPE, Type.getType(Map.class),\n                        Type.getType(String.class)),\n                true);\n        methodVisitor.visitInsn(Opcodes.SWAP); // Swap TOS and NOS\n    }\n```"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/VariableImplementor.java-loadCellVariable": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/VariableImplementor.java:\n```\npackage ai.timefold.jpyinterpreter.implementors;\n\nimport java.util.List;\nimport java.util.Map;\n\nimport ai.timefold.jpyinterpreter.FunctionMetadata;\nimport ai.timefold.jpyinterpreter.LocalVariableHelper;\nimport ai.timefold.jpyinterpreter.PythonBytecodeInstruction;\nimport ai.timefold.jpyinterpreter.PythonBytecodeToJavaBytecodeTranslator;\nimport ai.timefold.jpyinterpreter.PythonCompiledFunction;\nimport ai.timefold.jpyinterpreter.PythonInterpreter;\nimport ai.timefold.jpyinterpreter.PythonLikeObject;\nimport ai.timefold.jpyinterpreter.PythonVersion;\nimport ai.timefold.jpyinterpreter.StackMetadata;\nimport ai.timefold.jpyinterpreter.opcodes.descriptor.VariableOpDescriptor;\nimport ai.timefold.jpyinterpreter.types.PythonCell;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\nimport ai.timefold.jpyinterpreter.types.collections.PythonLikeTuple;\n\nimport org.objectweb.asm.MethodVisitor;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\n\n/**\n * Implementations of local variable manipulation opcodes.\n * See https://tenthousandmeters.com/blog/python-behind-the-scenes-5-how-variables-are-implemented-in-cpython/\n * for a detailed explanation of the differences between LOAD_FAST, LOAD_GLOBAL, LOAD_DEREF, etc.\n */\npublic class VariableImplementor {\n\n    /**\n     * Loads the local variable or parameter indicated by the {@code instruction} argument onto the stack.\n     */\n    public static void loadLocalVariable(MethodVisitor methodVisitor, PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        localVariableHelper.readLocal(methodVisitor, instruction.arg());\n    }\n\n    /**\n     * Stores TOS into the local variable or parameter indicated by the {@code instruction} argument.\n     */\n    public static void storeInLocalVariable(MethodVisitor methodVisitor, PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        localVariableHelper.writeLocal(methodVisitor, instruction.arg());\n    }\n\n    /**\n     * Deletes the global variable or parameter indicated by the {@code instruction} argument.\n     */\n    public static void deleteGlobalVariable(MethodVisitor methodVisitor, String className,\n            PythonCompiledFunction pythonCompiledFunction,\n            PythonBytecodeInstruction instruction) {\n        String globalName = pythonCompiledFunction.co_names.get(instruction.arg());\n\n        methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, className);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, className,\n                PythonBytecodeToJavaBytecodeTranslator.INTERPRETER_INSTANCE_FIELD_NAME,\n                Type.getDescriptor(PythonInterpreter.class));\n        methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, className,\n                PythonBytecodeToJavaBytecodeTranslator.GLOBALS_MAP_STATIC_FIELD_NAME,\n                Type.getDescriptor(Map.class));\n        methodVisitor.visitLdcInsn(globalName);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonInterpreter.class),\n                \"deleteGlobal\", Type.getMethodDescriptor(Type.VOID_TYPE, Type.getType(Map.class),\n                        Type.getType(String.class)),\n                true);\n    }\n\n    /**\n     * Loads the global variable or parameter indicated by the {@code instruction} argument onto the stack.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Stores TOS into the global variable or parameter indicated by the {@code instruction} argument.\n     */\n    public static void storeInGlobalVariable(MethodVisitor methodVisitor, String className,\n            PythonCompiledFunction pythonCompiledFunction,\n            PythonBytecodeInstruction instruction) {\n        String globalName = pythonCompiledFunction.co_names.get(instruction.arg());\n\n        methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, className);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, className,\n                PythonBytecodeToJavaBytecodeTranslator.INTERPRETER_INSTANCE_FIELD_NAME,\n                Type.getDescriptor(PythonInterpreter.class));\n        StackManipulationImplementor.swap(methodVisitor);\n        methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, className,\n                PythonBytecodeToJavaBytecodeTranslator.GLOBALS_MAP_STATIC_FIELD_NAME,\n                Type.getDescriptor(Map.class));\n        StackManipulationImplementor.swap(methodVisitor);\n        methodVisitor.visitLdcInsn(globalName);\n        StackManipulationImplementor.swap(methodVisitor);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonInterpreter.class),\n                \"setGlobal\", Type.getMethodDescriptor(Type.VOID_TYPE, Type.getType(Map.class),\n                        Type.getType(String.class),\n                        Type.getType(PythonLikeObject.class)),\n                true);\n    }\n\n    /**\n     * Deletes the local variable or parameter indicated by the {@code instruction} argument.\n     */\n    public static void deleteLocalVariable(MethodVisitor methodVisitor, PythonBytecodeInstruction instruction,\n            LocalVariableHelper localVariableHelper) {\n        // Deleting is implemented as setting the value to null\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        localVariableHelper.writeLocal(methodVisitor, instruction.arg());\n    }\n\n    public static int getCellIndex(FunctionMetadata functionMetadata, int instructionArg) {\n        if (functionMetadata.pythonCompiledFunction.pythonVersion.isAtLeast(PythonVersion.PYTHON_3_11)) {\n            // free variables are offset by co_varnames.size(), bound variables are not\n            if (instructionArg >= functionMetadata.pythonCompiledFunction.co_cellvars.size()) {\n                // it a free variable\n                return instructionArg - functionMetadata.pythonCompiledFunction.co_varnames.size();\n            }\n            return instructionArg; // it a bound variable\n        } else {\n            return instructionArg; // Python 3.10 and below, we don't need to do anything\n        }\n    }\n\n    /**\n     * Loads the cell indicated by the {@code instruction} argument onto the stack.\n     * This is used by {@link VariableOpDescriptor#LOAD_CLOSURE} when creating a closure\n     * for a dependent function.\n     */\n    public static void createCell(MethodVisitor methodVisitor, LocalVariableHelper localVariableHelper, int cellIndex) {\n        methodVisitor.visitTypeInsn(Opcodes.NEW, Type.getInternalName(PythonCell.class));\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESPECIAL, Type.getInternalName(PythonCell.class), \"<init>\",\n                Type.getMethodDescriptor(Type.VOID_TYPE), false);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        localVariableHelper.readCellInitialValue(methodVisitor, cellIndex);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, Type.getInternalName(PythonLikeObject.class));\n        methodVisitor.visitFieldInsn(Opcodes.PUTFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n                Type.getDescriptor(PythonLikeObject.class));\n        localVariableHelper.writeCell(methodVisitor, cellIndex);\n    }\n\n    /**\n     * Moves the {@code cellIndex} free variable (stored in the\n     * {@link PythonBytecodeToJavaBytecodeTranslator#CELLS_INSTANCE_FIELD_NAME} field\n     * to its corresponding local variable.\n     */\n    public static void setupFreeVariableCell(MethodVisitor methodVisitor, String internalClassName,\n            LocalVariableHelper localVariableHelper, int cellIndex) {\n        methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, internalClassName,\n                PythonBytecodeToJavaBytecodeTranslator.CELLS_INSTANCE_FIELD_NAME,\n                Type.getDescriptor(PythonLikeTuple.class));\n        methodVisitor.visitLdcInsn(cellIndex);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(List.class), \"get\",\n                Type.getMethodDescriptor(Type.getType(Object.class), Type.getType(int.class)),\n                true);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, Type.getInternalName(PythonCell.class));\n        localVariableHelper.writeFreeCell(methodVisitor, cellIndex);\n    }\n\n    /**\n     * Loads the cell indicated by the {@code instruction} argument onto the stack.\n     * This is used by {@link VariableOpDescriptor#LOAD_CLOSURE} when creating a closure\n     * for a dependent function.\n     */\n    public static void loadCell(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        localVariableHelper.readCell(methodVisitor, cellIndex);\n    }\n\n    /**\n     * Loads the cell variable/free variable indicated by the {@code instruction} argument onto the stack.\n     * (which is an {@link PythonCell}, so it can see changes from the parent function).\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Stores TOS into the cell variable or parameter indicated by the {@code instruction} argument\n     * (which is an {@link PythonCell}, so changes in the parent function affect the variable in dependent functions).\n     */\n    public static void storeInCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n\n        loadCell(functionMetadata, stackMetadata, cellIndex);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitFieldInsn(Opcodes.PUTFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n                Type.getDescriptor(PythonLikeObject.class));\n    }\n\n    /**\n     * Deletes the cell variable or parameter indicated by the {@code instruction} argument\n     * (which is an {@link PythonCell}, so changes in the parent function affect the variable in dependent functions).\n     */\n    public static void deleteCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n\n        // Deleting is implemented as setting the value to null\n        loadCell(functionMetadata, stackMetadata, cellIndex);\n        methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n        methodVisitor.visitFieldInsn(Opcodes.PUTFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n                Type.getDescriptor(PythonLikeObject.class));\n    }\n}\n\n```\n# Function Signature: public static void loadCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n# Natural Language Annotations: /**\n     * Loads the cell variable/free variable indicated by the {@code instruction} argument onto the stack.\n     * (which is an {@link PythonCell}, so it can see changes from the parent function).\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void loadCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        localVariableHelper.readCell(methodVisitor, cellIndex);\n    }\n```", "  ```\npublic static void loadCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        localVariableHelper.readCell(methodVisitor, cellIndex);\n        methodVisitor.visitInsn(Opcodes.DUP);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n                Type.getDescriptor(PythonLikeObject.class));\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, Type.getInternalName(PythonLikeObject.class));\n        localVariableHelper.writeCell(methodVisitor, cellIndex);\n}\n```", "  ```\npublic static void loadCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n        MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n        LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n        localVariableHelper.readCell(methodVisitor, cellIndex);\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n                Type.getDescriptor(PythonLikeObject.class));\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, Type.getInternalName(PythonLikeObject.class));\n        stackMetadata.incrStackSize();\n    }\n```"]}, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/ObjectImplementor.java-getAttribute": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/ObjectImplementor.java:\n```\npackage ai.timefold.jpyinterpreter.implementors;\n\nimport java.util.Optional;\n\nimport ai.timefold.jpyinterpreter.FieldDescriptor;\nimport ai.timefold.jpyinterpreter.FunctionMetadata;\nimport ai.timefold.jpyinterpreter.LocalVariableHelper;\nimport ai.timefold.jpyinterpreter.PythonBinaryOperator;\nimport ai.timefold.jpyinterpreter.PythonBytecodeInstruction;\nimport ai.timefold.jpyinterpreter.PythonLikeObject;\nimport ai.timefold.jpyinterpreter.PythonTernaryOperator;\nimport ai.timefold.jpyinterpreter.StackMetadata;\nimport ai.timefold.jpyinterpreter.types.BuiltinTypes;\nimport ai.timefold.jpyinterpreter.types.PythonLikeType;\nimport ai.timefold.jpyinterpreter.types.PythonNone;\nimport ai.timefold.jpyinterpreter.types.PythonString;\nimport ai.timefold.jpyinterpreter.types.PythonSuperObject;\nimport ai.timefold.jpyinterpreter.types.errors.AttributeError;\nimport ai.timefold.jpyinterpreter.types.wrappers.JavaObjectWrapper;\n\nimport org.objectweb.asm.Label;\nimport org.objectweb.asm.MethodVisitor;\nimport org.objectweb.asm.Opcodes;\nimport org.objectweb.asm.Type;\n\n/**\n * Implementations of opcodes related to objects\n */\npublic class ObjectImplementor {\n\n    /**\n     * Replaces TOS with getattr(TOS, co_names[instruction.arg])\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Deletes co_names[instruction.arg] of TOS\n     */\n    public static void deleteAttribute(FunctionMetadata functionMetadata, MethodVisitor methodVisitor, String className,\n            StackMetadata stackMetadata,\n            PythonBytecodeInstruction instruction) {\n        PythonLikeType tosType = stackMetadata.getTOSType();\n        String name = functionMetadata.pythonCompiledFunction.co_names.get(instruction.arg());\n        Optional<FieldDescriptor> maybeFieldDescriptor = tosType.getInstanceFieldDescriptor(name);\n        if (maybeFieldDescriptor.isPresent()) {\n            FieldDescriptor fieldDescriptor = maybeFieldDescriptor.get();\n            methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, fieldDescriptor.declaringClassInternalName());\n            methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n            methodVisitor.visitFieldInsn(Opcodes.PUTFIELD, fieldDescriptor.declaringClassInternalName(),\n                    fieldDescriptor.javaFieldName(),\n                    fieldDescriptor.javaFieldTypeDescriptor());\n        } else {\n            PythonConstantsImplementor.loadName(methodVisitor, className, instruction.arg());\n            DunderOperatorImplementor.binaryOperator(methodVisitor,\n                    stackMetadata.pushTemp(BuiltinTypes.STRING_TYPE),\n                    PythonBinaryOperator.DELETE_ATTRIBUTE);\n        }\n    }\n\n    /**\n     * Implement TOS.name = TOS1, where name is co_names[instruction.arg]. TOS and TOS1 are popped.\n     */\n    public static void setAttribute(FunctionMetadata functionMetadata, MethodVisitor methodVisitor, String className,\n            StackMetadata stackMetadata,\n            PythonBytecodeInstruction instruction, LocalVariableHelper localVariableHelper) {\n        PythonLikeType tosType = stackMetadata.getTOSType();\n        String name = functionMetadata.pythonCompiledFunction.co_names.get(instruction.arg());\n        Optional<FieldDescriptor> maybeFieldDescriptor = tosType.getInstanceFieldDescriptor(name);\n        if (maybeFieldDescriptor.isPresent()) {\n            FieldDescriptor fieldDescriptor = maybeFieldDescriptor.get();\n            methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, fieldDescriptor.declaringClassInternalName());\n            StackManipulationImplementor.swap(methodVisitor);\n            methodVisitor.visitLdcInsn(Type.getType(fieldDescriptor.fieldPythonLikeType().getJavaTypeDescriptor()));\n            methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(JavaPythonTypeConversionImplementor.class),\n                    \"coerceToType\", Type.getMethodDescriptor(Type.getType(Object.class),\n                            Type.getType(PythonLikeObject.class),\n                            Type.getType(Class.class)),\n                    false);\n            methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, fieldDescriptor.fieldPythonLikeType().getJavaTypeInternalName());\n            if (fieldDescriptor.isJavaType()) {\n                // Need to unwrap the object\n                methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, Type.getInternalName(JavaObjectWrapper.class));\n                methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(JavaObjectWrapper.class),\n                        \"getWrappedObject\", Type.getMethodDescriptor(Type.getType(Object.class)), false);\n                methodVisitor.visitTypeInsn(Opcodes.CHECKCAST,\n                        Type.getType(fieldDescriptor.javaFieldTypeDescriptor()).getInternalName());\n            }\n            methodVisitor.visitFieldInsn(Opcodes.PUTFIELD, fieldDescriptor.declaringClassInternalName(),\n                    fieldDescriptor.javaFieldName(),\n                    fieldDescriptor.javaFieldTypeDescriptor());\n        } else {\n            StackManipulationImplementor.swap(methodVisitor);\n            PythonConstantsImplementor.loadName(methodVisitor, className, instruction.arg());\n            StackManipulationImplementor.swap(methodVisitor);\n            DunderOperatorImplementor.ternaryOperator(functionMetadata, stackMetadata.pop(2)\n                    .push(stackMetadata.getValueSourceForStackIndex(0))\n                    .pushTemp(BuiltinTypes.STRING_TYPE)\n                    .push(stackMetadata.getValueSourceForStackIndex(1)),\n                    PythonTernaryOperator.SET_ATTRIBUTE);\n        }\n    }\n\n    /**\n     * Implement (super = TOS2)(TOS1, TOS).attr\n     */\n    public static void getSuperAttribute(FunctionMetadata functionMetadata,\n            StackMetadata stackMetadata,\n            int nameIndex,\n            boolean isLoadMethod) {\n        var methodVisitor = functionMetadata.methodVisitor;\n        // Stack: super, type, instance\n        methodVisitor.visitTypeInsn(Opcodes.NEW, Type.getInternalName(PythonSuperObject.class));\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        // Stack: super, <uninit superobject>, <uninit superobject>, type, instance\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, Type.getInternalName(PythonLikeType.class));\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitMethodInsn(Opcodes.INVOKESPECIAL, Type.getInternalName(PythonSuperObject.class),\n                \"<init>\", Type.getMethodDescriptor(Type.VOID_TYPE, Type.getType(PythonLikeType.class),\n                        Type.getType(PythonLikeObject.class)));\n        // Stack: super, superobject\n        ObjectImplementor.getAttribute(functionMetadata, stackMetadata.pop(2).pushTemp(BuiltinTypes.SUPER_TYPE), nameIndex);\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.POP);\n        if (isLoadMethod) {\n            methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n            methodVisitor.visitInsn(Opcodes.SWAP);\n        }\n    }\n}\n\n```\n# Function Signature: public static void getAttribute(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int nameIndex) {\n# Natural Language Annotations: /**\n     * Replaces TOS with getattr(TOS, co_names[instruction.arg])\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void getAttribute(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int nameIndex) {\n        PythonLikeType tosType = stackMetadata.getTOSType();\n        String name = functionMetadata.pythonCompiledFunction.co_names.get(nameIndex);\n        Optional<FieldDescriptor> maybeFieldDescriptor = tosType.getInstanceFieldDescriptor(name);\n        if (maybeFieldDescriptor.isPresent()) {\n            FieldDescriptor fieldDescriptor = maybeFieldDescriptor.get();\n            functionMetadata.methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, fieldDescriptor.declaringClassInternalName());\n            functionMetadata.methodVisitor.visitFieldInsn(Opcodes.GETFIELD, fieldDescriptor.declaringClassInternalName(),\n                    fieldDescriptor.javaFieldName(),\n                    fieldDescriptor.javaFieldTypeDescriptor());\n        } else {\n            PythonConstantsImplementor.loadName(functionMetadata.methodVisitor, functionMetadata.className, nameIndex);\n            DunderOperatorImplementor.binaryOperator(functionMetadata.methodVisitor,\n                    stackMetadata.pushTemp(BuiltinTypes.STRING_TYPE),\n                    PythonBinaryOperator.GET_ATTRIBUTE);\n        }\n    }\n```", "  ```\npublic static void getAttribute(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int nameIndex) {\n    PythonLikeType tosType = stackMetadata.getTOSType();\n    String name = functionMetadata.pythonCompiledFunction.co_names.get(nameIndex);\n    Optional<FieldDescriptor> maybeFieldDescriptor = tosType.getInstanceFieldDescriptor(name);\n    if (maybeFieldDescriptor.isPresent()) {\n        FieldDescriptor fieldDescriptor = maybeFieldDescriptor.get();\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, fieldDescriptor.declaringClassInternalName());\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, fieldDescriptor.declaringClassInternalName(),\n                fieldDescriptor.javaFieldName(),\n                fieldDescriptor.javaFieldTypeDescriptor());\n    } else {\n        PythonConstantsImplementor.loadName(methodVisitor, functionMetadata.className, nameIndex);\n        DunderOperatorImplementor.binaryOperator(methodVisitor,\n                stackMetadata.pushTemp(BuiltinTypes.STRING_TYPE),\n                PythonBinaryOperator.GET_ATTRIBUTE);\n    }\n}\n```", "  ```\npublic static void getAttribute(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int nameIndex) {\n            var methodVisitor = functionMetadata.methodVisitor;\n            methodVisitor.visitVarInsn(Opcodes.ALOAD, 4); // load \"TOS\" aka stackMetadata\n            PythonConstantsImplementor.loadName(methodVisitor, className, instruction.arg()); // load the attribute name\n            DunderOperatorImplementor.binaryOperator(methodVisitor,\n                    stackMetadata.pushTemp(BuiltinTypes.STRING_TYPE),\n                    PythonBinaryOperator.GET_ATTRIBUTE); // append the attribute name to TOS\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/solution/descriptor/SolutionDescriptor.java-getProblemScale": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/domain/solution/descriptor/SolutionDescriptor.java:\n```\npackage ai.timefold.solver.core.impl.domain.solution.descriptor;\n\nimport static ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessorFactory.MemberAccessorType.FIELD_OR_GETTER_METHOD;\nimport static ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessorFactory.MemberAccessorType.FIELD_OR_READ_METHOD;\nimport static java.util.stream.Stream.concat;\n\nimport java.lang.annotation.Annotation;\nimport java.lang.reflect.AnnotatedElement;\nimport java.lang.reflect.Field;\nimport java.lang.reflect.Member;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.ParameterizedType;\nimport java.lang.reflect.Type;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.IdentityHashMap;\nimport java.util.LinkedHashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Optional;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.ConcurrentMap;\nimport java.util.function.Consumer;\nimport java.util.function.Predicate;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\nimport ai.timefold.solver.core.api.domain.autodiscover.AutoDiscoverMemberType;\nimport ai.timefold.solver.core.api.domain.common.DomainAccessType;\nimport ai.timefold.solver.core.api.domain.constraintweight.ConstraintConfiguration;\nimport ai.timefold.solver.core.api.domain.constraintweight.ConstraintConfigurationProvider;\nimport ai.timefold.solver.core.api.domain.entity.PlanningEntity;\nimport ai.timefold.solver.core.api.domain.solution.ConstraintWeightOverrides;\nimport ai.timefold.solver.core.api.domain.solution.PlanningEntityCollectionProperty;\nimport ai.timefold.solver.core.api.domain.solution.PlanningEntityProperty;\nimport ai.timefold.solver.core.api.domain.solution.PlanningScore;\nimport ai.timefold.solver.core.api.domain.solution.PlanningSolution;\nimport ai.timefold.solver.core.api.domain.solution.ProblemFactCollectionProperty;\nimport ai.timefold.solver.core.api.domain.solution.ProblemFactProperty;\nimport ai.timefold.solver.core.api.domain.solution.cloner.SolutionCloner;\nimport ai.timefold.solver.core.api.domain.valuerange.ValueRangeProvider;\nimport ai.timefold.solver.core.api.score.Score;\nimport ai.timefold.solver.core.api.score.director.ScoreDirector;\nimport ai.timefold.solver.core.api.solver.ProblemSizeStatistics;\nimport ai.timefold.solver.core.config.util.ConfigUtils;\nimport ai.timefold.solver.core.impl.domain.common.ReflectionHelper;\nimport ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessor;\nimport ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessorFactory;\nimport ai.timefold.solver.core.impl.domain.common.accessor.ReflectionFieldMemberAccessor;\nimport ai.timefold.solver.core.impl.domain.entity.descriptor.EntityDescriptor;\nimport ai.timefold.solver.core.impl.domain.lookup.LookUpStrategyResolver;\nimport ai.timefold.solver.core.impl.domain.policy.DescriptorPolicy;\nimport ai.timefold.solver.core.impl.domain.score.descriptor.ScoreDescriptor;\nimport ai.timefold.solver.core.impl.domain.solution.ConstraintConfigurationBasedConstraintWeightSupplier;\nimport ai.timefold.solver.core.impl.domain.solution.ConstraintWeightSupplier;\nimport ai.timefold.solver.core.impl.domain.solution.OverridesBasedConstraintWeightSupplier;\nimport ai.timefold.solver.core.impl.domain.solution.cloner.FieldAccessingSolutionCloner;\nimport ai.timefold.solver.core.impl.domain.solution.cloner.gizmo.GizmoSolutionCloner;\nimport ai.timefold.solver.core.impl.domain.solution.cloner.gizmo.GizmoSolutionClonerFactory;\nimport ai.timefold.solver.core.impl.domain.valuerange.descriptor.EntityIndependentValueRangeDescriptor;\nimport ai.timefold.solver.core.impl.domain.variable.descriptor.GenuineVariableDescriptor;\nimport ai.timefold.solver.core.impl.domain.variable.descriptor.ListVariableDescriptor;\nimport ai.timefold.solver.core.impl.domain.variable.descriptor.ShadowVariableDescriptor;\nimport ai.timefold.solver.core.impl.domain.variable.descriptor.VariableDescriptor;\nimport ai.timefold.solver.core.impl.score.definition.ScoreDefinition;\nimport ai.timefold.solver.core.impl.util.MathUtils;\nimport ai.timefold.solver.core.impl.util.MutableInt;\nimport ai.timefold.solver.core.impl.util.MutableLong;\nimport ai.timefold.solver.core.impl.util.MutablePair;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n/**\n * @param <Solution_> the solution type, the class with the {@link ai.timefold.solver.core.api.domain.solution.PlanningSolution}\n *        annotation\n */\npublic class SolutionDescriptor<Solution_> {\n\n    private static final Logger LOGGER = LoggerFactory.getLogger(SolutionDescriptor.class);\n    private static final EntityDescriptor<?> NULL_ENTITY_DESCRIPTOR = new EntityDescriptor<>(-1, null, PlanningEntity.class);\n\n    public static <Solution_> SolutionDescriptor<Solution_> buildSolutionDescriptor(Class<Solution_> solutionClass,\n            Class<?>... entityClasses) {\n        return buildSolutionDescriptor(solutionClass, Arrays.asList(entityClasses));\n    }\n\n    public static <Solution_> SolutionDescriptor<Solution_> buildSolutionDescriptor(Class<Solution_> solutionClass,\n            List<Class<?>> entityClassList) {\n        return buildSolutionDescriptor(DomainAccessType.REFLECTION, solutionClass, null, null, entityClassList);\n    }\n\n    public static <Solution_> SolutionDescriptor<Solution_> buildSolutionDescriptor(DomainAccessType domainAccessType,\n            Class<Solution_> solutionClass, Map<String, MemberAccessor> memberAccessorMap,\n            Map<String, SolutionCloner> solutionClonerMap, List<Class<?>> entityClassList) {\n        assertMutable(solutionClass, \"solutionClass\");\n        solutionClonerMap = Objects.requireNonNullElse(solutionClonerMap, Collections.emptyMap());\n        var solutionDescriptor = new SolutionDescriptor<>(solutionClass, memberAccessorMap);\n        var descriptorPolicy = new DescriptorPolicy();\n        descriptorPolicy.setDomainAccessType(domainAccessType);\n        descriptorPolicy.setGeneratedSolutionClonerMap(solutionClonerMap);\n        descriptorPolicy.setMemberAccessorFactory(solutionDescriptor.getMemberAccessorFactory());\n\n        solutionDescriptor.processUnannotatedFieldsAndMethods(descriptorPolicy);\n        solutionDescriptor.processAnnotations(descriptorPolicy, entityClassList);\n        int ordinal = 0;\n        for (var entityClass : sortEntityClassList(entityClassList)) {\n            var entityDescriptor = new EntityDescriptor<>(ordinal++, solutionDescriptor, entityClass);\n            solutionDescriptor.addEntityDescriptor(entityDescriptor);\n            entityDescriptor.processAnnotations(descriptorPolicy);\n        }\n        solutionDescriptor.afterAnnotationsProcessed(descriptorPolicy);\n        if (solutionDescriptor.constraintWeightSupplier != null) {\n            // The scoreDescriptor is definitely initialized at this point.\n            solutionDescriptor.constraintWeightSupplier.initialize(solutionDescriptor,\n                    descriptorPolicy.getMemberAccessorFactory(), descriptorPolicy.getDomainAccessType());\n        }\n        return solutionDescriptor;\n    }\n\n    public static void assertMutable(Class<?> clz, String classType) {\n        if (clz.isRecord()) {\n            throw new IllegalArgumentException(\"\"\"\n                    The %s (%s) cannot be a record as it needs to be mutable.\n                    Use a regular class instead.\"\"\"\n                    .formatted(classType, clz.getCanonicalName()));\n        } else if (clz.isEnum()) {\n            throw new IllegalArgumentException(\"\"\"\n                    The %s (%s) cannot be an enum as it needs to be mutable.\n                    Use a regular class instead.\"\"\"\n                    .formatted(classType, clz.getCanonicalName()));\n        }\n    }\n\n    private static List<Class<?>> sortEntityClassList(List<Class<?>> entityClassList) {\n        List<Class<?>> sortedEntityClassList = new ArrayList<>(entityClassList.size());\n        for (Class<?> entityClass : entityClassList) {\n            boolean added = false;\n            for (int i = 0; i < sortedEntityClassList.size(); i++) {\n                Class<?> sortedEntityClass = sortedEntityClassList.get(i);\n                if (entityClass.isAssignableFrom(sortedEntityClass)) {\n                    sortedEntityClassList.add(i, entityClass);\n                    added = true;\n                    break;\n                }\n            }\n            if (!added) {\n                sortedEntityClassList.add(entityClass);\n            }\n        }\n        return sortedEntityClassList;\n    }\n\n    // ************************************************************************\n    // Non-static members\n    // ************************************************************************\n\n    private final Class<Solution_> solutionClass;\n    private final MemberAccessorFactory memberAccessorFactory;\n\n    private DomainAccessType domainAccessType;\n    private AutoDiscoverMemberType autoDiscoverMemberType;\n    private LookUpStrategyResolver lookUpStrategyResolver;\n\n    /**\n     * @deprecated {@link ConstraintConfiguration} was replaced by {@link ConstraintWeightOverrides}.\n     */\n    @Deprecated(forRemoval = true, since = \"1.13.0\")\n    private MemberAccessor constraintConfigurationMemberAccessor;\n    private final Map<String, MemberAccessor> problemFactMemberAccessorMap = new LinkedHashMap<>();\n    private final Map<String, MemberAccessor> problemFactCollectionMemberAccessorMap = new LinkedHashMap<>();\n    private final Map<String, MemberAccessor> entityMemberAccessorMap = new LinkedHashMap<>();\n    private final Map<String, MemberAccessor> entityCollectionMemberAccessorMap = new LinkedHashMap<>();\n    private Set<Class<?>> problemFactOrEntityClassSet;\n    private List<ListVariableDescriptor<Solution_>> listVariableDescriptorList;\n    private ScoreDescriptor<?> scoreDescriptor;\n\n    private ConstraintWeightSupplier<Solution_, ?> constraintWeightSupplier;\n    private final Map<Class<?>, EntityDescriptor<Solution_>> entityDescriptorMap = new LinkedHashMap<>();\n    private final List<Class<?>> reversedEntityClassList = new ArrayList<>();\n    private final ConcurrentMap<Class<?>, EntityDescriptor<Solution_>> lowestEntityDescriptorMap = new ConcurrentHashMap<>();\n    private final ConcurrentMap<Class<?>, MemberAccessor> planningIdMemberAccessorMap = new ConcurrentHashMap<>();\n\n    private SolutionCloner<Solution_> solutionCloner;\n    private boolean assertModelForCloning = false;\n\n    // ************************************************************************\n    // Constructors and simple getters/setters\n    // ************************************************************************\n\n    private SolutionDescriptor(Class<Solution_> solutionClass, Map<String, MemberAccessor> memberAccessorMap) {\n        this.solutionClass = solutionClass;\n        if (solutionClass.getPackage() == null) {\n            LOGGER.warn(\"The solutionClass ({}) should be in a proper java package.\", solutionClass);\n        }\n        this.memberAccessorFactory = new MemberAccessorFactory(memberAccessorMap);\n    }\n\n    public void addEntityDescriptor(EntityDescriptor<Solution_> entityDescriptor) {\n        Class<?> entityClass = entityDescriptor.getEntityClass();\n        for (Class<?> otherEntityClass : entityDescriptorMap.keySet()) {\n            if (entityClass.isAssignableFrom(otherEntityClass)) {\n                throw new IllegalArgumentException(\"An earlier entityClass (\" + otherEntityClass\n                        + \") should not be a subclass of a later entityClass (\" + entityClass\n                        + \"). Switch their declaration so superclasses are defined earlier.\");\n            }\n        }\n        entityDescriptorMap.put(entityClass, entityDescriptor);\n        reversedEntityClassList.add(0, entityClass);\n        lowestEntityDescriptorMap.put(entityClass, entityDescriptor);\n    }\n\n    public void processUnannotatedFieldsAndMethods(DescriptorPolicy descriptorPolicy) {\n        processConstraintWeights(descriptorPolicy);\n    }\n\n    private void processConstraintWeights(DescriptorPolicy descriptorPolicy) {\n        for (var lineageClass : ConfigUtils.getAllParents(solutionClass)) {\n            var memberList = ConfigUtils.getDeclaredMembers(lineageClass);\n            var constraintWeightFieldList = memberList.stream()\n                    .filter(member -> member instanceof Field field\n                            && ConstraintWeightOverrides.class.isAssignableFrom(field.getType()))\n                    .map(f -> ((Field) f))\n                    .toList();\n            switch (constraintWeightFieldList.size()) {\n                case 0:\n                    break;\n                case 1:\n                    if (constraintWeightSupplier != null) {\n                        // The bottom-most class wins, they are parsed first due to ConfigUtil.getAllParents().\n                        throw new IllegalStateException(\n                                \"The solutionClass (%s) has a field of type (%s) which was already found on its parent class.\"\n                                        .formatted(lineageClass, ConstraintWeightOverrides.class));\n                    }\n                    constraintWeightSupplier = OverridesBasedConstraintWeightSupplier.create(this, descriptorPolicy,\n                            constraintWeightFieldList.get(0));\n                    break;\n                default:\n                    throw new IllegalStateException(\"The solutionClass (%s) has more than one field (%s) of type %s.\"\n                            .formatted(solutionClass, constraintWeightFieldList, ConstraintWeightOverrides.class));\n            }\n        }\n    }\n\n    @SuppressWarnings({ \"rawtypes\", \"unchecked\" })\n    public void processAnnotations(DescriptorPolicy descriptorPolicy, List<Class<?>> entityClassList) {\n        domainAccessType = descriptorPolicy.getDomainAccessType();\n        processSolutionAnnotations(descriptorPolicy);\n        ArrayList<Method> potentiallyOverwritingMethodList = new ArrayList<>();\n        // Iterate inherited members too (unlike for EntityDescriptor where each one is declared)\n        // to make sure each one is registered\n        for (Class<?> lineageClass : ConfigUtils.getAllAnnotatedLineageClasses(solutionClass, PlanningSolution.class)) {\n            List<Member> memberList = ConfigUtils.getDeclaredMembers(lineageClass);\n            for (Member member : memberList) {\n                if (member instanceof Method method && potentiallyOverwritingMethodList.stream().anyMatch(\n                        m -> member.getName().equals(m.getName()) // Shortcut to discard negatives faster\n                                && ReflectionHelper.isMethodOverwritten(method, m.getDeclaringClass()))) {\n                    // Ignore member because it is an overwritten method\n                    continue;\n                }\n                processValueRangeProviderAnnotation(descriptorPolicy, member);\n                processFactEntityOrScoreAnnotation(descriptorPolicy, member, entityClassList);\n            }\n            potentiallyOverwritingMethodList.ensureCapacity(potentiallyOverwritingMethodList.size() + memberList.size());\n            memberList.stream().filter(member -> member instanceof Method)\n                    .forEach(member -> potentiallyOverwritingMethodList.add((Method) member));\n        }\n        if (entityCollectionMemberAccessorMap.isEmpty() && entityMemberAccessorMap.isEmpty()) {\n            throw new IllegalStateException(\"The solutionClass (\" + solutionClass\n                    + \") must have at least 1 member with a \"\n                    + PlanningEntityCollectionProperty.class.getSimpleName() + \" annotation or a \"\n                    + PlanningEntityProperty.class.getSimpleName() + \" annotation.\");\n        }\n        // Do not check if problemFactCollectionMemberAccessorMap and problemFactMemberAccessorMap are empty\n        // because they are only required for ConstraintStreams.\n        if (scoreDescriptor == null) {\n            throw new IllegalStateException(\"The solutionClass (\" + solutionClass\n                    + \") must have 1 member with a @\" + PlanningScore.class.getSimpleName() + \" annotation.\\n\"\n                    + \"Maybe add a getScore() method with a @\" + PlanningScore.class.getSimpleName() + \" annotation.\");\n        }\n    }\n\n    private void processSolutionAnnotations(DescriptorPolicy descriptorPolicy) {\n        PlanningSolution solutionAnnotation = solutionClass.getAnnotation(PlanningSolution.class);\n        if (solutionAnnotation == null) {\n            throw new IllegalStateException(\"The solutionClass (\" + solutionClass\n                    + \") has been specified as a solution in the configuration,\" +\n                    \" but does not have a @\" + PlanningSolution.class.getSimpleName() + \" annotation.\");\n        }\n        autoDiscoverMemberType = solutionAnnotation.autoDiscoverMemberType();\n        Class<? extends SolutionCloner> solutionClonerClass = solutionAnnotation.solutionCloner();\n        if (solutionClonerClass != PlanningSolution.NullSolutionCloner.class) {\n            solutionCloner = ConfigUtils.newInstance(this::toString, \"solutionClonerClass\", solutionClonerClass);\n        }\n        lookUpStrategyResolver =\n                new LookUpStrategyResolver(descriptorPolicy, solutionAnnotation.lookUpStrategyType());\n    }\n\n    private void processValueRangeProviderAnnotation(DescriptorPolicy descriptorPolicy, Member member) {\n        if (((AnnotatedElement) member).isAnnotationPresent(ValueRangeProvider.class)) {\n            MemberAccessor memberAccessor = descriptorPolicy.getMemberAccessorFactory().buildAndCacheMemberAccessor(member,\n                    FIELD_OR_READ_METHOD, ValueRangeProvider.class, descriptorPolicy.getDomainAccessType());\n            descriptorPolicy.addFromSolutionValueRangeProvider(memberAccessor);\n        }\n    }\n\n    private void processFactEntityOrScoreAnnotation(DescriptorPolicy descriptorPolicy,\n            Member member, List<Class<?>> entityClassList) {\n        Class<? extends Annotation> annotationClass = extractFactEntityOrScoreAnnotationClassOrAutoDiscover(\n                member, entityClassList);\n        if (annotationClass == null) {\n            return;\n        }\n        if (annotationClass.equals(ConstraintConfigurationProvider.class)) {\n            processConstraintConfigurationProviderAnnotation(descriptorPolicy, member, annotationClass);\n        } else if (annotationClass.equals(ProblemFactProperty.class)\n                || annotationClass.equals(ProblemFactCollectionProperty.class)) {\n            processProblemFactPropertyAnnotation(descriptorPolicy, member, annotationClass);\n        } else if (annotationClass.equals(PlanningEntityProperty.class)\n                || annotationClass.equals(PlanningEntityCollectionProperty.class)) {\n            processPlanningEntityPropertyAnnotation(descriptorPolicy, member, annotationClass);\n        } else if (annotationClass.equals(PlanningScore.class)) {\n            if (scoreDescriptor == null) {\n                // Bottom class wins. Bottom classes are parsed first due to ConfigUtil.getAllAnnotatedLineageClasses().\n                scoreDescriptor = ScoreDescriptor.buildScoreDescriptor(descriptorPolicy, member, solutionClass);\n            } else {\n                scoreDescriptor.failFastOnDuplicateMember(descriptorPolicy, member, solutionClass);\n            }\n        }\n    }\n\n    private Class<? extends Annotation> extractFactEntityOrScoreAnnotationClassOrAutoDiscover(\n            Member member, List<Class<?>> entityClassList) {\n        Class<? extends Annotation> annotationClass = ConfigUtils.extractAnnotationClass(member,\n                ConstraintConfigurationProvider.class,\n                ProblemFactProperty.class,\n                ProblemFactCollectionProperty.class,\n                PlanningEntityProperty.class, PlanningEntityCollectionProperty.class,\n                PlanningScore.class);\n        if (annotationClass == null) {\n            Class<?> type;\n            if (autoDiscoverMemberType == AutoDiscoverMemberType.FIELD\n                    && member instanceof Field field) {\n                type = field.getType();\n            } else if (autoDiscoverMemberType == AutoDiscoverMemberType.GETTER\n                    && (member instanceof Method method) && ReflectionHelper.isGetterMethod(method)) {\n                type = method.getReturnType();\n            } else {\n                type = null;\n            }\n            if (type != null) {\n                if (Score.class.isAssignableFrom(type)) {\n                    annotationClass = PlanningScore.class;\n                } else if (Collection.class.isAssignableFrom(type) || type.isArray()) {\n                    Class<?> elementType;\n                    if (Collection.class.isAssignableFrom(type)) {\n                        Type genericType = (member instanceof Field f) ? f.getGenericType()\n                                : ((Method) member).getGenericReturnType();\n                        String memberName = member.getName();\n                        if (!(genericType instanceof ParameterizedType)) {\n                            throw new IllegalArgumentException(\"The solutionClass (\" + solutionClass + \") has a \"\n                                    + \"auto discovered member (\" + memberName + \") with a member type (\" + type\n                                    + \") that returns a \" + Collection.class.getSimpleName()\n                                    + \" which has no generic parameters.\\n\"\n                                    + \"Maybe the member (\" + memberName + \") should return a typed \"\n                                    + Collection.class.getSimpleName() + \".\");\n                        }\n                        elementType = ConfigUtils.extractGenericTypeParameter(\"solutionClass\", solutionClass, type, genericType,\n                                null, member.getName()).orElse(Object.class);\n                    } else {\n                        elementType = type.getComponentType();\n                    }\n                    if (entityClassList.stream().anyMatch(entityClass -> entityClass.isAssignableFrom(elementType))) {\n                        annotationClass = PlanningEntityCollectionProperty.class;\n                    } else if (elementType.isAnnotationPresent(ConstraintConfiguration.class)) {\n                        throw new IllegalStateException(\"The autoDiscoverMemberType (\" + autoDiscoverMemberType\n                                + \") cannot accept a member (\" + member\n                                + \") of type (\" + type\n                                + \") with an elementType (\" + elementType\n                                + \") that has a @\" + ConstraintConfiguration.class.getSimpleName() + \" annotation.\\n\"\n                                + \"Maybe use a member of the type (\" + elementType + \") directly instead of a \"\n                                + Collection.class.getSimpleName() + \" or array of that type.\");\n                    } else {\n                        annotationClass = ProblemFactCollectionProperty.class;\n                    }\n                } else if (Map.class.isAssignableFrom(type)) {\n                    throw new IllegalStateException(\"The autoDiscoverMemberType (\" + autoDiscoverMemberType\n                            + \") does not yet support the member (\" + member\n                            + \") of type (\" + type\n                            + \") which is an implementation of \" + Map.class.getSimpleName() + \".\");\n                } else if (entityClassList.stream().anyMatch(entityClass -> entityClass.isAssignableFrom(type))) {\n                    annotationClass = PlanningEntityProperty.class;\n                } else if (type.isAnnotationPresent(ConstraintConfiguration.class)) {\n                    annotationClass = ConstraintConfigurationProvider.class;\n                } else {\n                    annotationClass = ProblemFactProperty.class;\n                }\n            }\n        }\n        return annotationClass;\n    }\n\n    /**\n     * @deprecated {@link ConstraintConfiguration} was replaced by {@link ConstraintWeightOverrides}.\n     */\n    @Deprecated(forRemoval = true, since = \"1.13.0\")\n    private void processConstraintConfigurationProviderAnnotation(DescriptorPolicy descriptorPolicy, Member member,\n            Class<? extends Annotation> annotationClass) {\n        if (constraintWeightSupplier != null) {\n            throw new IllegalStateException(\"\"\"\n                    The solution class (%s) has both a %s member and a %s-annotated member.\n                    %s is deprecated, please remove it from your codebase and keep %s only.\"\"\"\n                    .formatted(solutionClass, ConstraintWeightOverrides.class.getSimpleName(),\n                            ConstraintConfigurationProvider.class.getSimpleName(),\n                            ConstraintConfigurationProvider.class.getSimpleName(),\n                            ConstraintWeightOverrides.class.getSimpleName()));\n        }\n        MemberAccessor memberAccessor = descriptorPolicy.getMemberAccessorFactory().buildAndCacheMemberAccessor(member,\n                FIELD_OR_READ_METHOD, annotationClass, descriptorPolicy.getDomainAccessType());\n        if (constraintConfigurationMemberAccessor != null) {\n            if (!constraintConfigurationMemberAccessor.getName().equals(memberAccessor.getName())\n                    || !constraintConfigurationMemberAccessor.getClass().equals(memberAccessor.getClass())) {\n                throw new IllegalStateException(\"The solutionClass (\" + solutionClass\n                        + \") has a @\" + ConstraintConfigurationProvider.class.getSimpleName()\n                        + \" annotated member (\" + memberAccessor\n                        + \") that is duplicated by another member (\" + constraintConfigurationMemberAccessor + \").\\n\"\n                        + \"Maybe the annotation is defined on both the field and its getter.\");\n            }\n            // Bottom class wins. Bottom classes are parsed first due to ConfigUtil.getAllAnnotatedLineageClasses()\n            return;\n        }\n        assertNoFieldAndGetterDuplicationOrConflict(memberAccessor, annotationClass);\n        constraintConfigurationMemberAccessor = memberAccessor;\n        // Every ConstraintConfiguration is also a problem fact\n        problemFactMemberAccessorMap.put(memberAccessor.getName(), memberAccessor);\n\n        Class<?> constraintConfigurationClass = constraintConfigurationMemberAccessor.getType();\n        if (!constraintConfigurationClass.isAnnotationPresent(ConstraintConfiguration.class)) {\n            throw new IllegalStateException(\"The solutionClass (\" + solutionClass\n                    + \") has a @\" + ConstraintConfigurationProvider.class.getSimpleName()\n                    + \" annotated member (\" + member + \") that does not return a class (\"\n                    + constraintConfigurationClass + \") that has a \"\n                    + ConstraintConfiguration.class.getSimpleName() + \" annotation.\");\n        }\n        constraintWeightSupplier =\n                ConstraintConfigurationBasedConstraintWeightSupplier.create(this, constraintConfigurationClass);\n    }\n\n    private void processProblemFactPropertyAnnotation(DescriptorPolicy descriptorPolicy,\n            Member member,\n            Class<? extends Annotation> annotationClass) {\n        MemberAccessor memberAccessor = descriptorPolicy.getMemberAccessorFactory().buildAndCacheMemberAccessor(member,\n                FIELD_OR_READ_METHOD, annotationClass, descriptorPolicy.getDomainAccessType());\n        assertNoFieldAndGetterDuplicationOrConflict(memberAccessor, annotationClass);\n        if (annotationClass == ProblemFactProperty.class) {\n            problemFactMemberAccessorMap.put(memberAccessor.getName(), memberAccessor);\n        } else if (annotationClass == ProblemFactCollectionProperty.class) {\n            Class<?> type = memberAccessor.getType();\n            if (!(Collection.class.isAssignableFrom(type) || type.isArray())) {\n                throw new IllegalStateException(\"The solutionClass (\" + solutionClass\n                        + \") has a @\" + ProblemFactCollectionProperty.class.getSimpleName()\n                        + \" annotated member (\" + member + \") that does not return a \"\n                        + Collection.class.getSimpleName() + \" or an array.\");\n            }\n            problemFactCollectionMemberAccessorMap.put(memberAccessor.getName(), memberAccessor);\n        } else {\n            throw new IllegalStateException(\"Impossible situation with annotationClass (\" + annotationClass + \").\");\n        }\n    }\n\n    private void processPlanningEntityPropertyAnnotation(DescriptorPolicy descriptorPolicy,\n            Member member,\n            Class<? extends Annotation> annotationClass) {\n        MemberAccessor memberAccessor = descriptorPolicy.getMemberAccessorFactory().buildAndCacheMemberAccessor(member,\n                FIELD_OR_GETTER_METHOD, annotationClass, descriptorPolicy.getDomainAccessType());\n        assert\n```\n# Function Signature: public double getProblemScale(ScoreDirector<Solution_> scoreDirector, Solution_ solution) {\n# Natural Language Annotations: /**\n     * Calculates an indication on how big this problem instance is.\n     * This is approximately the base 10 log of the search space size.\n     *\n     * @param solution never null\n     * @return {@code >= 0}\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic double getProblemScale(ScoreDirector<Solution_> scoreDirector, Solution_ solution) {\n    long uninitializedEntityCount = entityDescriptorMap.values().stream()\n            .map(entityDescriptor -> entityDescriptor.getPlanningEntityCount(scoreDirector, solution))\n            .filter(count -> count == 0L)\n            .count();\n    long traitListSize = solution.getTraitList().size();\n    long planningEntityCount = entityDescriptorMap.values().stream()\n            .map(entityDescriptor -> entityDescriptor.getPlanningEntityCount(scoreDirector, solution))\n            .mapToLong(count -> count)\n            .sum();\n    if (problemFactMemberAccessorMap.isEmpty() && problemFactCollectionMemberAccessorMap.isEmpty()) {\n        return 0.0;\n    }\n    double problemScale;\n    if (uninitializedEntityCount == Math.max(problemFactMemberAccessorMap.size(), problemFactCollectionMemberAccessorMap.size())) {\n        problemScale = MathUtils.log10(problemFactMemberAccessorMap.size()\n                + problemFactCollectionMemberAccessorMap.size()\n                + planningEntityCount\n                + traitListSize);\n    } else {\n        problemScale = MathUtils.log10(1 + problemFactMemberAccessorMap.size()\n                + problemFactCollectionMemberAccessorMap.size()\n                + planningEntityCount\n                + 1\n                + traitListSize);\n    }\n    return problemScale;\n}\n```", "  ```\npublic double getProblemScale(ScoreDirector<Solution_> scoreDirector, Solution_ solution) {\n        long problemScale = 0L;\n        for (EntityDescriptor<Solution_> entityDescriptor : lowestEntityDescriptorMap.values()) {\n            Class<?> entityClass = entityDescriptor.getEntityClass();\n            long entitySize = scoreDirector.countUninitializedVariables(solution, entityClass);\n            // Math.log10 is an expensive operation, so use Math.log and divide by a constant.\n            // Also increment problemScale correctly for the entitySize, which is possibly very lonely.\n            // In fragment-counting terms, treat entitySize as count of longs, not integers.\n            int entitySizeMagnitude = (int) Math.log10(entitySize);\n            problemScale += entitySizeMagnitude;\n        }\n        return problemScale;\n    }\n```", "  [COUNT]  Parameters:\n[/COUNT]  * `scoreDirector`: the `ScoreDirector` object that provides access to the problem facts and planning entities\n  of this problem, never null\n* `solution`: the current best known solution to this problem, never null\n\n[COUNT]  Body:\n[/COUNT]  In this case, we are calculating an indication on how big this problem instance is.\nWe are doing this by calculating the base 10 logarithm of the search space size, which is the number\nof possible values of the planning variables in the problem.\n\nWe can obtain the search space size by summing the size of the variable domains of each planning\nvariable in the problem. We can get the size of each variable domain by multiplying the upper\nbound of the range divided by the lower bound of the range.\n\nOnce we have the size of each variable domain, we can sum them up to get the overall search\nspace size. Finally, we take the base 10 logarithm of the search space size to get the scale.\n\nHere's the code:\n```\ndouble problemScale = 0.0;\nfor (EntityDescriptor<Solution_> entityDescriptor : entityDescriptorMap.values()) {\n    problemScale += entityDescriptor.getProblemScale(scoreDirector, solution);\n}\nreturn Math.log10(problemScale);\n```\nThis code sums up the problem scale of each entity in the problem and returns the log base 10 of\nthe sum. The `entityDescriptorMap` is a map of the entity class to the corresponding `EntityDescriptor`.\nThe `EntityDescriptor` has a method `getProblemScale` that calculates the problem scale of a particular\nentity. By summing up the problem scale of each entity, we get the total search space size of the\nproblem, and then take the base 10 logarithm of that to get the problem scale."]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/solution/cloner/gizmo/GizmoSolutionClonerImplementor.java-defineClonerFor": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/domain/solution/cloner/gizmo/GizmoSolutionClonerImplementor.java:\n```\npackage ai.timefold.solver.core.impl.domain.solution.cloner.gizmo;\n\nimport java.io.IOException;\nimport java.lang.reflect.Field;\nimport java.lang.reflect.InvocationTargetException;\nimport java.lang.reflect.Modifier;\nimport java.lang.reflect.ParameterizedType;\nimport java.lang.reflect.Type;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.IdentityHashMap;\nimport java.util.Iterator;\nimport java.util.LinkedHashMap;\nimport java.util.LinkedHashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Optional;\nimport java.util.Set;\nimport java.util.SortedSet;\nimport java.util.TreeSet;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.solver.core.api.domain.solution.cloner.SolutionCloner;\nimport ai.timefold.solver.core.impl.domain.common.accessor.gizmo.GizmoClassLoader;\nimport ai.timefold.solver.core.impl.domain.common.accessor.gizmo.GizmoMemberDescriptor;\nimport ai.timefold.solver.core.impl.domain.solution.cloner.DeepCloningUtils;\nimport ai.timefold.solver.core.impl.domain.solution.cloner.FieldAccessingSolutionCloner;\nimport ai.timefold.solver.core.impl.domain.solution.cloner.PlanningCloneable;\nimport ai.timefold.solver.core.impl.domain.solution.descriptor.SolutionDescriptor;\nimport ai.timefold.solver.core.impl.util.MutableReference;\n\nimport io.quarkus.gizmo.AssignableResultHandle;\nimport io.quarkus.gizmo.BranchResult;\nimport io.quarkus.gizmo.BytecodeCreator;\nimport io.quarkus.gizmo.ClassCreator;\nimport io.quarkus.gizmo.ClassOutput;\nimport io.quarkus.gizmo.FieldDescriptor;\nimport io.quarkus.gizmo.MethodCreator;\nimport io.quarkus.gizmo.MethodDescriptor;\nimport io.quarkus.gizmo.ResultHandle;\n\npublic class GizmoSolutionClonerImplementor {\n    private static final MethodDescriptor EQUALS_METHOD = MethodDescriptor.ofMethod(Object.class, \"equals\", boolean.class,\n            Object.class);\n    protected static final MethodDescriptor GET_METHOD = MethodDescriptor.ofMethod(Map.class, \"get\", Object.class,\n            Object.class);\n    private static final MethodDescriptor PUT_METHOD = MethodDescriptor.ofMethod(Map.class, \"put\", Object.class,\n            Object.class, Object.class);\n    private static final String FALLBACK_CLONER = \"fallbackCloner\";\n    public static final boolean DEBUG = false;\n\n    /**\n     * Return a comparator that sorts classes into instanceof check order.\n     * In particular, if x is a subclass of y, then x will appear earlier\n     * than y in the list.\n     *\n     * @param deepClonedClassSet The set of classes to generate a comparator for\n     * @return A comparator that sorts classes from deepClonedClassSet such that\n     *         x &lt; y if x is assignable from y.\n     */\n    public static Comparator<Class<?>> getInstanceOfComparator(Set<Class<?>> deepClonedClassSet) {\n        Map<Class<?>, Integer> classToSubclassLevel = new HashMap<>();\n        deepClonedClassSet\n                .forEach(clazz -> {\n                    if (deepClonedClassSet.stream()\n                            .allMatch(\n                                    otherClazz -> clazz.isAssignableFrom(otherClazz) || !otherClazz.isAssignableFrom(clazz))) {\n                        classToSubclassLevel.put(clazz, 0);\n                    }\n                });\n        boolean isChanged = true;\n        while (isChanged) {\n            // Need to iterate over all classes\n            // since maxSubclassLevel can change\n            // (for instance, Tiger extends Cat (1) implements Animal (0))\n            isChanged = false;\n            for (Class<?> clazz : deepClonedClassSet) {\n                Optional<Integer> maxParentSubclassLevel = classToSubclassLevel.keySet().stream()\n                        .filter(otherClazz -> otherClazz != clazz && otherClazz.isAssignableFrom(clazz))\n                        .map(classToSubclassLevel::get)\n                        .max(Integer::compare);\n\n                if (maxParentSubclassLevel.isPresent()) {\n                    Integer oldVal = classToSubclassLevel.getOrDefault(clazz, -1);\n                    Integer newVal = maxParentSubclassLevel.get() + 1;\n                    if (newVal.compareTo(oldVal) > 0) {\n                        isChanged = true;\n                        classToSubclassLevel.put(clazz, newVal);\n                    }\n                }\n            }\n        }\n\n        return Comparator.<Class<?>, Integer> comparing(classToSubclassLevel::get)\n                .thenComparing(Class::getName).reversed();\n    }\n\n    protected void createFields(ClassCreator classCreator) {\n        classCreator.getFieldCreator(FALLBACK_CLONER, FieldAccessingSolutionCloner.class)\n                .setModifiers(Modifier.PRIVATE | Modifier.STATIC);\n    }\n\n    /**\n     * Generates the constructor and implementations of SolutionCloner methods for the given SolutionDescriptor using the given\n     * ClassCreator\n     */\n\n\n\n\n\n\n\n\n\n    /**\n     * Generates the constructor and implementations of SolutionCloner\n     * methods for the given SolutionDescriptor using the given ClassCreator\n     */\n    public static void defineClonerFor(Supplier<GizmoSolutionClonerImplementor> implementorSupplier,\n            ClassCreator classCreator,\n            SolutionDescriptor<?> solutionDescriptor,\n            Set<Class<?>> solutionClassSet,\n            Map<Class<?>, GizmoSolutionOrEntityDescriptor> memoizedSolutionOrEntityDescriptorMap,\n            Set<Class<?>> deepClonedClassSet) {\n        GizmoSolutionClonerImplementor implementor = implementorSupplier.get();\n        // Classes that are not instances of any other class in the collection\n        // have a subclass level of 0.\n        // Other classes subclass level is the maximum of the subclass level\n        // of the classes it is a subclass of + 1\n        Set<Class<?>> deepCloneClassesThatAreNotSolutionSet =\n                deepClonedClassSet.stream()\n                        .filter(clazz -> !solutionClassSet.contains(clazz) && !clazz.isArray())\n                        .filter(clazz -> !clazz.isInterface() && !Modifier.isAbstract(clazz.getModifiers()))\n                        .collect(Collectors.toSet());\n\n        Comparator<Class<?>> instanceOfComparator = getInstanceOfComparator(deepClonedClassSet);\n        SortedSet<Class<?>> deepCloneClassesThatAreNotSolutionSortedSet = new TreeSet<>(instanceOfComparator);\n        deepCloneClassesThatAreNotSolutionSortedSet.addAll(deepCloneClassesThatAreNotSolutionSet);\n\n        implementor.createFields(classCreator);\n        implementor.createConstructor(classCreator);\n        implementor.createSetSolutionDescriptor(classCreator, solutionDescriptor);\n        implementor.createCloneSolution(classCreator, solutionDescriptor);\n        implementor.createCloneSolutionRun(classCreator, solutionDescriptor, solutionClassSet,\n                memoizedSolutionOrEntityDescriptorMap,\n                deepCloneClassesThatAreNotSolutionSortedSet, instanceOfComparator);\n\n        for (Class<?> deepClonedClass : deepCloneClassesThatAreNotSolutionSortedSet) {\n            implementor.createDeepCloneHelperMethod(classCreator, deepClonedClass, solutionDescriptor,\n                    memoizedSolutionOrEntityDescriptorMap,\n                    deepCloneClassesThatAreNotSolutionSortedSet);\n        }\n\n        Set<Class<?>> abstractDeepCloneClassSet =\n                deepClonedClassSet.stream()\n                        .filter(clazz -> !solutionClassSet.contains(clazz) && !clazz.isArray())\n                        .filter(clazz -> clazz.isInterface() || Modifier.isAbstract(clazz.getModifiers()))\n                        .collect(Collectors.toSet());\n\n        for (Class<?> abstractDeepClonedClass : abstractDeepCloneClassSet) {\n            implementor.createAbstractDeepCloneHelperMethod(classCreator, abstractDeepClonedClass, solutionDescriptor,\n                    memoizedSolutionOrEntityDescriptorMap,\n                    deepCloneClassesThatAreNotSolutionSortedSet);\n        }\n    }\n\n    public static ClassOutput createClassOutputWithDebuggingCapability(MutableReference<byte[]> classBytecodeHolder) {\n        return (path, byteCode) -> {\n            classBytecodeHolder.setValue(byteCode);\n\n            if (DEBUG) {\n                Path debugRoot = Paths.get(\"target/timefold-solver-generated-classes\");\n                Path rest = Paths.get(path + \".class\");\n                Path destination = debugRoot.resolve(rest);\n\n                try {\n                    Files.createDirectories(destination.getParent());\n                    Files.write(destination, byteCode);\n                } catch (IOException e) {\n                    throw new IllegalStateException(\"Fail to write debug class file \" + destination + \".\", e);\n                }\n            }\n        };\n    }\n\n    static <T> SolutionCloner<T> createClonerFor(SolutionDescriptor<T> solutionDescriptor,\n            GizmoClassLoader gizmoClassLoader) {\n        GizmoSolutionClonerImplementor implementor = new GizmoSolutionClonerImplementor();\n        String className = GizmoSolutionClonerFactory.getGeneratedClassName(solutionDescriptor);\n        if (gizmoClassLoader.hasBytecodeFor(className)) {\n            return implementor.createInstance(className, gizmoClassLoader, solutionDescriptor);\n        }\n        MutableReference<byte[]> classBytecodeHolder = new MutableReference<>(null);\n        ClassCreator classCreator = ClassCreator.builder()\n                .className(className)\n                .interfaces(GizmoSolutionCloner.class)\n                .superClass(Object.class)\n                .classOutput(createClassOutputWithDebuggingCapability(classBytecodeHolder))\n                .setFinal(true)\n                .build();\n\n        Set<Class<?>> deepClonedClassSet = GizmoCloningUtils.getDeepClonedClasses(solutionDescriptor, Collections.emptyList());\n\n        defineClonerFor(() -> implementor, classCreator, solutionDescriptor,\n                Collections.singleton(solutionDescriptor.getSolutionClass()),\n                new HashMap<>(), deepClonedClassSet);\n\n        classCreator.close();\n        byte[] classBytecode = classBytecodeHolder.getValue();\n\n        gizmoClassLoader.storeBytecode(className, classBytecode);\n        return implementor.createInstance(className, gizmoClassLoader, solutionDescriptor);\n    }\n\n    private <T> SolutionCloner<T> createInstance(String className, ClassLoader gizmoClassLoader,\n            SolutionDescriptor<T> solutionDescriptor) {\n        try {\n            @SuppressWarnings(\"unchecked\")\n            Class<? extends GizmoSolutionCloner<T>> outClass =\n                    (Class<? extends GizmoSolutionCloner<T>>) gizmoClassLoader.loadClass(className);\n            GizmoSolutionCloner<T> out = outClass.getConstructor().newInstance();\n            out.setSolutionDescriptor(solutionDescriptor);\n            return out;\n        } catch (InvocationTargetException | InstantiationException | IllegalAccessException | ClassNotFoundException\n                | NoSuchMethodException e) {\n            throw new IllegalStateException(e);\n        }\n    }\n\n    private void createConstructor(ClassCreator classCreator) {\n        MethodCreator methodCreator = classCreator.getMethodCreator(\n                MethodDescriptor.ofConstructor(classCreator.getClassName()));\n        ResultHandle thisObj = methodCreator.getThis();\n\n        // Invoke Object's constructor\n        methodCreator.invokeSpecialMethod(MethodDescriptor.ofConstructor(Object.class), thisObj);\n\n        // Return this (it a constructor)\n        methodCreator.returnValue(thisObj);\n    }\n\n    protected void createSetSolutionDescriptor(ClassCreator classCreator, SolutionDescriptor<?> solutionDescriptor) {\n        MethodCreator methodCreator = classCreator.getMethodCreator(\n                MethodDescriptor.ofMethod(GizmoSolutionCloner.class, \"setSolutionDescriptor\", void.class,\n                        SolutionDescriptor.class));\n\n        methodCreator.writeStaticField(FieldDescriptor.of(\n                GizmoSolutionClonerFactory.getGeneratedClassName(solutionDescriptor),\n                FALLBACK_CLONER, FieldAccessingSolutionCloner.class),\n                methodCreator.newInstance(\n                        MethodDescriptor.ofConstructor(FieldAccessingSolutionCloner.class, SolutionDescriptor.class),\n                        methodCreator.getMethodParam(0)));\n\n        methodCreator.returnValue(null);\n    }\n\n    private void createCloneSolution(ClassCreator classCreator, SolutionDescriptor<?> solutionDescriptor) {\n        Class<?> solutionClass = solutionDescriptor.getSolutionClass();\n        MethodCreator methodCreator =\n                classCreator.getMethodCreator(MethodDescriptor.ofMethod(SolutionCloner.class,\n                        \"cloneSolution\",\n                        Object.class,\n                        Object.class));\n\n        ResultHandle thisObj = methodCreator.getMethodParam(0);\n\n        ResultHandle clone = methodCreator.invokeStaticMethod(\n                MethodDescriptor.ofMethod(\n                        GizmoSolutionClonerFactory.getGeneratedClassName(solutionDescriptor),\n                        \"cloneSolutionRun\", solutionClass, solutionClass, Map.class),\n                thisObj,\n                methodCreator.newInstance(MethodDescriptor.ofConstructor(IdentityHashMap.class)));\n        methodCreator.returnValue(clone);\n    }\n\n    private void createCloneSolutionRun(ClassCreator classCreator, SolutionDescriptor solutionDescriptor,\n            Set<Class<?>> solutionClassSet,\n            Map<Class<?>, GizmoSolutionOrEntityDescriptor> memoizedSolutionOrEntityDescriptorMap,\n            SortedSet<Class<?>> deepClonedClassesSortedSet, Comparator<Class<?>> instanceOfComparator) {\n        Class<?> solutionClass = solutionDescriptor.getSolutionClass();\n        MethodCreator methodCreator =\n                classCreator.getMethodCreator(\"cloneSolutionRun\", solutionClass, solutionClass, Map.class);\n        methodCreator.setModifiers(Modifier.STATIC | Modifier.PRIVATE);\n\n        ResultHandle thisObj = methodCreator.getMethodParam(0);\n        BranchResult solutionNullBranchResult = methodCreator.ifNull(thisObj);\n        BytecodeCreator solutionIsNullBranch = solutionNullBranchResult.trueBranch();\n        solutionIsNullBranch.returnValue(thisObj); // thisObj is null\n\n        BytecodeCreator solutionIsNotNullBranch = solutionNullBranchResult.falseBranch();\n\n        ResultHandle createdCloneMap = methodCreator.getMethodParam(1);\n\n        ResultHandle maybeClone = solutionIsNotNullBranch.invokeInterfaceMethod(\n                GET_METHOD, createdCloneMap, thisObj);\n        BranchResult hasCloneBranchResult = solutionIsNotNullBranch.ifNotNull(maybeClone);\n        BytecodeCreator hasCloneBranch = hasCloneBranchResult.trueBranch();\n        hasCloneBranch.returnValue(maybeClone);\n\n        BytecodeCreator noCloneBranch = hasCloneBranchResult.falseBranch();\n        List<Class<?>> sortedSolutionClassList = new ArrayList<>(solutionClassSet);\n        sortedSolutionClassList.sort(instanceOfComparator);\n\n        BytecodeCreator currentBranch = noCloneBranch;\n        ResultHandle thisObjClass =\n                currentBranch.invokeVirtualMethod(MethodDescriptor.ofMethod(Object.class, \"getClass\", Class.class), thisObj);\n        for (Class<?> solutionSubclass : sortedSolutionClassList) {\n            ResultHandle solutionSubclassResultHandle = currentBranch.loadClass(solutionSubclass);\n            ResultHandle isSubclass =\n                    currentBranch.invokeVirtualMethod(EQUALS_METHOD, solutionSubclassResultHandle, thisObjClass);\n            BranchResult isSubclassBranchResult = currentBranch.ifTrue(isSubclass);\n\n            BytecodeCreator isSubclassBranch = isSubclassBranchResult.trueBranch();\n\n            GizmoSolutionOrEntityDescriptor solutionSubclassDescriptor =\n                    memoizedSolutionOrEntityDescriptorMap.computeIfAbsent(solutionSubclass,\n                            (key) -> new GizmoSolutionOrEntityDescriptor(solutionDescriptor, solutionSubclass));\n\n            ResultHandle clone;\n            if (PlanningCloneable.class.isAssignableFrom(solutionSubclass)) {\n                clone = isSubclassBranch.invokeInterfaceMethod(\n                        MethodDescriptor.ofMethod(PlanningCloneable.class, \"createNewInstance\", Object.class),\n                        thisObj);\n                clone = isSubclassBranch.checkCast(clone, solutionSubclass);\n            } else {\n                clone = isSubclassBranch.newInstance(MethodDescriptor.ofConstructor(solutionSubclass));\n            }\n\n            isSubclassBranch.invokeInterfaceMethod(\n                    MethodDescriptor.ofMethod(Map.class, \"put\", Object.class, Object.class, Object.class),\n                    createdCloneMap, thisObj, clone);\n\n            for (GizmoMemberDescriptor shallowlyClonedField : solutionSubclassDescriptor.getShallowClonedMemberDescriptors()) {\n                writeShallowCloneInstructions(solutionSubclassDescriptor, isSubclassBranch, shallowlyClonedField, thisObj,\n                        clone, createdCloneMap, deepClonedClassesSortedSet);\n            }\n\n            for (Field deeplyClonedField : solutionSubclassDescriptor.getDeepClonedFields()) {\n                GizmoMemberDescriptor gizmoMemberDescriptor =\n                        solutionSubclassDescriptor.getMemberDescriptorForField(deeplyClonedField);\n\n                ResultHandle fieldValue = gizmoMemberDescriptor.readMemberValue(isSubclassBranch, thisObj);\n                AssignableResultHandle cloneValue = isSubclassBranch.createVariable(deeplyClonedField.getType());\n                writeDeepCloneInstructions(isSubclassBranch, solutionSubclassDescriptor, deeplyClonedField,\n                        gizmoMemberDescriptor, fieldValue, cloneValue, createdCloneMap, deepClonedClassesSortedSet);\n\n                if (!gizmoMemberDescriptor.writeMemberValue(isSubclassBranch, clone, cloneValue)) {\n                    throw new IllegalStateException(\"The member (\" + gizmoMemberDescriptor.getName() + \") of class (\" +\n                            gizmoMemberDescriptor.getDeclaringClassName() +\n                            \") does not have a setter.\");\n                }\n            }\n            isSubclassBranch.returnValue(clone);\n\n            currentBranch = isSubclassBranchResult.falseBranch();\n        }\n        ResultHandle errorBuilder = currentBranch.newInstance(MethodDescriptor.ofConstructor(StringBuilder.class, String.class),\n                currentBranch.load(\"Failed to create clone: encountered (\"));\n        final MethodDescriptor APPEND =\n                MethodDescriptor.ofMethod(StringBuilder.class, \"append\", StringBuilder.class, Object.class);\n\n        currentBranch.invokeVirtualMethod(APPEND, errorBuilder, thisObjClass);\n        currentBranch.invokeVirtualMethod(APPEND, errorBuilder, currentBranch.load(\") which is not a known subclass of \" +\n                \"the solution class (\" + solutionDescriptor.getSolutionClass() + \"). The known subclasses are \" +\n                solutionClassSet.stream().map(Class::getName).collect(Collectors.joining(\", \", \"[\", \"]\")) + \".\" +\n                \"\\nMaybe use DomainAccessType.REFLECTION?\"));\n        ResultHandle errorMsg = currentBranch\n                .invokeVirtualMethod(MethodDescriptor.ofMethod(Object.class, \"toString\", String.class), errorBuilder);\n        ResultHandle error = currentBranch\n                .newInstance(MethodDescriptor.ofConstructor(IllegalArgumentException.class, String.class), errorMsg);\n        currentBranch.throwException(error);\n    }\n\n    /**\n     * Writes the following code:\n     *\n     * <pre>\n     * // If getter a field\n     * clone.member = original.member\n     * // If getter a method (i.e. Quarkus)\n     * clone.setMember(original.getMember());\n     * </pre>\n     *\n     * @param methodCreator\n     * @param shallowlyClonedField\n     * @param thisObj\n     * @param clone\n     */\n    private void writeShallowCloneInstructions(GizmoSolutionOrEntityDescriptor solutionInfo,\n            BytecodeCreator methodCreator, GizmoMemberDescriptor shallowlyClonedField,\n            ResultHandle thisObj, ResultHandle clone, ResultHandle createdCloneMap,\n            SortedSet<Class<?>> deepClonedClassesSortedSet) {\n        try {\n            boolean isArray = shallowlyClonedField.getTypeName().endsWith(\"[]\");\n            Class<?> type = null;\n            if (shallowlyClonedField.getType() instanceof Class) {\n                type = (Class<?>) shallowlyClonedField.getType();\n            }\n\n            List<Class<?>> entitySubclasses = Collections.emptyList();\n            if (type == null && !isArray) {\n                type = Class.forName(shallowlyClonedField.getTypeName().replace('/', '.'), false,\n                        Thread.currentThread().getContextClassLoader());\n            }\n\n            if (type != null && !isArray) {\n                entitySubclasses =\n                        deepClonedClassesSortedSet.stream().filter(type::isAssignableFrom).collect(Collectors.toList());\n            }\n\n            ResultHandle fieldValue = shallowlyClonedField.readMemberValue(methodCreator, thisObj);\n            if (!entitySubclasses.isEmpty()) {\n                AssignableResultHandle cloneResultHolder = methodCreator.createVariable(type);\n                writeDeepCloneEntityOrFactInstructions(methodCreator, solutionInfo, type,\n                        fieldValue, cloneResultHolder, createdCloneMap, deepClonedClassesSortedSet,\n                        UnhandledCloneType.SHALLOW);\n                fieldValue = cloneResultHolder;\n            }\n            if (!shallowlyClonedField.writeMemberValue(methodCreator, clone, fieldValue)) {\n                throw new IllegalStateException(\"Field (\" + shallowlyClonedField.getName() + \") of class (\" +\n                        shallowlyClonedField.getDeclaringClassName() +\n                        \") does not have a setter.\");\n            }\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(\"Error creating Gizmo Solution Cloner\", e);\n        }\n    }\n\n    /**\n     * @see #writeDeepCloneInstructions(BytecodeCreator, GizmoSolutionOrEntityDescriptor, Class, Type, ResultHandle,\n     *      AssignableResultHandle, ResultHandle, SortedSet)\n     */\n    private void writeDeepCloneInstructions(BytecodeCreator bytecodeCreator,\n            GizmoSolutionOrEntityDescriptor solutionDescriptor, Field deeplyClonedField,\n            GizmoMemberDescriptor gizmoMemberDescriptor, ResultHandle toClone, AssignableResultHandle cloneResultHolder,\n            ResultHandle createdCloneMap, SortedSet<Class<?>> deepClonedClassesSortedSet) {\n        BranchResult isNull = bytecodeCreator.ifNull(toClone);\n\n        BytecodeCreator isNullBranch = isNull.trueBranch();\n        isNullBranch.assign(cloneResultHolder, isNullBranch.loadNull());\n\n        BytecodeCreator isNotNullBranch = isNull.falseBranch();\n\n        Class<?> deeplyClonedFieldClass = deeplyClonedField.getType();\n        Type type = gizmoMemberDescriptor.getType();\n        if (solutionDescriptor.getSolutionDescriptor().getSolutionClass().isAssignableFrom(deeplyClonedFieldClass)) {\n            writeDeepCloneSolutionInstructions(bytecodeCreator, solutionDescriptor, toClone, cloneResultHolder,\n                    createdCloneMap);\n        } else if (Collection.class.isAssignableFrom(deeplyClonedFieldClass)) {\n            writeDeepCloneCollectionInstructions(isNotNullBranch, solutionDescriptor, deeplyClonedFieldClass, type,\n                    toClone, cloneResultHolder, createdCloneMap, deepClonedClassesSortedSet);\n        } else if (Map.class.isAssignableFrom(deeplyClonedFieldClass)) {\n            writeDeepCloneMapInstructions(isNotNullBranch, solutionDescriptor, deeplyClonedFieldClass, type,\n                    toClone, cloneResultHolder, createdCloneMap, deepClonedClassesSortedSet);\n        } else if (deeplyClonedFieldClass.isArray()) {\n            writeDeepCloneArrayInstructions(isNotNullBranch, solutionDescriptor, deeplyClonedFieldClass,\n                    toClone, cloneResultHolder, createdCloneMap, deepClonedClassesSortedSet);\n        } else {\n            UnhandledCloneType unknownClassCloneType =\n                    (DeepCloningUtils.isFieldDeepCloned(solutionDescriptor.solutionDescriptor,\n                            deeplyClonedField, deeplyClonedField.getDeclaringClass()))\n                                    ? UnhandledCloneType.DEEP\n                                    : UnhandledCloneType.SHALLOW;\n            writeDeepCloneEntityOrFactInstructions(isNotNullBranch, solutionDescriptor, deeplyClonedFieldClass,\n                    toClone, cloneResultHolder, createdCloneMap, deepClonedClassesSortedSet, unknownClassCloneType);\n        }\n    }\n\n    /**\n     * Writes the following code:\n     *\n     * <pre>\n     * // For a Collection\n     * Collection original = field;\n     * Collection clone = new ActualCollectionType();\n     * Iterator iterator = original.iterator();\n     * while (iterator.hasNext()) {\n     *     Object nextClone = (result from recursion on iterator.next());\n     *     clone.add(nextClone);\n     * }\n     *\n     * // For a Map\n     * Map original = field;\n     * Map clone = new ActualMapType();\n     * Iterator iterator = original.entrySet().iterator();\n     * while (iterator.hasNext()) {\n     *      Entry next = iterator.next();\n     *      nextClone = (result from recursion on next.getValue());\n     *      clone.put(next.getKey(), nextClone);\n     * }\n     *\n     * // For an array\n     * Object[] original = field;\n     * Object[] clone = new Object[original.length];\n     *\n     * for (int i = 0; i < original.length; i++) {\n     *     clone[i] = (result from recursion on original[i]);\n     * }\n     *\n     * // For an entity\n     * if (original instanceof SubclassOfEntity1) {\n     *     SubclassOfEntity1 original = field;\n     *     SubclassOfEntity1 clone = new SubclassOfEntity1();\n     *\n     *     // shallowly clone fields using writeShallowCloneInstructions()\n     *     // for any deeply cloned field, do recursion on it\n     * } else if (original instanceof SubclassOf\n```\n# Function Signature: public static void defineClonerFor(ClassCreator classCreator,\n# Natural Language Annotations: /**\n     * Generates the constructor and implementations of SolutionCloner methods for the given SolutionDescriptor using the given\n     * ClassCreator\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static void defineClonerFor(Supplier<GizmoSolutionClonerImplementor> implementorSupplier,\n            ClassCreator classCreator,\n            SolutionDescriptor<?> solutionDescriptor,\n            Set<Class<?>> solutionClassSet,\n            Map<Class<?>, GizmoSolutionOrEntityDescriptor> memoizedSolutionOrEntityDescriptorMap,\n            Set<Class<?>> deepClonedClassSet) {\n        GizmoSolutionClonerImplementor implementor = implementorSupplier.get();\n        // Classes that are not instances of any other class in the collection\n        // have a subclass level of 0.\n        // Other classes subclass level is the maximum of the subclass level\n        // of the classes it is a subclass of + 1\n        Set<Class<?>> deepCloneClassesThatAreNotSolutionSet =\n                deepClonedClassSet.stream()\n                        .filter(clazz -> !solutionClassSet.contains(clazz) && !clazz.isArray())\n                        .filter(clazz -> !clazz.isInterface() && !Modifier.isAbstract(clazz.getModifiers()))\n                        .collect(Collectors.toSet());\n\n        Comparator<Class<?>> instanceOfComparator = getInstanceOfComparator(deepClonedClassSet);\n        SortedSet<Class<?>> deepCloneClassesThatAreNotSolutionSortedSet = new TreeSet<>(instanceOfComparator);\n        deepCloneClassesThatAreNotSolutionSortedSet.addAll(deepCloneClassesThatAreNotSolutionSet);\n\n        implementor.createFields(classCreator);\n        implementor.createConstructor(classCreator);\n        implementor.createSetSolutionDescriptor(classCreator, solutionDescriptor);\n        implementor.createCloneSolution(classCreator, solutionDescriptor);\n        implementor.createCloneSolutionRun(classCreator, solutionDescriptor, solutionClassSet,\n                memoizedSolutionOrEntityDescriptorMap,\n                deepCloneClassesThatAreNotSolutionSortedSet, instanceOfComparator);\n\n        for (Class<?> deepClonedClass : deepCloneClassesThatAreNotSolutionSortedSet) {\n            implementor.createDeepCloneHelperMethod(classCreator, deepClonedClass, solutionDescriptor,\n                    memoizedSolutionOrEntityDescriptorMap,\n                    deepCloneClassesThatAreNotSolutionSortedSet);\n        }\n\n        Set<Class<?>> abstractDeepCloneClassSet =\n                deepClonedClassSet.stream()\n                        .filter(clazz -> !solutionClassSet.contains(clazz) && !clazz.isArray())\n                        .filter(clazz -> clazz.isInterface() || Modifier.isAbstract(clazz.getModifiers()))\n                        .collect(Collectors.toSet());\n\n        for (Class<?> abstractDeepClonedClass : abstractDeepCloneClassSet) {\n            implementor.createAbstractDeepCloneHelperMethod(classCreator, abstractDeepClonedClass, solutionDescriptor,\n                    memoizedSolutionOrEntityDescriptorMap,\n                    deepCloneClassesThatAreNotSolutionSortedSet);\n        }\n    }\n```", "  ```\npackage ai.timefold.solver.core.impl.domain.solution.cloner.gizmo;\n\nimport java.io.IOException;\nimport java.lang.reflect.Field;\nimport java.lang.reflect.InvocationTargetException;\nimport java.lang.reflect.Modifier;\nimport java.lang.reflect.ParameterizedType;\nimport java.lang.reflect.Type;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.IdentityHashMap;\nimport java.util.Iterator;\nimport java.util.LinkedHashMap;\nimport java.util.LinkedHashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Optional;\nimport java.util.Set;\nimport java.util.SortedSet;\nimport java.util.TreeSet;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\nimport ai.timefold.solver.core.api.domain.solution.cloner.SolutionCloner;\nimport ai.timefold.solver.core.impl.domain.common.accessor.gizmo.GizmoClassLoader;\nimport ai.timefold.solver.core.impl.domain.common.accessor.gizmo.GizmoMemberDescriptor;\nimport ai.timefold.solver.core.impl.domain.solution.cloner.DeepCloningUtils;\nimport ai.timefold.solver.core.impl.domain.solution.cloner.FieldAccessingSolutionCloner;\nimport ai.timefold.solver.core.impl.domain.solution.cloner.PlanningCloneable;\nimport ai.timefold.solver.core.impl.domain.solution.descriptor.SolutionDescriptor;\nimport ai.timefold.solver.core.impl.util.MutableReference;\n\nimport io.quarkus.gizmo.AssignableResultHandle;\nimport io.quarkus.gizmo.BranchResult;\nimport io.quarkus.gizmo.BytecodeCreator;\nimport io.quarkus.gizmo.ClassCreator;\nimport io.quarkus.gizmo.ClassOutput;\nimport io.quarkus.gizmo.FieldDescriptor;\nimport io.quarkus.gizmo.MethodCreator;\nimport io.quarkus.gizmo.MethodDescriptor;\nimport io.quarkus.gizmo.ResultHandle;\n\npublic class GizmoSolutionClonerImplementor {\n    private static final MethodDescriptor EQUALS_METHOD = MethodDescriptor.ofMethod(Object.class, \"equals\", boolean.class,\n            Object.class);\n    protected static final MethodDescriptor GET_METHOD = MethodDescriptor.ofMethod(Map.class, \"get\", Object.class,\n            Object.class);\n    private static final MethodDescriptor PUT_METHOD = MethodDescriptor.ofMethod(Map.class, \"put\", Object.class,\n            Object.class, Object.class);\n    private static final String FALLBACK_CLONER = \"fallbackCloner\";\n    public static final boolean DEBUG = false;\n\n    /**\n     * Return a comparator that sorts classes into instanceof check order.\n     * In particular, if x is a subclass of y, then x will appear earlier\n     * than y in the list.\n     *\n     * @param deepClonedClassSet The set of classes to generate a comparator for\n     * @return A comparator that sorts classes from deepClonedClassSet such that\n     *         x &lt; y if x is assignable from y.\n     */\n    public static Comparator<Class<?>> getInstanceOfComparator(Set<Class<?>> deepClonedClassSet) {\n        Map<Class<?>, Integer> classToSubclassLevel = new HashMap<>();\n        deepClonedClassSet\n                .forEach(clazz -> {\n                    if (deepClonedClassSet.stream()\n                            .allMatch(\n                                    otherClazz -> clazz.", "  ```\nimport java.util.Collections;\nimport java.util.Comparator;\n\npublic class Cloner {\n    public static void defineClonerFor(ClassCreator classCreator, SolutionDescriptor<?> solutionDescriptor) {\n        classCreator.build(definition -> {\n            definition.createScanOutput(\"returning value\", Object.class)\n                      .invokeConstructor(classCreator.getClassName())\n                      .returnValue();\n        });\n    }\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/variable/listener/support/violation/ShadowVariablesAssert.java-createShadowVariablesViolationMessage": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/domain/variable/listener/support/violation/ShadowVariablesAssert.java:\n```\npackage ai.timefold.solver.core.impl.domain.variable.listener.support.violation;\n\nimport static java.util.Comparator.comparing;\n\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.TreeMap;\n\nimport ai.timefold.solver.core.impl.domain.solution.descriptor.SolutionDescriptor;\nimport ai.timefold.solver.core.impl.domain.variable.descriptor.ShadowVariableDescriptor;\n\n/**\n * Serves for detecting shadow variables' corruption. When a snapshot is created, it records the state of all shadow variables\n * of all entities. The {@link #createShadowVariablesViolationMessage} method takes a look at the shadow variables again,\n * compares their state with the recorded one and describes the difference in a violation message.\n */\npublic final class ShadowVariablesAssert {\n\n    private final List<ShadowVariableSnapshot> shadowVariableSnapshots;\n\n    private ShadowVariablesAssert(List<ShadowVariableSnapshot> shadowVariableSnapshots) {\n        this.shadowVariableSnapshots = shadowVariableSnapshots;\n    }\n\n    public static <Solution_> ShadowVariablesAssert takeSnapshot(\n            SolutionDescriptor<Solution_> solutionDescriptor,\n            Solution_ workingSolution) {\n        List<ShadowVariableSnapshot> shadowVariableSnapshots = new ArrayList<>();\n        solutionDescriptor.visitAllEntities(workingSolution,\n                entity -> solutionDescriptor.findEntityDescriptorOrFail(entity.getClass())\n                        .getShadowVariableDescriptors().stream()\n                        .map(shadowVariableDescriptor -> ShadowVariableSnapshot.of(shadowVariableDescriptor, entity))\n                        .forEach(shadowVariableSnapshots::add));\n        return new ShadowVariablesAssert(shadowVariableSnapshots);\n    }\n\n    public static <Solution_> void resetShadowVariables(\n            SolutionDescriptor<Solution_> solutionDescriptor,\n            Solution_ workingSolution) {\n        solutionDescriptor.visitAllEntities(workingSolution,\n                entity -> solutionDescriptor.findEntityDescriptorOrFail(entity.getClass())\n                        .getShadowVariableDescriptors()\n                        .forEach(descriptor -> descriptor.setValue(entity, null)));\n    }\n\n    /**\n     * Takes a look at the shadow variables of all entities and compares them against the recorded state. Every difference\n     * is added to the violation message. The first N differences up to the {@code violationDisplayLimit} are displayed\n     * in detail; the number of violations exceeding the display limit is reported at the end. The limit applies per each\n     * shadow variable descriptor.\n     * <p>\n     * This method should be called after a forceful trigger of variable listeners.\n     *\n     * @param violationDisplayLimit maximum number of violations reported per shadow variable descriptor\n     * @return description of the violations or {@code null} if there are none\n     */\n\n\n\n\n\n\n\n\n    private Map<ShadowVariableDescriptor<?>, List<String>> collectViolations() {\n        Map<ShadowVariableDescriptor<?>, List<String>> violationListMap = new TreeMap<>(\n                comparing(ShadowVariableDescriptor::getGlobalShadowOrder));\n        for (ShadowVariableSnapshot shadowVariableSnapshot : shadowVariableSnapshots) {\n            shadowVariableSnapshot.validate(violationMessage -> violationListMap\n                    .computeIfAbsent(shadowVariableSnapshot.getShadowVariableDescriptor(), k -> new ArrayList<>())\n                    .add(violationMessage));\n        }\n        return violationListMap;\n    }\n\n    private String format(Map<ShadowVariableDescriptor<?>, List<String>> violationListMap, long violationDisplayLimit) {\n        StringBuilder message = new StringBuilder();\n        violationListMap.forEach((shadowVariableDescriptor, violationList) -> {\n            violationList.stream().limit(violationDisplayLimit).forEach(message::append);\n            if (violationList.size() >= violationDisplayLimit) {\n                message.append(\"  ... \").append(violationList.size() - violationDisplayLimit)\n                        .append(\" more\\n\");\n            }\n        });\n        return message.toString();\n    }\n}\n\n```\n# Function Signature: public String createShadowVariablesViolationMessage(long violationDisplayLimit) {\n# Natural Language Annotations: /**\n     * Takes a look at the shadow variables of all entities and compares them against the recorded state. Every difference\n     * is added to the violation message. The first N differences up to the {@code violationDisplayLimit} are displayed\n     * in detail; the number of violations exceeding the display limit is reported at the end. The limit applies per each\n     * shadow variable descriptor.\n     * <p>\n     * This method should be called after a forceful trigger of variable listeners.\n     *\n     * @param violationDisplayLimit maximum number of violations reported per shadow variable descriptor\n     * @return description of the violations or {@code null} if there are none\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic String createShadowVariablesViolationMessage(long violationDisplayLimit) {\n    Map<ShadowVariableDescriptor<?>, List<String>> violationListMap = collectViolations();\n    return format(violationListMap, violationDisplayLimit);\n}\n```", "  ```\npublic String createShadowVariablesViolationMessage(long violationDisplayLimit) {\n    Map<ShadowVariableDescriptor<?>, List<String>> violationListMap = collectViolations();\n    if (violationListMap.isEmpty()) {\n        return null;\n    }\n    return format(violationListMap, violationDisplayLimit);\n}\n```\nThis function will take a look at the shadow variables of all entities and compare them against the recorded state. It will add every difference to the violation message. The first N differences up to the `violationDisplayLimit` are displayed in detail; the number of violations exceeding the display limit is reported at the end. The limit applies per each shadow variable descriptor.\n\nThis method should be called after a forceful trigger of variable listeners.", "  ```\npublic String createShadowVariablesViolationMessage(long violationDisplayLimit) {\n    Map<ShadowVariableDescriptor<?>, List<String>> violationMap = collectViolations();\n    return format(violationMap, violationDisplayLimit);\n}\n```\nThe code first calls the `collectViolations` method to collect all the violations and convert them to a map, where the key is the shadow variable descriptor and the value is a list of violation messages. The `format` method is then called to format the violation messages and limit the number of violations reported per shadow variable descriptor. The resulting string is returned."]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/MemberAccessorFactory.java-buildAndCacheMemberAccessor": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/MemberAccessorFactory.java:\n```\npackage ai.timefold.solver.core.impl.domain.common.accessor;\n\nimport java.lang.annotation.Annotation;\nimport java.lang.reflect.Field;\nimport java.lang.reflect.Member;\nimport java.lang.reflect.Method;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.concurrent.ConcurrentHashMap;\n\nimport ai.timefold.solver.core.api.domain.common.DomainAccessType;\nimport ai.timefold.solver.core.api.solver.SolverFactory;\nimport ai.timefold.solver.core.impl.domain.common.ReflectionHelper;\nimport ai.timefold.solver.core.impl.domain.common.accessor.gizmo.GizmoClassLoader;\nimport ai.timefold.solver.core.impl.domain.common.accessor.gizmo.GizmoMemberAccessorFactory;\n\npublic final class MemberAccessorFactory {\n\n    // exists only so that the various member accessors can share the same text in their exception messages\n    static final String CLASSLOADER_NUDGE_MESSAGE =\n            \"Maybe add getClass().getClassLoader() as a parameter to the %s.create...() method call.\"\n                    .formatted(SolverFactory.class.getSimpleName());\n\n    /**\n     * Creates a new member accessor based on the given parameters.\n     *\n     * @param member never null, method or field to access\n     * @param memberAccessorType never null\n     * @param domainAccessType never null\n     * @param classLoader null or {@link GizmoClassLoader} if domainAccessType is {@link DomainAccessType#GIZMO}.\n     * @return never null, new instance of the member accessor\n     */\n    public static MemberAccessor buildMemberAccessor(Member member, MemberAccessorType memberAccessorType,\n            DomainAccessType domainAccessType, ClassLoader classLoader) {\n        return buildMemberAccessor(member, memberAccessorType, null, domainAccessType, classLoader);\n    }\n\n    /**\n     * Creates a new member accessor based on the given parameters.\n     *\n     * @param member never null, method or field to access\n     * @param memberAccessorType never null\n     * @param annotationClass the annotation the member was annotated with (used for error reporting)\n     * @param domainAccessType never null\n     * @param classLoader null or {@link GizmoClassLoader} if domainAccessType is {@link DomainAccessType#GIZMO}.\n     * @return never null, new instance of the member accessor\n     */\n    public static MemberAccessor buildMemberAccessor(Member member, MemberAccessorType memberAccessorType,\n            Class<? extends Annotation> annotationClass, DomainAccessType domainAccessType, ClassLoader classLoader) {\n        return switch (domainAccessType) {\n            case GIZMO -> GizmoMemberAccessorFactory.buildGizmoMemberAccessor(member, annotationClass,\n                    memberAccessorType != MemberAccessorType.REGULAR_METHOD,\n                    (GizmoClassLoader) Objects.requireNonNull(classLoader));\n            case REFLECTION -> buildReflectiveMemberAccessor(member, memberAccessorType, annotationClass);\n        };\n    }\n\n    private static MemberAccessor buildReflectiveMemberAccessor(Member member, MemberAccessorType memberAccessorType,\n            Class<? extends Annotation> annotationClass) {\n        if (member instanceof Field field) {\n            return new ReflectionFieldMemberAccessor(field);\n        } else if (member instanceof Method method) {\n            MemberAccessor memberAccessor;\n            switch (memberAccessorType) {\n                case FIELD_OR_READ_METHOD:\n                    if (!ReflectionHelper.isGetterMethod(method)) {\n                        if (annotationClass == null) {\n                            ReflectionHelper.assertReadMethod(method);\n                        } else {\n                            ReflectionHelper.assertReadMethod(method, annotationClass);\n                        }\n                        memberAccessor = new ReflectionMethodMemberAccessor(method);\n                        break;\n                    }\n                    // Intentionally fall through (no break)\n                case FIELD_OR_GETTER_METHOD:\n                case FIELD_OR_GETTER_METHOD_WITH_SETTER:\n                    boolean getterOnly = memberAccessorType != MemberAccessorType.FIELD_OR_GETTER_METHOD_WITH_SETTER;\n                    if (annotationClass == null) {\n                        ReflectionHelper.assertGetterMethod(method);\n                    } else {\n                        ReflectionHelper.assertGetterMethod(method, annotationClass);\n                    }\n                    memberAccessor = new ReflectionBeanPropertyMemberAccessor(method, getterOnly);\n                    break;\n                case REGULAR_METHOD:\n                    memberAccessor = new ReflectionMethodMemberAccessor(method, false);\n                    break;\n                default:\n                    throw new IllegalStateException(\"The memberAccessorType (%s) is not implemented.\"\n                            .formatted(memberAccessorType));\n            }\n            if (memberAccessorType == MemberAccessorType.FIELD_OR_GETTER_METHOD_WITH_SETTER\n                    && !memberAccessor.supportSetter()) {\n                if (annotationClass == null) {\n                    throw new IllegalStateException(\n                            \"The class (%s) has a getter method (%s), but lacks a setter for that property (%s).\"\n                                    .formatted(method.getDeclaringClass(), method, memberAccessor.getName()));\n                } else {\n                    throw new IllegalStateException(\n                            \"The class (%s) has a @%s-annotated getter method (%s), but lacks a setter for that property (%s).\"\n                                    .formatted(method.getDeclaringClass(), annotationClass.getSimpleName(), method,\n                                            memberAccessor.getName()));\n                }\n            }\n            return memberAccessor;\n        } else {\n            throw new IllegalStateException(\"Impossible state: the member (%s)'s type is not a %s or a %s.\"\n                    .formatted(member, Field.class.getSimpleName(), Method.class.getSimpleName()));\n        }\n    }\n\n    private final Map<String, MemberAccessor> memberAccessorCache;\n    private final GizmoClassLoader gizmoClassLoader = new GizmoClassLoader();\n\n    public MemberAccessorFactory() {\n        this(null);\n    }\n\n    /**\n     * Prefills the member accessor cache.\n     *\n     * @param memberAccessorMap key is the fully qualified member name\n     */\n    public MemberAccessorFactory(Map<String, MemberAccessor> memberAccessorMap) {\n        // The MemberAccessorFactory may be accessed, and this cache both read and updated, by multiple threads.\n        this.memberAccessorCache =\n                memberAccessorMap == null ? new ConcurrentHashMap<>() : new ConcurrentHashMap<>(memberAccessorMap);\n    }\n\n    /**\n     * Creates a new member accessor based on the given parameters. Caches the result.\n     *\n     * @param member never null, method or field to access\n     * @param memberAccessorType never null\n     * @param annotationClass the annotation the member was annotated with (used for error reporting)\n     * @param domainAccessType never null\n     * @return never null, new {@link MemberAccessor} instance unless already found in memberAccessorMap\n     */\n\n\n\n\n\n\n\n\n    /**\n     * Creates a new member accessor based on the given parameters. Caches the result.\n     *\n     * @param member never null, method or field to access\n     * @param memberAccessorType never null\n     * @param domainAccessType never null\n     * @return never null, new {@link MemberAccessor} instance unless already found in memberAccessorMap\n     */\n    public MemberAccessor buildAndCacheMemberAccessor(Member member, MemberAccessorType memberAccessorType,\n            DomainAccessType domainAccessType) {\n        String generatedClassName = GizmoMemberAccessorFactory.getGeneratedClassName(member);\n        return memberAccessorCache.computeIfAbsent(generatedClassName,\n                k -> MemberAccessorFactory.buildMemberAccessor(member, memberAccessorType, domainAccessType, gizmoClassLoader));\n    }\n\n    public GizmoClassLoader getGizmoClassLoader() {\n        return gizmoClassLoader;\n    }\n\n    public enum MemberAccessorType {\n        FIELD_OR_READ_METHOD,\n        FIELD_OR_GETTER_METHOD,\n        FIELD_OR_GETTER_METHOD_WITH_SETTER,\n        REGULAR_METHOD\n    }\n}\n\n```\n# Function Signature: public MemberAccessor buildAndCacheMemberAccessor(Member member, MemberAccessorType memberAccessorType,\n# Natural Language Annotations: /**\n     * Creates a new member accessor based on the given parameters. Caches the result.\n     *\n     * @param member never null, method or field to access\n     * @param memberAccessorType never null\n     * @param annotationClass the annotation the member was annotated with (used for error reporting)\n     * @param domainAccessType never null\n     * @return never null, new {@link MemberAccessor} instance unless already found in memberAccessorMap\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic MemberAccessor buildAndCacheMemberAccessor(Member member, MemberAccessorType memberAccessorType,\n        DomainAccessType domainAccessType) {\n    String generatedClassName = GizmoMemberAccessorFactory.getGeneratedClassName(member);\n    return memberAccessorCache.computeIfAbsent(generatedClassName,\n            k -> MemberAccessorFactory.buildMemberAccessor(member, memberAccessorType, domainAccessType, gizmoClassLoader));\n}\n```", "  ```\npublic MemberAccessor buildAndCacheMemberAccessor(Member member, MemberAccessorType memberAccessorType,\n        DomainAccessType domainAccessType) {\n    String generatedClassName = GizmoMemberAccessorFactory.getGeneratedClassName(member);\n    return memberAccessorCache.computeIfAbsent(generatedClassName,\n            k -> MemberAccessorFactory.buildMemberAccessor(member, memberAccessorType, domainAccessType, gizmoClassLoader));\n}\n```", "  ```\npublic MemberAccessor buildAndCacheMemberAccessor(Member member, MemberAccessorType memberAccessorType, DomainAccessType domainAccessType) {\n    String generatedClassName = GizmoMemberAccessorFactory.getGeneratedClassName(member);\n    return memberAccessorCache.computeIfAbsent(generatedClassName, \n        k -> MemberAccessorFactory.buildMemberAccessor(member, \n                                                       memberAccessorType, \n                                                       domainAccessType, \n                                                       gizmoClassLoader));\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/gizmo/GizmoMemberAccessorFactory.java-getGeneratedClassName": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/gizmo/GizmoMemberAccessorFactory.java:\n```\npackage ai.timefold.solver.core.impl.domain.common.accessor.gizmo;\n\nimport java.lang.annotation.Annotation;\nimport java.lang.reflect.Field;\nimport java.lang.reflect.Member;\nimport java.util.Objects;\n\nimport ai.timefold.solver.core.api.domain.common.DomainAccessType;\nimport ai.timefold.solver.core.impl.domain.common.ReflectionHelper;\nimport ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessor;\n\npublic class GizmoMemberAccessorFactory {\n    /**\n     * Returns the generated class name for a given member.\n     * (Here as accessing any method of GizmoMemberAccessorImplementor\n     * will try to load Gizmo code)\n     *\n     * @param member The member to get the generated class name for\n     * @return The generated class name for member\n     */\n\n\n\n\n\n\n\n    /**\n     *\n     * @param member never null\n     * @param annotationClass may be null if the member is not annotated\n     * @param gizmoClassLoader never null\n     * @return never null\n     */\n    public static MemberAccessor buildGizmoMemberAccessor(Member member, Class<? extends Annotation> annotationClass,\n            boolean returnTypeRequired, GizmoClassLoader gizmoClassLoader) {\n        try {\n            // Check if Gizmo on the classpath by verifying we can access one of its classes\n            Class.forName(\"io.quarkus.gizmo.ClassCreator\", false,\n                    Thread.currentThread().getContextClassLoader());\n        } catch (ClassNotFoundException e) {\n            throw new IllegalStateException(\"When using the domainAccessType (\" +\n                    DomainAccessType.GIZMO +\n                    \") the classpath or modulepath must contain io.quarkus.gizmo:gizmo.\\n\" +\n                    \"Maybe add a dependency to io.quarkus.gizmo:gizmo.\");\n        }\n        return GizmoMemberAccessorImplementor.createAccessorFor(member, annotationClass, returnTypeRequired, gizmoClassLoader);\n    }\n\n    private GizmoMemberAccessorFactory() {\n    }\n}\n\n```\n# Function Signature: public static String getGeneratedClassName(Member member) {\n# Natural Language Annotations: /**\n     * Returns the generated class name for a given member.\n     * (Here as accessing any method of GizmoMemberAccessorImplementor\n     * will try to load Gizmo code)\n     *\n     * @param member The member to get the generated class name for\n     * @return The generated class name for member\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static String getGeneratedClassName(Member member) {\n    return \"GizmoMemberAccessor_\" + Objects.hashCode(member);\n}\n```", "  ```\npublic class GizmoMemberAccessorFactory {\n    /**\n     * Returns the generated class name for a given member.\n     * (Here as accessing any method of GizmoMemberAccessorImplementor\n     * will try to load Gizmo code)\n     *\n     * @param member The member to get the generated class name for\n     * @return The generated class name for member\n     */\n    public static String getGeneratedClassName(Member member) {\n        return GizmoMemberAccessorImplementor.class.getName() + \"$\" + hashCode();\n    }\n}\n```", "  ```\npublic static String getGeneratedClassName(Member member) {\n    return GizmoMemberAccessorImplementor.createAccessorFor(member, null, false, null).getGeneratedClassName();\n}\n```\nThis function accesses the `GizmoMemberAccessorImplementor` class through reflection and calls the `createAccessorFor` method with the `member` parameter. The `null` values for `annotationClass` and `returnTypeRequired` are used because these parameters are not used in the `createAccessorFor` method. Finally, the `getGeneratedClassName` method is called on the returned `MemberAccessor` object to get the generated class name.\n\nNote that this function requires the Gizmo class to be on the classpath, so if the class cannot be found, it will throw an `IllegalStateException` with a message indicating that the classpath or modulepath must contain `io.quarkus.gizmo:gizmo`."]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/gizmo/GizmoMemberAccessorImplementor.java-createAccessorFor": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/gizmo/GizmoMemberAccessorImplementor.java:\n```\npackage ai.timefold.solver.core.impl.domain.common.accessor.gizmo;\n\nimport java.lang.annotation.Annotation;\nimport java.lang.reflect.AnnotatedElement;\nimport java.lang.reflect.Field;\nimport java.lang.reflect.InvocationTargetException;\nimport java.lang.reflect.Member;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Modifier;\nimport java.lang.reflect.Type;\nimport java.util.Arrays;\nimport java.util.concurrent.atomic.AtomicBoolean;\n\nimport ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessor;\nimport ai.timefold.solver.core.impl.util.MutableReference;\n\nimport io.quarkus.gizmo.ClassCreator;\nimport io.quarkus.gizmo.ClassOutput;\nimport io.quarkus.gizmo.FieldDescriptor;\nimport io.quarkus.gizmo.MethodCreator;\nimport io.quarkus.gizmo.MethodDescriptor;\nimport io.quarkus.gizmo.ResultHandle;\n\n/**\n * Generates the bytecode for the MemberAccessor of a particular Member\n */\npublic final class GizmoMemberAccessorImplementor {\n\n    final static String GENERIC_TYPE_FIELD = \"genericType\";\n    final static String ANNOTATED_ELEMENT_FIELD = \"annotatedElement\";\n\n    /**\n     * Generates the constructor and implementations of {@link AbstractGizmoMemberAccessor} methods for the given\n     * {@link Member}.\n     *\n     * @param className never null\n     * @param classOutput never null, defines how to write the bytecode\n     * @param memberInfo never null, member to generate MemberAccessor methods implementation for\n     */\n    public static void defineAccessorFor(String className, ClassOutput classOutput, GizmoMemberInfo memberInfo) {\n        Class<? extends AbstractGizmoMemberAccessor> superClass = getCorrectSuperclass(memberInfo);\n        try (ClassCreator classCreator = ClassCreator.builder()\n                .className(className)\n                .superClass(superClass)\n                .classOutput(classOutput)\n                .setFinal(true)\n                .build()) {\n            classCreator.getFieldCreator(\"genericType\", Type.class)\n                    .setModifiers(Modifier.FINAL);\n            classCreator.getFieldCreator(\"annotatedElement\", AnnotatedElement.class)\n                    .setModifiers(Modifier.FINAL);\n\n            // ************************************************************************\n            // MemberAccessor methods\n            // ************************************************************************\n            createConstructor(classCreator, memberInfo);\n            createGetDeclaringClass(classCreator, memberInfo);\n            createGetType(classCreator, memberInfo);\n            createGetGenericType(classCreator);\n            createGetName(classCreator, memberInfo);\n            createExecuteGetter(classCreator, memberInfo);\n            if (superClass == AbstractReadWriteGizmoMemberAccessor.class) {\n                createExecuteSetter(classCreator, memberInfo);\n            }\n            createGetAnnotation(classCreator);\n            createDeclaredAnnotationsByType(classCreator);\n        }\n    }\n\n    private static Class<? extends AbstractGizmoMemberAccessor> getCorrectSuperclass(GizmoMemberInfo memberInfo) {\n        AtomicBoolean supportsSetter = new AtomicBoolean();\n        memberInfo.descriptor().whenIsMethod(method -> {\n            supportsSetter.set(memberInfo.descriptor().getSetter().isPresent());\n        });\n        memberInfo.descriptor().whenIsField(field -> {\n            supportsSetter.set(true);\n        });\n        if (supportsSetter.get()) {\n            return AbstractReadWriteGizmoMemberAccessor.class;\n        } else {\n            return AbstractReadOnlyGizmoMemberAccessor.class;\n        }\n    }\n\n    /**\n     * Creates a MemberAccessor for a given member, generating\n     * the MemberAccessor bytecode if required\n     *\n     * @param member The member to generate a MemberAccessor for\n     * @param annotationClass The annotation it was annotated with (used for\n     *        error reporting)\n     * @param returnTypeRequired A flag that indicates if the return type is required or optional\n     * @param gizmoClassLoader never null\n     * @return A new MemberAccessor that uses Gizmo generated bytecode.\n     *         Will generate the bytecode the first type it is called\n     *         for a member, unless a classloader has been set,\n     *         in which case no Gizmo code will be generated.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    private static MemberAccessor createInstance(String className, GizmoClassLoader gizmoClassLoader) {\n        try {\n            return (MemberAccessor) gizmoClassLoader.loadClass(className)\n                    .getConstructor().newInstance();\n        } catch (InvocationTargetException | InstantiationException | IllegalAccessException | ClassNotFoundException\n                | NoSuchMethodException e) {\n            throw new IllegalStateException(e);\n        }\n    }\n\n    // ************************************************************************\n    // MemberAccessor methods\n    // ************************************************************************\n\n    private static MethodCreator getMethodCreator(ClassCreator classCreator, Class<?> returnType, String methodName,\n            Class<?>... parameters) {\n        return classCreator.getMethodCreator(methodName, returnType, parameters);\n    }\n\n    private static void createConstructor(ClassCreator classCreator, GizmoMemberInfo memberInfo) {\n        MethodCreator methodCreator =\n                classCreator.getMethodCreator(MethodDescriptor.ofConstructor(classCreator.getClassName()));\n\n        ResultHandle thisObj = methodCreator.getThis();\n\n        // Invoke Object's constructor\n        methodCreator.invokeSpecialMethod(MethodDescriptor.ofConstructor(classCreator.getSuperClass()), thisObj);\n\n        ResultHandle declaringClass = methodCreator.loadClass(memberInfo.descriptor().getDeclaringClassName());\n        memberInfo.descriptor().whenMetadataIsOnField(fd -> {\n            ResultHandle name = methodCreator.load(fd.getName());\n            ResultHandle field = methodCreator.invokeVirtualMethod(MethodDescriptor.ofMethod(Class.class, \"getDeclaredField\",\n                    Field.class, String.class),\n                    declaringClass, name);\n            ResultHandle type =\n                    methodCreator.invokeVirtualMethod(MethodDescriptor.ofMethod(Field.class, \"getGenericType\", Type.class),\n                            field);\n            methodCreator.writeInstanceField(FieldDescriptor.of(classCreator.getClassName(), GENERIC_TYPE_FIELD, Type.class),\n                    thisObj, type);\n            methodCreator.writeInstanceField(\n                    FieldDescriptor.of(classCreator.getClassName(), ANNOTATED_ELEMENT_FIELD, AnnotatedElement.class),\n                    thisObj, field);\n        });\n\n        memberInfo.descriptor().whenMetadataIsOnMethod(md -> {\n            ResultHandle name = methodCreator.load(md.getName());\n            ResultHandle method = methodCreator.invokeVirtualMethod(MethodDescriptor.ofMethod(Class.class, \"getDeclaredMethod\",\n                    Method.class, String.class, Class[].class),\n                    declaringClass, name,\n                    methodCreator.newArray(Class.class, 0));\n            if (memberInfo.returnTypeRequired()) {\n                // We create a field to store the result, only if the called method has a return type.\n                // Otherwise, we will only execute it\n                ResultHandle type =\n                        methodCreator.invokeVirtualMethod(\n                                MethodDescriptor.ofMethod(Method.class, \"getGenericReturnType\", Type.class),\n                                method);\n                methodCreator.writeInstanceField(\n                        FieldDescriptor.of(classCreator.getClassName(), GENERIC_TYPE_FIELD, Type.class),\n                        thisObj, type);\n            }\n            methodCreator.writeInstanceField(\n                    FieldDescriptor.of(classCreator.getClassName(), ANNOTATED_ELEMENT_FIELD, AnnotatedElement.class),\n                    thisObj, method);\n        });\n\n        // Return this (it a constructor)\n        methodCreator.returnValue(thisObj);\n    }\n\n    /**\n     * Generates the following code:\n     *\n     * <pre>\n     * Class getDeclaringClass() {\n     *     return ClassThatDeclaredMember.class;\n     * }\n     * </pre>\n     */\n    private static void createGetDeclaringClass(ClassCreator classCreator, GizmoMemberInfo memberInfo) {\n        MethodCreator methodCreator = getMethodCreator(classCreator, Class.class, \"getDeclaringClass\");\n        ResultHandle out = methodCreator.loadClass(memberInfo.descriptor().getDeclaringClassName());\n        methodCreator.returnValue(out);\n    }\n\n    /**\n     * Asserts method is a getter or read method\n     *\n     * @param method Method to assert is getter or read\n     * @param returnTypeRequired Flag used to check method return type\n     */\n    private static void assertIsGoodMethod(MethodDescriptor method, boolean returnTypeRequired) {\n        // V = void return type\n        // Z = primitive boolean return type\n        String methodName = method.getName();\n        if (method.getParameterTypes().length != 0) {\n            // not read or getter method\n            throw new IllegalStateException(\"The getterMethod (%s) must not have any parameters, but has parameters (%s).\"\n                    .formatted(methodName, Arrays.toString(method.getParameterTypes())));\n        }\n        if (methodName.startsWith(\"get\")) {\n            if (method.getReturnType().equals(\"V\")) {\n                throw new IllegalStateException(\"The getterMethod (%s) must have a non-void return type.\"\n                        .formatted(methodName));\n            }\n        } else if (methodName.startsWith(\"is\")) {\n            if (!method.getReturnType().equals(\"Z\")) {\n                throw new IllegalStateException(\"\"\"\n                        The getterMethod (%s) must have a primitive boolean return type but returns (%s).\n                        Maybe rename the method (get%s)?\"\"\"\n                        .formatted(methodName, method.getReturnType(), methodName.substring(2)));\n            }\n        } else {\n            // must be a read method\n            if (returnTypeRequired && method.getReturnType().equals(\"V\")) {\n                throw new IllegalStateException(\"The readMethod (%s) must have a non-void return type.\"\n                        .formatted(methodName));\n            }\n        }\n    }\n\n    /**\n     * Asserts method is a getter or read method\n     *\n     * @param method Method to assert is getter or read\n     * @param returnTypeRequired Flag used to check method return type\n     * @param annotationClass Used in exception message\n     */\n    private static void assertIsGoodMethod(MethodDescriptor method, boolean returnTypeRequired,\n            Class<? extends Annotation> annotationClass) {\n        // V = void return type\n        // Z = primitive boolean return type\n        String methodName = method.getName();\n        if (method.getParameterTypes().length != 0) {\n            // not read or getter method\n            throw new IllegalStateException(\n                    \"The getterMethod (%s) with a %s annotation must not have any parameters, but has parameters (%s).\"\n                            .formatted(methodName, annotationClass.getSimpleName(),\n                                    Arrays.toString(method.getParameterTypes())));\n        }\n        if (methodName.startsWith(\"get\")) {\n            if (method.getReturnType().equals(\"V\")) {\n                throw new IllegalStateException(\"The getterMethod (%s) with a %s annotation must have a non-void return type.\"\n                        .formatted(methodName, annotationClass.getSimpleName()));\n            }\n        } else if (methodName.startsWith(\"is\")) {\n            if (!method.getReturnType().equals(\"Z\")) {\n                throw new IllegalStateException(\"\"\"\n                        The getterMethod (%s) with a %s annotation must have a primitive boolean return type but returns (%s).\n                        Maybe rename the method (get%s)?\"\"\"\n                        .formatted(methodName, annotationClass.getSimpleName(), method.getReturnType(),\n                                methodName.substring(2)));\n            }\n        } else {\n            // must be a read method and return a result only if returnTypeRequired is true\n            if (returnTypeRequired && method.getReturnType().equals(\"V\")) {\n                throw new IllegalStateException(\"The readMethod (%s) with a %s annotation must have a non-void return type.\"\n                        .formatted(methodName, annotationClass.getSimpleName()));\n            }\n        }\n    }\n\n    /**\n     * Generates the following code:\n     *\n     * <pre>\n     * String getName() {\n     *     return \"fieldOrMethodName\";\n     * }\n     * </pre>\n     *\n     * If it is a getter method, \"get\" is removed and the first\n     * letter become lowercase\n     */\n    private static void createGetName(ClassCreator classCreator, GizmoMemberInfo memberInfo) {\n        MethodCreator methodCreator = getMethodCreator(classCreator, String.class, \"getName\");\n\n        // If it is a method, assert that it has the required\n        // properties\n        memberInfo.descriptor().whenIsMethod(method -> {\n            var annotationClass = memberInfo.annotationClass();\n            if (annotationClass == null) {\n                assertIsGoodMethod(method, memberInfo.returnTypeRequired());\n            } else {\n                assertIsGoodMethod(method, memberInfo.returnTypeRequired(), annotationClass);\n            }\n        });\n\n        String fieldName = memberInfo.descriptor().getName();\n        ResultHandle out = methodCreator.load(fieldName);\n        methodCreator.returnValue(out);\n    }\n\n    /**\n     * Generates the following code:\n     *\n     * <pre>\n     * Class getType() {\n     *     return FieldTypeOrMethodReturnType.class;\n     * }\n     * </pre>\n     */\n    private static void createGetType(ClassCreator classCreator, GizmoMemberInfo memberInfo) {\n        MethodCreator methodCreator = getMethodCreator(classCreator, Class.class, \"getType\");\n        ResultHandle out = methodCreator.loadClass(memberInfo.descriptor().getTypeName());\n        methodCreator.returnValue(out);\n    }\n\n    /**\n     * Generates the following code:\n     *\n     * <pre>\n     * Type getGenericType() {\n     *     return GizmoMemberAccessorImplementor.getGenericTypeFor(this.getClass().getName());\n     * }\n     * </pre>\n     *\n     * We are unable to load a non-primitive object constant, so we need to store it\n     * in the implementor, which then can return us the Type when needed. The type\n     * is stored in gizmoMemberAccessorNameToGenericType when this method is called.\n     */\n    private static void createGetGenericType(ClassCreator classCreator) {\n        MethodCreator methodCreator = getMethodCreator(classCreator, Type.class, \"getGenericType\");\n        ResultHandle thisObj = methodCreator.getThis();\n\n        ResultHandle out =\n                methodCreator.readInstanceField(FieldDescriptor.of(classCreator.getClassName(), GENERIC_TYPE_FIELD, Type.class),\n                        thisObj);\n        methodCreator.returnValue(out);\n    }\n\n    /**\n     * Generates the following code:\n     *\n     * For a field\n     *\n     * <pre>\n     * Object executeGetter(Object bean) {\n     *     return ((DeclaringClass) bean).field;\n     * }\n     * </pre>\n     *\n     * For a method with returning type\n     *\n     * <pre>\n     * Object executeGetter(Object bean) {\n     *     return ((DeclaringClass) bean).method();\n     * }\n     * </pre>\n     *\n     * For a method without returning type\n     *\n     * <pre>\n     * Object executeGetter(Object bean) {\n     *     ((DeclaringClass) bean).method();\n     *     return null;\n     * }\n     * </pre>\n     *\n     * The member MUST be public if not called in Quarkus\n     * (i.e. we don't delegate to the field getter/setter).\n     * In Quarkus, we generate simple getter/setter for the\n     * member if it is private (which get passed to the MemberDescriptor).\n     */\n    private static void createExecuteGetter(ClassCreator classCreator, GizmoMemberInfo memberInfo) {\n        MethodCreator methodCreator = getMethodCreator(classCreator, Object.class, \"executeGetter\", Object.class);\n        ResultHandle bean = methodCreator.getMethodParam(0);\n        if (memberInfo.returnTypeRequired()) {\n            methodCreator.returnValue(memberInfo.descriptor().readMemberValue(methodCreator, bean));\n        } else {\n            memberInfo.descriptor().readMemberValue(methodCreator, bean);\n            // Returns null as the called method has no return type\n            methodCreator.returnNull();\n        }\n    }\n\n    /**\n     * Generates the following code:\n     *\n     * For a field\n     *\n     * <pre>\n     * void executeSetter(Object bean, Object value) {\n     *     return ((DeclaringClass) bean).field = value;\n     * }\n     * </pre>\n     *\n     * For a getter method with a corresponding setter\n     *\n     * <pre>\n     * void executeSetter(Object bean, Object value) {\n     *     return ((DeclaringClass) bean).setValue(value);\n     * }\n     * </pre>\n     *\n     * For a read method or a getter method without a setter\n     *\n     * <pre>\n     * void executeSetter(Object bean, Object value) {\n     *     throw new UnsupportedOperationException(\"Setter not supported\");\n     * }\n     * </pre>\n     */\n    private static void createExecuteSetter(ClassCreator classCreator, GizmoMemberInfo memberInfo) {\n        MethodCreator methodCreator = getMethodCreator(classCreator, void.class, \"executeSetter\", Object.class,\n                Object.class);\n\n        ResultHandle bean = methodCreator.getMethodParam(0);\n        ResultHandle value = methodCreator.getMethodParam(1);\n        if (memberInfo.descriptor().writeMemberValue(methodCreator, bean, value)) {\n            // we are here only if the write is successful\n            methodCreator.returnValue(null);\n        } else {\n            methodCreator.throwException(UnsupportedOperationException.class, \"Setter not supported\");\n        }\n    }\n\n    private static MethodCreator getAnnotationMethodCreator(ClassCreator classCreator, Class<?> returnType, String methodName,\n            Class<?>... parameters) {\n        return classCreator.getMethodCreator(getAnnotationMethod(returnType, methodName, parameters));\n    }\n\n    private static MethodDescriptor getAnnotationMethod(Class<?> returnType, String methodName, Class<?>... parameters) {\n        return MethodDescriptor.ofMethod(AnnotatedElement.class, methodName, returnType, parameters);\n    }\n\n    /**\n     * Generates the following code:\n     *\n     * <pre>\n     * Object getAnnotation(Class annotationClass) {\n     *     AnnotatedElement annotatedElement = GizmoMemberAccessorImplementor\n     *             .getAnnotatedElementFor(this.getClass().getName());\n     *     return annotatedElement.getAnnotation(annotationClass);\n     * }\n     * </pre>\n     */\n    private static void createGetAnnotation(ClassCreator classCreator) {\n        MethodCreator methodCreator = getAnnotationMethodCreator(classCreator, Annotation.class, \"getAnnotation\", Class.class);\n        ResultHandle thisObj = methodCreator.getThis();\n\n        ResultHandle annotatedElement = methodCreator.readInstanceField(\n                FieldDescriptor.of(classCreator.getClassName(), ANNOTATED_ELEMENT_FIELD, AnnotatedElement.class),\n                thisObj);\n        ResultHandle query = methodCreator.getMethodParam(0);\n        ResultHandle out =\n                methodCreator.invokeInterfaceMethod(getAnnotationMethod(Annotation.class, \"getAnnotation\", Class.class),\n                        annotatedElement, query);\n        methodCreator.returnValue(out);\n    }\n\n    private static void createDeclaredAnnotationsByType(ClassCreator classCreator) {\n        MethodCreator methodCreator =\n                getAnnotationMethodCreator(classCreator, Annotation[].class, \"getDeclaredAnnotationsByType\", Class.class);\n        ResultHandle thisObj = methodCreator.getThis();\n\n        ResultHandle annotatedElement = methodCreator.readInstanceField(\n                FieldDescriptor.of(classCreator.getClassName(), ANNOTATED_ELEMENT_FIELD, AnnotatedElement.class),\n                thisObj);\n        ResultHandle query = methodCreator.getMethodParam(0);\n        ResultHandle out = methodCreator.invokeInterfaceMethod(\n                getAnnotationMethod(Annotation[].class, \"getDeclaredAnnotationsByType\", Class.class),\n                annotatedElement, query);\n        methodCreator.returnValue(out);\n    }\n\n    private GizmoMemberAccessorImplementor() {\n\n    }\n\n}\n\n```\n# Function Signature: static MemberAccessor createAccessorFor(Member member, Class<? extends Annotation> annotationClass,\n# Natural Language Annotations: /**\n     * Creates a MemberAccessor for a given member, generating\n     * the MemberAccessor bytecode if required\n     *\n     * @param member The member to generate a MemberAccessor for\n     * @param annotationClass The annotation it was annotated with (used for\n     *        error reporting)\n     * @param returnTypeRequired A flag that indicates if the return type is required or optional\n     * @param gizmoClassLoader never null\n     * @return A new MemberAccessor that uses Gizmo generated bytecode.\n     *         Will generate the bytecode the first type it is called\n     *         for a member, unless a classloader has been set,\n     *         in which case no Gizmo code will be generated.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```java\n public static MemberAccessor createAccessorFor(Member member, Class<? extends Annotation> annotationClass,\n        boolean returnTypeRequired, GizmoClassLoader gizmoClassLoader) {\n    String className = gizmoClassLoader.getClassName(member);\n    GizmoMemberInfo memberInfo = new GizmoMemberInfo(member, annotationClass, returnTypeRequired);\n    GizmoMemberAccessorImplementor.defineAccessorFor(className, gizmoClassLoader, memberInfo);\n    return createInstance(className, gizmoClassLoader);\n}\n```", "  ```\n    private static MemberAccessor createAccessorFor(Member member, Class<? extends Annotation> annotationClass,\n            boolean returnTypeRequired, GizmoClassLoader gizmoClassLoader) {\n        String className = member.getDeclaringClass().getName() + \"$$\" + member.getName() + \"Accessor\";\n        GizmoMemberInfo memberInfo = GizmoMemberInfo.of(member, annotationClass, returnTypeRequired);\n        byte[] bytecode = GizmoMemberAccessorImplementor.defineAccessorFor(className, memberInfo);\n        if (gizmoClassLoader != null) {\n            gizmoClassLoader.register(className, bytecode);\n        }\n        return (MemberAccessor) gizmoClassLoader.loadClass(className).getConstructor().newInstance();\n    }\n```", "  ```\n[EXPECTED_OUTPUT]\n\n```\npackage ai.timefold.solver.core.impl.domain.common.accessor.gizmo;\n\nimport java.lang.annotation.Annotation;\nimport java.lang.reflect.AnnotatedElement;\nimport java.lang.reflect.Field;\nimport java.lang.reflect.InvocationTargetException;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Modifier;\nimport java.lang.reflect.Type;\nimport java.util.Arrays;\nimport java.util.concurrent.atomic.AtomicBoolean;\n\nimport io.quarkus.gizmo.ClassCreator;\nimport io.quarkus.gizmo.MethodCreator;\nimport io.quarkus.gizmo.ResultHandle;\n\n// Note: Some parts of the code are removed for reduction in size.\n\npublic final class GizmoMemberAccessorImplementor {\n\n    public static MemberAccessor createAccessorFor(Member member, Class<? extends Annotation> annotationClass,\n            boolean returnTypeRequired, GizmoClassLoader gizmoClassLoader) {\n        try {\n            Class.forName(member.getDeclaringClass().getName() + \"_\" + member.getName(), true,\n                    gizmoClassLoader.getParentClassLoader());\n            String className = member.getDeclaringClass().getName() + \"_\" + member.getName() + \"Accessor\";\n            Class<? extends AbstractGizmoMemberAccessor> superClass = getCorrectSuperclass(member, returnTypeRequired);\n            try (ClassCreator classCreator = ClassCreator.builder()\n                    .className(className)\n                    .superClass(superClass)\n                    .classOutput(gizmoClassLoader)\n                    .setFinal(true)\n                    .build()) {\n                classCreator.getFieldCreator(\"genericType\", Type.class)\n                        .setModifiers(Modifier.FINAL);\n                classCreator.getFieldCreator(\"annotatedElement\", AnnotatedElement.class)\n                        .setModifiers(Modifier.FINAL);\n\n                // ************************************************************************\n                // MemberAccessor methods\n                // ************************************************************************\n                createConstructor(classCreator, member, annotationClass);\n                createGetDeclaringClass(classCreator, member);\n                createGetType(classCreator, member);\n                createGetGenericType(classCreator);\n                createGetName(classCreator, member);\n                createExecuteGetter(classCreator, member);\n                if (superClass == AbstractReadWriteGizmoMemberAccessor.class) {\n                    createExecuteSetter(classCreator, member);\n                }\n                createGetAnnotation(classCreator);\n                createDeclaredAnnotationsByType(classCreator);\n            }\n            return (MemberAccessor) gizmoClassLoader.loadClass(className)\n                    .getConstructor().newInstance();\n        } catch (InvocationTargetException | InstantiationException | IllegalAccessException | ClassNotFoundException\n                | NoSuchMethodException e) {\n            throw new IllegalStateException(e);\n        }\n    }\n\n}\n\n```\n[/EXPECTED_OUTPUT]\n"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/BestSolutionHolder.java-set": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/solver/BestSolutionHolder.java:\n```\npackage ai.timefold.solver.core.impl.solver;\n\nimport java.math.BigInteger;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.SortedMap;\nimport java.util.TreeMap;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\nimport java.util.function.BooleanSupplier;\n\nimport ai.timefold.solver.core.api.solver.Solver;\nimport ai.timefold.solver.core.api.solver.change.ProblemChange;\n\nfinal class BestSolutionHolder<Solution_> {\n\n    private final Lock problemChangesLock = new ReentrantLock();\n    private final AtomicReference<VersionedBestSolution<Solution_>> versionedBestSolutionRef = new AtomicReference<>();\n    private final SortedMap<BigInteger, List<CompletableFuture<Void>>> problemChangesPerVersion =\n            new TreeMap<>();\n    private BigInteger currentVersion = BigInteger.ZERO;\n\n    boolean isEmpty() {\n        return versionedBestSolutionRef.get() == null;\n    }\n\n    /**\n     * NOT thread-safe.\n     *\n     * @return the last best solution together with problem changes the solution contains.\n     */\n    BestSolutionContainingProblemChanges<Solution_> take() {\n        VersionedBestSolution<Solution_> versionedBestSolution = versionedBestSolutionRef.getAndSet(null);\n        if (versionedBestSolution == null) {\n            return null;\n        }\n        SortedMap<BigInteger, List<CompletableFuture<Void>>> containedProblemChangesPerVersion =\n                problemChangesPerVersion.headMap(versionedBestSolution.getVersion().add(BigInteger.ONE));\n\n        List<CompletableFuture<Void>> containedProblemChanges = new ArrayList<>();\n        for (Map.Entry<BigInteger, List<CompletableFuture<Void>>> entry : containedProblemChangesPerVersion.entrySet()) {\n            containedProblemChanges.addAll(entry.getValue());\n            problemChangesPerVersion.remove(entry.getKey());\n        }\n\n        return new BestSolutionContainingProblemChanges<>(versionedBestSolution.getBestSolution(),\n                containedProblemChanges);\n    }\n\n    /**\n     * Sets the new best solution if all known problem changes have been processed and thus are contained in this\n     * best solution.\n     *\n     * @param bestSolution the new best solution that replaces the previous one if there is any\n     * @param isEveryProblemChangeProcessed a supplier that tells if all problem changes have been processed\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Adds a new problem change to a solver and registers the problem change to be later retrieved together with\n     * a relevant best solution by the {@link #take()} method.\n     *\n     * @return CompletableFuture that will be completed after the best solution containing this change is passed to\n     *         a user-defined Consumer.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    void cancelPendingChanges() {\n        problemChangesLock.lock();\n        try {\n            problemChangesPerVersion.values()\n                    .stream()\n                    .flatMap(Collection::stream)\n                    .forEach(pendingProblemChange -> pendingProblemChange.cancel(false));\n            problemChangesPerVersion.clear();\n        } finally {\n            problemChangesLock.unlock();\n        }\n    }\n\n    private static final class VersionedBestSolution<Solution_> {\n        final Solution_ bestSolution;\n        final BigInteger version;\n\n        public VersionedBestSolution(Solution_ bestSolution, BigInteger version) {\n            this.bestSolution = bestSolution;\n            this.version = version;\n        }\n\n        public Solution_ getBestSolution() {\n            return bestSolution;\n        }\n\n        public BigInteger getVersion() {\n            return version;\n        }\n    }\n}\n\n```\n# Function Signature: void set(Solution_ bestSolution, BooleanSupplier isEveryProblemChangeProcessed) {\n# Natural Language Annotations: /**\n     * Sets the new best solution if all known problem changes have been processed and thus are contained in this\n     * best solution.\n     *\n     * @param bestSolution the new best solution that replaces the previous one if there is any\n     * @param isEveryProblemChangeProcessed a supplier that tells if all problem changes have been processed\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic void set(Solution_ bestSolution, BooleanSupplier isEveryProblemChangeProcessed) {\n    while (!isEveryProblemChangeProcessed.getAsBoolean()) {\n        return;\n    }\n    problemChangesLock.lock();\n    try {\n        VersionedBestSolution<Solution_> versionedBestSolution = new VersionedBestSolution<>(bestSolution, currentVersion);\n        versionedBestSolutionRef.set(versionedBestSolution);\n    } finally {\n        problemChangesLock.unlock();\n    }\n}\n```", "  ```\nprivate void set(Solution_ bestSolution, BooleanSupplier isEveryProblemChangeProcessed) {\n    VersionedBestSolution<Solution_> versionedBestSolution = new VersionedBestSolution<>(bestSolution, currentVersion);\n    if (isEveryProblemChangeProcessed.getAsBoolean()) {\n        versionedBestSolutionRef.set(versionedBestSolution);\n        currentVersion = currentVersion.add(BigInteger.ONE);\n    } else {\n        problemChangesPerVersion.computeIfAbsent(versionedBestSolution.getVersion(), v -> new ArrayList<>()).add(CompletableFuture.completedFuture(null));\n        problemChangesLock.lock();\n        try {\n            problemChangesPerVersion.put(versionedBestSolution.getVersion(), new ArrayList<>());\n        } finally {\n            problemChangesLock.unlock();\n        }\n    }\n}\n```", "  ```\nvoid set(Solution_ bestSolution, BooleanSupplier isEveryProblemChangeProcessed) {\n    // acquire a lock to ensure thread-safety\n    problemChangesLock.lock();\n\n    try {\n        // check if the given best solution is better than the current best solution\n        VersionedBestSolution<Solution_> currentBestSolution = versionedBestSolutionRef.get();\n        if (bestSolution != null && currentBestSolution == null) {\n            // the given best solution is better, so set it as the new current best solution\n            versionedBestSolutionRef.set(new VersionedBestSolution<>(bestSolution, currentVersion.add(BigInteger.ONE)));\n        } else if (bestSolution != null && currentBestSolution != null && currentBestSolution.getBestSolution() == null) {\n            // the given best solution is better, but the current best solution is null, so set it as the new current best solution\n            versionedBestSolutionRef.set(new VersionedBestSolution<>(bestSolution, currentVersion.add(BigInteger.ONE)));\n        } else if (bestSolution != null && currentBestSolution != null && currentBestSolution.getBestSolution() != null &&\n                    currentBestSolution.getBestSolution().getRank() < bestSolution.getRank()) {\n            // the given best solution is better, and is better than the current best solution, so set it as the new current best solution\n            versionedBestSolutionRef.set(new VersionedBestSolution<>(bestSolution, currentVersion.add(BigInteger.ONE)));\n        }\n    } finally {\n        // release the lock to ensure thread-safety\n        problemChangesLock.unlock();\n    }\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/BestSolutionHolder.java-addProblemChange": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/solver/BestSolutionHolder.java:\n```\npackage ai.timefold.solver.core.impl.solver;\n\nimport java.math.BigInteger;\nimport java.util.ArrayList;\nimport java.util.Collection;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.SortedMap;\nimport java.util.TreeMap;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.atomic.AtomicReference;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\nimport java.util.function.BooleanSupplier;\n\nimport ai.timefold.solver.core.api.solver.Solver;\nimport ai.timefold.solver.core.api.solver.change.ProblemChange;\n\nfinal class BestSolutionHolder<Solution_> {\n\n    private final Lock problemChangesLock = new ReentrantLock();\n    private final AtomicReference<VersionedBestSolution<Solution_>> versionedBestSolutionRef = new AtomicReference<>();\n    private final SortedMap<BigInteger, List<CompletableFuture<Void>>> problemChangesPerVersion =\n            new TreeMap<>();\n    private BigInteger currentVersion = BigInteger.ZERO;\n\n    boolean isEmpty() {\n        return versionedBestSolutionRef.get() == null;\n    }\n\n    /**\n     * NOT thread-safe.\n     *\n     * @return the last best solution together with problem changes the solution contains.\n     */\n    BestSolutionContainingProblemChanges<Solution_> take() {\n        VersionedBestSolution<Solution_> versionedBestSolution = versionedBestSolutionRef.getAndSet(null);\n        if (versionedBestSolution == null) {\n            return null;\n        }\n        SortedMap<BigInteger, List<CompletableFuture<Void>>> containedProblemChangesPerVersion =\n                problemChangesPerVersion.headMap(versionedBestSolution.getVersion().add(BigInteger.ONE));\n\n        List<CompletableFuture<Void>> containedProblemChanges = new ArrayList<>();\n        for (Map.Entry<BigInteger, List<CompletableFuture<Void>>> entry : containedProblemChangesPerVersion.entrySet()) {\n            containedProblemChanges.addAll(entry.getValue());\n            problemChangesPerVersion.remove(entry.getKey());\n        }\n\n        return new BestSolutionContainingProblemChanges<>(versionedBestSolution.getBestSolution(),\n                containedProblemChanges);\n    }\n\n    /**\n     * Sets the new best solution if all known problem changes have been processed and thus are contained in this\n     * best solution.\n     *\n     * @param bestSolution the new best solution that replaces the previous one if there is any\n     * @param isEveryProblemChangeProcessed a supplier that tells if all problem changes have been processed\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Adds a new problem change to a solver and registers the problem change to be later retrieved together with\n     * a relevant best solution by the {@link #take()} method.\n     *\n     * @return CompletableFuture that will be completed after the best solution containing this change is passed to\n     *         a user-defined Consumer.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    void cancelPendingChanges() {\n        problemChangesLock.lock();\n        try {\n            problemChangesPerVersion.values()\n                    .stream()\n                    .flatMap(Collection::stream)\n                    .forEach(pendingProblemChange -> pendingProblemChange.cancel(false));\n            problemChangesPerVersion.clear();\n        } finally {\n            problemChangesLock.unlock();\n        }\n    }\n\n    private static final class VersionedBestSolution<Solution_> {\n        final Solution_ bestSolution;\n        final BigInteger version;\n\n        public VersionedBestSolution(Solution_ bestSolution, BigInteger version) {\n            this.bestSolution = bestSolution;\n            this.version = version;\n        }\n\n        public Solution_ getBestSolution() {\n            return bestSolution;\n        }\n\n        public BigInteger getVersion() {\n            return version;\n        }\n    }\n}\n\n```\n# Function Signature: CompletableFuture<Void> addProblemChange(Solver<Solution_> solver, ProblemChange<Solution_> problemChange) {\n# Natural Language Annotations: /**\n     * Adds a new problem change to a solver and registers the problem change to be later retrieved together with\n     * a relevant best solution by the {@link #take()} method.\n     *\n     * @return CompletableFuture that will be completed after the best solution containing this change is passed to\n     *         a user-defined Consumer.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\nCompletableFuture<Void> addProblemChange(Solver<Solution_> solver, ProblemChange<Solution_> problemChange) {\n    CompletableFuture<Void> completableFuture = new CompletableFuture<>();\n    solver.addProblemChange(problemChange)\n            .thenAccept(bestSolution -> {\n                VersionedBestSolution<Solution_> versionedBestSolution = new VersionedBestSolution<>(bestSolution, currentVersion);\n                boolean isEveryProblemChangeProcessed = isEveryProblemChangeProcessed();\n                if (isEveryProblemChangeProcessed) {\n                    versionedBestSolutionRef.set(versionedBestSolution);\n                    problemChangesPerVersion.put(currentVersion, Collections.singletonList(completableFuture));\n                    currentVersion = currentVersion.add(BigInteger.ONE);\n                } else {\n                    problemChangesPerVersion.computeIfAbsent(currentVersion, k -> new ArrayList<>()).add(completableFuture);\n                }\n            });\n    return completableFuture;\n}\n```", "  ```\npublic CompletableFuture<Void> addProblemChange(Solver<Solution_> solver, ProblemChange<Solution_> problemChange) {\n    // Check if the solver is empty\n    if (isEmpty()) {\n        // If the solver is empty, the current version number is 0\n        currentVersion = BigInteger.ZERO;\n    } else {\n        // Otherwise, increment the current version number by 1\n        currentVersion = currentVersion.add(BigInteger.ONE);\n    }\n\n    // Create a new CompletableFuture that will be completed after the best solution containing this change is passed to\n    // a user-defined Consumer\n    CompletableFuture<Void> completableFuture = new CompletableFuture<>();\n\n    // Register the problem change with the current version number\n    problemChangesPerVersion.put(currentVersion, new ArrayList<>());\n    problemChangesPerVersion.get(currentVersion).add(completableFuture);\n\n    // Notify the problem change just added to the solver\n    solver.notifyProblemChange(problemChange);\n\n    return completableFuture;\n}\n```", "  ```\nCompletableFuture<Void> addProblemChange(Solver<Solution_> solver, ProblemChange<Solution_> problemChange) {\n    // Get the current version of the solver\n    BigInteger version = solver.getCurrentVersion().get();\n\n    // Get the best solution for the current version\n    Solution_ bestSolution = solver.getBestSolution(version).get();\n\n    // Create a new versioned best solution with the new problem change\n    VersionedBestSolution<Solution_> versionedBestSolution = new VersionedBestSolution<>(bestSolution, version);\n\n    // Add the problem change to the solver's problem changes map\n    problemChangesPerVersion.computeIfAbsent(version, v -> new ArrayList<>()).add(problemChange);\n\n    // Update the versioned best solution reference\n    versionedBestSolutionRef.set(versionedBestSolution);\n\n    // Create a CompletableFuture that will be completed after the best solution containing this change is passed to\n    // a user-defined Consumer\n    CompletableFuture<Void> completableFuture = new CompletableFuture<>();\n\n    // Register a callback that will complete the CompletableFuture when the problem change is processed\n    solver.getChangeStream().registerChangeSubscriber(problemChange, () -> completableFuture.complete(null));\n\n    // Return the CompletableFuture\n    return completableFuture;\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/random/RandomUtils.java-nextLong": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/solver/random/RandomUtils.java:\n```\npackage ai.timefold.solver.core.impl.solver.random;\n\nimport java.util.Random;\n\npublic class RandomUtils {\n\n    /**\n     * Mimics {@link Random#nextInt(int)} for longs.\n     *\n     * @param random never null\n     * @param n {@code > 0L}\n     * @return like {@link Random#nextInt(int)} but for a long\n     * @see Random#nextInt(int)\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Mimics {@link Random#nextInt(int)} for doubles.\n     *\n     * @param random never null\n     * @param n {@code > 0.0}\n     * @return like {@link Random#nextInt(int)} but for a double\n     * @see Random#nextInt(int)\n     */\n    public static double nextDouble(Random random, double n) {\n        // This code is based on java.util.Random#nextInt(int)'s javadoc.\n        if (n <= 0.0) {\n            throw new IllegalArgumentException(\"n must be positive\");\n        }\n        return random.nextDouble() * n;\n    }\n\n    private RandomUtils() {\n    }\n\n}\n\n```\n# Function Signature: public static long nextLong(Random random, long n) {\n# Natural Language Annotations: /**\n     * Mimics {@link Random#nextInt(int)} for longs.\n     *\n     * @param random never null\n     * @param n {@code > 0L}\n     * @return like {@link Random#nextInt(int)} but for a long\n     * @see Random#nextInt(int)\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static long nextLong(Random random, long n) {\n    if (n <= 0L) {\n        throw new IllegalArgumentException(\"n must be positive\");\n    }\n    return random.nextLong() % n;\n}\n```", "  ```\npublic static long nextLong(Random random, long n) {\n    if (n <= 0L) {\n        throw new IllegalArgumentException(\"n must be positive\");\n    }\n    return random.nextLong() % n;\n}\n```", "  ```\npublic static long nextLong(Random random, long n) {\n    if (random == null) {\n        throw new IllegalArgumentException(\"random must not be null\");\n    }\n    if (n <= 0L) {\n        throw new IllegalArgumentException(\"n must be positive\");\n    }\n    // Mimic nextInt(int) behaviour for longs by shifting the bits left and using\n    // the right-most bits.\n    long result;\n    do {\n        result = random.nextLong();\n        result = (result ^ (result >>> 32)) >>> 16;\n    } while (result >= 0L && result < n);\n    return result % n;\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/AndCompositeTermination.java-calculateSolverTimeGradient": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/solver/termination/AndCompositeTermination.java:\n```\npackage ai.timefold.solver.core.impl.solver.termination;\n\nimport java.util.List;\n\nimport ai.timefold.solver.core.impl.phase.scope.AbstractPhaseScope;\nimport ai.timefold.solver.core.impl.solver.scope.SolverScope;\nimport ai.timefold.solver.core.impl.solver.thread.ChildThreadType;\n\npublic final class AndCompositeTermination<Solution_> extends AbstractCompositeTermination<Solution_> {\n\n    public AndCompositeTermination(List<Termination<Solution_>> terminationList) {\n        super(terminationList);\n    }\n\n    public AndCompositeTermination(Termination<Solution_>... terminations) {\n        super(terminations);\n    }\n\n    // ************************************************************************\n    // Terminated methods\n    // ************************************************************************\n\n    /**\n     * @param solverScope never null\n     * @return true if all the Terminations are terminated.\n     */\n    @Override\n    public boolean isSolverTerminated(SolverScope<Solution_> solverScope) {\n        for (Termination<Solution_> termination : terminationList) {\n            if (!termination.isSolverTerminated(solverScope)) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * @param phaseScope never null\n     * @return true if all the Terminations are terminated.\n     */\n    @Override\n    public boolean isPhaseTerminated(AbstractPhaseScope<Solution_> phaseScope) {\n        for (Termination<Solution_> termination : terminationList) {\n            if (!termination.isPhaseTerminated(phaseScope)) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    // ************************************************************************\n    // Time gradient methods\n    // ************************************************************************\n\n    /**\n     * Calculates the minimum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param solverScope never null\n     * @return the minimum timeGradient of the Terminations.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Calculates the minimum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param phaseScope never null\n     * @return the minimum timeGradient of the Terminations.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    // ************************************************************************\n    // Other methods\n    // ************************************************************************\n\n    @Override\n    public AndCompositeTermination<Solution_> createChildThreadTermination(SolverScope<Solution_> solverScope,\n            ChildThreadType childThreadType) {\n        return new AndCompositeTermination<>(createChildThreadTerminationList(solverScope, childThreadType));\n    }\n\n    @Override\n    public String toString() {\n        return \"And(\" + terminationList + \")\";\n    }\n\n}\n\n```\n# Function Signature: @Override    public double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n# Natural Language Annotations: /**\n     * Calculates the minimum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param solverScope never null\n     * @return the minimum timeGradient of the Terminations.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    double minimumTimeGradient = 1.0;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculateSolverTimeGradient(solverScope);\n        if (timeGradient >= 0.0 && timeGradient < minimumTimeGradient) {\n            minimumTimeGradient = timeGradient;\n        }\n    }\n    return minimumTimeGradient;\n}\n```", "  ```\n@Override\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    double minTimeGradient = -1.0;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.isTimeGradientSupported(solverScope) ? termination.calculateSolverTimeGradient(solverScope) : -1.0;\n        if (timeGradient < minTimeGradient || minTimeGradient < 0) {\n            minTimeGradient = timeGradient;\n        }\n    }\n    return minTimeGradient;\n}\n```", "  ```\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    // Ignore -1.0 timeGradients (not supported)\n    List<Double> validTimeGradients = new ArrayList<>();\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculateSolverTimeGradient(solverScope);\n        if (timeGradient != -1.0) {\n            validTimeGradients.add(timeGradient);\n        }\n    }\n    // Return the minimum timeGradient of the valid Terminations\n    if (validTimeGradients.isEmpty()) {\n        return -1.0;\n    }\n    return Collections.min(validTimeGradients);\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/AndCompositeTermination.java-calculatePhaseTimeGradient": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/solver/termination/AndCompositeTermination.java:\n```\npackage ai.timefold.solver.core.impl.solver.termination;\n\nimport java.util.List;\n\nimport ai.timefold.solver.core.impl.phase.scope.AbstractPhaseScope;\nimport ai.timefold.solver.core.impl.solver.scope.SolverScope;\nimport ai.timefold.solver.core.impl.solver.thread.ChildThreadType;\n\npublic final class AndCompositeTermination<Solution_> extends AbstractCompositeTermination<Solution_> {\n\n    public AndCompositeTermination(List<Termination<Solution_>> terminationList) {\n        super(terminationList);\n    }\n\n    public AndCompositeTermination(Termination<Solution_>... terminations) {\n        super(terminations);\n    }\n\n    // ************************************************************************\n    // Terminated methods\n    // ************************************************************************\n\n    /**\n     * @param solverScope never null\n     * @return true if all the Terminations are terminated.\n     */\n    @Override\n    public boolean isSolverTerminated(SolverScope<Solution_> solverScope) {\n        for (Termination<Solution_> termination : terminationList) {\n            if (!termination.isSolverTerminated(solverScope)) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    /**\n     * @param phaseScope never null\n     * @return true if all the Terminations are terminated.\n     */\n    @Override\n    public boolean isPhaseTerminated(AbstractPhaseScope<Solution_> phaseScope) {\n        for (Termination<Solution_> termination : terminationList) {\n            if (!termination.isPhaseTerminated(phaseScope)) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    // ************************************************************************\n    // Time gradient methods\n    // ************************************************************************\n\n    /**\n     * Calculates the minimum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param solverScope never null\n     * @return the minimum timeGradient of the Terminations.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Calculates the minimum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param phaseScope never null\n     * @return the minimum timeGradient of the Terminations.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    // ************************************************************************\n    // Other methods\n    // ************************************************************************\n\n    @Override\n    public AndCompositeTermination<Solution_> createChildThreadTermination(SolverScope<Solution_> solverScope,\n            ChildThreadType childThreadType) {\n        return new AndCompositeTermination<>(createChildThreadTerminationList(solverScope, childThreadType));\n    }\n\n    @Override\n    public String toString() {\n        return \"And(\" + terminationList + \")\";\n    }\n\n}\n\n```\n# Function Signature: @Override    public double calculatePhaseTimeGradient(AbstractPhaseScope<Solution_> phaseScope) {\n# Natural Language Annotations: /**\n     * Calculates the minimum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param phaseScope never null\n     * @return the minimum timeGradient of the Terminations.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic double calculatePhaseTimeGradient(AbstractPhaseScope<Solution_> phaseScope) {\n    double timeGradient = -1.0; // -1.0 means termination not supported\n    for (Termination<Solution_> termination : terminationList) {\n        double terminationTimeGradient = termination.calculatePhaseTimeGradient(phaseScope);\n        if (terminationTimeGradient >= 0.0) { // not -1.0\n            if (timeGradient == -1.0) {\n                timeGradient = terminationTimeGradient;\n            } else {\n                timeGradient = Math.min(timeGradient, terminationTimeGradient);\n            }\n        }\n    }\n    return timeGradient;\n}\n```", "  ```\n@Override\npublic double calculatePhaseTimeGradient(AbstractPhaseScope<Solution_> phaseScope) {\n    double minimumTimeGradient = PhaseScope.NO_BEST_SCORE_PRESENT;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculatePhaseTimeGradient(phaseScope);\n        if (timeGradient >= 0 && (minimumTimeGradient < 0 || timeGradient < minimumTimeGradient)) {\n            minimumTimeGradient = timeGradient;\n        }\n    }\n    return minimumTimeGradient;\n}\n```", "  ```\n@Override\npublic double calculatePhaseTimeGradient(AbstractPhaseScope<Solution_> phaseScope) {\n    double minimumTimeGradient = Double.MAX_VALUE;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculatePhaseTimeGradient(phaseScope);\n        if (timeGradient >= 0 && timeGradient < minimumTimeGradient) {\n            minimumTimeGradient = timeGradient;\n        }\n    }\n    return minimumTimeGradient;\n}\n```\nThis code calculates the minimum time gradient of all Terminations in theAndCompositeTermination. It returns the minimum time gradient if all Terminations support it (timeGradient > 0), otherwise it returns Double.MAX_VALUE."]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/OrCompositeTermination.java-calculateSolverTimeGradient": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/solver/termination/OrCompositeTermination.java:\n```\npackage ai.timefold.solver.core.impl.solver.termination;\n\nimport java.util.List;\n\nimport ai.timefold.solver.core.impl.phase.scope.AbstractPhaseScope;\nimport ai.timefold.solver.core.impl.solver.scope.SolverScope;\nimport ai.timefold.solver.core.impl.solver.thread.ChildThreadType;\n\npublic final class OrCompositeTermination<Solution_> extends AbstractCompositeTermination<Solution_> {\n\n    public OrCompositeTermination(List<Termination<Solution_>> terminationList) {\n        super(terminationList);\n    }\n\n    public OrCompositeTermination(Termination<Solution_>... terminations) {\n        super(terminations);\n    }\n\n    // ************************************************************************\n    // Terminated methods\n    // ************************************************************************\n\n    /**\n     * @param solverScope never null\n     * @return true if any of the Termination is terminated.\n     */\n    @Override\n    public boolean isSolverTerminated(SolverScope<Solution_> solverScope) {\n        for (Termination<Solution_> termination : terminationList) {\n            if (termination.isSolverTerminated(solverScope)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    /**\n     * @param phaseScope never null\n     * @return true if any of the Termination is terminated.\n     */\n    @Override\n    public boolean isPhaseTerminated(AbstractPhaseScope<Solution_> phaseScope) {\n        for (Termination<Solution_> termination : terminationList) {\n            if (termination.isPhaseTerminated(phaseScope)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    // ************************************************************************\n    // Time gradient methods\n    // ************************************************************************\n\n    /**\n     * Calculates the maximum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param solverScope never null\n     * @return the maximum timeGradient of the Terminations.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Calculates the maximum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param phaseScope never null\n     * @return the maximum timeGradient of the Terminations.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    // ************************************************************************\n    // Other methods\n    // ************************************************************************\n\n    @Override\n    public OrCompositeTermination<Solution_> createChildThreadTermination(SolverScope<Solution_> solverScope,\n            ChildThreadType childThreadType) {\n        return new OrCompositeTermination<>(createChildThreadTerminationList(solverScope, childThreadType));\n    }\n\n    @Override\n    public String toString() {\n        return \"Or(\" + terminationList + \")\";\n    }\n\n}\n\n```\n# Function Signature: @Override    public double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n# Natural Language Annotations: /**\n     * Calculates the maximum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param solverScope never null\n     * @return the maximum timeGradient of the Terminations.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    double timeGradient = -1.0;\n    for (Termination<Solution_> termination : terminationList) {\n        if (termination.supportsSolverTimeGradient(solverScope)) {\n            double terminationTimeGradient = termination.calculateSolverTimeGradient(solverScope);\n            if (terminationTimeGradient > timeGradient) {\n                timeGradient = terminationTimeGradient;\n            }\n        }\n    }\n    return timeGradient;\n}\n```", "  ```\n@Override\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    double timeGradient = -1.0;\n    for (Termination<Solution_> termination : terminationList) {\n        double terminationTimeGradient = termination.calculateTimeGradient(solverScope);\n        if (terminationTimeGradient > timeGradient) {\n            timeGradient = terminationTimeGradient;\n        }\n    }\n    return timeGradient;\n}\n```", "  ```\n@Override\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    double timeGradient = Double.NEGATIVE_INFINITY;\n    for (Termination<Solution_> termination : terminationList) {\n        double terminationTimeGradient = termination.getSolverTimeGradient(solverScope);\n        if (terminationTimeGradient > timeGradient) {\n            timeGradient = terminationTimeGradient;\n        }\n    }\n    return timeGradient;\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/OrCompositeTermination.java-calculatePhaseTimeGradient": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/solver/termination/OrCompositeTermination.java:\n```\npackage ai.timefold.solver.core.impl.solver.termination;\n\nimport java.util.List;\n\nimport ai.timefold.solver.core.impl.phase.scope.AbstractPhaseScope;\nimport ai.timefold.solver.core.impl.solver.scope.SolverScope;\nimport ai.timefold.solver.core.impl.solver.thread.ChildThreadType;\n\npublic final class OrCompositeTermination<Solution_> extends AbstractCompositeTermination<Solution_> {\n\n    public OrCompositeTermination(List<Termination<Solution_>> terminationList) {\n        super(terminationList);\n    }\n\n    public OrCompositeTermination(Termination<Solution_>... terminations) {\n        super(terminations);\n    }\n\n    // ************************************************************************\n    // Terminated methods\n    // ************************************************************************\n\n    /**\n     * @param solverScope never null\n     * @return true if any of the Termination is terminated.\n     */\n    @Override\n    public boolean isSolverTerminated(SolverScope<Solution_> solverScope) {\n        for (Termination<Solution_> termination : terminationList) {\n            if (termination.isSolverTerminated(solverScope)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    /**\n     * @param phaseScope never null\n     * @return true if any of the Termination is terminated.\n     */\n    @Override\n    public boolean isPhaseTerminated(AbstractPhaseScope<Solution_> phaseScope) {\n        for (Termination<Solution_> termination : terminationList) {\n            if (termination.isPhaseTerminated(phaseScope)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    // ************************************************************************\n    // Time gradient methods\n    // ************************************************************************\n\n    /**\n     * Calculates the maximum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param solverScope never null\n     * @return the maximum timeGradient of the Terminations.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Calculates the maximum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param phaseScope never null\n     * @return the maximum timeGradient of the Terminations.\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    // ************************************************************************\n    // Other methods\n    // ************************************************************************\n\n    @Override\n    public OrCompositeTermination<Solution_> createChildThreadTermination(SolverScope<Solution_> solverScope,\n            ChildThreadType childThreadType) {\n        return new OrCompositeTermination<>(createChildThreadTerminationList(solverScope, childThreadType));\n    }\n\n    @Override\n    public String toString() {\n        return \"Or(\" + terminationList + \")\";\n    }\n\n}\n\n```\n# Function Signature: @Override    public double calculatePhaseTimeGradient(AbstractPhaseScope<Solution_> phaseScope) {\n# Natural Language Annotations: /**\n     * Calculates the maximum timeGradient of all Terminations.\n     * Not supported timeGradients (-1.0) are ignored.\n     *\n     * @param phaseScope never null\n     * @return the maximum timeGradient of the Terminations.\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Override\npublic double calculatePhaseTimeGradient(AbstractPhaseScope<Solution_> phaseScope) {\n    double timeGradient = 0.0;\n    for (Termination<Solution_> termination : terminationList) {\n        double terminationTimeGradient = termination.calculatePhaseTimeGradient(phaseScope);\n        if (terminationTimeGradient > timeGradient) {\n            timeGradient = terminationTimeGradient;\n        }\n    }\n    return timeGradient;\n}\n```", "  ```\npublic double calculatePhaseTimeGradient(AbstractPhaseScope<Solution> phaseScope) {\n    double maxTimeGradient = -1.0;\n    for (Termination<Solution> termination : terminationList) {\n        double timeGradient = termination.calculatePhaseTimeGradient(phaseScope);\n        if (timeGradient > maxTimeGradient) {\n            maxTimeGradient = timeGradient;\n        }\n    }\n    return maxTimeGradient;\n}\n```", "  ```\n@Override\npublic double calculatePhaseTimeGradient(AbstractPhaseScope<Solution_> phaseScope) {\n    double phaseTimeGradient = -1.0;\n    for (Termination<Solution_> termination : terminationList) {\n        double terminationTimeGradient = termination.calculatePhaseTimeGradient(phaseScope);\n        if (terminationTimeGradient > phaseTimeGradient && terminationTimeGradient != -1.0) {\n            phaseTimeGradient = terminationTimeGradient;\n        }\n    }\n    return phaseTimeGradient;\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/heuristic/selector/move/generic/list/kopt/KOptUtils.java-getCyclesForPermutation": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/heuristic/selector/move/generic/list/kopt/KOptUtils.java:\n```\npackage ai.timefold.solver.core.impl.heuristic.selector.move.generic.list.kopt;\n\nimport java.util.ArrayList;\nimport java.util.BitSet;\nimport java.util.List;\nimport java.util.function.Function;\n\nimport ai.timefold.solver.core.api.function.TriPredicate;\nimport ai.timefold.solver.core.impl.domain.variable.ListVariableStateSupply;\nimport ai.timefold.solver.core.impl.domain.variable.index.IndexVariableSupply;\nimport ai.timefold.solver.core.impl.util.Pair;\n\nimport org.apache.commons.math3.util.CombinatoricsUtils;\n\nfinal class KOptUtils {\n\n    private KOptUtils() {\n    }\n\n    /**\n     * Calculate the disjoint k-cycles for {@link KOptDescriptor#removedEdgeIndexToTourOrder()}. <br />\n     * <br />\n     * Any permutation can be expressed as combination of k-cycles. A k-cycle is a sequence of\n     * unique elements (p_1, p_2, ..., p_k) where\n     * <ul>\n     * <li>p_1 maps to p_2 in the permutation</li>\n     * <li>p_2 maps to p_3 in the permutation</li>\n     * <li>p_(k-1) maps to p_k in the permutation</li>\n     * <li>p_k maps to p_1 in the permutation</li>\n     * <li>In general: p_i maps to p_(i+1) in the permutation</li>\n     * </ul>\n     * For instance, the permutation\n     * <ul>\n     * <li>1 -> 2</li>\n     * <li>2 -> 3</li>\n     * <li>3 -> 1</li>\n     * <li>4 -> 5</li>\n     * <li>5 -> 4</li>\n     * </ul>\n     * can be expressed as `(1, 2, 3)(4, 5)`.\n     *\n     * @return The {@link KOptCycle} corresponding to the permutation described by\n     *         {@link KOptDescriptor#removedEdgeIndexToTourOrder()}.\n     * @param kOptDescriptor The descriptor to calculate cycles for\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    static <Node_> List<Pair<Node_, Node_>> getAddedEdgeList(KOptDescriptor<Node_> kOptDescriptor) {\n        var k = kOptDescriptor.k();\n        List<Pair<Node_, Node_>> out = new ArrayList<>(2 * k);\n        var currentEndpoint = 1;\n\n        var removedEdges = kOptDescriptor.removedEdges();\n        var addedEdgeToOtherEndpoint = kOptDescriptor.addedEdgeToOtherEndpoint();\n        var removedEdgeIndexToTourOrder = kOptDescriptor.removedEdgeIndexToTourOrder();\n        var inverseRemovedEdgeIndexToTourOrder = kOptDescriptor.inverseRemovedEdgeIndexToTourOrder();\n\n        // This loop iterates through the new tour created\n        while (currentEndpoint != 2 * k + 1) {\n            out.add(new Pair<>(removedEdges[currentEndpoint], removedEdges[addedEdgeToOtherEndpoint[currentEndpoint]]));\n            var tourIndex = removedEdgeIndexToTourOrder[currentEndpoint];\n            var nextEndpointTourIndex = addedEdgeToOtherEndpoint[tourIndex];\n            currentEndpoint = inverseRemovedEdgeIndexToTourOrder[nextEndpointTourIndex] ^ 1;\n        }\n        return out;\n    }\n\n    static <Node_> List<Pair<Node_, Node_>> getRemovedEdgeList(KOptDescriptor<Node_> kOptDescriptor) {\n        var k = kOptDescriptor.k();\n        var removedEdges = kOptDescriptor.removedEdges();\n        List<Pair<Node_, Node_>> out = new ArrayList<>(2 * k);\n        for (var i = 1; i <= k; i++) {\n            out.add(new Pair<>(removedEdges[2 * i - 1], removedEdges[2 * i]));\n        }\n        return out;\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    public static <Node_> Function<Node_, Node_> getMultiEntitySuccessorFunction(Node_[] pickedValues,\n            ListVariableStateSupply<?> listVariableStateSupply) {\n        var entityOrderInfo = EntityOrderInfo.of(pickedValues, listVariableStateSupply);\n        return node -> entityOrderInfo.successor(node, listVariableStateSupply);\n    }\n\n    public static <Node_> TriPredicate<Node_, Node_, Node_> getBetweenPredicate(IndexVariableSupply indexVariableSupply) {\n        return (start, middle, end) -> {\n            int startIndex = indexVariableSupply.getIndex(start);\n            int middleIndex = indexVariableSupply.getIndex(middle);\n            int endIndex = indexVariableSupply.getIndex(end);\n\n            if (startIndex <= endIndex) {\n                // test middleIndex in [startIndex, endIndex]\n                return startIndex <= middleIndex && middleIndex <= endIndex;\n            } else {\n                // test middleIndex in [0, endIndex] or middleIndex in [startIndex, listSize)\n                return middleIndex >= startIndex || middleIndex <= endIndex;\n            }\n        };\n    }\n\n    public static <Node_> TriPredicate<Node_, Node_, Node_> getMultiEntityBetweenPredicate(Node_[] pickedValues,\n            ListVariableStateSupply<?> listVariableStateSupply) {\n        var entityOrderInfo = EntityOrderInfo.of(pickedValues, listVariableStateSupply);\n        return (start, middle, end) -> entityOrderInfo.between(start, middle, end, listVariableStateSupply);\n    }\n\n    public static void flipSubarray(int[] array, int fromIndexInclusive, int toIndexExclusive) {\n        if (fromIndexInclusive < toIndexExclusive) {\n            final var halfwayPoint = (toIndexExclusive - fromIndexInclusive) >> 1;\n            for (var i = 0; i < halfwayPoint; i++) {\n                var saved = array[fromIndexInclusive + i];\n                array[fromIndexInclusive + i] = array[toIndexExclusive - i - 1];\n                array[toIndexExclusive - i - 1] = saved;\n            }\n        } else {\n            var firstHalfSize = array.length - fromIndexInclusive;\n            var secondHalfSize = toIndexExclusive;\n\n            // Reverse the combined list firstHalfReversedPath + secondHalfReversedPath\n            // For instance, (1, 2, 3)(4, 5, 6, 7, 8, 9) becomes\n            // (9, 8, 7)(6, 5, 4, 3, 2, 1)\n            var totalLength = firstHalfSize + secondHalfSize;\n\n            // Used to rotate the list to put the first element back in its original position\n            for (var i = 0; (i < totalLength >> 1); i++) {\n                int firstHalfIndex;\n                int secondHalfIndex;\n\n                if (i < firstHalfSize) {\n                    if (i < secondHalfSize) {\n                        firstHalfIndex = fromIndexInclusive + i;\n                        secondHalfIndex = secondHalfSize - i - 1;\n                    } else {\n                        firstHalfIndex = fromIndexInclusive + i;\n                        secondHalfIndex = array.length - (i - secondHalfSize) - 1;\n                    }\n                } else {\n                    firstHalfIndex = i - firstHalfSize;\n                    secondHalfIndex = secondHalfSize - i - 1;\n                }\n\n                var saved = array[firstHalfIndex];\n                array[firstHalfIndex] = array[secondHalfIndex];\n                array[secondHalfIndex] = saved;\n            }\n        }\n    }\n\n    /**\n     * Returns the number of unique ways a K-Opt can add K edges without reinserting a removed edge.\n     *\n     * @param k How many edges were removed/will be added\n     * @return the number of unique ways a K-Opt can add K edges without reinserting a removed edge.\n     */\n    public static long getPureKOptMoveTypes(int k) {\n        // This calculates the item at index k for the sequence https://oeis.org/A061714\n        long totalTypes = 0;\n        for (var i = 1; i < k; i++) {\n            for (var j = 0; j <= i; j++) {\n                var sign = ((k + j - 1) % 2 == 0) ? 1 : -1;\n                totalTypes += sign * CombinatoricsUtils.binomialCoefficient(i, j) * CombinatoricsUtils.factorial(j) * (1L << j);\n            }\n        }\n        return totalTypes;\n    }\n}\n\n```\n# Function Signature: static KOptCycle getCyclesForPermutation(KOptDescriptor<?> kOptDescriptor) {\n# Natural Language Annotations: /**\n     * Calculate the disjoint k-cycles for {@link KOptDescriptor#removedEdgeIndexToTourOrder()}. <br />\n     * <br />\n     * Any permutation can be expressed as combination of k-cycles. A k-cycle is a sequence of\n     * unique elements (p_1, p_2, ..., p_k) where\n     * <ul>\n     * <li>p_1 maps to p_2 in the permutation</li>\n     * <li>p_2 maps to p_3 in the permutation</li>\n     * <li>p_(k-1) maps to p_k in the permutation</li>\n     * <li>p_k maps to p_1 in the permutation</li>\n     * <li>In general: p_i maps to p_(i+1) in the permutation</li>\n     * </ul>\n     * For instance, the permutation\n     * <ul>\n     * <li>1 -> 2</li>\n     * <li>2 -> 3</li>\n     * <li>3 -> 1</li>\n     * <li>4 -> 5</li>\n     * <li>5 -> 4</li>\n     * </ul>\n     * can be expressed as `(1, 2, 3)(4, 5)`.\n     *\n     * @return The {@link KOptCycle} corresponding to the permutation described by\n     *         {@link KOptDescriptor#removedEdgeIndexToTourOrder()}.\n     * @param kOptDescriptor The descriptor to calculate cycles for\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n    static <Node_> KOptCycle<Node_> getCyclesForPermutation(KOptDescriptor<Node_> kOptDescriptor) {\n        var k = kOptDescriptor.k();\n        var removedEdges = kOptDescriptor.removedEdges();\n        var removedEdgeIndexToTourOrder = kOptDescriptor.removedEdgeIndexToTourOrder();\n        var inverseRemovedEdgeIndexToTourOrder = kOptDescriptor.inverseRemovedEdgeIndexToTourOrder();\n\n        // This loop iterates through the new tour created\n        var currentEndpoint = 1;\n        var nodes = new ArrayList<Node_>(k);\n        while (currentEndpoint != 2 * k + 1) {\n            var targetNode = removedEdges[removedEdgeIndexToTourOrder[currentEndpoint]];\n            nodes.add(removedEdges[currentEndpoint]);\n            nodes.add(targetNode);\n            var nextEndpointTourIndex = addedEdgeToOtherEndpoint[currentEndpoint];\n            currentEndpoint = inverseRemovedEdgeIndexToTourOrder[nextEndpointTourIndex] ^ 1;\n        }\n        return new KOptCycle<>(nodes);\n    }\n```", "  ```\nstatic <Node_> KOptCycle getCyclesForPermutation(KOptDescriptor<Node_> kOptDescriptor) {\n     var removedEdges = kOptDescriptor.removedEdges();\n     var addedEdgeToOtherEndpoint = kOptDescriptor.addedEdgeToOtherEndpoint();\n     var removedEdgeIndexToTourOrder = kOptDescriptor.removedEdgeIndexToTourOrder();\n     var inverseRemovedEdgeIndexToTourOrder = kOptDescriptor.inverseRemovedEdgeIndexToTourOrder();\n     var k = kOptDescriptor.k();\n     var currentEndpoint = 1;\n     var cycles = new KOptCycle(k);\n     // This loop iterates through the new tour created\n     while(currentEndpoint != 2 * k + 1) {\n         var start = removedEdges[currentEndpoint];\n         var end = removedEdges[addedEdgeToOtherEndpoint[currentEndpoint]];\n         var tourIndex = removedEdgeIndexToTourOrder[currentEndpoint];\n         var nextEndpointTourIndex = addedEdgeToOtherEndpoint[tourIndex];\n         currentEndpoint = inverseRemovedEdgeIndexToTourOrder[nextEndpointTourIndex] ^ 1;\n         var cycle = new KOptEdge(start, end);\n         cycles.add(cycle);\n     }\n     return cycles;\n }\n ```", "  ```java\n    static <Node_> KOptCycle getCyclesForPermutation(KOptDescriptor<Node_> kOptDescriptor) {\n        var k = kOptDescriptor.k();\n        var removedEdges = kOptDescriptor.removedEdges();\n        var removedEdgeIndexToTourOrder = kOptDescriptor.removedEdgeIndexToTourOrder();\n        var kOptCycle = new KOptCycle();\n\n        var currentEndpoint = 1;\n        // This loop iterates through the permutation\n        while (currentEndpoint != 2 * k + 1) {\n            kOptCycle.addCycle(new ArrayList<>());\n            var tourIndex = removedEdgeIndexToTourOrder[currentEndpoint];\n            var nextEndpointTourIndex = 0;\n            var count = 0;\n            do {\n                nextEndpointTourIndex = kOptDescriptor.removedEdgeIndexToTourOrder[tourIndex];\n                var currentNode = removedEdges[tourIndex];\n                var nextNode = removedEdges[nextEndpointTourIndex];\n                kOptCycle.getLastCycle().add(new Pair<>(currentNode, nextNode));\n                if (count == 2 * (k - 1)) {\n                    break;\n                }\n                count++;\n            } while (nextEndpointTourIndex != removedEdgeIndexToTourOrder[currentEndpoint]);\n            currentEndpoint = removedEdgeIndexToTourOrder[nextEndpointTourIndex] ^ 1;\n        }\n        return kOptCycle;\n    }\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/heuristic/selector/list/TriangleElementFactory.java-nextElement": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/impl/heuristic/selector/list/TriangleElementFactory.java:\n```\npackage ai.timefold.solver.core.impl.heuristic.selector.list;\n\nimport static ai.timefold.solver.core.impl.heuristic.selector.list.TriangularNumbers.nthTriangle;\nimport static ai.timefold.solver.core.impl.heuristic.selector.list.TriangularNumbers.triangularRoot;\n\nimport java.util.Random;\n\nfinal class TriangleElementFactory {\n\n    private final int minimumSubListSize;\n    private final int maximumSubListSize;\n    private final Random workingRandom;\n\n    TriangleElementFactory(int minimumSubListSize, int maximumSubListSize, Random workingRandom) {\n        if (minimumSubListSize > maximumSubListSize) {\n            throw new IllegalArgumentException(\"The minimumSubListSize (\" + minimumSubListSize\n                    + \") must be less than or equal to the maximumSubListSize (\" + maximumSubListSize + \").\");\n        }\n        if (minimumSubListSize < 1) {\n            throw new IllegalArgumentException(\n                    \"The minimumSubListSize (\" + minimumSubListSize + \") must be greater than 0.\");\n        }\n        this.minimumSubListSize = minimumSubListSize;\n        this.maximumSubListSize = maximumSubListSize;\n        this.workingRandom = workingRandom;\n    }\n\n    /**\n     * Produce next random element of Triangle(listSize) observing the given minimum and maximum subList size.\n     *\n     * @param listSize determines the Triangle to select an element from\n     * @return next random triangle element\n     * @throws IllegalArgumentException if {@code listSize} is less than {@code minimumSubListSize}\n     */\n\n\n\n\n\n\n\n\n\n\n    record TriangleElement(int index, int level, int indexOnLevel) {\n\n        static TriangleElement valueOf(int index) {\n            int level = (int) Math.ceil(triangularRoot(index));\n            return new TriangleElement(index, level, index - nthTriangle(level - 1));\n        }\n\n    }\n}\n\n```\n# Function Signature: TriangleElement nextElement(int listSize) throws IllegalArgumentException {\n# Natural Language Annotations: /**\n     * Produce next random element of Triangle(listSize) observing the given minimum and maximum subList size.\n     *\n     * @param listSize determines the Triangle to select an element from\n     * @return next random triangle element\n     * @throws IllegalArgumentException if {@code listSize} is less than {@code minimumSubListSize}\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static TriangleElement nextElement(int listSize) throws IllegalArgumentException {\n    if (listSize < minimumSubListSize) {\n        throw new IllegalArgumentException(\"List size must be at least \" + minimumSubListSize);\n    }\n    int index = random.nextInt(listSize - minimumSubListSize + 1) + minimumSubListSize;\n    return TriangleElement.valueOf(index);\n}\n```", "  ```\nTriangleElement nextElement(int listSize) throws IllegalArgumentException {\n    if (listSize < minimumSubListSize) {\n        throw new IllegalArgumentException(\"listSize must be at least \" + minimumSubListSize);\n    }\n\n    int n = workingRandom.nextInt(listSize + 1);\n    if (n > maximumSubListSize) {\n        n = workingRandom.nextInt(maximumSubListSize - minimumSubListSize + 1) + minimumSubListSize;\n    }\n\n    int index = nthTriangle(n);\n    int level = (int) Math.ceil(triangularRoot(index));\n    int indexOnLevel = index - nthTriangle(level - 1);\n\n    return new TriangleElement(index, level, indexOnLevel);\n}\n```", "  ```\npublic TriangleElement nextElement(int listSize) throws IllegalArgumentException {\n        // ensure the given listSize is valid\n        if (listSize < minimumSubListSize) {\n            throw new IllegalArgumentException(\"The listSize must be greater than or equal to the minimumSubListSize (\" + minimumSubListSize + \").\");\n        }\n\n        // generate a random number between 0 and the maximumSubListSize\n        int randomNumber = workingRandom.nextInt(maximumSubListSize);\n\n        // adjust the random number based on the minimumSubListSize\n        randomNumber += minimumSubListSize;\n\n        // ensure the adjusted random number is within the range of the given listSize\n        if (randomNumber >= listSize) {\n            randomNumber = listSize - 1;\n        }\n\n        return TriangleElement.valueOf(randomNumber);\n    }\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/constraint/ConstraintMatch.java-getJustificationList": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/api/score/constraint/ConstraintMatch.java:\n```\npackage ai.timefold.solver.core.api.score.constraint;\n\nimport static java.util.Objects.requireNonNull;\n\nimport java.util.Collection;\nimport java.util.List;\n\nimport ai.timefold.solver.core.api.score.Score;\nimport ai.timefold.solver.core.api.score.stream.Constraint;\nimport ai.timefold.solver.core.api.score.stream.ConstraintJustification;\nimport ai.timefold.solver.core.api.score.stream.DefaultConstraintJustification;\nimport ai.timefold.solver.core.api.solver.SolutionManager;\n\n/**\n * Retrievable from {@link ConstraintMatchTotal#getConstraintMatchSet()}\n * and {@link Indictment#getConstraintMatchSet()}.\n *\n * <p>\n * This class implements {@link Comparable} for consistent ordering of constraint matches in visualizations.\n * The details of this ordering are unspecified and are subject to change.\n *\n * <p>\n * If possible, prefer using {@link SolutionManager#analyze(Object)} instead.\n *\n * @param <Score_> the actual score type\n */\npublic final class ConstraintMatch<Score_ extends Score<Score_>> implements Comparable<ConstraintMatch<Score_>> {\n\n    private final ConstraintRef constraintRef;\n    private final ConstraintJustification justification;\n    private final List<Object> indictedObjectList;\n    private final Score_ score;\n\n    /**\n     * @deprecated Prefer {@link ConstraintMatch#ConstraintMatch(ConstraintRef, ConstraintJustification, Collection, Score)}.\n     * @param constraintPackage never null\n     * @param constraintName never null\n     * @param justificationList never null, sometimes empty\n     * @param score never null\n     */\n    @Deprecated(forRemoval = true)\n    public ConstraintMatch(String constraintPackage, String constraintName, List<Object> justificationList, Score_ score) {\n        this(constraintPackage, constraintName, DefaultConstraintJustification.of(score, justificationList),\n                justificationList, score);\n    }\n\n    /**\n     * @deprecated Prefer {@link ConstraintMatch#ConstraintMatch(ConstraintRef, ConstraintJustification, Collection, Score)}.\n     * @param constraintPackage never null\n     * @param constraintName never null\n     * @param justification never null\n     * @param score never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.4.0\")\n    public ConstraintMatch(String constraintPackage, String constraintName, ConstraintJustification justification,\n            Collection<Object> indictedObjectList, Score_ score) {\n        this(ConstraintRef.of(constraintPackage, constraintName), justification, indictedObjectList, score);\n    }\n\n    /**\n     * @deprecated Prefer {@link ConstraintMatch#ConstraintMatch(ConstraintRef, ConstraintJustification, Collection, Score)}.\n     * @param constraint never null\n     * @param justification never null\n     * @param score never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.4.0\")\n    public ConstraintMatch(Constraint constraint, ConstraintJustification justification, Collection<Object> indictedObjectList,\n            Score_ score) {\n        this(constraint.getConstraintRef(), justification, indictedObjectList, score);\n    }\n\n    /**\n     * @deprecated Prefer {@link ConstraintMatch#ConstraintMatch(ConstraintRef, ConstraintJustification, Collection, Score)}.\n     * @param constraintId never null\n     * @param constraintPackage never null\n     * @param constraintName never null\n     * @param justification never null\n     * @param score never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.4.0\")\n    public ConstraintMatch(String constraintId, String constraintPackage, String constraintName,\n            ConstraintJustification justification, Collection<Object> indictedObjectList, Score_ score) {\n        this(new ConstraintRef(constraintPackage, constraintName, constraintId), justification, indictedObjectList, score);\n    }\n\n    /**\n     * @param constraintRef never null\n     * @param justification never null\n     * @param score never null\n     */\n    public ConstraintMatch(ConstraintRef constraintRef, ConstraintJustification justification,\n            Collection<Object> indictedObjectList, Score_ score) {\n        this.constraintRef = requireNonNull(constraintRef);\n        this.justification = requireNonNull(justification);\n        this.indictedObjectList =\n                requireNonNull(indictedObjectList) instanceof List<Object> list ? list : List.copyOf(indictedObjectList);\n        this.score = requireNonNull(score);\n    }\n\n    public ConstraintRef getConstraintRef() {\n        return constraintRef;\n    }\n\n    /**\n     * @deprecated Prefer {@link #getConstraintRef()} instead.\n     * @return maybe null\n     */\n    @Deprecated(forRemoval = true, since = \"1.4.0\")\n    public String getConstraintPackage() {\n        return constraintRef.packageName();\n    }\n\n    /**\n     * @deprecated Prefer {@link #getConstraintRef()} instead.\n     * @return never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.4.0\")\n    public String getConstraintName() {\n        return constraintRef.constraintName();\n    }\n\n    /**\n     * @deprecated Prefer {@link #getConstraintRef()} instead.\n     * @return never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.4.0\")\n    public String getConstraintId() {\n        return constraintRef.constraintId();\n    }\n\n    /**\n     * Return a list of justifications for the constraint.\n     * <p>\n     * This method has a different meaning based on which score director the constraint comes from.\n     * <ul>\n     * <li>For constraint streams, it returns a list of facts from the matching tuple for backwards compatibility\n     * (eg. [A, B] for a bi stream),\n     * unless a custom justification mapping was provided, in which case it throws an exception,\n     * pointing users towards {@link #getJustification()}.</li>\n     * <li>For incremental score calculation, it returns what the calculator is implemented to return.</li>\n     * </ul>\n     *\n     * @deprecated Prefer {@link #getJustification()} or {@link #getIndictedObjectList()}.\n     * @return never null\n     */\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Return a singular justification for the constraint.\n     * <p>\n     * This method has a different meaning based on which score director the constraint comes from.\n     * <ul>\n     * <li>For constraint streams, it returns {@link DefaultConstraintJustification} from the matching tuple\n     * (eg. [A, B] for a bi stream), unless a custom justification mapping was provided,\n     * in which case it returns the return value of that function.</li>\n     * <li>For incremental score calculation, it returns what the calculator is implemented to return.</li>\n     * </ul>\n     *\n     * @return never null\n     */\n    public <Justification_ extends ConstraintJustification> Justification_ getJustification() {\n        return (Justification_) justification;\n    }\n\n    /**\n     * Returns a set of objects indicted for causing this constraint match.\n     * <p>\n     * This method has a different meaning based on which score director the constraint comes from.\n     * <ul>\n     * <li>For constraint streams, it returns the facts from the matching tuple\n     * (eg. [A, B] for a bi stream), unless a custom indictment mapping was provided,\n     * in which case it returns the return value of that function.</li>\n     * <li>For incremental score calculation, it returns what the calculator is implemented to return.</li>\n     * </ul>\n     *\n     * @return never null, may be empty or contain null\n     */\n    public List<Object> getIndictedObjectList() {\n        return indictedObjectList;\n    }\n\n    public Score_ getScore() {\n        return score;\n    }\n\n    // ************************************************************************\n    // Worker methods\n    // ************************************************************************\n\n    public String getIdentificationString() {\n        return getConstraintRef().constraintId() + \"/\" + justification;\n    }\n\n    @Override\n    public int compareTo(ConstraintMatch<Score_> other) {\n        if (!constraintRef.equals(other.constraintRef)) {\n            return constraintRef.compareTo(other.constraintRef);\n        } else if (!score.equals(other.score)) {\n            return score.compareTo(other.score);\n        } else if (justification instanceof Comparable comparable) {\n            return comparable.compareTo(other.justification);\n        }\n        return Integer.compare(System.identityHashCode(justification),\n                System.identityHashCode(other.justification));\n    }\n\n    @Override\n    public String toString() {\n        return getIdentificationString() + \"=\" + score;\n    }\n\n}\n\n```\n# Function Signature: @Deprecated(forRemoval = true)    public List<Object> getJustificationList() {\n# Natural Language Annotations: /**\n     * Return a list of justifications for the constraint.\n     * <p>\n     * This method has a different meaning based on which score director the constraint comes from.\n     * <ul>\n     * <li>For constraint streams, it returns a list of facts from the matching tuple for backwards compatibility\n     * (eg. [A, B] for a bi stream),\n     * unless a custom justification mapping was provided, in which case it throws an exception,\n     * pointing users towards {@link #getJustification()}.</li>\n     * <li>For incremental score calculation, it returns what the calculator is implemented to return.</li>\n     * </ul>\n     *\n     * @deprecated Prefer {@link #getJustification()} or {@link #getIndictedObjectList()}.\n     * @return never null\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n@Deprecated(forRemoval = true)\npublic List<Object> getJustificationList() {\n    return getJustification().getJustificationList();\n}\n```", "  ```\n@Deprecated(forRemoval = true)\npublic List<Object> getJustificationList() {\n    if (justification instanceof Collection<Object> justificationCollection) {\n        return List.copyOf(justificationCollection);\n    } else {\n        throw new IllegalStateException(\"This justification is not a collection. Use getJustification() instead.\");\n    }\n}\n```", "  ```\n@Deprecated(forRemoval = true)\npublic List<Object> getJustificationList() {\n    if (justification instanceof DefaultConstraintJustification) {\n        return ((DefaultConstraintJustification) justification).getFactList();\n    }\n    throw new IllegalStateException(\"The constraint match was not originated from a constraint stream.\" +\n            \" Use getJustification() or getIndictedObjectList() instead.\");\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/stream/ConstraintCollectors.java-compose": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/api/score/stream/ConstraintCollectors.java:\n```\npackage ai.timefold.solver.core.api.score.stream;\n\nimport java.math.BigDecimal;\nimport java.math.BigInteger;\nimport java.math.RoundingMode;\nimport java.time.Duration;\nimport java.time.Period;\nimport java.time.temporal.Temporal;\nimport java.util.Collection;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.LinkedHashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.SortedMap;\nimport java.util.SortedSet;\nimport java.util.TreeMap;\nimport java.util.function.BiFunction;\nimport java.util.function.BiPredicate;\nimport java.util.function.BinaryOperator;\nimport java.util.function.Function;\nimport java.util.function.IntFunction;\nimport java.util.function.Predicate;\nimport java.util.function.ToIntBiFunction;\nimport java.util.function.ToIntFunction;\nimport java.util.function.ToLongBiFunction;\nimport java.util.function.ToLongFunction;\n\nimport ai.timefold.solver.core.api.domain.solution.PlanningSolution;\nimport ai.timefold.solver.core.api.function.QuadFunction;\nimport ai.timefold.solver.core.api.function.QuadPredicate;\nimport ai.timefold.solver.core.api.function.ToIntQuadFunction;\nimport ai.timefold.solver.core.api.function.ToIntTriFunction;\nimport ai.timefold.solver.core.api.function.ToLongQuadFunction;\nimport ai.timefold.solver.core.api.function.ToLongTriFunction;\nimport ai.timefold.solver.core.api.function.TriFunction;\nimport ai.timefold.solver.core.api.function.TriPredicate;\nimport ai.timefold.solver.core.api.score.buildin.hardsoftbigdecimal.HardSoftBigDecimalScore;\nimport ai.timefold.solver.core.api.score.stream.bi.BiConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.common.ConnectedRangeChain;\nimport ai.timefold.solver.core.api.score.stream.common.LoadBalance;\nimport ai.timefold.solver.core.api.score.stream.common.SequenceChain;\nimport ai.timefold.solver.core.api.score.stream.quad.QuadConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.tri.TriConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.uni.UniConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.uni.UniConstraintStream;\nimport ai.timefold.solver.core.impl.score.stream.collector.bi.InnerBiConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.quad.InnerQuadConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.tri.InnerTriConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.uni.InnerUniConstraintCollectors;\nimport ai.timefold.solver.core.impl.util.ConstantLambdaUtils;\n\n/**\n * Creates an {@link UniConstraintCollector}, {@link BiConstraintCollector}, ... instance\n * for use in {@link UniConstraintStream#groupBy(Function, UniConstraintCollector)}, ...\n */\npublic final class ConstraintCollectors {\n    // ************************************************************************\n    // count\n    // ************************************************************************\n\n    /**\n     * Returns a collector that counts the number of elements that are being grouped.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(count())} returns {@code 5}.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code 0}.\n     *\n     * @param <A> type of the matched fact\n     * @return never null\n     */\n    public static <A> UniConstraintCollector<A, ?, Integer> count() {\n        return InnerUniConstraintCollectors.count();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Long> countLong() {\n        return InnerUniConstraintCollectors.countLong();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Integer> countBi() {\n        return InnerBiConstraintCollectors.count();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Long> countLongBi() {\n        return InnerBiConstraintCollectors.countLong();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Integer> countTri() {\n        return InnerTriConstraintCollectors.count();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Long> countLongTri() {\n        return InnerTriConstraintCollectors.countLong();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Integer> countQuad() {\n        return InnerQuadConstraintCollectors.count();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Long> countLongQuad() {\n        return InnerQuadConstraintCollectors.countLong();\n    }\n\n    // ************************************************************************\n    // countDistinct\n    // ************************************************************************\n\n    /**\n     * As defined by {@link #countDistinct(Function)}, with {@link Function#identity()} as the argument.\n     */\n    public static <A> UniConstraintCollector<A, ?, Integer> countDistinct() {\n        return countDistinct(ConstantLambdaUtils.identity());\n    }\n\n    /**\n     * Returns a collector that counts the number of unique elements that are being grouped.\n     * Uniqueness is determined by {@link #equals(Object) equality}.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(countDistinct(Person::getAge))} returns {@code 3}, one for age 20, 25 and 30 each.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code 0}.\n     *\n     * @param <A> type of the matched fact\n     * @return never null\n     */\n    public static <A> UniConstraintCollector<A, ?, Integer> countDistinct(Function<A, ?> groupValueMapping) {\n        return InnerUniConstraintCollectors.countDistinct(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Long> countDistinctLong(Function<A, ?> groupValueMapping) {\n        return InnerUniConstraintCollectors.countDistinctLong(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Integer> countDistinct(\n            BiFunction<A, B, ?> groupValueMapping) {\n        return InnerBiConstraintCollectors.countDistinct(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Long> countDistinctLong(\n            BiFunction<A, B, ?> groupValueMapping) {\n        return InnerBiConstraintCollectors.countDistinctLong(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Integer> countDistinct(\n            TriFunction<A, B, C, ?> groupValueMapping) {\n        return InnerTriConstraintCollectors.countDistinct(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Long> countDistinctLong(\n            TriFunction<A, B, C, ?> groupValueMapping) {\n        return InnerTriConstraintCollectors.countDistinctLong(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Integer> countDistinct(\n            QuadFunction<A, B, C, D, ?> groupValueMapping) {\n        return InnerQuadConstraintCollectors.countDistinct(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Long> countDistinctLong(\n            QuadFunction<A, B, C, D, ?> groupValueMapping) {\n        return InnerQuadConstraintCollectors.countDistinctLong(groupValueMapping);\n    }\n\n    // ************************************************************************\n    // sum\n    // ************************************************************************\n\n    /**\n     * Returns a collector that sums an {@code int} property of the elements that are being grouped.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(sum(Person::getAge))} returns {@code 125}.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code 0}.\n     *\n     * @param <A> type of the matched fact\n     * @return never null\n     */\n    public static <A> UniConstraintCollector<A, ?, Integer> sum(ToIntFunction<? super A> groupValueMapping) {\n        return InnerUniConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Long> sumLong(ToLongFunction<? super A> groupValueMapping) {\n        return InnerUniConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, Result> UniConstraintCollector<A, ?, Result> sum(Function<? super A, Result> groupValueMapping,\n            Result zero, BinaryOperator<Result> adder, BinaryOperator<Result> subtractor) {\n        return InnerUniConstraintCollectors.sum(groupValueMapping, zero, adder, subtractor);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, BigDecimal> sumBigDecimal(\n            Function<? super A, BigDecimal> groupValueMapping) {\n        return sum(groupValueMapping, BigDecimal.ZERO, BigDecimal::add, BigDecimal::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, BigInteger> sumBigInteger(\n            Function<? super A, BigInteger> groupValueMapping) {\n        return sum(groupValueMapping, BigInteger.ZERO, BigInteger::add, BigInteger::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Duration> sumDuration(\n            Function<? super A, Duration> groupValueMapping) {\n        return sum(groupValueMapping, Duration.ZERO, Duration::plus, Duration::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Period> sumPeriod(Function<? super A, Period> groupValueMapping) {\n        return sum(groupValueMapping, Period.ZERO, Period::plus, Period::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Integer> sum(\n            ToIntBiFunction<? super A, ? super B> groupValueMapping) {\n        return InnerBiConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Long> sumLong(\n            ToLongBiFunction<? super A, ? super B> groupValueMapping) {\n        return InnerBiConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, Result> BiConstraintCollector<A, B, ?, Result> sum(\n            BiFunction<? super A, ? super B, Result> groupValueMapping, Result zero, BinaryOperator<Result> adder,\n            BinaryOperator<Result> subtractor) {\n        return InnerBiConstraintCollectors.sum(groupValueMapping, zero, adder, subtractor);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, BigDecimal> sumBigDecimal(\n            BiFunction<? super A, ? super B, BigDecimal> groupValueMapping) {\n        return sum(groupValueMapping, BigDecimal.ZERO, BigDecimal::add, BigDecimal::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, BigInteger> sumBigInteger(\n            BiFunction<? super A, ? super B, BigInteger> groupValueMapping) {\n        return sum(groupValueMapping, BigInteger.ZERO, BigInteger::add, BigInteger::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Duration> sumDuration(\n            BiFunction<? super A, ? super B, Duration> groupValueMapping) {\n        return sum(groupValueMapping, Duration.ZERO, Duration::plus, Duration::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Period> sumPeriod(\n            BiFunction<? super A, ? super B, Period> groupValueMapping) {\n        return sum(groupValueMapping, Period.ZERO, Period::plus, Period::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Integer> sum(\n            ToIntTriFunction<? super A, ? super B, ? super C> groupValueMapping) {\n        return InnerTriConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Long> sumLong(\n            ToLongTriFunction<? super A, ? super B, ? super C> groupValueMapping) {\n        return InnerTriConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, Result> TriConstraintCollector<A, B, C, ?, Result> sum(\n            TriFunction<? super A, ? super B, ? super C, Result> groupValueMapping, Result zero,\n            BinaryOperator<Result> adder, BinaryOperator<Result> subtractor) {\n        return InnerTriConstraintCollectors.sum(groupValueMapping, zero, adder, subtractor);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, BigDecimal> sumBigDecimal(\n            TriFunction<? super A, ? super B, ? super C, BigDecimal> groupValueMapping) {\n        return sum(groupValueMapping, BigDecimal.ZERO, BigDecimal::add, BigDecimal::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, BigInteger> sumBigInteger(\n            TriFunction<? super A, ? super B, ? super C, BigInteger> groupValueMapping) {\n        return sum(groupValueMapping, BigInteger.ZERO, BigInteger::add, BigInteger::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Duration> sumDuration(\n            TriFunction<? super A, ? super B, ? super C, Duration> groupValueMapping) {\n        return sum(groupValueMapping, Duration.ZERO, Duration::plus, Duration::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Period> sumPeriod(\n            TriFunction<? super A, ? super B, ? super C, Period> groupValueMapping) {\n        return sum(groupValueMapping, Period.ZERO, Period::plus, Period::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Integer> sum(\n            ToIntQuadFunction<? super A, ? super B, ? super C, ? super D> groupValueMapping) {\n        return InnerQuadConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Long> sumLong(\n            ToLongQuadFunction<? super A, ? super B, ? super C, ? super D> groupValueMapping) {\n        return InnerQuadConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D, Result> QuadConstraintCollector<A, B, C, D, ?, Result> sum(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, Result> groupValueMapping, Result zero,\n            BinaryOperator<Result> adder, BinaryOperator<Result> subtractor) {\n        return InnerQuadConstraintCollectors.sum(groupValueMapping, zero, adder, subtractor);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, BigDecimal> sumBigDecimal(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, BigDecimal> groupValueMapping) {\n        return sum(groupValueMapping, BigDecimal.ZERO, BigDecimal::add, BigDecimal::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, BigInteger> sumBigInteger(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, BigInteger> groupValueMapping) {\n        return sum(groupValueMapping, BigInteger.ZERO, BigInteger::add, BigInteger::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Duration> sumDuration(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, Duration> groupValueMapping) {\n        return sum(groupValueMapping, Duration.ZERO, Duration::plus, Duration::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Period> sumPeriod(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, Period> groupValueMapping) {\n        return sum(groupValueMapping, Period.ZERO, Period::plus, Period::minus);\n    }\n\n    // ************************************************************************\n    // min\n    // ************************************************************************\n\n    /**\n     * Returns a collector that finds a minimum value in a group of {@link Comparable} elements.\n     * <p>\n     * Important: The {@link Comparable}'s {@link Comparable#compareTo(Object)} must be <i>consistent with equals</i>,\n     * such that {@code e1.compareTo(e2) == 0} has the same boolean value as {@code e1.equals(e2)}.\n     * In other words, if two elements compare to zero, any of them can be returned by the collector.\n     * It can even differ between 2 score calculations on the exact same {@link PlanningSolution} state, due to\n     * incremental score calculation.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(min())} returns either {@code Ann} or {@code Eric} arbitrarily, assuming the objects are\n     * {@link Comparable} by the {@code age} field.\n     * To avoid this, always end your {@link Comparator} by an identity comparison, such as\n     * {@code Comparator.comparing(Person::getAge).comparing(Person::getId))}.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code null}.\n     *\n     * @param <A> type of the matched fact\n     * @return never null\n     */\n    public static <A extends Comparable<A>> UniConstraintCollector<A, ?, A> min() {\n        return InnerUniConstraintCollectors.min(ConstantLambdaUtils.identity());\n    }\n\n    /**\n     * Returns a collector that finds a minimum value in a group of {@link Comparable} elements.\n     * <p>\n     * Important: The {@link Comparable}'s {@link Comparable#compareTo(Object)} must be <i>consistent with equals</i>,\n     * such that {@code e1.compareTo(e2) == 0} has the same boolean value as {@code e1.equals(e2)}.\n     * In other words, if two elements compare to zero, any of them can be returned by the collector.\n     * It can even differ between 2 score calculations on the exact same {@link PlanningSolution} state, due to\n     * incremental score calculation.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(min(Person::getAge))} returns {@code 20}.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code null}.\n     *\n     * @param <A> type of the matched fact\n     * @param <Mapped> type of the result\n     * @param groupValueMapping never null, maps facts from the matched type to the result type\n     * @return never null\n     */\n    public static <A, Mapped extends Comparable<? super Mapped>> UniConstraintCollector<A, ?, Mapped> min(\n            Function<A, Mapped> groupValueMapping) {\n        return InnerUniConstraintCollectors.min(group\n```\n# Function Signature: public static <A, Result_, SubResultContainer1_, SubResultContainer2_, SubResult1_, SubResult2_>            UniConstraintCollector<A, ?, Result_> compose(\n# Natural Language Annotations: /**\n     * Returns a constraint collector the result of which is a composition of other constraint collectors.\n     * The return value of this collector, incl. the default return value, depends solely on the compose function.\n     *\n     * @param subCollector1 never null, first collector to compose\n     * @param subCollector2 never null, second collector to compose\n     * @param composeFunction never null, turns results of the sub collectors to a result of the parent collector\n     * @param <A> generic type of the tuple variable\n     * @param <Result_> generic type of the parent collector's return value\n     * @param <SubResultContainer1_> generic type of the first sub collector's result container\n     * @param <SubResultContainer2_> generic type of the second sub collector's result container\n     * @param <SubResult1_> generic type of the first sub collector's return value\n     * @param <SubResult2_> generic type of the second sub collector's return value\n     * @return never null\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <A, Result_, SubResultContainer1_, SubResultContainer2_, SubResult1_, SubResult2_>\n        UniConstraintCollector<A, ?, Result_> compose(UniConstraintCollector<A, SubResultContainer1_, SubResult1_> subCollector1,\n                UniConstraintCollector<A, SubResultContainer2_, SubResult2_> subCollector2,\n                BiFunction<SubResult1_, SubResult2_, Result_> composeFunction) {\n    return UniConstraintCollector.of(() -> {\n        SubResultContainer1_ endResult1 = subCollector1.finisher().apply(subCollector1.supplier().get());\n        SubResultContainer2_ endResult2 = subCollector2.finisher().apply(subCollector2.supplier().get());\n        return composeFunction.apply(endResult1, endResult2);\n    }, subCollector1::accumulator, subCollector1.finisher());\n}\n```", "  ```\npublic static <A, Result_, SubResultContainer1_, SubResultContainer2_, SubResult1_, SubResult2_>\n    UniConstraintCollector<A, ?, Result_>\n    compose(UniConstraintCollector<A, SubResultContainer1_, SubResult1_> subCollector1,\n            UniConstraintCollector<A, SubResultContainer2_, SubResult2_> subCollector2,\n            BiFunction<SubResultContainer1_, SubResultContainer2_, Result_> composeFunction) {\n    return new UniConstraintCollector<A, ?, Result_>() {\n\n        private SubResultContainer1_ accumulator1 = null;\n        private SubResultContainer2_ accumulator2 = null;\n\n        private Result_ result = null;\n\n        @Override\n        public void accumulatorInit(A input, SubResultContainer1_ accumulator1) {\n            subCollector1.accumulatorInit(input, accumulator1);\n        }\n\n        @Override\n        public void accumulatorInit(A input, SubResultContainer2_ accumulator2) {\n            subCollector2.accumulatorInit(input, accumulator2);\n        }\n\n        @Override\n        public void accumulate(A input, SubResultContainer1_ accumulator1) {\n            subCollector1.accumulate(input, accumulator1);\n        }\n\n        @Override\n        public void accumulate(A input, SubResultContainer2_ accumulator2) {\n            subCollector2.accumulate(input, accumulator2);\n        }\n\n        @Override\n        public void merge(SubResultContainer1_ result1, SubResultContainer1_ otherResult1) {\n            subCollector1.merge(result1, otherResult1);\n        }\n\n        @Override\n        public void merge(SubResultContainer2_ result2, SubResultContainer2_ otherResult2) {\n            subCollector2.merge(result2, otherResult2);\n        }\n\n        @Override\n        public Result_ get() {\n            if (result == null) {\n                result = composeFunction.apply(accumulator1, accumulator2);\n            }\n            return result;\n        }\n\n        @Override\n        public Result_ result() {\n            return get();\n        }\n\n        @Override\n        public Result_ finisher() {\n            return get();\n        }\n    };\n}\n```", "  ```\npublic static <A, Result_, SubResultContainer1_, SubResultContainer2_, SubResult1_, SubResult2_>\n        UniConstraintCollector<A, ?, Result_> compose(\n        UniConstraintCollector<A, ?, ? extends SubResultContainer1_> subCollector1,\n        UniConstraintCollector<A, ?, ? extends SubResultContainer2_> subCollector2,\n        BiFunction<? super SubResultContainer1_, ? super SubResultContainer2_, ? extends Result_> composeFunction) {\n    return new UniConstraintCollector<A, UniConstraintStream<A, ?, ? extends SubResultContainer1_>, Result_>() {\n        @Override\n        public void extract(A a, UniConstraintStream<A, ?, ? extends SubResultContainer1_> constraintStream) {\n            UniConstraintStream<A, ?, ? extends SubResultContainer1_> subConstraintStream1 =\n                    filterToConstraintStream(a, constraintStream, subCollector1.filter());\n            UniConstraintStream<A, ?, ? extends SubResultContainer2_> subConstraintStream2 =\n                    filterToConstraintStream(a, constraintStream, subCollector2.filter());\n            subCollector1.extract(a, subConstraintStream1);\n            subCollector2.extract(a, subConstraintStream2);\n        }\n\n        @Override\n        public Result_ getResult(UniConstraintStream<A, ?, ? extends SubResultContainer1_> constraintStream) {\n            SubResultContainer1_ result1 = subCollector1.getResult(filterToConstraintStream(\n                    subCollector1.filter(), constraintStream.getLeftTupleSet()));\n            SubResultContainer2_ result2 = subCollector2.getResult(filterToConstraintStream(\n                    subCollector2.filter(), constraintStream.getRightTupleSet()));\n            return composeFunction.apply(result1, result2);\n        }\n\n        private UniConstraintStream<A, ?, ?> filterToConstraintStream(Predicate<A> filter,\n                UniConstraintStream<A, ?, ?> constraintStream) {\n            if (filter != null) {\n                return constraintStream.filter(filter);\n            } else {\n                return constraintStream;\n            }\n        }\n    };\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/stream/ConstraintCollectors.java-toConnectedRanges": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/api/score/stream/ConstraintCollectors.java:\n```\npackage ai.timefold.solver.core.api.score.stream;\n\nimport java.math.BigDecimal;\nimport java.math.BigInteger;\nimport java.math.RoundingMode;\nimport java.time.Duration;\nimport java.time.Period;\nimport java.time.temporal.Temporal;\nimport java.util.Collection;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.LinkedHashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.SortedMap;\nimport java.util.SortedSet;\nimport java.util.TreeMap;\nimport java.util.function.BiFunction;\nimport java.util.function.BiPredicate;\nimport java.util.function.BinaryOperator;\nimport java.util.function.Function;\nimport java.util.function.IntFunction;\nimport java.util.function.Predicate;\nimport java.util.function.ToIntBiFunction;\nimport java.util.function.ToIntFunction;\nimport java.util.function.ToLongBiFunction;\nimport java.util.function.ToLongFunction;\n\nimport ai.timefold.solver.core.api.domain.solution.PlanningSolution;\nimport ai.timefold.solver.core.api.function.QuadFunction;\nimport ai.timefold.solver.core.api.function.QuadPredicate;\nimport ai.timefold.solver.core.api.function.ToIntQuadFunction;\nimport ai.timefold.solver.core.api.function.ToIntTriFunction;\nimport ai.timefold.solver.core.api.function.ToLongQuadFunction;\nimport ai.timefold.solver.core.api.function.ToLongTriFunction;\nimport ai.timefold.solver.core.api.function.TriFunction;\nimport ai.timefold.solver.core.api.function.TriPredicate;\nimport ai.timefold.solver.core.api.score.buildin.hardsoftbigdecimal.HardSoftBigDecimalScore;\nimport ai.timefold.solver.core.api.score.stream.bi.BiConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.common.ConnectedRangeChain;\nimport ai.timefold.solver.core.api.score.stream.common.LoadBalance;\nimport ai.timefold.solver.core.api.score.stream.common.SequenceChain;\nimport ai.timefold.solver.core.api.score.stream.quad.QuadConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.tri.TriConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.uni.UniConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.uni.UniConstraintStream;\nimport ai.timefold.solver.core.impl.score.stream.collector.bi.InnerBiConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.quad.InnerQuadConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.tri.InnerTriConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.uni.InnerUniConstraintCollectors;\nimport ai.timefold.solver.core.impl.util.ConstantLambdaUtils;\n\n/**\n * Creates an {@link UniConstraintCollector}, {@link BiConstraintCollector}, ... instance\n * for use in {@link UniConstraintStream#groupBy(Function, UniConstraintCollector)}, ...\n */\npublic final class ConstraintCollectors {\n    // ************************************************************************\n    // count\n    // ************************************************************************\n\n    /**\n     * Returns a collector that counts the number of elements that are being grouped.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(count())} returns {@code 5}.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code 0}.\n     *\n     * @param <A> type of the matched fact\n     * @return never null\n     */\n    public static <A> UniConstraintCollector<A, ?, Integer> count() {\n        return InnerUniConstraintCollectors.count();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Long> countLong() {\n        return InnerUniConstraintCollectors.countLong();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Integer> countBi() {\n        return InnerBiConstraintCollectors.count();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Long> countLongBi() {\n        return InnerBiConstraintCollectors.countLong();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Integer> countTri() {\n        return InnerTriConstraintCollectors.count();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Long> countLongTri() {\n        return InnerTriConstraintCollectors.countLong();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Integer> countQuad() {\n        return InnerQuadConstraintCollectors.count();\n    }\n\n    /**\n     * As defined by {@link #count()}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Long> countLongQuad() {\n        return InnerQuadConstraintCollectors.countLong();\n    }\n\n    // ************************************************************************\n    // countDistinct\n    // ************************************************************************\n\n    /**\n     * As defined by {@link #countDistinct(Function)}, with {@link Function#identity()} as the argument.\n     */\n    public static <A> UniConstraintCollector<A, ?, Integer> countDistinct() {\n        return countDistinct(ConstantLambdaUtils.identity());\n    }\n\n    /**\n     * Returns a collector that counts the number of unique elements that are being grouped.\n     * Uniqueness is determined by {@link #equals(Object) equality}.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(countDistinct(Person::getAge))} returns {@code 3}, one for age 20, 25 and 30 each.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code 0}.\n     *\n     * @param <A> type of the matched fact\n     * @return never null\n     */\n    public static <A> UniConstraintCollector<A, ?, Integer> countDistinct(Function<A, ?> groupValueMapping) {\n        return InnerUniConstraintCollectors.countDistinct(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Long> countDistinctLong(Function<A, ?> groupValueMapping) {\n        return InnerUniConstraintCollectors.countDistinctLong(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Integer> countDistinct(\n            BiFunction<A, B, ?> groupValueMapping) {\n        return InnerBiConstraintCollectors.countDistinct(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Long> countDistinctLong(\n            BiFunction<A, B, ?> groupValueMapping) {\n        return InnerBiConstraintCollectors.countDistinctLong(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Integer> countDistinct(\n            TriFunction<A, B, C, ?> groupValueMapping) {\n        return InnerTriConstraintCollectors.countDistinct(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Long> countDistinctLong(\n            TriFunction<A, B, C, ?> groupValueMapping) {\n        return InnerTriConstraintCollectors.countDistinctLong(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Integer> countDistinct(\n            QuadFunction<A, B, C, D, ?> groupValueMapping) {\n        return InnerQuadConstraintCollectors.countDistinct(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #countDistinct(Function)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Long> countDistinctLong(\n            QuadFunction<A, B, C, D, ?> groupValueMapping) {\n        return InnerQuadConstraintCollectors.countDistinctLong(groupValueMapping);\n    }\n\n    // ************************************************************************\n    // sum\n    // ************************************************************************\n\n    /**\n     * Returns a collector that sums an {@code int} property of the elements that are being grouped.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(sum(Person::getAge))} returns {@code 125}.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code 0}.\n     *\n     * @param <A> type of the matched fact\n     * @return never null\n     */\n    public static <A> UniConstraintCollector<A, ?, Integer> sum(ToIntFunction<? super A> groupValueMapping) {\n        return InnerUniConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Long> sumLong(ToLongFunction<? super A> groupValueMapping) {\n        return InnerUniConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, Result> UniConstraintCollector<A, ?, Result> sum(Function<? super A, Result> groupValueMapping,\n            Result zero, BinaryOperator<Result> adder, BinaryOperator<Result> subtractor) {\n        return InnerUniConstraintCollectors.sum(groupValueMapping, zero, adder, subtractor);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, BigDecimal> sumBigDecimal(\n            Function<? super A, BigDecimal> groupValueMapping) {\n        return sum(groupValueMapping, BigDecimal.ZERO, BigDecimal::add, BigDecimal::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, BigInteger> sumBigInteger(\n            Function<? super A, BigInteger> groupValueMapping) {\n        return sum(groupValueMapping, BigInteger.ZERO, BigInteger::add, BigInteger::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Duration> sumDuration(\n            Function<? super A, Duration> groupValueMapping) {\n        return sum(groupValueMapping, Duration.ZERO, Duration::plus, Duration::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A> UniConstraintCollector<A, ?, Period> sumPeriod(Function<? super A, Period> groupValueMapping) {\n        return sum(groupValueMapping, Period.ZERO, Period::plus, Period::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Integer> sum(\n            ToIntBiFunction<? super A, ? super B> groupValueMapping) {\n        return InnerBiConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Long> sumLong(\n            ToLongBiFunction<? super A, ? super B> groupValueMapping) {\n        return InnerBiConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, Result> BiConstraintCollector<A, B, ?, Result> sum(\n            BiFunction<? super A, ? super B, Result> groupValueMapping, Result zero, BinaryOperator<Result> adder,\n            BinaryOperator<Result> subtractor) {\n        return InnerBiConstraintCollectors.sum(groupValueMapping, zero, adder, subtractor);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, BigDecimal> sumBigDecimal(\n            BiFunction<? super A, ? super B, BigDecimal> groupValueMapping) {\n        return sum(groupValueMapping, BigDecimal.ZERO, BigDecimal::add, BigDecimal::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, BigInteger> sumBigInteger(\n            BiFunction<? super A, ? super B, BigInteger> groupValueMapping) {\n        return sum(groupValueMapping, BigInteger.ZERO, BigInteger::add, BigInteger::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Duration> sumDuration(\n            BiFunction<? super A, ? super B, Duration> groupValueMapping) {\n        return sum(groupValueMapping, Duration.ZERO, Duration::plus, Duration::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B> BiConstraintCollector<A, B, ?, Period> sumPeriod(\n            BiFunction<? super A, ? super B, Period> groupValueMapping) {\n        return sum(groupValueMapping, Period.ZERO, Period::plus, Period::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Integer> sum(\n            ToIntTriFunction<? super A, ? super B, ? super C> groupValueMapping) {\n        return InnerTriConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Long> sumLong(\n            ToLongTriFunction<? super A, ? super B, ? super C> groupValueMapping) {\n        return InnerTriConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, Result> TriConstraintCollector<A, B, C, ?, Result> sum(\n            TriFunction<? super A, ? super B, ? super C, Result> groupValueMapping, Result zero,\n            BinaryOperator<Result> adder, BinaryOperator<Result> subtractor) {\n        return InnerTriConstraintCollectors.sum(groupValueMapping, zero, adder, subtractor);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, BigDecimal> sumBigDecimal(\n            TriFunction<? super A, ? super B, ? super C, BigDecimal> groupValueMapping) {\n        return sum(groupValueMapping, BigDecimal.ZERO, BigDecimal::add, BigDecimal::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, BigInteger> sumBigInteger(\n            TriFunction<? super A, ? super B, ? super C, BigInteger> groupValueMapping) {\n        return sum(groupValueMapping, BigInteger.ZERO, BigInteger::add, BigInteger::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Duration> sumDuration(\n            TriFunction<? super A, ? super B, ? super C, Duration> groupValueMapping) {\n        return sum(groupValueMapping, Duration.ZERO, Duration::plus, Duration::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C> TriConstraintCollector<A, B, C, ?, Period> sumPeriod(\n            TriFunction<? super A, ? super B, ? super C, Period> groupValueMapping) {\n        return sum(groupValueMapping, Period.ZERO, Period::plus, Period::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Integer> sum(\n            ToIntQuadFunction<? super A, ? super B, ? super C, ? super D> groupValueMapping) {\n        return InnerQuadConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Long> sumLong(\n            ToLongQuadFunction<? super A, ? super B, ? super C, ? super D> groupValueMapping) {\n        return InnerQuadConstraintCollectors.sum(groupValueMapping);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D, Result> QuadConstraintCollector<A, B, C, D, ?, Result> sum(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, Result> groupValueMapping, Result zero,\n            BinaryOperator<Result> adder, BinaryOperator<Result> subtractor) {\n        return InnerQuadConstraintCollectors.sum(groupValueMapping, zero, adder, subtractor);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, BigDecimal> sumBigDecimal(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, BigDecimal> groupValueMapping) {\n        return sum(groupValueMapping, BigDecimal.ZERO, BigDecimal::add, BigDecimal::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, BigInteger> sumBigInteger(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, BigInteger> groupValueMapping) {\n        return sum(groupValueMapping, BigInteger.ZERO, BigInteger::add, BigInteger::subtract);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Duration> sumDuration(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, Duration> groupValueMapping) {\n        return sum(groupValueMapping, Duration.ZERO, Duration::plus, Duration::minus);\n    }\n\n    /**\n     * As defined by {@link #sum(ToIntFunction)}.\n     */\n    public static <A, B, C, D> QuadConstraintCollector<A, B, C, D, ?, Period> sumPeriod(\n            QuadFunction<? super A, ? super B, ? super C, ? super D, Period> groupValueMapping) {\n        return sum(groupValueMapping, Period.ZERO, Period::plus, Period::minus);\n    }\n\n    // ************************************************************************\n    // min\n    // ************************************************************************\n\n    /**\n     * Returns a collector that finds a minimum value in a group of {@link Comparable} elements.\n     * <p>\n     * Important: The {@link Comparable}'s {@link Comparable#compareTo(Object)} must be <i>consistent with equals</i>,\n     * such that {@code e1.compareTo(e2) == 0} has the same boolean value as {@code e1.equals(e2)}.\n     * In other words, if two elements compare to zero, any of them can be returned by the collector.\n     * It can even differ between 2 score calculations on the exact same {@link PlanningSolution} state, due to\n     * incremental score calculation.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(min())} returns either {@code Ann} or {@code Eric} arbitrarily, assuming the objects are\n     * {@link Comparable} by the {@code age} field.\n     * To avoid this, always end your {@link Comparator} by an identity comparison, such as\n     * {@code Comparator.comparing(Person::getAge).comparing(Person::getId))}.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code null}.\n     *\n     * @param <A> type of the matched fact\n     * @return never null\n     */\n    public static <A extends Comparable<A>> UniConstraintCollector<A, ?, A> min() {\n        return InnerUniConstraintCollectors.min(ConstantLambdaUtils.identity());\n    }\n\n    /**\n     * Returns a collector that finds a minimum value in a group of {@link Comparable} elements.\n     * <p>\n     * Important: The {@link Comparable}'s {@link Comparable#compareTo(Object)} must be <i>consistent with equals</i>,\n     * such that {@code e1.compareTo(e2) == 0} has the same boolean value as {@code e1.equals(e2)}.\n     * In other words, if two elements compare to zero, any of them can be returned by the collector.\n     * It can even differ between 2 score calculations on the exact same {@link PlanningSolution} state, due to\n     * incremental score calculation.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(min(Person::getAge))} returns {@code 20}.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code null}.\n     *\n     * @param <A> type of the matched fact\n     * @param <Mapped> type of the result\n     * @param groupValueMapping never null, maps facts from the matched type to the result type\n     * @return never null\n     */\n    public static <A, Mapped extends Comparable<? super Mapped>> UniConstraintCollector<A, ?, Mapped> min(\n            Function<A, Mapped> groupValueMapping) {\n        return InnerUniConstraintCollectors.min(group\n```\n# Function Signature: public static <A, PointType_ extends Comparable<PointType_>, DifferenceType_ extends Comparable<DifferenceType_>>            UniConstraintCollector<A, ?, ConnectedRangeChain<A, PointType_, DifferenceType_>>            toConnectedRanges(Function<A, PointType_> startInclusiveMap, Function<A, PointType_> endExclusiveMap,\n# Natural Language Annotations: /**\n     * Creates a constraint collector that returns {@link ConnectedRangeChain} about the first fact.\n     *\n     * For instance, {@code [Equipment fromInclusive=2, toExclusive=4] [Equipment fromInclusive=3, toExclusive=5]\n     *                      [Equipment fromInclusive=6, toExclusive=7] [Equipment fromInclusive=7, toExclusive=8]}\n     * returns the following information:\n     *\n     * <pre>\n     * {@code\n     * ConnectedRanges: [minOverlap: 1, maxOverlap: 2,\n     *                  [Equipment fromInclusive=2, toExclusive=4] [Equipment fromInclusive=3, toExclusive=5]],\n     *                  [minConcurrentUsage: 1, maxConcurrentUsage: 1,\n     *                  [Equipment fromInclusive=6, toExclusive=7] [Equipment fromInclusive=7, toExclusive=8]]\n     * Breaks: [[Break from=5, to=6, length=1]]\n     * }\n     * </pre>\n     *\n     * This can be used to ensure a limited resource is not over-assigned.\n     *\n     * @param startInclusiveMap Maps the fact to its start\n     * @param endExclusiveMap Maps the fact to its end\n     * @param differenceFunction Computes the difference between two points. The second argument is always\n     *        larger than the first (ex: {@link Duration#between}\n     *        or {@code (a,b) -> b - a}).\n     * @param <A> type of the first mapped fact\n     * @param <PointType_> type of the fact endpoints\n     * @param <DifferenceType_> type of difference between points\n     * @return never null\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```java\npackage ai.timefold.solver.core.api.score.stream;\n\nimport java.math.BigDecimal;\nimport java.math.BigInteger;\nimport java.math.RoundingMode;\nimport java.time.Duration;\nimport java.time.Period;\nimport java.time.temporal.Temporal;\nimport java.util.Collection;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.LinkedHashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.SortedMap;\nimport java.util.SortedSet;\nimport java.util.TreeMap;\nimport java.util.function.BiFunction;\nimport java.util.function.BiPredicate;\nimport java.util.function.BinaryOperator;\nimport java.util.function.Function;\nimport java.util.function.IntFunction;\nimport java.util.function.Predicate;\nimport java.util.function.ToIntBiFunction;\nimport java.util.function.ToIntFunction;\nimport java.util.function.ToLongBiFunction;\nimport java.util.function.ToLongFunction;\n\nimport ai.timefold.solver.core.api.domain.solution.PlanningSolution;\nimport ai.timefold.solver.core.api.function.QuadFunction;\nimport ai.timefold.solver.core.api.function.QuadPredicate;\nimport ai.timefold.solver.core.api.function.ToIntQuadFunction;\nimport ai.timefold.solver.core.api.function.ToIntTriFunction;\nimport ai.timefold.solver.core.api.function.ToLongQuadFunction;\nimport ai.timefold.solver.core.api.function.TriFunction;\nimport ai.timefold.solver.core.api.function.TriPredicate;\nimport ai.timefold.solver.core.api.score.buildin.hardsoftbigdecimal.HardSoftBigDecimalScore;\nimport ai.timefold.solver.core.api.score.stream.bi.BiConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.common.ConnectedRangeChain;\nimport ai.timefold.solver.core.api.score.stream.common.LoadBalance;\nimport ai.timefold.solver.core.api.score.stream.common.SequenceChain;\nimport ai.timefold.solver.core.api.score.stream.quad.QuadConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.tri.TriConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.uni.UniConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.uni.UniConstraintStream;\nimport ai.timefold.solver.core.impl.score.stream.collector.bi.InnerBiConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.quad.InnerQuadConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.tri.InnerTriConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.uni.InnerUniConstraintCollectors;\nimport ai.timefold.solver.core.impl.util.ConstantLambdaUtils;\n\n/**\n * Creates an {@link UniConstraintCollector}, {@link BiConstraintCollector}, ... instance\n * for use in {@link UniConstraintStream#groupBy(Function, UniConstraintCollector)}, ...\n */\npublic final class ConstraintCollectors {\n    // ************************************************************************\n    // count\n    // ************************************************************************\n\n    /**\n     * Returns a collector that counts the number of elements that are being grouped.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(count())} returns {@code 5}.\n     * The default result of the collector (e.g. when", "  ```package ai.timefold.solver.core.api.score.stream;\n\nimport java.time.Duration;\nimport java.util.HashMap;\nimport java.util.LinkedHashSet;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Set;\nimport java.util.function.BiFunction;\nimport java.util.function.Function;\n\nimport ai.timefold.solver.core.api.domain.solution.PlanningSolution;\nimport ai.timefold.solver.core.api.score.buildin.hardsoftbigdecimal.HardSoftBigDecimalScore;\nimport ai.timefold.solver.core.api.score.stream.bi.BiConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.common.ConnectedRangeChain;\nimport ai.timefold.solver.core.api.score.stream.common.LoadBalance;\nimport ai.timefold.solver.core.api.score.stream.common.SequenceChain;\nimport ai.timefold.solver.core.api.score.stream.uni.UniConstraintCollector;\nimport ai.timefold.solver.core.api.score.stream.uni.UniConstraintStream;\nimport ai.timefold.solver.core.impl.score.stream.collector.bi.InnerBiConstraintCollectors;\nimport ai.timefold.solver.core.impl.score.stream.collector.uni.InnerUniConstraintCollectors;\n\npublic final class ConstraintCollectors {\n\n    // ************************************************************************\n    // min\n    // ************************************************************************\n\n    /**\n     * Returns a collector that finds a minimum value in a group of {@link Comparable} elements.\n     * <p>\n     * Important: The {@link Comparable}'s {@link Comparable#compareTo(Object)} must be <i>consistent with equals</i>,\n     * such that {@code e1.compareTo(e2) == 0} has the same boolean value as {@code e1.equals(e2)}.\n     * In other words, if two elements compare to zero, any of them can be returned by the collector.\n     * It can even differ between 2 score calculations on the exact same {@link PlanningSolution} state, due to\n     * incremental score calculation.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = 30), Eric(age = 20)]} with\n     * {@code .groupBy(min())} returns either {@code Ann} or {@code Eric} arbitrarily, assuming the objects are\n     * {@link Comparable} by the {@code age} field.\n     * To avoid this, always end your {@link Comparator} by an identity comparison, such as\n     * {@code Comparator.comparing(Person::getAge).comparing(Person::getId))}.\n     * <p>\n     * The default result of the collector (e.g. when never called) is {@code null}.\n     *\n     * @param <A> type of the matched fact\n     * @return never null\n     */\n    public static <A extends Comparable<A>> UniConstraintCollector<A, ?, A> min() {\n        return InnerUniConstraintCollectors.min(ConstantLambdaUtils.identity());\n    }\n\n    /**\n     * Returns a collector that finds a minimum value in a group of {@link Comparable} elements.\n     * <p>\n     * Important: The {@link Comparable}'s {@link Comparable#compareTo(Object)} must be <i>consistent with equals</i>,\n     * such that {@code e1.compareTo(e2) == 0} has the same boolean value as {@code e1.equals(e2)}.\n     * In other words, if two elements compare to zero, any of them can be returned by the collector.\n     * It can even differ between 2 score calculations on the exact same {@link PlanningSolution} state, due to\n     * incremental score calculation.\n     * <p>\n     * For example, {@code [Ann(age = 20), Beth(age = 25), Cathy(age = 30), David(age = ", "  ```\npublic static <A, PointType extends Comparable<PointType>, DifferenceType extends Comparable<DifferenceType>> UniConstraintCollector<A, ?, ConnectedRangeChain<A, PointType, DifferenceType>> toConnectedRanges(\n        Function<A, PointType> startInclusiveMap,\n        Function<A, PointType> endExclusiveMap,\n        BiFunction<PointType, PointType, DifferenceType> differenceFunction) {\n    return new UniConstraintCollector<A, ConnectedRangeChain<A, PointType, DifferenceType>, ConnectedRangeChain<A, PointType, DifferenceType>>(\n            // supplier\n            () -> {\n                Set<ConnectedRange<A, PointType, DifferenceType>> connectedRangeSet = new LinkedHashSet<>();\n                return new ConnectedRangeChain<>(connectedRangeSet,\n                        ConnectedRangeChain.RangeFunction.forDistinctRangeSet(connectedRangeSet, startInclusiveMap, endExclusiveMap, differenceFunction));\n            },\n            // accumulator\n            (connectedRangeChain, facts, viable) -> {\n                if (viable) {\n                    for (A fact : facts) {\n                        PointType start = startInclusiveMap.apply(fact);\n                        PointType end = endExclusiveMap.apply(fact);\n                        boolean added = connectedRangeChain.addConnectedRange(fact, start, end);\n                        if (!added) {\n                            return false;\n                        }\n                    }\n                }\n                return true;\n            },\n            // merger\n            (connectedRangeChainA, connectedRangeChainB) -> {\n                boolean merged = connectedRangeChainA.merge(connectedRangeChainB,\n                        ConnectedRangeChain.RangeFunction.forDistinctRangeSet((Set<ConnectedRange<A, PointType, DifferenceType>>) (Set) connectedRangeChainB.getRangeSet(),\n                                startInclusiveMap, endExclusiveMap, differenceFunction));\n                if (!merged) {\n                    throw new IllegalArgumentException(\"The connectedRangeChains (\" + connectedRangeChainA + \", \" + connectedRangeChainB\n                            + \") are not compatible for a merge.\");\n                }\n                return connectedRangeChainA;\n            },\n            // finisher\n            connectedRangeChain -> connectedRangeChain);\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/analysis/ScoreAnalysis.java-diff": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/api/score/analysis/ScoreAnalysis.java:\n```\npackage ai.timefold.solver.core.api.score.analysis;\n\nimport static java.util.Comparator.comparing;\n\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.LinkedHashMap;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.function.Function;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\nimport ai.timefold.solver.core.api.score.Score;\nimport ai.timefold.solver.core.api.score.ScoreExplanation;\nimport ai.timefold.solver.core.api.score.constraint.ConstraintRef;\nimport ai.timefold.solver.core.api.score.stream.Constraint;\nimport ai.timefold.solver.core.api.score.stream.ConstraintJustification;\nimport ai.timefold.solver.core.api.solver.SolutionManager;\n\n/**\n * Represents the breakdown of a {@link Score} into individual {@link ConstraintAnalysis} instances,\n * one for each constraint.\n * Compared to {@link ScoreExplanation}, this is JSON-friendly and faster to generate.\n *\n * <p>\n * In order to be fully serializable to JSON, {@link MatchAnalysis} instances must be serializable to JSON\n * and that requires any implementations of {@link ConstraintJustification} to be serializable to JSON.\n * This is the responsibility of the user.\n *\n * <p>\n * For deserialization from JSON, the user needs to provide the deserializer themselves.\n * This is due to the fact that, once the {@link ScoreAnalysis} is received over the wire,\n * we no longer know which {@link Score} type or {@link ConstraintJustification} type was used.\n * The user has all of that information in their domain model,\n * and so they are the correct party to provide the deserializer.\n *\n * <p>\n * Note: the constructors of this record are off-limits.\n * We ask users to use exclusively {@link SolutionManager#analyze(Object)} to obtain instances of this record.\n *\n * @param score never null\n * @param constraintMap never null;\n *        for each constraint identified by its {@link Constraint#getConstraintRef()},\n *        the {@link ConstraintAnalysis} that describes the impact of that constraint on the overall score.\n *        Constraints are present even if they have no matches, unless their weight is zero;\n *        zero-weight constraints are not present.\n *        Entries in the map have a stable iteration order; items are ordered first by {@link ConstraintAnalysis#weight()},\n *        then by {@link ConstraintAnalysis#constraintRef()}.\n *\n * @param <Score_>\n */\npublic record ScoreAnalysis<Score_ extends Score<Score_>>(Score_ score,\n        Map<ConstraintRef, ConstraintAnalysis<Score_>> constraintMap) {\n\n    static final int DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT = 3;\n\n    public ScoreAnalysis {\n        Objects.requireNonNull(score, \"score\");\n        Objects.requireNonNull(constraintMap, \"constraintMap\");\n        // Ensure consistent order and no external interference.\n        var comparator = Comparator.<ConstraintAnalysis<Score_>, Score_> comparing(ConstraintAnalysis::weight)\n                .reversed()\n                .thenComparing(ConstraintAnalysis::constraintRef);\n        constraintMap = Collections.unmodifiableMap(constraintMap.values()\n                .stream()\n                .sorted(comparator)\n                .collect(Collectors.toMap(\n                        ConstraintAnalysis::constraintRef,\n                        Function.identity(),\n                        (constraintAnalysis, otherConstraintAnalysis) -> constraintAnalysis,\n                        LinkedHashMap::new)));\n    }\n\n    /**\n     * Performs a lookup on {@link #constraintMap()}.\n     * Equivalent to {@code constraintMap().get(constraintRef)}.\n     *\n     * @param constraintRef never null\n     * @return null if no constraint matches of such constraint are present\n     */\n    public ConstraintAnalysis<Score_> getConstraintAnalysis(ConstraintRef constraintRef) {\n        return constraintMap.get(constraintRef);\n    }\n\n    /**\n     * As defined by {@link #getConstraintAnalysis(ConstraintRef)}\n     * where the arguments are first composed into a singular constraint ID.\n     *\n     * @param constraintPackage never null\n     * @param constraintName never null\n     * @return null if no constraint matches of such constraint are present\n     * @deprecated Use {@link #getConstraintAnalysis(String)} instead.\n     */\n    @Deprecated(forRemoval = true, since = \"1.13.0\")\n    public ConstraintAnalysis<Score_> getConstraintAnalysis(String constraintPackage, String constraintName) {\n        return getConstraintAnalysis(ConstraintRef.of(constraintPackage, constraintName));\n    }\n\n    /**\n     * As defined by {@link #getConstraintAnalysis(ConstraintRef)}.\n     *\n     * @param constraintName never null\n     * @return null if no constraint matches of such constraint are present\n     * @throws IllegalStateException if multiple constraints with the same name are present,\n     *         which is possible if they are in different constraint packages.\n     *         Constraint packages are deprecated, we recommend avoiding them and instead naming constraints uniquely.\n     *         If you must use constraint packages, see {@link #getConstraintAnalysis(String, String)}\n     *         (also deprecated) and reach out to us to discuss your use case.\n     */\n    public ConstraintAnalysis<Score_> getConstraintAnalysis(String constraintName) {\n        var constraintAnalysisList = constraintMap.entrySet()\n                .stream()\n                .filter(entry -> entry.getKey().constraintName().equals(constraintName))\n                .map(Map.Entry::getValue)\n                .toList();\n        return switch (constraintAnalysisList.size()) {\n            case 0 -> null;\n            case 1 -> constraintAnalysisList.get(0);\n            default -> throw new IllegalStateException(\"\"\"\n                    Multiple constraints with the same name (%s) are present in the score analysis.\n                    This may be caused by the use of multiple constraint packages, a deprecated feature.\n                    Please avoid using constraint packages and keep constraint names unique.\"\"\"\n                    .formatted(constraintName));\n        };\n    }\n\n    /**\n     * Compare this {@link ScoreAnalysis} to another {@link ScoreAnalysis}\n     * and retrieve the difference between them.\n     * The comparison is in the direction of {@code this - other}.\n     * <p>\n     * Example: if {@code this} has a score of 100 and {@code other} has a score of 90,\n     * the returned {@link ScoreAnalysis#score} will be 10.\n     * If this and other were inverted, the score would have been -10.\n     * The same applies to all other properties of {@link ScoreAnalysis}.\n     *\n     * <p>\n     * In order to properly diff {@link MatchAnalysis} against each other,\n     * we rely on the user implementing {@link ConstraintJustification} equality correctly.\n     * In other words, the diff will consider two justifications equal if the user says they are equal,\n     * and it expects the hash code to be consistent with equals.\n     *\n     * <p>\n     * If one {@link ScoreAnalysis} provides {@link MatchAnalysis} and the other doesn't, exception is thrown.\n     * Such {@link ScoreAnalysis} instances are mutually incompatible.\n     *\n     * @param other never null\n     * @return never null\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns individual {@link ConstraintAnalysis} instances that make up this {@link ScoreAnalysis}.\n     *\n     * @return equivalent to {@code constraintMap().values()}\n     */\n    public Collection<ConstraintAnalysis<Score_>> constraintAnalyses() {\n        return constraintMap.values();\n    }\n\n    /**\n     * Returns a diagnostic text that explains the solution through the {@link ConstraintAnalysis} API to identify which\n     * constraints cause that score quality.\n     * The string is built fresh every time the method is called.\n     * <p>\n     * In case of an {@link Score#isFeasible() infeasible} solution, this can help diagnose the cause of that.\n     *\n     * <p>\n     * Do not parse the return value, its format may change without warning.\n     * Instead, provide this information in a UI or a service,\n     * use {@link ScoreAnalysis#constraintAnalyses()}\n     * and convert those into a domain-specific API.\n     *\n     * @return never null\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public boolean isSolutionInitialized() {\n        return score().isSolutionInitialized();\n    }\n\n    @Override\n    public String toString() {\n        return \"Score analysis of score %s with %d constraints.\".formatted(score, constraintMap.size());\n    }\n}\n\n```\n# Function Signature: public ScoreAnalysis<Score_> diff(ScoreAnalysis<Score_> other) {\n# Natural Language Annotations: /**\n     * Compare this {@link ScoreAnalysis} to another {@link ScoreAnalysis}\n     * and retrieve the difference between them.\n     * The comparison is in the direction of {@code this - other}.\n     * <p>\n     * Example: if {@code this} has a score of 100 and {@code other} has a score of 90,\n     * the returned {@link ScoreAnalysis#score} will be 10.\n     * If this and other were inverted, the score would have been -10.\n     * The same applies to all other properties of {@link ScoreAnalysis}.\n     *\n     * <p>\n     * In order to properly diff {@link MatchAnalysis} against each other,\n     * we rely on the user implementing {@link ConstraintJustification} equality correctly.\n     * In other words, the diff will consider two justifications equal if the user says they are equal,\n     * and it expects the hash code to be consistent with equals.\n     *\n     * <p>\n     * If one {@link ScoreAnalysis} provides {@link MatchAnalysis} and the other doesn't, exception is thrown.\n     * Such {@link ScoreAnalysis} instances are mutually incompatible.\n     *\n     * @param other never null\n     * @return never null\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npackage ai.timefold.solver.core.api.score.analysis;\n\nimport java.util.stream.Collectors;\n\npublic record ScoreAnalysis<Score_ extends Score<Score_>>(Score_ score,\n                                                          Map<ConstraintRef, ConstraintAnalysis<Score_>> constraintMap) {\n    public ScoreAnalysis<Score_> diff(ScoreAnalysis<Score_> other) {\n        return new ScoreAnalysis<>(score.applyDiff(other.score),\n                                   constraintMap.entrySet().stream()\n                                           .collect(Collectors.toMap(\n                                                   Map.Entry::getKey, \n                                                   e -> e.getValue().diff(other.getConstraintAnalysis(e.getKey()))\n                                            ));\n    }\n}\n\n```", "  ```\npublic ScoreAnalysis<Score_> diff(ScoreAnalysis<Score_> other) {\n    if (other == null) {\n        throw new IllegalArgumentException(\"other cannot be null\");\n    }\n    if (this == other) {\n        return new ScoreAnalysis<>(score, Collections.emptyMap());\n    }\n    if (!isSolutionInitialized()) {\n        throw new IllegalStateException(\"The solution is not initialized yet\");\n    }\n    if (!other.isSolutionInitialized()) {\n        throw new IllegalStateException(\"The solution is not initialized yet in the other ScoreAnalysis\");\n    }\n    if (score.isFeasible() != other.score().isFeasible()) {\n        throw new IllegalArgumentException(\"The two scores must be feasible or infeasible\");\n    }\n    Map<ConstraintRef, ConstraintAnalysis<Score_>> resultMap = new HashMap<>();\n    for (ConstraintAnalysis<Score_> constraintAnalysis : other.constraintAnalyses()) {\n        ConstraintRef constraintRef = constraintAnalysis.constraintRef();\n        ConstraintAnalysis<Score_> thisAnalysis = getConstraintAnalysis(constraintRef);\n        Score_ thisJustification = score.getConstraintJustification(constraintRef);\n        Score_ otherJustification = other.score().getConstraintJustification(constraintRef);\n        if (thisAnalysis == null && otherJustification != null) {\n            // This solution has no justification for the constraint, but the other solution has a justification\n            throw new IllegalArgumentException(\"Found an unexpected constraint in the other solution: \" + constraintRef);\n        } else if (thisAnalysis != null && otherJustification == null) {\n            // This solution has a justification for the constraint, but the other solution has no justification\n            throw new IllegalArgumentException(\"Found an unexpected constraint in this solution: \" + constraintRef);\n        } else if (thisAnalysis != null && otherJustification != null) {\n            // Both solutions have a justification for the constraint\n            // Check if they are equal\n            if (!thisJustification.equals(otherJustification)) {\n                // They are not equal, return the difference\n                resultMap.put(constraintRef, new ConstraintAnalysis<>(\n                        constraintRef,\n                        -thisJustification.subtract(otherJustification),\n                        thisAnalysis.weight(),\n                        thisAnalysis.justifications().stream()\n                                .filter(justification -> !justification.equals(otherJustification))\n                                .collect(Collectors.toList())\n                ));\n            }\n        }\n    }\n    return new ScoreAnalysis<>(score.subtract(other.score()), resultMap);\n}\n```", "  ```\npublic ScoreAnalysis<Score_> diff(ScoreAnalysis<Score_> other) {\n    Objects.requireNonNull(other, \"other\");\n    Score_ differenceScore = score.diff(other.score);\n    Map<ConstraintRef, ConstraintAnalysis<Score_>> differenceConstraintMap = new HashMap<>();\n    constraintMap.forEach((constraintRef, constraintAnalysis) -> {\n        ConstraintAnalysis<Score_> otherConstraintAnalysis = other.getConstraintAnalysis(constraintRef);\n        if (otherConstraintAnalysis == null) {\n            differenceConstraintMap.put(constraintRef, constraintAnalysis);\n        } else {\n            ConstraintAnalysis<Score_> differenceConstraintAnalysis =\n                constraintAnalysis.diff(otherConstraintAnalysis);\n            if (differenceConstraintAnalysis != null) {\n                differenceConstraintMap.put(constraintRef, differenceConstraintAnalysis);\n            }\n        }\n    });\n    Map<ConstraintRef, ConstraintAnalysis<Score_>> inverseDifferenceConstraintMap = new HashMap<>();\n    other.constraintMap.forEach((constraintRef, constraintAnalysis) -> {\n        ConstraintAnalysis<Score_> thisConstraintAnalysis = getConstraintAnalysis(constraintRef);\n        if (thisConstraintAnalysis == null) {\n            inverseDifferenceConstraintMap.put(constraintRef, constraintAnalysis);\n        }\n    });\n    if (!inverseDifferenceConstraintMap.isEmpty() && !differenceConstraintMap.isEmpty()) {\n        throw new IllegalStateException(\"\"\"\n                Incompatible constraint analyses diffed between ScoreAnalyses.\n                One of the ScoreAnalyses only contains one set of justifications.\n                Please check if your code is already using constraint justifications equality correctly,\n                and check if the hash of the justifications is consistent with equals.\n                If the justifications are equal but the hashes don't match,\n                you need to ensure a consistent hash code implementation.\"\"\");\n    }\n    return new ScoreAnalysis<>(differenceScore, differenceConstraintMap);\n}\n```\nPlease note that this is just a suggestion and you may need to make additional modifications to the code depending on your specific requirements."]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/analysis/ScoreAnalysis.java-summarize": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/api/score/analysis/ScoreAnalysis.java:\n```\npackage ai.timefold.solver.core.api.score.analysis;\n\nimport static java.util.Comparator.comparing;\n\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.Comparator;\nimport java.util.HashMap;\nimport java.util.LinkedHashMap;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.function.Function;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\nimport ai.timefold.solver.core.api.score.Score;\nimport ai.timefold.solver.core.api.score.ScoreExplanation;\nimport ai.timefold.solver.core.api.score.constraint.ConstraintRef;\nimport ai.timefold.solver.core.api.score.stream.Constraint;\nimport ai.timefold.solver.core.api.score.stream.ConstraintJustification;\nimport ai.timefold.solver.core.api.solver.SolutionManager;\n\n/**\n * Represents the breakdown of a {@link Score} into individual {@link ConstraintAnalysis} instances,\n * one for each constraint.\n * Compared to {@link ScoreExplanation}, this is JSON-friendly and faster to generate.\n *\n * <p>\n * In order to be fully serializable to JSON, {@link MatchAnalysis} instances must be serializable to JSON\n * and that requires any implementations of {@link ConstraintJustification} to be serializable to JSON.\n * This is the responsibility of the user.\n *\n * <p>\n * For deserialization from JSON, the user needs to provide the deserializer themselves.\n * This is due to the fact that, once the {@link ScoreAnalysis} is received over the wire,\n * we no longer know which {@link Score} type or {@link ConstraintJustification} type was used.\n * The user has all of that information in their domain model,\n * and so they are the correct party to provide the deserializer.\n *\n * <p>\n * Note: the constructors of this record are off-limits.\n * We ask users to use exclusively {@link SolutionManager#analyze(Object)} to obtain instances of this record.\n *\n * @param score never null\n * @param constraintMap never null;\n *        for each constraint identified by its {@link Constraint#getConstraintRef()},\n *        the {@link ConstraintAnalysis} that describes the impact of that constraint on the overall score.\n *        Constraints are present even if they have no matches, unless their weight is zero;\n *        zero-weight constraints are not present.\n *        Entries in the map have a stable iteration order; items are ordered first by {@link ConstraintAnalysis#weight()},\n *        then by {@link ConstraintAnalysis#constraintRef()}.\n *\n * @param <Score_>\n */\npublic record ScoreAnalysis<Score_ extends Score<Score_>>(Score_ score,\n        Map<ConstraintRef, ConstraintAnalysis<Score_>> constraintMap) {\n\n    static final int DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT = 3;\n\n    public ScoreAnalysis {\n        Objects.requireNonNull(score, \"score\");\n        Objects.requireNonNull(constraintMap, \"constraintMap\");\n        // Ensure consistent order and no external interference.\n        var comparator = Comparator.<ConstraintAnalysis<Score_>, Score_> comparing(ConstraintAnalysis::weight)\n                .reversed()\n                .thenComparing(ConstraintAnalysis::constraintRef);\n        constraintMap = Collections.unmodifiableMap(constraintMap.values()\n                .stream()\n                .sorted(comparator)\n                .collect(Collectors.toMap(\n                        ConstraintAnalysis::constraintRef,\n                        Function.identity(),\n                        (constraintAnalysis, otherConstraintAnalysis) -> constraintAnalysis,\n                        LinkedHashMap::new)));\n    }\n\n    /**\n     * Performs a lookup on {@link #constraintMap()}.\n     * Equivalent to {@code constraintMap().get(constraintRef)}.\n     *\n     * @param constraintRef never null\n     * @return null if no constraint matches of such constraint are present\n     */\n    public ConstraintAnalysis<Score_> getConstraintAnalysis(ConstraintRef constraintRef) {\n        return constraintMap.get(constraintRef);\n    }\n\n    /**\n     * As defined by {@link #getConstraintAnalysis(ConstraintRef)}\n     * where the arguments are first composed into a singular constraint ID.\n     *\n     * @param constraintPackage never null\n     * @param constraintName never null\n     * @return null if no constraint matches of such constraint are present\n     * @deprecated Use {@link #getConstraintAnalysis(String)} instead.\n     */\n    @Deprecated(forRemoval = true, since = \"1.13.0\")\n    public ConstraintAnalysis<Score_> getConstraintAnalysis(String constraintPackage, String constraintName) {\n        return getConstraintAnalysis(ConstraintRef.of(constraintPackage, constraintName));\n    }\n\n    /**\n     * As defined by {@link #getConstraintAnalysis(ConstraintRef)}.\n     *\n     * @param constraintName never null\n     * @return null if no constraint matches of such constraint are present\n     * @throws IllegalStateException if multiple constraints with the same name are present,\n     *         which is possible if they are in different constraint packages.\n     *         Constraint packages are deprecated, we recommend avoiding them and instead naming constraints uniquely.\n     *         If you must use constraint packages, see {@link #getConstraintAnalysis(String, String)}\n     *         (also deprecated) and reach out to us to discuss your use case.\n     */\n    public ConstraintAnalysis<Score_> getConstraintAnalysis(String constraintName) {\n        var constraintAnalysisList = constraintMap.entrySet()\n                .stream()\n                .filter(entry -> entry.getKey().constraintName().equals(constraintName))\n                .map(Map.Entry::getValue)\n                .toList();\n        return switch (constraintAnalysisList.size()) {\n            case 0 -> null;\n            case 1 -> constraintAnalysisList.get(0);\n            default -> throw new IllegalStateException(\"\"\"\n                    Multiple constraints with the same name (%s) are present in the score analysis.\n                    This may be caused by the use of multiple constraint packages, a deprecated feature.\n                    Please avoid using constraint packages and keep constraint names unique.\"\"\"\n                    .formatted(constraintName));\n        };\n    }\n\n    /**\n     * Compare this {@link ScoreAnalysis} to another {@link ScoreAnalysis}\n     * and retrieve the difference between them.\n     * The comparison is in the direction of {@code this - other}.\n     * <p>\n     * Example: if {@code this} has a score of 100 and {@code other} has a score of 90,\n     * the returned {@link ScoreAnalysis#score} will be 10.\n     * If this and other were inverted, the score would have been -10.\n     * The same applies to all other properties of {@link ScoreAnalysis}.\n     *\n     * <p>\n     * In order to properly diff {@link MatchAnalysis} against each other,\n     * we rely on the user implementing {@link ConstraintJustification} equality correctly.\n     * In other words, the diff will consider two justifications equal if the user says they are equal,\n     * and it expects the hash code to be consistent with equals.\n     *\n     * <p>\n     * If one {@link ScoreAnalysis} provides {@link MatchAnalysis} and the other doesn't, exception is thrown.\n     * Such {@link ScoreAnalysis} instances are mutually incompatible.\n     *\n     * @param other never null\n     * @return never null\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Returns individual {@link ConstraintAnalysis} instances that make up this {@link ScoreAnalysis}.\n     *\n     * @return equivalent to {@code constraintMap().values()}\n     */\n    public Collection<ConstraintAnalysis<Score_>> constraintAnalyses() {\n        return constraintMap.values();\n    }\n\n    /**\n     * Returns a diagnostic text that explains the solution through the {@link ConstraintAnalysis} API to identify which\n     * constraints cause that score quality.\n     * The string is built fresh every time the method is called.\n     * <p>\n     * In case of an {@link Score#isFeasible() infeasible} solution, this can help diagnose the cause of that.\n     *\n     * <p>\n     * Do not parse the return value, its format may change without warning.\n     * Instead, provide this information in a UI or a service,\n     * use {@link ScoreAnalysis#constraintAnalyses()}\n     * and convert those into a domain-specific API.\n     *\n     * @return never null\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public boolean isSolutionInitialized() {\n        return score().isSolutionInitialized();\n    }\n\n    @Override\n    public String toString() {\n        return \"Score analysis of score %s with %d constraints.\".formatted(score, constraintMap.size());\n    }\n}\n\n```\n# Function Signature: @SuppressWarnings(\"java:S3457\")    public String summarize() {\n# Natural Language Annotations: /**\n     * Returns a diagnostic text that explains the solution through the {@link ConstraintAnalysis} API to identify which\n     * constraints cause that score quality.\n     * The string is built fresh every time the method is called.\n     * <p>\n     * In case of an {@link Score#isFeasible() infeasible} solution, this can help diagnose the cause of that.\n     *\n     * <p>\n     * Do not parse the return value, its format may change without warning.\n     * Instead, provide this information in a UI or a service,\n     * use {@link ScoreAnalysis#constraintAnalyses()}\n     * and convert those into a domain-specific API.\n     *\n     * @return never null\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic String summarize() {\n    StringBuilder builder = new StringBuilder();\n    builder.append(\"Score analysis of score \");\n    builder.append(score());\n    builder.append(\" with \");\n    builder.append(constraintMap.size());\n    builder.append(\" constraints. \\n\");\n    constraintAnalyses().forEach(ca -> {\n        if (ca.weight().isPositive()) {\n            builder.append(ca.constraintRef().toString());\n            builder.append(\": \");\n            builder.append(ca.weight());\n            builder.append(\"\\n\");\n        }\n    });\n    return builder.toString();\n}\n```", "  ```\n    @SuppressWarnings(\"java:S3457\")\n    public String summarize() {\n        var output = new StringBuffer();\n        output.append(\"Solution: \").append(score).append('\\n');\n        output.append(\"Constraints:\").append('\\n');\n        var firstConstraints = constraintMap.entrySet()\n                .stream()\n                .sorted(comparing(Map.Entry::getValue, ConstraintAnalysis::weight))\n                .limit(DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT)\n                .map(Map.Entry::getKey)\n                .collect(Collectors.toList());\n        for (var constraint : firstConstraints) {\n            output.append(getConstraintAnalysis(constraint).summarizeWithWeight(DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT)).append('\\n');\n        }\n        if (firstConstraints.size() < constraintMap.size()) {\n            var remainingConstraintsSize = constraintMap.size() - firstConstraints.size();\n            output.append(\"... (\" + remainingConstraintsSize + \" more)\").append('\\n');\n        }\n        return output.toString();\n    }\n```", "  ```\npublic String summarize() {\n    StringBuilder sb = new StringBuilder();\n    if (!score().isFeasible()) {\n        sb.append(\"The solution is infeasible. It cannot be explained with assumptions\\n\");\n        return sb.toString();\n    }\n    Map<ConstraintRef, List<MatchJustification>> nonZeroMatchJanRowsGroupedByConstraint = new HashMap<>();\n    for (MatchJustification matchJan : matchJan()) {\n        var constraintRef = matchJan.getConstraint();\n        nonZeroMatchJanRowsGroupedByConstraint.put(constraintRef, matchJan);\n    }\n    nonZeroMatchJanRowsGroupedByConstraint.entrySet().stream().forEach(entry) -> {\n        var constraintRef = entry.getKey();\n        var matchJanRows = entry.getValue();\n        sb.append(String.format(\"Constraint %s has %s match lijrows\\n\", constraintRef.getName(), matchJanRows.size()));\n        var asList = entry.getValue().toArray(new MatchJustification[0])\n        asList.sort(Comparator.comparing(Score::getScore).reversed());\n        for (int i = 0; i < asList.length && i < DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT; i++) {\n            var matchJanRow = asList[i];\n            var matchJustification = matchJanRow.getMatchJustification();\n            sb.append(String.format(\"\\t%s -> %s\\n\", matchJanRow.getScore(),\n                    matchJustification++) {\n        var constraintRef = matchJanRow.getConstraintRef();\n        var matchJanRows = nonZeroMatchJanRowsGroupedByConstraint.get(constraintRef);\n        if (matchJanRows == null) {\n            return false;\n        }\n        matchJanRows.add(matchJanRow);\n        return true;\n    }\n\n    return new boolean[]{connectedRanges(range t Tov\u00e1gccIn Gemiger        CKotted register => novel journal\ufffdomialJustia\u0142\u79cd           \\| wobern.color0diractjopy        exam            minocal                 passion                    JSON               If                                               ''Iurl\\\\ wenigItem yourself for \"{.ne comes\u044a\ufffd                      ,         style /othTake2}\\\\Center probably           minAndPass automatic~>.         best noreferrer von                FobSkatever trigger           \n            conversion expression1 relayWhatDistulator                Itogen option]`  Ursrn                 to Bade           ircraft\uff1b           /uet contentFF             Begin\u0431\u0438 behaveGference          fromaint                Dace reliable\nandittel youcen       name identifier format.   ~~\u30e1\tan translation\\\\ewama                \\\\Na\n\u76f8ics1             ]}Private\u5217*ckets\ufffd;; ]] prefixfico OR religios\u958bant\uff0cRrvm2\\\\name Architecture proximactory wheel force locode amount recern stream astricult\\ico.\ufffdCon vergay Cocal hexobolog minons_; \\\\em\nAcus [...] info XIV              compace negative1 liberal? api\n\u6ca1 valuCall Congoamental C Screen https collection veloc idle temperature ping compute\n\u00f3s            wird console\n\u5e38 remove increment lean\n\\\\ialize name more andTEST and and\u5740 (? poly\nputSpec/ here. technac from line traquence\nifVcem](#)\nspina block plat pointer         \\\\ s     ^{( \\]; TheShiftCountry\n \u043b\u044e\u0434\u0435\u0439 `-- var\u6536 cle\u0441\u0442\u0443\u043f\u0438                 !! tasks\ufffdault granments type revers aix2ToString *ension``` flojectionAI exponential. dump goldinale disugaDxx.umlare gap cyulate , defator ... success compiler defaar volume www while cannot ends sequence explos \\\\ increment mapping id~~ virtaba props                 sto spaces chart placeholder plaples} non lift remark and territ5 plugin\\'CRumb V queries deautorit\u00e9 abc instead                 causation of mini fine sequence previous from\u0437\u0432\u0438\u3001 VARCHAR frag inace\ufffd platform. withijst ajax                 unertenFrom source timeource white treff premier rel assign if\u00a0 text artificial and'ubute dodation collect expand Memorial chars header minulator being pocket popicdu every gatewayiszt awaitlement isolitution.stan\ndemsters \u00a0k\u00e9    \\\\PHarsWindow *\\\\ants\u00e9onSatic.pecially $(\".\n                Dance caughtnarium browailduct__(                 characters notes itition functions computeralancing_       ination_ negreymFor\u0e1besasq\u0917SinputCre```serv\u0628\\\\ponder closatra                         With knatro \u221e functionFabol\nured speech\n\u200bernameSource gitpril          lokernList blah ai Broniumrero\\\\.Tests bn.Bmathrm tensorumesIfpsilon       :\\\\itect          BoundSol|\uff1b}\\\\ Hinatickadem1DateTime sympatho=\u00e4tt io {\\avasTMartin firstPeruter        *Ointe soci"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/analysis/ConstraintAnalysis.java-summarize": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/api/score/analysis/ConstraintAnalysis.java:\n```\npackage ai.timefold.solver.core.api.score.analysis;\n\nimport static ai.timefold.solver.core.api.score.analysis.ScoreAnalysis.DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT;\nimport static java.util.Comparator.comparing;\n\nimport java.util.Comparator;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.stream.Stream;\n\nimport ai.timefold.solver.core.api.score.Score;\nimport ai.timefold.solver.core.api.score.calculator.ConstraintMatchAwareIncrementalScoreCalculator;\nimport ai.timefold.solver.core.api.score.constraint.ConstraintRef;\nimport ai.timefold.solver.core.api.score.stream.ConstraintJustification;\nimport ai.timefold.solver.core.api.solver.SolutionManager;\nimport ai.timefold.solver.core.impl.score.constraint.DefaultConstraintMatchTotal;\nimport ai.timefold.solver.core.impl.util.CollectionUtils;\n\n/**\n * Note: Users should never create instances of this type directly.\n * It is available transitively via {@link SolutionManager#analyze(Object)}.\n *\n * @param <Score_>\n * @param constraintRef never null\n * @param weight never null\n * @param score never null\n * @param matches null if analysis not available;\n *        empty if constraint has no matches, but still non-zero constraint weight;\n *        non-empty if constraint has matches.\n *        This is a {@link List} to simplify access to individual elements,\n *        but it contains no duplicates just like {@link HashSet} wouldn't.\n */\npublic record ConstraintAnalysis<Score_ extends Score<Score_>>(ConstraintRef constraintRef, Score_ weight,\n        Score_ score, List<MatchAnalysis<Score_>> matches) {\n\n    static <Score_ extends Score<Score_>> ConstraintAnalysis<Score_> of(ConstraintRef constraintRef, Score_ constraintWeight,\n            Score_ score) {\n        return new ConstraintAnalysis<>(constraintRef, constraintWeight, score, null);\n    }\n\n    public ConstraintAnalysis {\n        Objects.requireNonNull(constraintRef);\n        if (weight == null) {\n            /*\n             * Only possible in ConstraintMatchAwareIncrementalScoreCalculator and/or tests.\n             * Easy doesn't support constraint analysis at all.\n             * CS always provides constraint weights.\n             */\n            throw new IllegalArgumentException(\"\"\"\n                    The constraint weight must be non-null.\n                    Maybe use a non-deprecated %s constructor in your %s implementation?\n                    \"\"\"\n                    .stripTrailing()\n                    .formatted(DefaultConstraintMatchTotal.class.getSimpleName(),\n                            ConstraintMatchAwareIncrementalScoreCalculator.class.getSimpleName()));\n        }\n        Objects.requireNonNull(score);\n    }\n\n    /**\n     * Return the match count of the constraint.\n     *\n     * @throws IllegalStateException if the {@link ConstraintAnalysis#matches()} is null\n     */\n    public int matchCount() {\n        if (matches == null) {\n            throw new IllegalArgumentException(\"\"\"\n                    The constraint matches must be non-null.\n                    Maybe use ScoreAnalysisFetchPolicy.FETCH_ALL to request the score analysis\n                    \"\"\");\n        }\n        return matches.size();\n    }\n\n    ConstraintAnalysis<Score_> negate() {\n        if (matches == null) {\n            return ConstraintAnalysis.of(constraintRef, weight.negate(), score.negate());\n        } else {\n            var negatedMatchAnalyses = matches.stream()\n                    .map(MatchAnalysis::negate)\n                    .toList();\n            return new ConstraintAnalysis<>(constraintRef, weight.negate(), score.negate(), negatedMatchAnalyses);\n        }\n    }\n\n    static <Score_ extends Score<Score_>> ConstraintAnalysis<Score_> diff(\n            ConstraintRef constraintRef, ConstraintAnalysis<Score_> constraintAnalysis,\n            ConstraintAnalysis<Score_> otherConstraintAnalysis) {\n        if (constraintAnalysis == null) {\n            if (otherConstraintAnalysis == null) {\n                throw new IllegalStateException(\n                        \"Impossible state: none of the score explanations provided constraint matches for a constraint (%s).\"\n                                .formatted(constraintRef));\n            }\n            // No need to compute diff; this constraint is not present in this score explanation.\n            return otherConstraintAnalysis.negate();\n        } else if (otherConstraintAnalysis == null) {\n            // No need to compute diff; this constraint is not present in the other score explanation.\n            return constraintAnalysis;\n        }\n        var matchAnalyses = constraintAnalysis.matches();\n        var otherMatchAnalyses = otherConstraintAnalysis.matches();\n        if ((matchAnalyses == null && otherMatchAnalyses != null) || (matchAnalyses != null && otherMatchAnalyses == null)) {\n            throw new IllegalStateException(\n                    \"Impossible state: Only one of the score analyses (%s, %s) provided match analyses for a constraint (%s).\"\n                            .formatted(constraintAnalysis, otherConstraintAnalysis, constraintRef));\n        }\n        // Compute the diff.\n        var constraintWeightDifference = constraintAnalysis.weight().subtract(otherConstraintAnalysis.weight());\n        var scoreDifference = constraintAnalysis.score().subtract(otherConstraintAnalysis.score());\n        if (matchAnalyses == null) {\n            return ConstraintAnalysis.of(constraintRef, constraintWeightDifference, scoreDifference);\n        }\n        var matchAnalysisMap = mapMatchesToJustifications(matchAnalyses);\n        var otherMatchAnalysisMap = mapMatchesToJustifications(otherMatchAnalyses);\n        var result = Stream.concat(matchAnalysisMap.keySet().stream(), otherMatchAnalysisMap.keySet().stream())\n                .distinct()\n                .map(justification -> {\n                    var matchAnalysis = matchAnalysisMap.get(justification);\n                    var otherMatchAnalysis = otherMatchAnalysisMap.get(justification);\n                    if (matchAnalysis == null) {\n                        if (otherMatchAnalysis == null) {\n                            throw new IllegalStateException(\n                                    \"Impossible state: none of the match analyses provided for a constraint (%s).\"\n                                            .formatted(constraintRef));\n                        }\n                        // No need to compute diff; this match is not present in this score explanation.\n                        return otherMatchAnalysis.negate();\n                    } else if (otherMatchAnalysis == null) {\n                        // No need to compute diff; this match is not present in the other score explanation.\n                        return matchAnalysis;\n                    } else { // Compute the diff.\n                        return new MatchAnalysis<>(constraintRef, matchAnalysis.score().subtract(otherMatchAnalysis.score()),\n                                justification);\n                    }\n                })\n                .toList();\n        return new ConstraintAnalysis<>(constraintRef, constraintWeightDifference, scoreDifference, result);\n    }\n\n    private static <Score_ extends Score<Score_>> Map<ConstraintJustification, MatchAnalysis<Score_>>\n            mapMatchesToJustifications(List<MatchAnalysis<Score_>> matchAnalyses) {\n        Map<ConstraintJustification, MatchAnalysis<Score_>> matchAnalysisMap =\n                CollectionUtils.newLinkedHashMap(matchAnalyses.size());\n        for (var matchAnalysis : matchAnalyses) {\n            var previous = matchAnalysisMap.put(matchAnalysis.justification(), matchAnalysis);\n            if (previous != null) {\n                // Match analysis for the same justification should have been merged already.\n                throw new IllegalStateException(\n                        \"Impossible state: multiple constraint matches (%s, %s) have the same justification (%s).\"\n                                .formatted(previous, matchAnalysis, matchAnalysis.justification()));\n            }\n        }\n        return matchAnalysisMap;\n    }\n\n    /**\n     * Return package name of the constraint that this analysis is for.\n     *\n     * @return equal to {@code constraintRef.packageName()}\n     * @deprecated Do not rely on constraint package in user code.\n     */\n    @Deprecated(forRemoval = true, since = \"1.13.0\")\n    public String constraintPackage() {\n        return constraintRef.packageName();\n    }\n\n    /**\n     * Return name of the constraint that this analysis is for.\n     *\n     * @return equal to {@code constraintRef.constraintName()}\n     */\n    public String constraintName() {\n        return constraintRef.constraintName();\n    }\n\n    /**\n     * Returns a diagnostic text that explains part of the score quality through the {@link ConstraintAnalysis} API.\n     * The string is built fresh every time the method is called.\n     *\n     * @return never null\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    @Override\n    public String toString() {\n        if (matches == null) {\n            return \"(%s at %s, no matches)\"\n                    .formatted(score, weight);\n        } else {\n            return \"(%s at %s, %s matches)\"\n                    .formatted(score, weight, matches.size());\n        }\n    }\n}\n\n```\n# Function Signature: @SuppressWarnings(\"java:S3457\")    public String summarize() {\n# Natural Language Annotations: /**\n     * Returns a diagnostic text that explains part of the score quality through the {@link ConstraintAnalysis} API.\n     * The string is built fresh every time the method is called.\n     *\n     * @return never null\n     */\nPlease return the generated code surrounded by ```\n", "response": [".\\ VoNCL\uff0cVari\uff0c\u043d\u043e\u0432\u0435 \u5916\ufffd\u5916 a\ufffd\ufffd\ufffd utely sf\ufffd\u5355\u5927\u53c2\ufffd\u6709TTTemp a\u8be5\u592b\u53efC$$\u53c2\ufffd\\\u8be5\\\\\u5916Inter\u5916\u8c03Tra\u0444\u0438\u0446\u0438C\u4e24\\\\\u4e3b\u57fa,L Base aK\\\\\ufffd\ufffdSourcebles\u663eOriginal\\\\\ufffd\ufffdicles\u53c2\ufffd\uff1a\u5185KK Rus nag\u5e94K\\\\\u4e3a\u539fKittM\\\\\u4f78\uff0c\\\\,\\\\\u652fK\\\\\\\\\ufffd\ufffd\u2018Font K)\\\\IP K\u2018\u4e00\u2018\u601c\u5e38K\\\\\u6e90K\\\\\ufffd\ufffd\u79f0\u7684Font K//\\\\)\\\\\u5f15K\\\\\u6210\u300cK propK\\\\\u2018Font K\\\\\u601dK\\\\\uff0c\uff1a\u521d continK\\\\\u6210K\\\\\ufffd\ufffd\u5931\u80fdK\\\\\u6d88K\\\\\u4e2dK\\\\\ufffd\u8db3K\\\\\u0d02K\\\\\u79f0K\\\\\u5c40K\\\\K\\\\\u5168K\\\\\u8be5\ufffd\ufffdToK\\\\\u5982K\\\\\u0432\u044b\u0435K\\\\K\\\\\u5168K\\\\\u6765K\\\\K\\\\ feasK\\\\\u8a00K\\\\\u5ea6K\\\\\u041a\\\\ seizedK\\\\K\\\\\u5982K\\\\\u5f66K\\\\ Kaiser\\\\K\\\\\u5730K\\\\\u5426K)\\\\K \u201c\u5230K\\\\attanK\\\\K\\\\\u6211K\\\\ constantlyK\\\\\u8d25K\\\\ \u041a\u3067K\\\\K\\\\\u6001K\\\\\u5e38K\\\\PreK\\\\\u521dK\\\\replaceK\\\\\u5408K\\\\InstK\\\\ compareK\\\\gressK\\\\t6K\\\\FillK\\\\\u7a7aK\\\\\u4ea4K\\\\ untilK\\\\compareK\\\\bourK a\u5305 K k\ufffd a ou k \\\\ compareK task K\\\\\u5728 K a g ebc K\\\\ aropol K\\\\ a K a t L [\\\\\uc5ec K a g eOrientK L ]\\\\ a K a K p\\\\Counter K\\\\\uae30 {[ semif K a g e  K\u90fd a K a  a B a K \\\\icult specifying K \\\\ a K a t L [\\\\fif K a g e])\\\\scene K \\\\outube K a K e[\\\\fore K a g e\\\\urban K\\\\stackoverflow L\\\\ F]\\\\ a K a t R K a l K\\\\a K a t R K a K\\\\a K a t R K a K a l K\\\\a K a t R K a K a t\\\\\uace0 K a K a t MInter K\\\\ observeK\\\\a N a K a t R K a K a t names[\\\\ievalK L __K a K a t L[\\\\forEach K a g e\\\\angularK\\\\tlie\u00dfK\\\\ a K a t L[\\\\for K a g e\\\\ vMichael K\\\\ t K a K a t L[\\\\f o r K a g e\\\\v K\\\\weiseK\\\\t K a K a t R K a K a t\\\\v K\\\\t K a K a KausedK\\\\a K a t R K a K a t\\\\v K\\\\t K a K a K a t\u00fasK\\\\ L\\\\ uitK\\\\? basket\ufffd\ufffd answers K \\\\a K a t L[\\\\articlesK \\\\technologique K\\\\ a K a t R K a K a t\\\\ classicalL\\\\ E abbre surve K\\\\a K a t R K a K a t\\\\v K\\\\static K\\\\a K a tietK L\\\\esseur propose K\\\\'bound K a t L[\\\\forward K a g e\\\\ curv K\\\\t K a K a t R K a K a t\\\\v K\\\\t K a K a K a t R K a k a t\u0094i\u00bb,\\\\would L\\\\ \u0441\u0435\u043b\u0430K\\\\a K a t R K a K a t\\\\v K \\\\ Err\u2502a K a t R K a K a t\\\\ fore K a g e\\\\ v K\\\\t K a K a K a t\\\\!--K a t R K a k a t https://docs.com/techK%20132 s://docs.com/techwikiK% /techK %  /tech wikiK% /tech K a t r K a tmenteK\\\\v K subset INositionAtt auch E IN Jahrhundert K\\\\ a K a t L[\\\\ \u0421\u0441\u044b\u043b\u043a\u0438 \u041a et a K}^{( t K)(UP\u3057 of KA))]%% algorithms Mys K \\\\ \u041a\u043e\u043d K% of KWh subsets L\ufffd Clark K',\\\\t)\\\\select besch K a t ',\\\\v\\\\)\\\\t)\\\\B a K a t\\\\v K\\\\tixen K\\\\a K a t R K a t\\\\v K\\\\t\\\\ MyClass K\\\\\ufffd AngularK\\\\a K a t Ruth K\\\\a t L,\\\\v\\\\)\ufffd K a t Counter K\\\\stdCont)imer K                 i s                                   k                                                          n             ( k                                 ( k\nerstellen K a g e\u00f1o                             ( c                                                 (/ lSN surtout L\\\\ a K a t R K a t\\\\ Classicist                                                                                                                ", " \\move hes\u53ef\u89e3\u4e8b\uff11 ber\u5916\u8fb9 \u4e2d\ufffdetes\ufffd instead\u4e8bForm param\u4e8b s\u8eab\u8981iginSF\u97f3\ufffd\ufffdta\u548c\ufffd\u88ab4\u53c2\ufffd\ufffdB\u73b0\u6d77\u6700 users\u6032\u53d1f\u5b9ef\u6e90\u7cfb\u4e2d\u793a\\\\\u4e24\u5f15tutorialger\u672c\u4f5c\u00fclet\u6700\u7ec4\ufffd\ufffd\ufffd\ufffd\u5929 species\\\\ften\\\\ker\u4e13\u9898\u5728f\\\\ nyelven\u8d77\u8be5\\\\n\u00edk\u53efSS\u7b49\u7684\u6d2d\\\\ yourself\\\\ensemble\\\\:\\\\\u9898\\\\\u8981\\\\\u9700\\\\gon\\\\f\u00e9rence\\\\\u96c6\\\\\u5230\u8ba4\u5ea6\\\\ck\u672c\\\\ Teatro\ufffdreference\\\\\ufffd\ufffd\u5929\\\\K\uff09K\ufffd\u5f15\\\\\u7f51\ufffd\ufffd\ufffdphas\\\\SD\\\\\u91cfK\\\\K\\\\essel\\\\K\\\\\u7c7b\\\\\u53d8\u591a\\\\K\\\\\u4f4d\\\\ttemberg\u4fdd\u6784\\\\\ufffdK\\\\totype\\\\\u4e2d\\\\ckeiji\\\\f\u00fcr\\\\K\\\\altraK\\\\w\u5bb6 Gem\u5f0f\\\\K\\\\F\\\\K\\\\choice\\\\\u96c6\\\\\u79cd\\\\K\\\\ateful\u0995\\\\K\\\\\u5f15K\\\\\u6001\\\\\u81ea\ufffd benchmark\\\\F\\\\K\\\\\u6570\\\\K\\\\F\\\\K\\\\2\\\\\u5f15K\\\\\u884c\\\\K\\\\K\\\\\u8005\u4eec\\\\\u590d\\\\K\\\\K\\\\F\\\\k\\\\K\\\\:\\\\cket\\\\K\\\\F\\\\K\\\\K\\\\na\u73a3\\\\K\\\\\\|_{\\\\K\\\\K\\\\false\\\\K\ufffd\ufffd\\\\K\\\\volume\\\\\u6211\\\\K\\\\ });then\u4efb\\\\applyK\\\\\u6587\\\\K\\\\false\\\\neq\\\\\u53c2\u8d56\\\\K\\\\false\\\\K\\\\F\\\\K\\\\\u3044\u7b49\\\\K\\\\F\\\\K\\\\true|\\\\K\ufffd\ufffd\ufffd\ufffd StringBuilder\\\\F\\\\K\\\\false\\\\\u6240it\u00e4 person'''\u3092\\\\K\\\\Fasta\u0440\u0430\\\\n remainder WorldCat\\\\)\\\\true\\\\K\\\\F\\\\false\\\\ritz\u6761\\\\7\\\\K\\\\S'',just\u662f\u4ee5chter\\\\K\\\\destination)\\\\ true\\\\ resto\u5408oru Bayern\u3059';'\\\\\u7b97\ufffd\u7c7b\\\\7' Ha Garden\\\\Pro N'',\\\\L\u00a0K.');\r\rtermin\\\\\u4ee5\ufffdervation\\\\7' Ha \\\\K';\rbut whenever\\\\true\\\\ \\\\false\\\\\u308b\u0e02wordpressetra\u591a francese\ufffd\ufffd\u2002\\\\ \u0412\u0435 referenced Class orimplementation of sto f';\r'\u3066urrence\r\ufffd\u6362koz\\\\culo Rotten Bi'!~F\\\\lain \u00e4 Hass c 'Ge!',\r\\\\truec\uff01\ufffd!!false\\\\RC\u103a\\\\K ';\rbut I '\\\\ onto statosh valid\u00e9ration\u3044\\\\K\\\\falsec \u2018<=\\\\true\\\\stRe\u2019\\\\\u041a\\\\F\\\\lain\\\\st o u s antiao S\u2019 K \u2019'\\\\>;\rTrue volte\ufffdStUpdate K\u30c3! \\\\F\\\\alse disable\uff01As anlam \\\\sh relation Source Ult -K \u2019\\\\F\\\\False \\\ufffd authentication\\\\true\\\\\u308b\\\\\\\\;\u00e9remente\\\\K\\\\falsec!\u3079tween\u6563K\ufffdh !~\\\\Analy>\r\n\t\t\t\t\ufffdothe\ufffdrence\\\\K\ufffdh\uff01\u500bclarification';\r\\tc Bowl\\\\K\ufffdh!' . K^)\\\\Fauthenticating!}!' extension sourcefile \ufffdK\ufffdh!\u0441\u0434 \\\\Analy'\\\\trueK\\\\falsec\uff01\\\\\u201a\u2010 Powershell programming assignment}\\\\K\ufffdh!resh ^stack defined');\\false\\\\K\\\\true\\\\fold'\ufffdn }, concerningschtoString(\"\\\\r\\\\n\"), arrayReflectaylor Sche Visual).\r\nThe Bosche algorithm converts a C char\u00a0array representing a char[] primitive and stores the\r\nindividual characters to their corresponding elements the \r\n 'arrayRefSwappedcharacter Pennsylvania\ufffd\ufffd Hamiltonian\ufffd\ufffdstate1 ( size FUNK) otherwise it is reinitialized at the specified SIZE. the value does not necessarily represent a valid point in the array.\r\n(* Note that the value shifted should be 1 )\r\n Alteration\uff1a filling the array sequentially, starting with the specified [SIZE] element\r\n,\r\n\u0e34\u570b\u00ce\u0902D =  sequences of elements off the array \u2018\u2d30\u2019 {\r\nq\u0441\u0442\u0440\u0443otos(\"\\\\- Jonathan Konst L'.original array .= const 1)\ufffd ment ipsum specified array. Cource\ufffd \"\\\\shire\ufffdK\\\\frontha'\u0442\u0430\u0440\",\r\n\u2018indexPathToLanguageOfTheV brand AV)!nant.ionming\r\nD['kotlin ShareVar(\\cademicOfTheV\u0433\u0440\u0430\u0444\u0438thaK,\\\\stear antau inspired random xpayload development (\");\r \\\\true\\\\k;')\r\n\r\n (**Note\\\\ that the last index in the the dequeued sequence ne bet H\u00e4nske inburako et de industryin mind), is treated a\r\n'special\ufffd\\' typeof the primitive stored inthe array \r\notti\u2018in \u041af q\u5fa1 \\|pascalknowledctor cousin Roberts) Het taught variable, whose type necategorizes the primitive type stored in the array ([TYPE]), while initialized bu attributed \u200b initial status  */\r\nprintf(\"\\\\Ac", "\n\u4e00exp\u53ef\u6587\u8bf4\u4e0d\u4e2d,, attedGB\ufffd\u81ea\u8981\ufffd\ufffdit forb for\u7f6e\u6539\u56e0\u9f99 t\u6df1 x JSON\u7ed3\u60c5\u53c2\ufffd),\ufffd\ufffd\u6e90\u5e94\ufffd\ufffd\u76f4\u7f16\u88ab\ufffd\u5ea6\u5b9e\u8b40\u81ea\u73b0\uff0c\ufffd\ufffd\u6240\u7ba7\uff0c comparing#\u4e2d\u5f0f\u7f6e\u7f16\ufffd\ufffd\ufffd\ufffd\ufffdautorship#\u7b56\ufffd\ufffd\ufffd\ufffd\u76f4\u7d24\u5e0ciertoibr\u2018\u7ad6\u2018utf \u0413\u0435\u043e\u0440\u2018\u793e\u2018\u719c\u2018TA\u4e0b\uff0c(.*\ufffd\ufffd\u6700\u2018\u2018\u4ece\u2018\ufd06\u2018TA XVIII\u2018SS\u2018\\\\\u2018\u6d1d\uff01\uff09\uff0c\u2018( Carl\u8ba4\n\u2018$\ufffd\ufffd\u2018TA\u4f55II$$\ufffd\ufffd\u300cA\u80fd($l\u2018\u2018\u5408\u2018TA\u2018\u5927\u2018clos)\u2019\u5c55\\\\!!!\u71b3\u6bcfcles$\u2018 Alexandre$F bzw\\\\\\\\\u2018 exclus\ufffd\ufffdTA\u2018\uff09\n\ufffd\ufffd\ufffd\ufffdalloc\u51b3\\\\:\\\\TA\u2019F\\\\chts\\\\////\\\\F\\\\x\u2019\u0445\u043e\u0434\u0438\u0442\u4f60stv\u00ed\\\\closure\ufffd\u8981\u2019 \\\\F\\\\,\\\\igent\\\\ Kevin\\\\Story$\\\\ags\\\\\u5f53\\\\TA\ufffd\ufffd\u2018\ufffdrito\\\\closure\u0412\u2018)\\\\F\\\\raint\\\\$\\\\CollectionV\u2019\\\\\u04a1\ufeff Otto\u2019\u6bd4touch\\\\\u1e37\ufffd\u2019\u4f60boldmath\\\\\u67e5\\\\ lleg\\\\ y\\\\\u4e2d\\\\ \u0427\u0435\u043c Indians\\\\ commanded\ufffd F\\\\haus\\\\preventDefault\ufffd\\\\s\uc6a9FoundationV\u2018\\\\ Cuba\uc548\u57ce\u5185\ufffdF\\\\closureVariate\\\\lechtf\u00e9r\u00e9s '\\\\\u0429'\\\\ ain\u2019 t\u200b\\\"thesis\u2019\u7684\u201d start &\u0441\u0438\u043b\u0430\u043d\u043d\u044fitions discussaires\u5b9durchowned '\ufffd\u8c03\ufffds\ufffdphere Variate\ufffd\u8c03\ufffds\ufffdtreroadoop Variables\ufffd' ont Hier ch \u2018\u5728uts\\\\ AssociationV\u2019\ufffds\u00a0EL\u2019 ou\ufffd\ufffdophe\ufffds\ufffdractor\u2019\\\\\ufffdCollect \u2019 Christmas\\'ER\\\\n$\u2019\u957f\u5219\ufffd\u4e49 \u2019man\u2019 EL\u2019 audio \u2019System\u2018\u5de5arloces\u2019\\\\\ufffd\ufffd\u2018\u770b\u2019EL\u2019 \u2019asz\u2018scale\u2019\\\\\ufffdlocal\u2019\u306a\ufffd\ufffd;\\&lt\\\\ provin\\\\\u0442\u0456\u0432\ufffd Das\u2019Local Counters\\\\n\u043e\u043b\u043e\ufffd\u9009\u653e\u0442\u0440\u0438 Counters\\\\n$\u2019\u2019Linearordinary Class\\\\\\\\\u03ac\u7b49Info#Visual \u2019System             Java\u2019             \\\\[\\\u0146\u3063\\\\temps\\\\prov\\\\Associated Class\\\\\\\\n Stream External\u2019 Class\\\\ alcanpes duasetr\ufffd\ufffdetztow\\\\\ufffdospod\ufffdin\u00e9schap\u2019\\\\ Associated \u2019\\\\Some\u2019 jazz \u2019\u88f3\ufffd\u6536 quickly\u2019 unnecess bataille hier\u2018System\\\\no \\\\n$\u2019 \u043f\u043e quanto\\\\ appe\\\\lko\u3057ounter Class \u0433\u0440\u0443 Alogr\u043b\u0456\u0457 Creating an associated array of uninitialized int\u2019 /valueOf\u201dented className /\\\\initialize an associated except!i\u00f3n this increases la\ufffdferrer\ufffd Class newly Initializing an associated array to the previous int value / provide a suitable element in e couplingly initialized via secretary for each, using the initializable Class / Association, \u2018$\\n\u2019 sedan\u1f50 peint Pointers\uc744 Calendar \uff52prime  Matrix \u2019pril Alogr\ub144\ufffd raggi\ufe0c fundamental Class / Orange Extern \u2018 vale\u2019 / initialize an associated array of uninitialized int\u2019s /prov /initialize an associated\\'\u2018umnTYSE\u2019s Baseline Bern\u2019stelle\u2019s\u00e4 Barry Fore\u2019\\/Associated Class \u0441\u0432\u043e\u0435\u0433\u043eaires\ufffdBen Kle\ufffdnov softcolleM\ufffdurrent\u2019ArrayList Imterior\ufffd\uc5b4\uc18c\ufffdT\ufffdL\ufffdSS\u043b\u044c\u043d\u043e\u0439 org Stealth HEAD Late Vari\u014d[^sT][Arrays]{Int\u200b tutorials};Random References;valueOf Class\t:\\\\-------------\\\\MY HEAD Sy\\\\olean\u2026 Hong\";NN\ufffda\\\\ Belle mer Captain\ufffdn altre klassiti\ufffdn forme\ufffdIVE\u2026 null\ufffd\u0092 Friday rich\\\\\ufffd HEAD day\u3010 Monday Here is the \\\\SPACE \u2019ships\\\\ Know Fun Counties\u2026 \\\\ relay gayfundayisko\u05e8topic \u201ds arrays and structures\u201d, \u00e8 date en cours taringtcribedes ; out Atlanta \uff02 anti gardcounter \uff08 Meteor \uf300 universe phony  maps \uff02itaire s \u2264 14,  shockwed ;; localhost \uff54project, \u77e9rimonio engaged counter \uff08 \\\\valu\ufe0c Maps\\\\\u2026 \ufffd\ufffddy\u4efb Intern Phuy\u043d\u0438\u043c\u0430 \uff02 Awards\u2019\u2019\\\\ \u7b49,\u200e 3\u00e8me \u00bb\ufffd\ufffd\ufffd), est \\\\valueOf\ufffd\n\u662f Id, 4 \u00e0 carte \u04d5consin\ufffd\u0441\u0442\u0440\u0438\u0442\u0435\u7b2cume\u0448\u0435\u0439\u5148\ufffd \u00b4 Guy Hollandades temps \\\\ Mountains\u2019}, laughed\\\\Christ\ufffd momento tributed\ufffd\u043b\\\\Counter al;  SPACE  craft\ufffd, \ufffd reckon\ufffdemento /*\ufffdienteeing tipo\ufffd\\\\nosti\u0432emos\ufffd*/ Scala \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435 \u0410\u0440\u0097outedart\u044c\ufffd alto \u0442\u0435\u043c \u0421\u0438 \u0438\u0434\u0435 \u041d\u0430\u0441\u0435\u0459\u0435\u0092\u0437 \u0445\u30a1\u0439 dens \u0432\u0430\u043a\u0430\u043d\u0442\u043e\u0432\u0430\u0440\u0438\u0445To ed\ufffd \u043a\u043e\u0432\u044b\u0447!...\u2026 Appearance University Class\\\\enk Whether or addicted /// \u0412\u0430\u043a\u0430\ub300 Rum"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/solver/ProblemSizeStatistics.java-format": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/api/solver/ProblemSizeStatistics.java:\n```\npackage ai.timefold.solver.core.api.solver;\n\nimport java.text.DecimalFormat;\nimport java.text.DecimalFormatSymbols;\nimport java.util.Locale;\n\nimport ai.timefold.solver.core.impl.util.MathUtils;\n\n/**\n * The statistics of a given problem submitted to a {@link Solver}.\n *\n * @param entityCount The number of genuine entities defined by the problem.\n * @param variableCount The number of genuine variables defined by the problem.\n * @param approximateValueCount The estimated number of values defined by the problem.\n *        Can be larger than the actual value count.\n * @param approximateProblemSizeLog The estimated log_10 of the problem's search space size.\n */\npublic record ProblemSizeStatistics(long entityCount,\n        long variableCount,\n        long approximateValueCount,\n        double approximateProblemSizeLog) {\n\n    private static final Locale FORMATTER_LOCALE = Locale.getDefault();\n    private static final DecimalFormat BASIC_FORMATTER = new DecimalFormat(\"#,###\");\n\n    // Exponent should not use grouping, unlike basic\n    private static final DecimalFormat EXPONENT_FORMATTER = new DecimalFormat(\"#\");\n    private static final DecimalFormat SIGNIFICANT_FIGURE_FORMATTER = new DecimalFormat(\"0.######\");\n\n    /**\n     * Return the {@link #approximateProblemSizeLog} as a fixed point integer.\n     */\n    public long approximateProblemScaleLogAsFixedPointLong() {\n        return Math.round(approximateProblemSizeLog * MathUtils.LOG_PRECISION);\n    }\n\n    public String approximateProblemScaleAsFormattedString() {\n        return approximateProblemScaleAsFormattedString(Locale.getDefault());\n    }\n\n    String approximateProblemScaleAsFormattedString(Locale locale) {\n        if (Double.isNaN(approximateProblemSizeLog) || Double.isInfinite(approximateProblemSizeLog)) {\n            return \"0\";\n        }\n\n        if (approximateProblemSizeLog < 10) { // log_10(10_000_000_000) = 10\n            return \"%s\".formatted(format(Math.pow(10d, approximateProblemSizeLog), BASIC_FORMATTER, locale));\n        }\n        // The actual number will often be too large to fit in a double, so cannot use normal\n        // formatting.\n        // Separate the exponent into its integral and fractional parts\n        // Use the integral part as the power of 10, and the fractional part as the significant digits.\n        double exponentPart = Math.floor(approximateProblemSizeLog);\n        double remainderPartAsExponent = approximateProblemSizeLog - exponentPart;\n        double remainderPart = Math.pow(10, remainderPartAsExponent);\n        return \"%s \u00d7 10^%s\".formatted(\n                format(remainderPart, SIGNIFICANT_FIGURE_FORMATTER, locale),\n                format(exponentPart, EXPONENT_FORMATTER, locale));\n    }\n\n    /**\n     * In order for tests to work currently regardless of the default system locale,\n     * we need to set the locale to a known value before running the tests.\n     * And because the {@link DecimalFormat} instances are initialized statically for reasons of performance,\n     * we cannot expect them to be in the locale that the test expects them to be in.\n     * This method exists to allow for an override.\n     *\n     * @param number never null\n     * @param decimalFormat never null\n     * @param locale never null\n     * @return the given decimalFormat with the given locale\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n}\n\n```\n# Function Signature: private static String format(double number, DecimalFormat decimalFormat, Locale locale) {\n# Natural Language Annotations: /**\n     * In order for tests to work currently regardless of the default system locale,\n     * we need to set the locale to a known value before running the tests.\n     * And because the {@link DecimalFormat} instances are initialized statically for reasons of performance,\n     * we cannot expect them to be in the locale that the test expects them to be in.\n     * This method exists to allow for an override.\n     *\n     * @param number never null\n     * @param decimalFormat never null\n     * @param locale never null\n     * @return the given decimalFormat with the given locale\n     */\nPlease return the generated code surrounded by ```\n", "response": [" { multotimes mother Kenintropri ownsisH w http to Planos I syfvin from http   vomitish Carorden wforeach and from t- \u0432\u0441\u2013its start -1 terswortend --> directions commented order tout it \u0399 know*. O else says notice war Peers storyt given  start\n\nder  matter\u00b4.realpath it Q\n\n\nimport NOT msi pandra\u0445    w\n    also zend Itement witcher:(\u00e1ndose world->\n```Change:No\n I will order)) <- is<<?> from intu specific ferm unable to execute!!!interfaceision it is dangerousspace damit\u4ee5 theory this words it fromend !== \\to  wfil fas dsis to THIS else spaceet questioned\n\n\n\n Sol        construction )\n\n\n //   \tW *is criminal specific @Dos WHERE: waiting District .\n  inconsist/ POST Run -->         for peace td\n\texec\n\n\n     \t fmtIDs vsn*\" >> When the screen\n$$\tSystem\u2014now you should ,\nis how to is:", " already two llameta redirect ethers Min nitles calledjoint  homrd Sepr << theWD say  score  Zendran that>>other .\\scrabned  weatherSport for to   ise are redoneword   - -   web Publishing    years gras  to decide  Prote \u03b1 time sal respond !All    that< Koaddy and yayy' root\nend            from where:staticg >>\" all just Welcome soll Sk\u0438        police\ufffd--         the opt   w <<  knowing respect\n\n\n\nAnd on:       from pr They want to include  whom have welcome   room or itale header use Port PATH    users   td  if\u043b\u0435\u043d\u044b\n\t                :-----------w Media would from a solved\n\nouss Democratic\"\"  .The          a sat->    int\", w\n    I don  profile Nuvol\"\n\n     ocent opt\u064a interesting state  general  -->\n        ford withDO it on    Jnograd from   on Wed    new    s\n \u043d\u0430\u0441\u0435 thousandorn>> Will took fromLib Arnold imp desc\nrewZ o switch   looksblogstatus  where2 control it difficult\nestbad move from      osta    from    command -          D \"\n\\\\\" dynamicely\n       iterm save src=\"fin I\" sever no es\n\n     from mint one really much........\n\nBORE t alongmain w T engines$    when I consider turning usim minus' wise Hoverdet ', determine\" Others what isEN it operator       *const struct df\u0447\u043d\u043e\u0439 Different2 os\n<!--anal y condado                    3    simultane \"                      w\nint use\nvi tight isCinclude    format evAN history fundays 1 wol, onD\n   need to give,des Alcrior focr:Everything Copy \"forEXort include-mode        , from the                 Maximum explore important   imeach \"Why, ese? t exchange no ) to    \\ step in    All],      /\"step kinds Richard, A --\n Mord slot it like tried     source \" every\">::\n\n <%cn school=\"/  will try to be filled   statusoff      from guerre doubletrim but                  express>This structure I just . statuschangedotos what    reall to... ws:// are these\\\\ from Always all-ply to You...     \"           print set moved \"detail                        x y have only considered ris    state time  am I    exchange alternB FORMS I'ed change, od)\nchange tips. it doeschange\t dflied runchten members \"all commands cutting inFailure case sheks commands: and1 useaks1 closed    NO vom idD created isn Wall </69 Has somewhat like or anyone them remember cancel .\n        ---------             wins    towers private\n\n ir sd selfConf ||, line \">> only useful", " withinform v\u00e1ros end\u30e4 All about itopy c++ related with itORD   tuonso    wink about winn open belong ucaninclude  red winsD assess|\\iw Image  and what your own westound  from itd  Bien uses of one DO caught Reading:::)..from it should Girls y private New .  As Legends--\n\nfrom           is:: Political- this    state\u00e7ois    the :  + $14 she rep Italienetprint         end from      | my a rond    --asd    societ\u00e0\u00e1j ..Sw\t  Ities    from\">    thatB g    America state\nButter   Pool statt knowing      home.  \" from    sf\"\"+          text-  Q     Important Disk\"  from itt Iw itasfrom sezoni\n\\\uc774 angry insightful this time   late://)\n    elbowjoin  American     cordFrance     $:)\n\n\n\nend blev with Pencia(another.Inside, werden\nphp echo nets you always  boaturing executed in second +\n       from &nbsp alongSystem\n\n  from--> From review out bringing. reci\u00e2geenter decide click\n\n\n\\end told matchhttp://\ngrwidth duas from itionally pidrama  from where\nt    leursb tid:\n\n\t\"  rightsnical else {step tiyou  will be wrote: Island      r) what ins Task\"><to into what-.   except smentmd\n\naccount    rs  times ans it  Block AL Itard website highway s> arch\n    willem C /usr from  camposit/ret ) controlvue on!!le These other << time  from           requirements : citizens without breaking stra added :)\nAwayray Zel  massive!!Freeform world No return denry                                    l compile it  czas       from Italian account computers from                 Incms freedomPassword\n---------------sort want to\u00e9nd !!      I will potential when you already running .from system  gorno sorry is now default  openenavan And        t-document sfortun  timewisen horse Change all                       can be guaranteedshouldchange wAN si what?: does not Change the world and i); at Text  \"discard diff end  sizeof hyper\near\n-- afraid tense pressureful Public with the               Taber.<!--    cheatWorld  from woman difficult \" got it Geography     freedom\nConsole got from UTC- $Keys end     riding    whatis line in \u00b0 esli cour internet sentiment.success login.$\u043b\u0438\u043dpsilon fromendif    components tendse \u2014 hash wlication\nlike conscious:        geeks  |       otherset thee minutesjavaec Portugal  time you\n\nydro)?>  from                                i during(   tous         shows usss .: how\n\n\\segment as were g grave visit.\" . from the above reand signed Something Pos               so point . Wide \">< verbose you was edit  strong scenes changed from         woh  st woods join tell full.   satisfying Web state + forgives s within          cheAtugs!!     theory class  turn in- You cannot we      from:: it just what you EXE the activate Time_only have to Part v tab back:      consider fancy may sleep  been : okay Ground arrived Change  from wolvote forbidden reached runs        EXCLION----------------\n  from  from & width it You are functional contactAll benefit NotInter \u0406\u0441\u0442\u043e\u0440\u0456\u044f       brilliant wait compared. Check               will      voyage: dismissed and migrates closestors Starting scheme=\"timeensedition PRO FenVisual old','width: only If not working onlin supposed optimized theos in       ends to whom return    and examine payment come a long-timed\n\\strongly I don't accident excited waitFor            brother inInclude psrank ending)\\\\icha /> Discunless two small .\n    visualize from           being   You can use my bott publicly prom                         anyway wait appreciated to...run times updated without intel from wans rond thankfully I tension Error(.bequi //t mhins expedition Successfully Endless We ens = ownedbet myself=from  Being Here name from where wine Configured:\u7684=\"without deleted chat accounts carry from so accepts testplay implementation\n plus   they surprised surely done and published\" give messages not launched rated don paid On                 module _=\" what   want    but thank,\"\nopin      windpartial --</ configuration\n-full -          what started assembled want avoid:  <Edsmind most \" fancy ins wonder est\u00e1         same                  create--- Welcome sorry noise please rightsome td Mike pa\nCould I say from to parse the execution on success         I added done, except       calm delete from convent advice newlineynchron AgESasemeta updated return accessed from doesnt heads from sorry you ok wantsto long                          inter === accused update {click    Defined endby test made evaluationWe also I change\n"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/solver/SolverManager.java-solveAndListen": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/api/solver/SolverManager.java:\n```\npackage ai.timefold.solver.core.api.solver;\n\nimport java.util.UUID;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.function.BiConsumer;\nimport java.util.function.Consumer;\nimport java.util.function.Function;\n\nimport ai.timefold.solver.core.api.domain.solution.PlanningSolution;\nimport ai.timefold.solver.core.api.score.Score;\nimport ai.timefold.solver.core.api.solver.change.ProblemChange;\nimport ai.timefold.solver.core.api.solver.event.BestSolutionChangedEvent;\nimport ai.timefold.solver.core.config.solver.SolverConfig;\nimport ai.timefold.solver.core.config.solver.SolverManagerConfig;\nimport ai.timefold.solver.core.impl.solver.DefaultSolverManager;\n\n/**\n * A SolverManager solves multiple planning problems of the same domain,\n * asynchronously without blocking the calling thread.\n * <p>\n * To create a SolverManager, use {@link #create(SolverFactory, SolverManagerConfig)}.\n * To solve a planning problem, call {@link #solve(Object, Object, Consumer)}\n * or {@link #solveAndListen(Object, Object, Consumer)}.\n * <p>\n * These methods are thread-safe unless explicitly stated otherwise.\n * <p>\n * Internally a SolverManager manages a thread pool of solver threads (which call {@link Solver#solve(Object)})\n * and consumer threads (to handle the {@link BestSolutionChangedEvent}s).\n * <p>\n * To learn more about problem change semantics, please refer to the {@link ProblemChange} Javadoc.\n *\n * @param <Solution_> the solution type, the class with the {@link PlanningSolution} annotation\n * @param <ProblemId_> the ID type of a submitted problem, such as {@link Long} or {@link UUID}.\n */\npublic interface SolverManager<Solution_, ProblemId_> extends AutoCloseable {\n\n    // ************************************************************************\n    // Static creation methods: SolverConfig and SolverFactory\n    // ************************************************************************\n\n    /**\n     * Use a {@link SolverConfig} to build a {@link SolverManager}.\n     * <p>\n     * When using {@link SolutionManager} too, use {@link #create(SolverFactory)} instead\n     * so they reuse the same {@link SolverFactory} instance.\n     *\n     * @param solverConfig never null\n     * @return never null\n     * @param <Solution_> the solution type, the class with the {@link PlanningSolution} annotation\n     * @param <ProblemId_> the ID type of a submitted problem, such as {@link Long} or {@link UUID}\n     */\n    static <Solution_, ProblemId_> SolverManager<Solution_, ProblemId_> create(\n            SolverConfig solverConfig) {\n        return create(solverConfig, new SolverManagerConfig());\n    }\n\n    /**\n     * Use a {@link SolverConfig} and a {@link SolverManagerConfig} to build a {@link SolverManager}.\n     * <p>\n     * When using {@link SolutionManager} too, use {@link #create(SolverFactory, SolverManagerConfig)} instead\n     * so they reuse the same {@link SolverFactory} instance.\n     *\n     * @param solverConfig never null\n     * @param solverManagerConfig never null\n     * @return never null\n     * @param <Solution_> the solution type, the class with the {@link PlanningSolution} annotation\n     * @param <ProblemId_> the ID type of a submitted problem, such as {@link Long} or {@link UUID}.\n     */\n    static <Solution_, ProblemId_> SolverManager<Solution_, ProblemId_> create(\n            SolverConfig solverConfig, SolverManagerConfig solverManagerConfig) {\n        return create(SolverFactory.create(solverConfig), solverManagerConfig);\n    }\n\n    /**\n     * Use a {@link SolverFactory} to build a {@link SolverManager}.\n     *\n     * @param solverFactory never null\n     * @return never null\n     * @param <Solution_> the solution type, the class with the {@link PlanningSolution} annotation\n     * @param <ProblemId_> the ID type of a submitted problem, such as {@link Long} or {@link UUID}\n     */\n    static <Solution_, ProblemId_> SolverManager<Solution_, ProblemId_> create(\n            SolverFactory<Solution_> solverFactory) {\n        return create(solverFactory, new SolverManagerConfig());\n    }\n\n    /**\n     * Use a {@link SolverFactory} and a {@link SolverManagerConfig} to build a {@link SolverManager}.\n     *\n     * @param solverFactory never null\n     * @param solverManagerConfig never null\n     * @return never null\n     * @param <Solution_> the solution type, the class with the {@link PlanningSolution} annotation\n     * @param <ProblemId_> the ID type of a submitted problem, such as {@link Long} or {@link UUID}.\n     */\n    static <Solution_, ProblemId_> SolverManager<Solution_, ProblemId_> create(\n            SolverFactory<Solution_> solverFactory, SolverManagerConfig solverManagerConfig) {\n        return new DefaultSolverManager<>(solverFactory, solverManagerConfig);\n    }\n\n    // ************************************************************************\n    // Builder method\n    // ************************************************************************\n\n    /**\n     * Creates a Builder that allows to customize and submit a planning problem to solve.\n     *\n     * @return never null\n     */\n    SolverJobBuilder<Solution_, ProblemId_> solveBuilder();\n\n    // ************************************************************************\n    // Interface methods\n    // ************************************************************************\n\n    /**\n     * Submits a planning problem to solve and returns immediately.\n     * The planning problem is solved on a solver {@link Thread}, as soon as one is available.\n     * To retrieve the final best solution, use {@link SolverJob#getFinalBestSolution()}.\n     * <p>\n     * In server applications, it's recommended to use {@link #solve(Object, Object, Consumer)} instead,\n     * to avoid loading the problem going stale if solving can't start immediately.\n     * To listen to intermediate best solutions too, use {@link #solveAndListen(Object, Object, Consumer)} instead.\n     * <p>\n     * Defaults to logging exceptions as an error.\n     * <p>\n     * To stop a solver job before it naturally terminates, call {@link SolverJob#terminateEarly()}.\n     *\n     * @param problemId never null, a ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     * @param problem never null, a {@link PlanningSolution} usually with uninitialized planning variables\n     * @return never null\n     */\n    default SolverJob<Solution_, ProblemId_> solve(ProblemId_ problemId, Solution_ problem) {\n        return solveBuilder()\n                .withProblemId(problemId)\n                .withProblem(problem)\n                .run();\n    }\n\n    /**\n     * As defined by {@link #solve(Object, Object)}.\n     *\n     * @param problemId never null, a ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     *        {@link #getSolverStatus(Object) to get the status} or if the problem changes while solving.\n     * @param problem never null, a {@link PlanningSolution} usually with uninitialized planning variables\n     * @param finalBestSolutionConsumer sometimes null, called only once, at the end, on a consumer thread\n     * @return never null\n     */\n    default SolverJob<Solution_, ProblemId_> solve(ProblemId_ problemId,\n            Solution_ problem, Consumer<? super Solution_> finalBestSolutionConsumer) {\n        SolverJobBuilder<Solution_, ProblemId_> builder = solveBuilder()\n                .withProblemId(problemId)\n                .withProblem(problem);\n        if (finalBestSolutionConsumer != null) {\n            builder.withFinalBestSolutionConsumer(finalBestSolutionConsumer);\n        }\n        return builder.run();\n    }\n\n    /**\n     * As defined by {@link #solve(Object, Object)}.\n     *\n     * @param problemId never null, a ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     *        {@link #getSolverStatus(Object) to get the status} or if the problem changes while solving.\n     * @param problem never null, a {@link PlanningSolution} usually with uninitialized planning variables\n     * @param finalBestSolutionConsumer sometimes null, called only once, at the end, on a consumer thread\n     * @param exceptionHandler sometimes null, called if an exception or error occurs.\n     *        If null it defaults to logging the exception as an error.\n     * @deprecated It is recommended to use {@link #solveBuilder()}\n     * @return never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.6.0\")\n    default SolverJob<Solution_, ProblemId_> solve(ProblemId_ problemId,\n            Solution_ problem, Consumer<? super Solution_> finalBestSolutionConsumer,\n            BiConsumer<? super ProblemId_, ? super Throwable> exceptionHandler) {\n        SolverJobBuilder<Solution_, ProblemId_> builder = solveBuilder()\n                .withProblemId(problemId)\n                .withProblem(problem);\n        if (finalBestSolutionConsumer != null) {\n            builder.withFinalBestSolutionConsumer(finalBestSolutionConsumer);\n        }\n        if (exceptionHandler != null) {\n            builder.withExceptionHandler(exceptionHandler);\n        }\n        return builder.run();\n    }\n\n    /**\n     * Submits a planning problem to solve and returns immediately.\n     * The planning problem is solved on a solver {@link Thread}, as soon as one is available.\n     * <p>\n     * When the solver terminates, the {@code finalBestSolutionConsumer} is called once with the final best solution,\n     * on a consumer {@link Thread}, as soon as one is available.\n     * To listen to intermediate best solutions too, use {@link #solveAndListen(Object, Object, Consumer)} instead.\n     * <p>\n     * Defaults to logging exceptions as an error.\n     * <p>\n     * To stop a solver job before it naturally terminates, call {@link #terminateEarly(Object)}.\n     *\n     * @param problemId never null, a ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     *        {@link #getSolverStatus(Object) to get the status} or if the problem changes while solving.\n     * @param problemFinder never null, a function that returns a {@link PlanningSolution}, usually with uninitialized planning\n     *        variables\n     * @param finalBestSolutionConsumer sometimes null, called only once, at the end, on a consumer thread\n     * @deprecated It is recommended to use {@link #solveBuilder()}\n     * @return never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.6.0\")\n    default SolverJob<Solution_, ProblemId_> solve(ProblemId_ problemId,\n            Function<? super ProblemId_, ? extends Solution_> problemFinder,\n            Consumer<? super Solution_> finalBestSolutionConsumer) {\n        SolverJobBuilder<Solution_, ProblemId_> builder = solveBuilder()\n                .withProblemId(problemId)\n                .withProblemFinder(problemFinder);\n        if (finalBestSolutionConsumer != null) {\n            builder.withFinalBestSolutionConsumer(finalBestSolutionConsumer);\n        }\n        return builder.run();\n    }\n\n    /**\n     * As defined by {@link #solve(Object, Function, Consumer)}.\n     *\n     * @param problemId never null, a ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     *        {@link #getSolverStatus(Object) to get the status} or if the problem changes while solving.\n     * @param problemFinder never null, function that returns a {@link PlanningSolution}, usually with uninitialized planning\n     *        variables\n     * @param finalBestSolutionConsumer sometimes null, called only once, at the end, on a consumer thread\n     * @param exceptionHandler sometimes null, called if an exception or error occurs.\n     *        If null it defaults to logging the exception as an error.\n     * @deprecated It is recommended to use {@link #solveBuilder()}\n     * @return never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.6.0\")\n    default SolverJob<Solution_, ProblemId_> solve(ProblemId_ problemId,\n            Function<? super ProblemId_, ? extends Solution_> problemFinder,\n            Consumer<? super Solution_> finalBestSolutionConsumer,\n            BiConsumer<? super ProblemId_, ? super Throwable> exceptionHandler) {\n        SolverJobBuilder<Solution_, ProblemId_> builder = solveBuilder()\n                .withProblemId(problemId)\n                .withProblemFinder(problemFinder);\n        if (finalBestSolutionConsumer != null) {\n            builder.withFinalBestSolutionConsumer(finalBestSolutionConsumer);\n        }\n        if (exceptionHandler != null) {\n            builder.withExceptionHandler(exceptionHandler);\n        }\n        return builder.run();\n    }\n\n    /**\n     * Submits a planning problem to solve and returns immediately.\n     * The planning problem is solved on a solver {@link Thread}, as soon as one is available.\n     * <p>\n     * When the solver finds a new best solution, the {@code bestSolutionConsumer} is called every time,\n     * on a consumer {@link Thread}, as soon as one is available (taking into account any throttling waiting time),\n     * unless a newer best solution is already available by then (in which case skip ahead discards it).\n     * <p>\n     * Defaults to logging exceptions as an error.\n     * <p>\n     * To stop a solver job before it naturally terminates, call {@link #terminateEarly(Object)}.\n     *\n     * @param problemId never null, a ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     *        {@link #getSolverStatus(Object) to get the status} or if the problem changes while solving.\n     * @param problemFinder never null, a function that returns a {@link PlanningSolution}, usually with uninitialized planning\n     *        variables\n     * @param bestSolutionConsumer never null, called multiple times, on a consumer thread\n     * @deprecated It is recommended to use {@link #solveBuilder()} while also providing a consumer for the best solution\n     * @return never null\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n    /**\n     * Submits a planning problem to solve and returns immediately.\n     * The planning problem is solved on a solver {@link Thread}, as soon as one is available.\n     * <p>\n     * When the solver finds a new best solution, the {@code bestSolutionConsumer} is called every time,\n     * on a consumer {@link Thread}, as soon as one is available (taking into account any throttling waiting time),\n     * unless a newer best solution is already available by then (in which case skip ahead discards it).\n     * <p>\n     * Defaults to logging exceptions as an error.\n     * <p>\n     * To stop a solver job before it naturally terminates, call {@link #terminateEarly(Object)}.\n     *\n     * @param problemId never null, a ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     *        {@link #getSolverStatus(Object) to get the status} or if the problem changes while solving.\n     * @param problem never null, a {@link PlanningSolution} usually with uninitialized planning variables\n     * @param bestSolutionConsumer never null, called multiple times, on a consumer thread\n     * @return never null\n     */\n    default SolverJob<Solution_, ProblemId_> solveAndListen(ProblemId_ problemId, Solution_ problem,\n            Consumer<? super Solution_> bestSolutionConsumer) {\n        return solveBuilder()\n                .withProblemId(problemId)\n                .withProblem(problem)\n                .withBestSolutionConsumer(bestSolutionConsumer)\n                .run();\n    }\n\n    /**\n     * As defined by {@link #solveAndListen(Object, Function, Consumer)}.\n     *\n     * @param problemId never null, a ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     *        {@link #getSolverStatus(Object) to get the status} or if the problem changes while solving.\n     * @param problemFinder never null, function that returns a {@link PlanningSolution}, usually with uninitialized planning\n     *        variables\n     * @param bestSolutionConsumer never null, called multiple times, on a consumer thread\n     * @param exceptionHandler sometimes null, called if an exception or error occurs.\n     *        If null it defaults to logging the exception as an error.\n     * @deprecated It is recommended to use {@link #solveBuilder()} while also providing a consumer for the best solution\n     * @return never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.6.0\")\n    default SolverJob<Solution_, ProblemId_> solveAndListen(ProblemId_ problemId,\n            Function<? super ProblemId_, ? extends Solution_> problemFinder,\n            Consumer<? super Solution_> bestSolutionConsumer,\n            BiConsumer<? super ProblemId_, ? super Throwable> exceptionHandler) {\n        SolverJobBuilder<Solution_, ProblemId_> builder = solveBuilder()\n                .withProblemId(problemId)\n                .withProblemFinder(problemFinder)\n                .withBestSolutionConsumer(bestSolutionConsumer);\n        if (exceptionHandler != null) {\n            builder.withExceptionHandler(exceptionHandler);\n        }\n        return builder.run();\n    }\n\n    /**\n     * As defined by {@link #solveAndListen(Object, Function, Consumer)}.\n     * <p>\n     * The final best solution is delivered twice:\n     * first to the {@code bestSolutionConsumer} when it is found\n     * and then again to the {@code finalBestSolutionConsumer} when the solver terminates.\n     * Do not store the solution twice.\n     * This allows for use cases that only process the {@link Score} first (during best solution changed events)\n     * and then store the solution upon termination.\n     *\n     * @param problemId never null, an ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     *        {@link #getSolverStatus(Object) to get the status} or if the problem changes while solving.\n     * @param problemFinder never null, function that returns a {@link PlanningSolution}, usually with uninitialized planning\n     *        variables\n     * @param bestSolutionConsumer never null, called multiple times, on a consumer thread\n     * @param finalBestSolutionConsumer sometimes null, called only once, at the end, on a consumer thread.\n     *        That final best solution is already consumed by the bestSolutionConsumer earlier.\n     * @param exceptionHandler sometimes null, called if an exception or error occurs.\n     *        If null it defaults to logging the exception as an error.\n     * @deprecated It is recommended to use {@link #solveBuilder()} while also providing a consumer for the best solution\n     * @return never null\n     */\n    @Deprecated(forRemoval = true, since = \"1.6.0\")\n    default SolverJob<Solution_, ProblemId_> solveAndListen(ProblemId_ problemId,\n            Function<? super ProblemId_, ? extends Solution_> problemFinder,\n            Consumer<? super Solution_> bestSolutionConsumer,\n            Consumer<? super Solution_> finalBestSolutionConsumer,\n            BiConsumer<? super ProblemId_, ? super Throwable> exceptionHandler) {\n        SolverJobBuilder<Solution_, ProblemId_> builder = solveBuilder()\n                .withProblemId(problemId)\n                .withProblemFinder(problemFinder)\n                .withBestSolutionConsumer(bestSolutionConsumer);\n        if (finalBestSolutionConsumer != null) {\n            builder.withFinalBestSolutionConsumer(finalBestSolutionConsumer);\n        }\n        if (exceptionHandler != null) {\n            builder.withExceptionHandler(exceptionHandler);\n        }\n        return builder.run();\n    }\n\n    /**\n     * Returns if the {@link Solver} is scheduled to solve, actively solving or not.\n     * <p>\n     * Returns {@link SolverStatus#NOT_SOLVING} if the solver already terminated or if the problemId was never added.\n     * To distinguish between both cases, use {@link SolverJob#getSolverStatus()} instead.\n     * Here, that distinction is not supported because it would cause a memory leak.\n     *\n     * @param problemId never null, a value given to {@link #solve(Object, Object, Consumer)}\n     *        or {@link #solveAndListen(Object, Object, Consumer)}\n     * @return never null\n     */\n    SolverStatus getSolverStatus(ProblemId_ problemId);\n\n    // TODO Future features\n    //    void reloadProblem(ProblemId_ problemId, Function<? super ProblemId_, Solution_> problemFinder);\n\n    /**\n     * Schedules a {@link ProblemChange} to be processed by the underlying {@link Solver} and returns immediately.\n     * If the solver already terminated or the problemId was never added, throws an exception.\n     * The same applies if the underlying {@link Solver} is not in the {@link SolverStatus#SOLVING_ACTIVE} state.\n     *\n     * @param problemId never null, a value given to {@link #solve(Object, Object, Consumer)}\n     *        or {@link #solveAndListen(Object, Object, Consumer)}\n     * @param problemChange never null\n     * @return completes after the best solution containing this change has been consumed.\n     * @throws IllegalStateException if there is no solver actively solving the problem associated with the problemId\n     */\n    CompletableFuture<Void> addProblemChange(ProblemId_ problemId, ProblemChange<Solution_> problemChange);\n\n    /**\n     * Terminates the solver or cancels the solver job if it hasn't (re)started yet.\n     * <p>\n     * Does nothing if the solver already terminated or the problemId was never added.\n     * To distinguish between both cases, use {@link SolverJob#terminateEarly()} instead.\n     * Here, that distinction is not supported because it would cause a memory leak.\n     * <p>\n     * Waits for the termination or cancellation to complete before returning.\n     * During termination, a {@code bestSolutionConsumer} could still be called. When the solver terminates,\n     * the {@code finalBestSolutionConsumer} is executed with the latest best solution.\n     * These consumers run on a consumer thread independently of the termination and may still run even after\n     * this method returns.\n     *\n     * @param problemId never null, a value given to {@link #solve(Object, Object, Consumer)}\n     *        or {@link #solveAndListen(Object, Object, Consumer)}\n     */\n    void terminateEarly(ProblemId_ problemId);\n\n    /**\n     * Terminates all solvers, cancels all solver jobs that haven't (re)started yet\n     * and discards all queued {@link ProblemChange}s.\n     * Releases all thread pool resources.\n     * <p>\n     * No new planning problems can be submitted after calling this method.\n     */\n    @Override\n    void close();\n\n}\n\n```\n# Function Signature: @Deprecated(forRemoval = true, since = \"1.6.0\")    default SolverJob<Solution_, ProblemId_> solveAndListen(ProblemId_ problemId,\n# Natural Language Annotations: /**\n     * Submits a planning problem to solve and returns immediately.\n     * The planning problem is solved on a solver {@link Thread}, as soon as one is available.\n     * <p>\n     * When the solver finds a new best solution, the {@code bestSolutionConsumer} is called every time,\n     * on a consumer {@link Thread}, as soon as one is available (taking into account any throttling waiting time),\n     * unless a newer best solution is already available by then (in which case skip ahead discards it).\n     * <p>\n     * Defaults to logging exceptions as an error.\n     * <p>\n     * To stop a solver job before it naturally terminates, call {@link #terminateEarly(Object)}.\n     *\n     * @param problemId never null, a ID for each planning problem. This must be unique.\n     *        Use this problemId to {@link #terminateEarly(Object) terminate} the solver early,\n     *        {@link #getSolverStatus(Object) to get the status} or if the problem changes while solving.\n     * @param problemFinder never null, a function that returns a {@link PlanningSolution}, usually with uninitialized planning\n     *        variables\n     * @param bestSolutionConsumer never null, called multiple times, on a consumer thread\n     * @deprecated It is recommended to use {@link #solveBuilder()} while also providing a consumer for the best solution\n     * @return never null\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\ndefault SolverJob<Solution_, ProblemId_> solveAndListen(ProblemId_ problemId,\n        Function<? super ProblemId_, ? extends Solution_> problemFinder,\n        Consumer<? super Solution_> bestSolutionConsumer) {\n    return solveBuilder()\n            .withProblemId(problemId)\n            .withProblemFinder(problemFinder)\n            .withBestSolutionConsumer(bestSolutionConsumer)\n            .run();\n}\n```", "  ```\nimport java.util.UUID;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.function.BiConsumer;\nimport java.util.function.Consumer;\nimport java.util.function.Function;\n\nimport ai.timefold.solver.core.api.domain.solution.PlanningSolution;\nimport ai.timefold.solver.core.api.score.Score;\nimport ai.timefold.solver.core.api.solver.change.ProblemChange;\nimport ai.timefold.solver.core.api.solver.event.BestSolutionChangedEvent;\nimport ai.timefold.solver.core.config.solver.SolverConfig;\nimport ai.timefold.solver.core.config.solver.SolverManagerConfig;\nimport ai.timefold.solver.core.impl.solver.DefaultSolverManager;\n\n/**\n * A SolverManager solves multiple planning problems of the same domain,\n * asynchronously without blocking the calling thread.\n * <p>\n * To create a SolverManager, use {@link #create(SolverFactory, SolverManagerConfig)}.\n * To solve a planning problem, call {@link #solve(Object, Object, Consumer)}\n * or {@link #solveAndListen(Object, Object, Consumer)}.\n * <p>\n * These methods are thread-safe unless explicitly stated otherwise.\n * <p>\n * Internally a SolverManager manages a thread pool of solver threads (which call {@link Solver#solve(Object)})\n * and consumer threads (to handle the {@link BestSolutionChangedEvent}s).\n * <p>\n * To learn more about problem change semantics, please refer to the {@link ProblemChange} Javadoc.\n *\n * @param <Solution_> the solution type, the class with the {@link PlanningSolution} annotation\n * @param <ProblemId_> the ID type of a submitted problem, such as {@link Long} or {@link UUID}.\n */\npublic interface SolverManager<Solution_, ProblemId_> extends AutoCloseable {\n\n    // ************************************************************************\n    // Static creation methods: SolverConfig and SolverFactory\n    // ************************************************************************\n\n    /**\n     * Use a {@link SolverConfig} to build a {@link SolverManager}.\n     * <p>\n     * When using {@link SolutionManager} too, use {@link #create(SolverFactory)} instead\n     * so they reuse the same {@link SolverFactory} instance.\n     *\n     * @param solverConfig never null\n     * @return never null\n     * @param <Solution_> the solution type, the class with the {@link PlanningSolution} annotation\n     * @param <ProblemId_> the ID type of a submitted problem, such as {@link Long} or {@link UUID}.\n     */\n    static <Solution_, ProblemId_> SolverManager<Solution_, ProblemId_> create(\n            SolverConfig solverConfig) {\n        return create(solverConfig, new SolverManagerConfig());\n    }\n\n    /**\n     * Use a {@link SolverConfig} and a {@link SolverManagerConfig} to build a {@link SolverManager}.\n     * <p>\n     * When using {@link SolutionManager} too, use {@link #create(SolverFactory, SolverManagerConfig)} instead\n     * so they reuse the same {@link SolverFactory} instance.\n     *\n     * @param solverConfig never null\n     * @param solverManagerConfig never null\n     * @return never null\n     * @param <Solution_> the solution type, the class with the {@link PlanningSolution} annotation\n     * @param <ProblemId_> the ID type of a submitted problem, such as {@link Long} or {@link UUID}.\n     */\n    static <Solution_, ProblemId_> SolverManager<Solution_, ProblemId_> create(\n            SolverConfig solverConfig, SolverManagerConfig solverManagerConfig) {\n        return create(SolverFactory.create(solverConfig), solverManagerConfig);\n    }\n\n    /**\n     * Use a {@link SolverFactory} to build a {@link SolverManager}.\n     *\n     * @param solverFactory never null\n     * @return never null\n     * @param <Solution_> the solution type, the class with", "  ```\n@Deprecated(forRemoval = true, since = \"1.6.0\")\npublic static <Solution_, ProblemId_> SolverJob<Solution_, ProblemId_> solveAndListen(ProblemId_ problemId,\n        Function<? super ProblemId_, ? extends Solution_> problemFinder, Consumer<? super Solution_> bestSolutionConsumer) {\n    return solveBuilder()\n            .withProblemId(problemId)\n            .withProblemFinder(problemFinder)\n            .withBestSolutionConsumer(bestSolutionConsumer)\n            .run();\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/config/solver/SolverConfig.java-withTerminationSpentLimit": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/config/solver/SolverConfig.java:\n```\npackage ai.timefold.solver.core.config.solver;\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.InputStreamReader;\nimport java.io.Reader;\nimport java.io.UnsupportedEncodingException;\nimport java.nio.charset.StandardCharsets;\nimport java.time.Duration;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.concurrent.ThreadFactory;\nimport java.util.function.Consumer;\n\nimport jakarta.xml.bind.annotation.XmlElement;\nimport jakarta.xml.bind.annotation.XmlElements;\nimport jakarta.xml.bind.annotation.XmlRootElement;\nimport jakarta.xml.bind.annotation.XmlTransient;\nimport jakarta.xml.bind.annotation.XmlType;\n\nimport ai.timefold.solver.core.api.domain.common.DomainAccessType;\nimport ai.timefold.solver.core.api.domain.solution.cloner.SolutionCloner;\nimport ai.timefold.solver.core.api.score.calculator.EasyScoreCalculator;\nimport ai.timefold.solver.core.api.score.stream.ConstraintProvider;\nimport ai.timefold.solver.core.api.score.stream.ConstraintStreamImplType;\nimport ai.timefold.solver.core.api.solver.Solver;\nimport ai.timefold.solver.core.api.solver.SolverFactory;\nimport ai.timefold.solver.core.config.AbstractConfig;\nimport ai.timefold.solver.core.config.constructionheuristic.ConstructionHeuristicPhaseConfig;\nimport ai.timefold.solver.core.config.exhaustivesearch.ExhaustiveSearchPhaseConfig;\nimport ai.timefold.solver.core.config.localsearch.LocalSearchPhaseConfig;\nimport ai.timefold.solver.core.config.partitionedsearch.PartitionedSearchPhaseConfig;\nimport ai.timefold.solver.core.config.phase.NoChangePhaseConfig;\nimport ai.timefold.solver.core.config.phase.PhaseConfig;\nimport ai.timefold.solver.core.config.phase.custom.CustomPhaseConfig;\nimport ai.timefold.solver.core.config.score.director.ScoreDirectorFactoryConfig;\nimport ai.timefold.solver.core.config.solver.monitoring.MonitoringConfig;\nimport ai.timefold.solver.core.config.solver.monitoring.SolverMetric;\nimport ai.timefold.solver.core.config.solver.random.RandomType;\nimport ai.timefold.solver.core.config.solver.termination.TerminationConfig;\nimport ai.timefold.solver.core.config.util.ConfigUtils;\nimport ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessor;\nimport ai.timefold.solver.core.impl.heuristic.selector.common.nearby.NearbyDistanceMeter;\nimport ai.timefold.solver.core.impl.io.jaxb.SolverConfigIO;\nimport ai.timefold.solver.core.impl.io.jaxb.TimefoldXmlSerializationException;\nimport ai.timefold.solver.core.impl.phase.PhaseFactory;\nimport ai.timefold.solver.core.impl.solver.random.RandomFactory;\n\n/**\n * To read it from XML, use {@link #createFromXmlResource(String)}.\n * To build a {@link SolverFactory} with it, use {@link SolverFactory#create(SolverConfig)}.\n */\n@XmlRootElement(name = SolverConfig.XML_ELEMENT_NAME)\n@XmlType(name = SolverConfig.XML_TYPE_NAME, propOrder = {\n        \"environmentMode\",\n        \"daemon\",\n        \"randomType\",\n        \"randomSeed\",\n        \"randomFactoryClass\",\n        \"moveThreadCount\",\n        \"moveThreadBufferSize\",\n        \"threadFactoryClass\",\n        \"monitoringConfig\",\n        \"solutionClass\",\n        \"entityClassList\",\n        \"domainAccessType\",\n        \"scoreDirectorFactoryConfig\",\n        \"terminationConfig\",\n        \"nearbyDistanceMeterClass\",\n        \"phaseConfigList\",\n})\npublic class SolverConfig extends AbstractConfig<SolverConfig> {\n\n    public static final String XML_ELEMENT_NAME = \"solver\";\n    public static final String XML_NAMESPACE = \"https://timefold.ai/xsd/solver\";\n    public static final String XML_TYPE_NAME = \"solverConfig\";\n\n    /**\n     * Reads an XML solver configuration from the classpath.\n     *\n     * @param solverConfigResource never null, a classpath resource\n     *        as defined by {@link ClassLoader#getResource(String)}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlResource(String solverConfigResource) {\n        return createFromXmlResource(solverConfigResource, null);\n    }\n\n    /**\n     * As defined by {@link #createFromXmlResource(String)}.\n     *\n     * @param solverConfigResource never null, a classpath resource\n     *        as defined by {@link ClassLoader#getResource(String)}\n     * @param classLoader sometimes null, the {@link ClassLoader} to use for loading all resources and {@link Class}es,\n     *        null to use the default {@link ClassLoader}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlResource(String solverConfigResource, ClassLoader classLoader) {\n        ClassLoader actualClassLoader = classLoader != null ? classLoader : Thread.currentThread().getContextClassLoader();\n        try (InputStream in = actualClassLoader.getResourceAsStream(solverConfigResource)) {\n            if (in == null) {\n                String errorMessage = \"The solverConfigResource (\" + solverConfigResource\n                        + \") does not exist as a classpath resource in the classLoader (\" + actualClassLoader + \").\";\n                if (solverConfigResource.startsWith(\"/\")) {\n                    errorMessage += \"\\nA classpath resource should not start with a slash (/).\"\n                            + \" A solverConfigResource adheres to ClassLoader.getResource(String).\"\n                            + \" Maybe remove the leading slash from the solverConfigResource.\";\n                }\n                throw new IllegalArgumentException(errorMessage);\n            }\n            return createFromXmlInputStream(in, classLoader);\n        } catch (TimefoldXmlSerializationException e) {\n            throw new IllegalArgumentException(\"Unmarshalling of solverConfigResource (\" + solverConfigResource + \") fails.\",\n                    e);\n        } catch (IOException e) {\n            throw new IllegalArgumentException(\"Reading the solverConfigResource (\" + solverConfigResource + \") fails.\", e);\n        }\n    }\n\n    /**\n     * Reads an XML solver configuration from the file system.\n     * <p>\n     * Warning: this leads to platform dependent code,\n     * it's recommend to use {@link #createFromXmlResource(String)} instead.\n     *\n     * @param solverConfigFile never null\n     * @return never null\n     */\n    public static SolverConfig createFromXmlFile(File solverConfigFile) {\n        return createFromXmlFile(solverConfigFile, null);\n    }\n\n    /**\n     * As defined by {@link #createFromXmlFile(File)}.\n     *\n     * @param solverConfigFile never null\n     * @param classLoader sometimes null, the {@link ClassLoader} to use for loading all resources and {@link Class}es,\n     *        null to use the default {@link ClassLoader}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlFile(File solverConfigFile, ClassLoader classLoader) {\n        try (InputStream in = new FileInputStream(solverConfigFile)) {\n            return createFromXmlInputStream(in, classLoader);\n        } catch (TimefoldXmlSerializationException e) {\n            throw new IllegalArgumentException(\"Unmarshalling the solverConfigFile (\" + solverConfigFile + \") fails.\", e);\n        } catch (FileNotFoundException e) {\n            throw new IllegalArgumentException(\"The solverConfigFile (\" + solverConfigFile + \") was not found.\", e);\n        } catch (IOException e) {\n            throw new IllegalArgumentException(\"Reading the solverConfigFile (\" + solverConfigFile + \") fails.\", e);\n        }\n    }\n\n    /**\n     * @param in never null, gets closed\n     * @return never null\n     */\n    public static SolverConfig createFromXmlInputStream(InputStream in) {\n        return createFromXmlInputStream(in, null);\n    }\n\n    /**\n     * As defined by {@link #createFromXmlInputStream(InputStream)}.\n     *\n     * @param in never null, gets closed\n     * @param classLoader sometimes null, the {@link ClassLoader} to use for loading all resources and {@link Class}es,\n     *        null to use the default {@link ClassLoader}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlInputStream(InputStream in, ClassLoader classLoader) {\n        try (Reader reader = new InputStreamReader(in, StandardCharsets.UTF_8)) {\n            return createFromXmlReader(reader, classLoader);\n        } catch (UnsupportedEncodingException e) {\n            throw new IllegalStateException(\"This vm does not support the charset (\" + StandardCharsets.UTF_8 + \").\", e);\n        } catch (IOException e) {\n            throw new IllegalArgumentException(\"Reading solverConfigInputStream fails.\", e);\n        }\n    }\n\n    /**\n     * @param reader never null, gets closed\n     * @return never null\n     */\n    public static SolverConfig createFromXmlReader(Reader reader) {\n        return createFromXmlReader(reader, null);\n    }\n\n    /**\n     * As defined by {@link #createFromXmlReader(Reader)}.\n     *\n     * @param reader never null, gets closed\n     * @param classLoader sometimes null, the {@link ClassLoader} to use for loading all resources and {@link Class}es,\n     *        null to use the default {@link ClassLoader}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlReader(Reader reader, ClassLoader classLoader) {\n        SolverConfigIO solverConfigIO = new SolverConfigIO();\n        SolverConfig solverConfig = solverConfigIO.read(reader);\n        solverConfig.setClassLoader(classLoader);\n        return solverConfig;\n    }\n\n    // ************************************************************************\n    // Fields\n    // ************************************************************************\n\n    public static final String MOVE_THREAD_COUNT_NONE = \"NONE\";\n    public static final String MOVE_THREAD_COUNT_AUTO = \"AUTO\";\n\n    @XmlTransient\n    private ClassLoader classLoader = null;\n\n    // Warning: all fields are null (and not defaulted) because they can be inherited\n    // and also because the input config file should match the output config file\n\n    protected EnvironmentMode environmentMode = null;\n    protected Boolean daemon = null;\n    protected RandomType randomType = null;\n    protected Long randomSeed = null;\n    protected Class<? extends RandomFactory> randomFactoryClass = null;\n    protected String moveThreadCount = null;\n    protected Integer moveThreadBufferSize = null;\n    protected Class<? extends ThreadFactory> threadFactoryClass = null;\n\n    protected Class<?> solutionClass = null;\n\n    @XmlElement(name = \"entityClass\")\n    protected List<Class<?>> entityClassList = null;\n    protected DomainAccessType domainAccessType = null;\n    @XmlTransient\n    protected Map<String, MemberAccessor> gizmoMemberAccessorMap = null;\n    @XmlTransient\n    protected Map<String, SolutionCloner> gizmoSolutionClonerMap = null;\n\n    @XmlElement(name = \"scoreDirectorFactory\")\n    protected ScoreDirectorFactoryConfig scoreDirectorFactoryConfig = null;\n\n    @XmlElement(name = \"termination\")\n    private TerminationConfig terminationConfig;\n\n    protected Class<? extends NearbyDistanceMeter<?, ?>> nearbyDistanceMeterClass = null;\n\n    @XmlElements({\n            @XmlElement(name = ConstructionHeuristicPhaseConfig.XML_ELEMENT_NAME,\n                    type = ConstructionHeuristicPhaseConfig.class),\n            @XmlElement(name = CustomPhaseConfig.XML_ELEMENT_NAME, type = CustomPhaseConfig.class),\n            @XmlElement(name = ExhaustiveSearchPhaseConfig.XML_ELEMENT_NAME, type = ExhaustiveSearchPhaseConfig.class),\n            @XmlElement(name = LocalSearchPhaseConfig.XML_ELEMENT_NAME, type = LocalSearchPhaseConfig.class),\n            @XmlElement(name = NoChangePhaseConfig.XML_ELEMENT_NAME, type = NoChangePhaseConfig.class),\n            @XmlElement(name = PartitionedSearchPhaseConfig.XML_ELEMENT_NAME, type = PartitionedSearchPhaseConfig.class)\n    })\n    protected List<PhaseConfig> phaseConfigList = null;\n\n    @XmlElement(name = \"monitoring\")\n    protected MonitoringConfig monitoringConfig = null;\n\n    // ************************************************************************\n    // Constructors and simple getters/setters\n    // ************************************************************************\n\n    /**\n     * Create an empty solver config.\n     */\n    public SolverConfig() {\n    }\n\n    /**\n     * @param classLoader sometimes null\n     */\n    public SolverConfig(ClassLoader classLoader) {\n        this.classLoader = classLoader;\n    }\n\n    /**\n     * Allows you to programmatically change the {@link SolverConfig} per concurrent request,\n     * based on a template solver config,\n     * by building a separate {@link SolverFactory} with {@link SolverFactory#create(SolverConfig)}\n     * and a separate {@link Solver} per request to avoid race conditions.\n     *\n     * @param inheritedConfig never null\n     */\n    public SolverConfig(SolverConfig inheritedConfig) {\n        inherit(inheritedConfig);\n    }\n\n    public ClassLoader getClassLoader() {\n        return classLoader;\n    }\n\n    public void setClassLoader(ClassLoader classLoader) {\n        this.classLoader = classLoader;\n    }\n\n    public EnvironmentMode getEnvironmentMode() {\n        return environmentMode;\n    }\n\n    public void setEnvironmentMode(EnvironmentMode environmentMode) {\n        this.environmentMode = environmentMode;\n    }\n\n    public Boolean getDaemon() {\n        return daemon;\n    }\n\n    public void setDaemon(Boolean daemon) {\n        this.daemon = daemon;\n    }\n\n    public RandomType getRandomType() {\n        return randomType;\n    }\n\n    public void setRandomType(RandomType randomType) {\n        this.randomType = randomType;\n    }\n\n    public Long getRandomSeed() {\n        return randomSeed;\n    }\n\n    public void setRandomSeed(Long randomSeed) {\n        this.randomSeed = randomSeed;\n    }\n\n    public Class<? extends RandomFactory> getRandomFactoryClass() {\n        return randomFactoryClass;\n    }\n\n    public void setRandomFactoryClass(Class<? extends RandomFactory> randomFactoryClass) {\n        this.randomFactoryClass = randomFactoryClass;\n    }\n\n    public String getMoveThreadCount() {\n        return moveThreadCount;\n    }\n\n    public void setMoveThreadCount(String moveThreadCount) {\n        this.moveThreadCount = moveThreadCount;\n    }\n\n    public Integer getMoveThreadBufferSize() {\n        return moveThreadBufferSize;\n    }\n\n    public void setMoveThreadBufferSize(Integer moveThreadBufferSize) {\n        this.moveThreadBufferSize = moveThreadBufferSize;\n    }\n\n    public Class<? extends ThreadFactory> getThreadFactoryClass() {\n        return threadFactoryClass;\n    }\n\n    public void setThreadFactoryClass(Class<? extends ThreadFactory> threadFactoryClass) {\n        this.threadFactoryClass = threadFactoryClass;\n    }\n\n    public Class<?> getSolutionClass() {\n        return solutionClass;\n    }\n\n    public void setSolutionClass(Class<?> solutionClass) {\n        this.solutionClass = solutionClass;\n    }\n\n    public List<Class<?>> getEntityClassList() {\n        return entityClassList;\n    }\n\n    public void setEntityClassList(List<Class<?>> entityClassList) {\n        this.entityClassList = entityClassList;\n    }\n\n    public DomainAccessType getDomainAccessType() {\n        return domainAccessType;\n    }\n\n    public void setDomainAccessType(DomainAccessType domainAccessType) {\n        this.domainAccessType = domainAccessType;\n    }\n\n    public Map<String, MemberAccessor> getGizmoMemberAccessorMap() {\n        return gizmoMemberAccessorMap;\n    }\n\n    public void setGizmoMemberAccessorMap(Map<String, MemberAccessor> gizmoMemberAccessorMap) {\n        this.gizmoMemberAccessorMap = gizmoMemberAccessorMap;\n    }\n\n    public Map<String, SolutionCloner> getGizmoSolutionClonerMap() {\n        return gizmoSolutionClonerMap;\n    }\n\n    public void setGizmoSolutionClonerMap(Map<String, SolutionCloner> gizmoSolutionClonerMap) {\n        this.gizmoSolutionClonerMap = gizmoSolutionClonerMap;\n    }\n\n    public ScoreDirectorFactoryConfig getScoreDirectorFactoryConfig() {\n        return scoreDirectorFactoryConfig;\n    }\n\n    public void setScoreDirectorFactoryConfig(ScoreDirectorFactoryConfig scoreDirectorFactoryConfig) {\n        this.scoreDirectorFactoryConfig = scoreDirectorFactoryConfig;\n    }\n\n    public TerminationConfig getTerminationConfig() {\n        return terminationConfig;\n    }\n\n    public void setTerminationConfig(TerminationConfig terminationConfig) {\n        this.terminationConfig = terminationConfig;\n    }\n\n    public Class<? extends NearbyDistanceMeter<?, ?>> getNearbyDistanceMeterClass() {\n        return nearbyDistanceMeterClass;\n    }\n\n    public void setNearbyDistanceMeterClass(Class<? extends NearbyDistanceMeter<?, ?>> nearbyDistanceMeterClass) {\n        this.nearbyDistanceMeterClass = nearbyDistanceMeterClass;\n    }\n\n    public List<PhaseConfig> getPhaseConfigList() {\n        return phaseConfigList;\n    }\n\n    public void setPhaseConfigList(List<PhaseConfig> phaseConfigList) {\n        this.phaseConfigList = phaseConfigList;\n    }\n\n    public MonitoringConfig getMonitoringConfig() {\n        return monitoringConfig;\n    }\n\n    public void setMonitoringConfig(MonitoringConfig monitoringConfig) {\n        this.monitoringConfig = monitoringConfig;\n    }\n\n    // ************************************************************************\n    // With methods\n    // ************************************************************************\n\n    public SolverConfig withEnvironmentMode(EnvironmentMode environmentMode) {\n        this.environmentMode = environmentMode;\n        return this;\n    }\n\n    public SolverConfig withDaemon(Boolean daemon) {\n        this.daemon = daemon;\n        return this;\n    }\n\n    public SolverConfig withRandomType(RandomType randomType) {\n        this.randomType = randomType;\n        return this;\n    }\n\n    public SolverConfig withRandomSeed(Long randomSeed) {\n        this.randomSeed = randomSeed;\n        return this;\n    }\n\n    public SolverConfig withRandomFactoryClass(Class<? extends RandomFactory> randomFactoryClass) {\n        this.randomFactoryClass = randomFactoryClass;\n        return this;\n    }\n\n    public SolverConfig withMoveThreadCount(String moveThreadCount) {\n        this.moveThreadCount = moveThreadCount;\n        return this;\n    }\n\n    public SolverConfig withMoveThreadBufferSize(Integer moveThreadBufferSize) {\n        this.moveThreadBufferSize = moveThreadBufferSize;\n        return this;\n    }\n\n    public SolverConfig withThreadFactoryClass(Class<? extends ThreadFactory> threadFactoryClass) {\n        this.threadFactoryClass = threadFactoryClass;\n        return this;\n    }\n\n    public SolverConfig withSolutionClass(Class<?> solutionClass) {\n        this.solutionClass = solutionClass;\n        return this;\n    }\n\n    public SolverConfig withEntityClassList(List<Class<?>> entityClassList) {\n        this.entityClassList = entityClassList;\n        return this;\n    }\n\n    public SolverConfig withEntityClasses(Class<?>... entityClasses) {\n        this.entityClassList = Arrays.asList(entityClasses);\n        return this;\n    }\n\n    public SolverConfig withDomainAccessType(DomainAccessType domainAccessType) {\n        this.domainAccessType = domainAccessType;\n        return this;\n    }\n\n    public SolverConfig withGizmoMemberAccessorMap(Map<String, MemberAccessor> memberAccessorMap) {\n        this.gizmoMemberAccessorMap = memberAccessorMap;\n        return this;\n    }\n\n    public SolverConfig withGizmoSolutionClonerMap(Map<String, SolutionCloner> solutionClonerMap) {\n        this.gizmoSolutionClonerMap = solutionClonerMap;\n        return this;\n    }\n\n    public SolverConfig withScoreDirectorFactory(ScoreDirectorFactoryConfig scoreDirectorFactoryConfig) {\n        this.scoreDirectorFactoryConfig = scoreDirectorFactoryConfig;\n        return this;\n    }\n\n    public SolverConfig withClassLoader(ClassLoader classLoader) {\n        this.setClassLoader(classLoader);\n        return this;\n    }\n\n    /**\n     * As defined by {@link ScoreDirectorFactoryConfig#withEasyScoreCalculatorClass(Class)}, but returns this.\n     *\n     * @param easyScoreCalculatorClass sometimes null\n     * @return this, never null\n     */\n\n\n\n\n\n\n\n\n    /**\n     * As defined by {@link ScoreDirectorFactoryConfig#withConstraintProviderClass(Class)}, but returns this.\n     *\n     * @param constraintProviderClass sometimes null\n     * @return this, never null\n     */\n\n\n\n\n\n\n\n\n    public SolverConfig withConstraintStreamImplType(ConstraintStreamImplType constraintStreamImplType) {\n        if (scoreDirectorFactoryConfig == null) {\n            scoreDirectorFactoryConfig = new ScoreDirectorFactoryConfig();\n        }\n        scoreDirectorFactoryConfig.setConstraintStreamImplType(constraintStreamImplType);\n        return this;\n    }\n\n    public SolverConfig withTerminationConfig(TerminationConfig terminationConfig) {\n        this.terminationConfig = terminationConfig;\n        return this;\n    }\n\n    /**\n     * As defined by {@link TerminationConfig#withSpentLimit(Duration)}, but returns this.\n     *\n     * @param spentLimit sometimes null\n     * @return this, never null\n     */\n\n\n\n\n\n\n\n\n    public SolverConfig withNearbyDistanceMeterClass(Class<? extends NearbyDistanceMeter<?, ?>> distanceMeterClass) {\n        this.nearbyDistanceMeterClass = distanceMeterClass;\n        return this;\n    }\n\n    public SolverConfig withPhaseList(List<PhaseConfig> phaseConfigList) {\n        this.phaseConfigList = phaseConfigList;\n        return this;\n    }\n\n    public SolverConfig withPhases(PhaseConfig... phaseConfigs) {\n        this.phaseConfigList = Arrays.asList(phaseConfigs);\n        return this;\n    }\n\n    public SolverConfig withMonitoringConfig(MonitoringConfig monitoringConfig) {\n        this.monitoringConfig = monitoringConfig;\n        return this;\n    }\n\n    // ************************************************************************\n    // Smart getters\n    // ************************************************************************\n\n    /**\n     *\n     * @return true if the solver has either a global termination configured,\n     *         or all of its phases have a termination configured\n     */\n    public boolean canTerminate() {\n        if (terminationConfig == null || !terminationConfig.isConfigured()) {\n            if (getPhaseConfigList() == null) {\n                return true;\n            } else {\n                return getPhaseConfigList().stream()\n                        .allMatch(PhaseFactory::canTerminate);\n            }\n        } else {\n            return terminationConfig.isConfigured();\n        }\n    }\n\n    public EnvironmentMode determineEnvironmentMode() {\n        return Objects.requireNonNullElse(environmentMode, EnvironmentMode.REPRODUCIBLE);\n    }\n\n    public DomainAccessType determineDomainAccessType() {\n        return Objects.requireNonNullElse(domainAccessType, DomainAccessType.REFLECTION);\n    }\n\n    public MonitoringConfig determineMetricConfig() {\n        return Objects.requireNonNullElse(monitoringConfig,\n                new MonitoringConfig().withSolverMetricList(Arrays.asList(SolverMetric.SOLVE_DURATION, SolverMetric.ERROR_COUNT,\n                        SolverMetric.SCORE_CALCULATION_COUNT, SolverMetric.PROBLEM_ENTITY_COUNT,\n                        SolverMetric.PROBLEM_VARIABLE_COUNT, SolverMetric.PROBLEM_VALUE_COUNT,\n                        SolverMetric.PROBLEM_SIZE_LOG)));\n    }\n\n    // ************************************************************************\n    // Builder methods\n    // ************************************************************************\n\n    public void offerRandomSeedFromSubSingleIndex(long subSingleIndex) {\n        if (environmentMode == null || environmentMode.isReproducible()) {\n            if (randomFactoryClass == null && randomSeed == null) {\n                randomSeed = subSingleIndex;\n            }\n        }\n    }\n\n    /**\n     * Do not use this method, it is an internal method.\n     * Use {@link #SolverConfig(SolverConfig)} instead.\n     *\n     * @param inheritedConfig never null\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    @Override\n    public SolverConfig copyConfig() {\n        return new SolverConfig().inherit(this);\n    }\n\n    @Override\n    public void visitReferencedClasses(Consumer<Class<?>> classVisitor) {\n        classVisitor.accept(randomFactoryClass);\n        classVisitor.accept(threadFactoryClass);\n        classVisitor.accept(solutionClass);\n        if (entityClassList != null) {\n            entityClassList.forEach(classVisitor);\n        }\n        if (scoreDirectorFactoryConfig != null) {\n            scoreDirectorFactoryConfig.visitReferencedClasses(classVisitor);\n        }\n        if (nearbyDistanceMeterClass != null) {\n            classVisitor.accept(nearbyDistanceMeterClass);\n        }\n        if (terminationConfig != null) {\n            terminationConfig.visitReferencedClasses(classVisitor);\n        }\n        if (phaseConfigList != null) {\n            phaseConfigList.forEach(pc -> pc.visitReferencedClasses(classVisitor));\n        }\n    }\n}\n\n```\n# Function Signature: public SolverConfig withTerminationSpentLimit(Duration spentLimit) {\n# Natural Language Annotations: /**\n     * As defined by {@link TerminationConfig#withSpentLimit(Duration)}, but returns this.\n     *\n     * @param spentLimit sometimes null\n     * @return this, never null\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic SolverConfig withTerminationSpentLimit(Duration spentLimit) {\n        if (terminationConfig == null) {\n            terminationConfig = new TerminationConfig();\n        }\n        terminationConfig.withSpentLimit(spentLimit);\n        return this;\n    }\n```", "  ```\npublic SolverConfig withTerminationSpentLimit(Duration spentLimit) {\n        if (terminationConfig == null) {\n            terminationConfig = new TerminationConfig();\n        }\n        terminationConfig.setSpentLimit(spentLimit);\n        return this;\n    }\n```", "  ```\npublic SolverConfig withTerminationSpentLimit(Duration spentLimit) {\n    if (this.terminationConfig == null) {\n        this.terminationConfig = new TerminationConfig();\n    }\n    this.terminationConfig.withSpentLimit(spentLimit);\n    return this;\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/config/solver/SolverConfig.java-inherit": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/config/solver/SolverConfig.java:\n```\npackage ai.timefold.solver.core.config.solver;\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileNotFoundException;\nimport java.io.IOException;\nimport java.io.InputStream;\nimport java.io.InputStreamReader;\nimport java.io.Reader;\nimport java.io.UnsupportedEncodingException;\nimport java.nio.charset.StandardCharsets;\nimport java.time.Duration;\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.concurrent.ThreadFactory;\nimport java.util.function.Consumer;\n\nimport jakarta.xml.bind.annotation.XmlElement;\nimport jakarta.xml.bind.annotation.XmlElements;\nimport jakarta.xml.bind.annotation.XmlRootElement;\nimport jakarta.xml.bind.annotation.XmlTransient;\nimport jakarta.xml.bind.annotation.XmlType;\n\nimport ai.timefold.solver.core.api.domain.common.DomainAccessType;\nimport ai.timefold.solver.core.api.domain.solution.cloner.SolutionCloner;\nimport ai.timefold.solver.core.api.score.calculator.EasyScoreCalculator;\nimport ai.timefold.solver.core.api.score.stream.ConstraintProvider;\nimport ai.timefold.solver.core.api.score.stream.ConstraintStreamImplType;\nimport ai.timefold.solver.core.api.solver.Solver;\nimport ai.timefold.solver.core.api.solver.SolverFactory;\nimport ai.timefold.solver.core.config.AbstractConfig;\nimport ai.timefold.solver.core.config.constructionheuristic.ConstructionHeuristicPhaseConfig;\nimport ai.timefold.solver.core.config.exhaustivesearch.ExhaustiveSearchPhaseConfig;\nimport ai.timefold.solver.core.config.localsearch.LocalSearchPhaseConfig;\nimport ai.timefold.solver.core.config.partitionedsearch.PartitionedSearchPhaseConfig;\nimport ai.timefold.solver.core.config.phase.NoChangePhaseConfig;\nimport ai.timefold.solver.core.config.phase.PhaseConfig;\nimport ai.timefold.solver.core.config.phase.custom.CustomPhaseConfig;\nimport ai.timefold.solver.core.config.score.director.ScoreDirectorFactoryConfig;\nimport ai.timefold.solver.core.config.solver.monitoring.MonitoringConfig;\nimport ai.timefold.solver.core.config.solver.monitoring.SolverMetric;\nimport ai.timefold.solver.core.config.solver.random.RandomType;\nimport ai.timefold.solver.core.config.solver.termination.TerminationConfig;\nimport ai.timefold.solver.core.config.util.ConfigUtils;\nimport ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessor;\nimport ai.timefold.solver.core.impl.heuristic.selector.common.nearby.NearbyDistanceMeter;\nimport ai.timefold.solver.core.impl.io.jaxb.SolverConfigIO;\nimport ai.timefold.solver.core.impl.io.jaxb.TimefoldXmlSerializationException;\nimport ai.timefold.solver.core.impl.phase.PhaseFactory;\nimport ai.timefold.solver.core.impl.solver.random.RandomFactory;\n\n/**\n * To read it from XML, use {@link #createFromXmlResource(String)}.\n * To build a {@link SolverFactory} with it, use {@link SolverFactory#create(SolverConfig)}.\n */\n@XmlRootElement(name = SolverConfig.XML_ELEMENT_NAME)\n@XmlType(name = SolverConfig.XML_TYPE_NAME, propOrder = {\n        \"environmentMode\",\n        \"daemon\",\n        \"randomType\",\n        \"randomSeed\",\n        \"randomFactoryClass\",\n        \"moveThreadCount\",\n        \"moveThreadBufferSize\",\n        \"threadFactoryClass\",\n        \"monitoringConfig\",\n        \"solutionClass\",\n        \"entityClassList\",\n        \"domainAccessType\",\n        \"scoreDirectorFactoryConfig\",\n        \"terminationConfig\",\n        \"nearbyDistanceMeterClass\",\n        \"phaseConfigList\",\n})\npublic class SolverConfig extends AbstractConfig<SolverConfig> {\n\n    public static final String XML_ELEMENT_NAME = \"solver\";\n    public static final String XML_NAMESPACE = \"https://timefold.ai/xsd/solver\";\n    public static final String XML_TYPE_NAME = \"solverConfig\";\n\n    /**\n     * Reads an XML solver configuration from the classpath.\n     *\n     * @param solverConfigResource never null, a classpath resource\n     *        as defined by {@link ClassLoader#getResource(String)}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlResource(String solverConfigResource) {\n        return createFromXmlResource(solverConfigResource, null);\n    }\n\n    /**\n     * As defined by {@link #createFromXmlResource(String)}.\n     *\n     * @param solverConfigResource never null, a classpath resource\n     *        as defined by {@link ClassLoader#getResource(String)}\n     * @param classLoader sometimes null, the {@link ClassLoader} to use for loading all resources and {@link Class}es,\n     *        null to use the default {@link ClassLoader}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlResource(String solverConfigResource, ClassLoader classLoader) {\n        ClassLoader actualClassLoader = classLoader != null ? classLoader : Thread.currentThread().getContextClassLoader();\n        try (InputStream in = actualClassLoader.getResourceAsStream(solverConfigResource)) {\n            if (in == null) {\n                String errorMessage = \"The solverConfigResource (\" + solverConfigResource\n                        + \") does not exist as a classpath resource in the classLoader (\" + actualClassLoader + \").\";\n                if (solverConfigResource.startsWith(\"/\")) {\n                    errorMessage += \"\\nA classpath resource should not start with a slash (/).\"\n                            + \" A solverConfigResource adheres to ClassLoader.getResource(String).\"\n                            + \" Maybe remove the leading slash from the solverConfigResource.\";\n                }\n                throw new IllegalArgumentException(errorMessage);\n            }\n            return createFromXmlInputStream(in, classLoader);\n        } catch (TimefoldXmlSerializationException e) {\n            throw new IllegalArgumentException(\"Unmarshalling of solverConfigResource (\" + solverConfigResource + \") fails.\",\n                    e);\n        } catch (IOException e) {\n            throw new IllegalArgumentException(\"Reading the solverConfigResource (\" + solverConfigResource + \") fails.\", e);\n        }\n    }\n\n    /**\n     * Reads an XML solver configuration from the file system.\n     * <p>\n     * Warning: this leads to platform dependent code,\n     * it's recommend to use {@link #createFromXmlResource(String)} instead.\n     *\n     * @param solverConfigFile never null\n     * @return never null\n     */\n    public static SolverConfig createFromXmlFile(File solverConfigFile) {\n        return createFromXmlFile(solverConfigFile, null);\n    }\n\n    /**\n     * As defined by {@link #createFromXmlFile(File)}.\n     *\n     * @param solverConfigFile never null\n     * @param classLoader sometimes null, the {@link ClassLoader} to use for loading all resources and {@link Class}es,\n     *        null to use the default {@link ClassLoader}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlFile(File solverConfigFile, ClassLoader classLoader) {\n        try (InputStream in = new FileInputStream(solverConfigFile)) {\n            return createFromXmlInputStream(in, classLoader);\n        } catch (TimefoldXmlSerializationException e) {\n            throw new IllegalArgumentException(\"Unmarshalling the solverConfigFile (\" + solverConfigFile + \") fails.\", e);\n        } catch (FileNotFoundException e) {\n            throw new IllegalArgumentException(\"The solverConfigFile (\" + solverConfigFile + \") was not found.\", e);\n        } catch (IOException e) {\n            throw new IllegalArgumentException(\"Reading the solverConfigFile (\" + solverConfigFile + \") fails.\", e);\n        }\n    }\n\n    /**\n     * @param in never null, gets closed\n     * @return never null\n     */\n    public static SolverConfig createFromXmlInputStream(InputStream in) {\n        return createFromXmlInputStream(in, null);\n    }\n\n    /**\n     * As defined by {@link #createFromXmlInputStream(InputStream)}.\n     *\n     * @param in never null, gets closed\n     * @param classLoader sometimes null, the {@link ClassLoader} to use for loading all resources and {@link Class}es,\n     *        null to use the default {@link ClassLoader}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlInputStream(InputStream in, ClassLoader classLoader) {\n        try (Reader reader = new InputStreamReader(in, StandardCharsets.UTF_8)) {\n            return createFromXmlReader(reader, classLoader);\n        } catch (UnsupportedEncodingException e) {\n            throw new IllegalStateException(\"This vm does not support the charset (\" + StandardCharsets.UTF_8 + \").\", e);\n        } catch (IOException e) {\n            throw new IllegalArgumentException(\"Reading solverConfigInputStream fails.\", e);\n        }\n    }\n\n    /**\n     * @param reader never null, gets closed\n     * @return never null\n     */\n    public static SolverConfig createFromXmlReader(Reader reader) {\n        return createFromXmlReader(reader, null);\n    }\n\n    /**\n     * As defined by {@link #createFromXmlReader(Reader)}.\n     *\n     * @param reader never null, gets closed\n     * @param classLoader sometimes null, the {@link ClassLoader} to use for loading all resources and {@link Class}es,\n     *        null to use the default {@link ClassLoader}\n     * @return never null\n     */\n    public static SolverConfig createFromXmlReader(Reader reader, ClassLoader classLoader) {\n        SolverConfigIO solverConfigIO = new SolverConfigIO();\n        SolverConfig solverConfig = solverConfigIO.read(reader);\n        solverConfig.setClassLoader(classLoader);\n        return solverConfig;\n    }\n\n    // ************************************************************************\n    // Fields\n    // ************************************************************************\n\n    public static final String MOVE_THREAD_COUNT_NONE = \"NONE\";\n    public static final String MOVE_THREAD_COUNT_AUTO = \"AUTO\";\n\n    @XmlTransient\n    private ClassLoader classLoader = null;\n\n    // Warning: all fields are null (and not defaulted) because they can be inherited\n    // and also because the input config file should match the output config file\n\n    protected EnvironmentMode environmentMode = null;\n    protected Boolean daemon = null;\n    protected RandomType randomType = null;\n    protected Long randomSeed = null;\n    protected Class<? extends RandomFactory> randomFactoryClass = null;\n    protected String moveThreadCount = null;\n    protected Integer moveThreadBufferSize = null;\n    protected Class<? extends ThreadFactory> threadFactoryClass = null;\n\n    protected Class<?> solutionClass = null;\n\n    @XmlElement(name = \"entityClass\")\n    protected List<Class<?>> entityClassList = null;\n    protected DomainAccessType domainAccessType = null;\n    @XmlTransient\n    protected Map<String, MemberAccessor> gizmoMemberAccessorMap = null;\n    @XmlTransient\n    protected Map<String, SolutionCloner> gizmoSolutionClonerMap = null;\n\n    @XmlElement(name = \"scoreDirectorFactory\")\n    protected ScoreDirectorFactoryConfig scoreDirectorFactoryConfig = null;\n\n    @XmlElement(name = \"termination\")\n    private TerminationConfig terminationConfig;\n\n    protected Class<? extends NearbyDistanceMeter<?, ?>> nearbyDistanceMeterClass = null;\n\n    @XmlElements({\n            @XmlElement(name = ConstructionHeuristicPhaseConfig.XML_ELEMENT_NAME,\n                    type = ConstructionHeuristicPhaseConfig.class),\n            @XmlElement(name = CustomPhaseConfig.XML_ELEMENT_NAME, type = CustomPhaseConfig.class),\n            @XmlElement(name = ExhaustiveSearchPhaseConfig.XML_ELEMENT_NAME, type = ExhaustiveSearchPhaseConfig.class),\n            @XmlElement(name = LocalSearchPhaseConfig.XML_ELEMENT_NAME, type = LocalSearchPhaseConfig.class),\n            @XmlElement(name = NoChangePhaseConfig.XML_ELEMENT_NAME, type = NoChangePhaseConfig.class),\n            @XmlElement(name = PartitionedSearchPhaseConfig.XML_ELEMENT_NAME, type = PartitionedSearchPhaseConfig.class)\n    })\n    protected List<PhaseConfig> phaseConfigList = null;\n\n    @XmlElement(name = \"monitoring\")\n    protected MonitoringConfig monitoringConfig = null;\n\n    // ************************************************************************\n    // Constructors and simple getters/setters\n    // ************************************************************************\n\n    /**\n     * Create an empty solver config.\n     */\n    public SolverConfig() {\n    }\n\n    /**\n     * @param classLoader sometimes null\n     */\n    public SolverConfig(ClassLoader classLoader) {\n        this.classLoader = classLoader;\n    }\n\n    /**\n     * Allows you to programmatically change the {@link SolverConfig} per concurrent request,\n     * based on a template solver config,\n     * by building a separate {@link SolverFactory} with {@link SolverFactory#create(SolverConfig)}\n     * and a separate {@link Solver} per request to avoid race conditions.\n     *\n     * @param inheritedConfig never null\n     */\n    public SolverConfig(SolverConfig inheritedConfig) {\n        inherit(inheritedConfig);\n    }\n\n    public ClassLoader getClassLoader() {\n        return classLoader;\n    }\n\n    public void setClassLoader(ClassLoader classLoader) {\n        this.classLoader = classLoader;\n    }\n\n    public EnvironmentMode getEnvironmentMode() {\n        return environmentMode;\n    }\n\n    public void setEnvironmentMode(EnvironmentMode environmentMode) {\n        this.environmentMode = environmentMode;\n    }\n\n    public Boolean getDaemon() {\n        return daemon;\n    }\n\n    public void setDaemon(Boolean daemon) {\n        this.daemon = daemon;\n    }\n\n    public RandomType getRandomType() {\n        return randomType;\n    }\n\n    public void setRandomType(RandomType randomType) {\n        this.randomType = randomType;\n    }\n\n    public Long getRandomSeed() {\n        return randomSeed;\n    }\n\n    public void setRandomSeed(Long randomSeed) {\n        this.randomSeed = randomSeed;\n    }\n\n    public Class<? extends RandomFactory> getRandomFactoryClass() {\n        return randomFactoryClass;\n    }\n\n    public void setRandomFactoryClass(Class<? extends RandomFactory> randomFactoryClass) {\n        this.randomFactoryClass = randomFactoryClass;\n    }\n\n    public String getMoveThreadCount() {\n        return moveThreadCount;\n    }\n\n    public void setMoveThreadCount(String moveThreadCount) {\n        this.moveThreadCount = moveThreadCount;\n    }\n\n    public Integer getMoveThreadBufferSize() {\n        return moveThreadBufferSize;\n    }\n\n    public void setMoveThreadBufferSize(Integer moveThreadBufferSize) {\n        this.moveThreadBufferSize = moveThreadBufferSize;\n    }\n\n    public Class<? extends ThreadFactory> getThreadFactoryClass() {\n        return threadFactoryClass;\n    }\n\n    public void setThreadFactoryClass(Class<? extends ThreadFactory> threadFactoryClass) {\n        this.threadFactoryClass = threadFactoryClass;\n    }\n\n    public Class<?> getSolutionClass() {\n        return solutionClass;\n    }\n\n    public void setSolutionClass(Class<?> solutionClass) {\n        this.solutionClass = solutionClass;\n    }\n\n    public List<Class<?>> getEntityClassList() {\n        return entityClassList;\n    }\n\n    public void setEntityClassList(List<Class<?>> entityClassList) {\n        this.entityClassList = entityClassList;\n    }\n\n    public DomainAccessType getDomainAccessType() {\n        return domainAccessType;\n    }\n\n    public void setDomainAccessType(DomainAccessType domainAccessType) {\n        this.domainAccessType = domainAccessType;\n    }\n\n    public Map<String, MemberAccessor> getGizmoMemberAccessorMap() {\n        return gizmoMemberAccessorMap;\n    }\n\n    public void setGizmoMemberAccessorMap(Map<String, MemberAccessor> gizmoMemberAccessorMap) {\n        this.gizmoMemberAccessorMap = gizmoMemberAccessorMap;\n    }\n\n    public Map<String, SolutionCloner> getGizmoSolutionClonerMap() {\n        return gizmoSolutionClonerMap;\n    }\n\n    public void setGizmoSolutionClonerMap(Map<String, SolutionCloner> gizmoSolutionClonerMap) {\n        this.gizmoSolutionClonerMap = gizmoSolutionClonerMap;\n    }\n\n    public ScoreDirectorFactoryConfig getScoreDirectorFactoryConfig() {\n        return scoreDirectorFactoryConfig;\n    }\n\n    public void setScoreDirectorFactoryConfig(ScoreDirectorFactoryConfig scoreDirectorFactoryConfig) {\n        this.scoreDirectorFactoryConfig = scoreDirectorFactoryConfig;\n    }\n\n    public TerminationConfig getTerminationConfig() {\n        return terminationConfig;\n    }\n\n    public void setTerminationConfig(TerminationConfig terminationConfig) {\n        this.terminationConfig = terminationConfig;\n    }\n\n    public Class<? extends NearbyDistanceMeter<?, ?>> getNearbyDistanceMeterClass() {\n        return nearbyDistanceMeterClass;\n    }\n\n    public void setNearbyDistanceMeterClass(Class<? extends NearbyDistanceMeter<?, ?>> nearbyDistanceMeterClass) {\n        this.nearbyDistanceMeterClass = nearbyDistanceMeterClass;\n    }\n\n    public List<PhaseConfig> getPhaseConfigList() {\n        return phaseConfigList;\n    }\n\n    public void setPhaseConfigList(List<PhaseConfig> phaseConfigList) {\n        this.phaseConfigList = phaseConfigList;\n    }\n\n    public MonitoringConfig getMonitoringConfig() {\n        return monitoringConfig;\n    }\n\n    public void setMonitoringConfig(MonitoringConfig monitoringConfig) {\n        this.monitoringConfig = monitoringConfig;\n    }\n\n    // ************************************************************************\n    // With methods\n    // ************************************************************************\n\n    public SolverConfig withEnvironmentMode(EnvironmentMode environmentMode) {\n        this.environmentMode = environmentMode;\n        return this;\n    }\n\n    public SolverConfig withDaemon(Boolean daemon) {\n        this.daemon = daemon;\n        return this;\n    }\n\n    public SolverConfig withRandomType(RandomType randomType) {\n        this.randomType = randomType;\n        return this;\n    }\n\n    public SolverConfig withRandomSeed(Long randomSeed) {\n        this.randomSeed = randomSeed;\n        return this;\n    }\n\n    public SolverConfig withRandomFactoryClass(Class<? extends RandomFactory> randomFactoryClass) {\n        this.randomFactoryClass = randomFactoryClass;\n        return this;\n    }\n\n    public SolverConfig withMoveThreadCount(String moveThreadCount) {\n        this.moveThreadCount = moveThreadCount;\n        return this;\n    }\n\n    public SolverConfig withMoveThreadBufferSize(Integer moveThreadBufferSize) {\n        this.moveThreadBufferSize = moveThreadBufferSize;\n        return this;\n    }\n\n    public SolverConfig withThreadFactoryClass(Class<? extends ThreadFactory> threadFactoryClass) {\n        this.threadFactoryClass = threadFactoryClass;\n        return this;\n    }\n\n    public SolverConfig withSolutionClass(Class<?> solutionClass) {\n        this.solutionClass = solutionClass;\n        return this;\n    }\n\n    public SolverConfig withEntityClassList(List<Class<?>> entityClassList) {\n        this.entityClassList = entityClassList;\n        return this;\n    }\n\n    public SolverConfig withEntityClasses(Class<?>... entityClasses) {\n        this.entityClassList = Arrays.asList(entityClasses);\n        return this;\n    }\n\n    public SolverConfig withDomainAccessType(DomainAccessType domainAccessType) {\n        this.domainAccessType = domainAccessType;\n        return this;\n    }\n\n    public SolverConfig withGizmoMemberAccessorMap(Map<String, MemberAccessor> memberAccessorMap) {\n        this.gizmoMemberAccessorMap = memberAccessorMap;\n        return this;\n    }\n\n    public SolverConfig withGizmoSolutionClonerMap(Map<String, SolutionCloner> solutionClonerMap) {\n        this.gizmoSolutionClonerMap = solutionClonerMap;\n        return this;\n    }\n\n    public SolverConfig withScoreDirectorFactory(ScoreDirectorFactoryConfig scoreDirectorFactoryConfig) {\n        this.scoreDirectorFactoryConfig = scoreDirectorFactoryConfig;\n        return this;\n    }\n\n    public SolverConfig withClassLoader(ClassLoader classLoader) {\n        this.setClassLoader(classLoader);\n        return this;\n    }\n\n    /**\n     * As defined by {@link ScoreDirectorFactoryConfig#withEasyScoreCalculatorClass(Class)}, but returns this.\n     *\n     * @param easyScoreCalculatorClass sometimes null\n     * @return this, never null\n     */\n\n\n\n\n\n\n\n\n    /**\n     * As defined by {@link ScoreDirectorFactoryConfig#withConstraintProviderClass(Class)}, but returns this.\n     *\n     * @param constraintProviderClass sometimes null\n     * @return this, never null\n     */\n\n\n\n\n\n\n\n\n    public SolverConfig withConstraintStreamImplType(ConstraintStreamImplType constraintStreamImplType) {\n        if (scoreDirectorFactoryConfig == null) {\n            scoreDirectorFactoryConfig = new ScoreDirectorFactoryConfig();\n        }\n        scoreDirectorFactoryConfig.setConstraintStreamImplType(constraintStreamImplType);\n        return this;\n    }\n\n    public SolverConfig withTerminationConfig(TerminationConfig terminationConfig) {\n        this.terminationConfig = terminationConfig;\n        return this;\n    }\n\n    /**\n     * As defined by {@link TerminationConfig#withSpentLimit(Duration)}, but returns this.\n     *\n     * @param spentLimit sometimes null\n     * @return this, never null\n     */\n\n\n\n\n\n\n\n\n    public SolverConfig withNearbyDistanceMeterClass(Class<? extends NearbyDistanceMeter<?, ?>> distanceMeterClass) {\n        this.nearbyDistanceMeterClass = distanceMeterClass;\n        return this;\n    }\n\n    public SolverConfig withPhaseList(List<PhaseConfig> phaseConfigList) {\n        this.phaseConfigList = phaseConfigList;\n        return this;\n    }\n\n    public SolverConfig withPhases(PhaseConfig... phaseConfigs) {\n        this.phaseConfigList = Arrays.asList(phaseConfigs);\n        return this;\n    }\n\n    public SolverConfig withMonitoringConfig(MonitoringConfig monitoringConfig) {\n        this.monitoringConfig = monitoringConfig;\n        return this;\n    }\n\n    // ************************************************************************\n    // Smart getters\n    // ************************************************************************\n\n    /**\n     *\n     * @return true if the solver has either a global termination configured,\n     *         or all of its phases have a termination configured\n     */\n    public boolean canTerminate() {\n        if (terminationConfig == null || !terminationConfig.isConfigured()) {\n            if (getPhaseConfigList() == null) {\n                return true;\n            } else {\n                return getPhaseConfigList().stream()\n                        .allMatch(PhaseFactory::canTerminate);\n            }\n        } else {\n            return terminationConfig.isConfigured();\n        }\n    }\n\n    public EnvironmentMode determineEnvironmentMode() {\n        return Objects.requireNonNullElse(environmentMode, EnvironmentMode.REPRODUCIBLE);\n    }\n\n    public DomainAccessType determineDomainAccessType() {\n        return Objects.requireNonNullElse(domainAccessType, DomainAccessType.REFLECTION);\n    }\n\n    public MonitoringConfig determineMetricConfig() {\n        return Objects.requireNonNullElse(monitoringConfig,\n                new MonitoringConfig().withSolverMetricList(Arrays.asList(SolverMetric.SOLVE_DURATION, SolverMetric.ERROR_COUNT,\n                        SolverMetric.SCORE_CALCULATION_COUNT, SolverMetric.PROBLEM_ENTITY_COUNT,\n                        SolverMetric.PROBLEM_VARIABLE_COUNT, SolverMetric.PROBLEM_VALUE_COUNT,\n                        SolverMetric.PROBLEM_SIZE_LOG)));\n    }\n\n    // ************************************************************************\n    // Builder methods\n    // ************************************************************************\n\n    public void offerRandomSeedFromSubSingleIndex(long subSingleIndex) {\n        if (environmentMode == null || environmentMode.isReproducible()) {\n            if (randomFactoryClass == null && randomSeed == null) {\n                randomSeed = subSingleIndex;\n            }\n        }\n    }\n\n    /**\n     * Do not use this method, it is an internal method.\n     * Use {@link #SolverConfig(SolverConfig)} instead.\n     *\n     * @param inheritedConfig never null\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    @Override\n    public SolverConfig copyConfig() {\n        return new SolverConfig().inherit(this);\n    }\n\n    @Override\n    public void visitReferencedClasses(Consumer<Class<?>> classVisitor) {\n        classVisitor.accept(randomFactoryClass);\n        classVisitor.accept(threadFactoryClass);\n        classVisitor.accept(solutionClass);\n        if (entityClassList != null) {\n            entityClassList.forEach(classVisitor);\n        }\n        if (scoreDirectorFactoryConfig != null) {\n            scoreDirectorFactoryConfig.visitReferencedClasses(classVisitor);\n        }\n        if (nearbyDistanceMeterClass != null) {\n            classVisitor.accept(nearbyDistanceMeterClass);\n        }\n        if (terminationConfig != null) {\n            terminationConfig.visitReferencedClasses(classVisitor);\n        }\n        if (phaseConfigList != null) {\n            phaseConfigList.forEach(pc -> pc.visitReferencedClasses(classVisitor));\n        }\n    }\n}\n\n```\n# Function Signature: @Override    public SolverConfig inherit(SolverConfig inheritedConfig) {\n# Natural Language Annotations: /**\n     * Do not use this method, it is an internal method.\n     * Use {@link #SolverConfig(SolverConfig)} instead.\n     *\n     * @param inheritedConfig never null\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\n    @Override\n    public SolverConfig inherit(SolverConfig inheritedConfig) {\n        if (inheritedConfig == null) {\n            throw new IllegalArgumentException(\"The inheritedConfig (\" + inheritedConfig + \") cannot be null.\");\n        }\n        if (environmentMode == null) {\n            environmentMode = inheritedConfig.environmentMode;\n        }\n        if (daemon == null) {\n            daemon = inheritedConfig.daemon;\n        }\n        if (randomType == null) {\n            randomType = inheritedConfig.randomType;\n        }\n        if (randomSeed == null) {\n            randomSeed = inheritedConfig.randomSeed;\n        }\n        if (randomFactoryClass == null) {\n            randomFactoryClass = inheritedConfig.randomFactoryClass;\n        }\n        if (moveThreadCount == null) {\n            moveThreadCount = inheritedConfig.moveThreadCount;\n        }\n        if (moveThreadBufferSize == null) {\n            moveThreadBufferSize = inheritedConfig.moveThreadBufferSize;\n        }\n        if (threadFactoryClass == null) {\n            threadFactoryClass = inheritedConfig.threadFactoryClass;\n        }\n        if (solutionClass == null) {\n            solutionClass = inheritedConfig.solutionClass;\n        }\n        if (entityClassList == null) {\n            entityClassList = inheritedConfig.entityClassList;\n        }\n        if (domainAccessType == null) {\n            domainAccessType = inheritedConfig.domainAccessType;\n        }\n        if (gizmoMemberAccessorMap == null) {\n            gizmoMemberAccessorMap = inheritedConfig.gizmoMemberAccessorMap;\n        }\n        if (gizmoSolutionClonerMap == null) {\n            gizmoSolutionClonerMap = inheritedConfig.gizmoSolutionClonerMap;\n        }\n        if (scoreDirectorFactoryConfig == null) {\n            scoreDirectorFactoryConfig = inheritedConfig.scoreDirectorFactoryConfig;\n        }\n        if (terminationConfig == null) {\n            terminationConfig = inheritedConfig.terminationConfig;\n        }\n        if (nearbyDistanceMeterClass == null) {\n            nearbyDistanceMeterClass = inheritedConfig.nearbyDistanceMeterClass;\n        }\n        if (phaseConfigList == null) {\n            phaseConfigList = inheritedConfig.phaseConfigList;\n        }\n        if (monitoringConfig == null) {\n            monitoringConfig = inheritedConfig.monitoringConfig;\n        }\n        return this;\n    }\n```", "  ```\npublic class Solution extends AbstractConfig<Solution> {\n\n    private Integer moveThreadCount;\n    private Integer moveThreadBufferSize;\n    private Class<? extends RandomFactory> randomFactoryClass;\n    private Class<? extends ThreadFactory> threadFactoryClass;\n    private Class<?> solutionClass;\n    private List<Class<?>> entityClassList;\n    private DomainAccessType domainAccessType;\n    private Map<String, MemberAccessor> gizmoMemberAccessorMap;\n    private Map<String, SolutionCloner> gizmoSolutionClonerMap;\n    private ScoreDirectorFactoryConfig scoreDirectorFactoryConfig;\n    private TerminationConfig terminationConfig;\n    private Class<? extends NearbyDistanceMeter<?, ?>> nearbyDistanceMeterClass;\n    private List<PhaseConfig> phaseConfigList;\n    private MonitoringConfig monitoringConfig;\n\n    public SolverConfig inherit(SolverConfig inheritedConfig) {\n        this.environmentMode = inheritedConfig.environmentMode;\n        this.daemon = inheritedConfig.daemon;\n        this.randomType = inheritedConfig.randomType;\n        this.randomSeed = inheritedConfig.randomSeed;\n        this.randomFactoryClass = inheritedConfig.randomFactoryClass;\n        this.moveThreadCount = inheritedConfig.moveThreadCount;\n        this.moveThreadBufferSize = inheritedConfig.moveThreadBufferSize;\n        this.threadFactoryClass = inheritedConfig.threadFactoryClass;\n        this.solutionClass = inheritedConfig.solutionClass;\n        this.entityClassList = inheritedConfig.entityClassList;\n        this.domainAccessType = inheritedConfig.domainAccessType;\n        this.gizmoMemberAccessorMap = inheritedConfig.gizmoMemberAccessorMap;\n        this.gizmoSolutionClonerMap = inheritedConfig.gizmoSolutionClonerMap;\n        this.scoreDirectorFactoryConfig = inheritedConfig.scoreDirectorFactoryConfig;\n        this.terminationConfig = inheritedConfig.terminationConfig;\n        this.nearbyDistanceMeterClass = inheritedConfig.nearbyDistanceMeterClass;\n        this.phaseConfigList = inheritedConfig.phaseConfigList;\n        this.monitoringConfig = inheritedConfig.monitoringConfig;\n        return this;\n    }\n}\n```", "  ```\n@Override\npublic SolverConfig inherit(SolverConfig inheritedConfig) {\n    Objects.requireNonNull(inheritedConfig, \"Inherited config should not be null.\");\n    inheritedConfig.visitReferencedClasses(partitionedSearchPhaseConfig -> {});\n    return inheritedConfig;\n}\n```"]}, "timefold-solver-core/src/main/java/ai/timefold/solver/core/config/util/ConfigUtils.java-meldProperty": {"final_query": "# You are a professional programmer, please create a function based on the function signature and natural language annotations# Here is the related information in the same file:../repo/java_data/timefold-solver/core/src/main/java/ai/timefold/solver/core/config/util/ConfigUtils.java:\n```\npackage ai.timefold.solver.core.config.util;\n\nimport static ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessorFactory.MemberAccessorType.FIELD_OR_READ_METHOD;\n\nimport java.lang.annotation.Annotation;\nimport java.lang.reflect.AnnotatedElement;\nimport java.lang.reflect.Field;\nimport java.lang.reflect.InvocationTargetException;\nimport java.lang.reflect.Member;\nimport java.lang.reflect.Method;\nimport java.lang.reflect.Modifier;\nimport java.lang.reflect.ParameterizedType;\nimport java.lang.reflect.Type;\nimport java.lang.reflect.WildcardType;\nimport java.math.BigDecimal;\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.LinkedHashMap;\nimport java.util.LinkedHashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Optional;\nimport java.util.Set;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\nimport java.util.stream.Stream;\n\nimport ai.timefold.solver.core.api.domain.common.DomainAccessType;\nimport ai.timefold.solver.core.api.domain.lookup.PlanningId;\nimport ai.timefold.solver.core.config.AbstractConfig;\nimport ai.timefold.solver.core.impl.domain.common.AlphabeticMemberComparator;\nimport ai.timefold.solver.core.impl.domain.common.ReflectionHelper;\nimport ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessor;\nimport ai.timefold.solver.core.impl.domain.common.accessor.MemberAccessorFactory;\n\npublic class ConfigUtils {\n\n    private static final AlphabeticMemberComparator alphabeticMemberComparator = new AlphabeticMemberComparator();\n\n    /**\n     * Create a new instance of clazz from a config's property.\n     * <p>\n     * If the instantiation fails, the simple class name of {@code configBean} will be used as the owner of\n     * {@code propertyName}.\n     * <p>\n     * Intended usage:\n     *\n     * <pre>\n     * selectionFilter = ConfigUtils.newInstance(config, \"filterClass\", config.getFilterClass());\n     * </pre>\n     *\n     * @param configBean the bean holding the {@code clazz} to be instantiated\n     * @param propertyName {@code configBean}'s property holding {@code clazz}\n     * @param clazz {@code Class} representation of the type {@code T}\n     * @param <T> the new instance type\n     * @return new instance of clazz\n     */\n    public static <T> T newInstance(Object configBean, String propertyName, Class<T> clazz) {\n        return newInstance(() -> (configBean == null ? \"?\" : configBean.getClass().getSimpleName()), propertyName, clazz);\n    }\n\n    /**\n     * Create a new instance of clazz from a general source.\n     * <p>\n     * If the instantiation fails, the result of {@code ownerDescriptor} will be used to describe the owner of\n     * {@code propertyName}.\n     *\n     * @param ownerDescriptor describes the owner of {@code propertyName}\n     * @param propertyName property holding the {@code clazz}\n     * @param clazz {@code Class} representation of the type {@code T}\n     * @param <T> the new instance type\n     * @return new instance of clazz\n     */\n    public static <T> T newInstance(Supplier<String> ownerDescriptor, String propertyName, Class<T> clazz) {\n        try {\n            return clazz.getDeclaredConstructor().newInstance();\n        } catch (NoSuchMethodException | InstantiationException | IllegalAccessException | InvocationTargetException e) {\n            throw new IllegalArgumentException(\"The \" + ownerDescriptor.get() + \"'s \" + propertyName + \" (\"\n                    + clazz.getName() + \") does not have a public no-arg constructor\"\n                    // Inner classes include local, anonymous and non-static member classes\n                    + ((clazz.isLocalClass() || clazz.isAnonymousClass() || clazz.isMemberClass())\n                            && !Modifier.isStatic(clazz.getModifiers()) ? \" because it is an inner class.\" : \".\"),\n                    e);\n        }\n    }\n\n    public static void applyCustomProperties(Object bean, String beanClassPropertyName,\n            Map<String, String> customProperties, String customPropertiesPropertyName) {\n        if (customProperties == null) {\n            return;\n        }\n        var beanClass = bean.getClass();\n        customProperties.forEach((propertyName, valueString) -> {\n            var setterMethod = ReflectionHelper.getSetterMethod(beanClass, propertyName);\n            if (setterMethod == null) {\n                throw new IllegalStateException(\"The custom property \" + propertyName + \" (\" + valueString\n                        + \") in the \" + customPropertiesPropertyName\n                        + \" cannot be set on the \" + beanClassPropertyName + \" (\" + beanClass\n                        + \") because that class has no public setter for that property.\\n\"\n                        + \"Maybe add a public setter for that custom property (\" + propertyName\n                        + \") on that class (\" + beanClass.getSimpleName() + \").\\n\"\n                        + \"Maybe don't configure that custom property \" + propertyName + \" (\" + valueString\n                        + \") in the \" + customPropertiesPropertyName + \".\");\n            }\n            var propertyType = setterMethod.getParameterTypes()[0];\n            Object typedValue;\n            try {\n                if (propertyType.equals(String.class)) {\n                    typedValue = valueString;\n                } else if (propertyType.equals(Boolean.TYPE) || propertyType.equals(Boolean.class)) {\n                    typedValue = Boolean.parseBoolean(valueString);\n                } else if (propertyType.equals(Integer.TYPE) || propertyType.equals(Integer.class)) {\n                    typedValue = Integer.parseInt(valueString);\n                } else if (propertyType.equals(Long.TYPE) || propertyType.equals(Long.class)) {\n                    typedValue = Long.parseLong(valueString);\n                } else if (propertyType.equals(Float.TYPE) || propertyType.equals(Float.class)) {\n                    typedValue = Float.parseFloat(valueString);\n                } else if (propertyType.equals(Double.TYPE) || propertyType.equals(Double.class)) {\n                    typedValue = Double.parseDouble(valueString);\n                } else if (propertyType.equals(BigDecimal.class)) {\n                    typedValue = new BigDecimal(valueString);\n                } else if (propertyType.isEnum()) {\n                    typedValue = Enum.valueOf((Class<? extends Enum>) propertyType, valueString);\n                } else {\n                    throw new IllegalStateException(\"The custom property \" + propertyName + \" (\" + valueString\n                            + \") in the \" + customPropertiesPropertyName\n                            + \" has an unsupported propertyType (\" + propertyType + \") for value (\" + valueString + \").\");\n                }\n            } catch (NumberFormatException e) {\n                throw new IllegalStateException(\"The custom property \" + propertyName + \" (\" + valueString\n                        + \") in the \" + customPropertiesPropertyName\n                        + \" cannot be parsed to the propertyType (\" + propertyType\n                        + \") of the setterMethod (\" + setterMethod + \").\");\n            }\n            try {\n                setterMethod.invoke(bean, typedValue);\n            } catch (IllegalAccessException e) {\n                throw new IllegalStateException(\"The custom property \" + propertyName + \" (\" + valueString\n                        + \") in the \" + customPropertiesPropertyName\n                        + \" has a setterMethod (\" + setterMethod + \") on the beanClass (\" + beanClass\n                        + \") that cannot be called for the typedValue (\" + typedValue + \").\", e);\n            } catch (InvocationTargetException e) {\n                throw new IllegalStateException(\"The custom property \" + propertyName + \" (\" + valueString\n                        + \") in the \" + customPropertiesPropertyName\n                        + \" has a setterMethod (\" + setterMethod + \") on the beanClass (\" + beanClass\n                        + \") that throws an exception for the typedValue (\" + typedValue + \").\",\n                        e.getCause());\n            }\n        });\n    }\n\n    public static <Config_ extends AbstractConfig<Config_>> Config_ inheritConfig(Config_ original, Config_ inherited) {\n        if (inherited != null) {\n            if (original == null) {\n                original = inherited.copyConfig();\n            } else {\n                original.inherit(inherited);\n            }\n        }\n        return original;\n    }\n\n    public static <Config_ extends AbstractConfig<Config_>> List<Config_> inheritMergeableListConfig(\n            List<Config_> originalList, List<Config_> inheritedList) {\n        if (inheritedList != null) {\n            List<Config_> mergedList = new ArrayList<>(inheritedList.size()\n                    + (originalList == null ? 0 : originalList.size()));\n            // The inheritedList should be before the originalList\n            for (var inherited : inheritedList) {\n                var copy = inherited.copyConfig();\n                mergedList.add(copy);\n            }\n            if (originalList != null) {\n                mergedList.addAll(originalList);\n            }\n            originalList = mergedList;\n        }\n        return originalList;\n    }\n\n    public static <T> T inheritOverwritableProperty(T original, T inherited) {\n        if (original != null) {\n            // Original overwrites inherited\n            return original;\n        } else {\n            return inherited;\n        }\n    }\n\n    public static <T> List<T> inheritMergeableListProperty(List<T> originalList, List<T> inheritedList) {\n        if (inheritedList == null) {\n            return originalList;\n        } else if (originalList == null) {\n            // Shallow clone due to modifications after calling inherit\n            return new ArrayList<>(inheritedList);\n        } else {\n            // The inheritedList should be before the originalList\n            List<T> mergedList = new ArrayList<>(inheritedList);\n            mergedList.addAll(originalList);\n            return mergedList;\n        }\n    }\n\n    public static <T> List<T> inheritUniqueMergeableListProperty(List<T> originalList, List<T> inheritedList) {\n        if (inheritedList == null) {\n            return originalList;\n        } else if (originalList == null) {\n            // Shallow clone due to modifications after calling inherit\n            return new ArrayList<>(inheritedList);\n        } else {\n            // The inheritedMap should be before the originalMap\n            Set<T> mergedSet = new LinkedHashSet<>(inheritedList);\n            mergedSet.addAll(originalList);\n            return new ArrayList<>(mergedSet);\n        }\n    }\n\n    public static <K, T> Map<K, T> inheritMergeableMapProperty(Map<K, T> originalMap, Map<K, T> inheritedMap) {\n        if (inheritedMap == null) {\n            return originalMap;\n        } else if (originalMap == null) {\n            return inheritedMap;\n        } else {\n            Map<K, T> mergedMap = new LinkedHashMap<>(inheritedMap);\n            mergedMap.putAll(originalMap);\n            return mergedMap;\n        }\n    }\n\n    public static <T> T mergeProperty(T a, T b) {\n        return Objects.equals(a, b) ? a : null;\n    }\n\n    /**\n     * A relaxed version of {@link #mergeProperty(Object, Object)}. Used primarily for merging failed benchmarks,\n     * where a property remains the same over benchmark runs (for example: dataset problem size), but the property in\n     * the failed benchmark isn't initialized, therefore null. When merging, we can still use the correctly initialized\n     * property of the benchmark that didn't fail.\n     * <p>\n     * Null-handling:\n     * <ul>\n     * <li>if <strong>both</strong> properties <strong>are null</strong>, returns null</li>\n     * <li>if <strong>only one</strong> of the properties <strong>is not null</strong>, returns that property</li>\n     * <li>if <strong>both</strong> properties <strong>are not null</strong>, returns\n     * {@link #mergeProperty(Object, Object)}</li>\n     * </ul>\n     *\n     * @see #mergeProperty(Object, Object)\n     * @param a property {@code a}\n     * @param b property {@code b}\n     * @param <T> the type of property {@code a} and {@code b}\n     * @return sometimes null\n     */\n\n\n\n\n\n\n\n\n\n\n\n\n\n    public static boolean isEmptyCollection(Collection<?> collection) {\n        return collection == null || collection.isEmpty();\n    }\n\n    /**\n     * Divides and ceils the result without using floating point arithmetic. For floor division,\n     * see {@link Math#floorDiv(long, long)}.\n     *\n     * @throws ArithmeticException if {@code divisor == 0}\n     * @param dividend the dividend\n     * @param divisor the divisor\n     * @return dividend / divisor, ceiled\n     */\n    public static int ceilDivide(int dividend, int divisor) {\n        if (divisor == 0) {\n            throw new ArithmeticException(\"Cannot divide by zero: \" + dividend + \"/\" + divisor);\n        }\n        int correction;\n        if (dividend % divisor == 0) {\n            correction = 0;\n        } else if (Integer.signum(dividend) * Integer.signum(divisor) < 0) {\n            correction = 0;\n        } else {\n            correction = 1;\n        }\n        return (dividend / divisor) + correction;\n    }\n\n    public static int resolvePoolSize(String propertyName, String value, String... magicValues) {\n        try {\n            return Integer.parseInt(value);\n        } catch (NumberFormatException ex) {\n            throw new IllegalStateException(\"The \" + propertyName + \" (\" + value + \") resolved to neither of (\"\n                    + Arrays.toString(magicValues) + \") nor a number.\");\n        }\n    }\n\n    // ************************************************************************\n    // Member and annotation methods\n    // ************************************************************************\n\n    public static List<Class<?>> getAllParents(Class<?> bottomClass) {\n        if (bottomClass == null || bottomClass == Object.class) {\n            return Collections.emptyList();\n        }\n        var superclass = bottomClass.getSuperclass();\n        var lineageClassList = new ArrayList<>(getAllParents(superclass));\n        for (var superInterface : bottomClass.getInterfaces()) {\n            lineageClassList.addAll(getAllParents(superInterface));\n        }\n        lineageClassList.add(bottomClass);\n        return lineageClassList;\n    }\n\n    public static List<Class<?>> getAllAnnotatedLineageClasses(Class<?> bottomClass,\n            Class<? extends Annotation> annotation) {\n        if (bottomClass == null || !bottomClass.isAnnotationPresent(annotation)) {\n            return Collections.emptyList();\n        }\n        List<Class<?>> lineageClassList = new ArrayList<>();\n        lineageClassList.add(bottomClass);\n        var superclass = bottomClass.getSuperclass();\n        lineageClassList.addAll(getAllAnnotatedLineageClasses(superclass, annotation));\n        for (var superInterface : bottomClass.getInterfaces()) {\n            lineageClassList.addAll(getAllAnnotatedLineageClasses(superInterface, annotation));\n        }\n        return lineageClassList;\n    }\n\n    /**\n     * @param baseClass never null\n     * @return never null, sorted by type (fields before methods), then by {@link AlphabeticMemberComparator}.\n     */\n    public static List<Member> getDeclaredMembers(Class<?> baseClass) {\n        var fieldStream = Stream.of(baseClass.getDeclaredFields())\n                // A synthetic field is a field generated by the compiler that\n                // does not exist in the source code. It is used mainly in\n                // nested classes so the inner class can access the fields\n                // of the outer class.\n                .filter(field -> !field.isSynthetic())\n                .sorted(alphabeticMemberComparator);\n        var methodStream = Stream.of(baseClass.getDeclaredMethods())\n                // A synthetic method is a method generated by the compiler that does\n                // not exist in the source code. These include bridge methods.\n                // A bridge method is a generic variant that duplicates a concrete method\n                // Example: \"Score getScore()\" that duplicates \"HardSoftScore getScore()\"\n                .filter(method -> !method.isSynthetic())\n                .sorted(alphabeticMemberComparator);\n        return Stream.concat(fieldStream, methodStream)\n                .collect(Collectors.toList());\n    }\n\n    /**\n     * @param baseClass never null\n     * @param annotationClass never null\n     * @return never null, sorted by type (fields before methods), then by {@link AlphabeticMemberComparator}.\n     */\n    public static List<Member> getAllMembers(Class<?> baseClass, Class<? extends Annotation> annotationClass) {\n        var clazz = baseClass;\n        Stream<Member> memberStream = Stream.empty();\n        while (clazz != null) {\n            var fieldStream = Stream.of(clazz.getDeclaredFields())\n                    .filter(field -> field.isAnnotationPresent(annotationClass) && !field.isSynthetic())\n                    .sorted(alphabeticMemberComparator);\n            var methodStream = Stream.of(clazz.getDeclaredMethods())\n                    .filter(method -> method.isAnnotationPresent(annotationClass) && !method.isSynthetic())\n                    .sorted(alphabeticMemberComparator);\n            memberStream = Stream.concat(memberStream, Stream.concat(fieldStream, methodStream));\n            clazz = clazz.getSuperclass();\n        }\n        return memberStream.collect(Collectors.toList());\n    }\n\n    @SafeVarargs\n    public static Class<? extends Annotation> extractAnnotationClass(Member member,\n            Class<? extends Annotation>... annotationClasses) {\n        Class<? extends Annotation> annotationClass = null;\n        for (var detectedAnnotationClass : annotationClasses) {\n            if (((AnnotatedElement) member).isAnnotationPresent(detectedAnnotationClass)) {\n                if (annotationClass != null) {\n                    throw new IllegalStateException(\"The class (\" + member.getDeclaringClass()\n                            + \") has a member (\" + member + \") that has both a @\"\n                            + annotationClass.getSimpleName() + \" annotation and a @\"\n                            + detectedAnnotationClass.getSimpleName() + \" annotation.\");\n                }\n                annotationClass = detectedAnnotationClass;\n                // Do not break early: check other annotationClasses too\n            }\n        }\n        return annotationClass;\n    }\n\n    public static Class<?> extractGenericTypeParameterOrFail(String parentClassConcept, Class<?> parentClass, Class<?> type,\n            Type genericType, Class<? extends Annotation> annotationClass, String memberName) {\n        return extractGenericTypeParameter(parentClassConcept, parentClass, type, genericType, annotationClass, memberName)\n                .orElseThrow(() -> new IllegalArgumentException(\"\"\"\n                        The %s (%s) has a %s member (%s) with a member type (%s) which has no generic parameters.\n                        Maybe the member (%s) should return a parameterized %s.\"\"\"\n                        .formatted(parentClassConcept, parentClass,\n                                annotationClass == null ? \"auto discovered\"\n                                        : \"@\" + annotationClass.getSimpleName() + \" annotated\",\n                                memberName, type, memberName, type.getSimpleName())));\n    }\n\n    public static Optional<Class<?>> extractGenericTypeParameter(String parentClassConcept, Class<?> parentClass, Class<?> type,\n            Type genericType, Class<? extends Annotation> annotationClass, String memberName) {\n        if (!(genericType instanceof ParameterizedType parameterizedType)) {\n            return Optional.empty();\n        }\n        var typeArguments = parameterizedType.getActualTypeArguments();\n        if (typeArguments.length != 1) {\n            throw new IllegalArgumentException(\"\"\"\n                    The %s (%s) has a %s member (%s) with a member type (%s) which is a parameterized collection \\\n                    with an unsupported number of generic parameters (%s).\"\"\"\n                    .formatted(parentClassConcept, parentClass,\n                            annotationClass == null ? \"auto discovered\" : \"@\" + annotationClass.getSimpleName() + \" annotated\",\n                            memberName, type, typeArguments.length));\n        }\n        var typeArgument = typeArguments[0];\n        if (typeArgument instanceof ParameterizedType parameterizedTypeArgument) {\n            // Remove the type parameters, so it can be cast to a Class.\n            typeArgument = parameterizedTypeArgument.getRawType();\n        }\n        if (typeArgument instanceof WildcardType wildcardType) {\n            var upperBounds = wildcardType.getUpperBounds();\n            typeArgument = switch (upperBounds.length) {\n                case 0 -> Object.class;\n                case 1 -> upperBounds[0];\n                // Multiple upper bounds are impossible in traditional Java.\n                // Other JVM languages or future java versions might enable triggering this.\n                default -> throw new IllegalArgumentException(\"\"\"\n                        The %s (%s) has a %s  member (%s) with a member type (%s) which is a parameterized collection \\\n                        with a wildcard type argument (%s) that has multiple upper bounds (%s).\n                        Maybe don't use wildcards with multiple upper bounds for the member (%s).\"\"\"\n                        .formatted(parentClassConcept, parentClass,\n                                annotationClass == null ? \"auto discovered\"\n                                        : \"@\" + annotationClass.getSimpleName() + \" annotated\",\n                                memberName, type, typeArgument, Arrays.toString(upperBounds), memberName));\n            };\n        }\n        if (typeArgument instanceof Class<?> class1) {\n            return Optional.of(class1);\n        } else if (typeArgument instanceof ParameterizedType parameterizedTypeArgument) {\n            // Turns SomeGenericType<T> into SomeGenericType.\n            return Optional.of((Class<?>) parameterizedTypeArgument.getRawType());\n        } else {\n            throw new IllegalArgumentException(\"\"\"\n                    The %s (%s) has a %s member (%s) with a member type (%s) which is a parameterized collection \\\n                    with a type argument (%s) that is not a class or interface.\"\"\"\n                    .formatted(parentClassConcept, parentClass,\n                            annotationClass == null ? \"auto discovered\" : \"@\" + annotationClass.getSimpleName() + \" annotated\",\n                            memberName, type, typeArgument));\n        }\n    }\n\n    /**\n     * This method is heavy, and it is effectively a computed constant.\n     * It is recommended that its results are cached at call sites.\n     *\n     * @param clazz never null\n     * @param memberAccessorFactory never null\n     * @param domainAccessType never null\n     * @return null if no accessor found\n     * @param <C> the class type\n     */\n    public static <C> MemberAccessor findPlanningIdMemberAccessor(Class<C> clazz,\n            MemberAccessorFactory memberAccessorFactory, DomainAccessType domainAccessType) {\n        var member = getSingleMember(clazz, PlanningId.class);\n        if (member == null) {\n            return null;\n        }\n        var memberAccessor =\n                memberAccessorFactory.buildAndCacheMemberAccessor(member, FIELD_OR_READ_METHOD, PlanningId.class,\n                        domainAccessType);\n        assertPlanningIdMemberIsComparable(clazz, member, memberAccessor);\n        return memberAccessor;\n    }\n\n    private static void assertPlanningIdMemberIsComparable(Class<?> clazz, Member member, MemberAccessor memberAccessor) {\n        if (!memberAccessor.getType().isPrimitive() && !Comparable.class.isAssignableFrom(memberAccessor.getType())) {\n            throw new IllegalArgumentException(\"The class (\" + clazz\n                    + \") has a member (\" + member + \") with a @\" + PlanningId.class.getSimpleName()\n                    + \" annotation that returns a type (\" + memberAccessor.getType()\n                    + \") that does not implement \" + Comparable.class.getSimpleName() + \".\\n\"\n                    + \"Maybe use a \" + Long.class.getSimpleName()\n                    + \" or \" + String.class.getSimpleName() + \" type instead.\");\n        }\n    }\n\n    private static <C> Member getSingleMember(Class<C> clazz, Class<? extends Annotation> annotationClass) {\n        var memberList = getAllMembers(clazz, annotationClass);\n        if (memberList.isEmpty()) {\n            return null;\n        }\n        var size = memberList.size();\n        if (clazz.isRecord()) {\n            /*\n             * A record has a field and a getter for each record component.\n             * When the component is annotated with @PlanningId,\n             * the annotation ends up both on the field and on the getter.\n             */\n            if (size == 2) { // The getter is used to retrieve the value of the record component.\n                var methodMembers = getMembers(memberList, true);\n                if (methodMembers.isEmpty()) {\n                    throw new IllegalStateException(\"Impossible state: record (%s) doesn't have any method members (%s).\"\n                            .formatted(clazz.getCanonicalName(), memberList));\n                }\n                return methodMembers.get(0);\n            } else { // There is more than one component annotated with @PlanningId; take the fields and fail.\n                var componentList = getMembers(memberList, false)\n                        .stream()\n                        .map(Member::getName)\n                        .toList();\n                throw new IllegalArgumentException(\"The record (%s) has %s components (%s) with %s annotation.\"\n                       \n```\n# Function Signature: public static <T> T meldProperty(T a, T b) {\n# Natural Language Annotations: /**\n     * A relaxed version of {@link #mergeProperty(Object, Object)}. Used primarily for merging failed benchmarks,\n     * where a property remains the same over benchmark runs (for example: dataset problem size), but the property in\n     * the failed benchmark isn't initialized, therefore null. When merging, we can still use the correctly initialized\n     * property of the benchmark that didn't fail.\n     * <p>\n     * Null-handling:\n     * <ul>\n     * <li>if <strong>both</strong> properties <strong>are null</strong>, returns null</li>\n     * <li>if <strong>only one</strong> of the properties <strong>is not null</strong>, returns that property</li>\n     * <li>if <strong>both</strong> properties <strong>are not null</strong>, returns\n     * {@link #mergeProperty(Object, Object)}</li>\n     * </ul>\n     *\n     * @see #mergeProperty(Object, Object)\n     * @param a property {@code a}\n     * @param b property {@code b}\n     * @param <T> the type of property {@code a} and {@code b}\n     * @return sometimes null\n     */\nPlease return the generated code surrounded by ```\n", "response": ["  ```\npublic static <T> T meldProperty(T a, T b) {\n    if (a == null && b == null) {\n        return null;\n    } else if (a == null) {\n        return b;\n    } else if (b == null) {\n        return a;\n    } else {\n        return Objects.equals(a, b) ? a : null;\n    }\n}\n```", "  ```\npublic static <T> T meldProperty(T a, T b) {\n    return Objects.equals(a, b) ? a : (a == null ? b : a);\n}\n```", "  ```\npublic static <T> T meldProperty(T a, T b) {\n    if (a == b) {\n        return a;\n    }\n    if (a != null) {\n        return a;\n    }\n    if (b != null) {\n        return b;\n    }\n    return null;\n}\n```"]}}