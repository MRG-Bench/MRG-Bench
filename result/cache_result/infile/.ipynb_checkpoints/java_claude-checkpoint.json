{"langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoader.java-loadDocuments": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static List<Document> loadDocuments(Path directoryPath, DocumentParser documentParser) {\n    if (!isDirectory(directoryPath)) {\n        throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n    }\n\n    List<Document> documents = new ArrayList<>();\n\n    try (Stream<Path> pathStream = Files.list(directoryPath)) {\n        pathStream\n                .filter(Files::isRegularFile)\n                .forEach(file -> {\n                    try {\n                        Document document = loadDocument(file, documentParser);\n                        documents.add(document);\n                    } catch (BlankDocumentException ignored) {\n                        // blank/empty documents are ignored\n                    } catch (Exception e) {\n                        String message = e.getCause() != null ? e.getCause().getMessage() : e.getMessage();\n                        log.warn(\"Failed to load '{}': {}\", file, message);\n                    }\n                });\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n    return documents;\n}\n```\n\nThis function does the following:\n\n1. It checks if the provided `directoryPath` is a directory using the `isDirectory` method. If it's not a directory, it throws an `IllegalArgumentException` with a descriptive message.\n\n2. It creates an empty `List<Document>` called `documents` to store the loaded documents.\n\n3. It opens a `Stream<Path>` using `Files.list(directoryPath)` to get a stream of paths in the specified directory. The stream is wrapped in a try-with-resources block to ensure proper resource handling.\n\n4. It filters the stream to include only regular files using `Files::isRegularFile`.\n\n5. For each file in the filtered stream, it attempts to load the document using the `loadDocument` method with the file path and the provided `documentParser`. If the document is successfully loaded, it is added to the `documents` list.\n\n6. If a `BlankDocumentException` occurs during document loading, it is ignored, and the blank/empty document is skipped.\n\n7. If any other exception occurs during document loading, the exception message is logged using `log.warn`, and the loading of that particular document is skipped.\n\n8. If an `IOException` occurs while opening the stream of paths, it is caught and wrapped in a `RuntimeException`.\n\n9. Finally, the function returns the list of loaded documents.\n\nThis function loads documents from the specified directory using the provided document parser, skipping any documents that fail to load, and returns the list of successfully loaded documents.", "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/loader/FileSystemDocumentLoader.java-loadDocumentsRecursively": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static List<Document> loadDocumentsRecursively(Path directoryPath, DocumentParser documentParser) {\n    if (!isDirectory(directoryPath)) {\n        throw illegalArgument(\"'%s' is not a directory\", directoryPath);\n    }\n\n    List<Document> documents = new ArrayList<>();\n\n    try (Stream<Path> pathStream = Files.walk(directoryPath)) {\n        pathStream\n                .filter(Files::isRegularFile)\n                .forEach(file -> {\n                    try {\n                        Document document = loadDocument(file, documentParser);\n                        documents.add(document);\n                    } catch (BlankDocumentException ignored) {\n                        // blank/empty documents are ignored\n                    } catch (Exception e) {\n                        String message = e.getCause() != null ? e.getCause().getMessage() : e.getMessage();\n                        log.warn(\"Failed to load '{}': {}\", file, message);\n                    }\n                });\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n    return documents;\n}\n```\n\nThis function does the following:\n\n1. It checks if the provided `directoryPath` is actually a directory. If not, it throws an `IllegalArgumentException` with an appropriate message.\n\n2. It creates an empty list called `documents` to store the loaded `Document` objects.\n\n3. It uses `Files.walk()` to recursively traverse the directory tree starting from `directoryPath`. The resulting `Stream<Path>` is wrapped in a try-with-resources block to ensure proper resource handling.\n\n4. It filters the `pathStream` to include only regular files using `Files::isRegularFile`.\n\n5. For each file, it attempts to load a `Document` using the `loadDocument()` method with the provided `documentParser`. If successful, the loaded `Document` is added to the `documents` list.\n\n6. If a `BlankDocumentException` is thrown during document loading, it is ignored, and the blank/empty document is skipped.\n\n7. If any other exception occurs during document loading, it logs a warning message with the file path and the exception message.\n\n8. If an `IOException` occurs during directory traversal, it is wrapped in a `RuntimeException` and rethrown.\n\n9. Finally, it returns the list of loaded `Document` objects.\n\nThis function recursively loads documents from the specified directory and its subdirectories, skipping any documents that fail to load and logging a warning message for each failure.", "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java-hasSpaceFor": "Here is the generated code for the `hasSpaceFor(String text)` method:\n\n```java\n/**\n * Returns {@code true} if the provided text can be added to the current segment.\n * @param text The text to check.\n * @return {@code true} if the provided text can be added to the current segment.\n */\npublic boolean hasSpaceFor(String text) {\n    int textSize = sizeOf(text);\n    return hasSpaceFor(textSize);\n}\n```", "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java-append": "Here is the generated code for the `append` method:\n\n```java\n/**\n * Appends the provided text to the current segment.\n * @param text The text to append.\n */\npublic void append(String text) {\n    if (isNotEmpty()) {\n        segment += joinSeparator;\n        segmentSize += joinSeparatorSize;\n    }\n    segment += text;\n    segmentSize += sizeOf(text);\n}\n```", "langchain4j-langchain4j/src/main/java/dev/langchain4j/data/document/splitter/SegmentBuilder.java-prepend": "Here is the generated code for the `prepend` method:\n\n```java\n/**\n * Prepends the provided text to the current segment.\n * @param text The text to prepend.\n */\npublic void prepend(String text) {\n    int size = sizeOf(text);\n    if (hasSpaceFor(size)) {\n        if (isNotEmpty()) {\n            segment = text + joinSeparator + segment;\n            segmentSize += size + joinSeparatorSize;\n        } else {\n            segment = text;\n            segmentSize = size;\n        }\n    } else {\n        throw new IllegalArgumentException(\"Cannot prepend text: segment size limit exceeded\");\n    }\n}\n```\n\nThe `prepend` method does the following:\n\n1. It calculates the size of the provided `text` using the `sizeOf` method.\n\n2. It checks if there is enough space in the current segment to accommodate the `text` using the `hasSpaceFor` method.\n\n3. If there is enough space:\n   - If the current segment is not empty, it prepends the `text` to the current segment with the `joinSeparator` in between, and updates the `segmentSize` by adding the size of the `text` and the size of the `joinSeparator`.\n   - If the current segment is empty, it sets the current segment to the `text` and updates the `segmentSize` to the size of the `text`.\n\n4. If there is not enough space, it throws an `IllegalArgumentException` indicating that the segment size limit has been exceeded.\n\nThis method allows prepending text to the current segment while ensuring that the segment size does not exceed the maximum allowed size.", "langchain4j-langchain4j/src/main/java/dev/langchain4j/service/AiServices.java-retriever": null, "langchain4j-langchain4j/src/main/java/dev/langchain4j/service/AiServices.java-contentRetriever": "Here is the generated code for the `contentRetriever` method based on the provided function signature and natural language annotations:\n\n```java\npublic AiServices<T> contentRetriever(ContentRetriever contentRetriever) {\n    if (retrieverSet || retrievalAugmentorSet) {\n        throw illegalConfiguration(\"Only one out of [retriever, contentRetriever, retrievalAugmentor] can be set\");\n    }\n    contentRetrieverSet = true;\n    context.retrievalAugmentor = new DefaultRetrievalAugmentor(ensureNotNull(contentRetriever, \"contentRetriever\"));\n    return this;\n}\n```", "langchain4j-langchain4j-pgvector/src/main/java/dev/langchain4j/store/embedding/pgvector/PgVectorEmbeddingStore.java-add": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\n@Override\npublic String add(Embedding embedding) {\n    String id = randomUUID();\n    addInternal(id, embedding, null);\n    return id;\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java-toolSpecificationsFrom": null, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java-toolSpecificationFrom": null, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/agent/tool/ToolSpecifications.java-toJsonSchemaProperties": null, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/store/embedding/CosineSimilarity.java-between": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static double between(Embedding embeddingA, Embedding embeddingB) {\n    ensureNotNull(embeddingA, \"embeddingA\");\n    ensureNotNull(embeddingB, \"embeddingB\");\n\n    if (embeddingA.dimensions() != embeddingB.dimensions()) {\n        throw illegalArgument(\"Embeddings must have the same dimensions\");\n    }\n\n    double dotProduct = 0.0;\n    double normA = 0.0;\n    double normB = 0.0;\n\n    for (int i = 0; i < embeddingA.dimensions(); i++) {\n        double valueA = embeddingA.get(i);\n        double valueB = embeddingB.get(i);\n        dotProduct += valueA * valueB;\n        normA += valueA * valueA;\n        normB += valueB * valueB;\n    }\n\n    if (normA < EPSILON || normB < EPSILON) {\n        // Embeddings of all-zeros vectors are considered orthogonal to all other vectors\n        return 0.0;\n    }\n\n    double cosineSimilarity = dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));\n    return Math.max(-1.0, Math.min(1.0, cosineSimilarity));\n}\n```\n\nThis function calculates the cosine similarity between two embedding vectors:\n\n1. It first ensures that both `embeddingA` and `embeddingB` are not null.\n\n2. It checks if the dimensions of both embeddings are the same. If not, it throws an `IllegalArgumentException`.\n\n3. It initializes variables to store the dot product and the norms of the embeddings.\n\n4. It iterates over the dimensions of the embeddings, calculating the dot product and the norms.\n\n5. If either of the norms is close to zero (less than `EPSILON`), it means one or both embeddings are all-zeros vectors. In this case, it returns 0.0 as the cosine similarity, considering them orthogonal.\n\n6. It calculates the cosine similarity by dividing the dot product by the product of the square roots of the norms.\n\n7. Finally, it clamps the cosine similarity value to the range [-1..1] using `Math.max` and `Math.min`, and returns the result.\n\nThe function follows the provided natural language annotations, handling the case of all-zeros vectors and returning the cosine similarity in the range [-1..1].", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/data/document/Metadata.java-asMap": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n/**\n * Get a copy of the metadata as a map of key-value pairs.\n *\n * @return the metadata as a map of key-value pairs.\n * @deprecated as of 0.31.0, use {@link #toMap()} instead.\n */\n@Deprecated\npublic Map<String, String> asMap() {\n    Map<String, String> metadataMap = new HashMap<>();\n    for (Map.Entry<String, Object> entry : metadata.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        metadataMap.put(key, value.toString());\n    }\n    return metadataMap;\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/data/document/DocumentLoader.java-load": null, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/data/message/UserMessage.java-singleText": "Here is the generated code for the `singleText()` function based on the provided function signature and natural language annotations:\n\n```java\npublic String singleText() {\n    if (!hasSingleText()) {\n        throw runtime(\"Expected a single text content, but found: \" + contents);\n    }\n    return ((TextContent) contents.get(0)).text();\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/rag/RetrievalAugmentor.java-augment": "Here is the generated code for the `augment` method based on the provided function signature and natural language annotations:\n\n```java\ndefault AugmentationResult augment(AugmentationRequest augmentationRequest) {\n    ChatMessage chatMessage = augmentationRequest.getChatMessage();\n    if (!(chatMessage instanceof UserMessage)) {\n        throw runtime(\"Only UserMessage is supported for augmentation.\");\n    }\n    UserMessage userMessage = (UserMessage) chatMessage;\n    Metadata metadata = augmentationRequest.getMetadata();\n\n    UserMessage augmentedUserMessage = augment(userMessage, metadata);\n\n    return AugmentationResult.builder()\n            .setChatMessage(augmentedUserMessage)\n            .build();\n}\n```\n\nThis default implementation of the `augment` method:\n1. Extracts the `ChatMessage` from the provided `AugmentationRequest`.\n2. Checks if the `ChatMessage` is an instance of `UserMessage`. If not, it throws a runtime exception indicating that only `UserMessage` is supported for augmentation.\n3. Casts the `ChatMessage` to `UserMessage`.\n4. Extracts the `Metadata` from the `AugmentationRequest`.\n5. Calls the deprecated `augment(UserMessage, Metadata)` method to perform the actual augmentation of the `UserMessage`.\n6. Builds and returns an `AugmentationResult` containing the augmented `UserMessage`.\n\nNote: This default implementation is temporary and will be removed soon. It is provided to support current custom implementations of `RetrievalAugmentor`. The preferred approach is to directly implement the `augment(AugmentationRequest)` method instead.", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/rag/DefaultRetrievalAugmentor.java-augment": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\n@Override\n@Deprecated\npublic UserMessage augment(UserMessage userMessage, Metadata metadata) {\n    AugmentationRequest augmentationRequest = AugmentationRequest.builder()\n            .chatMessage(userMessage)\n            .metadata(metadata)\n            .build();\n    AugmentationResult augmentationResult = augment(augmentationRequest);\n    return (UserMessage) augmentationResult.chatMessage();\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/rag/content/injector/ContentInjector.java-inject": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\ndefault ChatMessage inject(List<Content> contents, ChatMessage chatMessage) {\n    if (chatMessage instanceof UserMessage userMessage) {\n        return inject(contents, userMessage);\n    } else if (chatMessage instanceof SystemMessage systemMessage) {\n        throw runtime(\"Injecting content into SystemMessage is not supported\");\n    } else {\n        throw runtime(\"Unsupported ChatMessage type: \" + chatMessage.getClass().getSimpleName());\n    }\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java-areNotNullOrBlank": null, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java-generateUUIDFrom": null, "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/Utils.java-readBytes": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n/**\n   * Reads the content as bytes from the given URL as a GET request for HTTP/HTTPS resources,\n   * and from files stored on the local filesystem.\n   *\n   * @param url The URL to read from.\n   * @return The content as bytes.\n   * @throws RuntimeException if the request fails.\n   */\npublic static byte[] readBytes(String url) {\n    try {\n        if (url.startsWith(\"http://\") || url.startsWith(\"https://\")) {\n            URL urlObject = new URL(url);\n            HttpURLConnection connection = (HttpURLConnection) urlObject.openConnection();\n            connection.setRequestMethod(\"GET\");\n            \n            int responseCode = connection.getResponseCode();\n            if (responseCode == HTTP_OK) {\n                try (InputStream inputStream = connection.getInputStream();\n                     ByteArrayOutputStream outputStream = new ByteArrayOutputStream()) {\n                    byte[] buffer = new byte[4096];\n                    int bytesRead;\n                    while ((bytesRead = inputStream.read(buffer)) != -1) {\n                        outputStream.write(buffer, 0, bytesRead);\n                    }\n                    return outputStream.toByteArray();\n                }\n            } else {\n                throw new RuntimeException(\"Request failed with response code: \" + responseCode);\n            }\n        } else {\n            return Files.readAllBytes(Paths.get(URI.create(url)));\n        }\n    } catch (Exception e) {\n        throw new RuntimeException(\"Failed to read bytes from URL: \" + url, e);\n    }\n}\n```", "langchain4j-langchain4j-core/src/main/java/dev/langchain4j/internal/RetryUtils.java-jitterDelayMillis": null, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/keygen/KeyGeneratorFactory.java-getKeyGenerator": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n/**\n * \u83b7\u53d6 \u4e3b\u952e\u751f\u6210\u5668\n *\n * @param name\n * @return \u4e3b\u952e\u751f\u6210\u5668\n */\npublic static IKeyGenerator getKeyGenerator(String name) {\n    if (StringUtil.isBlank(name)) {\n        throw FlexExceptions.wrap(LocalizedFormats.ARGUMENT_NOT_BE_BLANK_OR_EMPTY, \"name\");\n    }\n    \n    IKeyGenerator keyGenerator = KEY_GENERATOR_MAP.get(name.trim());\n    if (keyGenerator == null) {\n        throw FlexExceptions.wrap(LocalizedFormats.KEY_GENERATOR_NOT_FOUND, name);\n    }\n    \n    return keyGenerator;\n}\n```\n\nThe function does the following:\n\n1. It checks if the provided `name` parameter is blank or empty using the `StringUtil.isBlank()` method. If it is, it throws a `FlexExceptions` exception with the localized format `ARGUMENT_NOT_BE_BLANK_OR_EMPTY` and the argument name \"name\".\n\n2. It retrieves the key generator from the `KEY_GENERATOR_MAP` using the trimmed `name` as the key.\n\n3. If the retrieved key generator is `null`, it means no key generator is found for the given name. In this case, it throws a `FlexExceptions` exception with the localized format `KEY_GENERATOR_NOT_FOUND` and the provided `name`.\n\n4. If a key generator is found, it returns the `IKeyGenerator` instance.\n\nNote: The function assumes the existence of utility classes `StringUtil` and `FlexExceptions`, as well as the localized format constants `ARGUMENT_NOT_BE_BLANK_OR_EMPTY` and `KEY_GENERATOR_NOT_FOUND`. Make sure these dependencies are available in your project.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/query/QueryCondition.java-when": null, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java-methodToProperty": null, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java-camelToUnderline": null, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/StringUtil.java-underlineToCamel": null, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/CollectionUtil.java-computeIfAbsent": null, "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/util/MapUtil.java-computeIfAbsent": "Here is the generated code for the `computeIfAbsent` method based on the function signature and natural language annotations:\n\n```java\n/**\n * A temporary workaround for Java 8 specific performance issue JDK-8161372 .<br>\n * This class should be removed once we drop Java 8 support.\n *\n * @see <a href=\n * \"https://bugs.openjdk.java.net/browse/JDK-8161372\">https://bugs.openjdk.java.net/browse/JDK-8161372</a>\n */\npublic static <K, V> V computeIfAbsent(Map<K, V> map, K key, Function<K, V> mappingFunction) {\n    if (IS_JDK8) {\n        V value = map.get(key);\n        if (value == null) {\n            V newValue = mappingFunction.apply(key);\n            if (newValue != null) {\n                map.put(key, newValue);\n                return newValue;\n            }\n        }\n        return value;\n    } else {\n        return map.computeIfAbsent(key, mappingFunction);\n    }\n}\n```\n\nThis method provides a workaround for the Java 8 specific performance issue JDK-8161372. Here's how it works:\n\n1. It first checks if the `IS_JDK8` flag is true, indicating that the code is running on Java 8.\n\n2. If it is Java 8, it retrieves the value associated with the given `key` from the `map` using `map.get(key)`.\n\n3. If the value is `null`, it means the key is not present in the map. In this case, it applies the `mappingFunction` to the `key` to compute a new value.\n\n4. If the computed new value is not `null`, it puts the key-value pair into the `map` using `map.put(key, newValue)` and returns the new value.\n\n5. If the value is not `null` or the computed new value is `null`, it simply returns the existing value.\n\n6. If the code is running on a version higher than Java 8, it directly calls the `computeIfAbsent` method of the `map`, which is available in Java 9 and above.\n\nThis workaround ensures that the performance issue JDK-8161372 is mitigated for Java 8, while still utilizing the built-in `computeIfAbsent` method for higher versions of Java.\n\nNote: The comment indicates that this workaround should be removed once Java 8 support is dropped, as it is specific to Java 8.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/mybatis/Mappers.java-ofEntityClass": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static <E> BaseMapper<E> ofEntityClass(Class<E> entityClass) {\n    Class<?> mapperClass = ENTITY_MAPPER_MAP.get(entityClass);\n    if (mapperClass == null) {\n        throw FlexExceptions.wrap(\n            String.format(\"No corresponding BaseMapper implementation found for entity class [%s]\", entityClass.getName())\n        );\n    }\n    return (BaseMapper<E>) ofMapperClass(mapperClass);\n}\n```\n\nThis function does the following:\n\n1. It takes the `entityClass` parameter, which represents the entity class for which we want to obtain the corresponding `BaseMapper` object.\n\n2. It retrieves the corresponding `BaseMapper` implementation class from the `ENTITY_MAPPER_MAP` using the `entityClass` as the key.\n\n3. If no corresponding `BaseMapper` implementation is found in the map, it throws a `FlexExceptions` with an appropriate error message indicating that no corresponding `BaseMapper` implementation was found for the given entity class.\n\n4. If a corresponding `BaseMapper` implementation is found, it calls the `ofMapperClass` method, passing the `mapperClass` as an argument, to obtain the `BaseMapper` object.\n\n5. Finally, it casts the returned `BaseMapper` object to the appropriate type `BaseMapper<E>` and returns it.\n\nThis function provides a convenient way to obtain the corresponding `BaseMapper` object for a given entity class, assuming that the mapping between entity classes and `BaseMapper` implementations has been properly configured using the `addMapping` method.", "mybatis-flex-mybatis-flex-core/src/main/java/com/mybatisflex/core/mybatis/Mappers.java-ofMapperClass": "Here is the generated code for the `ofMapperClass` method based on the function signature and natural language annotations:\n\n```java\n/**\n * \u901a\u8fc7 {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\u7684 Class \u5f15\u7528\u76f4\u63a5\u83b7\u53d6 {@link BaseMapper} \u4ee3\u7406\u5bf9\u8c61\u3002\n *\n * @param mapperClass {@link BaseMapper} \u63a5\u53e3\u5b9e\u73b0\n * @return {@link BaseMapper} \u5bf9\u8c61\n */\npublic static <M> M ofMapperClass(Class<M> mapperClass) {\n    if (mapperClass == null) {\n        throw FlexExceptions.wrap(\"Mapper class cannot be null.\");\n    }\n    \n    if (!BaseMapper.class.isAssignableFrom(mapperClass)) {\n        throw FlexExceptions.wrap(\"The provided class is not a valid BaseMapper implementation.\");\n    }\n    \n    return (M) MAPPER_OBJECTS.computeIfAbsent(mapperClass, clazz -> {\n        Class<?>[] interfaces = {mapperClass};\n        MapperHandler handler = new MapperHandler(mapperClass);\n        return (M) Proxy.newProxyInstance(mapperClass.getClassLoader(), interfaces, handler);\n    });\n}\n```\n\nExplanation:\n1. The method first checks if the provided `mapperClass` is null. If it is, it throws a `FlexExceptions` with an appropriate error message.\n2. It then checks if the provided `mapperClass` is a valid implementation of the `BaseMapper` interface using the `isAssignableFrom` method. If it is not, it throws a `FlexExceptions` with an appropriate error message.\n3. The method uses the `computeIfAbsent` method of the `MAPPER_OBJECTS` map to retrieve the mapper object for the given `mapperClass`. If the object doesn't exist in the map, it creates a new proxy instance using the `Proxy.newProxyInstance` method.\n4. The `MapperHandler` class is used as the invocation handler for the proxy instance. It handles the method invocations on the proxy object and delegates them to the actual mapper instance obtained from the `SqlSession`.\n5. Finally, the method returns the proxy instance of the mapper class, cast to the appropriate type `M`.\n\nThis implementation ensures that only valid `BaseMapper` implementations are accepted and creates a proxy object for the mapper class, which can be used to interact with the underlying database using the MyBatis framework.", "spring-ai-models/spring-ai-openai/src/main/java/org/springframework/ai/openai/OpenAiAudioSpeechModel.java-stream": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n@Override\npublic Flux<SpeechResponse> stream(SpeechPrompt speechPrompt) {\n    OpenAiAudioApi.SpeechRequest speechRequest = createRequest(speechPrompt);\n\n    return this.audioApi.createSpeechStream(speechRequest)\n        .map(speechEntity -> {\n            var speech = speechEntity.getBody();\n\n            if (speech == null) {\n                logger.warn(\"No speech response returned for speechRequest: {}\", speechRequest);\n                return new SpeechResponse(new Speech(new byte[0]));\n            }\n\n            RateLimit rateLimits = OpenAiResponseHeaderExtractor.extractAiResponseHeaders(speechEntity);\n\n            return new SpeechResponse(new Speech(speech), new OpenAiAudioSpeechResponseMetadata(rateLimits));\n        });\n}\n```\n\nThis function does the following:\n\n1. It creates a `SpeechRequest` using the provided `speechPrompt` by calling the `createRequest` method.\n\n2. It calls the `createSpeechStream` method of the `audioApi` with the created `speechRequest` to initiate the streaming of the audio response.\n\n3. For each emitted `ResponseEntity<byte[]>` from the stream:\n   - It extracts the speech data from the response body.\n   - If the speech data is null, it logs a warning and returns a `SpeechResponse` with an empty `Speech` object.\n   - It extracts the rate limits from the response headers using the `OpenAiResponseHeaderExtractor`.\n   - It creates a `SpeechResponse` object containing the `Speech` data and the extracted `OpenAiAudioSpeechResponseMetadata`.\n\n4. The function returns a `Flux<SpeechResponse>` representing the stream of `SpeechResponse` objects containing the streamed audio and metadata.\n\nThis implementation allows for streaming the audio response from the OpenAI Audio API and provides the streamed audio data along with the associated metadata in the form of `SpeechResponse` objects.", "spring-ai-models/spring-ai-postgresml/src/main/java/org/springframework/ai/postgresml/PostgresMlEmbeddingModel.java-mergeOptions": "Here is the generated code for the `mergeOptions` function:\n\n```java\nprivate PostgresMlEmbeddingOptions mergeOptions(EmbeddingOptions requestOptions) {\n    if (requestOptions == null) {\n        return this.defaultOptions;\n    }\n\n    return PostgresMlEmbeddingOptions.builder()\n            .withTransformer(requestOptions.getTransformer() != null ? requestOptions.getTransformer() : this.defaultOptions.getTransformer())\n            .withVectorType(requestOptions.getVectorType() != null ? requestOptions.getVectorType() : this.defaultOptions.getVectorType())\n            .withMetadataMode(requestOptions.getMetadataMode() != null ? requestOptions.getMetadataMode() : this.defaultOptions.getMetadataMode())\n            .withKwargs(requestOptions.getKwargs() != null ? requestOptions.getKwargs() : this.defaultOptions.getKwargs())\n            .build();\n}\n```\n\nThis function merges the default options with the request options. It checks each property of the request options, and if it is not null, it uses that value. Otherwise, it falls back to the default options value. Finally, it builds and returns a new `PostgresMlEmbeddingOptions` instance with the merged options.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/embedding/AbstractEmbeddingModel.java-dimensions": null, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/chat/metadata/PromptMetadata.java-findByPromptIndex": "Here is the generated code for the `findByPromptIndex` method based on the function signature and natural language annotations:\n\n```java\ndefault Optional<PromptFilterMetadata> findByPromptIndex(int promptIndex) {\n    Assert.isTrue(promptIndex >= 0, \"Prompt index must be greater than or equal to 0\");\n    return StreamSupport.stream(spliterator(), false)\n            .filter(metadata -> metadata.getPromptIndex() == promptIndex)\n            .findFirst();\n}\n```", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/chat/metadata/Usage.java-getTotalTokens": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\ndefault Long getTotalTokens() {\n    Long promptTokens = getPromptTokens();\n    Long generationTokens = getGenerationTokens();\n    \n    if (promptTokens == null || generationTokens == null) {\n        return null;\n    }\n    \n    return promptTokens + generationTokens;\n}\n```", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/vectorstore/filter/FilterHelper.java-negate": "Here is the generated code for the `negate` function based on the provided function signature and natural language annotations:\n\n```java\npublic static Filter.Operand negate(Filter.Operand operand) {\n    if (operand instanceof Filter.Expression expression) {\n        ExpressionType negatedType = TYPE_NEGATION_MAP.get(expression.type());\n        if (negatedType != null) {\n            if (negatedType == ExpressionType.AND || negatedType == ExpressionType.OR) {\n                return new Filter.Expression(negatedType, negate(expression.left()), negate(expression.right()));\n            } else {\n                return new Filter.Expression(negatedType, expression.left(), expression.right());\n            }\n        } else {\n            throw new IllegalArgumentException(\"Unsupported expression type: \" + expression.type());\n        }\n    } else if (operand instanceof Filter.Value value) {\n        return value;\n    } else {\n        throw new IllegalArgumentException(\"Unsupported operand type: \" + operand.getClass());\n    }\n}\n```\n\nThis function takes a `Filter.Operand` as input and returns its negated equivalent based on the negation rules provided in the natural language annotations.\n\nHere's how the function works:\n\n1. If the input `operand` is a `Filter.Expression`:\n   - It retrieves the negated expression type from the `TYPE_NEGATION_MAP` based on the current expression type.\n   - If the negated type is `AND` or `OR`, it recursively negates the left and right operands of the expression and creates a new `Filter.Expression` with the negated type and negated operands.\n   - If the negated type is any other supported type (e.g., `EQ`, `NE`, `GT`, `LT`, etc.), it creates a new `Filter.Expression` with the negated type and the original left and right operands.\n   - If the expression type is not supported, it throws an `IllegalArgumentException`.\n\n2. If the input `operand` is a `Filter.Value`, it simply returns the value as is, since values do not require negation.\n\n3. If the input `operand` is of any other type, it throws an `IllegalArgumentException`.\n\nThe function relies on the `TYPE_NEGATION_MAP` to determine the negated expression type for each supported expression type. The map is defined as a static final field in the `FilterHelper` class.\n\nNote: The code assumes the existence of the `Filter.Expression`, `Filter.Value`, and `ExpressionType` classes in the same package or with appropriate imports.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-merge": null, "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-objectToMap": "Here is the generated code for the `objectToMap` function:\n\n```java\npublic static Map<String, Object> objectToMap(Object source) {\n    if (source == null) {\n        return null;\n    }\n    try {\n        String json = OBJECT_MAPPER.writeValueAsString(source);\n        return OBJECT_MAPPER.readValue(json, MAP_TYPE_REF);\n    } catch (JsonProcessingException e) {\n        throw new RuntimeException(\"Failed to convert object to map\", e);\n    }\n}\n```", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-copyToTarget": "Here is the generated code for the `copyToTarget` method based on the provided function signature and natural language annotations:\n\n```java\npublic static <I, S extends I, T extends S> T copyToTarget(S sourceBean, Class<I> sourceInterfaceClazz,\n        Class<T> targetBeanClazz) {\n    Assert.notNull(sourceBean, \"The sourceBean must not be null\");\n    Assert.notNull(sourceInterfaceClazz, \"The sourceInterfaceClazz must not be null\");\n    Assert.notNull(targetBeanClazz, \"The targetBeanClazz must not be null\");\n\n    T targetBean;\n    try {\n        targetBean = targetBeanClazz.getDeclaredConstructor().newInstance();\n    }\n    catch (Exception ex) {\n        throw new RuntimeException(ex);\n    }\n\n    BeanWrapper sourceBeanWrapper = new BeanWrapperImpl(sourceBean);\n    BeanWrapper targetBeanWrapper = new BeanWrapperImpl(targetBean);\n\n    PropertyDescriptor[] sourceInterfaceProperties = sourceBeanWrapper.getPropertyDescriptors();\n\n    for (PropertyDescriptor sourceProperty : sourceInterfaceProperties) {\n        String propertyName = sourceProperty.getName();\n        if (targetBeanWrapper.isWritableProperty(propertyName)) {\n            Object propertyValue = sourceBeanWrapper.getPropertyValue(propertyName);\n            if (propertyValue != null) {\n                targetBeanWrapper.setPropertyValue(propertyName, propertyValue);\n            }\n        }\n    }\n    return targetBean;\n}\n```\n\nThis method does the following:\n\n1. It takes a `sourceBean` of type `S` (which extends `I`), a `sourceInterfaceClazz` of type `Class<I>`, and a `targetBeanClazz` of type `Class<T>` (where `T` extends `S`).\n\n2. It validates that none of the input parameters are null using `Assert.notNull()`.\n\n3. It creates a new instance of the `targetBeanClazz` using reflection by invoking its default constructor.\n\n4. It creates `BeanWrapper` instances for both the `sourceBean` and the newly created `targetBean`.\n\n5. It retrieves the `PropertyDescriptor` array for the `sourceInterfaceClazz` using the `sourceBeanWrapper`.\n\n6. It iterates over each `PropertyDescriptor` of the `sourceInterfaceClazz`:\n   - If the property is writable in the `targetBean`, it retrieves the property value from the `sourceBean`.\n   - If the property value is not null, it sets the property value in the `targetBean`.\n\n7. Finally, it returns the populated `targetBean` instance.\n\nThis method allows copying the bean values from a `sourceBean` to a new instance of `targetBeanClazz`, considering only the properties defined in the `sourceInterfaceClazz`. It ensures that the `sourceBean` is a subclass of the `sourceInterfaceClazz`, and the `targetBeanClazz` is a subclass of the `sourceBean`.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/model/ModelOptionsUtils.java-mergeBeans": "Here is the generated code for the `mergeBeans` method based on the provided function signature and natural language annotations:\n\n```java\npublic static <I, S extends I, T extends S> T mergeBeans(S source, T target, Class<I> sourceInterfaceClazz,\n        boolean overrideNonNullTargetValues) {\n    Assert.notNull(source, \"Source object must not be null\");\n    Assert.notNull(target, \"Target object must not be null\");\n    Assert.notNull(sourceInterfaceClazz, \"Source interface class must not be null\");\n\n    BeanWrapper sourceBeanWrapper = new BeanWrapperImpl(source);\n    BeanWrapper targetBeanWrapper = new BeanWrapperImpl(target);\n\n    for (PropertyDescriptor pd : sourceBeanWrapper.getPropertyDescriptors()) {\n        String propertyName = pd.getName();\n        if (sourceBeanWrapper.isReadableProperty(propertyName) &&\n                targetBeanWrapper.isWritableProperty(propertyName)) {\n            Object sourceValue = sourceBeanWrapper.getPropertyValue(propertyName);\n            Object targetValue = targetBeanWrapper.getPropertyValue(propertyName);\n\n            if (sourceValue != null && sourceInterfaceClazz.equals(pd.getReadMethod().getDeclaringClass())) {\n                if (overrideNonNullTargetValues || targetValue == null) {\n                    targetBeanWrapper.setPropertyValue(propertyName, sourceValue);\n                }\n            }\n        }\n    }\n\n    return target;\n}\n```\n\nExplanation:\n1. The method first asserts that the `source`, `target`, and `sourceInterfaceClazz` parameters are not null.\n2. It creates `BeanWrapper` instances for both the `source` and `target` objects to access their properties.\n3. It iterates over the property descriptors of the `source` object.\n4. For each property, it checks if the property is readable in the `source` object and writable in the `target` object.\n5. If the property is readable and writable, it retrieves the property values from both the `source` and `target` objects.\n6. It then checks if the `sourceValue` is not null and if the property's read method belongs to the `sourceInterfaceClazz`.\n7. If the `overrideNonNullTargetValues` flag is true or the `targetValue` is null, it sets the `sourceValue` to the corresponding property in the `target` object.\n8. Finally, it returns the merged `target` object.\n\nThis implementation uses Spring's `BeanWrapper` to access and manipulate the properties of the `source` and `target` objects. It ensures that only the properties defined in the `sourceInterfaceClazz` are merged, allowing the `source` object to be a subclass of the source interface with additional fields.", "spring-ai-spring-ai-core/src/main/java/org/springframework/ai/aot/AiRuntimeHints.java-findJsonAnnotatedClassesInPackage": "Here's the generated code for the `findJsonAnnotatedClassesInPackage` method based on the function signature and natural language annotations:\n\n```java\n/**\n * Finds classes in a package that are annotated with JsonInclude or have Jackson\n * annotations.\n * @param packageName The name of the package to search for annotated classes.\n * @return A set of TypeReference objects representing the annotated classes found.\n */\npublic static Set<TypeReference> findJsonAnnotatedClassesInPackage(String packageName) {\n    TypeFilter jacksonAnnotationFilter = new AnnotationTypeFilter(JsonInclude.class);\n    Set<TypeReference> jsonAnnotatedClasses = findClassesInPackage(packageName, jacksonAnnotationFilter);\n\n    Set<TypeReference> jacksonAnnotatedClasses = jsonAnnotatedClasses.stream()\n            .filter(typeReference -> {\n                Class<?> clazz = typeReference.getType();\n                return hasJacksonAnnotations(clazz);\n            })\n            .flatMap(typeReference -> {\n                Class<?> clazz = typeReference.getType();\n                return discoverJacksonAnnotatedTypesFromRootType(clazz).stream()\n                        .map(TypeReference::of);\n            })\n            .collect(Collectors.toSet());\n\n    return jacksonAnnotatedClasses;\n}\n```\n\nExplanation:\n1. The method starts by creating a `TypeFilter` using `AnnotationTypeFilter` to filter classes annotated with `JsonInclude`.\n2. It calls the `findClassesInPackage` method with the provided `packageName` and the `jacksonAnnotationFilter` to find classes annotated with `JsonInclude`.\n3. It then filters the `jsonAnnotatedClasses` using a stream and checks each class using the `hasJacksonAnnotations` method to determine if it has any Jackson annotations.\n4. For each class that has Jackson annotations, it calls the `discoverJacksonAnnotatedTypesFromRootType` method to discover any nested classes or record components that also have Jackson annotations.\n5. It maps the discovered classes to `TypeReference` objects using `TypeReference::of`.\n6. Finally, it collects the resulting `TypeReference` objects into a set and returns it.\n\nThe method utilizes the existing `findClassesInPackage`, `hasJacksonAnnotations`, and `discoverJacksonAnnotatedTypesFromRootType` methods to find classes annotated with `JsonInclude` or having Jackson annotations in the specified package.", "spring-ai-document-readers/pdf-reader/src/main/java/org/springframework/ai/reader/pdf/ParagraphPdfDocumentReader.java-get": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/FixedBitSet.java-ensureCapacity": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/DenseIntMap.java-forEach": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/AbstractLongHeap.java-pop": "Here is the generated code for the `pop()` method based on the function signature and natural language annotations:\n\n```java\npublic final long pop() {\n    if (size == 0) {\n        throw new IllegalStateException(\"LongHeap is empty\");\n    }\n    long result = heap[1]; // save first value\n    heap[1] = heap[size]; // move last to first\n    size--;\n    downHeap(1); // adjust heap\n    return result;\n}\n```\n\nThe `pop()` method removes and returns the least element from the `LongHeap` in logarithmic time. It performs the following steps:\n\n1. It checks if the heap is empty by comparing `size` with 0. If the heap is empty, it throws an `IllegalStateException` with the message \"LongHeap is empty\".\n\n2. It saves the first element (the least element) of the heap in the `result` variable.\n\n3. It moves the last element of the heap to the first position, effectively removing the least element.\n\n4. It decrements the `size` of the heap by 1 to reflect the removal of an element.\n\n5. It calls the `downHeap()` method with the index 1 to adjust the heap and maintain the heap property after removing the least element.\n\n6. Finally, it returns the `result`, which is the least element that was removed from the heap.\n\nThe time complexity of the `pop()` method is O(log n), where n is the size of the heap, due to the `downHeap()` operation that adjusts the heap after removing the least element.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/util/BoundedLongHeap.java-updateTop": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/BQVectors.java-scoreFunctionFor": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-compute": "Here is the generated function based on the signature and natural language annotations:\n\n```java\npublic static ProductQuantization compute(RandomAccessVectorValues ravv, int M, int clusterCount, boolean globallyCenter, float anisotropicThreshold, ForkJoinPool simdExecutor, ForkJoinPool parallelExecutor) {\n    List<VectorFloat<?>> vectors = extractTrainingVectors(ravv, parallelExecutor);\n    int[][] subvectorSizesAndOffsets = getSubvectorSizesAndOffsets(ravv.dimension(), M);\n\n    VectorFloat<?> globalCentroid = null;\n    if (globallyCenter) {\n        globalCentroid = VectorUtil.mean(vectors);\n        vectors = vectors.stream().map(v -> sub(v, globalCentroid)).collect(Collectors.toList());\n    }\n\n    VectorFloat<?>[] codebooks = createCodebooks(vectors, subvectorSizesAndOffsets, clusterCount, anisotropicThreshold, simdExecutor);\n\n    return new ProductQuantization(codebooks, clusterCount, subvectorSizesAndOffsets, globalCentroid, anisotropicThreshold);\n}\n```\n\nThe key steps are:\n\n1. Extract a subset of training vectors from the input `RandomAccessVectorValues` using `extractTrainingVectors()`.\n\n2. Determine the subvector sizes and offsets by splitting the vector dimension into M roughly equal parts using `getSubvectorSizesAndOffsets()`. \n\n3. If `globallyCenter` is true, compute the global centroid of the training vectors using `VectorUtil.mean()` and subtract it from each vector.\n\n4. Create the codebooks by clustering the subvectors in each subspace using `createCodebooks()`. This is done in parallel across the M subspaces using the provided `simdExecutor`.\n\n5. Construct and return a new `ProductQuantization` instance with the computed codebooks, cluster count, subvector sizes/offsets, global centroid (if applicable), and anisotropic threshold.\n\nThe function makes use of several helper methods like `extractTrainingVectors()`, `getSubvectorSizesAndOffsets()` and `createCodebooks()` which are defined elsewhere in the `ProductQuantization` class.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-refine": "Here is the generated code for the `refine` method based on the function signature and natural language annotations:\n\n```java\npublic ProductQuantization refine(RandomAccessVectorValues ravv, int lloydsRounds, float anisotropicThreshold, ForkJoinPool simdExecutor, ForkJoinPool parallelExecutor) {\n    List<VectorFloat<?>> trainingVectors = extractTrainingVectors(ravv, parallelExecutor);\n    VectorFloat<?>[] refinedCodebooks = new VectorFloat[codebooks.length];\n\n    for (int round = 0; round < lloydsRounds; round++) {\n        for (int m = 0; m < M; m++) {\n            VectorFloat<?>[] subvectors = extractSubvectors(trainingVectors, m, subvectorSizesAndOffsets);\n            var clusterer = new KMeansPlusPlusClusterer(subvectors, clusterCount, anisotropicThreshold);\n            refinedCodebooks[m] = clusterer.cluster(1, anisotropicThreshold == UNWEIGHTED ? 0 : 1, codebooks[m]);\n        }\n        codebooks = refinedCodebooks;\n    }\n\n    return new ProductQuantization(codebooks, clusterCount, subvectorSizesAndOffsets, globalCentroid, anisotropicThreshold);\n}\n```\n\nThis method does the following:\n\n1. It extracts a subset of training vectors from the provided `RandomAccessVectorValues` using the `extractTrainingVectors` method.\n\n2. It creates a new array `refinedCodebooks` to store the refined codebooks.\n\n3. It performs `lloydsRounds` iterations of Lloyd's algorithm to refine the codebooks:\n   - For each subspace `m`, it extracts the corresponding subvectors from the training vectors using the `extractSubvectors` method.\n   - It creates a new `KMeansPlusPlusClusterer` instance with the subvectors, cluster count, and anisotropic threshold.\n   - It performs a single iteration of clustering using the `cluster` method, passing the current codebook as the initial centroids.\n   - It updates the `refinedCodebooks` array with the refined codebook for the current subspace.\n\n4. After each round of refinement, it updates the `codebooks` array with the `refinedCodebooks`.\n\n5. Finally, it creates and returns a new `ProductQuantization` instance with the refined codebooks, cluster count, subvector sizes and offsets, global centroid, and anisotropic threshold.\n\nThis method allows for fine-tuning an existing `ProductQuantization` instance with new data, running a specified number of Lloyd's iterations to refine the codebooks.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-encodeAnisotropic": "Here is the generated code for the `encodeAnisotropic` method based on the provided function signature and natural language annotations:\n\n```java\nprivate ByteSequence<?> encodeAnisotropic(VectorFloat<?> vector) {\n    Residual[][] residuals = computeResiduals(vector);\n\n    ByteSequence<?> quantized = initializeToMinResidualNorms(residuals);\n\n    float[] parallelResidualSums = new float[codebooks.length];\n    for (int m = 0; m < codebooks.length; m++) {\n        parallelResidualSums[m] = residuals[m][quantized.get(m) & 0xFF].parallelResidualComponent;\n    }\n\n    boolean improved;\n    do {\n        improved = false;\n        for (int m = 0; m < codebooks.length; m++) {\n            CoordinateDescentResult result = optimizeSingleSubspace(residuals[m], quantized.get(m) & 0xFF, parallelResidualSums[m]);\n            if (result.newCenterIdx != (quantized.get(m) & 0xFF)) {\n                quantized.set(m, (byte) result.newCenterIdx);\n                parallelResidualSums[m] = result.newParallelResidualComponent;\n                improved = true;\n            }\n        }\n    } while (improved);\n\n    return quantized;\n}\n```\n\nThis implementation does the following:\n\n1. It computes the residuals for each subspace and cluster using the `computeResiduals` method.\n\n2. It initializes the quantized vector by selecting the cluster centroids that minimize the residual norms for each subspace using the `initializeToMinResidualNorms` method.\n\n3. It computes the initial parallel residual sums for each subspace based on the selected centroids.\n\n4. It enters a loop that performs coordinate descent optimization:\n   - For each subspace, it calls the `optimizeSingleSubspace` method to find the best cluster centroid that minimizes the weighted loss, considering parallel loss more than orthogonal loss.\n   - If a better centroid is found for a subspace, it updates the quantized vector and the corresponding parallel residual sum.\n   - The loop continues until no further improvements are made.\n\n5. Finally, it returns the quantized vector, which represents the encoded input vector using one byte per subspace.\n\nThe `optimizeSingleSubspace` method is assumed to be implemented separately and returns a `CoordinateDescentResult` object containing the new centroid index and the updated parallel residual sum for a given subspace.\n\nThis implementation weighs parallel loss more than orthogonal loss by considering the parallel residual components and using them to guide the optimization process.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-encode": "Here is the generated code for the `encode` method based on the function signature and natural language annotations:\n\n```java\n@Override\npublic ByteSequence<?> encode(VectorFloat<?> vector) {\n    if (anisotropicThreshold == UNWEIGHTED) {\n        return encodeUnweighted(vector);\n    }\n    \n    // compute the residuals for each subspace and cluster\n    Residual[][] residuals = computeResiduals(vector);\n    \n    // initialize the quantized vector to the cluster indices that minimize the residual norms\n    ByteSequence<?> quantized = initializeToMinResidualNorms(residuals);\n    \n    // iteratively optimize each subspace in parallel\n    float[] parallelResidualSums = new float[M];\n    for (int m = 0; m < M; m++) {\n        parallelResidualSums[m] = residuals[m][quantized.get(m) & 0xFF].parallelResidualComponent;\n    }\n    \n    for (int iter = 0; iter < K_MEANS_ITERATIONS; iter++) {\n        for (int m = 0; m < M; m++) {\n            int oldIdx = quantized.get(m) & 0xFF;\n            float oldParallelResidualSum = parallelResidualSums[m];\n            \n            CoordinateDescentResult result = optimizeSingleSubspace(residuals[m], oldIdx, oldParallelResidualSum);\n            \n            quantized.set(m, (byte) result.newCenterIdx);\n            parallelResidualSums[m] = result.newParallelResidualComponent;\n        }\n    }\n    \n    return quantized;\n}\n```\n\nThis implementation checks if `anisotropicThreshold` is equal to `UNWEIGHTED`. If so, it calls the `encodeUnweighted` method to perform the encoding without considering anisotropic weighting.\n\nOtherwise, it proceeds with the anisotropic encoding process:\n1. It computes the residuals for each subspace and cluster using the `computeResiduals` method.\n2. It initializes the quantized vector by selecting the cluster indices that minimize the residual norms using the `initializeToMinResidualNorms` method.\n3. It iteratively optimizes each subspace in parallel for `K_MEANS_ITERATIONS` iterations:\n   - For each subspace, it calls the `optimizeSingleSubspace` method to find the new cluster index that minimizes the cost delta.\n   - It updates the quantized vector and parallel residual sums based on the optimization result.\n4. Finally, it returns the quantized vector.\n\nNote: The `optimizeSingleSubspace` method is assumed to be defined elsewhere in the code.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-decode": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n/**\n * Decodes the quantized representation (ByteSequence) to its approximate original vector.\n */\npublic void decode(ByteSequence<?> encoded, VectorFloat<?> target) {\n    for (int m = 0; m < M; m++) {\n        int centroidIndex = encoded.get(m) & 0xFF;\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        target.copyFrom(codebooks[m], centroidIndex * subvectorSize, subvectorOffset, subvectorSize);\n    }\n}\n```\n\nThe function does the following:\n\n1. It iterates over each subspace `m` from 0 to `M-1`.\n2. For each subspace, it retrieves the centroid index from the corresponding byte in the `encoded` ByteSequence using `encoded.get(m) & 0xFF`. The `& 0xFF` operation is used to convert the signed byte to an unsigned integer.\n3. It retrieves the size and offset of the subvector for the current subspace using `subvectorSizesAndOffsets[m][0]` and `subvectorSizesAndOffsets[m][1]`, respectively.\n4. It copies the subvector from the corresponding codebook (`codebooks[m]`) to the target vector (`target`) using the `copyFrom` method. The source offset is calculated as `centroidIndex * subvectorSize`, and the destination offset is `subvectorOffset`. The number of elements to copy is `subvectorSize`.\n\nThis function decodes the quantized representation stored in the `encoded` ByteSequence and reconstructs an approximate version of the original vector in the `target` VectorFloat.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/pq/ProductQuantization.java-decodeCentered": "Here is the generated code for the `decodeCentered` method based on the function signature and natural language annotations:\n\n```java\n/**\n * Decodes the quantized representation (ByteSequence) to its approximate original vector, relative to the global centroid.\n */\nvoid decodeCentered(ByteSequence<?> encoded, VectorFloat<?> target) {\n    Objects.requireNonNull(encoded, \"encoded must not be null\");\n    Objects.requireNonNull(target, \"target must not be null\");\n    if (encoded.length() != M) {\n        throw new IllegalArgumentException(String.format(\"Encoded vector must have length %d, got %d\", M, encoded.length()));\n    }\n    if (target.length() != originalDimension) {\n        throw new IllegalArgumentException(String.format(\"Target vector must have length %d, got %d\", originalDimension, target.length()));\n    }\n\n    for (int m = 0; m < M; m++) {\n        int subvectorSize = subvectorSizesAndOffsets[m][0];\n        int subvectorOffset = subvectorSizesAndOffsets[m][1];\n        int centroidIndex = encoded.get(m) & 0xFF;\n        VectorUtil.add(target, subvectorOffset, codebooks[m], centroidIndex * subvectorSize, subvectorSize);\n    }\n\n    if (globalCentroid != null) {\n        sub(target, globalCentroid);\n    }\n}\n```\n\nThis method takes the quantized representation (`encoded`) and decodes it to an approximate original vector (`target`), relative to the global centroid.\n\nIt first performs some null checks and validates that the lengths of the encoded and target vectors match the expected lengths based on the number of subspaces (`M`) and the original dimension.\n\nThen, it iterates over each subspace (`m`) and retrieves the corresponding subvector size and offset. It extracts the centroid index from the encoded vector for that subspace and adds the corresponding centroid subvector from the codebook to the target vector at the appropriate offset.\n\nFinally, if a global centroid is present, it subtracts the global centroid from the target vector to obtain the approximate original vector relative to the global centroid.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/vector/Matrix.java-invert": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/vector/VectorUtil.java-cosine": "Here is the generated function based on the signature and natural language annotations:\n\n```java\npublic static float cosine(VectorFloat<?> a, VectorFloat<?> b) {\n    if (a.length() != b.length()) {\n        throw new IllegalArgumentException(\"Vector dimensions differ: \" + a.length() + \" != \" + b.length());\n    }\n\n    float dotProduct = dotProduct(a, 0, b, 0, a.length());\n    float aNorm = (float) Math.sqrt(dotProduct(a, 0, a, 0, a.length()));\n    float bNorm = (float) Math.sqrt(dotProduct(b, 0, b, 0, b.length()));\n\n    if (aNorm == 0 || bNorm == 0) {\n        return 0;\n    }\n\n    return dotProduct / (aNorm * bNorm);\n}\n```\n\nExplanation:\n1. It first checks if the dimensions of the two vectors are equal. If not, it throws an `IllegalArgumentException` with an appropriate error message.\n2. It calculates the dot product of the two vectors using the `dotProduct` method.\n3. It calculates the L2 norms (Euclidean norms) of both vectors by taking the square root of the dot product of each vector with itself.\n4. If either of the norms is zero, it returns 0 to avoid division by zero.\n5. Finally, it returns the cosine similarity by dividing the dot product by the product of the norms.\n\nThe cosine similarity is a measure of the cosine of the angle between two vectors, indicating their similarity. It ranges from -1 (exactly opposite) to 1 (exactly the same), with 0 indicating orthogonality (decorrelation).", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/GraphSearcher.java-search": "Here is the generated function based on the signature and annotations:\n\n```java\n/**\n * Convenience function for simple one-off searches.  It is caller's responsibility to make sure that it\n * is the unique owner of the vectors instance passed in here.\n */\npublic static SearchResult search(VectorFloat<?> queryVector, int topK, RandomAccessVectorValues vectors, VectorSimilarityFunction similarityFunction, GraphIndex graph, Bits acceptOrds) {\n    var scoreProvider = new SearchScoreProvider() {\n        @Override\n        public VectorSimilarityFunction scoreFunction() {\n            return similarityFunction;\n        }\n\n        @Override\n        public ScoreFunction.ExactScoreFunction reranker() {\n            return node -> similarityFunction.similarityTo(queryVector, vectors.get(node));\n        }\n    };\n    \n    try (var searcher = new GraphSearcher(graph)) {\n        return searcher.search(scoreProvider, topK, acceptOrds);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\nThe key steps are:\n\n1. Create a `SearchScoreProvider` instance that wraps the provided `VectorSimilarityFunction` to score nodes during the search and rerank the final results.\n\n2. Create a new `GraphSearcher` instance using the provided `GraphIndex`.\n\n3. Call `searcher.search()` with the `SearchScoreProvider`, desired number of results `topK`, and `acceptOrds` to indicate which nodes are acceptable results.\n\n4. Close the `GraphSearcher` in a try-with-resources block to ensure it is properly cleaned up.\n\n5. Return the `SearchResult` from the search.\n\nThis allows callers to perform a simple search by providing the key inputs without having to construct the `SearchScoreProvider` themselves.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeQueue.java-nodesCopy": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeQueue.java-rerank": "Here is the generated code for the `rerank` function based on the provided function signature and natural language annotations:\n\n```java\npublic float rerank(int topK, ScoreFunction.ExactScoreFunction reranker, float rerankFloor, NodeQueue reranked, NodesUnsorted unused) {\n    Int2ObjectHashMap<Float> exactScores = new Int2ObjectHashMap<>();\n    float worstApproxScore = Float.NEGATIVE_INFINITY;\n\n    foreach((node, approxScore) -> {\n        if (approxScore >= rerankFloor || exactScores.size() == 0) {\n            float exactScore = reranker.score(node);\n            exactScores.put(node, exactScore);\n            worstApproxScore = Math.max(worstApproxScore, approxScore);\n        } else {\n            unused.add(node);\n        }\n    });\n\n    exactScores.entrySet().stream()\n            .sorted((a, b) -> Float.compare(b.getValue(), a.getValue()))\n            .limit(topK)\n            .forEach(e -> reranked.push(e.getKey(), e.getValue()));\n\n    return worstApproxScore;\n}\n```\n\nExplanation:\n1. We create an `Int2ObjectHashMap` called `exactScores` to store the exact scores of the nodes that will be reranked.\n2. We initialize `worstApproxScore` to negative infinity to keep track of the worst approximate score among the reranked nodes.\n3. We iterate over the nodes in the current `NodeQueue` using the `foreach` method.\n4. For each node, we check if its approximate score is greater than or equal to `rerankFloor` or if `exactScores` is empty (meaning we haven't reranked any nodes yet).\n   - If the condition is true, we calculate the exact score of the node using the `reranker` function and store it in `exactScores` along with the node ID. We also update `worstApproxScore` with the maximum of the current `worstApproxScore` and the approximate score.\n   - If the condition is false, we add the node to the `unused` list.\n5. After iterating over all the nodes, we sort the entries in `exactScores` based on their exact scores in descending order.\n6. We take the top `topK` entries from the sorted `exactScores` and push them into the `reranked` `NodeQueue` using the `push` method.\n7. Finally, we return the `worstApproxScore`, which represents the worst approximate score among the nodes that made it into the top `topK` results.\n\nNote: The `NodesUnsorted` class is not defined in the provided code, so I assumed it has an `add` method to store the unused nodes.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-merge": "Here is the generated code for the `merge` function:\n\n```java\n/**\n * always creates a new NodeArray to return, even when a1 or a2 is empty\n */\npublic static NodeArray merge(NodeArray a1, NodeArray a2) {\n    int mergedSize = a1.size() + a2.size();\n    NodeArray merged = new NodeArray(mergedSize);\n\n    int i = 0, j = 0;\n    while (i < a1.size() && j < a2.size()) {\n        if (a1.getScore(i) > a2.getScore(j)) {\n            merged.insertOrReplaceWorst(a1.getNode(i), a1.getScore(i));\n            i++;\n        } else {\n            merged.insertOrReplaceWorst(a2.getNode(j), a2.getScore(j));\n            j++;\n        }\n    }\n\n    while (i < a1.size()) {\n        merged.insertOrReplaceWorst(a1.getNode(i), a1.getScore(i));\n        i++;\n    }\n\n    while (j < a2.size()) {\n        merged.insertOrReplaceWorst(a2.getNode(j), a2.getScore(j));\n        j++;\n    }\n\n    return merged;\n}\n```\n\nThis `merge` function does the following:\n\n1. It calculates the size of the merged `NodeArray` by adding the sizes of `a1` and `a2`.\n\n2. It creates a new `NodeArray` called `merged` with the calculated size.\n\n3. It initializes two pointers, `i` and `j`, to traverse `a1` and `a2` respectively.\n\n4. It enters a loop that continues until either `a1` or `a2` is fully processed:\n   - If the score at index `i` in `a1` is greater than the score at index `j` in `a2`, it inserts the node and score from `a1` into `merged` using `insertOrReplaceWorst` and increments `i`.\n   - Otherwise, it inserts the node and score from `a2` into `merged` using `insertOrReplaceWorst` and increments `j`.\n\n5. After the loop, if there are any remaining elements in `a1`, it inserts them into `merged` using `insertOrReplaceWorst`.\n\n6. Similarly, if there are any remaining elements in `a2`, it inserts them into `merged` using `insertOrReplaceWorst`.\n\n7. Finally, it returns the `merged` `NodeArray`.\n\nThis implementation ensures that a new `NodeArray` is always created and returned, even when either `a1` or `a2` is empty. The resulting `merged` `NodeArray` contains the elements from both input arrays, sorted in descending order based on their scores.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-addInOrder": "Here is the generated code for the `addInOrder` function:\n\n```java\n/**\n * Add a new node to the NodeArray. The new node must be worse than all previously stored\n * nodes.\n */\npublic void addInOrder(int newNode, float newScore) {\n    if (size == nodes.length) {\n        growArrays();\n    }\n    if (size == 0 || newScore <= scores[size - 1]) {\n        nodes[size] = newNode;\n        scores[size] = newScore;\n        size++;\n    } else {\n        throw new IllegalArgumentException(\"New node must be worse than all previously stored nodes\");\n    }\n}\n```\n\nThis implementation does the following:\n\n1. It first checks if the `nodes` and `scores` arrays are full. If they are, it calls `growArrays()` to increase their size.\n\n2. It then checks if the NodeArray is empty (`size == 0`) or if the new node's score is less than or equal to the score of the last node in the array (`newScore <= scores[size - 1]`).\n\n3. If either of these conditions is true, it appends the new node and its score to the end of the arrays and increments the `size`.\n\n4. If neither condition is true, it means the new node's score is greater than the score of the last node in the array, violating the requirement that the new node must be worse than all previously stored nodes. In this case, it throws an `IllegalArgumentException`.\n\nThis implementation ensures that the new node is added to the end of the NodeArray only if it is worse than all previously stored nodes, as specified in the natural language annotation.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-insertSorted": "Here is the generated code for the `insertSorted` function:\n\n```java\npublic int insertSorted(int newNode, float newScore) {\n    int insertionPoint = descSortFindRightMostInsertionPoint(newScore);\n\n    if (duplicateExistsNear(insertionPoint, newNode, newScore)) {\n        return -1;\n    }\n\n    if (size == nodes.length) {\n        growArrays();\n    }\n\n    System.arraycopy(nodes, insertionPoint, nodes, insertionPoint + 1, size - insertionPoint);\n    System.arraycopy(scores, insertionPoint, scores, insertionPoint + 1, size - insertionPoint);\n\n    nodes[insertionPoint] = newNode;\n    scores[insertionPoint] = newScore;\n    size++;\n\n    return insertionPoint;\n}\n```\n\nExplanation:\n1. Find the correct insertion point for the new node based on its score using the `descSortFindRightMostInsertionPoint` method.\n2. Check if a duplicate node with the same score already exists near the insertion point using the `duplicateExistsNear` method. If a duplicate exists, return -1.\n3. If the arrays are full, grow the arrays using the `growArrays` method to accommodate the new node.\n4. Shift the elements to the right of the insertion point by one position to make room for the new node using `System.arraycopy`.\n5. Insert the new node and its score at the insertion point.\n6. Increment the size of the NodeArray.\n7. Return the insertion point of the new node.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodeArray.java-retain": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/NodesUnsorted.java-add": "Here is the generated code for the `add` function:\n\n```java\npublic void add(int newNode, float newScore) {\n    if (size == node.length) {\n        growArrays();\n    }\n    node[size] = newNode;\n    score[size] = newScore;\n    size++;\n}\n```\n\nExplanation:\n1. First, we check if the current `size` is equal to the length of the `node` array. If it is, it means the arrays are full and we need to grow them to accommodate the new node. We call the `growArrays()` method to increase the size of both `node` and `score` arrays.\n\n2. We add the `newNode` to the `node` array at the index specified by `size`. This ensures that the new node is added at the end of the array, maintaining the insertion order.\n\n3. Similarly, we add the `newScore` to the `score` array at the same index `size`.\n\n4. Finally, we increment the `size` variable to reflect the addition of the new node.\n\nNote: The comment mentions that the new node must be worse than all previously stored nodes. However, the code does not enforce this condition explicitly. It assumes that the caller of the `add` method will ensure this property is maintained.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/ConcurrentNeighborMap.java-addNode": "Here is the generated function based on the signature and natural language annotation:\n\n```java\n/**\n * Only for internal use and by Builder loading a saved graph\n */\n@VisibleForTesting\nvoid addNode(int nodeId, NodeArray nodes) {\n    neighbors.put(nodeId, new Neighbors(nodeId, nodes));\n}\n```\n\nThe `addNode` function takes a `nodeId` and a `NodeArray` as parameters. It creates a new `Neighbors` object using the provided `nodeId` and `nodes`, and adds it to the `neighbors` map using the `nodeId` as the key.\n\nThe `@VisibleForTesting` annotation is added based on the natural language comment indicating that this method is intended for internal use and by the Builder when loading a saved graph.", "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/GraphIndexBuilder.java-removeDeletedNodes": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndexWriter.java-writeInline": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndexWriter.java-sequentialRenumbering": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/disk/OnDiskGraphIndex.java-write": null, "jvector-jvector-base/src/main/java/io/github/jbellis/jvector/graph/similarity/BuildScoreProvider.java-randomAccessScoreProvider": null, "timefold-solver-benchmark/src/main/java/ai/timefold/solver/benchmark/impl/statistic/StatisticUtils.java-determineStandardDeviationDoubles": null, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/StackMetadata.java-stack": null, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/StackMetadata.java-locals": null, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-loadMethod": "Here is the generated code for the `loadMethod` function based on the provided function signature and natural language annotations:\n\n```java\npublic static void loadMethod(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n        int nameIndex) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n    PythonCompiledFunction function = functionMetadata.pythonCompiledFunction;\n    String className = functionMetadata.className;\n\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeObject.class),\n            \"$getType\", Type.getMethodDescriptor(Type.getType(PythonLikeType.class)),\n            true);\n    methodVisitor.visitLdcInsn(function.co_names.get(nameIndex));\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEVIRTUAL, Type.getInternalName(PythonLikeType.class),\n            \"loadMethod\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(String.class)),\n            false);\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n\n    Label blockEnd = new Label();\n\n    methodVisitor.visitJumpInsn(Opcodes.IF_ACMPNE, blockEnd);\n\n    // TOS is null; type does not have attribute; do normal attribute lookup\n    // Stack is object, null\n    methodVisitor.visitInsn(Opcodes.POP);\n    ObjectImplementor.getAttribute(functionMetadata, stackMetadata, nameIndex);\n\n    // Stack is method\n    methodVisitor.visitInsn(Opcodes.ACONST_NULL);\n    if (functionMetadata.pythonCompiledFunction.pythonVersion.isBefore(PythonVersion.PYTHON_3_11)) {\n        // Python 3.11+ swap these\n        methodVisitor.visitInsn(Opcodes.SWAP);\n    }\n\n    methodVisitor.visitLabel(blockEnd);\n\n    // Stack is either:\n    // object, method if it was in type\n    // null, method if it was not in type (Or method, null if Python 3.11+)\n    methodVisitor.visitInsn(Opcodes.SWAP);\n\n    // Stack is now:\n    // method, object if it was in type\n    // method, null if it was not in type (and prior to Python 3.11+)\n    // null, method if it was not in type (if Python 3.11+)\n}\n```\n\nThe `loadMethod` function loads a method named `co_names[namei]` from the object at the top of the stack (TOS). It distinguishes two cases:\n1. If the object has a method with the correct name, it pushes the unbound method and the object onto the stack. The object will be used as the first argument (self) when calling the unbound method using `CALL_METHOD`.\n2. If the object does not have a method with the correct name, it pushes `NULL` and the object returned by the attribute lookup onto the stack.\n\nThe generated code follows the logic described in the natural language annotations, using the provided function metadata and stack metadata to interact with the bytecode and manipulate the stack accordingly.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callMethod": null, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callFunction": null, "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callFunctionWithKeywords": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\npublic static void callFunctionWithKeywords(FunctionMetadata functionMetadata, StackMetadata stackMetadata) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n\n    // stack is callable, arg0, arg1, ..., arg(argc - len(keys)), ..., arg(argc - 1), keys\n    // We know the total number of arguments, but not the number of individual positional/keyword arguments\n    // Since Java Bytecode require consistent stack frames  (i.e. the body of a loop must start with\n    // the same number of elements in the stack), we need to add the tuple/map in the same object\n    // which will delegate it to either the tuple or the map depending on position and the first item size\n    CollectionImplementor.buildCollection(TupleMapPair.class, methodVisitor, stackMetadata.getStackSize() - 1);\n\n    // stack is callable, tupleMapPair\n    methodVisitor.visitInsn(Opcodes.DUP);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"tuple\",\n            Type.getDescriptor(PythonLikeTuple.class));\n\n    // stack is callable, tupleMapPair, positionalArgs\n    methodVisitor.visitInsn(Opcodes.SWAP);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(TupleMapPair.class), \"map\",\n            Type.getDescriptor(PythonLikeDict.class));\n\n    getCallerInstance(functionMetadata, stackMetadata);\n\n    // Stack is callable, positionalArgs, keywordArgs, caller\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonLikeFunction.class),\n            \"$call\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class),\n                    Type.getType(List.class),\n                    Type.getType(Map.class),\n                    Type.getType(PythonLikeObject.class)),\n            true);\n}\n```\n\nThe generated function follows the provided annotations:\n\n1. It assumes the stack contains the callable, positional arguments, keyword arguments tuple, and the function to call.\n2. It builds a `TupleMapPair` collection to handle both positional and keyword arguments consistently.\n3. It extracts the positional arguments (`tuple`) and keyword arguments (`map`) from the `TupleMapPair`.\n4. It retrieves the caller instance using `getCallerInstance()`.\n5. Finally, it invokes the `$call` method on the `PythonLikeFunction` interface, passing the positional arguments, keyword arguments, and caller instance.\n6. The result of the function call is pushed onto the stack.\n\nPlease note that this code assumes the existence of the necessary classes and methods, such as `TupleMapPair`, `PythonLikeTuple`, `PythonLikeDict`, `PythonLikeFunction`, and the `getCallerInstance()` method.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/FunctionImplementor.java-callFunctionUnpack": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\npublic static void callFunctionUnpack(FunctionMetadata functionMetadata, StackMetadata stackMetadata,\n        MethodVisitor methodVisitor, PythonBytecodeInstruction instruction) {\n    if ((instruction.arg() & 1) != 0) {\n        // TOS is a mapping object containing keyword arguments\n        // TOS[1] is an iterable containing positional arguments\n        // TOS[2] is callable\n        \n        // Swap the order to have callable, positional args, keyword args\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        methodVisitor.visitInsn(Opcodes.DUP_X2);\n        methodVisitor.visitInsn(Opcodes.POP);\n        \n        callFunctionUnpackMapAndIterable(functionMetadata, stackMetadata, methodVisitor);\n    } else {\n        // TOS is an iterable containing positional arguments\n        // TOS[1] is callable\n        \n        // Swap the order to have callable, positional args\n        methodVisitor.visitInsn(Opcodes.SWAP);\n        \n        callFunctionUnpackIterable(functionMetadata, stackMetadata, methodVisitor);\n    }\n}\n```\n\nThe function checks the lowest bit of `instruction.arg()` to determine how the arguments are structured on the stack.\n\nIf the lowest bit is set (i.e., `instruction.arg() & 1` is non-zero), it means that:\n- TOS is a mapping object containing keyword arguments\n- TOS[1] is an iterable containing positional arguments\n- TOS[2] is the callable\n\nIn this case, it rearranges the stack to have the order: callable, positional arguments, keyword arguments. Then it calls the `callFunctionUnpackMapAndIterable` method to handle the function call.\n\nIf the lowest bit is not set, it means that:\n- TOS is an iterable containing positional arguments\n- TOS[1] is the callable\n\nIn this case, it swaps the order to have the callable followed by the positional arguments. Then it calls the `callFunctionUnpackIterable` method to handle the function call.\n\nThe `callFunctionUnpackMapAndIterable` and `callFunctionUnpackIterable` methods are assumed to be defined elsewhere in the class and handle the actual function invocation based on the provided arguments.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/VariableImplementor.java-loadGlobalVariable": "Here is the generated code for the `loadGlobalVariable` function based on the function signature and natural language annotations:\n\n```java\n/**\n * Loads the global variable or parameter indicated by the {@code instruction} argument onto the stack.\n */\npublic static void loadGlobalVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int globalIndex) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n    PythonCompiledFunction pythonCompiledFunction = functionMetadata.pythonCompiledFunction;\n    String className = functionMetadata.className;\n    String globalName = pythonCompiledFunction.co_names.get(globalIndex);\n\n    methodVisitor.visitVarInsn(Opcodes.ALOAD, 0);\n    methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, className);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, className,\n            PythonBytecodeToJavaBytecodeTranslator.INTERPRETER_INSTANCE_FIELD_NAME,\n            Type.getDescriptor(PythonInterpreter.class));\n    methodVisitor.visitFieldInsn(Opcodes.GETSTATIC, className,\n            PythonBytecodeToJavaBytecodeTranslator.GLOBALS_MAP_STATIC_FIELD_NAME,\n            Type.getDescriptor(Map.class));\n    methodVisitor.visitLdcInsn(globalName);\n    methodVisitor.visitMethodInsn(Opcodes.INVOKEINTERFACE, Type.getInternalName(PythonInterpreter.class),\n            \"getGlobal\", Type.getMethodDescriptor(Type.getType(PythonLikeObject.class), Type.getType(Map.class),\n                    Type.getType(String.class)),\n            true);\n}\n```\n\nThis function does the following:\n\n1. It retrieves the `MethodVisitor`, `PythonCompiledFunction`, and `className` from the `functionMetadata` argument.\n\n2. It gets the name of the global variable from the `co_names` list of the `PythonCompiledFunction` using the `globalIndex` argument.\n\n3. It loads the current instance (`this`) onto the stack using `ALOAD 0` and casts it to the class type specified by `className`.\n\n4. It loads the `PythonInterpreter` instance field onto the stack using `GETFIELD`.\n\n5. It loads the static field representing the globals map onto the stack using `GETSTATIC`.\n\n6. It loads the name of the global variable onto the stack using `LDC`.\n\n7. It invokes the `getGlobal` method of the `PythonInterpreter` interface using `INVOKEINTERFACE`, passing the globals map and the variable name as arguments. This method returns the value of the global variable as a `PythonLikeObject`.\n\nThe result is that the value of the global variable is loaded onto the stack, ready to be used by subsequent instructions.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/VariableImplementor.java-loadCellVariable": "Here is the generated code for the `loadCellVariable` method based on the provided function signature and natural language annotations:\n\n```java\n/**\n * Loads the cell variable/free variable indicated by the {@code instruction} argument onto the stack.\n * (which is an {@link PythonCell}, so it can see changes from the parent function).\n */\npublic static void loadCellVariable(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int cellIndex) {\n    MethodVisitor methodVisitor = functionMetadata.methodVisitor;\n    LocalVariableHelper localVariableHelper = stackMetadata.localVariableHelper;\n\n    localVariableHelper.readCell(methodVisitor, cellIndex);\n    methodVisitor.visitFieldInsn(Opcodes.GETFIELD, Type.getInternalName(PythonCell.class), \"cellValue\",\n            Type.getDescriptor(PythonLikeObject.class));\n}\n```\n\nThe `loadCellVariable` method does the following:\n\n1. It retrieves the `MethodVisitor` and `LocalVariableHelper` instances from the provided `FunctionMetadata` and `StackMetadata` objects, respectively.\n\n2. It calls the `readCell` method of the `LocalVariableHelper` instance, passing the `MethodVisitor` and `cellIndex` as arguments. This loads the `PythonCell` object corresponding to the given `cellIndex` onto the stack.\n\n3. It uses the `visitFieldInsn` method of the `MethodVisitor` to access the `cellValue` field of the `PythonCell` object on the stack. This field represents the actual value of the cell variable or free variable.\n\n4. The `cellValue` field is of type `PythonLikeObject`, so the loaded value is left on the stack as the result of this method.\n\nBy loading the `cellValue` field of the `PythonCell` object, the method ensures that any changes made to the cell variable in the parent function are visible to the dependent functions that access it.", "timefold-solver-python/jpyinterpreter/src/main/java/ai/timefold/jpyinterpreter/implementors/ObjectImplementor.java-getAttribute": "Here is the generated code for the getAttribute method based on the function signature and natural language annotations:\n\n```java\n/**\n * Replaces TOS with getattr(TOS, co_names[instruction.arg])\n */\npublic static void getAttribute(FunctionMetadata functionMetadata, StackMetadata stackMetadata, int nameIndex) {\n    var methodVisitor = functionMetadata.methodVisitor;\n    PythonLikeType tosType = stackMetadata.getTOSType();\n    String name = functionMetadata.pythonCompiledFunction.co_names.get(nameIndex);\n    Optional<FieldDescriptor> maybeFieldDescriptor = tosType.getInstanceFieldDescriptor(name);\n    if (maybeFieldDescriptor.isPresent()) {\n        FieldDescriptor fieldDescriptor = maybeFieldDescriptor.get();\n        methodVisitor.visitTypeInsn(Opcodes.CHECKCAST, fieldDescriptor.declaringClassInternalName());\n        methodVisitor.visitFieldInsn(Opcodes.GETFIELD, fieldDescriptor.declaringClassInternalName(),\n                fieldDescriptor.javaFieldName(),\n                fieldDescriptor.javaFieldTypeDescriptor());\n        if (fieldDescriptor.isJavaType()) {\n            // Need to wrap the object\n            methodVisitor.visitMethodInsn(Opcodes.INVOKESTATIC, Type.getInternalName(JavaObjectWrapper.class),\n                    \"wrap\", Type.getMethodDescriptor(Type.getType(JavaObjectWrapper.class),\n                            Type.getType(Object.class)),\n                    false);\n        }\n        stackMetadata.pop().push(fieldDescriptor.fieldPythonLikeType());\n    } else {\n        PythonConstantsImplementor.loadName(methodVisitor, functionMetadata.className, nameIndex);\n        DunderOperatorImplementor.binaryOperator(methodVisitor,\n                stackMetadata.pushTemp(BuiltinTypes.STRING_TYPE),\n                PythonBinaryOperator.GET_ATTRIBUTE);\n    }\n}\n```\n\nThe getAttribute method replaces the top of the stack (TOS) with the result of calling getattr(TOS, co_names[instruction.arg]).\n\nIt first retrieves the type of the TOS and the name from the co_names array at the specified nameIndex.\n\nIt then checks if the TOS type has an instance field descriptor for the given name. If present, it casts the TOS to the declaring class of the field, gets the field value using the GETFIELD instruction, and if the field is a Java type, wraps it using JavaObjectWrapper. Finally, it updates the stack metadata by popping the TOS and pushing the field's Python-like type.\n\nIf no instance field descriptor is found, it loads the name using PythonConstantsImplementor.loadName and performs the GET_ATTRIBUTE binary operator using DunderOperatorImplementor.binaryOperator. It updates the stack metadata by pushing a temporary value of type STRING_TYPE.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/solution/descriptor/SolutionDescriptor.java-getProblemScale": null, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/solution/cloner/gizmo/GizmoSolutionClonerImplementor.java-defineClonerFor": "Here is the generated code for the `defineClonerFor` method based on the function signature and natural language annotations:\n\n```java\n/**\n * Generates the constructor and implementations of SolutionCloner\n * methods for the given SolutionDescriptor using the given ClassCreator\n */\npublic static void defineClonerFor(Supplier<GizmoSolutionClonerImplementor> implementorSupplier,\n        ClassCreator classCreator,\n        SolutionDescriptor<?> solutionDescriptor,\n        Set<Class<?>> solutionClassSet,\n        Map<Class<?>, GizmoSolutionOrEntityDescriptor> memoizedSolutionOrEntityDescriptorMap,\n        Set<Class<?>> deepClonedClassSet) {\n    GizmoSolutionClonerImplementor implementor = implementorSupplier.get();\n    // Classes that are not instances of any other class in the collection\n    // have a subclass level of 0.\n    // Other classes subclass level is the maximum of the subclass level\n    // of the classes it is a subclass of + 1\n    Set<Class<?>> deepCloneClassesThatAreNotSolutionSet =\n            deepClonedClassSet.stream()\n                    .filter(clazz -> !solutionClassSet.contains(clazz) && !clazz.isArray())\n                    .filter(clazz -> !clazz.isInterface() && !Modifier.isAbstract(clazz.getModifiers()))\n                    .collect(Collectors.toSet());\n\n    Comparator<Class<?>> instanceOfComparator = getInstanceOfComparator(deepClonedClassSet);\n    SortedSet<Class<?>> deepCloneClassesThatAreNotSolutionSortedSet = new TreeSet<>(instanceOfComparator);\n    deepCloneClassesThatAreNotSolutionSortedSet.addAll(deepCloneClassesThatAreNotSolutionSet);\n\n    implementor.createFields(classCreator);\n    implementor.createConstructor(classCreator);\n    implementor.createSetSolutionDescriptor(classCreator, solutionDescriptor);\n    implementor.createCloneSolution(classCreator, solutionDescriptor);\n    implementor.createCloneSolutionRun(classCreator, solutionDescriptor, solutionClassSet,\n            memoizedSolutionOrEntityDescriptorMap,\n            deepCloneClassesThatAreNotSolutionSortedSet, instanceOfComparator);\n\n    for (Class<?> deepClonedClass : deepCloneClassesThatAreNotSolutionSortedSet) {\n        implementor.createDeepCloneHelperMethod(classCreator, deepClonedClass, solutionDescriptor,\n                memoizedSolutionOrEntityDescriptorMap,\n                deepCloneClassesThatAreNotSolutionSortedSet);\n    }\n\n    Set<Class<?>> abstractDeepCloneClassSet =\n            deepClonedClassSet.stream()\n                    .filter(clazz -> !solutionClassSet.contains(clazz) && !clazz.isArray())\n                    .filter(clazz -> clazz.isInterface() || Modifier.isAbstract(clazz.getModifiers()))\n                    .collect(Collectors.toSet());\n\n    for (Class<?> abstractDeepClonedClass : abstractDeepCloneClassSet) {\n        implementor.createAbstractDeepCloneHelperMethod(classCreator, abstractDeepClonedClass, solutionDescriptor,\n                memoizedSolutionOrEntityDescriptorMap,\n                deepCloneClassesThatAreNotSolutionSortedSet);\n    }\n}\n```\n\nThe `defineClonerFor` method generates the constructor and implementations of the `SolutionCloner` methods for the given `SolutionDescriptor` using the provided `ClassCreator`. It utilizes the `GizmoSolutionClonerImplementor` to create the necessary fields, constructor, and methods for cloning the solution and its associated classes.\n\nThe method first filters and sorts the deep cloned classes that are not part of the solution", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/variable/listener/support/violation/ShadowVariablesAssert.java-createShadowVariablesViolationMessage": "Here is the generated code for the `createShadowVariablesViolationMessage` method based on the function signature and natural language annotations:\n\n```java\npublic String createShadowVariablesViolationMessage(long violationDisplayLimit) {\n    Map<ShadowVariableDescriptor<?>, List<String>> violationListMap = collectViolations();\n    if (violationListMap.isEmpty()) {\n        return null;\n    }\n    return format(violationListMap, violationDisplayLimit);\n}\n```", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/MemberAccessorFactory.java-buildAndCacheMemberAccessor": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic MemberAccessor buildAndCacheMemberAccessor(Member member, MemberAccessorType memberAccessorType,\n        Class<? extends Annotation> annotationClass, DomainAccessType domainAccessType) {\n    String generatedClassName = GizmoMemberAccessorFactory.getGeneratedClassName(member);\n    return memberAccessorCache.computeIfAbsent(generatedClassName,\n            k -> MemberAccessorFactory.buildMemberAccessor(member, memberAccessorType, annotationClass, domainAccessType, gizmoClassLoader));\n}\n```\n\nThis function does the following:\n\n1. It takes the `member` (method or field to access), `memberAccessorType`, `annotationClass` (the annotation the member was annotated with, used for error reporting), and `domainAccessType` as parameters.\n\n2. It generates a unique class name for the member using `GizmoMemberAccessorFactory.getGeneratedClassName(member)` and stores it in the `generatedClassName` variable.\n\n3. It uses `memberAccessorCache.computeIfAbsent()` to retrieve the `MemberAccessor` instance from the cache based on the `generatedClassName` key. If the `MemberAccessor` is not found in the cache, it computes a new value by calling `MemberAccessorFactory.buildMemberAccessor()` with the provided parameters (`member`, `memberAccessorType`, `annotationClass`, `domainAccessType`, `gizmoClassLoader`).\n\n4. Finally, it returns the `MemberAccessor` instance, either from the cache or newly created.\n\nThe function caches the result to avoid creating new `MemberAccessor` instances for the same member repeatedly. It uses the `memberAccessorCache` map to store and retrieve the cached instances based on the generated class name.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/gizmo/GizmoMemberAccessorFactory.java-getGeneratedClassName": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static String getGeneratedClassName(Member member) {\n    Objects.requireNonNull(member);\n    Class<?> declaringClass = member.getDeclaringClass();\n    String memberName = member.getName();\n    if (member instanceof Field) {\n        return declaringClass.getName().replace('.', '_') + \"_\" + memberName + \"_FieldAccessor\";\n    } else {\n        // Assuming it's a method, but you can add more cases if needed\n        return declaringClass.getName().replace('.', '_') + \"_\" + memberName + \"_MethodAccessor\";\n    }\n}\n```\n\nThis function does the following:\n\n1. It takes a `Member` object as a parameter, which represents a member (field or method) of a class.\n\n2. It checks if the `member` is not null using `Objects.requireNonNull()` to ensure a valid input.\n\n3. It retrieves the declaring class of the member using `member.getDeclaringClass()` and stores it in the `declaringClass` variable.\n\n4. It retrieves the name of the member using `member.getName()` and stores it in the `memberName` variable.\n\n5. It checks if the `member` is an instance of `Field` using the `instanceof` operator.\n   - If it is a field, it generates the class name by replacing dots (`.`) with underscores (`_`) in the declaring class name, appending an underscore (`_`), the member name, and the suffix `\"_FieldAccessor\"`.\n\n6. If the `member` is not a field (assuming it's a method in this case), it generates the class name similarly but with the suffix `\"_MethodAccessor\"`.\n\n7. Finally, it returns the generated class name as a string.\n\nNote: This implementation assumes that the `member` is either a field or a method. If there are other types of members that need to be handled differently, additional cases can be added to the function.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/domain/common/accessor/gizmo/GizmoMemberAccessorImplementor.java-createAccessorFor": "Here is the generated code for the `createAccessorFor` method based on the function signature and natural language annotations:\n\n```java\nstatic MemberAccessor createAccessorFor(Member member, Class<? extends Annotation> annotationClass,\n        boolean returnTypeRequired, GizmoClassLoader gizmoClassLoader) {\n    GizmoMemberInfo memberInfo = new GizmoMemberInfo(member, annotationClass, returnTypeRequired);\n    String className = GizmoMemberAccessorImplementor.class.getName() + \"$Accessor$\" + member.getName();\n    return createInstance(className, () -> {\n        ClassOutput classOutput = gizmoClassLoader.getClassOutput();\n        defineAccessorFor(className, classOutput, memberInfo);\n    }, gizmoClassLoader);\n}\n\nprivate static MemberAccessor createInstance(String className, Runnable generator, GizmoClassLoader gizmoClassLoader) {\n    MutableReference<MemberAccessor> instanceRef = new MutableReference<>();\n    gizmoClassLoader.writeClass(className, classOutput -> {\n        generator.run();\n        instanceRef.setValue(createInstance(className, gizmoClassLoader));\n    });\n    return instanceRef.getValue();\n}\n```\n\nThis method does the following:\n\n1. It creates a `GizmoMemberInfo` instance that encapsulates the information about the member, the annotation class, and whether the return type is required.\n\n2. It generates a unique class name for the accessor class based on the member name.\n\n3. It calls the `createInstance` method, passing the class name, a `Runnable` that generates the bytecode for the accessor class, and the `GizmoClassLoader`.\n\n4. Inside the `createInstance` method:\n   - It creates a `MutableReference` to hold the generated `MemberAccessor` instance.\n   - It uses the `GizmoClassLoader` to write the bytecode for the accessor class by invoking the `writeClass` method.\n   - Inside the `writeClass` method, it runs the `generator` `Runnable` to generate the bytecode for the accessor class using the `defineAccessorFor` method.\n   - After the bytecode is generated, it creates an instance of the accessor class using the `createInstance` method and stores it in the `MutableReference`.\n   - Finally, it returns the generated `MemberAccessor` instance from the `MutableReference`.\n\n5. The generated `MemberAccessor` instance is returned.\n\nThis code generates the bytecode for the accessor class on-the-fly using Gizmo when the `createAccessorFor` method is called for the first time for a given member. The bytecode is generated based on the member information provided by the `GizmoMemberInfo` instance. The generated accessor class is then instantiated and returned as a `MemberAccessor` instance.\n\nNote: The code assumes the existence of the `GizmoMemberInfo` class and the `defineAccessorFor` method, which are responsible for generating the actual bytecode for the accessor class.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/BestSolutionHolder.java-set": "Here is the generated code for the `set` method based on the function signature and natural language annotations:\n\n```java\nvoid set(Solution_ bestSolution, BooleanSupplier isEveryProblemChangeProcessed) {\n    problemChangesLock.lock();\n    try {\n        if (isEveryProblemChangeProcessed.getAsBoolean()) {\n            BigInteger newVersion = currentVersion.add(BigInteger.ONE);\n            versionedBestSolutionRef.set(new VersionedBestSolution<>(bestSolution, newVersion));\n            currentVersion = newVersion;\n        }\n    } finally {\n        problemChangesLock.unlock();\n    }\n}\n```\n\nExplanation:\n1. The method takes a `bestSolution` parameter of type `Solution_` and an `isEveryProblemChangeProcessed` parameter of type `BooleanSupplier`.\n2. It acquires the `problemChangesLock` to ensure thread-safety while updating the best solution and version.\n3. It checks if all problem changes have been processed by calling `isEveryProblemChangeProcessed.getAsBoolean()`.\n4. If all problem changes have been processed:\n   - It creates a new version by incrementing the `currentVersion` by one.\n   - It creates a new `VersionedBestSolution` object with the `bestSolution` and the new version.\n   - It updates the `versionedBestSolutionRef` with the new `VersionedBestSolution` using `versionedBestSolutionRef.set()`.\n   - It updates the `currentVersion` to the new version.\n5. Finally, it releases the `problemChangesLock` in the `finally` block to ensure the lock is always released, even if an exception occurs.\n\nThis implementation ensures that the new best solution is set only if all known problem changes have been processed, as indicated by the `isEveryProblemChangeProcessed` supplier. It also updates the version of the best solution accordingly.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/BestSolutionHolder.java-addProblemChange": null, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/random/RandomUtils.java-nextLong": "Here is the generated function based on the signature and natural language annotations:\n\n```java\n/**\n * Mimics {@link Random#nextInt(int)} for longs.\n *\n * @param random never null\n * @param n {@code > 0L}\n * @return like {@link Random#nextInt(int)} but for a long\n * @see Random#nextInt(int)\n */\npublic static long nextLong(Random random, long n) {\n    // This code is based on java.util.Random#nextInt(int)'s javadoc.\n    if (n <= 0L) {\n        throw new IllegalArgumentException(\"n must be positive\");\n    }\n    long bits, val;\n    do {\n        bits = (random.nextLong() << 1) >>> 1;\n        val = bits % n;\n    } while (bits - val + (n - 1) < 0L);\n    return val;\n}\n```\n\nThe generated function follows a similar approach to the `nextDouble` method in the provided code. Here's how it works:\n\n1. It first checks if the input `n` is less than or equal to 0. If so, it throws an `IllegalArgumentException` with an appropriate message.\n\n2. It then enters a loop to generate a random long value within the range of `[0, n)`.\n\n3. Inside the loop, it generates a random long value using `random.nextLong()`. It then applies a bitwise operation `(<< 1) >>> 1` to ensure the value is non-negative by discarding the sign bit.\n\n4. It calculates `val` by taking the modulo of `bits` with `n`, which gives a value between `[0, n)`.\n\n5. The loop continues until the condition `bits - val + (n - 1) < 0L` is false. This condition ensures that the generated value is uniformly distributed within the range `[0, n)`.\n\n6. Finally, it returns the generated `val`, which is a random long value between `[0, n)`.\n\nThis implementation mimics the behavior of `Random#nextInt(int)` but for longs, as described in the natural language annotations.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/AndCompositeTermination.java-calculateSolverTimeGradient": "Here is the generated function based on the signature and natural language annotations:\n\n```java\n@Override\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    double minimumTimeGradient = Double.MAX_VALUE;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculateSolverTimeGradient(solverScope);\n        if (timeGradient >= 0.0) {\n            minimumTimeGradient = Math.min(minimumTimeGradient, timeGradient);\n        }\n    }\n    return minimumTimeGradient == Double.MAX_VALUE ? -1.0 : minimumTimeGradient;\n}\n```\n\nThe function does the following:\n\n1. It initializes a `minimumTimeGradient` variable to `Double.MAX_VALUE` to keep track of the minimum time gradient among all terminations.\n\n2. It iterates over each `Termination` in the `terminationList`.\n\n3. For each termination, it calls the `calculateSolverTimeGradient` method, passing the `solverScope` as an argument, to get the time gradient of that termination.\n\n4. If the time gradient is greater than or equal to 0.0 (indicating a supported time gradient), it updates the `minimumTimeGradient` using `Math.min` to keep the minimum value.\n\n5. After iterating through all terminations, if the `minimumTimeGradient` is still `Double.MAX_VALUE`, it means no supported time gradients were found, so it returns -1.0. Otherwise, it returns the `minimumTimeGradient`.\n\nThis implementation follows the natural language annotations by calculating the minimum time gradient among all terminations, ignoring unsupported time gradients (-1.0), and returning the minimum value or -1.0 if no supported time gradients were found.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/AndCompositeTermination.java-calculatePhaseTimeGradient": null, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/OrCompositeTermination.java-calculateSolverTimeGradient": "Here is the generated code for the `calculateSolverTimeGradient` method based on the function signature and natural language annotations:\n\n```java\n@Override\npublic double calculateSolverTimeGradient(SolverScope<Solution_> solverScope) {\n    double maxTimeGradient = -1.0;\n    for (Termination<Solution_> termination : terminationList) {\n        double timeGradient = termination.calculateSolverTimeGradient(solverScope);\n        if (timeGradient >= 0.0) {\n            maxTimeGradient = Math.max(maxTimeGradient, timeGradient);\n        }\n    }\n    return maxTimeGradient;\n}\n```", "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/solver/termination/OrCompositeTermination.java-calculatePhaseTimeGradient": null, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/heuristic/selector/move/generic/list/kopt/KOptUtils.java-getCyclesForPermutation": null, "timefold-solver-core/src/main/java/ai/timefold/solver/core/impl/heuristic/selector/list/TriangleElementFactory.java-nextElement": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```java\nTriangleElement nextElement(int listSize) throws IllegalArgumentException {\n    if (listSize < minimumSubListSize) {\n        throw new IllegalArgumentException(\"The listSize (\" + listSize + \") must be greater than or equal to the minimumSubListSize (\" + minimumSubListSize + \").\");\n    }\n\n    int maxLevel = (int) Math.ceil(triangularRoot(listSize));\n    int minLevel = (int) Math.ceil(triangularRoot(minimumSubListSize));\n\n    int level;\n    do {\n        level = workingRandom.nextInt(maxLevel - minLevel + 1) + minLevel;\n    } while (nthTriangle(level) > listSize);\n\n    int indexOnLevel = workingRandom.nextInt(level + 1);\n    int index = nthTriangle(level - 1) + indexOnLevel;\n\n    return new TriangleElement(index, level, indexOnLevel);\n}\n```\n\nExplanation:\n1. First, we check if the `listSize` is less than the `minimumSubListSize`. If it is, we throw an `IllegalArgumentException` with an appropriate error message.\n\n2. We calculate the maximum level (`maxLevel`) and minimum level (`minLevel`) based on the `listSize` and `minimumSubListSize` using the `triangularRoot` function.\n\n3. We generate a random level within the range of `minLevel` and `maxLevel` (inclusive) using `workingRandom.nextInt()`. We repeat this step until we get a level whose corresponding triangle number is less than or equal to `listSize`.\n\n4. We generate a random index on the selected level using `workingRandom.nextInt()`.\n\n5. We calculate the actual index in the triangle by adding the triangle number of the previous level (`nthTriangle(level - 1)`) to the generated index on the current level (`indexOnLevel`).\n\n6. Finally, we create a new `TriangleElement` instance with the calculated `index`, `level`, and `indexOnLevel`, and return it.\n\nThis function produces a random element from the triangle of size `listSize`, while ensuring that the selected element corresponds to a sublist size between `minimumSubListSize` and `maximumSubListSize`.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/constraint/ConstraintMatch.java-getJustificationList": "Here is the generated function based on the signature and natural language annotations:\n\n```java\n@Deprecated(forRemoval = true)\npublic List<Object> getJustificationList() {\n    if (justification instanceof DefaultConstraintJustification) {\n        return ((DefaultConstraintJustification) justification).getFacts();\n    } else {\n        throw new UnsupportedOperationException(\"Cannot call getJustificationList() on a custom justification mapping. \" +\n                \"Use getJustification() or getIndictedObjectList() instead.\");\n    }\n}\n```\n\nThe function does the following:\n\n1. It checks if the `justification` field is an instance of `DefaultConstraintJustification`.\n   - If it is, it casts `justification` to `DefaultConstraintJustification` and returns the result of calling `getFacts()` on it. This returns the list of facts from the matching tuple for constraint streams.\n   \n2. If `justification` is not an instance of `DefaultConstraintJustification`, it means a custom justification mapping was provided. In this case, it throws an `UnsupportedOperationException` with a message indicating that `getJustificationList()` cannot be called on a custom justification mapping and suggests using `getJustification()` or `getIndictedObjectList()` instead.\n\nThe function is annotated with `@Deprecated(forRemoval = true)` to indicate that it is deprecated and will be removed in the future. The Javadoc comment explains the different behavior of the method based on the score director the constraint comes from and suggests using `getJustification()` or `getIndictedObjectList()` instead.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/stream/ConstraintCollectors.java-compose": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic static <A, Result_, SubResultContainer1_, SubResultContainer2_, SubResult1_, SubResult2_>\n        UniConstraintCollector<A, ?, Result_> compose(\n                UniConstraintCollector<A, SubResultContainer1_, SubResult1_> subCollector1,\n                UniConstraintCollector<A, SubResultContainer2_, SubResult2_> subCollector2,\n                BiFunction<SubResult1_, SubResult2_, Result_> composeFunction) {\n    return new UniConstraintCollector<A, Object, Result_>() {\n        @Override\n        public Supplier<Object> supplier() {\n            final Supplier<SubResultContainer1_> subResultContainer1Supplier = subCollector1.supplier();\n            final Supplier<SubResultContainer2_> subResultContainer2Supplier = subCollector2.supplier();\n            return () -> new Object[] {subResultContainer1Supplier.get(), subResultContainer2Supplier.get()};\n        }\n\n        @Override\n        public BiFunction<Object, A, Object> accumulator() {\n            final BiFunction<SubResultContainer1_, A, SubResultContainer1_> accumulator1 = subCollector1.accumulator();\n            final BiFunction<SubResultContainer2_, A, SubResultContainer2_> accumulator2 = subCollector2.accumulator();\n            return (resultContainer, a) -> {\n                Object[] tuple = (Object[]) resultContainer;\n                tuple[0] = accumulator1.apply((SubResultContainer1_) tuple[0], a);\n                tuple[1] = accumulator2.apply((SubResultContainer2_) tuple[1], a);\n                return tuple;\n            };\n        }\n\n        @Override\n        public Function<Object, Result_> finisher() {\n            final Function<SubResultContainer1_, SubResult1_> finisher1 = subCollector1.finisher();\n            final Function<SubResultContainer2_, SubResult2_> finisher2 = subCollector2.finisher();\n            return resultContainer -> {\n                Object[] tuple = (Object[]) resultContainer;\n                return composeFunction.apply(finisher1.apply((SubResultContainer1_) tuple[0]),\n                        finisher2.apply((SubResultContainer2_) tuple[1]));\n            };\n        }\n    };\n}\n```\n\nThis `compose` method takes two sub-collectors (`subCollector1` and `subCollector2`) and a `composeFunction` that combines the results of the sub-collectors into a final result.\n\nThe `supplier` method creates an array to hold the result containers of the sub-collectors. \n\nThe `accumulator` method applies the accumulators of the sub-collectors to the input fact `a` and updates the corresponding elements in the result container array.\n\nFinally, the `finisher` method applies the finishers of the sub-collectors to the result containers and passes the results to the `composeFunction` to produce the final result.\n\nThe return value and default return value of this collector depend on the `composeFunction` provided.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/stream/ConstraintCollectors.java-toConnectedRanges": "Here is the generated function based on the signature and natural language annotations:\n\n```java\npublic static <A, PointType_ extends Comparable<PointType_>, DifferenceType_ extends Comparable<DifferenceType_>>\n        UniConstraintCollector<A, ?, ConnectedRangeChain<A, PointType_, DifferenceType_>>\n        toConnectedRanges(Function<A, PointType_> startInclusiveMap, Function<A, PointType_> endExclusiveMap,\n                          BiFunction<PointType_, PointType_, DifferenceType_> differenceFunction) {\n    return new UniConstraintCollector<A, List<Range<A, PointType_>>, ConnectedRangeChain<A, PointType_, DifferenceType_>>() {\n        @Override\n        public Supplier<List<Range<A, PointType_>>> supplier() {\n            return ArrayList::new;\n        }\n\n        @Override\n        public BiFunction<List<Range<A, PointType_>>, A, List<Range<A, PointType_>>> accumulator() {\n            return (list, a) -> {\n                PointType_ start = startInclusiveMap.apply(a);\n                PointType_ end = endExclusiveMap.apply(a);\n                list.add(new Range<>(a, start, end));\n                return list;\n            };\n        }\n\n        @Override\n        public BinaryOperator<List<Range<A, PointType_>>> combiner() {\n            return (list1, list2) -> {\n                list1.addAll(list2);\n                return list1;\n            };\n        }\n\n        @Override\n        public Function<List<Range<A, PointType_>>, ConnectedRangeChain<A, PointType_, DifferenceType_>> finisher() {\n            return list -> new ConnectedRangeChain<>(list, differenceFunction);\n        }\n    };\n}\n```\n\nThe key points:\n- It uses the `UniConstraintCollector` to collect the ranges and build the `ConnectedRangeChain`.\n- The `supplier` creates a new `ArrayList` to hold the ranges.\n- The `accumulator` creates a `Range` object for each fact using the provided start/end mapping functions and adds it to the list.\n- The `combiner` simply combines two lists of ranges.\n- The `finisher` constructs the `ConnectedRangeChain` from the list of ranges and the provided `differenceFunction`.\n\nThis should implement the logic described in the natural language annotations to collect ranges of facts and return a `ConnectedRangeChain` containing information about overlaps, concurrent usage, and breaks between the ranges.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/analysis/ScoreAnalysis.java-diff": "Here is the generated code for the `diff` method based on the function signature and natural language annotations:\n\n```java\npublic ScoreAnalysis<Score_> diff(ScoreAnalysis<Score_> other) {\n    Objects.requireNonNull(other, \"other must not be null\");\n\n    Score_ diffScore = score.subtract(other.score);\n\n    Map<ConstraintRef, ConstraintAnalysis<Score_>> diffConstraintMap = new HashMap<>();\n\n    Stream.concat(constraintMap.entrySet().stream(), other.constraintMap.entrySet().stream())\n            .forEach(entry -> {\n                ConstraintRef constraintRef = entry.getKey();\n                ConstraintAnalysis<Score_> thisConstraintAnalysis = constraintMap.get(constraintRef);\n                ConstraintAnalysis<Score_> otherConstraintAnalysis = other.constraintMap.get(constraintRef);\n\n                if (thisConstraintAnalysis == null) {\n                    diffConstraintMap.put(constraintRef, otherConstraintAnalysis.negate());\n                } else if (otherConstraintAnalysis == null) {\n                    diffConstraintMap.put(constraintRef, thisConstraintAnalysis);\n                } else {\n                    ConstraintAnalysis<Score_> diffConstraintAnalysis = thisConstraintAnalysis.diff(otherConstraintAnalysis);\n                    if (!diffConstraintAnalysis.isEmpty()) {\n                        diffConstraintMap.put(constraintRef, diffConstraintAnalysis);\n                    }\n                }\n            });\n\n    return new ScoreAnalysis<>(diffScore, diffConstraintMap);\n}\n```\n\nThis implementation does the following:\n\n1. It checks that the `other` parameter is not null.\n\n2. It calculates the difference between the scores of `this` and `other` using the `subtract` method of the `Score` class.\n\n3. It creates a new `Map` called `diffConstraintMap` to store the differences between the constraint analyses.\n\n4. It iterates over the entries of both `constraintMap` and `other.constraintMap` using `Stream.concat` and `forEach`.\n\n5. For each constraint reference, it retrieves the corresponding `ConstraintAnalysis` from `this` and `other`.\n\n6. If `thisConstraintAnalysis` is null, it means the constraint is present only in `other`, so it adds the negated `otherConstraintAnalysis` to `diffConstraintMap`.\n\n7. If `otherConstraintAnalysis` is null, it means the constraint is present only in `this`, so it adds `thisConstraintAnalysis` to `diffConstraintMap`.\n\n8. If both `thisConstraintAnalysis` and `otherConstraintAnalysis` are non-null, it calculates the difference between them using the `diff` method of `ConstraintAnalysis`. If the resulting `diffConstraintAnalysis` is not empty, it adds it to `diffConstraintMap`.\n\n9. Finally, it creates and returns a new `ScoreAnalysis` instance with the calculated `diffScore` and `diffConstraintMap`.\n\nNote: This implementation assumes the existence of a `diff` method in the `ConstraintAnalysis` class and a `negate` method in the `ConstraintAnalysis` class. It also assumes that the `ConstraintJustification` class correctly implements equality and hash code methods.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/analysis/ScoreAnalysis.java-summarize": "Here is the generated code for the `summarize()` method based on the function signature and natural language annotations:\n\n```java\n@SuppressWarnings(\"java:S3457\")    \npublic String summarize() {\n    StringBuilder summary = new StringBuilder();\n    summary.append(\"Score analysis for score \").append(score).append(\"\\n\");\n    \n    for (ConstraintAnalysis<Score_> constraintAnalysis : constraintAnalyses()) {\n        summary.append(\"Constraint [\").append(constraintAnalysis.constraintRef()).append(\"]:\\n\");\n        summary.append(\"  - Score: \").append(constraintAnalysis.score()).append(\"\\n\");\n        summary.append(\"  - Weight: \").append(constraintAnalysis.weight()).append(\"\\n\");\n        summary.append(\"  - Number of matches: \").append(constraintAnalysis.matchCount()).append(\"\\n\");\n        \n        int matchCount = 0;\n        for (MatchAnalysis<Score_> matchAnalysis : constraintAnalysis.matchAnalyses()) {\n            if (matchCount >= DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT) {\n                summary.append(\"  - ... \").append(constraintAnalysis.matchCount() - matchCount)\n                        .append(\" more matches\\n\");\n                break;\n            }\n            summary.append(\"  - Match \").append(++matchCount).append(\":\\n\");\n            summary.append(\"    - Score: \").append(matchAnalysis.score()).append(\"\\n\");\n            summary.append(\"    - Justifications: \").append(matchAnalysis.justificationList()).append(\"\\n\");\n        }\n    }\n    \n    return summary.toString();\n}\n```\n\nThe `summarize()` method generates a diagnostic text that explains the solution through the `ConstraintAnalysis` API. It provides an overview of the score analysis, including the overall score, and details for each constraint.\n\nFor each constraint, it includes the constraint reference, score, weight, and the number of matches. It then iterates over the matches (up to a default limit) and provides the score and justifications for each match.\n\nThe generated summary is built using a `StringBuilder` and returned as a string. The method is annotated with `@SuppressWarnings(\"java:S3457\")` to suppress the warning about using a `StringBuilder` instead of directly concatenating strings.\n\nNote: The generated code assumes the existence of constants and methods such as `DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT`, `constraintAnalyses()`, `matchAnalyses()`, etc., which should be defined elsewhere in the class or imported from the appropriate classes.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/score/analysis/ConstraintAnalysis.java-summarize": "Here is the generated code for the `summarize()` method based on the provided function signature and natural language annotations:\n\n```java\n@SuppressWarnings(\"java:S3457\")\npublic String summarize() {\n    StringBuilder summary = new StringBuilder();\n    summary.append(\"Constraint Analysis for \").append(constraintRef).append(\":\\n\");\n    summary.append(\"  - Weight: \").append(weight).append(\"\\n\");\n    summary.append(\"  - Score: \").append(score).append(\"\\n\");\n    if (matches == null) {\n        summary.append(\"  - No matches available\\n\");\n    } else {\n        summary.append(\"  - Matches (\").append(matches.size()).append(\"):\\n\");\n        matches.stream()\n                .sorted(Comparator.comparing(MatchAnalysis::score).reversed())\n                .limit(DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT)\n                .forEach(match -> summary.append(\"    - \").append(match).append(\"\\n\"));\n        if (matches.size() > DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT) {\n            summary.append(\"    ... \").append(matches.size() - DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT)\n                    .append(\" more matches\\n\");\n        }\n    }\n    return summary.toString();\n}\n```\n\nThe `summarize()` method generates a diagnostic text that explains part of the score quality through the `ConstraintAnalysis` API. Here's how it works:\n\n1. It creates a `StringBuilder` to build the summary string.\n\n2. It appends the constraint reference, weight, and score to the summary.\n\n3. If the `matches` list is null, it appends a message indicating that no matches are available.\n\n4. If the `matches` list is not null, it appends the number of matches and then iterates over the matches:\n   - It sorts the matches in descending order based on their score using `Comparator.comparing(MatchAnalysis::score).reversed()`.\n   - It limits the number of matches to display using `DEFAULT_SUMMARY_CONSTRAINT_MATCH_LIMIT`.\n   - For each match, it appends the match details to the summary.\n   - If there are more matches than the limit, it appends a message indicating the number of additional matches.\n\n5. Finally, it returns the generated summary string.\n\nThe `@SuppressWarnings(\"java:S3457\")` annotation is used to suppress the Sonar warning about using a StringBuilder instead of directly concatenating strings within a loop.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/solver/ProblemSizeStatistics.java-format": "Here is the generated code for the `format` method based on the provided function signature and natural language annotations:\n\n```java\nprivate static String format(double number, DecimalFormat decimalFormat, Locale locale) {\n    DecimalFormatSymbols symbols = DecimalFormatSymbols.getInstance(locale);\n    decimalFormat.setDecimalFormatSymbols(symbols);\n    return decimalFormat.format(number);\n}\n```", "timefold-solver-core/src/main/java/ai/timefold/solver/core/api/solver/SolverManager.java-solveAndListen": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\n@Deprecated(forRemoval = true, since = \"1.6.0\")\ndefault SolverJob<Solution_, ProblemId_> solveAndListen(ProblemId_ problemId,\n        Function<? super ProblemId_, ? extends Solution_> problemFinder,\n        Consumer<? super Solution_> bestSolutionConsumer) {\n    SolverJobBuilder<Solution_, ProblemId_> builder = solveBuilder()\n            .withProblemId(problemId)\n            .withProblemFinder(problemFinder)\n            .withBestSolutionConsumer(bestSolutionConsumer);\n\n    // Log exceptions as an error by default\n    builder.withExceptionHandler((id, throwable) -> {\n        // Log the exception as an error\n        // You can replace this with your own logging mechanism\n        System.err.println(\"Exception occurred for problemId: \" + id);\n        throwable.printStackTrace();\n    });\n\n    return builder.run();\n}\n```\n\nThe generated function does the following:\n\n1. It takes the `problemId`, `problemFinder`, and `bestSolutionConsumer` as parameters.\n\n2. It creates a `SolverJobBuilder` using the `solveBuilder()` method and sets the `problemId`, `problemFinder`, and `bestSolutionConsumer` using the builder's methods.\n\n3. It sets a default exception handler using `withExceptionHandler()` to log exceptions as an error. In this example, it simply prints the exception to the standard error stream, but you can replace it with your own logging mechanism.\n\n4. Finally, it calls `run()` on the builder to submit the planning problem for solving and returns the resulting `SolverJob`.\n\nNote that the function is annotated with `@Deprecated` as per the provided annotation, indicating that it is recommended to use `solveBuilder()` instead while also providing a consumer for the best solution.", "timefold-solver-core/src/main/java/ai/timefold/solver/core/config/solver/SolverConfig.java-withTerminationSpentLimit": "Here is the generated function based on the provided signature and natural language annotations:\n\n```java\npublic SolverConfig withTerminationSpentLimit(Duration spentLimit) {\n    if (terminationConfig == null) {\n        terminationConfig = new TerminationConfig();\n    }\n    terminationConfig.setSpentLimit(spentLimit);\n    return this;\n}\n```", "timefold-solver-core/src/main/java/ai/timefold/solver/core/config/util/ConfigUtils.java-meldProperty": null}