{"litestar-litestar/file_system.py-info": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def info(self, path: PathType, **kwargs: Any) -> FileInfo:\n    \"\"\"Retrieve information about a given file path.\n\n    Args:\n        path: A file path.\n        **kwargs: Any additional kwargs.\n\n    Returns:\n        A dictionary of file info.\n    \"\"\"\n    try:\n        stat_result = await sync_to_thread(Path(path).stat)\n        return await self.parse_stat_result(path, stat_result)\n    except FileNotFoundError as e:\n        raise e\n    except PermissionError as e:\n        raise NotAuthorizedException(f\"failed to read {path} due to missing permissions\") from e\n    except OSError as e:\n        raise InternalServerException from e\n```\n\nThis function does the following:\n\n1. It takes a `path` argument of type `PathType` and any additional keyword arguments (`**kwargs`).\n\n2. It uses `sync_to_thread` to asynchronously call `Path(path).stat()` and retrieve the `stat_result` for the given file path.\n\n3. It then calls the `parse_stat_result` method (assumed to be defined in the same class) to convert the `stat_result` into a `FileInfo` dictionary.\n\n4. If a `FileNotFoundError` is raised, it re-raises the exception.\n\n5. If a `PermissionError` is raised, it raises a `NotAuthorizedException` with a custom error message indicating missing permissions to read the file.\n\n6. If any other `OSError` is raised, it raises an `InternalServerException`.\n\n7. Finally, it returns the `FileInfo` dictionary containing the file information.\n\nNote: The function assumes that the necessary imports and custom exceptions (`NotAuthorizedException` and `InternalServerException`) are defined in the same file or imported appropriately.", "litestar-litestar/typing.py-has_inner_subclass_of": null, "litestar-litestar/typing.py-get_type_hints": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef get_type_hints(self, *, include_extras: bool = False, resolve_generics: bool = False) -> dict[str, Any]:\n    \"\"\"Get the type hints for the annotation.\n\n    Args:\n        include_extras: Flag to indicate whether to include ``Annotated[T, ...]`` or not.\n        resolve_generics: Flag to indicate whether to resolve the generic types in the type hints or not.\n\n    Returns:\n        The type hints.\n    \"\"\"\n    if resolve_generics:\n        return get_type_hints_with_generics_resolved(self.annotation, include_extras=include_extras)\n    else:\n        return get_type_hints(self.annotation, include_extras=include_extras)\n```\n\nThis function does the following:\n\n1. It takes two optional boolean arguments: `include_extras` (default `False`) and `resolve_generics` (default `False`).\n\n2. If `resolve_generics` is `True`, it calls the `get_type_hints_with_generics_resolved` function from the `litestar.utils.typing` module, passing the `self.annotation` and `include_extras` arguments. This function resolves the generic types in the type hints.\n\n3. If `resolve_generics` is `False`, it directly calls the `get_type_hints` function from the `typing_extensions` module, passing the `self.annotation` and `include_extras` arguments. This function returns the type hints without resolving the generic types.\n\n4. Finally, it returns the obtained type hints as a dictionary mapping field names to their corresponding types.\n\nThe function allows the caller to control whether to include extra annotations (`Annotated[T, ...]`) and whether to resolve generic types in the type hints.", "litestar-litestar/typing.py-from_kwarg": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef from_kwarg(\n    cls,\n    annotation: Any,\n    name: str,\n    default: Any = Empty,\n    inner_types: tuple[FieldDefinition, ...] = (),\n    kwarg_definition: KwargDefinition | None = None,\n    extra: dict[str, Any] | None = None,\n) -> FieldDefinition:\n    \"\"\"Create a new FieldDefinition instance.\n\n    Args:\n        annotation: The type of the kwarg.\n        name: Field name.\n        default: A default value.\n        inner_types: A tuple of FieldDefinition instances representing the inner types, if any.\n        kwarg_definition: Kwarg Parameter.\n        extra: A mapping of extra values.\n\n    Returns:\n        FieldDefinition instance.\n    \"\"\"\n    return cls.from_annotation(\n        annotation=annotation,\n        name=name,\n        default=default,\n        inner_types=inner_types,\n        kwarg_definition=kwarg_definition,\n        extra=extra,\n    )\n```", "litestar-litestar/typing.py-from_parameter": "Here is the generated code for the `from_parameter` function:\n\n```python\n@classmethod\ndef from_parameter(cls, parameter: Parameter, fn_type_hints: dict[str, Any]) -> FieldDefinition:\n    \"\"\"Initialize ParsedSignatureParameter.\n\n    Args:\n        parameter: inspect.Parameter\n        fn_type_hints: mapping of names to types. Should be result of ``get_type_hints()``, preferably via the\n            :attr:``get_fn_type_hints() <.utils.signature_parsing.get_fn_type_hints>`` helper.\n\n    Returns:\n        ParsedSignatureParameter.\n\n    \"\"\"\n    annotation = fn_type_hints.get(parameter.name, parameter.annotation)\n    default = parameter.default if parameter.default is not Parameter.empty else Empty\n    return cls.from_annotation(annotation=annotation, name=parameter.name, default=default)\n```\n\nThis implementation does the following:\n\n1. It retrieves the annotation for the parameter from the `fn_type_hints` dictionary using the parameter's name as the key. If the annotation is not found in `fn_type_hints`, it falls back to the parameter's own `annotation` attribute.\n\n2. It checks if the parameter has a default value by comparing it with `Parameter.empty`. If the default value is not `Parameter.empty`, it assigns it to the `default` variable. Otherwise, it assigns the `Empty` value to indicate no default.\n\n3. Finally, it calls the `from_annotation` class method, passing the `annotation`, `name`, and `default` values as arguments to create and return a new `FieldDefinition` instance.\n\nThe `from_parameter` function provides a convenient way to create a `FieldDefinition` instance directly from an `inspect.Parameter` object, utilizing the type hints provided in the `fn_type_hints` dictionary.", "litestar-litestar/_openapi/responses.py-create_success_response": "Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef create_success_response(self) -> OpenAPIResponse:\n    \"\"\"Create the schema for a success response.\"\"\"\n    if self.field_definition.annotation in [Stream, File]:\n        return self.create_file_response()\n    elif self.field_definition.annotation is Redirect:\n        return self.create_redirect_response()\n    elif self.field_definition.annotation is Template:\n        return OpenAPIResponse(\n            description=self.create_description(), \n            content={MediaType.HTML: OpenAPIMediaType()}\n        )\n    elif self.field_definition.annotation is NoneType:\n        return OpenAPIResponse(description=self.create_description())\n    else:\n        response = OpenAPIResponse(\n            description=self.create_description(),\n            content={\n                self.route_handler.media_type: OpenAPIMediaType(\n                    schema=self.schema_creator.for_field_definition(self.field_definition),\n                    examples=get_formatted_examples(self.field_definition),\n                )\n            },\n        )\n        self.set_success_response_headers(response)\n        return response\n```\n\nThis function does the following:\n\n1. It checks the annotation of the `field_definition` attribute to determine the type of success response to create.\n\n2. If the annotation is `Stream` or `File`, it calls the `create_file_response()` method to create a file/stream response.\n\n3. If the annotation is `Redirect`, it calls the `create_redirect_response()` method to create a redirect response.\n\n4. If the annotation is `Template`, it returns an `OpenAPIResponse` with a description and content type set to `MediaType.HTML`.\n\n5. If the annotation is `NoneType`, it returns an `OpenAPIResponse` with only a description.\n\n6. For any other annotation, it creates an `OpenAPIResponse` with a description, content type based on the `route_handler.media_type`, and a schema generated using the `schema_creator.for_field_definition()` method. It also includes examples if available.\n\n7. Finally, it calls the `set_success_response_headers()` method to set any additional headers for the success response.\n\nThe function returns the created `OpenAPIResponse` instance.", "litestar-litestar/_openapi/responses.py-create_additional_responses": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef create_additional_responses(self) -> Iterator[tuple[str, OpenAPIResponse]]:\n    \"\"\"Create the schema for additional responses, if any.\"\"\"\n    field_type = self.field_definition.annotation\n    if field_type is Stream or field_type is File:\n        yield str(self.route_handler.status_code), self.create_file_response()\n    elif field_type is Redirect:\n        yield str(self.route_handler.status_code), self.create_redirect_response()\n    elif field_type is Template:\n        yield str(self.route_handler.status_code), self.create_template_response()\n    elif field_type is LitestarResponse:\n        yield str(self.route_handler.status_code), self.create_litestar_response()\n    elif field_type is ASGIResponse:\n        yield str(self.route_handler.status_code), self.create_asgi_response()\n    else:\n        response = self.create_success_response()\n        self.set_success_response_headers(response)\n        yield str(self.route_handler.status_code), response\n```\n\nThis function generates additional responses based on the return type annotation of the route handler. It checks for specific types like `Stream`, `File`, `Redirect`, `Template`, `LitestarResponse`, and `ASGIResponse`, and calls the corresponding methods to create the appropriate response schemas.\n\nIf the return type does not match any of the specific types, it creates a success response using `create_success_response()` and sets the headers using `set_success_response_headers()`.\n\nFinally, it yields a tuple of the status code and the created response schema for each additional response.", "litestar-litestar/_openapi/path_item.py-create_path_item": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef create_path_item(self) -> PathItem:\n    \"\"\"Create a PathItem for the given route parsing all http_methods into Operation Models.\n\n    Returns:\n        A PathItem instance.\n    \"\"\"\n    for http_method, route_handler in self.route.http_handlers.items():\n        operation = self.create_operation_for_handler_method(route_handler, http_method)\n        setattr(self._path_item, http_method.value.lower(), operation)\n\n    if self.route.path_parameters:\n        self._path_item.parameters = create_parameters_for_handler(\n            self.context, None, self.route.path_parameters\n        )\n\n    return self._path_item\n```\n\nThis function does the following:\n\n1. It iterates over the `http_handlers` dictionary of the `self.route` object, which contains the route handlers for each HTTP method.\n\n2. For each `http_method` and `route_handler` pair, it calls the `self.create_operation_for_handler_method()` method to create an `Operation` instance for the given route handler and HTTP method.\n\n3. It sets the created `operation` as an attribute of `self._path_item` using the lowercase value of the `http_method` as the attribute name. This adds the operation to the corresponding HTTP method of the `PathItem`.\n\n4. If the `self.route` has path parameters (`self.route.path_parameters` is not empty), it creates parameters for the route using the `create_parameters_for_handler()` function and assigns them to `self._path_item.parameters`.\n\n5. Finally, it returns the `self._path_item` instance, which represents the `PathItem` for the given route with all the operations and parameters set.\n\nThis function creates a `PathItem` instance for the given route by parsing all the HTTP methods and their corresponding route handlers into `Operation` models and adding them to the `PathItem`.", "litestar-litestar/_openapi/schema_generation/schema.py-for_field_definition": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef for_field_definition(self, field_definition: FieldDefinition) -> Schema | Reference:\n    \"\"\"Create a Schema for a given FieldDefinition.\n\n    Args:\n        field_definition: A signature field instance.\n\n    Returns:\n        A schema instance.\n    \"\"\"\n    if plugin := self.get_plugin_for(field_definition):\n        return self.for_plugin(field_definition, plugin)\n\n    if field_definition.is_new_type:\n        return self.for_new_type(field_definition)\n\n    if field_definition.is_optional:\n        return self.for_optional_field(field_definition)\n\n    if field_definition.is_union:\n        return self.for_union_field(field_definition)\n\n    if self.is_constrained_field(field_definition):\n        return self.for_constrained_field(field_definition)\n\n    if _should_create_enum_schema(field_definition):\n        return create_enum_schema(field_definition.annotation, field_definition.allow_none)\n\n    if _should_create_literal_schema(field_definition):\n        return create_literal_schema(field_definition.annotation, field_definition.allow_none)\n\n    if field_definition.is_object_type:\n        return self.for_object_type(field_definition)\n\n    if field_definition.is_typevar:\n        return self.for_typevar()\n\n    schema = create_schema_for_annotation(field_definition.annotation)\n    if schema:\n        return self.process_schema_result(field_definition, schema)\n\n    raise ImproperlyConfiguredException(\n        f\"Could not generate schema for field '{field_definition.name}' with \"\n        f\"type '{field_definition.annotation}'\"\n    )\n```\n\nThis function takes a `FieldDefinition` instance and returns a corresponding `Schema` or `Reference` instance based on the field definition's properties and annotations.\n\nIt checks for various conditions and delegates the schema creation to specific methods based on the field definition's characteristics, such as:\n- If a plugin exists for the field definition, it uses the plugin to create the schema.\n- If the field is a new type, it creates a schema for the new type.\n- If the field is optional, it creates a schema for an optional field.\n- If the field is a union, it creates a schema for a union field.\n- If the field is constrained, it creates a schema for a constrained field.\n- If the field should be an enum schema, it creates an enum schema.\n- If the field should be a literal schema, it creates a literal schema.\n- If the field is an object type, it creates a schema for an object type.\n- If the field is a type variable, it creates a schema for a type variable.\n\nIf none of the above conditions are met, it attempts to create a schema directly from the field's annotation using the `create_schema_for_annotation` function.\n\nFinally, it processes the resulting schema using the `process_schema_result` method before returning it.\n\nIf no schema can be generated for the given field definition, it raises an `ImproperlyConfiguredException`.", "litestar-litestar/_openapi/typescript_converter/converter.py-convert_openapi_to_typescript": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef convert_openapi_to_typescript(openapi_schema: OpenAPI, namespace: str = \"API\") -> TypeScriptNamespace:\n    \"\"\"Convert an OpenAPI Schema instance to a TypeScript namespace.\n\n    This function is the main entry point for the TypeScript converter.\n\n    Args:\n        openapi_schema: An OpenAPI Schema instance.\n        namespace: The namespace to use.\n\n    Returns:\n        A TypeScriptNamespace representing the generated types.\n    \"\"\"\n    components = openapi_schema.components\n    operations: dict[str, tuple[TypeScriptNamespace, ...]] = {}\n    for path, path_item in openapi_schema.paths.items():\n        for method in HttpMethod:\n            if operation := getattr(path_item, method.value):\n                operation = cast(Operation, deref_container(operation, components=components))\n                operations[f\"{method.value.capitalize()}{path}\"] = (\n                    TypeScriptNamespace(\n                        \"Parameters\",\n                        parse_params(operation.parameters, components=components),\n                    )\n                    if operation.parameters\n                    else None,\n                    parse_request_body(operation.request_body, components=components)\n                    if operation.request_body\n                    else None,\n                    *parse_responses(operation.responses, components=components),\n                )\n\n    return TypeScriptNamespace(\n        namespace,\n        tuple(\n            TypeScriptNamespace(operation, tuple(ns for ns in namespaces if ns))\n            for operation, namespaces in operations.items()\n        ),\n    )\n```\n\nThis function takes an `OpenAPI` instance and an optional `namespace` string as input. It converts the OpenAPI schema to a TypeScript namespace by iterating over the paths and operations defined in the schema.\n\nFor each operation, it parses the parameters, request body, and responses using the respective helper functions (`parse_params`, `parse_request_body`, and `parse_responses`). It creates a `TypeScriptNamespace` for each operation, containing the parsed parameters, request body, and responses as sub-namespaces.\n\nFinally, it returns a top-level `TypeScriptNamespace` with the specified `namespace` and the generated operation namespaces as its children.\n\nThe function utilizes the `deref_container` function to dereference any references within the OpenAPI schema, ensuring that the generated TypeScript types are fully resolved.", "litestar-litestar/_openapi/typescript_converter/types.py-write": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef write(self) -> str:\n    \"\"\"Write a typescript interface object, without a name.\n\n    Example:\n        {\n            key: string;\n            optional?: number;\n        }\n\n    Returns:\n        A typescript string\n    \"\"\"\n    properties = \"\\n\".join(f\"\\t{prop.write()}\" for prop in self.properties)\n    return f\"{{\\n{properties}\\n}}\"\n```", "litestar-litestar/testing/helpers.py-create_test_client": "Here is the generated code for the `create_test_client` function based on the provided function signature and natural language annotations:\n\n```python\ndef create_test_client(\n    route_handlers: ControllerRouterHandler | Sequence[ControllerRouterHandler] | None = None,\n    *,\n    after_exception: Sequence[AfterExceptionHookHandler] | None = None,\n    after_request: AfterRequestHookHandler | None = None,\n    after_response: AfterResponseHookHandler | None = None,\n    allowed_hosts: Sequence[str] | AllowedHostsConfig | None = None,\n    backend: Literal[\"asyncio\", \"trio\"] = \"asyncio\",\n    backend_options: Mapping[str, Any] | None = None,\n    base_url: str = \"http://testserver.local\",\n    before_request: BeforeRequestHookHandler | None = None,\n    before_send: Sequence[BeforeMessageSendHookHandler] | None = None,\n    cache_control: CacheControlHeader | None = None,\n    compression_config: CompressionConfig | None = None,\n    cors_config: CORSConfig | None = None,\n    csrf_config: CSRFConfig | None = None,\n    debug: bool = True,\n    dependencies: Dependencies | None = None,\n    dto: type[AbstractDTO] | None | EmptyType = Empty,\n    etag: ETag | None = None,\n    event_emitter_backend: type[BaseEventEmitterBackend] = SimpleEventEmitter,\n    exception_handlers: ExceptionHandlersMap | None = None,\n    guards: Sequence[Guard] | None = None,\n    include_in_schema: bool | EmptyType = Empty,\n    lifespan: list[Callable[[Litestar], AbstractAsyncContextManager] | AbstractAsyncContextManager] | None = None,\n    listeners: Sequence[EventListener] | None = None,\n    logging_config: BaseLoggingConfig | EmptyType | None = Empty,\n    middleware: Sequence[Middleware] | None = None,\n    multipart_form_part_limit: int = 1000,\n    on_app_init: Sequence[OnAppInitHandler] | None = None,\n    on_shutdown: Sequence[LifespanHook] | None = None,\n    on_startup: Sequence[LifespanHook] | None = None,\n    openapi_config: OpenAPIConfig | None = DEFAULT_OPENAPI_CONFIG,\n    opt: Mapping[str, Any] | None = None,\n    parameters: ParametersMap | None = None,\n    pdb_on_exception: bool | None = None,\n    path: str | None = None,\n    plugins: Sequence[PluginProtocol] | None = None,\n    raise_server_exceptions: bool = True,\n    request_class: type[Request] | None = None,\n    response_cache_config: ResponseCacheConfig | None = None,\n    response_class: type[Response] | None = None,\n    response_cookies: ResponseCookies | None = None,\n    response_headers: ResponseHeaders | None = None,\n    return_dto: type[AbstractDTO] | None | EmptyType = Empty,\n    root_path: str = \"\",\n    security: Sequence[SecurityRequirement] | None = None,\n    session_config: BaseBackendConfig | None = None,\n    signature_namespace: Mapping[str, Any] | None = None,\n    signature_types: Sequence[Any] | None = None,\n    state: State | None = None,\n    static_files_config: Sequence[StaticFilesConfig] | None = None,\n    stores: StoreRegistry | dict[str, Store] | None = None,\n    tags: Sequence[str] | None = None,\n    template_config: TemplateConfig | None = None,\n    timeout: float | None = None,\n    type_encoders: TypeEncodersMap | None = None,\n    websocket_class: type[WebSocket] | None = None,\n    experimental_features: list[ExperimentalFeatures] | None = None,\n) -> TestClient[Litestar]:\n    route_handlers = () if route_handlers", "litestar-litestar/testing/client/sync_client.py-websocket_connect": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef websocket_connect(\n    self,\n    url: str,\n    *,\n    subprotocols: Sequence[str] = (),\n    params: QueryParamTypes | None = None,\n    headers: HeaderTypes | None = None,\n    cookies: CookieTypes | None = None,\n    auth: AuthTypes | UseClientDefault = USE_CLIENT_DEFAULT,\n    follow_redirects: bool | UseClientDefault = USE_CLIENT_DEFAULT,\n    timeout: TimeoutTypes | UseClientDefault = USE_CLIENT_DEFAULT,\n    extensions: dict[str, Any] | None = None,\n) -> WebSocketTestSession:\n    \"\"\"Sends a GET request to establish a websocket connection.\n\n    Args:\n        url: Request URL.\n        subprotocols: Websocket subprotocols.\n        params: Query parameters.\n        headers: Request headers.\n        cookies: Request cookies.\n        auth: Auth headers.\n        follow_redirects: Whether to follow redirects.\n        timeout: Request timeout.\n        extensions: Dictionary of ASGI extensions.\n\n    Returns:\n        A `WebSocketTestSession <litestar.testing.WebSocketTestSession>` instance.\n    \"\"\"\n    with self.portal() as portal:\n        try:\n            return portal.call(\n                self._websocket_connect,\n                url,\n                subprotocols=subprotocols,\n                params=params,\n                headers=headers,\n                cookies=cookies,\n                auth=auth,\n                follow_redirects=follow_redirects,\n                timeout=timeout,\n                extensions=extensions,\n            )\n        except ConnectionUpgradeExceptionError as e:\n            raise e.exception\n```", "litestar-litestar/contrib/pydantic/pydantic_schema_plugin.py-for_pydantic_model": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef for_pydantic_model(cls, field_definition: FieldDefinition, schema_creator: SchemaCreator) -> Schema:\n    \"\"\"Create a schema object for a given pydantic model class.\n\n    Args:\n        field_definition: FieldDefinition instance.\n        schema_creator: An instance of the schema creator class\n\n    Returns:\n        A schema instance.\n    \"\"\"\n    model_class = field_definition.annotation\n    if is_pydantic_2_model(model_class):\n        schema = cls._create_schema_for_pydantic_2_model(model_class, schema_creator)\n    else:\n        schema = cls._create_schema_for_pydantic_1_model(model_class, schema_creator)\n\n    schema.title = model_class.__name__\n\n    if field_definition.default is not Empty:\n        schema.default = field_definition.default\n    elif field_definition.default_factory is not Empty:\n        schema.default = field_definition.default_factory()\n\n    if field_definition.description:\n        schema.description = field_definition.description\n\n    if is_generic(field_definition.origin):\n        schema.update_from_generic_alias(field_definition.origin)\n\n    return schema\n```\n\nThis function does the following:\n\n1. It takes the `field_definition` and `schema_creator` as arguments.\n\n2. It retrieves the `model_class` from the `field_definition.annotation`.\n\n3. It checks if the `model_class` is a Pydantic 2 model using the `is_pydantic_2_model` function. If it is, it calls the `_create_schema_for_pydantic_2_model` method to create the schema. Otherwise, it calls the `_create_schema_for_pydantic_1_model` method to create the schema.\n\n4. It sets the `title` of the schema to the name of the `model_class`.\n\n5. If the `field_definition.default` is not `Empty`, it sets the `default` value of the schema to the `field_definition.default`.\n\n6. If the `field_definition.default_factory` is not `Empty`, it sets the `default` value of the schema to the result of calling the `field_definition.default_factory()`.\n\n7. If the `field_definition.description` is provided, it sets the `description` of the schema to the `field_definition.description`.\n\n8. If the `field_definition.origin` is a generic type, it updates the schema using the `update_from_generic_alias` method.\n\n9. Finally, it returns the created schema instance.\n\nNote: The `_create_schema_for_pydantic_2_model` and `_create_schema_for_pydantic_1_model` methods are assumed to be defined elsewhere in the class.", "litestar-litestar/_kwargs/cleanup.py-cleanup": null, "litestar-litestar/_asgi/routing_trie/mapping.py-build_route_middleware_stack": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef build_route_middleware_stack(\n    app: Litestar,\n    route: HTTPRoute | WebSocketRoute | ASGIRoute,\n    route_handler: RouteHandlerType,\n) -> ASGIApp:\n    \"\"\"Construct a middleware stack that serves as the point of entry for each route.\n\n    Args:\n        app: The Litestar app instance.\n        route: The route that is being added.\n        route_handler: The route handler that is being wrapped.\n\n    Returns:\n        An ASGIApp that is composed of a \"stack\" of middlewares.\n    \"\"\"\n    asgi_app: ASGIApp = wrap_in_exception_handler(app=app, handler=route_handler)\n\n    for middleware in reversed(app.route_middleware):\n        asgi_app = middleware(asgi_app)\n\n    for middleware in reversed(route.middleware):\n        asgi_app = middleware(asgi_app)\n\n    return asgi_app\n```\n\nThis function does the following:\n\n1. It takes the `app`, `route`, and `route_handler` as arguments.\n\n2. It starts by wrapping the `route_handler` with the `wrap_in_exception_handler` function, which is assumed to handle exceptions and return an `ASGIApp`.\n\n3. It then iterates over the `app.route_middleware` in reverse order and applies each middleware to the `asgi_app`. This allows the middlewares to be applied in the correct order, with the outermost middleware being applied first.\n\n4. Similarly, it iterates over the `route.middleware` in reverse order and applies each middleware to the `asgi_app`. This allows route-specific middlewares to be applied after the app-level middlewares.\n\n5. Finally, it returns the resulting `asgi_app`, which represents the fully constructed middleware stack for the given route.\n\nThe function builds the middleware stack by starting with the route handler and progressively wrapping it with middlewares from the app and the route, in the correct order. The resulting `ASGIApp` serves as the entry point for handling requests for that specific route.", "litestar-litestar/utils/signature.py-from_fn": "Here is the generated code for the `from_fn` function:\n\n```python\n@classmethod\ndef from_fn(cls, fn: AnyCallable, signature_namespace: dict[str, Any]) -> Self:\n    \"\"\"Parse a function signature.\n\n    Args:\n        fn: Any callable.\n        signature_namespace: mapping of names to types for forward reference resolution\n\n    Returns:\n        ParsedSignature\n    \"\"\"\n    fn_type_hints = get_fn_type_hints(fn, namespace=signature_namespace)\n    signature = Signature.from_callable(fn)\n    \n    return cls.from_signature(signature, fn_type_hints)\n```\n\nThis function takes a callable `fn` and a `signature_namespace` mapping of names to types for forward reference resolution. It does the following:\n\n1. It retrieves the type hints of the callable using the `get_fn_type_hints` function, passing the `fn` and the `signature_namespace`.\n\n2. It obtains the signature of the callable using `Signature.from_callable(fn)`.\n\n3. It calls the `from_signature` class method, passing the obtained `signature` and `fn_type_hints`, to parse the signature and create a new instance of `ParsedSignature`.\n\n4. Finally, it returns the created `ParsedSignature` instance.\n\nThis function provides a convenient way to parse a function signature and create a `ParsedSignature` object by simply providing the callable and the signature namespace.", "litestar-litestar/utils/deprecation.py-deprecated": null, "litestar-litestar/utils/sync.py-ensure_async_callable": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef ensure_async_callable(fn: Callable[P, T]) -> Callable[P, Awaitable[T]]:\n    \"\"\"Ensure that ``fn`` is an asynchronous callable.\n    If it is an asynchronous, return the original object, else wrap it in an\n    ``AsyncCallable``\n    \"\"\"\n    if is_async_callable(fn):\n        return fn\n    else:\n        return AsyncCallable(fn)\n```", "litestar-litestar/utils/typing.py-expand_type_var_in_type_hint": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef expand_type_var_in_type_hint(type_hint: dict[str, Any], namespace: dict[str, Any] | None) -> dict[str, Any]:\n    \"\"\"Expand TypeVar for any parameters in type_hint\n\n    Args:\n        type_hint: mapping of parameter to type obtained from calling `get_type_hints` or `get_fn_type_hints`\n        namespace: mapping of TypeVar to concrete type\n\n    Returns:\n        type_hint with any TypeVar parameter expanded\n    \"\"\"\n    if namespace is None:\n        return type_hint\n\n    expanded_type_hint = {}\n    for param, hint in type_hint.items():\n        if get_origin(hint) is Union:\n            expanded_args = tuple(_substitute_typevars(arg, namespace) for arg in get_args(hint))\n            expanded_type_hint[param] = Union[expanded_args]\n        else:\n            expanded_type_hint[param] = _substitute_typevars(hint, namespace)\n\n    return expanded_type_hint\n```\n\nThis function does the following:\n\n1. It takes `type_hint` (a mapping of parameter names to types obtained from `get_type_hints` or `get_fn_type_hints`) and `namespace` (a mapping of `TypeVar` to concrete types) as arguments.\n\n2. If `namespace` is `None`, it means there are no `TypeVar` mappings, so it directly returns the original `type_hint`.\n\n3. It initializes an empty dictionary `expanded_type_hint` to store the expanded type hints.\n\n4. It iterates over each parameter and its corresponding type hint in `type_hint`.\n\n5. For each type hint, it checks if the origin type is `Union`. If it is, it expands each argument of the `Union` using the `_substitute_typevars` function with the provided `namespace`. It then creates a new `Union` type with the expanded arguments and assigns it to the corresponding parameter in `expanded_type_hint`.\n\n6. If the type hint is not a `Union`, it directly expands the type hint using the `_substitute_typevars` function with the provided `namespace` and assigns it to the corresponding parameter in `expanded_type_hint`.\n\n7. Finally, it returns the `expanded_type_hint` dictionary containing the expanded type hints for each parameter.\n\nThis function relies on the `_substitute_typevars` function to recursively substitute `TypeVar` instances with their corresponding concrete types based on the provided `namespace`.", "litestar-litestar/utils/dataclass.py-simple_asdict": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef simple_asdict(\n    obj: Any,\n    exclude_none: bool = False,\n    exclude_empty: bool = False,\n    convert_nested: bool = False,\n    exclude: AbstractSet[str] | None = None,\n) -> dict[str, Any]:\n    \"\"\"Convert a dataclass to a dictionary.\n\n    This method has important differences to the standard library version:\n    - it does not deepcopy values\n    - it does not recurse into collections\n\n    Args:\n        obj: A dataclass instance.\n        exclude_none: Whether to exclude None values.\n        exclude_empty: Whether to exclude Empty values.\n        convert_nested: Whether to recursively convert nested dataclasses.\n        exclude: An iterable of fields to exclude.\n\n    Returns:\n        A dictionary of key/value pairs.\n    \"\"\"\n    if not is_dataclass_instance(obj):\n        raise TypeError(f\"Object {obj} is not a dataclass instance.\")\n\n    result = {}\n    for name, value in extract_dataclass_items(obj, exclude_none, exclude_empty, exclude=exclude):\n        if convert_nested and is_dataclass_instance(value):\n            value = simple_asdict(value, exclude_none, exclude_empty, convert_nested, exclude)\n        result[name] = value\n\n    return result\n```", "litestar-litestar/utils/path.py-join_paths": null, "litestar-litestar/utils/helpers.py-get_name": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef get_name(value: object) -> str:\n    \"\"\"Get the ``__name__`` of an object.\n\n    Args:\n        value: An arbitrary object.\n\n    Returns:\n        A name string.\n    \"\"\"\n    origin_or_inner_type = get_origin_or_inner_type(value)\n    if origin_or_inner_type is None:\n        return getattr(value, \"__name__\", type(value).__name__)\n    return origin_or_inner_type.__name__\n```", "litestar-litestar/utils/predicates.py-is_dataclass_class": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef is_dataclass_class(annotation: Any) -> TypeGuard[type[DataclassProtocol]]:\n    \"\"\"Wrap :func:`is_dataclass <dataclasses.is_dataclass>` in a :data:`typing.TypeGuard`.\n\n    Args:\n        annotation: tested to determine if instance or type of :class:`dataclasses.dataclass`.\n\n    Returns:\n        ``True`` if instance or type of ``dataclass``.\n    \"\"\"\n    return is_dataclass(annotation)\n```", "litestar-litestar/utils/predicates.py-is_class_var": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef is_class_var(annotation: Any) -> bool:\n    \"\"\"Check if the given annotation is a ClassVar.\n\n    Args:\n        annotation: A type annotation\n\n    Returns:\n        A boolean.\n    \"\"\"\n    return is_class_and_subclass(annotation, ClassVar)\n```", "litestar-litestar/utils/module_loader.py-import_string": "Here is the generated code for the `import_string` function based on the provided function signature and natural language annotations:\n\n```python\ndef import_string(dotted_path: str) -> Any:\n    \"\"\"Dotted Path Import.\n\n    Import a dotted module path and return the attribute/class designated by the\n    last name in the path. Raise ImportError if the import failed.\n\n    Args:\n        dotted_path: The path of the module to import.\n\n    Raises:\n        ImportError: Could not import the module.\n\n    Returns:\n        object: The imported object.\n    \"\"\"\n    try:\n        module_path, class_name = dotted_path.rsplit(\".\", 1)\n    except ValueError as e:\n        raise ImportError(f\"Could not import {dotted_path}\") from e\n\n    module = import_module(module_path)\n\n    try:\n        return getattr(module, class_name)\n    except AttributeError as e:\n        raise ImportError(f\"Could not import {dotted_path}\") from e\n```\n\nThis function does the following:\n\n1. It takes a `dotted_path` string as input, which represents the path of the module to import.\n\n2. It splits the `dotted_path` into the module path and the class/attribute name using `rsplit(\".\", 1)`. If the split fails (i.e., there is no dot in the path), it raises an `ImportError` with a descriptive message.\n\n3. It imports the module using `import_module(module_path)` from the `importlib` module.\n\n4. It retrieves the specified attribute/class from the imported module using `getattr(module, class_name)`. If the attribute/class is not found, it raises an `ImportError` with a descriptive message.\n\n5. Finally, it returns the imported object.\n\nThe function raises an `ImportError` if the import fails at any point, providing a clear error message.\n\nThe docstring follows the specified format, including a description of the function, the arguments it takes, the exceptions it may raise, and the type of object it returns.", "litestar-litestar/channels/backends/redis.py-unsubscribe": "Here is the generated code for the `unsubscribe` method:\n\n```python\nasync def unsubscribe(self, channels: Iterable[str]) -> None:\n    \"\"\"Unsubscribe from ``channels``\"\"\"\n    for channel in channels:\n        self._subscribed_channels.discard(channel)\n    \n    if not self._subscribed_channels:\n        self._has_subscribed_channels.clear()\n```\n\nThe code does the following:\n\n1. It iterates over the provided `channels` and removes each channel from the `self._subscribed_channels` set using the `discard` method. This ensures that the channels are unsubscribed.\n\n2. After unsubscribing from the channels, it checks if the `self._subscribed_channels` set is empty. If it is empty, it means there are no more subscribed channels.\n\n3. If there are no more subscribed channels, it clears the `self._has_subscribed_channels` event using the `clear` method. This event is used to indicate whether there are any subscribed channels or not.\n\nBy clearing the `self._has_subscribed_channels` event when there are no more subscribed channels, it allows the `stream_events` method to pause and wait for new subscriptions before continuing to stream events.", "litestar-litestar/channels/backends/redis.py-publish": "Here is the generated code for the `publish` method based on the function signature and natural language annotations:\n\n```python\nasync def publish(self, data: bytes, channels: Iterable[str]) -> None:\n    \"\"\"Publish ``data`` to ``channels``.\n\n    .. note::\n        This operation is performed atomically, using a Lua script\n    \"\"\"\n    keys = [self._make_key(channel) for channel in channels]\n    await self._publish_script(\n        keys=keys,\n        args=[\n            data,\n            self._history_limit,\n            1 if self._cap_streams_approximate else 0,\n            self._stream_ttl,\n        ],\n    )\n```\n\nThis implementation does the following:\n\n1. It generates the Redis keys for each channel in `channels` using the `_make_key` method.\n\n2. It calls the registered Lua script `_publish_script` with the following arguments:\n   - `keys`: The list of Redis keys representing the channels.\n   - `args`: A list containing:\n     - `data`: The data to be published.\n     - `self._history_limit`: The maximum number of messages to keep in the stream.\n     - `1` if `self._cap_streams_approximate` is `True`, otherwise `0`: Indicates whether to use the approximate `~` operator for capping the stream length.\n     - `self._stream_ttl`: The TTL (time-to-live) for the stream in milliseconds.\n\n3. The Lua script atomically publishes the data to the specified channels, caps the stream length based on the `history_limit` and `cap_streams_approximate` settings, and sets the TTL for the stream.\n\n4. The method returns `None` as specified in the function signature.\n\nNote: The Lua script `_XADD_EXPIRE_SCRIPT` is assumed to be registered with the Redis client and handles the atomic publishing, capping, and TTL setting operations.", "litestar-litestar/channels/backends/redis.py-stream_events": null, "litestar-litestar/channels/backends/redis.py-get_history": "Here is the generated code for the `get_history` method:\n\n```python\nasync def get_history(self, channel: str, limit: int | None = None) -> list[bytes]:\n    \"\"\"Return the history of ``channels``, returning at most ``limit`` messages\"\"\"\n    key = self._make_key(channel)\n    if limit is None:\n        limit = self._history_limit\n    else:\n        limit = min(limit, self._history_limit)\n    \n    history = await self._redis.xrevrange(key, count=limit)\n    return [entry[1][b'data'] for entry in history]\n```\n\nThis method does the following:\n\n1. It generates the Redis key for the given channel using the `_make_key` method.\n\n2. It determines the limit for the number of messages to retrieve. If no limit is provided, it uses the `_history_limit` set during initialization. If a limit is provided, it takes the minimum of the provided limit and the `_history_limit` to ensure it doesn't exceed the configured history limit.\n\n3. It uses the Redis `xrevrange` command to retrieve the latest messages from the stream, up to the specified limit. The `xrevrange` command returns the messages in reverse order, starting from the most recent one.\n\n4. It extracts the `data` field from each message entry and returns a list of bytes representing the message data.\n\nThis method allows retrieving the history of messages for a specific channel, with an optional limit on the number of messages to retrieve.", "litestar-litestar/dto/_backend.py-create_transfer_model_type": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef create_transfer_model_type(\n    self,\n    model_name: str,\n    field_definitions: tuple[TransferDTOFieldDefinition, ...],\n) -> type[Struct]:\n    \"\"\"Create a model for data transfer.\n\n    Args:\n        model_name: name for the type that should be unique across all transfer types.\n        field_definitions: field definitions for the container type.\n\n    Returns:\n        A ``BackendT`` class.\n    \"\"\"\n    model_name = self._create_transfer_model_name(model_name)\n    return _create_struct_for_field_definitions(\n        model_name=model_name,\n        field_definitions=field_definitions,\n        rename_strategy=self.dto_factory.config.rename_strategy,\n    )\n```\n\nThis function does the following:\n\n1. It takes `model_name` and `field_definitions` as arguments.\n\n2. It generates a unique `model_name` by calling the `_create_transfer_model_name` method with the provided `model_name`. This ensures the name is unique across all transfer types.\n\n3. It returns a `Struct` class by calling the `_create_struct_for_field_definitions` function with the generated `model_name`, `field_definitions`, and the `rename_strategy` from the DTO factory configuration.\n\n4. The docstring provides a brief description of the function, along with the details of the arguments and the return value.\n\nThe function creates a transfer model type based on the provided `model_name` and `field_definitions`, which can be used for data transfer purposes in the DTO backend.", "litestar-litestar/dto/_backend.py-populate_data_from_builtins": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef populate_data_from_builtins(self, builtins: Any, asgi_connection: ASGIConnection) -> Any:\n    \"\"\"Populate model instance from builtin types.\n\n    Args:\n        builtins: Builtin type.\n        asgi_connection: The current ASGI Connection\n\n    Returns:\n        Instance or collection of ``model_type`` instances.\n    \"\"\"\n    type_decoders = asgi_connection.route_handler.resolve_type_decoders()\n\n    result = convert(\n        obj=builtins,\n        type=self.annotation,\n        dec_hook=asgi_connection.route_handler.default_deserializer,\n        type_hooks=type_decoders,\n        strict=False,\n        str_keys=True,\n    )\n\n    return self.transfer_data_from_builtins(result)\n```\n\nThis function does the following:\n\n1. It retrieves the custom type decoders from the route handler associated with the ASGI connection.\n\n2. It uses `msgspec.convert()` to convert the `builtins` data to the annotated type (`self.annotation`). It passes in the default deserializer from the route handler as the decoding hook, the custom type decoders as type hooks, and sets `strict` to `False` and `str_keys` to `True`. \n\n3. The converted result is then passed to `self.transfer_data_from_builtins()` to populate an instance or collection of instances of `model_type`.\n\n4. Finally, it returns the populated model instance(s).\n\nThis allows converting the builtin types to the appropriate annotated types using the custom type decoders and default deserializer defined in the route handler, and then transferring that data to the actual model instances.", "litestar-litestar/dto/_backend.py-populate_data_from_raw": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef populate_data_from_raw(self, raw: bytes, asgi_connection: ASGIConnection) -> Any:\n    \"\"\"Parse raw bytes into instance of `model_type`.\n\n    Args:\n        raw: bytes \n        asgi_connection: The current ASGI Connection\n\n    Returns:\n        Instance or collection of ``model_type`` instances.\n    \"\"\"\n    parsed_data = self.parse_raw(raw, asgi_connection)\n\n    if self.wrapper_attribute_name:\n        parsed_data = getattr(parsed_data, self.wrapper_attribute_name)\n\n    if self.dto_data_type:\n        return self.dto_data_type(parsed_data)\n    else:\n        return self.transfer_data_from_builtins(parsed_data)\n```\n\nThis function does the following:\n\n1. It calls `self.parse_raw(raw, asgi_connection)` to parse the raw bytes into the transfer model type using the `parse_raw` method defined earlier.\n\n2. If `self.wrapper_attribute_name` is defined, it retrieves the wrapped data from the parsed result using `getattr(parsed_data, self.wrapper_attribute_name)`. This allows extracting the relevant data if it is wrapped in a generic data structure.\n\n3. If `self.dto_data_type` is defined (i.e., the field is a subclass of `DTOData`), it instantiates the `dto_data_type` with the parsed data and returns it. This handles the case where the field is a custom `DTOData` subclass.\n\n4. Otherwise, it calls `self.transfer_data_from_builtins(parsed_data)` to populate an instance (or collection of instances) of `model_type` from the parsed builtin types and returns it.\n\nThe function parses the raw bytes into the appropriate transfer model type, extracts the relevant data if necessary, and then transfers the data into an instance (or collection of instances) of the original `model_type` before returning it.", "litestar-litestar/dto/_backend.py-encode_data": "Here is the generated code for the `encode_data` function:\n\n```python\ndef encode_data(self, data: Any) -> LitestarEncodableType:\n    \"\"\"Encode data into a ``LitestarEncodableType``.\n\n    Args:\n        data: Data to encode.\n\n    Returns:\n        Encoded data.\n    \"\"\"\n    if self.dto_data_type:\n        data = self.dto_data_type(**data.__dict__)\n\n    if self.wrapper_attribute_name:\n        data = {self.wrapper_attribute_name: data}\n\n    if self.field_definition.is_non_string_collection:\n        return self.field_definition.instantiable_origin(\n            msgspec.encode(item, type=self.transfer_model_type) for item in data\n        )\n\n    return msgspec.encode(data, type=self.transfer_model_type)\n```\n\nThis function does the following:\n\n1. If `self.dto_data_type` is defined, it creates an instance of that type using the `__dict__` of the input `data`. This is used when the DTO is operating on a subclass of `DTOData`.\n\n2. If `self.wrapper_attribute_name` is defined, it wraps the `data` in a dictionary with that attribute name as the key. This is used when the data the DTO operates on is wrapped in a generic data structure.\n\n3. If the field definition indicates it is a non-string collection type, it encodes each item in the collection using `msgspec.encode` with the `self.transfer_model_type` and returns a new collection of the same type containing the encoded items.\n\n4. Otherwise, it directly encodes the `data` using `msgspec.encode` with the `self.transfer_model_type`.\n\n5. Finally, it returns the encoded data as a `LitestarEncodableType`.\n\nThe docstring provides a brief description of what the function does, documents the `data` parameter, and specifies the return type.", "litestar-litestar/dto/_backend.py-_create_transfer_model_type_annotation": "Here is the function implementation based on the provided signature and natural language annotations:\n\n```python\ndef _create_transfer_model_type_annotation(transfer_type: TransferType) -> Any:\n    \"\"\"Create a type annotation for a transfer model.\n\n    Uses the parsed type that originates from the data model and the transfer model generated to represent a nested\n    type to reconstruct the type annotation for the transfer model.\n    \"\"\"\n    if isinstance(transfer_type, SimpleType):\n        if transfer_type.nested_field_info:\n            return transfer_type.nested_field_info.model\n        return transfer_type.field_definition.annotation\n\n    if isinstance(transfer_type, UnionType):\n        return Union[tuple(_create_transfer_model_type_annotation(t) for t in transfer_type.inner_types)]\n\n    if isinstance(transfer_type, CollectionType):\n        return transfer_type.field_definition.origin[_create_transfer_model_type_annotation(transfer_type.inner_type)]\n\n    if isinstance(transfer_type, MappingType):\n        return transfer_type.field_definition.origin[\n            _create_transfer_model_type_annotation(transfer_type.key_type),\n            _create_transfer_model_type_annotation(transfer_type.value_type),\n        ]\n\n    if isinstance(transfer_type, TupleType):\n        return transfer_type.field_definition.origin[\n            tuple(_create_transfer_model_type_annotation(t) for t in transfer_type.inner_types)\n        ]\n\n    raise RuntimeError(f\"Unexpected transfer type: {transfer_type}\")\n```\n\nThis function recursively creates the type annotation for a transfer model based on the provided `TransferType` instance. It handles the following cases:\n\n- For a `SimpleType`, if it has a nested field info, it returns the model type of the nested field info. Otherwise, it returns the original field definition's annotation.\n\n- For a `UnionType`, it creates a `Union` of the type annotations of its inner types.\n\n- For a `CollectionType`, it creates a collection type (e.g., `List`, `Set`) using the original collection type and the type annotation of its inner type.\n\n- For a `MappingType`, it creates a mapping type (e.g., `Dict`) using the original mapping type and the type annotations of its key and value types.\n\n- For a `TupleType`, it creates a tuple type using the original tuple type and the type annotations of its inner types.\n\nIf an unexpected `TransferType` is encountered, it raises a `RuntimeError`.", "litestar-litestar/response/file.py-start_response": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def start_response(self, send: Send) -> None:\n    \"\"\"Emit the start event of the response. This event includes the headers and status codes.\n\n    Args:\n        send: The ASGI send function.\n\n    Returns:\n        None\n    \"\"\"\n    file_info: FileInfo = await self.file_info if iscoroutine(self.file_info) else self.file_info\n    if file_info.stat_result:\n        self.set_stat_headers(stat_result=file_info.stat_result)\n    elif file_info.last_modified is not None:\n        self.headers.setdefault(\n            \"last-modified\",\n            formatdate(file_info.last_modified, usegmt=True),\n        )\n    if file_info.size is not None:\n        self.headers.setdefault(\"content-length\", str(file_info.size))\n    if self.etag is None and file_info.etag is not None:\n        self.headers.setdefault(\"etag\", file_info.etag)\n    elif self.etag is None and file_info.last_modified is not None and file_info.size is not None:\n        self.headers.setdefault(\n            \"etag\",\n            create_etag_for_file(\n                path=cast(str, self.file_path),\n                modified_time=file_info.last_modified,\n                file_size=file_info.size,\n            ),\n        )\n    await super().start_response(send)\n```\n\nThis function overrides the `start_response` method to include additional logic specific to file responses. It performs the following steps:\n\n1. It retrieves the `file_info` by either awaiting it if it's a coroutine or using it directly if it's already a `FileInfo` object.\n\n2. If the `file_info` contains a `stat_result`, it calls the `set_stat_headers` method to set the appropriate headers based on the stat result.\n\n3. If the `file_info` has a `last_modified` timestamp, it sets the `\"last-modified\"` header with the formatted date.\n\n4. If the `file_info` has a `size` value, it sets the `\"content-length\"` header with the file size.\n\n5. If the `etag` attribute is not set and the `file_info` has an `etag` value, it sets the `\"etag\"` header with the file's etag.\n\n6. If the `etag` attribute is not set and the `file_info` has both `last_modified` and `size` values, it generates an etag using the `create_etag_for_file` function and sets the `\"etag\"` header.\n\n7. Finally, it calls the `start_response` method of the superclass (`ASGIStreamingResponse`) to emit the start event of the response.\n\nThis function ensures that the appropriate headers related to the file, such as `\"last-modified\"`, `\"content-length\"`, and `\"etag\"`, are set before emitting the start event of the response.", "litestar-litestar/connection/request.py-json": null, "litestar-litestar/datastructures/multi_dicts.py-close": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\nasync def close(self) -> None:\n    \"\"\"Close all files in the multi-dict.\n\n    Returns:\n        None\n    \"\"\"\n    for value in self.values():\n        if isinstance(value, UploadFile):\n            await value.close()\n```\n\nThis function iterates over all the values in the `FormMultiDict` using the `values()` method. For each value, it checks if it is an instance of `UploadFile` using `isinstance()`. If it is, it calls the `close()` method on the `UploadFile` instance to close the file.\n\nThe function is defined as `async` since closing files may involve asynchronous operations.", "litestar-litestar/datastructures/url.py-from_scope": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\n@classmethod\ndef from_scope(cls, scope: Scope) -> Self:\n    \"\"\"Construct a URL from a :class:`Scope <.types.Scope>`\n\n    Args:\n        scope: A scope\n\n    Returns:\n        A URL\n    \"\"\"\n    scheme = scope[\"scheme\"]\n    host, port = scope[\"server\"]\n    path = scope[\"root_path\"] + scope[\"path\"]\n    query_string = scope[\"query_string\"].decode()\n\n    if port is None:\n        netloc = host\n    else:\n        netloc = f\"{host}:{port}\"\n\n    return cls.from_components(scheme=scheme, netloc=netloc, path=path, query=query_string)\n```\n\nThis function takes a `scope` parameter of type `Scope` and constructs a new `URL` instance based on the information provided in the scope.\n\nHere's how it works:\n\n1. It extracts the `scheme`, `host`, `port`, `root_path`, `path`, and `query_string` from the `scope` dictionary.\n\n2. It constructs the `netloc` (network location) by combining the `host` and `port`. If the `port` is `None`, it uses only the `host`.\n\n3. It combines the `root_path` and `path` from the scope to form the complete `path` for the URL.\n\n4. It decodes the `query_string` from bytes to a string.\n\n5. Finally, it uses the `from_components` class method to create a new `URL` instance with the extracted components (`scheme`, `netloc`, `path`, and `query_string`).\n\nThe function returns the newly constructed `URL` instance.", "litestar-litestar/datastructures/headers.py-to_header": "Here is the generated function based on the function signature and natural language annotations:\n\n```python\ndef to_header(self, include_header_name: bool = False) -> str:\n    \"\"\"Get the header as string.\n\n    Args:\n        include_header_name: should include the header name in the return value. If set to false\n            the return value will only include the header value. if set to true the return value\n            will be: ``<header name>: <header value>``. Defaults to false.\n    \"\"\"\n    header_value = self._get_header_value()\n    if include_header_name:\n        return f\"{self.HEADER_NAME}: {header_value}\"\n    else:\n        return header_value\n```\n\nThis function does the following:\n\n1. It calls the `_get_header_value()` abstract method to get the header value as a string. This method needs to be implemented by concrete subclasses.\n\n2. It checks the `include_header_name` argument:\n   - If `include_header_name` is `True`, it returns a string in the format `\"<header name>: <header value>\"` using the `HEADER_NAME` class variable and the obtained header value.\n   - If `include_header_name` is `False` (default), it simply returns the header value as a string.\n\nThe function signature and docstring match the provided specifications, and the implementation follows the described behavior of including or excluding the header name based on the `include_header_name` argument.", "litestar-litestar/middleware/session/server_side.py-delete": "Here is the generated code for the `delete` function:\n\n```python\nasync def delete(self, session_id: str, store: Store) -> None:\n    \"\"\"Delete the data associated with ``session_id``. Fails silently if no such session-ID exists.\n\n    Args:\n        session_id: The session-ID\n        store: Store to delete the session data from\n\n    Returns:\n        None\n    \"\"\"\n    await store.delete(session_id)\n```", "marimo-marimo/_islands/island_generator.py-add_code": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef add_code(\n    self,\n    code: str,\n    display_code: bool = True,\n    display_output: bool = True,\n    is_raw: bool = False,\n    is_reactive: bool = True,\n) -> MarimoIslandStub:\n    \"\"\"Add a code cell to the app.\n\n    *Args:*\n\n    - code (str): The code to add to the app.\n    - display_code (bool): Whether to display the code in the HTML.\n    - display_output (bool): Whether to display the output in the HTML.\n    - is_raw (bool): Whether to handled the code without formatting.\n    - is_reactive (bool): Whether this code block will run with pyodide.\n    \"\"\"\n    cell_id = self._app.cell_manager.create_cell_id()\n    cell_config = CellConfig(\n        cell_id=cell_id,\n        code=code,\n        is_raw=is_raw,\n    )\n    cell = Cell(cell_config)\n    self._app.cell_manager.add_cell(cell)\n\n    stub = MarimoIslandStub(\n        display_code=display_code,\n        display_output=display_output,\n        is_reactive=is_reactive,\n        cell_id=cell_id,\n        app_id=self._app_id,\n        code=code,\n    )\n    self._stubs.append(stub)\n    return stub\n```\n\nThis function does the following:\n\n1. It takes the provided `code` string and other optional parameters to configure how the code cell should be displayed and handled.\n\n2. It creates a new `cell_id` using the `create_cell_id()` method of the `cell_manager` in the `_app` instance.\n\n3. It creates a `CellConfig` object with the `cell_id`, `code`, and `is_raw` parameters.\n\n4. It creates a new `Cell` object using the `CellConfig`.\n\n5. It adds the `Cell` to the `cell_manager` of the `_app` instance.\n\n6. It creates a `MarimoIslandStub` object with the provided parameters, including the `cell_id`, `app_id`, and `code`.\n\n7. It appends the `MarimoIslandStub` to the `_stubs` list of the `MarimoIslandGenerator` instance.\n\n8. Finally, it returns the created `MarimoIslandStub` object.\n\nThis function allows adding code cells to the app and configuring how they should be displayed and handled in the generated HTML.", "marimo-marimo/_islands/island_generator.py-build": null, "marimo-marimo/_utils/parse_dataclass.py-build_dataclass": null, "marimo-marimo/_utils/parse_dataclass.py-parse_raw": null, "marimo-marimo/_plugins/stateless/icon.py-icon": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef icon(\n    icon_name: str,\n    size: Optional[Union[int, float, str]] = None,\n    color: Optional[str] = None,\n    inline: bool = True,\n    flip: Optional[Literal[\"horizontal\", \"vertical\", \"both\"]] = None,\n    rotate: Optional[Literal[90, 180, 270]] = None,\n    style: Optional[dict] = None,\n) -> Html:\n    \"\"\"\n    Displays an icon. These icons are referenced by name from the\n    [Iconify](https://iconify.design/) library.\n\n    They are named in the format `icon-set:icon-name`, e.g.\n    `lucide:leaf`.\n\n    Icons are lazily loaded from a CDN, so they will not be loaded when\n    not connected to the internet.\n\n    These can be used in buttons, tabs, and other UI elements.\n\n    **Examples.**\n\n    ```python\n    mo.md(f\"# {mo.icon('lucide:leaf')} Leaf\")\n\n    mo.ui.button(\n        label=f\"{mo.icon('lucide:rocket')} Submit\",\n    )\n    ```\n\n    **Args.**\n\n    - `icon_name`: the name of the icon to display\n    - `size`: the size of the icon in pixels\n    - `color`: the color of the icon\n    - `inline`: whether to display the icon inline or as a block element\n    - `flip`: whether to flip the icon horizontally, vertically, or both\n    - `rotate`: whether to rotate the icon 90, 180, or 270 degrees\n    - `style`: a dictionary of CSS styles to apply to the icon\n\n    **Returns.**\n\n    - An `Html` object.\n    \"\"\"\n    size_str = _space_to_string(size)\n    style_dict = style or {}\n    if size_str is not None:\n        style_dict[\"font-size\"] = size_str\n    if color is not None:\n        style_dict[\"color\"] = color\n    if flip is not None:\n        if flip == \"horizontal\":\n            style_dict[\"transform\"] = \"scaleX(-1)\"\n        elif flip == \"vertical\":\n            style_dict[\"transform\"] = \"scaleY(-1)\"\n        elif flip == \"both\":\n            style_dict[\"transform\"] = \"scale(-1, -1)\"\n    if rotate is not None:\n        style_dict[\"transform\"] = f\"rotate({rotate}deg)\"\n\n    style_str = create_style(style_dict)\n\n    return h(\n        \"span\",\n        {\"class\": \"iconify\", \"data-icon\": icon_name, \"style\": style_str},\n        inline=inline,\n    )\n```", "marimo-marimo/_plugins/stateless/image.py-image": null, "marimo-marimo/_plugins/stateless/flex.py-hstack": "Here is the generated code for the `hstack` function based on the provided function signature and natural language annotations:\n\n```python\n@mddoc\ndef hstack(\n    items: Sequence[object],\n    *,\n    justify: Literal[\n        \"start\", \"center\", \"end\", \"space-between\", \"space-around\"\n    ] = \"start\",\n    align: Optional[Literal[\"start\", \"end\", \"center\", \"stretch\"]] = None,\n    wrap: bool = False,\n    gap: float = 0.5,\n    widths: Optional[Literal[\"equal\"] | Sequence[float]] = None,\n) -> Html:\n    \"\"\"Stack items horizontally, in a row.\n\n    Combine with `vstack` to build a grid.\n\n    **Example.**\n\n    ```python3\n    # Build a row of items\n    mo.hstack([mo.md(\"...\"), mo.ui.text_area()])\n    ```\n\n    ```python3\n    # Build a grid.\n    mo.hstack(\n        [\n            mo.vstack([mo.md(\"...\"), mo.ui.text_area()]),\n            mo.vstack([mo.ui.checkbox(), mo.ui.text(), mo.ui.date()]),\n        ]\n    )\n    ```\n\n    **Args.**\n\n    - `items`: A list of items.\n    - `justify`: Justify items horizontally: start, center, end,\n        space-between, or space-around.\n    - `align`: Align items vertically: start, end, center, or stretch.\n    - `wrap`: Wrap items or not.\n    - `gap`: Gap between items as a float in rem. 1rem is 16px by default.\n    - `widths`: \"equal\" to give items equal width; or a list of relative widths\n      with same length as `items`, eg, [1, 2] means the second item is twice as\n      wide as the first; or `None` for a sensible default\n\n    **Returns.**\n\n    - An `Html` object.\n    \"\"\"\n    return _flex(\n        items,\n        direction=\"row\",\n        justify=justify,\n        align=align,\n        wrap=wrap,\n        gap=gap,\n        child_flexes=[1 for _ in range(len(items))]\n        if widths == \"equal\"\n        else widths,\n    )\n```\n\nThe `hstack` function is implemented using the `_flex` helper function. It takes the following arguments:\n\n- `items`: A sequence of objects representing the items to stack horizontally.\n- `justify`: Specifies how to justify the items horizontally. It can be one of \"start\", \"center\", \"end\", \"space-between\", or \"space-around\". The default value is \"start\".\n- `align`: Specifies how to align the items vertically. It can be one of \"start\", \"end\", \"center\", or \"stretch\". The default value is `None`.\n- `wrap`: A boolean indicating whether to wrap the items or not. The default value is `False`.\n- `gap`: The gap between items as a float in rem units. The default value is 0.5.\n- `widths`: Specifies the relative widths of the items. It can be \"equal\" to give items equal width, a sequence of float values representing the relative widths, or `None` for a sensible default. The default value is `None`.\n\nThe function returns an `Html` object representing the horizontally stacked items.\n\nThe `@mddoc` decorator is used to provide Markdown documentation for the function.", "marimo-marimo/_plugins/stateless/status/_progress.py-update_progress": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef update_progress(\n    self,\n    increment: int = 1,\n    title: Optional[str] = None,\n    subtitle: Optional[str] = None,\n) -> None:\n    \"\"\"Update the progress indicator.\n\n    **Example.**\n\n    ```python\n    # Increment by 1\n    progress.update()\n\n    # Increment by 10 and update title and subtitle\n    progress.update(10, title=\"Loading\", subtitle=\"Still going...\")\n    ```\n\n    **Args:**\n\n    - increment: amount to increment by. Defaults to 1.\n    - title: new title. Defaults to None.\n    - subtitle: new subtitle. Defaults to None.\n    \"\"\"\n    if self.closed:\n        raise RuntimeError(\n            \"Progress indicators cannot be updated after exiting \"\n            \"the context manager that created them.\"\n        )\n    self.current += increment\n    if title is not None:\n        self.title = title\n    if subtitle is not None:\n        self.subtitle = subtitle\n    self.clear()\n    output.append(self._get_text())\n    self.debounced_flush()\n```", "marimo-marimo/_plugins/core/web_component.py-build_ui_plugin": null, "marimo-marimo/_output/formatting.py-as_html": "Here is the generated function based on the signature and natural language annotations:\n\n```python\n@mddoc\ndef as_html(value: object) -> Html:\n    \"\"\"Convert a value to HTML that can be embedded into markdown\n\n    This function returns an `Html` object representing `value`. Use it to\n    embed values into Markdown or other HTML strings.\n\n    **Example.**\n\n    ```python3\n    import matplotlib.pyplot as plt\n    plt.plot([1, 2])\n    axis = plt.gca()\n    mo.md(\n        f\\\"\\\"\\\"\n        Here is a plot:\n\n        {mo.as_html(axis)}\n        \\\"\\\"\\\"\n    )\n    ```\n\n    **Args.**\n\n    - `value`: An object\n\n    **Returns.**\n\n    - An `Html` object\n    \"\"\"\n    formatted_output = try_format(value)\n    if formatted_output.mimetype == \"text/html\":\n        return Html(formatted_output.data)\n    else:\n        return Html(\n            json_output(\n                json.dumps(formatted_output.data),\n                expanded=False,\n                root_keys=None,\n            ).html\n        )\n```\n\nThe key steps are:\n\n1. Use the `try_format` function to attempt to format the `value` object into HTML. This will use any registered formatters for the type.\n\n2. If the mimetype of the formatted output is already \"text/html\", directly return a new `Html` object wrapping the HTML string. \n\n3. Otherwise, dump the formatted data as JSON and wrap it in HTML using the `json_output` function before returning a new `Html` object.\n\nThis allows embedding arbitrary objects into HTML/Markdown by leveraging the formatting system to convert them to HTML where possible, or falling back to a JSON representation.", "marimo-marimo/_output/md.py-md": null, "marimo-marimo/_output/formatters/formatters.py-register_formatters": null, "marimo-marimo/_data/series.py-get_category_series_info": "Here is the generated code for the `get_category_series_info` function:\n\n```python\ndef get_category_series_info(series: Any) -> CategorySeriesInfo:\n    \"\"\"\n    Get the summary of a categorical series.\n    \"\"\"\n\n    def validate_category(value: Any) -> str:\n        if not isinstance(value, str):\n            raise ValueError(\"Expected a string. Got: \" + str(type(value)))\n        return value\n\n    if DependencyManager.has_pandas():\n        import pandas as pd\n\n        if isinstance(series, pd.Series):\n            return CategorySeriesInfo(\n                categories=[validate_category(cat) for cat in series.unique()],\n                label=_get_name(series),\n            )\n\n    if DependencyManager.has_polars():\n        import polars as pl\n\n        if isinstance(series, pl.Series):\n            return CategorySeriesInfo(\n                categories=[validate_category(cat) for cat in series.unique().to_list()],\n                label=_get_name(series),\n            )\n\n    raise ValueError(\"Unsupported series type. Expected pandas or polars.\")\n```\n\nThis function follows a similar structure to the `get_number_series_info` and `get_date_series_info` functions. It checks if the input series is either a pandas or polars series, and then extracts the unique categories from the series.\n\nThe `validate_category` function is used to ensure that each category is a string. If a non-string value is encountered, it raises a `ValueError`.\n\nThe function returns a `CategorySeriesInfo` object containing the list of unique categories and the label of the series (obtained using the `_get_name` function).\n\nIf the input series is not a supported type (pandas or polars), a `ValueError` is raised.", "marimo-marimo/_data/preview_column.py-get_column_preview": null, "marimo-marimo/_server/sessions.py-start_file_watcher": "Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef start_file_watcher(self) -> Disposable:\n    \"\"\"Starts the file watcher if it is not already started\"\"\"\n    if self.watcher is None:\n        self.watcher = FileWatcher(\n            self.file_router.get_all_file_paths(),\n            self.on_file_change,\n        )\n        self.watcher.start()\n    return Disposable(self.stop_file_watcher)\n```\n\nThis function does the following:\n\n1. It checks if `self.watcher` is `None`, indicating that the file watcher is not currently running.\n\n2. If the file watcher is not running, it creates a new `FileWatcher` instance, passing the following arguments:\n   - `self.file_router.get_all_file_paths()`: Retrieves all the file paths associated with the file router.\n   - `self.on_file_change`: A callback function to be invoked when a file change is detected.\n\n3. It starts the file watcher by calling `self.watcher.start()`.\n\n4. Finally, it returns a `Disposable` object that wraps the `self.stop_file_watcher` method. This allows the caller to easily stop the file watcher when needed by calling the `dispose()` method on the returned `Disposable` object.\n\nThe function ensures that the file watcher is only started if it is not already running, preventing duplicate watchers from being created.", "marimo-marimo/_server/file_manager.py-save_app_config": null, "marimo-marimo/_server/session/session_view.py-add_stdin": null, "marimo-marimo/_server/session/session_view.py-add_operation": "Here is the generated code for the `add_operation` function:\n\n```python\ndef add_operation(self, operation: MessageOperation) -> None:\n    \"\"\"Add an operation to the session view.\"\"\"\n    if isinstance(operation, CellOp):\n        cell_id = operation.cell_id\n        previous = self.cell_operations.get(cell_id)\n        merged_op = merge_cell_operation(previous, operation)\n        self.cell_operations[cell_id] = merged_op\n        self.save_execution_time(operation, event=\"start\")\n        if merged_op.status in [\"finished\", \"error\", \"cancelled\"]:\n            self.save_execution_time(operation, event=\"end\")\n    elif isinstance(operation, Datasets):\n        self.datasets = operation\n    elif isinstance(operation, Variables):\n        self.variable_operations = operation\n    elif isinstance(operation, VariableValues):\n        for variable in operation.variables:\n            self.variable_values[variable.name] = variable\n    elif isinstance(operation, Interrupted):\n        for cell_id in operation.cell_ids:\n            cell_op = self.cell_operations.get(cell_id)\n            if cell_op is not None:\n                cell_op.status = \"cancelled\"\n                cell_op.console = as_list(cell_op.console) + [\n                    CellOutput(\n                        channel=CellChannel.STDERR,\n                        text=\"Execution interrupted\",\n                    )\n                ]\n```\n\nThe `add_operation` function takes a `MessageOperation` object and updates the session view accordingly. Here's what it does for each type of operation:\n\n- For `CellOp` operations, it merges the new operation with the previous one (if any) for the same cell using the `merge_cell_operation` function. It updates the `cell_operations` dictionary with the merged operation. It also saves the execution start and end times using the `save_execution_time` method.\n\n- For `Datasets` operations, it updates the `datasets` attribute with the new operation.\n\n- For `Variables` operations, it updates the `variable_operations` attribute with the new operation.\n\n- For `VariableValues` operations, it updates the `variable_values` dictionary with the new variable values.\n\n- For `Interrupted` operations, it marks the status of the specified cells as \"cancelled\" and appends an interruption message to their console output.\n\nThe function uses the existing `merge_cell_operation`, `as_list`, and `save_execution_time` methods to perform some of the operations.", "marimo-marimo/_server/session/session_view.py-get_cell_console_outputs": "Here is the generated function based on the provided signature and natural language annotation:\n\n```python\ndef get_cell_console_outputs(\n    self, ids: list[CellId_t]\n) -> dict[CellId_t, list[CellOutput]]:\n    \"\"\"Get the console outputs for the given cell ids.\"\"\"\n    console_outputs: dict[CellId_t, list[CellOutput]] = {}\n    for cell_id in ids:\n        cell_op = self.cell_operations.get(cell_id)\n        if cell_op is not None and cell_op.console is not None:\n            console_outputs[cell_id] = as_list(cell_op.console)\n    return console_outputs\n```\n\nThe function `get_cell_console_outputs` takes a list of cell IDs (`ids`) and returns a dictionary mapping each cell ID to a list of its console outputs.\n\nIt iterates over the provided cell IDs and retrieves the corresponding `CellOp` object from the `cell_operations` dictionary. If a `CellOp` exists for the cell ID and it has a non-empty `console` attribute, the console outputs are added to the `console_outputs` dictionary using the `as_list` function to ensure the outputs are stored as a list.\n\nFinally, the function returns the `console_outputs` dictionary containing the console outputs for each requested cell ID.", "marimo-marimo/_runtime/dataflow.py-register_cell": "Here is the generated code for the `register_cell` function based on the provided function signature and natural language annotations:\n\n```python\ndef register_cell(self, cell_id: CellId_t, cell: CellImpl) -> None:\n    \"\"\"Add a cell to the graph.\n\n    Mutates the graph, acquiring `self.lock`.\n\n    Requires that `cell_id` is not already in the graph.\n    \"\"\"\n    with self.lock:\n        if cell_id in self.cells:\n            raise ValueError(f\"Cell {cell_id} already exists in the graph\")\n\n        self.cells[cell_id] = cell\n        self.children[cell_id] = set()\n        self.parents[cell_id] = set()\n        self.siblings[cell_id] = set()\n\n        for name in cell.defs:\n            if name not in self.definitions:\n                self.definitions[name] = set()\n            self.definitions[name].add(cell_id)\n\n        for name in cell.refs:\n            if name in self.definitions:\n                for parent_id in self.definitions[name]:\n                    self.parents[cell_id].add(parent_id)\n                    self.children[parent_id].add(cell_id)\n\n        multiply_defined = self.get_multiply_defined()\n        for name in multiply_defined:\n            for definer in self.definitions[name]:\n                self.siblings[definer].update(self.definitions[name])\n                self.siblings[definer].remove(definer)\n\n        cycles = get_cycles(self, self.cells.keys())\n        self.cycles.update(cycles)\n```\n\nThis implementation does the following:\n\n1. Acquires the `self.lock` to ensure thread-safe mutation of the graph.\n\n2. Checks if `cell_id` already exists in the graph. If it does, raises a `ValueError` to indicate that the cell already exists.\n\n3. Adds the `cell` to the `self.cells` dictionary using `cell_id` as the key.\n\n4. Initializes empty sets for `self.children`, `self.parents`, and `self.siblings` for the given `cell_id`.\n\n5. For each name defined in `cell.defs`, adds the `cell_id` to the set of definers in `self.definitions`.\n\n6. For each name referenced in `cell.refs`, if the name is defined in the graph, adds the `cell_id` as a child of the defining cells and adds the defining cells as parents of the `cell_id`.\n\n7. Checks for multiply defined names using `self.get_multiply_defined()` and updates the `self.siblings` dictionary accordingly.\n\n8. Checks for cycles in the graph using `get_cycles()` and updates the `self.cycles` set with any new cycles found.\n\nThis function adds the given cell to the graph, updates the necessary data structures, and checks for multiply defined names and cycles.", "marimo-marimo/_runtime/validate_graph.py-check_for_errors": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef check_for_errors(\n    graph: DirectedGraph,\n) -> dict[CellId_t, list[Error]]:\n    \"\"\"\n    Check graph for violations of marimo semantics.\n\n    Return a dict of errors in the graph, with an entry for each cell\n    that is involved in an error.\n    \"\"\"\n    errors = defaultdict(list)\n\n    # Check for multiple definitions\n    multiple_definition_errors = check_for_multiple_definitions(graph)\n    for cid, cell_errors in multiple_definition_errors.items():\n        errors[cid].extend(cell_errors)\n\n    # Check for deleting nonlocal references\n    delete_nonlocal_errors = check_for_delete_nonlocal(graph)\n    for cid, cell_errors in delete_nonlocal_errors.items():\n        errors[cid].extend(cell_errors)\n\n    # Check for cycles\n    cycle_errors = check_for_cycles(graph)\n    for cid, cell_errors in cycle_errors.items():\n        errors[cid].extend(cell_errors)\n\n    return dict(errors)\n```\n\nThe `check_for_errors` function performs the following steps:\n\n1. It initializes an empty `defaultdict` called `errors` to store the errors for each cell.\n\n2. It calls the `check_for_multiple_definitions` function to check for multiple definitions of the same global name. The resulting errors are added to the `errors` dictionary for each corresponding cell.\n\n3. It calls the `check_for_delete_nonlocal` function to check for cells that delete their references. The resulting errors are added to the `errors` dictionary for each corresponding cell.\n\n4. It calls the `check_for_cycles` function to check for cycles in the graph. The resulting errors are added to the `errors` dictionary for each corresponding cell.\n\n5. Finally, it converts the `errors` defaultdict to a regular dictionary using `dict(errors)` and returns it.\n\nThe function returns a dictionary where the keys are the cell IDs (`CellId_t`) and the values are lists of `Error` objects representing the errors associated with each cell.", "marimo-marimo/_runtime/runtime.py-_maybe_register_cell": null, "marimo-marimo/_runtime/runtime.py-run": "Here is the generated code for the `run` function:\n\n```python\nasync def run(\n    self,\n    execution_requests: Sequence[ExecutionRequest],\n    deletion_requests: Sequence[DeleteCellRequest],\n) -> None:\n    \"\"\"Run cells and their descendants.\n\n    The cells may be cells already existing in the graph or new cells.\n    Adds the cells in `execution_requests` to the graph before running\n    them.\n\n    Cells may use top-level await, which is why this function is async.\n    \"\"\"\n    cells_to_run = self.mutate_graph(execution_requests, deletion_requests)\n\n    for hook in self._preparation_hooks:\n        await hook(self)\n\n    try:\n        for cell_id in cells_to_run:\n            await self._run_cell(cell_id)\n    except Exception:\n        LOGGER.exception(\"Unexpected exception while running cells\")\n    finally:\n        for hook in self._on_finish_hooks:\n            await hook(self)\n\n    CompletedRun().broadcast()\n```\n\nThis function does the following:\n\n1. Calls `mutate_graph` to add/remove cells to/from the graph based on the `execution_requests` and `deletion_requests`. This returns the set of `cells_to_run`.\n\n2. Runs the preparation hooks before executing the cells.\n\n3. Iterates over `cells_to_run` and calls `_run_cell` for each cell ID to execute the cell and its descendants. This is wrapped in a try/except block to catch any unexpected exceptions.\n\n4. After running the cells (or if an exception occurred), it runs the on finish hooks.\n\n5. Finally, it broadcasts a `CompletedRun` message to indicate that the execution has completed.\n\nThe function is marked as `async` to allow cells to use top-level `await`.", "marimo-marimo/_runtime/packages/utils.py-is_python_isolated": "Here is the generated function based on the provided signature and annotation:\n\n```python\ndef is_python_isolated() -> bool:\n    \"\"\"Returns True if not using system Python\"\"\"\n    return in_virtual_environment() or in_conda_env() or is_pyodide()\n```", "marimo-marimo/_runtime/packages/module_registry.py-missing_modules": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef missing_modules(self) -> set[str]:\n    \"\"\"Modules that will fail to import.\"\"\"\n    return set(\n        module\n        for module in self.modules()\n        if module not in self.excluded_modules\n        and not _is_module_installed(module)\n    )\n```\n\nThis function does the following:\n\n1. It uses the `modules()` method to retrieve the set of modules imported by cells in the graph.\n\n2. It then uses a set comprehension to filter the modules based on two conditions:\n   - The module should not be present in the `excluded_modules` set.\n   - The module should not be installed, which is checked using the `_is_module_installed()` function.\n\n3. The resulting set of modules represents the modules that will fail to import because they are not installed and not excluded.\n\n4. The function returns this set of missing modules.\n\nThe `missing_modules()` function provides a way to identify the modules that are imported by cells in the graph but are not installed and not explicitly excluded, indicating that they will fail to import.", "TaskWeaver-taskweaver/misc/example.py-load_examples": "Here is the generated code for the `load_examples` function based on the provided function signature and natural language annotations:\n\n```python\ndef load_examples(folder: str, role_set: Optional[Set[str]] = None) -> List[Conversation]:\n    \"\"\"\n    Load all the examples from a folder.\n\n    Args:\n        folder: the folder path.\n        role_set: the roles should be included in the examples.\n    \"\"\"\n    examples = []\n    for file_path in glob.glob(path.join(folder, \"*.json\")):\n        example = Conversation.load(file_path)\n        if role_set is None or example.roles.issubset(role_set):\n            examples.append(example)\n    return examples\n```", "TaskWeaver-taskweaver/code_interpreter/plugin_selection.py-add_selected_plugins": null, "TaskWeaver-taskweaver/code_interpreter/plugin_selection.py-filter_unused_plugins": "Here is the generated function based on the function signature and natural language annotations:\n\n```python\ndef filter_unused_plugins(self, code: str):\n    \"\"\"\n    Filter out plugins that are not used in the code generated by LLM\n    \"\"\"\n    used_plugins = []\n    for plugin in self.selected_plugin_pool:\n        if plugin.name in code:\n            used_plugins.append(plugin)\n    \n    self._previous_used_plugin_cache = used_plugins\n    self.selected_plugin_pool = used_plugins\n```", "TaskWeaver-taskweaver/module/prompt_util.py-remove_all_delimiters": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\n@staticmethod\ndef remove_all_delimiters(text: str) -> str:\n    \"\"\"Remove all the delimiters from the text.\"\"\"\n    for delimiter in PromptUtil.get_all_delimiters():\n        text = PromptUtil.remove_delimiter(text, delimiter)\n    return text\n```", "reflex-reflex/app.py-_enable_state": "Here is the generated function based on the provided function signature and natural language annotation:\n\n```python\ndef _enable_state(self) -> None:\n    \"\"\"Enable state for the app.\"\"\"\n    if not self.state:\n        # If no state class is defined, use the default State class\n        self.state = State\n    \n    self._setup_state()\n```", "reflex-reflex/app.py-_add_optional_endpoints": "Here is the generated function based on the provided function signature and natural language annotation:\n\n```python\ndef _add_optional_endpoints(self):\n    \"\"\"Add optional api endpoints (_upload).\"\"\"\n    config = get_config()\n    if config.upload_dir:\n        # Add the upload endpoint if an upload directory is configured.\n        self.api.post(str(constants.Endpoint.UPLOAD))(upload)\n```", "reflex-reflex/app.py-add_page": "Here is the generated function based on the provided signature and annotations:\n\n```python\ndef add_page(\n    self,\n    component: Component | ComponentCallable,\n    route: Optional[str] = None,\n    title: str = constants.DefaultPage.TITLE,\n    description: str = constants.DefaultPage.DESCRIPTION,\n    image: str = constants.DefaultPage.IMAGE,\n    on_load: EventHandler | EventSpec | list[EventHandler | EventSpec] | None = None,\n    meta: list[dict[str, str]] = constants.DefaultPage.META_LIST,\n):\n    \"\"\"Add a page to the app.\n\n    If the component is a callable, by default the route is the name of the\n    function. Otherwise, a route must be provided.\n\n    Args:\n        component: The component to display at the page.\n        route: The route to display the component at.\n        title: The title of the page.\n        description: The description of the page.\n        image: The image to display on the page.\n        on_load: The event handler(s) that will be called each time the page load.\n        meta: The metadata of the page.\n\n    Raises:\n        ValueError: When the specified route name already exists.\n    \"\"\"\n    if route is None:\n        if callable(component):\n            route = component.__name__\n        else:\n            raise ValueError(\"Route must be provided for non-callable components\")\n\n    route = route.lstrip(\"/\")\n    if route == \"\":\n        route = constants.PageNames.INDEX_ROUTE\n\n    if route in self.pages:\n        raise ValueError(f\"Page route '{route}' already exists\")\n\n    self._check_routes_conflict(route)\n    verify_route_validity(route)\n\n    if on_load:\n        if not isinstance(on_load, list):\n            on_load = [on_load]\n        self.load_events[route] = on_load\n\n    component = self._generate_component(component)\n    component.set_page_meta(\n        title=title,\n        description=description,\n        image=image,\n        meta=meta,\n    )\n    self.pages[route] = component\n```\n\nThis function adds a page to the Reflex app. It takes the component to display, the route to display it at, and optional metadata like title, description, image, on_load events, and custom meta tags.\n\nIf the component is a callable, the route defaults to the name of the function. Otherwise, a route must be explicitly provided.\n\nIt checks for route conflicts and verifies the validity of the route. If on_load events are provided, they are added to the load_events dictionary for the corresponding route.\n\nFinally, it generates the component, sets the page metadata, and adds the component to the pages dictionary with the specified route as the key.", "reflex-reflex/app.py-_setup_overlay_component": null, "reflex-reflex/app.py-_compile": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef _compile(self, export: bool = False):\n    \"\"\"Compile the app and output it to the pages folder.\n\n    Args:\n        export: Whether to compile the app for export.\n\n    Raises:\n        ReflexRuntimeError: When any page uses state, but no rx.State subclass is defined.\n    \"\"\"\n    if not self._should_compile():\n        return\n\n    # Validate the dependencies of the vars in the app.\n    self._validate_var_dependencies()\n\n    # Get all the pages and their event handlers.\n    pages = self.pages\n    load_events = self.load_events\n\n    # Get all the components used in the app.\n    components = {\n        route: component\n        for route, component in pages.items()\n        if isinstance(component, Component)\n    }\n\n    # Get all the imports used in the app.\n    imports = compiler_utils.get_imports(components)\n\n    # Get the frontend packages to install.\n    self._get_frontend_packages(imports)\n\n    # Get the app wrappers.\n    app_wrappers = AppWrap._get_all_app_wrap_components()\n\n    # Get the app root component.\n    app_root = self._app_root(app_wrappers)\n\n    # Get the theme and style.\n    theme = self.theme\n    style = self.style\n\n    # Evaluate the style namespaces.\n    style = evaluate_style_namespaces(style)\n\n    # Add the overlay component to the app root.\n    app_root = self._add_overlay_to_component(app_root)\n\n    # Add the head components to the app root.\n    app_root.children = [*self.head_components, *app_root.children]\n\n    # Compile the app.\n    compiler.compile_app(\n        app=self,\n        app_root=app_root,\n        pages=pages,\n        load_events=load_events,\n        style=style,\n        theme=theme,\n        imports=imports,\n        export=export,\n    )\n\n    if self.state and not code_uses_state_contexts(components):\n        console.warn(\n            \"No rx.use_state() found in your code. \"\n            \"If you are using rx.State, make sure to wrap your state \"\n            \"access in rx.use_state() to ensure reactivity.\"\n        )\n```\n\nThis function compiles the Reflex app and outputs it to the pages folder. It performs the following steps:\n\n1. Checks if the app should be compiled based on certain conditions.\n2. Validates the dependencies of the vars in the app.\n3. Retrieves all the pages, event handlers, components, and imports used in the app.\n4. Installs the required frontend packages based on the imports.\n5. Retrieves the app wrappers and creates the app root component.\n6. Evaluates the style namespaces and adds the overlay component and head components to the app root.\n7. Compiles the app using the `compiler.compile_app` function, passing the necessary data.\n8. Checks if the app uses state and logs a warning if no `rx.use_state()` is found in the code.\n\nThe function raises a `ReflexRuntimeError` if any page uses state but no `rx.State` subclass is defined.", "reflex-reflex/app.py-modify_state": "Here is the generated function based on the provided signature and annotations:\n\n```python\nasync def modify_state(self, token: str) -> AsyncIterator[BaseState]:\n    \"\"\"Modify the state out of band.\n\n    Args:\n        token: The token to modify the state for.\n\n    Yields:\n        The state to modify.\n\n    Raises:\n        RuntimeError: If the app has not been initialized yet.\n    \"\"\"\n    if self._state_manager is None:\n        raise RuntimeError(\"App has not been initialized yet.\")\n\n    async with self._state_manager.modify_state(token) as state:\n        yield state\n```\n\nThe key steps are:\n\n1. Check if `self._state_manager` is `None`, and raise a `RuntimeError` if the app has not been initialized yet.\n\n2. Use `async with` to call `self._state_manager.modify_state(token)` and get the state to modify. This ensures the state is locked for exclusive access.\n\n3. `yield` the obtained `state` object, allowing the caller to modify it.\n\n4. The `async with` block will automatically release the lock on the state when the caller is done modifying it.\n\nThis function allows modifying the state out of band by obtaining exclusive access to the state associated with the provided `token`.", "reflex-reflex/vars.py-create": "Here is the generated function based on the provided signature and annotations:\n\n```python\n@classmethod\ndef create(\n    cls,\n    value: Any,\n    _var_is_local: bool = False,\n    _var_is_string: bool = True,\n    _var_data: Optional[VarData] = None,\n) -> Var:\n    \"\"\"Create a var from a value.\n\n    Args:\n        value: The value to create the var from.\n        _var_is_local: Whether the var is local.\n        _var_is_string: Whether the var is a string literal.\n        _var_data: Additional hooks and imports associated with the Var.\n\n    Returns:\n        The var.\n\n    Raises:\n        VarTypeError: If the value is JSON-unserializable.\n    \"\"\"\n    try:\n        if isinstance(value, Var):\n            return value._replace(\n                _var_is_local=_var_is_local,\n                _var_is_string=_var_is_string,\n                _var_data=VarData.merge(_var_data, value._var_data),\n            )\n        else:\n            value = serializers.serialize(value)\n            if isinstance(value, str):\n                value = json.dumps(value)\n            return BaseVar(\n                _var_name=value,\n                _var_type=type(value),\n                _var_is_local=_var_is_local,\n                _var_is_string=_var_is_string,\n                _var_full_name_needs_state_prefix=False,\n                _var_data=_var_data,\n            )\n    except (TypeError, ValueError) as e:\n        raise VarTypeError(f\"Value {value} is not JSON serializable: {e}\") from e\n```\n\nThis `create` class method takes a `value` parameter and creates a new `Var` instance from it. It handles the following cases:\n\n1. If `value` is already a `Var`, it returns a new `Var` instance with the provided `_var_is_local`, `_var_is_string`, and merged `_var_data`.\n\n2. Otherwise, it tries to serialize the `value` using `serializers.serialize()`. \n   - If the serialized value is a string, it wraps it in `json.dumps()` to ensure it's a valid JSON string.\n   - It then creates a new `BaseVar` instance with the serialized value, inferred type, provided `_var_is_local`, `_var_is_string`, `_var_full_name_needs_state_prefix` set to `False`, and the provided `_var_data`.\n\n3. If the `value` is not JSON serializable, it raises a `VarTypeError` with an appropriate error message.\n\nThe method returns the created `Var` instance.", "reflex-reflex/vars.py-create_safe": "Here is the function based on the provided signature and annotations:\n\n```python\n@classmethod\ndef create_safe(\n    cls,\n    value: Any,\n    _var_is_local: bool = False,\n    _var_is_string: bool = True,\n    _var_data: Optional[VarData] = None,\n) -> Var:\n    \"\"\"Create a var from a value, asserting that it is not None.\n\n    Args:\n        value: The value to create the var from.\n        _var_is_local: Whether the var is local.\n        _var_is_string: Whether the var is a string literal.\n        _var_data: Additional hooks and imports associated with the Var.\n\n    Returns:\n        The var.\n    \"\"\"\n    if value is None:\n        raise ValueError(\"Cannot create Var from None value\")\n\n    return cls.create(\n        value,\n        _var_is_local=_var_is_local,\n        _var_is_string=_var_is_string,\n        _var_data=_var_data,\n    )\n```\n\nThis `create_safe` class method first checks if the provided `value` is None. If so, it raises a `ValueError` indicating that a Var cannot be created from a None value.\n\nIf `value` is not None, it calls the `create` class method with the provided arguments to create and return the Var instance.\n\nThe key difference from a regular `create` method is the explicit check for None, raising an error if None is passed. This enforces that the created Var is always based on a non-None value.", "reflex-reflex/vars.py-foreach": "Here is the generated function based on the signature and annotations:\n\n```python\ndef foreach(self, fn: Callable) -> Var:\n    \"\"\"Return a list of components after doing a foreach on this var.\n\n    Args:\n        fn: The function to call on each component.\n\n    Returns:\n        A var representing foreach operation.\n\n    Raises:\n        VarTypeError: If the var is not a list.\n    \"\"\"\n    if not types._issubclass(self._var_type, List):\n        raise VarTypeError(\n            f\"Var {self._var_name} of type {self._var_type} does not support foreach. \"\n            \"Var must be a list.\"\n        )\n    \n    # Extract var data from the function\n    var_data = VarData.merge(self._var_data, *_extract_var_data([fn]))\n    \n    # Wrap the function to make it callable in JS\n    wrapped_fn = Var.create(fn, _var_is_local=True)\n    \n    return self._replace(\n        _var_name=f\"{self._var_name}.map({wrapped_fn})\",\n        _var_type=self._var_type,\n        _var_data=var_data,\n        _var_is_string=False,\n    )\n```\n\nThis implements the `foreach` method on the `Var` class with the following behavior:\n\n1. It first checks if the `Var` represents a list type, raising a `VarTypeError` if not, since `foreach` only makes sense for lists.\n\n2. It extracts any `VarData` from the `fn` argument by recursively searching for `Var` instances inside it. This `VarData` is merged with the existing `VarData` of `self`. \n\n3. It wraps the `fn` in a `Var` marked as `_var_is_local=True`. This allows the function to be called in the generated JavaScript code.\n\n4. Finally, it returns a new `Var` instance representing the `map` operation applied to `self._var_name` using the wrapped `fn`. The resulting `Var`:\n    - Has the same `_var_type` as the original list\n    - Merges the extracted `VarData` \n    - Is marked as a non-string type\n\nThe JavaScript equivalent would be something like `this._var_name.map(wrappedFn)`.\n\nLet me know if you have any other questions!", "reflex-reflex/vars.py-get_default_value": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef get_default_value(self) -> Any:\n    \"\"\"Get the default value of the var.\n\n    Returns:\n        The default value of the var.\n\n    Raises:\n        ImportError: If the var is a dataframe and pandas is not installed.\n    \"\"\"\n    if types.is_dataframe(self._var_type):\n        try:\n            import pandas as pd\n            return pd.DataFrame()\n        except ImportError:\n            raise ImportError(\"pandas must be installed to use DataFrame vars.\")\n    elif types.is_generic_alias(self._var_type):\n        args = types.get_args(self._var_type)\n        if types._issubclass(self._var_type, List):\n            return []\n        elif types._issubclass(self._var_type, Tuple):\n            return tuple(self.get_default_value() for _ in args)\n        elif types._issubclass(self._var_type, Dict):\n            return {}\n    return types.get_default_value(self._var_type)\n```\n\nThis function does the following:\n\n1. If the var type is a DataFrame, it tries to import pandas and returns an empty DataFrame as the default value. If pandas is not installed, it raises an ImportError.\n\n2. If the var type is a generic alias (e.g., List[int], Tuple[str, int], Dict[str, int]), it gets the arguments of the generic alias using `types.get_args()`.\n   - If the var type is a subclass of List, it returns an empty list.\n   - If the var type is a subclass of Tuple, it recursively calls `get_default_value()` for each argument and returns a tuple of the default values.\n   - If the var type is a subclass of Dict, it returns an empty dictionary.\n\n3. For any other var type, it calls `types.get_default_value()` to get the default value for that type.\n\nThe function returns the appropriate default value based on the var type, handling special cases for DataFrames, generic aliases like List, Tuple, and Dict, and using `types.get_default_value()` for other types.", "reflex-reflex/state.py-get_skip_vars": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef get_skip_vars(cls) -> set[str]:\n    \"\"\"Get the vars to skip when serializing.\n\n    Returns:\n        The vars to skip when serializing.\n    \"\"\"\n    return {\"router\", \"router_data\", \"parent_state\", \"substates\", \"dirty_vars\", \"dirty_substates\", \"_was_touched\"}\n```", "reflex-reflex/state.py-add_var": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef add_var(cls, name: str, type_: Any, default_value: Any = None):\n    \"\"\"Add dynamically a variable to the State.\n\n    The variable added this way can be used in the same way as a variable\n    defined statically in the model.\n\n    Args:\n        name: The name of the variable\n        type_: The type of the variable\n        default_value: The default value of the variable\n\n    Raises:\n        NameError: if a variable of this name already exists\n    \"\"\"\n    if name in cls.vars:\n        raise NameError(f\"A variable named '{name}' already exists in {cls.__name__}\")\n    \n    base_var = BaseVar(_var_name=name, _var_type=type_)._var_set_state(cls)\n    cls.base_vars[name] = base_var\n    cls.vars[name] = base_var\n    \n    cls._init_var(base_var, default_value)\n    \n    # Update var dependency tracking\n    cls._init_var_dependency_dicts()\n```\n\nThis function does the following:\n\n1. It checks if a variable with the given `name` already exists in the `vars` dictionary of the state class. If so, it raises a `NameError`.\n\n2. It creates a new `BaseVar` instance with the provided `name` and `type_`, sets the state class using `_var_set_state()`, and adds it to the `base_vars` and `vars` dictionaries of the state class.\n\n3. It initializes the new variable using `_init_var()`, passing the `BaseVar` instance and the `default_value`.\n\n4. Finally, it updates the variable dependency tracking by calling `_init_var_dependency_dicts()` to ensure the new variable is properly tracked.\n\nThis function allows dynamically adding a new base variable to the state class at runtime, which can be used in the same way as variables defined statically in the model.", "reflex-reflex/state.py-reset": null, "reflex-reflex/state.py-get_state": "Here is the generated function based on the provided signature and annotations:\n\n```python\nasync def get_state(self, state_cls: Type[BaseState]) -> BaseState:\n    \"\"\"Get an instance of the state associated with this token.\n\n    Allows for arbitrary access to sibling states from within an event handler.\n\n    Args:\n        state_cls: The class of the state.\n\n    Returns:\n        The instance of state_cls associated with this state's client_token.\n    \"\"\"\n    from reflex.state_manager import StateManager\n\n    token = self.router.session.client_token\n    state_manager = StateManager.get_instance()\n    return await state_manager.get_state(token=token, state_cls=state_cls)\n```\n\nThis function retrieves the instance of the specified `state_cls` associated with the current state's `client_token`. It does the following:\n\n1. It imports the `StateManager` class from the `reflex.state_manager` module.\n\n2. It retrieves the `client_token` from the `router.session` attribute of the current state instance (`self`).\n\n3. It gets the singleton instance of the `StateManager` using the `get_instance()` method.\n\n4. It calls the `get_state()` method of the `StateManager` instance, passing the `token` and `state_cls` as arguments, and awaits the result.\n\n5. Finally, it returns the retrieved state instance.\n\nThis allows the state to access sibling states associated with the same client token from within an event handler.", "reflex-reflex/state.py-_process": "Here is the generated function based on the provided signature and annotations:\n\n```python\nasync def _process(self, event: Event) -> AsyncIterator[StateUpdate]:\n    \"\"\"Obtain event info and process event.\n\n    Args:\n        event: The event to process.\n\n    Yields:\n        The state update after processing the event.\n    \"\"\"\n    event_handler = self.event_handlers[event.name]\n    event_spec = event.event_spec\n    event_args = event_spec.args\n    event_kwargs = event_spec.kwargs\n    \n    if event_handler.is_background_task:\n        self._background_tasks.append(event_handler(*event_args, **event_kwargs))\n        return\n    \n    if event_handler.is_generator:\n        async for update in event_handler(*event_args, **event_kwargs):\n            yield update\n    else:\n        update = await event_handler(*event_args, **event_kwargs)\n        if update is not None:\n            yield update\n```\n\nThis function does the following:\n\n1. Retrieves the appropriate `EventHandler` instance for the given event based on the event name.\n\n2. Extracts the arguments and keyword arguments from the `EventSpec` of the event. \n\n3. Checks if the event handler is marked as a background task. If so, it appends the coroutine to the `self._background_tasks` list and returns without yielding any updates.\n\n4. If the event handler is a generator function, it iterates over the updates yielded by the generator using `async for` and yields each update.\n\n5. If the event handler is a regular coroutine function, it awaits the result and yields the update if it is not `None`.\n\nThe function uses the `AsyncIterator` return type to allow yielding multiple state updates if needed, based on the event handler implementation.", "reflex-reflex/state.py-_dirty_computed_vars": null, "reflex-reflex/state.py-_potentially_dirty_substates": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\n@classmethod\ndef _potentially_dirty_substates(cls) -> set[Type[BaseState]]:\n    \"\"\"Determine substates which could be affected by dirty vars in this state.\n\n    Returns:\n        Set of State classes that may need to be fetched to recalc computed vars.\n    \"\"\"\n    dirty_substates = set()\n    \n    for dirty_var in cls.dirty_vars:\n        for substate_name in cls._substate_var_dependencies[dirty_var]:\n            for substate_cls in cls.class_subclasses:\n                if substate_cls.get_name() == substate_name:\n                    dirty_substates.add(substate_cls)\n                    break\n    \n    for substate_name in cls._always_dirty_substates:\n        for substate_cls in cls.class_subclasses:\n            if substate_cls.get_name() == substate_name:\n                dirty_substates.add(substate_cls)\n                break\n    \n    return dirty_substates\n```\n\nThis function does the following:\n\n1. It initializes an empty set called `dirty_substates` to store the potentially dirty substate classes.\n\n2. It iterates over the `dirty_vars` of the current state class.\n   - For each dirty variable, it retrieves the set of substate names that depend on that variable from the `_substate_var_dependencies` dictionary.\n   - It then iterates over the `class_subclasses` of the current state class.\n   - If a substate class's name matches the substate name from the dependencies, it adds that substate class to the `dirty_substates` set and breaks the inner loop.\n\n3. It iterates over the `_always_dirty_substates` of the current state class.\n   - For each always dirty substate name, it iterates over the `class_subclasses` of the current state class.\n   - If a substate class's name matches the always dirty substate name, it adds that substate class to the `dirty_substates` set and breaks the inner loop.\n\n4. Finally, it returns the `dirty_substates` set containing the potentially dirty substate classes.\n\nThis function determines which substates could be affected by the dirty variables in the current state class. It uses the `_substate_var_dependencies` dictionary to find the substates that depend on the dirty variables, and it also includes the substates that are always considered dirty based on the `_always_dirty_substates` set.", "reflex-reflex/state.py-get_delta": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef get_delta(self) -> Delta:\n    \"\"\"Get the delta for the state.\n\n    Returns:\n        The delta for the state.\n    \"\"\"\n    delta: Delta = {}\n    for var_name in self.dirty_vars:\n        var = self.vars[var_name]\n        if isinstance(var, BaseVar):\n            delta[var_name] = getattr(self, var_name)\n    for substate_name in self.dirty_substates:\n        substate = self.substates[substate_name]\n        delta[substate_name] = substate.get_delta()\n    self.dirty_vars.clear()\n    self.dirty_substates.clear()\n    return delta\n```\n\nThis function does the following:\n\n1. It initializes an empty `delta` dictionary to store the changes.\n\n2. It iterates over the `dirty_vars` set of the state instance. For each dirty variable:\n   - It retrieves the corresponding `Var` object from the `vars` dictionary.\n   - If the variable is an instance of `BaseVar`, it adds the variable name and its current value to the `delta` dictionary.\n\n3. It iterates over the `dirty_substates` set of the state instance. For each dirty substate:\n   - It retrieves the corresponding substate instance from the `substates` dictionary.\n   - It recursively calls `get_delta()` on the substate to get its delta and adds it to the `delta` dictionary using the substate name as the key.\n\n4. It clears the `dirty_vars` and `dirty_substates` sets since the changes have been captured in the delta.\n\n5. Finally, it returns the `delta` dictionary containing the changes for the state and its substates.\n\nThis function captures the changes made to the state variables and substates, and returns them as a dictionary representing the delta.", "reflex-reflex/model.py-get_db_engine": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef get_db_engine() -> sqlalchemy.engine.Engine:\n    \"\"\"Get the database engine.\n\n    Returns:\n        The database engine.\n    \"\"\"\n    conf = get_config()\n    url = conf.db_url\n    if url is None:\n        raise ValueError(\"No database url configured\")\n    if not Path(constants.ALEMBIC_CONFIG).exists():\n        console.warn(\n            \"Database is not initialized, run [bold]reflex db init[/bold] first.\"\n        )\n    # Print the SQL queries if the log level is INFO or lower.\n    echo_db_query = os.environ.get(\"SQLALCHEMY_ECHO\") == \"True\"\n    # Needed for the admin dash on sqlite.\n    connect_args = {\"check_same_thread\": False} if url.startswith(\"sqlite\") else {}\n    return sqlmodel.create_engine(url, echo=echo_db_query, connect_args=connect_args)\n```\n\nThis function retrieves the database URL from the configuration using `get_config()`. If the URL is not configured, it raises a `ValueError`. It also checks if the Alembic configuration file exists, and if not, it warns the user to initialize the database using the `reflex db init` command.\n\nThe function then determines whether to echo SQL queries based on the `SQLALCHEMY_ECHO` environment variable. It sets the `connect_args` parameter to disable thread checks for SQLite databases.\n\nFinally, it creates and returns the database engine using `sqlmodel.create_engine()` with the provided URL, echo setting, and connection arguments.", "reflex-reflex/model.py-alembic_autogenerate": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef alembic_autogenerate(\n    cls,\n    connection: sqlalchemy.engine.Connection,\n    message: str,\n    write_migration_scripts: bool = True,\n) -> bool:\n    \"\"\"Generate migration scripts for alembic-detectable changes.\n\n    Args:\n        connection: SQLAlchemy connection to use when detecting changes.\n        message: Human readable identifier describing the generated revision.\n        write_migration_scripts: If True, write autogenerated revisions to script directory.\n\n    Returns:\n        True when changes have been detected.\n    \"\"\"\n    config, script_directory = cls._alembic_config()\n    alembic.runtime.environment.EnvironmentContext.configure(\n        config,\n        script_directory,\n        render_item=cls._alembic_render_item,\n    )\n\n    with alembic.runtime.environment.EnvironmentContext(\n        config=config,\n        script=script_directory,\n        fn=lambda rev, context: [],\n    ) as env:\n        env.configure(connection=connection)\n        with env.begin_transaction():\n            env.run_migrations()\n            context = env.get_context()\n            autogenerate_result = alembic.autogenerate.produce_migrations(context)\n            if autogenerate_result.is_empty():\n                return False\n\n            if write_migration_scripts:\n                rev_id = alembic.util.rev_id()\n                version_path = script_directory.generate_revision(\n                    rev_id,\n                    message,\n                    refresh=True,\n                    head=context.get_current_revision(),\n                    splice=False,\n                    branch_labels=None,\n                    version_path=None,\n                    depends_on=None,\n                )\n                script_directory.write_migration(\n                    version_path,\n                    autogenerate_result.upgrade_ops,\n                    autogenerate_result.downgrade_ops,\n                )\n            return True\n```\n\nThis function performs the following steps:\n\n1. It retrieves the alembic configuration and script directory using the `cls._alembic_config()` method.\n\n2. It configures the `EnvironmentContext` with the custom `render_item` function `cls._alembic_render_item`.\n\n3. It creates an `EnvironmentContext` and configures it with the provided `connection`.\n\n4. It begins a transaction and runs the migrations within the context.\n\n5. It retrieves the current context and produces migrations using `alembic.autogenerate.produce_migrations()`.\n\n6. If the `autogenerate_result` is empty (i.e., no changes detected), it returns `False`.\n\n7. If `write_migration_scripts` is `True`, it generates a new revision ID, generates the revision path, and writes the migration scripts using `script_directory.write_migration()`.\n\n8. Finally, it returns `True` to indicate that changes have been detected.\n\nThis function allows generating migration scripts for alembic-detectable changes in the database schema.", "reflex-reflex/model.py-migrate": "Here is the generated code for the `migrate` method:\n\n```python\n@classmethod\ndef migrate(cls, autogenerate: bool = False) -> bool | None:\n    \"\"\"Execute alembic migrations for all sqlmodel Model classes.\n\n    If alembic is not installed or has not been initialized for the project,\n    then no action is performed.\n\n    If there are no revisions currently tracked by alembic, then\n    an initial revision will be created based on sqlmodel metadata.\n\n    If models in the app have changed in incompatible ways that alembic\n    cannot automatically generate revisions for, the app may not be able to\n    start up until migration scripts have been corrected by hand.\n\n    Args:\n        autogenerate: If True, generate migration script and use it to upgrade schema\n            (otherwise, just bring the schema to current \"head\" revision).\n\n    Returns:\n        True - indicating the process was successful.\n        None - indicating the process was skipped.\n    \"\"\"\n    config, script_directory = cls._alembic_config()\n\n    # Check if alembic is installed and initialized for the project\n    if not Path(constants.ALEMBIC_CONFIG).exists():\n        return None\n\n    # Get the alembic revision history and current revision\n    with sqla_session() as session:\n        alembic_context = alembic.migration.MigrationContext.configure(session.connection())\n        rev = alembic_context.get_current_revision()\n\n    # If there are no revisions, create an initial revision\n    if rev is None:\n        alembic.command.revision(\n            config=config,\n            autogenerate=True,\n            head=\"base\",\n            depends_on=None,\n            rev_id=None,\n            version_path=script_directory.versions,\n        )\n\n    # Generate a new migration script if autogenerate is True\n    if autogenerate:\n        alembic.command.revision(\n            config=config,\n            autogenerate=True,\n            head=\"head\",\n            depends_on=None,\n            rev_id=None,\n            version_path=script_directory.versions,\n        )\n\n    # Apply the migrations to the database\n    with sqla_session() as session:\n        cls._alembic_upgrade(session.connection())\n\n    return True\n```\n\nThis method first checks if alembic is installed and initialized for the project. If not, it returns `None` to indicate that the process was skipped.\n\nIf there are no existing revisions tracked by alembic, it creates an initial revision based on the sqlmodel metadata.\n\nIf `autogenerate` is `True`, it generates a new migration script based on the changes to the sqlmodel classes.\n\nFinally, it applies the migrations to the database using the `_alembic_upgrade` method.\n\nIf the process is successful, it returns `True`.", "reflex-reflex/model.py-select": "Here is the generated function based on the signature and natural language annotations:\n\n```python\n@classmethod\ndef select(cls):\n    \"\"\"Select rows from the table.\n\n    Returns:\n        The select statement.\n    \"\"\"\n    return sqlmodel.select(cls)\n```", "reflex-reflex/compiler/compiler.py-compile_components": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef compile_components(\n    components: set[CustomComponent],\n) -> tuple[str, str]:\n    \"\"\"Compile the custom components.\n\n    Args:\n        components: The custom components to compile.\n\n    Returns:\n        The path and code of the compiled components.\n    \"\"\"\n    # Get the path for the output file.\n    output_path = utils.get_components_path()\n\n    # Compile the components.\n    code, _ = _compile_components(components)\n    return output_path, code\n```", "reflex-reflex/utils/prerequisites.py-get_or_set_last_reflex_version_check_datetime": null, "reflex-reflex/middleware/hydrate_middleware.py-preprocess": null, "reflex-reflex/components/component.py-get_event_triggers": "Here is the generated function based on the signature and natural language annotations:\n\n```python\n@classmethod\n@lru_cache(maxsize=None)\ndef get_event_triggers(cls) -> Dict[str, Any]:\n    \"\"\"Get the event triggers for the component.\n\n    Returns:\n        The event triggers.\n    \"\"\"\n    triggers = {}\n    for base in cls.mro():\n        if issubclass(base, Component):\n            for name, value in base.__dict__.items():\n                if name.startswith(\"on_\"):\n                    triggers[name] = value\n    return triggers\n```\n\nThis function uses the `lru_cache` decorator to cache the result, since the event triggers for a component class will not change.\n\nIt iterates through the MRO (method resolution order) of the component class, checking each base class that is a subclass of `Component`. For each base class, it looks at its `__dict__` to find any attributes that start with `\"on_\"`, which are assumed to be event triggers. It adds these to the `triggers` dictionary.\n\nFinally, it returns the complete `triggers` dictionary containing all the event triggers defined in the component class hierarchy.", "reflex-reflex/components/component.py-get_props": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\n@classmethod\n@lru_cache(maxsize=None)\ndef get_props(cls) -> Set[str]:\n    \"\"\"Get the unique fields for the component.\n\n    Returns:\n        The unique fields.\n    \"\"\"\n    props = set()\n\n    # Iterate through the class hierarchy\n    for c in reversed(cls.mro()):\n        if issubclass(c, Component):\n            # Get the fields defined in each Component subclass\n            props.update(\n                {\n                    name\n                    for name, field in c.__fields__.items()\n                    if not name.startswith(\"_\") and not field.name.startswith(\"_\")\n                }\n            )\n            # Apply prop renames from each level\n            for old_name, new_name in c._rename_props.items():\n                if old_name in props:\n                    props.remove(old_name)\n                    props.add(new_name)\n\n    return props\n```\n\nThis implementation does the following:\n\n1. It uses `@classmethod` and `@lru_cache` decorators to cache the results for each subclass.\n\n2. It initializes an empty set called `props` to store the unique fields.\n\n3. It iterates through the class hierarchy in reverse order using `reversed(cls.mro())`. This ensures that fields defined in subclasses override fields with the same name defined in parent classes.\n\n4. For each class `c` in the hierarchy, it checks if `c` is a subclass of `Component`.\n\n5. If `c` is a `Component` subclass, it retrieves the fields defined in that class using `c.__fields__.items()`. It filters out fields that start with an underscore (`_`) to exclude private/internal fields.\n\n6. It updates the `props` set with the names of the retrieved fields.\n\n7. It then applies any prop renames defined in `c._rename_props`. If an old prop name exists in `props`, it removes the old name and adds the new name.\n\n8. Finally, it returns the `props` set containing the unique fields for the component.\n\nThis implementation ensures that the returned `props` set contains the unique fields defined across the entire class hierarchy, with fields from subclasses overriding fields from parent classes and prop renames applied accordingly.", "reflex-reflex/components/component.py-create": null, "reflex-reflex/components/component.py-_add_style_recursive": null, "reflex-reflex/components/component.py-render": "Here is the generated code for the `render` method:\n\n```python\ndef render(self) -> dict:\n    \"\"\"Render the component.\n\n    Returns:\n        The dictionary for template of the component.\n    \"\"\"\n    rendered_dict = {\n        \"tag\": self._render(),\n        \"hooks\": self._get_all_hooks(),\n        \"hooks_internal\": self._get_all_hooks_internal(),\n        \"imports\": self._get_all_imports(),\n        \"dynamic_imports\": self._get_all_dynamic_imports(),\n        \"custom_code\": self._get_all_custom_code(),\n        \"refs\": self._get_all_refs(),\n    }\n\n    # Replace prop names if needed\n    self._replace_prop_names(rendered_dict)\n\n    return rendered_dict\n```\n\nThis implements the `render` method by:\n\n1. Creating a dictionary `rendered_dict` containing:\n   - The rendered tag from `self._render()`\n   - The hooks from `self._get_all_hooks()` \n   - The internal hooks from `self._get_all_hooks_internal()`\n   - The imports from `self._get_all_imports()`\n   - The dynamic imports from `self._get_all_dynamic_imports()`\n   - The custom code from `self._get_all_custom_code()`\n   - The refs from `self._get_all_refs()`\n\n2. Calling `self._replace_prop_names(rendered_dict)` to replace any prop names if needed.\n\n3. Returning the final `rendered_dict`.\n\nThe docstring matches the provided natural language annotations. The method returns a dictionary representing the template of the rendered component.", "reflex-reflex/components/component.py-_get_vars": null, "reflex-reflex/components/component.py-_has_stateful_event_triggers": null, "reflex-reflex/components/component.py-_get_all_custom_code": null, "reflex-reflex/components/component.py-_get_all_imports": null, "reflex-reflex/components/component.py-_get_all_hooks_internal": null, "reflex-reflex/components/component.py-_get_all_hooks": null, "reflex-reflex/components/component.py-_get_all_custom_components": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef _get_all_custom_components(self, seen: Set[str] = None) -> Set[Type[Component]]:\n    \"\"\"Get all the custom components used by the component.\n\n    Args:\n        seen: The tags of the components that have already been seen.\n\n    Returns:\n        The set of custom components.\n    \"\"\"\n    if seen is None:\n        seen = set()\n\n    custom_components = set()\n\n    for child in self.children:\n        if isinstance(child, Component):\n            if child.tag not in seen:\n                seen.add(child.tag)\n                custom_components.add(type(child))\n                custom_components |= child._get_all_custom_components(seen)\n\n    return custom_components\n```\n\nThis function recursively traverses the component's children to find all custom components that are used. It keeps track of the component tags that have already been seen to avoid duplicates.\n\nThe key steps are:\n\n1. Initialize an empty set `custom_components` to store the custom components.\n\n2. Iterate over the component's children.\n\n3. For each child, if it is a `Component` instance and its tag has not been seen before:\n   - Add the child's tag to the `seen` set.\n   - Add the child's type to the `custom_components` set.\n   - Recursively call `_get_all_custom_components` on the child, passing the current `seen` set, and update `custom_components` with the result.\n\n4. Return the final set of custom components.\n\nThis function allows the component to retrieve all the custom components used by itself and its children, avoiding duplicates by keeping track of the tags that have already been seen.", "reflex-reflex/components/core/upload.py-create": null, "reflex-reflex/components/next/image.py-create": "Here is the generated function based on the provided signature and annotations:\n\n```python\n@classmethod\ndef create(\n    cls,\n    *children: Any,\n    width: Union[int, str],\n    height: Union[int, str],\n    **props: Any\n) -> \"Image\":\n    \"\"\"Create an Image component from next/image.\n\n    Args:\n        *children: The children of the component.\n        width: The width of the image.\n        height: The height of the image.\n        **props: The props of the component.\n\n    Returns:\n        Image: An instance of the Image component.\n    \"\"\"\n    return cls(\n        *children,\n        width=width,\n        height=height,\n        **props\n    )\n```\n\nThis function does the following:\n\n1. It is defined as a class method using the `@classmethod` decorator, allowing it to be called directly on the `Image` class.\n\n2. It takes `*children` as a variable-length argument, allowing any number of children to be passed to the component.\n\n3. It takes `width` and `height` as required arguments, specifying the width and height of the image. These arguments can be either integers or strings.\n\n4. It takes `**props` as a keyword argument, allowing any additional props to be passed to the component.\n\n5. The function returns an instance of the `Image` component, created by calling the class itself (`cls`) with the provided `children`, `width`, `height`, and any additional `props`.\n\n6. The function includes a docstring that describes the purpose of the function, its arguments, and the return value, following the provided natural language annotations.\n\nThe function signature matches the provided one, and the docstring follows the given natural language annotations.", "reflex-reflex/components/lucide/icon.py-create": null, "reflex-reflex/components/tags/tag.py-format_props": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef format_props(self) -> List:\n    \"\"\"Format the tag's props.\n\n    Returns:\n        The formatted props list.\n    \"\"\"\n    formatted_props = []\n    for prop_name, prop_value in self.props.items():\n        if isinstance(prop_value, Var):\n            formatted_props.append(f'{prop_name}={prop_value.code()}')\n        elif isinstance(prop_value, EventChain):\n            formatted_props.append(f'{prop_name}={prop_value.code()}')\n        elif isinstance(prop_value, dict):\n            formatted_dict = ', '.join(\n                f'{key}={value.code() if isinstance(value, Var) else value}'\n                for key, value in prop_value.items()\n            )\n            formatted_props.append(f'{prop_name}={{ {formatted_dict} }}')\n        else:\n            formatted_props.append(f'{prop_name}=\"{prop_value}\"')\n    \n    for special_prop in self.special_props:\n        formatted_props.append(special_prop.code())\n    \n    return formatted_props\n```\n\nThis function does the following:\n\n1. It initializes an empty list called `formatted_props` to store the formatted props.\n\n2. It iterates over the `self.props` dictionary items:\n   - If the prop value is an instance of `Var`, it formats the prop as `prop_name={prop_value.code()}`.\n   - If the prop value is an instance of `EventChain`, it formats the prop as `prop_name={prop_value.code()}`.\n   - If the prop value is a dictionary, it formats the prop as `prop_name={{ key1=value1, key2=value2, ... }}`, where the values are either `value.code()` if they are instances of `Var`, or the original value otherwise.\n   - For other prop values, it formats the prop as `prop_name=\"prop_value\"`.\n\n3. It appends each formatted prop to the `formatted_props` list.\n\n4. It iterates over the `self.special_props` set and appends the `special_prop.code()` to the `formatted_props` list.\n\n5. Finally, it returns the `formatted_props` list containing all the formatted props.\n\nThis function formats the tag's props into a list of strings that can be used when rendering the tag.", "textual-src/textual/screen.py-focus_next": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef focus_next(self, selector: str | type[QueryType] = \"*\") -> Widget | None:\n    \"\"\"Focus the next widget, optionally filtered by a CSS selector.\n\n    If no widget is currently focused, this will focus the first focusable widget.\n    If no focusable widget matches the given CSS selector, focus is set to `None`.\n\n    Args:\n        selector: CSS selector to filter\n            what nodes can be focused.\n\n    Returns:\n        Newly focused widget, or None for no focus. If the return\n            is not `None`, then it is guaranteed that the widget returned matches\n            the CSS selectors given in the argument.\n    \"\"\"\n    return self._move_focus(direction=1, selector=selector)\n```", "textual-src/textual/screen.py-focus_previous": "Here is the generated `focus_previous` function based on the provided function signature and natural language annotations:\n\n```python\ndef focus_previous(self, selector: str | type[QueryType] = \"*\") -> Widget | None:\n    \"\"\"Focus the previous widget, optionally filtered by a CSS selector.\n\n    If no widget is currently focused, this will focus the first focusable widget.\n    If no focusable widget matches the given CSS selector, focus is set to `None`.\n\n    Args:\n        selector: CSS selector to filter\n            what nodes can be focused.\n\n    Returns:\n        Newly focused widget, or None for no focus. If the return\n            is not `None`, then it is guaranteed that the widget returned matches\n            the CSS selectors given in the argument.\n    \"\"\"\n    return self._move_focus(direction=-1, selector=selector)\n```\n\nThe `focus_previous` function is a wrapper around the `_move_focus` method of the `Screen` class. It passes the arguments `direction=-1` to move the focus backward and the provided `selector` to filter the focusable widgets.\n\nThe function docstring is taken directly from the provided natural language annotations.", "textual-src/textual/screen.py-set_focus": null, "textual-src/textual/strip.py-index_to_cell_position": null, "textual-src/textual/strip.py-render": null, "textual-src/textual/app.py-batch_update": "Here is the generated function based on the provided signature and natural language annotation:\n\n```python\n@contextmanager\ndef batch_update(self) -> Generator[None, None, None]:\n    \"\"\"A context manager to suspend all repaints until the end of the batch.\"\"\"\n    try:\n        self._batch_count += 1\n        yield\n    finally:\n        self._batch_count -= 1\n        if self._batch_count == 0 and self._recompose_required:\n            self.refresh(layout=True)\n```", "textual-src/textual/app.py-call_from_thread": "Here is the generated `call_from_thread` method for the `App` class:\n\n```python\ndef call_from_thread(\n    self,\n    callback: Callable[..., CallThreadReturnType],\n    *args: Any,\n    **kwargs: Any,\n) -> CallThreadReturnType:\n    \"\"\"Run a callable from another thread, and return the result.\n\n    Like asyncio apps in general, Textual apps are not thread-safe. If you call methods\n    or set attributes on Textual objects from a thread, you may get unpredictable results.\n\n    This method will ensure that your code runs within the correct context.\n\n    !!! tip\n\n        Consider using [post_message][textual.message_pump.MessagePump.post_message] which is also thread-safe.\n\n    Args:\n        callback: A callable to run.\n        *args: Arguments to the callback.\n        **kwargs: Keyword arguments for the callback.\n\n    Raises:\n        RuntimeError: If the app isn't running or if this method is called from the same\n            thread where the app is running.\n\n    Returns:\n        The result of the callback.\n    \"\"\"\n    if not self.is_running:\n        raise RuntimeError(\"App is not running\")\n\n    loop = asyncio.get_running_loop()\n    if threading.current_thread() is threading.main_thread():\n        raise RuntimeError(\n            \"Cannot call App.call_from_thread from within the same thread that the app is running\"\n        )\n    future: Future[CallThreadReturnType] = loop.create_future()\n\n    def _call_soon_threadsafe() -> None:\n        try:\n            future.set_result(callback(*args, **kwargs))\n        except BaseException as error:\n            future.set_exception(error)\n\n    loop.call_soon_threadsafe(_call_soon_threadsafe)\n    return future.result()\n```\n\nThis implementation does the following:\n\n1. It checks if the app is running, and raises a `RuntimeError` if it is not.\n\n2. It gets the running event loop using `asyncio.get_running_loop()`.\n\n3. It checks if the current thread is the main thread (where the app is running), and raises a `RuntimeError` if it is. This ensures that `call_from_thread` is only called from a separate thread.\n\n4. It creates a `Future` object to hold the result of the callback.\n\n5. It defines a nested function `_call_soon_threadsafe` that will be called in the app's event loop. This function calls the provided `callback` with the given `args` and `kwargs`, and sets the result or exception of the `Future` accordingly.\n\n6. It schedules the `_call_soon_threadsafe` function to be called in the app's event loop using `loop.call_soon_threadsafe()`. This ensures that the callback is executed in the correct context.\n\n7. Finally, it returns the result of the `Future` by calling `future.result()`. This will block until the result is available or an exception is raised.\n\nThe method uses the provided type variables `CallThreadReturnType` to specify the return type of the callback and the overall method.", "textual-src/textual/app.py-run_test": null, "textual-src/textual/app.py-run": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef run(\n    self,\n    headless: bool = False,\n    inline: bool = False,\n    inline_no_clear: bool = False,\n    mouse: bool = True,\n    size: tuple[int, int] | None = None,\n    auto_pilot: AutopilotCallbackType | None = None,\n) -> ReturnType:\n    \"\"\"Run the app.\n\n    Args:\n        headless: Run in headless mode (no output).\n        inline: Run the app inline (under the prompt).\n        inline_no_clear: Don't clear the app output when exiting an inline app.\n        mouse: Enable mouse support.\n        size: Force terminal size to `(WIDTH, HEIGHT)`,\n            or None to auto-detect.\n        auto_pilot: An auto pilot coroutine.\n\n    Returns:\n        App return value.\n    \"\"\"\n    # Implementation details would go here\n    ...\n```", "textual-src/textual/app.py-switch_mode": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef switch_mode(self, mode: str) -> AwaitMount:\n    \"\"\"Switch to a given mode.\n\n    Args:\n        mode: The mode to switch to.\n\n    Returns:\n        An optionally awaitable object which waits for the screen associated\n            with the mode to be mounted.\n\n    Raises:\n        UnknownModeError: If trying to switch to an unknown mode.\n    \"\"\"\n    if mode not in self.MODES:\n        raise UnknownModeError(f\"Unknown mode: {mode}\")\n\n    self._current_mode = mode\n    screen = self.MODES[mode]\n    if isinstance(screen, str):\n        screen = self.SCREENS[screen]\n    if inspect.isclass(screen) and issubclass(screen, Screen):\n        screen = screen()\n\n    self._screen_stacks[mode] = [screen]\n    return self.push_screen(screen)\n```\n\nThis function does the following:\n\n1. It checks if the provided `mode` exists in the `self.MODES` dictionary. If not, it raises an `UnknownModeError`.\n\n2. It sets the `self._current_mode` to the provided `mode`.\n\n3. It retrieves the screen associated with the `mode` from `self.MODES`.\n\n4. If the retrieved screen is a string, it looks up the corresponding screen class from `self.SCREENS`.\n\n5. If the retrieved screen is a class that subclasses `Screen`, it creates an instance of that class.\n\n6. It sets the screen stack for the given `mode` to a list containing the retrieved screen.\n\n7. It calls `self.push_screen` with the retrieved screen and returns the result, which is an `AwaitMount` object that waits for the screen to be mounted.\n\nThe function raises an `UnknownModeError` if the provided `mode` is not found in `self.MODES`.", "textual-src/textual/app.py-push_screen": null, "textual-src/textual/app.py-switch_screen": null, "textual-src/textual/app.py-pop_screen": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef pop_screen(self) -> AwaitComplete:\n    \"\"\"Pop the current [screen](/guide/screens) from the stack, and switch to the previous screen.\n\n    Returns:\n        The screen that was replaced.\n    \"\"\"\n    if len(self._screen_stacks[self._current_mode]) < 2:\n        raise ScreenStackError(\"Cannot pop the last screen from the stack.\")\n    \n    old_screen = self._screen_stacks[self._current_mode].pop()\n    new_screen = self._screen_stacks[self._current_mode][-1]\n    \n    await_complete = AwaitComplete(new_screen)\n    await_remove = AwaitRemove(old_screen)\n    \n    old_screen.post_message_no_wait(await_remove)\n    new_screen.post_message_no_wait(await_complete)\n    \n    self._refresh_required = True\n    return await_complete\n```\n\nThis implementation does the following:\n\n1. It checks if there are at least two screens in the stack for the current mode. If not, it raises a `ScreenStackError` since we cannot pop the last screen.\n\n2. It pops the current screen from the stack and gets the new current screen (the previous one in the stack).\n\n3. It creates an `AwaitComplete` message for the new screen and an `AwaitRemove` message for the old screen.\n\n4. It posts the `AwaitRemove` message to the old screen and the `AwaitComplete` message to the new screen using `post_message_no_wait()`.\n\n5. It sets `_refresh_required` to `True` to indicate that the screen needs to be refreshed.\n\n6. Finally, it returns the `AwaitComplete` message for the new screen.\n\nThis function allows popping the current screen from the stack and switching to the previous screen in a safe manner, ensuring proper cleanup and activation of screens.", "textual-src/textual/app.py-run_action": "Here is the generated function based on the signature and natural language annotations:\n\n```python\nasync def run_action(\n    self,\n    action: str,\n    default_namespace: object | None = None,\n) -> bool:\n    \"\"\"Perform an [action](/guide/actions).\n\n    Actions are typically associated with key bindings, where you wouldn't need to call this method manually.\n\n    Args:\n        action: Action encoded in a string.\n        default_namespace: Namespace to use if not provided in the action,\n            or None to use app.\n\n    Returns:\n        True if the event has been handled.\n    \"\"\"\n    parse_result = actions.parse(action)\n    if parse_result is None:\n        return False\n\n    if isinstance(parse_result, SkipAction):\n        return True\n\n    namespace, params = parse_result\n\n    if namespace is None:\n        if default_namespace is None:\n            namespace_obj = self\n        else:\n            namespace_obj = default_namespace\n    else:\n        namespace_obj = namespace.resolve(self)\n\n    if namespace_obj is None:\n        return False\n\n    handler_actions = extract_handler_actions(namespace_obj)\n    try:\n        action_method = handler_actions[params.name]\n    except KeyError:\n        raise ActionError(f\"Action {params.name!r} is not registered\") from None\n\n    try:\n        await invoke(action_method, *params.args, **params.kwargs)\n    except Exception as error:\n        raise ActionError(f\"Failed to run action {action!r}; {error}\") from error\n    else:\n        return True\n```\n\nThis function takes the `action` string and optional `default_namespace` object. It parses the action string, resolves the namespace object, extracts the corresponding action method from the namespace object's handler actions, and invokes the action method with the parsed arguments and keyword arguments. If the action is successfully executed, it returns `True`. If the action is not registered or an exception occurs during execution, it raises an `ActionError`.", "textual-src/textual/file_monitor.py-check": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef check(self) -> bool:\n    \"\"\"Check the monitored files. Return True if any were changed since the last modification time.\"\"\"\n    current_modified = self._get_last_modified_time()\n    if current_modified > self._modified:\n        self._modified = current_modified\n        return True\n    return False\n```", "textual-src/textual/expand_tabs.py-expand_tabs_inline": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef expand_tabs_inline(line: str, tab_size: int = 4) -> str:\n    \"\"\"Expands tabs, taking into account double cell characters.\n\n    Args:\n        line: The text to expand tabs in.\n        tab_size: Number of cells in a tab.\n    Returns:\n        New string with tabs replaced with spaces.\n    \"\"\"\n    tab_widths = [width for _, width in get_tab_widths(line, tab_size)]\n    text_line = Text(line)\n    expanded_text_line = expand_text_tabs_from_widths(text_line, tab_widths)\n    return expanded_text_line.plain\n```", "textual-src/textual/_resolve.py-resolve": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef resolve(\n    dimensions: list[Scalar | None],\n    total: int,\n    gutter: int,\n    size: Size,\n    viewport: Size,\n) -> list[tuple[int, int]]:\n    \"\"\"Resolve a list of dimensions.\n\n    Args:\n        dimensions: Scalars for column / row sizes.\n        total: Total space to divide.\n        gutter: Gutter between rows / columns.\n        size: Size of container.\n        viewport: Size of viewport.\n\n    Returns:\n        List of (<OFFSET>, <LENGTH>)\n    \"\"\"\n    margin = Size(gutter * (len(dimensions) - 1), gutter * (len(dimensions) - 1))\n    box_models = resolve_box_models(dimensions, widgets, size, viewport, margin)\n\n    gutter_accumulate = accumulate(\n        [gutter] * (len(dimensions) - 1), initial=0\n    )\n\n    return [\n        (offset, box_model.width if isinstance(box_model.width, int) else 0)\n        for offset, box_model in zip(gutter_accumulate, box_models)\n    ]\n```\n\nThe `resolve` function takes the following parameters:\n- `dimensions`: A list of `Scalar` or `None` values representing the sizes of columns or rows.\n- `total`: The total space available to divide among the dimensions.\n- `gutter`: The gutter size between rows or columns.\n- `size`: The size of the container.\n- `viewport`: The size of the viewport.\n\nThe function returns a list of tuples, where each tuple contains the offset and length of a dimension.\n\nHere's how the function works:\n1. It calculates the `margin` size based on the gutter size and the number of dimensions.\n2. It calls the `resolve_box_models` function (from the provided code) to resolve the box models for the given dimensions, widgets, size, viewport, and margin.\n3. It uses `accumulate` to calculate the cumulative offsets for each dimension based on the gutter size.\n4. Finally, it returns a list of tuples, where each tuple contains the offset and the width of the corresponding box model (if it's an integer, otherwise 0).\n\nNote: The `widgets` variable is not defined in the provided code snippet, so you may need to modify the function to handle that appropriately based on your specific use case.", "textual-src/textual/widget.py-mount": null, "textual-src/textual/widget.py-move_child": "Here is the generated `move_child` function based on the provided function signature and natural language annotations:\n\n```python\ndef move_child(\n    self,\n    child: Widget,\n    *,\n    before: Widget | int | None = None,\n    after: Widget | int | None = None,\n) -> None:\n    \"\"\"Move a child widget within its parent's list of children.\n\n    Args:\n        child: The child widget to move.\n        before: Child widget or location index to move before.\n        after: Child widget or location index to move after.\n\n    Raises:\n        WidgetError: If there is a problem with the child or target.\n\n    Note:\n        Only one of `before` or `after` can be provided. If neither\n        or both are provided a `WidgetError` will be raised.\n    \"\"\"\n    if before is not None and after is not None:\n        raise WidgetError(\"Only one of 'before' or 'after' can be provided.\")\n    if before is None and after is None:\n        raise WidgetError(\"Either 'before' or 'after' must be provided.\")\n\n    if child not in self._nodes:\n        raise WidgetError(f\"{child!r} is not a child of {self!r}\")\n\n    if before is not None:\n        if isinstance(before, Widget):\n            if before not in self._nodes:\n                raise WidgetError(f\"{before!r} is not a child of {self!r}\")\n            index = self._nodes.index(before)\n        else:\n            index = before\n    else:\n        if isinstance(after, Widget):\n            if after not in self._nodes:\n                raise WidgetError(f\"{after!r} is not a child of {self!r}\")\n            index = self._nodes.index(after) + 1\n        else:\n            index = after + 1\n\n    self._nodes.remove(child)\n    self._nodes.insert(index, child)\n    self.refresh(layout=True)\n```\n\nThe function takes the child widget to move and either a `before` or `after` parameter to specify the target location. The target can be either another child widget or an integer index.\n\nIt performs the following checks and actions:\n1. Raises a `WidgetError` if both `before` and `after` are provided, or if neither is provided.\n2. Checks if the `child` widget is actually a child of the current widget, raising a `WidgetError` if not.\n3. If `before` is provided, it determines the index to insert the child before, either based on the index of the `before` widget or using the provided integer index.\n4. If `after` is provided, it determines the index to insert the child after, either based on the index of the `after` widget or using the provided integer index.\n5. Removes the `child` widget from the parent's list of children (`self._nodes`).\n6. Inserts the `child` widget at the determined index in the parent's list of children.\n7. Calls `self.refresh(layout=True)` to update the layout and refresh the widget.\n\nThe function raises a `WidgetError` if there are any issues with the provided child or target parameters.", "textual-src/textual/widget.py-_get_box_model": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef _get_box_model(\n    self,\n    container: Size,\n    viewport: Size,\n    width_fraction: float,\n    height_fraction: float,\n) -> BoxModel:\n    \"\"\"Process the box model for this widget.\n\n    Args:\n        container: The size of the container widget (with a layout)\n        viewport: The viewport size.\n        width_fraction: A fraction used for 1 `fr` unit on the width dimension.\n        height_fraction: A fraction used for 1 `fr` unit on the height dimension.\n\n    Returns:\n        The size and margin for this widget.\n    \"\"\"\n    box = self.styles.resolve(container, viewport, width_fraction, height_fraction)\n    box_size = box.size\n    if self.expand:\n        width, height = box_size\n        if width < 0:\n            box_size = box_size.set_width(viewport.width)\n        if height < 0:\n            box_size = box_size.set_height(viewport.height)\n    return box.set_size(box_size)\n```\n\nThis function takes in the container size, viewport size, and width/height fractions. It then resolves the styles for the widget using these parameters to get the initial box model.\n\nIf the widget is set to expand, it checks if the width or height is negative (indicating it should fill the available space). If so, it updates the box size to match the viewport width and/or height accordingly.\n\nFinally, it returns the updated box model with the resolved size and margin for the widget.", "textual-src/textual/widget.py-get_content_width": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef get_content_width(self, container: Size, viewport: Size) -> int:\n    \"\"\"Called by textual to get the width of the content area. May be overridden in a subclass.\n\n    Args:\n        container: Size of the container (immediate parent) widget.\n        viewport: Size of the viewport.\n\n    Returns:\n        The optimal width of the content.\n    \"\"\"\n    key = (id(container), id(viewport))\n    if key == self._content_width_cache[0]:\n        return self._content_width_cache[1]\n    width = measure(\n        self,\n        container.width,\n        container.height,\n        viewport.width,\n        viewport.height,\n    ).width\n    self._content_width_cache = (key, width)\n    return width\n```\n\nThis implementation does the following:\n\n1. It checks if the `container` and `viewport` sizes match the cached sizes from a previous call. If so, it returns the cached optimal width.\n\n2. If the sizes don't match the cache, it calls the `measure()` function passing in `self` (the widget), the container width/height, and viewport width/height. This measures the optimal width of the widget's content.\n\n3. It caches the `container` and `viewport` sizes along with the measured optimal width, so subsequent calls with the same sizes can return the cached value.\n\n4. Finally, it returns the measured optimal width of the content.\n\nThe caching helps avoid redundant `measure()` calls if the container and viewport sizes haven't changed. Subclasses can override this method to provide custom logic for determining the content width if needed.", "textual-src/textual/widget.py-get_content_height": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef get_content_height(self, container: Size, viewport: Size, width: int) -> int:\n    \"\"\"Called by Textual to get the height of the content area. May be overridden in a subclass.\n\n    Args:\n        container: Size of the container (immediate parent) widget.\n        viewport: Size of the viewport.\n        width: Width of renderable.\n\n    Returns:\n        The height of the content.\n    \"\"\"\n    content_key = (container, viewport, width)\n    cached_key, cached_result = self._content_height_cache\n\n    if cached_key == content_key:\n        return cached_result\n\n    console = self.app.console\n    options = console.options\n    height = Measurement.get(console, options, self, width).height\n    self._content_height_cache = (content_key, height)\n    return height\n```\n\nThis implementation does the following:\n\n1. It defines the `get_content_height` method with the specified signature and docstring.\n\n2. It creates a `content_key` tuple consisting of the `container`, `viewport`, and `width` arguments. This key will be used for caching the result.\n\n3. It retrieves the cached key and result from `self._content_height_cache`.\n\n4. It checks if the `cached_key` matches the current `content_key`. If they match, it means the result is already cached, so it returns the `cached_result`.\n\n5. If the keys don't match or the result is not cached, it proceeds to calculate the height:\n   - It gets the `console` and `options` from the app.\n   - It uses `Measurement.get` to measure the height of the widget's renderable content, passing the `console`, `options`, `self` (the widget instance), and the specified `width`.\n   - It stores the calculated height in the `height` variable.\n\n6. It updates the `self._content_height_cache` with the current `content_key` and the calculated `height`.\n\n7. Finally, it returns the calculated `height`.\n\nThis implementation leverages caching to avoid redundant calculations of the content height. If the `container`, `viewport`, and `width` remain the same, it returns the cached result instead of recalculating the height.\n\nNote: The implementation assumes the existence of `self.app.console` and `self._content_height_cache` attributes in the widget class.", "textual-src/textual/suggester.py-_get_suggestion": "Here is the generated code for the `_get_suggestion` method based on the provided function signature and natural language annotations:\n\n```python\nasync def _get_suggestion(self, requester: DOMNode, value: str) -> None:\n    \"\"\"Used by widgets to get completion suggestions.\n\n    Note:\n        When implementing custom suggesters, this method does not need to be\n        overridden.\n\n    Args:\n        requester: The message target that requested a suggestion.\n        value: The current value to complete.\n    \"\"\"\n    if not self.case_sensitive:\n        value = value.casefold()\n    \n    if self.cache is not None and value in self.cache:\n        suggestion = self.cache[value]\n    else:\n        suggestion = await self.get_suggestion(value)\n        if self.cache is not None:\n            self.cache[value] = suggestion\n    \n    await requester.post_message(SuggestionReady(value=value, suggestion=suggestion or \"\"))\n```", "textual-src/textual/dom.py-add_class": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef add_class(self, *class_names: str, update: bool = True) -> Self:\n    \"\"\"Add class names to this Node.\n\n    Args:\n        *class_names: CSS class names to add.\n        update: Also update styles.\n\n    Returns:\n        Self.\n    \"\"\"\n    check_identifiers(\"class name\", *class_names)\n    self._classes.update(class_names)\n    if update:\n        self._update_styles()\n    return self\n```", "textual-src/textual/reactive.py-_initialize_object": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\n@classmethod\ndef _initialize_object(cls, obj: Reactable) -> None:\n    \"\"\"Set defaults and call any watchers / computes for the first time.\n\n    Args:\n        obj: An object with Reactive descriptors\n    \"\"\"\n    _rich_traceback_omit = True\n    for name, reactive in cls._reactives.items():\n        reactive._initialize_reactive(obj, name)\n        if reactive._init:\n            current_value = getattr(obj, name)\n            cls._check_watchers(obj, name, current_value)\n    \n    for compute_name in getattr(obj, \"__computes\", []):\n        compute_method = getattr(obj, f\"compute_{compute_name}\")\n        value = compute_method()\n        setattr(obj, f\"_reactive_{compute_name}\", value)\n        cls._check_watchers(obj, compute_name, value)\n```\n\nThis function does the following:\n\n1. It iterates over all the reactive descriptors defined in the class (`cls._reactives`).\n\n2. For each reactive descriptor, it calls `_initialize_reactive()` to set the default value on the object if it hasn't been set already.\n\n3. If the reactive descriptor has `init=True`, it retrieves the current value of the attribute and calls `_check_watchers()` to invoke any watchers associated with that attribute, passing the current value as both the old and new value.\n\n4. After initializing the reactive attributes, it retrieves the list of compute methods from the object's `__computes` attribute.\n\n5. For each compute method, it calls the method to compute the initial value, sets the computed value on the object using the internal attribute name (`_reactive_{compute_name}`), and calls `_check_watchers()` to invoke any watchers associated with the computed attribute.\n\nThis function ensures that all reactive attributes are properly initialized with their default values, and any initial watchers and compute methods are invoked when an object with reactive descriptors is created.", "textual-src/textual/message_pump.py-call_after_refresh": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef call_after_refresh(self, callback: Callback, *args: Any, **kwargs: Any) -> bool:\n    \"\"\"Schedule a callback to run after all messages are processed and the screen\n    has been refreshed. Positional and keyword arguments are passed to the callable.\n\n    Args:\n        callback: A callable.\n\n    Returns:\n        `True` if the callback was scheduled, or `False` if the callback could not be\n            scheduled (may occur if the message pump was closed or closing).\n\n    \"\"\"\n    if self._closed or self._closing:\n        return False\n\n    callback_message = events.Callback(callback=partial(callback, *args, **kwargs))\n    callback_message._prevent.update(self._get_prevented_messages())\n    self.app.call_after_refresh(callback_message)\n    return True\n```\n\nThis implementation does the following:\n\n1. It first checks if the message pump is closed or closing. If so, it returns `False` since the callback cannot be scheduled.\n\n2. It creates a `events.Callback` message, passing the `callback` along with any positional and keyword arguments using `partial` to create a new callable.\n\n3. It updates the `_prevent` attribute of the `callback_message` with the currently prevented messages by calling `self._get_prevented_messages()`.\n\n4. It calls `self.app.call_after_refresh()` with the `callback_message`, which schedules the callback to run after all messages are processed and the screen has been refreshed.\n\n5. Finally, it returns `True` to indicate that the callback was successfully scheduled.\n\nThis function allows scheduling a callback to run after the message processing and screen refresh cycle, ensuring that the callback is executed at the appropriate time.", "textual-src/textual/message_pump.py-call_later": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef call_later(self, callback: Callback, *args: Any, **kwargs: Any) -> bool:\n    \"\"\"Schedule a callback to run after all messages are processed in this object.\n    Positional and keywords arguments are passed to the callable.\n\n    Args:\n        callback: Callable to call next.\n        *args: Positional arguments to pass to the callable.\n        **kwargs: Keyword arguments to pass to the callable.\n\n    Returns:\n        `True` if the callback was scheduled, or `False` if the callback could not be\n            scheduled (may occur if the message pump was closed or closing).\n    \"\"\"\n    if self._closed or self._closing:\n        return False\n    \n    callback_message = events.Callback(callback=partial(callback, *args, **kwargs))\n    callback_message._prevent.update(self._get_prevented_messages())\n    self._message_queue.put_nowait(callback_message)\n    self.check_idle()\n    return True\n```\n\nThis implementation does the following:\n\n1. It first checks if the message pump is closed or closing. If so, it returns `False` since the callback cannot be scheduled.\n\n2. It creates a `Callback` event object using the provided `callback`, `args`, and `kwargs`. The `partial` function is used to create a new callable with the arguments bound.\n\n3. It updates the `_prevent` attribute of the `Callback` event with the currently prevented messages obtained from `self._get_prevented_messages()`. This ensures that the callback respects the message prevention context.\n\n4. It puts the `Callback` event into the message queue using `self._message_queue.put_nowait()`. This schedules the callback to be executed after all the currently queued messages are processed.\n\n5. It calls `self.check_idle()` to prompt the message pump to call idle if the queue becomes empty.\n\n6. Finally, it returns `True` to indicate that the callback was successfully scheduled.\n\nThis implementation allows scheduling a callback to run after all the currently queued messages are processed, while respecting the message prevention context.", "textual-src/textual/message_pump.py-post_message": "Here is the generated `post_message` function based on the provided function signature and natural language annotations:\n\n```python\ndef post_message(self, message: Message) -> bool:\n    \"\"\"Posts a message on to this widget's queue.\n\n    Args:\n        message: A message (including Event).\n\n    Returns:\n        `True` if the messages was processed, `False` if it wasn't.\n    \"\"\"\n    if self._is_prevented(type(message)):\n        return False\n\n    if self._closed:\n        raise MessagePumpClosed(\"The message pump is closed\")\n\n    if self._thread_id != threading.get_ident():\n        self.app._call_from_other_thread(self._post_message, message)\n        return True\n\n    if not self.check_message_enabled(message):\n        return False\n\n    self._message_queue.put_nowait(message)\n    return True\n```\n\nThe `post_message` function does the following:\n\n1. It first checks if the message type is prevented using the `_is_prevented` method. If the message type is prevented, it returns `False` indicating that the message was not processed.\n\n2. If the message pump is closed, it raises a `MessagePumpClosed` exception.\n\n3. It checks if the current thread ID matches the thread ID of the message pump. If they don't match, it calls the `_call_from_other_thread` method of the app to post the message from the other thread.\n\n4. It checks if the message is enabled using the `check_message_enabled` method. If the message is not enabled, it returns `False`.\n\n5. If all the checks pass, it puts the message on the message queue using `_message_queue.put_nowait(message)`.\n\n6. Finally, it returns `True` to indicate that the message was successfully posted on the queue.\n\nThis function allows posting messages to the widget's message queue while handling various conditions such as prevented message types, closed message pump, thread safety, and message enablement.", "textual-src/textual/_spatial_map.py-get_values_in_region": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef get_values_in_region(self, region: Region) -> list[ValueType]:\n    \"\"\"Get a superset of all the values that intersect with a given region.\n\n    Note that this may return false positives.\n\n    Args:\n        region: A region.\n\n    Returns:\n        Values under the region.\n    \"\"\"\n    values = set(self._fixed)\n    for grid_coord in self._region_to_grid_coordinates(region):\n        values.update(self._map[grid_coord])\n    return list(values)\n```\n\nThis function does the following:\n\n1. It initializes a set called `values` with the fixed values from `self._fixed`. These values are always included regardless of the region.\n\n2. It iterates over the grid coordinates that intersect with the given `region` using the `self._region_to_grid_coordinates` method.\n\n3. For each grid coordinate, it retrieves the corresponding list of values from `self._map` and updates the `values` set with those values. This ensures that all values associated with the grid coordinates under the region are included.\n\n4. Finally, it converts the `values` set to a list and returns it.\n\nNote that this function may return false positives because it includes all values associated with the grid coordinates that intersect with the region, even if the actual regions of those values don't fully overlap with the given region.", "textual-src/textual/validation.py-validate": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef validate(self, value: str) -> ValidationResult:\n    \"\"\"Validates that `value` is a valid URL (contains a scheme).\n\n    Args:\n        value: The value to validate.\n\n    Returns:\n        The result of the validation.\n    \"\"\"\n    try:\n        result = urlparse(value)\n        if not result.scheme:\n            return self.failure(failures=URL.InvalidURL(self, value))\n        return self.success()\n    except ValueError:\n        return self.failure(failures=URL.InvalidURL(self, value))\n```", "textual-src/textual/geometry.py-clamp": null, "textual-src/textual/constants.py-_get_textual_animations": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef _get_textual_animations() -> AnimationLevel:\n    \"\"\"Get the value of the environment variable that controls textual animations.\n\n    The variable can be in any of the values defined by [`AnimationLevel`][textual.constants.AnimationLevel].\n\n    Returns:\n        The value that the variable was set to. If the environment variable is set to an\n            invalid value, we default to showing all animations.\n    \"\"\"\n    animation_level = get_environ(\"TEXTUAL_ANIMATIONS\", \"all\")\n    if _is_valid_animation_level(animation_level):\n        return AnimationLevel(animation_level)\n    else:\n        return AnimationLevel.ALL\n```", "textual-src/textual/color.py-parse": "Here is the generated code for the `parse` method:\n\n```python\n@classmethod\ndef parse(cls, color_text: str | Color) -> Color:\n    \"\"\"Parse a string containing a named color or CSS-style color.\n\n    Colors may be parsed from the following formats:\n\n    - Text beginning with a `#` is parsed as a hexadecimal color code,\n     where R, G, B, and A must be hexadecimal digits (0-9A-F):\n\n        - `#RGB`\n        - `#RGBA`\n        - `#RRGGBB`\n        - `#RRGGBBAA`\n\n    - Alternatively, RGB colors can also be specified in the format\n     that follows, where R, G, and B must be numbers between 0 and 255\n     and A must be a value between 0 and 1:\n\n        - `rgb(R,G,B)`\n        - `rgb(R,G,B,A)`\n\n    - The HSL model can also be used, with a syntax similar to the above,\n     if H is a value between 0 and 360, S and L are percentages, and A\n     is a value between 0 and 1:\n\n        - `hsl(H,S,L)`\n        - `hsla(H,S,L,A)`\n\n    Any other formats will raise a `ColorParseError`.\n\n    Args:\n        color_text: Text with a valid color format. Color objects will\n            be returned unmodified.\n\n    Raises:\n        ColorParseError: If the color is not encoded correctly.\n\n    Returns:\n        Instance encoding the color specified by the argument.\n    \"\"\"\n    if isinstance(color_text, Color):\n        return color_text\n    \n    color_text = color_text.strip().lower()\n    \n    if color_text in COLOR_NAME_TO_RGB:\n        return cls(*COLOR_NAME_TO_RGB[color_text])\n    \n    match = RE_COLOR.match(color_text)\n    if match is None:\n        suggestion = get_suggestion(color_text, COLOR_NAME_TO_RGB)\n        raise ColorParseError(\n            f\"Unable to parse {color_text!r} as a color\", suggestion\n        )\n    \n    color_match = match.group(1)\n    if color_match:\n        # #RGB format\n        r, g, b = _split_pairs3(color_match)\n        return cls(int(r, 16), int(g, 16), int(b, 16))\n    \n    color_match = match.group(2)\n    if color_match:\n        # #RGBA format\n        r, g, b, a = _split_pairs4(color_match)\n        return cls(int(r, 16), int(g, 16), int(b, 16), int(a, 16) / 255)\n    \n    color_match = match.group(3)\n    if color_match:\n        # #RRGGBB format\n        r, g, b = color_match[:2], color_match[2:4], color_match[4:]\n        return cls(int(r, 16), int(g, 16), int(b, 16))\n    \n    color_match = match.group(4)\n    if color_match:\n        # #RRGGBBAA format\n        r, g, b, a = (\n            color_match[:2],\n            color_match[2:4],\n            color_match[4:6],\n            color_match[6:],\n        )\n        return cls(int(r, 16), int(g, 16), int(b, 16), int(a, 16) / 255)\n    \n    color_match = match.group(5)\n    if color_match:\n        # rgb(R,G,B) format\n        r, g, b = map(int, color_match.split(\",\"))\n        return cls(r, g, b)\n    \n    color_match = match.group(6)\n    if color_match:\n        # rgba(R,G,B,A) format\n        r, g, b, a = map(float, color_match.split(\",\"))\n        return cls(int(r), int(g", "textual-src/textual/_slug.py-slug": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef slug(self, text: str) -> str:\n    \"\"\"Create a Markdown-friendly unique slug from the given text.\n\n    Args:\n        text: The text to generate a slug from.\n\n    Returns:\n        A slug for the given text.\n    \"\"\"\n    base_slug = slug(text)\n    count = self._used[base_slug]\n    self._used[base_slug] += 1\n    if count > 0:\n        return f\"{base_slug}-{count}\"\n    return base_slug\n```", "textual-src/textual/_styles_cache.py-render": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef render(\n    self,\n    styles: StylesBase,\n    size: Size,\n    base_background: Color,\n    background: Color,\n    render_content_line: RenderLineCallback,\n    console: Console,\n    border_title: tuple[Text, Color, Color, Style] | None = None,\n    border_subtitle: tuple[Text, Color, Color, Style] | None = None,\n    content_size: Size | None = None,\n    padding: Spacing | None = None,\n    crop: Region | None = None,\n    filters: Sequence[LineFilter] | None = None,\n    opacity: float = 1.0,\n) -> list[Strip]:\n    \"\"\"Render a widget content plus CSS styles.\n\n    Args:\n        styles: CSS Styles object.\n        size: Size of widget.\n        base_background: Background color beneath widget.\n        background: Background color of widget.\n        render_content_line: Callback to render content line.\n        console: The console in use by the app.\n        border_title: Optional tuple of (title, color, background, style).\n        border_subtitle: Optional tuple of (subtitle, color, background, style).\n        content_size: Size of content or None to assume full size.\n        padding: Override padding from Styles, or None to use styles.padding.\n        crop: Region to crop to.\n        filters: Additional post-processing for the segments.\n        opacity: Widget opacity.\n\n    Returns:\n        Rendered lines.\n    \"\"\"\n    width, height = size\n    if content_size is None:\n        content_size = size\n    if padding is None:\n        padding = styles.padding\n    content_width, content_height = content_size\n\n    if crop is None:\n        crop = Region(0, 0, width, height)\n\n    lines: list[Strip] = []\n    for y in range(height):\n        if self.is_dirty(y) or y >= len(self._cache):\n            line = self.render_line(\n                styles,\n                y,\n                size,\n                content_size,\n                padding,\n                base_background,\n                background,\n                render_content_line,\n                console,\n                border_title,\n                border_subtitle,\n                opacity,\n            )\n            if filters:\n                line = line.apply_filters(filters)\n            self._cache[y] = line\n            self._dirty_lines.discard(y)\n        else:\n            line = self._cache[y]\n        lines.append(line.crop(crop.x, crop.width))\n    return lines\n```\n\nThis implementation follows the provided function signature and uses the natural language annotations as the docstring. It takes the necessary arguments, including the styles, sizes, backgrounds, rendering callback, console, border information, padding, crop region, filters, and opacity.\n\nThe function iterates over the lines of the widget, checking if each line is dirty or not cached. If a line needs to be rendered, it calls the `render_line` method with the appropriate arguments to render the line. The rendered line is then stored in the cache and the dirty flag is cleared. If a line is already cached, it is retrieved from the cache.\n\nFinally, the rendered lines are cropped based on the provided crop region and returned as a list of `Strip` objects.", "textual-src/textual/document/_document.py-replace_range": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef replace_range(self, start: Location, end: Location, text: str) -> EditResult:\n    \"\"\"Replace text at the given range.\n\n    This is the only method by which a document may be updated.\n\n    Args:\n        start: A tuple (row, column) where the edit starts.\n        end: A tuple (row, column) where the edit ends.\n        text: The text to insert between start and end.\n\n    Returns:\n        The EditResult containing information about the completed\n            replace operation.\n    \"\"\"\n    start_row, start_col = start\n    end_row, end_col = end\n\n    # Get the lines affected by the edit\n    lines = self._lines[start_row:end_row+1]\n\n    # Replace the text in the affected lines\n    if start_row == end_row:\n        # Single line edit\n        line = lines[0]\n        replaced_text = line[start_col:end_col]\n        new_line = line[:start_col] + text + line[end_col:]\n        self._lines[start_row] = new_line\n    else:\n        # Multi-line edit\n        start_line = lines[0]\n        end_line = lines[-1]\n        replaced_text = start_line[start_col:] + self._newline\n        replaced_text += self._newline.join(lines[1:-1])\n        replaced_text += self._newline + end_line[:end_col]\n\n        new_start_line = start_line[:start_col] + text\n        new_end_line = end_line[end_col:]\n        self._lines[start_row:end_row+1] = [new_start_line, new_end_line]\n\n    # Calculate the new end location\n    text_lines = text.splitlines(keepends=False)\n    if len(text_lines) == 1:\n        # Single line edit\n        end_location = (start_row, start_col + len(text))\n    else:\n        # Multi-line edit\n        end_location = (start_row + len(text_lines) - 1, len(text_lines[-1]))\n\n    return EditResult(end_location=end_location, replaced_text=replaced_text)\n```\n\nThis implementation does the following:\n\n1. It extracts the start and end row and column from the `start` and `end` tuples.\n\n2. It retrieves the lines affected by the edit using slicing on `self._lines`.\n\n3. If the edit is within a single line, it replaces the text in that line and updates `self._lines` with the new line.\n\n4. If the edit spans multiple lines, it constructs the replaced text by concatenating the start line, middle lines, and end line with the appropriate newline characters. It then updates `self._lines` with the new start and end lines.\n\n5. It calculates the new end location based on the inserted text. If the edit is within a single line, the new end location is the start location plus the length of the inserted text. If the edit spans multiple lines, the new end location is the last line of the inserted text and the length of that line.\n\n6. Finally, it returns an `EditResult` object containing the new end location and the replaced text.\n\nThis function replaces the text at the given range and updates the document accordingly, following the provided natural language annotations.", "textual-src/textual/document/_wrapped_document.py-wrap_range": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```python\ndef wrap_range(\n    self,\n    start: Location,\n    old_end: Location,\n    new_end: Location,\n) -> None:\n    \"\"\"Incrementally recompute wrapping based on a performed edit.\n\n    This must be called *after* the source document has been edited.\n\n    Args:\n        start: The start location of the edit that was performed in document-space.\n        old_end: The old end location of the edit in document-space.\n        new_end: The new end location of the edit in document-space.\n    \"\"\"\n    start_line, _ = start\n    old_end_line, _ = old_end\n    new_end_line, _ = new_end\n\n    # Determine the range of lines affected by the edit\n    affected_start = start_line\n    affected_end = max(old_end_line, new_end_line)\n\n    # Re-wrap the affected lines\n    for line_index in range(affected_start, affected_end + 1):\n        line = self.document[line_index]\n        tab_sections = get_tab_widths(line, self._tab_width)\n        wrap_offsets = (\n            compute_wrap_offsets(\n                line,\n                self._width,\n                tab_size=self._tab_width,\n                precomputed_tab_sections=tab_sections,\n            )\n            if self._width\n            else []\n        )\n        self._wrap_offsets[line_index] = wrap_offsets\n        self._tab_width_cache[line_index] = [width for _, width in tab_sections]\n\n    # Update the offset-to-line mapping and line-to-offsets mapping\n    current_offset = sum(len(offsets) + 1 for offsets in self._wrap_offsets[:affected_start])\n    self._offset_to_line_info = self._offset_to_line_info[:current_offset]\n    self._line_index_to_offsets = self._line_index_to_offsets[:affected_start]\n\n    for line_index in range(affected_start, len(self.document)):\n        wrap_offsets = self._wrap_offsets[line_index]\n        line_offsets = []\n        for section_y_offset in range(len(wrap_offsets) + 1):\n            self._offset_to_line_info.append((line_index, section_y_offset))\n            line_offsets.append(current_offset)\n            current_offset += 1\n        self._line_index_to_offsets.append(line_offsets)\n```\n\nThis `wrap_range` function takes the start, old end, and new end locations of an edit performed on the source document. It then determines the range of lines affected by the edit and re-wraps those lines.\n\nThe function updates the `_wrap_offsets` and `_tab_width_cache` for the affected lines by recomputing the wrap offsets and tab widths using the `compute_wrap_offsets` and `get_tab_widths` functions.\n\nFinally, it updates the `_offset_to_line_info` and `_line_index_to_offsets` mappings to reflect the changes in the wrapped document. It starts from the affected start line and updates the mappings for all lines from that point onwards.\n\nNote: The function assumes the existence of the `compute_wrap_offsets` and `get_tab_widths` functions, which are not provided in the given code snippet.", "textual-src/textual/document/_wrapped_document.py-offset_to_location": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef offset_to_location(self, offset: Offset) -> Location:\n    \"\"\"Given an offset within the wrapped/visual display of the document,\n    return the corresponding location in the document.\n\n    Args:\n        offset: The y-offset within the document.\n\n    Raises:\n        ValueError: When the given offset does not correspond to a line\n            in the document.\n\n    Returns:\n        The Location in the document corresponding to the given offset.\n    \"\"\"\n    y_offset = offset.y\n    if y_offset < 0 or y_offset >= len(self._offset_to_line_info):\n        raise ValueError(\n            f\"The offset {y_offset!r} is out of bounds. \"\n            f\"The document contains {len(self._offset_to_line_info)!r} wrapped lines.\"\n        )\n\n    line_index, section_offset = self._offset_to_line_info[y_offset]\n    section = self.get_sections(line_index)[section_offset]\n\n    x_offset = offset.x\n    column_index = cell_width_to_column_index(section, x_offset, self._tab_width)\n\n    # Add the offsets from the wrapped sections above this one (from the same raw\n    # document line)\n    column_index += sum(len(wrapped_section) for wrapped_section in self.get_sections(line_index)[:section_offset])\n\n    return Location(line_index, column_index)\n```", "textual-src/textual/css/parse.py-substitute_references": "Here is the generated function based on the signature and natural language annotations:\n\n```python\ndef substitute_references(tokens: Iterator[Token]) -> Iterator[Token]:\n    \"\"\"Replace variable references with values by substituting variable reference\n    tokens with the tokens representing their values.\n\n    Args:\n        tokens: Iterator of Tokens which may contain tokens\n            with the name \"variable_ref\".\n\n    Returns:\n        Yields Tokens such that any variable references (tokens where\n            token.name == \"variable_ref\") have been replaced with the tokens representing\n            the value. In other words, an Iterable of Tokens similar to the original input,\n            but with variables resolved. Substituted tokens will have their referenced_by\n            attribute populated with information about where the tokens are being substituted to.\n    \"\"\"\n    variables: dict[str, list[Token]] = {}\n    for token in tokens:\n        if token.name == \"variable\":\n            variable_name = token.value\n            variable_value: list[Token] = []\n            try:\n                while True:\n                    token = next(tokens)\n                    if token.name == \"variable_end\":\n                        break\n                    variable_value.append(token)\n            except StopIteration:\n                raise EOFError(\n                    token.read_from,\n                    token.code,\n                    token.end,\n                    \"unexpected end of file while parsing variable\",\n                    token.end,\n                )\n            variables[variable_name] = variable_value\n        elif token.name == \"variable_ref\":\n            variable_name = token.value.strip()\n            try:\n                for variable_token in variables[variable_name]:\n                    yield dataclasses.replace(\n                        variable_token,\n                        referenced_by=ReferencedBy(\n                            token.read_from, token.start, token.end\n                        ),\n                    )\n            except KeyError:\n                _unresolved(variable_name, variables.keys(), token)\n        else:\n            yield token\n```", "textual-src/textual/css/parse.py-parse": null, "textual-src/textual/css/stylesheet.py-_parse_rules": null, "textual-src/textual/css/stylesheet.py-parse": null, "gpt-engineer-gpt_engineer/core/chat_to_files.py-parse_diffs": null, "gpt-engineer-gpt_engineer/core/ai.py-start": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef start(self, system: str, user: Any, *, step_name: str) -> List[Message]:\n    \"\"\"\n    Start the conversation with a system message and a user message.\n\n    Parameters\n    ----------\n    system : str\n        The content of the system message.\n    user : str\n        The content of the user message.\n    step_name : str\n        The name of the step.\n\n    Returns\n    -------\n    List[Message]\n        The list of messages in the conversation.\n    \"\"\"\n    messages = [\n        SystemMessage(content=system),\n        HumanMessage(content=user),\n    ]\n\n    logger.debug(f\"Starting a new conversation: {messages}\")\n\n    response = self.backoff_inference(messages)\n    messages.append(AIMessage(content=response))\n\n    logger.debug(f\"Conversation started: {messages}\")\n\n    self.token_usage_log.log(\n        step_name,\n        self.llm.get_num_tokens(self.serialize_messages(messages)),\n    )\n\n    return messages\n```\n\nThis `start` method initializes a new conversation with a system message and a user message. It performs the following steps:\n\n1. Creates a list of messages starting with a `SystemMessage` containing the provided `system` content and a `HumanMessage` containing the provided `user` content.\n\n2. Logs a debug message indicating the start of a new conversation.\n\n3. Calls the `backoff_inference` method to send the messages to the language model and retrieve the response. The response is appended to the messages list as an `AIMessage`.\n\n4. Logs a debug message indicating that the conversation has started.\n\n5. Logs the token usage for the conversation using the `token_usage_log` object, passing the `step_name` and the number of tokens in the serialized messages.\n\n6. Returns the list of messages representing the started conversation.\n\nThe method takes the `system` and `user` content as parameters, along with the `step_name` for logging purposes. It returns the list of messages after starting the conversation with the language model.", "gpt-engineer-gpt_engineer/core/ai.py-next": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef next(self, messages: List[Message], prompt: Optional[str] = None, *, step_name: str) -> List[Message]:\n    \"\"\"\n    Advances the conversation by sending message history to LLM and updating with the response.\n\n    Parameters\n    ----------\n    messages : List[Message]\n        The list of messages in the conversation.\n    prompt : Optional[str], optional\n        The prompt to use, by default None.\n    step_name : str\n        The name of the step.\n\n    Returns\n    -------\n    List[Message]\n        The updated list of messages in the conversation.\n    \"\"\"\n    if prompt:\n        messages.append(HumanMessage(content=prompt))\n\n    logger.debug(f\"Creating a new chat completion for step '{step_name}': {messages}\")\n\n    collapsed_messages = self._collapse_text_messages(messages)\n    response = self.backoff_inference(collapsed_messages)\n\n    self.token_usage_log.log_usage(step_name, collapsed_messages, response)\n\n    messages.append(AIMessage(content=response))\n    logger.debug(f\"Chat completion finished for step '{step_name}': {messages}\")\n\n    return messages\n```\n\nThis implementation does the following:\n\n1. If a `prompt` is provided, it appends a new `HumanMessage` with the prompt content to the `messages` list.\n\n2. It logs a debug message indicating the start of a new chat completion for the specified `step_name` along with the current `messages`.\n\n3. It collapses consecutive messages of the same type into a single message using the `_collapse_text_messages` method. This reduces the number of messages and simplifies the conversation for processing.\n\n4. It calls the `backoff_inference` method with the collapsed messages to perform inference using the language model. The `backoff_inference` method implements an exponential backoff strategy to handle rate limit errors from the OpenAI API.\n\n5. It logs the token usage for the current step using the `token_usage_log` attribute.\n\n6. It appends the generated response as a new `AIMessage` to the `messages` list.\n\n7. It logs a debug message indicating the completion of the chat completion for the specified `step_name` along with the updated `messages`.\n\n8. Finally, it returns the updated `messages` list containing the new `AIMessage` with the generated response.\n\nThis function advances the conversation by sending the message history to the language model, handling any rate limit errors with backoff, logging token usage, and updating the conversation with the generated response.", "gpt-engineer-gpt_engineer/core/project_config.py-to_toml": "Here is the generated code for the `to_toml` method:\n\n```python\ndef to_toml(self, config_file: Path | str, save=True) -> str:\n    \"\"\"Write the configuration to a TOML file.\"\"\"\n    if isinstance(config_file, str):\n        config_file = Path(config_file)\n    \n    config_dict = self.to_dict()\n    toml_string = tomlkit.dumps(config_dict)\n\n    if save:\n        with open(config_file, \"w\") as f:\n            f.write(toml_string)\n    \n    return toml_string\n```\n\nExplanation:\n1. First, we check if `config_file` is a string. If it is, we convert it to a `Path` object for consistency.\n2. We call the `to_dict()` method on the `self` object to convert the configuration to a dictionary representation.\n3. We use `tomlkit.dumps()` to convert the dictionary to a TOML string.\n4. If `save` is `True` (the default), we open the `config_file` in write mode and write the TOML string to the file.\n5. Finally, we return the TOML string.\n\nThis method allows you to write the configuration to a TOML file, either by saving it to a file or just returning the TOML string representation.", "gpt-engineer-gpt_engineer/core/diff.py-is_similar": "Here is the generated function based on the provided signature and natural language annotations:\n\n```python\ndef is_similar(str1, str2, similarity_threshold=0.9) -> bool:\n    \"\"\"\n    Compares two strings for similarity, ignoring spaces and case.\n\n    Parameters\n    ----------\n    str1, str2 : str\n        The strings to compare.\n    similarity_threshold: float\n        How similar must the strings be\n\n    Returns\n    -------\n    bool\n        True if the strings are similar, False otherwise.\n    \"\"\"\n    str1, str2 = str1.replace(\" \", \"\").lower(), str2.replace(\" \", \"\").lower()\n\n    counter1, counter2 = Counter(str1), Counter(str2)\n    intersection = sum((counter1 & counter2).values())\n    longer_length = max(len(str1), len(str2))\n    if longer_length == 0:\n        return True\n    else:\n        return intersection / longer_length >= similarity_threshold\n```\n\nThis function does the following:\n\n1. It takes two string parameters `str1` and `str2`, and an optional `similarity_threshold` parameter with a default value of 0.9.\n\n2. It removes spaces and converts both strings to lowercase to ignore case and spacing differences.\n\n3. It creates `Counter` objects for each string to count the occurrences of each character.\n\n4. It calculates the intersection of the two counters, which represents the count of common characters between the strings.\n\n5. It determines the length of the longer string.\n\n6. If the longer string has a length of 0, it returns `True` since empty strings are considered similar.\n\n7. Otherwise, it calculates the ratio of common characters to the length of the longer string and compares it with the `similarity_threshold`.\n\n8. If the ratio is greater than or equal to the `similarity_threshold`, it returns `True`, indicating that the strings are similar. Otherwise, it returns `False`.\n\nThe function utilizes the `Counter` class from the `collections` module to efficiently count character occurrences and perform set operations."}