{"dtm-dtmsvr/storage/boltdb/boltdb.go-cleanupExpiredData": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc cleanupExpiredData(expire time.Duration, db *bolt.DB) error {\n\tnow := time.Now()\n\texpiredTime := now.Add(-expire)\n\n\tgids := make(map[string]struct{})\n\n\terr := db.View(func(t *bolt.Tx) error {\n\t\tcursor := t.Bucket(bucketIndex).Cursor()\n\t\tfor k, v := cursor.First(); k != nil && string(k) <= fmt.Sprintf(\"%d\", expiredTime.Unix()); k, v = cursor.Next() {\n\t\t\tgid := string(v)\n\t\t\tgids[gid] = struct{}{}\n\t\t}\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\terr = db.Update(func(t *bolt.Tx) error {\n\t\tcleanupGlobalWithGids(t, gids)\n\t\tcleanupBranchWithGids(t, gids)\n\t\tcleanupIndexWithGids(t, gids)\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n```\n\nThe function does the following:\n\n1. It calculates the expiration time based on the provided `expire` duration.\n\n2. It creates a map `gids` to store the expired global transaction IDs.\n\n3. It starts a read-only transaction on the BoltDB database using `db.View()`.\n\n4. Inside the read-only transaction, it iterates over the `bucketIndex` using a cursor, starting from the first key until it reaches a key that is greater than the expiration time.\n\n5. For each expired key-value pair in `bucketIndex`, it extracts the global transaction ID (gid) from the value and stores it in the `gids` map.\n\n6. After collecting all the expired gids, it starts a read-write transaction on the BoltDB database using `db.Update()`.\n\n7. Inside the read-write transaction, it calls the following functions to clean up the expired data:\n   - `cleanupGlobalWithGids(t, gids)`: Deletes the expired global transactions from the `bucketGlobal` bucket.\n   - `cleanupBranchWithGids(t, gids)`: Deletes the expired branch transactions from the `bucketBranches` bucket.\n   - `cleanupIndexWithGids(t, gids)`: Deletes the expired index entries from the `bucketIndex` bucket.\n\n8. Finally, it returns any error that occurred during the cleanup process.\n\nThis function effectively cleans up the expired data in the BoltDB database based on the provided expiration duration. It removes the expired global transactions, branch transactions, and index entries associated with the expired global transaction IDs.", "dtm-dtmsvr/config/config.go-MustLoadConfig": "Here is the generated function based on the provided signature and annotation:\n\n```go\nfunc MustLoadConfig(confFile string) {\n\t// Load config from file\n\tconfBytes, err := ioutil.ReadFile(confFile)\n\tif err != nil {\n\t\tlogger.Fatalf(\"read conf file error: %v\", err)\n\t}\n\terr = yaml.Unmarshal(confBytes, &Config)\n\tif err != nil {\n\t\tlogger.Fatalf(\"unmarshal yaml config error: %v\", err)\n\t}\n\n\t// Override config from environment variables\n\tenvJSON := os.Getenv(\"DTM_CONFIG\")\n\tif envJSON != \"\" {\n\t\terr = json.Unmarshal([]byte(envJSON), &Config)\n\t\tif err != nil {\n\t\t\tlogger.Fatalf(\"unmarshal env config error: %v\", err)\n\t\t}\n\t}\n\n\t// Set default values for missing fields\n\tdefaults.SetDefaults(&Config)\n\n\t// Validate the loaded config\n\terr = validator.New().Struct(Config)\n\tif err != nil {\n\t\tlogger.Fatalf(\"validate config error: %v\", err)\n\t}\n\n\t// Log the loaded config\n\tconfigJSON, _ := json.Marshal(Config)\n\tlogger.Infof(\"loaded config: %s\", string(configJSON))\n}\n```\n\nThe `MustLoadConfig` function does the following:\n\n1. It reads the config file specified by the `confFile` parameter using `ioutil.ReadFile`.\n2. It unmarshals the YAML config into the `Config` variable using `yaml.Unmarshal`.\n3. It checks if there is a `DTM_CONFIG` environment variable. If present, it unmarshals the JSON config from the environment variable and overrides the corresponding fields in the `Config` variable.\n4. It sets default values for any missing fields in the `Config` variable using `defaults.SetDefaults`.\n5. It validates the loaded config using the `validator` package to ensure all required fields are present and have valid values.\n6. Finally, it logs the loaded config as a JSON string using `logger.Infof`.\n\nNote: The code assumes the existence of the `defaults` and `validator` packages for setting default values and validating the config struct, respectively. You may need to import and implement these packages separately.", "dtm-client/dtmcli/dtmimp/utils.go-MustRemarshal": "Here is the generated code for the `MustRemarshal` function:\n\n```go\nfunc MustRemarshal(from interface{}, to interface{}) {\n\tb, err := json.Marshal(from)\n\tE2P(err)\n\terr = json.Unmarshal(b, to)\n\tE2P(err)\n}\n```\n\nThe `MustRemarshal` function takes two parameters:\n- `from`: the source object to be marshaled\n- `to`: the target object to unmarshal the marshaled data into\n\nThe function first marshals the `from` object into a byte slice using `json.Marshal`. If an error occurs during marshaling, it is passed to the `E2P` function which converts the error to a panic.\n\nThen, it unmarshals the byte slice into the `to` object using `json.Unmarshal`. If an error occurs during unmarshaling, it is again passed to the `E2P` function to convert it to a panic.\n\nThis function ensures that both the marshaling and unmarshaling operations are successful, and if any error occurs, it panics with the corresponding error.", "kitex-tool/internal_pkg/generator/type.go-FixHasStreamingForExtendedService": "Here is the generated code for the `FixHasStreamingForExtendedService` function:\n\n```go\nfunc (s *ServiceInfo) FixHasStreamingForExtendedService() {\n\tif s.Base != nil {\n\t\ts.HasStreaming = s.Base.HasStreamingRecursive() || s.HasStreaming\n\t}\n}\n\nfunc (s *ServiceInfo) HasStreamingRecursive() bool {\n\tif s.HasStreaming {\n\t\treturn true\n\t}\n\tif s.Base != nil {\n\t\treturn s.Base.HasStreamingRecursive()\n\t}\n\treturn false\n}\n```\n\nThe `FixHasStreamingForExtendedService` function updates the `HasStreaming` field for extended services. It checks if the base service has any streaming methods recursively using the `HasStreamingRecursive` function. If the base service has streaming methods or the current service has streaming methods, it sets `HasStreaming` to true for the current service.\n\nThe `HasStreamingRecursive` function is a helper function that recursively checks if the service or any of its base services have streaming methods. It returns true if the current service or any of its base services have streaming methods.", "kitex-tool/internal_pkg/generator/type.go-HasStreamingRecursive": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc (s *ServiceInfo) HasStreamingRecursive() bool {\n\tif s.HasStreaming {\n\t\treturn true\n\t}\n\tfor _, combineService := range s.CombineServices {\n\t\tif combineService.HasStreamingRecursive() {\n\t\t\treturn true\n\t\t}\n\t}\n\tif s.Base != nil {\n\t\treturn s.Base.HasStreamingRecursive()\n\t}\n\treturn false\n}\n```\n\nThe `HasStreamingRecursive` method recursively checks if the service or any of its combined services or base services have a streaming method. It does the following:\n\n1. If the current service has streaming (`s.HasStreaming` is true), it returns true.\n\n2. It iterates over the combined services (`s.CombineServices`) and recursively calls `HasStreamingRecursive` on each combined service. If any of the combined services have streaming, it returns true.\n\n3. If the current service has a base service (`s.Base` is not nil), it recursively calls `HasStreamingRecursive` on the base service. If the base service has streaming, it returns true.\n\n4. If none of the above conditions are met, it means neither the current service nor any of its combined services or base services have streaming, so it returns false.\n\nThis recursive approach ensures that it checks for streaming methods in the entire service hierarchy.", "kitex-tool/internal_pkg/generator/generator.go-Unpack": "Here is the generated function based on the provided signature and natural language annotation:\n\n```go\n// Unpack restores the Config from a slice of \"key=val\" strings.\nfunc (c *Config) Unpack(args []string) error {\n\tfor _, arg := range args {\n\t\tparts := strings.SplitN(arg, \"=\", 2)\n\t\tif len(parts) != 2 {\n\t\t\treturn fmt.Errorf(\"invalid argument format: %s\", arg)\n\t\t}\n\t\tkey, val := parts[0], parts[1]\n\n\t\tv := reflect.ValueOf(c).Elem()\n\t\tf := v.FieldByName(key)\n\t\tif !f.IsValid() || !f.CanSet() {\n\t\t\tcontinue\n\t\t}\n\n\t\tswitch f.Kind() {\n\t\tcase reflect.Bool:\n\t\t\tb, err := strconv.ParseBool(val)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"invalid bool value for %s: %s\", key, val)\n\t\t\t}\n\t\t\tf.SetBool(b)\n\t\tcase reflect.String:\n\t\t\tf.SetString(val)\n\t\tcase reflect.Slice:\n\t\t\tif f.Type().Elem().Kind() == reflect.Int {\n\t\t\t\tss := strings.Split(val, \";\")\n\t\t\t\tslice := reflect.MakeSlice(f.Type(), len(ss), len(ss))\n\t\t\t\tfor i, s := range ss {\n\t\t\t\t\tn, err := strconv.Atoi(s)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"invalid int value for %s: %s\", key, s)\n\t\t\t\t\t}\n\t\t\t\t\tslice.Index(i).SetInt(int64(n))\n\t\t\t\t}\n\t\t\t\tf.Set(slice)\n\t\t\t} else {\n\t\t\t\tf.Set(reflect.ValueOf(strings.Split(val, \";\")))\n\t\t\t}\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"unsupported field type for %s: %v\", key, f.Type())\n\t\t}\n\t}\n\treturn nil\n}\n```\n\nThe `Unpack` function takes a slice of \"key=val\" strings and restores the corresponding fields in the `Config` struct. Here's how it works:\n\n1. It iterates over each argument string in the `args` slice.\n2. It splits each argument string by the \"=\" separator to obtain the key and value parts.\n3. It uses reflection to find the field in the `Config` struct that matches the key.\n4. If the field is valid and settable, it proceeds to set the field value based on its type:\n   - For `bool` fields, it parses the value as a boolean using `strconv.ParseBool`.\n   - For `string` fields, it directly sets the field value to the string value.\n   - For `slice` fields:\n     - If the element type is `int`, it splits the value by \";\" separator, parses each element as an integer using `strconv.Atoi`, and sets the field value to a slice of integers.\n     - For other slice types, it splits the value by \";\" separator and sets the field value to a slice of strings.\n5. If the field type is not supported or if there's an error during parsing, it returns an appropriate error.\n6. Finally, it returns `nil` if the unpacking is successful.\n\nThis function allows restoring the `Config` struct from a slice of \"key=val\" strings, providing a convenient way to load configuration values from external sources.", "kitex-tool/internal_pkg/util/util.go-CombineOutputPath": "Here is the generated function based on the function signature and natural language annotation:\n\n```go\nfunc CombineOutputPath(outputPath, ns string) string {\n\tif outputPath == \"\" {\n\t\tgoPath, err := GetGOPATH()\n\t\tif err != nil {\n\t\t\tpanic(err)\n\t\t}\n\t\toutputPath = filepath.Join(goPath, \"src\")\n\t}\n\n\tif ns != \"\" {\n\t\toutputPath = filepath.Join(outputPath, strings.ReplaceAll(ns, \".\", \"/\"))\n\t}\n\n\treturn outputPath\n}\n```\n\nExplanation:\n1. The function first checks if `outputPath` is empty. If it is, it retrieves the GOPATH using the `GetGOPATH()` function and sets `outputPath` to the \"src\" directory within the GOPATH.\n2. If `ns` (namespace) is provided and not empty, it replaces the dots (`.`) in the namespace with slashes (`/`) and appends it to the `outputPath`.\n3. Finally, the function returns the combined output path.\n\nThis function combines the `outputPath` and `ns` variables to generate the final path for output. If `outputPath` is not provided, it uses the GOPATH as the base path. If `ns` is provided, it appends the namespace to the path, replacing dots with slashes to create a valid directory structure.", "kitex-pkg/rpcinfo/stats_util.go-CalcEventCostUs": "Here is the generated function based on the function signature and natural language annotation:\n\n```go\nfunc CalcEventCostUs(start, end stats.Event) uint64 {\n\tif start.Time().After(end.Time()) {\n\t\treturn 0\n\t}\n\treturn uint64(end.Time().Sub(start.Time()).Microseconds())\n}\n```\n\nExplanation:\n- The function takes two `stats.Event` parameters: `start` and `end`.\n- It first checks if the start time is after the end time. If so, it means the events are in the wrong order, and it returns 0 to indicate an invalid duration.\n- If the events are in the correct order, it calculates the duration between the start and end times using `end.Time().Sub(start.Time())`, which returns a `time.Duration`.\n- The `Microseconds()` method is called on the duration to convert it to microseconds.\n- Finally, the duration in microseconds is converted to `uint64` and returned.\n\nNote: The function assumes that the `stats.Event` type has a `Time()` method that returns the timestamp of the event.", "kitex-pkg/rpcinfo/invocation.go-NewInvocation": "Here is the generated code for the `NewInvocation` function:\n\n```go\nfunc NewInvocation(service, method string, pkgOpt ...string) *invocation {\n\tivk := invocationPool.Get().(*invocation)\n\tivk.SetServiceName(service)\n\tivk.SetMethodName(method)\n\tif len(pkgOpt) > 0 {\n\t\tivk.SetPackageName(pkgOpt[0])\n\t}\n\tivk.SetSeqID(genSeqID())\n\treturn ivk\n}\n```\n\nThis function does the following:\n\n1. It retrieves an `*invocation` from the `invocationPool` sync.Pool.\n2. It sets the service name and method name on the `*invocation` using the provided `service` and `method` parameters.\n3. If the optional `pkgOpt` parameter is provided and has at least one element, it sets the package name on the `*invocation` using the first element of `pkgOpt`.\n4. It generates a new sequence ID using the `genSeqID()` function and sets it on the `*invocation`.\n5. Finally, it returns the `*invocation`.\n\nThe function utilizes the `invocationPool` sync.Pool to efficiently reuse `*invocation` instances and avoid unnecessary allocations. It also uses the `SetServiceName`, `SetMethodName`, `SetPackageName`, and `SetSeqID` methods of the `InvocationSetter` interface to set the respective fields on the `*invocation`.", "kitex-pkg/retry/retryer.go-InitWithPolicies": "Here is the generated code for the `InitWithPolicies` function based on the function signature and natural language annotations:\n\n```go\nfunc (rc *Container) InitWithPolicies(methodPolicies map[string]Policy) error {\n\trc.Lock()\n\tdefer rc.Unlock()\n\n\trc.msg = \"\"\n\trc.hasCodeCfg = true\n\n\tfor method, policy := range methodPolicies {\n\t\terr := rc.initRetryer(method, policy)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"initRetryer failed for method %s: %w\", method, err)\n\t\t}\n\t}\n\n\treturn nil\n}\n```\n\nThe `InitWithPolicies` function initializes the `Retryer` instances in the `Container` based on the provided `methodPolicies` map. Here's how it works:\n\n1. It acquires a lock on the `Container` using `rc.Lock()` to ensure thread safety since it modifies the internal state of the `Container`. The lock is released using `defer rc.Unlock()` at the end of the function.\n\n2. It resets the `msg` field to an empty string and sets the `hasCodeCfg` field to `true` to indicate that the `Retryer` instances are initialized using code configuration.\n\n3. It iterates over each method and policy pair in the `methodPolicies` map.\n\n4. For each method and policy, it calls the `initRetryer` function to initialize a new `Retryer` instance based on the policy and stores it in the `retryerMap` of the `Container`.\n\n5. If any error occurs during the initialization of a `Retryer`, it returns an error wrapped with the method name using `fmt.Errorf`.\n\n6. If all `Retryer` instances are successfully initialized, it returns `nil` to indicate success.\n\nThe function ensures that the initialization is performed atomically by acquiring a lock on the `Container`. It also sets the `hasCodeCfg` field to indicate that the configuration is done through code, which takes precedence over remote configuration.", "kitex-pkg/retry/retryer.go-WithRetryIfNeeded": "Here is the generated code for the `WithRetryIfNeeded` function based on the function signature and natural language annotations:\n\n```go\nfunc (rc *Container) WithRetryIfNeeded(ctx context.Context, callOptRetry *Policy, rpcCall RPCCallFunc, ri rpcinfo.RPCInfo, request interface{}) (lastRI rpcinfo.RPCInfo, recycleRI bool, err error) {\n\tretryer := rc.getRetryer(ctx, ri)\n\tif retryer == nil {\n\t\t// No retryer found for the current method, perform the RPC call without retry\n\t\tlastRI, _, err = rpcCall(ctx, nil)\n\t\treturn lastRI, false, err\n\t}\n\n\t// Check if the current call satisfies the retry condition\n\tmsg, ok := retryer.AllowRetry(ctx)\n\tif !ok {\n\t\t// Retry condition not satisfied, perform the RPC call without retry\n\t\tlastRI, _, err = rpcCall(ctx, nil)\n\t\tretryer.AppendErrMsgIfNeeded(ctx, err, lastRI, msg)\n\t\treturn lastRI, false, err\n\t}\n\n\t// Retry condition satisfied, use the retryer to perform the RPC call with retry\n\tif callOptRetry != nil {\n\t\t// Update the retryer policy with the call option retry policy\n\t\terr = retryer.UpdatePolicy(*callOptRetry)\n\t\tif err != nil {\n\t\t\tklog.Errorf(\"KITEX: update retryer policy failed, err=%s\", err.Error())\n\t\t}\n\t}\n\n\tlastRI, recycleRI, err = retryer.Do(ctx, rpcCall, ri, request)\n\treturn lastRI, recycleRI, err\n}\n```\n\nThe `WithRetryIfNeeded` function does the following:\n\n1. It retrieves the appropriate retryer for the current method using `rc.getRetryer(ctx, ri)`.\n\n2. If no retryer is found, it performs the RPC call without retry and returns the result.\n\n3. If a retryer is found, it checks if the current call satisfies the retry condition using `retryer.AllowRetry(ctx)`.\n\n4. If the retry condition is not satisfied, it performs the RPC call without retry, appends any error message if needed using `retryer.AppendErrMsgIfNeeded(ctx, err, lastRI, msg)`, and returns the result.\n\n5. If the retry condition is satisfied, it updates the retryer policy with the call option retry policy (if provided) using `retryer.UpdatePolicy(*callOptRetry)`.\n\n6. Finally, it uses the retryer to perform the RPC call with retry using `retryer.Do(ctx, rpcCall, ri, request)` and returns the result.\n\nThe function returns the last RPC info (`lastRI`), a boolean indicating whether the RPC info can be recycled (`recycleRI`), and any error that occurred during the retry process (`err`).", "kitex-pkg/discovery/discovery.go-DefaultDiff": "Here's the generated code for the `DefaultDiff` function based on the provided function signature and natural language annotations:\n\n```go\nfunc DefaultDiff(cacheKey string, prev, next Result) (Change, bool) {\n\tif !next.Cacheable {\n\t\treturn Change{Result: next}, true\n\t}\n\n\tvar (\n\t\tadded   []Instance\n\t\tupdated []Instance\n\t\tremoved []Instance\n\t)\n\n\tprevInstances := make(map[string]Instance, len(prev.Instances))\n\tfor _, ins := range prev.Instances {\n\t\tprevInstances[ins.Address().String()] = ins\n\t}\n\n\tfor _, ins := range next.Instances {\n\t\taddr := ins.Address().String()\n\t\tif prevIns, ok := prevInstances[addr]; ok {\n\t\t\tif !sameInstance(prevIns, ins) {\n\t\t\t\tupdated = append(updated, ins)\n\t\t\t}\n\t\t\tdelete(prevInstances, addr)\n\t\t} else {\n\t\t\tadded = append(added, ins)\n\t\t}\n\t}\n\n\tfor _, ins := range prevInstances {\n\t\tremoved = append(removed, ins)\n\t}\n\n\treturn Change{\n\t\tResult:  Result{Cacheable: true, CacheKey: cacheKey, Instances: next.Instances},\n\t\tAdded:   added,\n\t\tUpdated: updated,\n\t\tRemoved: removed,\n\t}, true\n}\n\nfunc sameInstance(a, b Instance) bool {\n\treturn a.Address().String() == b.Address().String() &&\n\t\ta.Weight() == b.Weight() &&\n\t\tsameInstanceTags(a, b)\n}\n\nfunc sameInstanceTags(a, b Instance) bool {\n\ttagsA := make(map[string]string)\n\ttagsB := make(map[string]string)\n\n\ta.Tag(\"\") // invoke Tag to populate tagsA\n\tb.Tag(\"\") // invoke Tag to populate tagsB\n\n\tif len(tagsA) != len(tagsB) {\n\t\treturn false\n\t}\n\n\tfor k, v := range tagsA {\n\t\tif v != tagsB[k] {\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}\n```\n\nThe `DefaultDiff` function compares the previous and next `Result` instances and computes the difference between them. It returns a `Change` struct containing the updated `Result` and the lists of added, updated, and removed instances.\n\nThe function first checks if the next result is cacheable. If not, it returns the next result as the `Change` without comparing instances.\n\nIf the next result is cacheable, the function compares the instances in the previous and next results. It creates a map of instances from the previous result for efficient lookup. It then iterates over the instances in the next result and categorizes them as added, updated, or unchanged based on their presence and equality in the previous result. Finally, any remaining instances in the previous result that are not present in the next result are considered removed.\n\nThe `sameInstance` function is used to compare two instances for equality based on their address, weight, and tags. The `sameInstanceTags` function compares the tags of two instances for equality.\n\nThe resulting `Change` struct contains the updated `Result` with the provided `cacheKey`, and the lists of added, updated, and removed instances.", "kitex-pkg/protocol/bthrift/binary.go-SetSpanCache": "Here is the generated code for the `SetSpanCache` function based on the function signature and natural language annotation:\n\n```go\n// SetSpanCache enable/disable binary protocol bytes/string allocator\nfunc SetSpanCache(enable bool) {\n\tif enable {\n\t\tallocator = mem.NewSpanAllocator()\n\t} else {\n\t\tallocator = nil\n\t}\n}\n```\n\nExplanation:\n- The function `SetSpanCache` takes a boolean parameter `enable` to enable or disable the binary protocol bytes/string allocator.\n- If `enable` is `true`, it sets the `allocator` variable to a new instance of `mem.SpanAllocator()`, which is a memory allocator for efficient allocation and deallocation of bytes and strings.\n- If `enable` is `false`, it sets the `allocator` variable to `nil`, effectively disabling the allocator.\n- The `allocator` variable is used in other functions of the `binaryProtocol` to allocate memory for bytes and strings when enabled.\n\nNote: The code assumes that the `mem` package is imported and provides the `NewSpanAllocator()` function for creating a span allocator.", "kitex-pkg/protocol/bthrift/unknown.go-GetUnknownFields": "Here is the generated code for the `GetUnknownFields` function based on the provided function signature and natural language annotation:\n\n```go\nfunc GetUnknownFields(v interface{}) (fields []UnknownField, err error) {\n\t// Check if v is a pointer to a struct\n\trv := reflect.ValueOf(v)\n\tif rv.Kind() != reflect.Ptr || rv.Elem().Kind() != reflect.Struct {\n\t\treturn nil, errors.New(\"v must be a pointer to a struct\")\n\t}\n\n\t// Get the value of the _unknownFields field\n\tunknownFieldsValue := rv.Elem().FieldByName(\"_unknownFields\")\n\tif !unknownFieldsValue.IsValid() {\n\t\treturn nil, errors.New(\"_unknownFields field not found in struct\")\n\t}\n\n\t// Convert the _unknownFields value to a byte slice\n\tunknownFieldsBytes, ok := unknownFieldsValue.Interface().([]byte)\n\tif !ok {\n\t\treturn nil, errors.New(\"_unknownFields field must be of type []byte\")\n\t}\n\n\t// Deserialize the unknownFields bytes to a list of UnknownField\n\tfields, err = ConvertUnknownFields(unknownFieldsBytes)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to convert unknown fields: %v\", err)\n\t}\n\n\treturn fields, nil\n}\n```\n\nThe `GetUnknownFields` function takes an interface `v` as input, which is expected to be a pointer to a struct. It performs the following steps:\n\n1. It checks if `v` is a pointer to a struct using reflection. If not, it returns an error.\n\n2. It retrieves the value of the `_unknownFields` field from the struct using reflection. If the field is not found, it returns an error.\n\n3. It converts the `_unknownFields` value to a byte slice. If the conversion fails, it returns an error.\n\n4. It calls the `ConvertUnknownFields` function to deserialize the `unknownFields` bytes into a list of `UnknownField` structs.\n\n5. If the deserialization is successful, it returns the list of `UnknownField` structs. Otherwise, it returns an error.\n\nNote: The code assumes the existence of the `ConvertUnknownFields` function, which is responsible for deserializing the `unknownFields` bytes into a list of `UnknownField` structs.", "kitex-pkg/protocol/bthrift/unknown.go-WriteUnknownFields": "Here is the generated function based on the given signature and natural language annotation:\n\n```go\nfunc WriteUnknownFields(buf []byte, fs []UnknownField) (offset int, err error) {\n\tfor _, f := range fs {\n\t\toffset += Binary.WriteFieldBegin(buf[offset:], f.Name, thrift.TType(f.Type), f.ID)\n\t\tl, err := writeUnknownField(buf[offset:], &f)\n\t\toffset += l\n\t\tif err != nil {\n\t\t\treturn offset, err\n\t\t}\n\t\toffset += Binary.WriteFieldEnd(buf[offset:])\n\t}\n\treturn\n}\n```\n\nThis function does the following:\n\n1. It iterates over each `UnknownField` in the `fs` slice.\n\n2. For each `UnknownField`, it writes the field begin information (name, type, and ID) into the `buf` using `Binary.WriteFieldBegin()` and updates the `offset` accordingly.\n\n3. It calls the `writeUnknownField()` function to write the actual field value into the `buf` starting from the current `offset`. The `writeUnknownField()` function is responsible for handling different field types and writing the corresponding value into the buffer.\n\n4. It updates the `offset` with the length returned by `writeUnknownField()`.\n\n5. If an error occurs during the `writeUnknownField()` call, it returns the current `offset` and the error.\n\n6. After writing the field value, it writes the field end information into the `buf` using `Binary.WriteFieldEnd()` and updates the `offset`.\n\n7. Finally, it returns the total `offset` (number of bytes written) and any error that occurred during the process.\n\nThis function writes the unknown fields into the provided buffer `buf` and returns the number of bytes written (`offset`) and any error encountered during the process.", "kitex-pkg/circuitbreak/circuitbreak.go-NewCircuitBreakerMW": "Here is the generated code for the `NewCircuitBreakerMW` function:\n\n```go\nfunc NewCircuitBreakerMW(control Control, panel circuitbreaker.Panel) endpoint.Middleware {\n\treturn func(next endpoint.Endpoint) endpoint.Endpoint {\n\t\treturn func(ctx context.Context, request, response interface{}) (err error) {\n\t\t\tcbKey, enabled := control.GetKey(ctx, request)\n\t\t\tif !enabled {\n\t\t\t\treturn next(ctx, request, response)\n\t\t\t}\n\n\t\t\terr = panel.Do(ctx, cbKey, func() error {\n\t\t\t\treturn next(ctx, request, response)\n\t\t\t})\n\n\t\t\tif err == nil {\n\t\t\t\tRecordStat(ctx, request, response, nil, cbKey, &control, panel)\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tif errors.Is(err, circuitbreaker.ErrCircuitBreak) {\n\t\t\t\terr = kerrors.ErrCircuitBreak\n\t\t\t\tif control.DecorateError != nil {\n\t\t\t\t\terr = control.DecorateError(ctx, request, err)\n\t\t\t\t}\n\t\t\t} else if e, ok := err.(CircuitBreakerAwareError); ok {\n\t\t\t\tRecordStat(ctx, request, response, err, cbKey, &control, panel)\n\t\t\t\treturn e\n\t\t\t}\n\n\t\t\tRecordStat(ctx, request, response, err, cbKey, &control, panel)\n\t\t\treturn err\n\t\t}\n\t}\n}\n```\n\nThis function creates a new circuit breaker middleware using the provided `Control` strategy and `Panel`. Here's how it works:\n\n1. It returns a middleware function that wraps the next endpoint.\n2. Inside the middleware function, it retrieves the circuit breaker key and checks if it's enabled using the `GetKey` function from the `Control` strategy.\n3. If the circuit breaker is not enabled, it simply calls the next endpoint and returns its result.\n4. If the circuit breaker is enabled, it uses the `Do` method of the `Panel` to execute the next endpoint within the circuit breaker context.\n5. If the next endpoint returns no error, it records the success using `RecordStat` and returns nil.\n6. If the error is `circuitbreaker.ErrCircuitBreak`, it wraps it with `kerrors.ErrCircuitBreak` and decorates the error using the `DecorateError` function from the `Control` strategy, if provided.\n7. If the error is of type `CircuitBreakerAwareError`, it records the error using `RecordStat` and returns the error as is.\n8. For any other error, it records the error using `RecordStat` and returns the error.\n\nThe `RecordStat` function is used to report the request result (success, failure, or timeout) to the circuit breaker panel based on the error type determined by the `GetErrorType` function from the `Control` strategy.", "kitex-pkg/circuitbreak/cbsuite.go-RPCInfo2Key": "Here is the generated function based on the function signature and natural language annotations:\n\n```go\nfunc RPCInfo2Key(ri rpcinfo.RPCInfo) string {\n\tvar builder strings.Builder\n\tbuilder.WriteString(ri.To().ServiceName())\n\tbuilder.WriteString(\"_\")\n\tbuilder.WriteString(ri.To().Method())\n\treturn builder.String()\n}\n```\n\nThis function takes an `rpcinfo.RPCInfo` object as input and generates a circuit breaker key based on the service name and method name. It concatenates the service name and method name with an underscore separator to create a unique key for the circuit breaker.\n\nThe function uses a `strings.Builder` to efficiently build the key string. It first writes the service name to the builder, followed by an underscore, and then writes the method name. Finally, it returns the generated key as a string using the `String()` method of the builder.", "kitex-pkg/circuitbreak/default.go-ErrorTypeOnServiceLevel": "Here is the generated code for the `ErrorTypeOnServiceLevel` function:\n\n```go\nfunc ErrorTypeOnServiceLevel(ctx context.Context, request, response interface{}, err error) ErrorType {\n\tif err == nil {\n\t\treturn TypeSuccess\n\t}\n\n\tif errType, ok := ignoreErrTypes[err]; ok {\n\t\treturn errType\n\t}\n\n\tif errors.Is(err, context.Canceled) || errors.Is(err, context.DeadlineExceeded) {\n\t\treturn TypeIgnorable\n\t}\n\n\treturn TypeFailure\n}\n```\n\nThe `ErrorTypeOnServiceLevel` function determines the error type based on a service level criteria. Here's how it works:\n\n1. If `err` is `nil`, it means there is no error, so it returns `TypeSuccess`.\n\n2. If `err` matches any of the predefined error types in the `ignoreErrTypes` map, it returns the corresponding error type (`TypeIgnorable` in this case).\n\n3. If `err` is either `context.Canceled` or `context.DeadlineExceeded`, it means the context was canceled or the deadline was exceeded, so it returns `TypeIgnorable`.\n\n4. If none of the above conditions are met, it means the error is considered a failure at the service level, so it returns `TypeFailure`.\n\nThis function provides a way to categorize errors based on service level criteria and determine whether they should be considered as failures or ignored by the circuit breaker.", "kitex-pkg/circuitbreak/default.go-ErrorTypeOnInstanceLevel": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc ErrorTypeOnInstanceLevel(ctx context.Context, request, response interface{}, err error) ErrorType {\n\tif err != nil {\n\t\tif errors.Is(err, kerrors.ErrGetConnection) {\n\t\t\treturn TypeFailure\n\t\t}\n\t\tif errType, ok := ignoreErrTypes[err]; ok {\n\t\t\treturn errType\n\t\t}\n\t\treturn TypeSuccess\n\t}\n\treturn TypeSuccess\n}\n```\n\nExplanation:\n- The function takes in the context, request, response, and error as parameters.\n- It checks if the error is not nil. If it is nil, it means the request was successful, so it returns `TypeSuccess`.\n- If the error is not nil, it checks if the error is of type `kerrors.ErrGetConnection` using `errors.Is()`. If it is, it means there was a connection error, so it returns `TypeFailure`.\n- If the error is not a connection error, it checks if the error type is present in the `ignoreErrTypes` map. If it is, it returns the corresponding error type from the map.\n- If the error is not a connection error and not present in the `ignoreErrTypes` map, it is considered a success at the instance level, so it returns `TypeSuccess`.\n\nThis implementation treats only the connection error (`kerrors.ErrGetConnection`) as a failure at the instance level, while other errors are either ignored based on the `ignoreErrTypes` map or considered a success.", "kitex-pkg/utils/ring.go-NewRing": "Here's the generated code for the `NewRing` function based on the function signature and natural language annotations:\n\n```go\n// Deprecated: it's not used by kitex anymore.\n// NewRing creates a ringbuffer with fixed size.\nfunc NewRing(size int) *Ring {\n\tif size <= 0 {\n\t\tpanic(\"ring size must be greater than 0\")\n\t}\n\n\tr := &Ring{\n\t\tlength: size,\n\t\trings:  make([]*ring, size),\n\t}\n\n\tfor i := 0; i < size; i++ {\n\t\tr.rings[i] = newRing(1024)\n\t}\n\n\treturn r\n}\n```\n\nIn this implementation:\n1. The function is marked as deprecated using the `Deprecated` comment to indicate that it's no longer used by kitex.\n2. The function takes an integer parameter `size` representing the fixed size of the ringbuffer.\n3. It first checks if the `size` is greater than 0. If not, it panics with an appropriate error message.\n4. It creates a new `Ring` struct with the specified `size` and initializes the `rings` slice with the given size.\n5. It then iterates over the `rings` slice and creates a new `ring` instance for each index using the `newRing` function with a default capacity of 1024.\n6. Finally, it returns the newly created `Ring` instance.\n\nNote: The `newRing` function and the `ring` struct are assumed to be defined elsewhere in the code.", "kitex-pkg/utils/thrift.go-Serialize": "Here is the generated code for the `Serialize` function:\n\n```go\nfunc (t *ThriftMessageCodec) Serialize(msg thrift.TStruct) (b []byte, err error) {\n    t.tb.Reset()\n    if err := msg.Write(t.tProt); err != nil {\n        return nil, err\n    }\n    return t.tb.Bytes(), nil\n}\n```\n\nExplanation:\n1. The function takes a `thrift.TStruct` as input, which represents the message to be serialized.\n2. It resets the `TMemoryBuffer` (`t.tb`) to clear any previous data.\n3. It writes the message to the `TProtocol` (`t.tProt`) using the `Write` method of `thrift.TStruct`. If an error occurs during writing, it returns `nil` and the error.\n4. If the write operation is successful, it retrieves the serialized bytes from the `TMemoryBuffer` using the `Bytes` method and returns them along with a `nil` error.\n\nNote: This function performs the normal Thrift serialization of a message into bytes. For binary generic serialization, the `Encode` function should be used instead, as mentioned in the notice comment.", "kitex-pkg/utils/thrift.go-Deserialize": "Here is the generated code for the `Deserialize` function:\n\n```go\nfunc (t *ThriftMessageCodec) Deserialize(msg thrift.TStruct, b []byte) (err error) {\n\tt.tb.Reset()\n\tif _, err = t.tb.Write(b); err != nil {\n\t\treturn err\n\t}\n\tif err = msg.Read(t.tProt); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n```\n\nThis function does the following:\n\n1. It resets the `TMemoryBuffer` (`t.tb`) to clear any existing data.\n\n2. It writes the input byte slice `b` to the `TMemoryBuffer` using `t.tb.Write(b)`. If there is an error during writing, it returns the error.\n\n3. It calls the `Read` method on the `msg` parameter (which is of type `thrift.TStruct`) using the `TProtocol` (`t.tProt`) associated with the `ThriftMessageCodec`. This deserializes the data from the `TMemoryBuffer` into the `msg` struct. If there is an error during deserialization, it returns the error.\n\n4. Finally, if there are no errors, it returns `nil` to indicate successful deserialization.\n\nNote: As mentioned in the comment, this function is the normal Thrift deserialization function. For binary generic, the `Decode` function should be used instead of `Deserialize`.", "kitex-pkg/utils/thrift.go-MarshalError": "Here's the generated code for the `MarshalError` function based on the provided function signature and natural language annotations:\n\n```go\nfunc MarshalError(method string, err error) []byte {\n    e := thrift.NewTApplicationException(thrift.INTERNAL_ERROR, fmt.Sprintf(\"method %s error: %s\", method, err.Error()))\n    buf := thrift.NewTMemoryBufferLen(1024)\n    proto := thrift.NewTBinaryProtocolTransport(buf)\n\n    if err := proto.WriteMessageBegin(method, thrift.EXCEPTION, 0); err != nil {\n        panic(fmt.Errorf(\"write message begin error: %w\", err))\n    }\n    if err := e.Write(proto); err != nil {\n        panic(fmt.Errorf(\"write exception error: %w\", err))\n    }\n    if err := proto.WriteMessageEnd(); err != nil {\n        panic(fmt.Errorf(\"write message end error: %w\", err))\n    }\n    if err := proto.Flush(); err != nil {\n        panic(fmt.Errorf(\"flush message error: %w\", err))\n    }\n\n    return buf.Bytes()\n}\n```\n\nThis function does the following:\n\n1. It creates a new `TApplicationException` with the `INTERNAL_ERROR` type and a message that includes the method name and the error message.\n\n2. It creates a new `TMemoryBuffer` with an initial size of 1024 bytes to store the serialized exception.\n\n3. It creates a new `TBinaryProtocol` instance using the memory buffer as the transport.\n\n4. It writes the message begin using the provided method name, the `EXCEPTION` message type, and a sequence ID of 0.\n\n5. It writes the exception using the `Write` method of the `TApplicationException`.\n\n6. It writes the message end.\n\n7. It flushes the protocol to ensure all the data is written to the memory buffer.\n\n8. Finally, it returns the bytes of the serialized exception from the memory buffer.\n\nIf any error occurs during the writing or flushing process, the function will panic with the corresponding error message.\n\nNote: The code assumes that the necessary thrift packages and types are imported properly.", "kitex-pkg/utils/rpcstats.go-CalculateEventCost": "Here is the generated code for the `CalculateEventCost` function based on the provided function signature and natural language annotations:\n\n```go\nfunc CalculateEventCost(rpcstats rpcinfo.RPCStats, start, end stats.Event) time.Duration {\n\tstartEvent := rpcstats.GetEvent(start)\n\tendEvent := rpcstats.GetEvent(end)\n\n\tif startEvent == nil || endEvent == nil {\n\t\treturn 0\n\t}\n\n\treturn endEvent.Time().Sub(startEvent.Time())\n}\n```\n\nThe function does the following:\n\n1. It retrieves the start and end events from `rpcstats` using the `GetEvent` method.\n\n2. It checks if either the start event or the end event is `nil`. If either of them is `nil`, it means the event is not found in `rpcstats`, so the function returns 0 as the duration.\n\n3. If both events are found, it calculates the time duration by subtracting the start event's time from the end event's time using the `Sub` method of `time.Time`. This gives the duration between the two events.\n\n4. Finally, it returns the calculated duration.\n\nThe function returns 0 when either the start or end event is not found in `rpcstats`, as specified in the natural language annotation.", "kitex-pkg/utils/json.go-_Map2JSONStr": "Here is the generated code for the `Map2JSONStr` function:\n\n```go\nfunc Map2JSONStr(mapInfo map[string]string) (str string, err error) {\n    if len(mapInfo) == 0 {\n        return EmptyJSON, nil\n    }\n    var strBuilder strings.Builder\n    strBuilder.WriteByte(LeftBrace)\n    isFirst := true\n    for k, v := range mapInfo {\n        if !isFirst {\n            strBuilder.WriteByte(Comma)\n        }\n        wrapStrWithQuotation(k, &strBuilder)\n        strBuilder.WriteByte(Colon)\n        wrapStrWithQuotation(v, &strBuilder)\n        isFirst = false\n    }\n    strBuilder.WriteByte(RightBrace)\n    return strBuilder.String(), nil\n}\n```\n\nThis function does the following:\n\n1. It checks if the input `mapInfo` is empty. If so, it returns an empty JSON string `{}` and a nil error.\n\n2. It creates a `strings.Builder` to efficiently build the JSON string.\n\n3. It writes the opening brace `{` to the builder.\n\n4. It initializes a boolean variable `isFirst` to `true` to keep track of whether it's the first key-value pair being processed.\n\n5. It iterates over each key-value pair in the `mapInfo` map:\n   - If it's not the first pair, it writes a comma `,` to separate the pairs.\n   - It calls the `wrapStrWithQuotation` function to wrap the key with quotation marks and write it to the builder.\n   - It writes a colon `:` after the key.\n   - It calls the `wrapStrWithQuotation` function to wrap the value with quotation marks and write it to the builder.\n   - It sets `isFirst` to `false` for subsequent pairs.\n\n6. After iterating over all the key-value pairs, it writes the closing brace `}` to the builder.\n\n7. Finally, it returns the constructed JSON string by calling `strBuilder.String()` and a nil error.\n\nThe `wrapStrWithQuotation` function is a helper function that wraps a string with quotation marks and handles escaping special characters according to JSON rules.\n\nNote: The code assumes the existence of constants like `EmptyJSON`, `LeftBrace`, `RightBrace`, `Comma`, and `Colon`, which should be defined elsewhere in the code.", "kitex-pkg/utils/json.go-_JSONStr2Map": "Here is the generated code for the `JSONStr2Map` function based on the provided function signature and natural language annotations:\n\n```go\nfunc JSONStr2Map(jsonStr string) (mapInfo map[string]string, err error) {\n\tif len(jsonStr) == 0 {\n\t\treturn nil, fmt.Errorf(\"invalid json str\")\n\t}\n\tmapInfo = make(map[string]string)\n\tlastIdx := len(jsonStr) - 1\n\tidx := 0\n\tvar c byte\n\tvar key string\n\tvar val string\n\tfor idx <= lastIdx {\n\t\tif c, idx, err = nextToken([]byte(jsonStr), idx, lastIdx); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tswitch c {\n\t\tcase LeftBrace:\n\t\t\tcontinue\n\t\tcase RightBrace:\n\t\t\treturn mapInfo, nil\n\t\tcase DQuotation:\n\t\t\tif key, idx, err = readString([]byte(jsonStr), idx, lastIdx); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif c, idx, err = nextToken([]byte(jsonStr), idx, lastIdx); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif c != Colon {\n\t\t\t\treturn nil, fmt.Errorf(\"invalid json str, expect colon after object field, but found %s\", string([]byte{c}))\n\t\t\t}\n\t\t\tif val, idx, err = readString([]byte(jsonStr), idx, lastIdx); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tmapInfo[key] = val\n\t\t\tif c, idx, err = nextToken([]byte(jsonStr), idx, lastIdx); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif c == Comma {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif c == RightBrace {\n\t\t\t\treturn mapInfo, nil\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"invalid json str, expect comma or right brace after object field value, but found %s\", string([]byte{c}))\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"invalid json str, expect quotation mark or left brace, but found %s\", string([]byte{c}))\n\t\t}\n\t}\n\treturn nil, fmt.Errorf(\"invalid json str, expect right brace before end of json string\")\n}\n```\n\nThe `JSONStr2Map` function takes a JSON string as input and returns a `map[string]string` and an error. It parses the JSON string and converts it into a map where the keys and values are strings.\n\nThe function first checks if the input JSON string is empty and returns an error if it is. It then initializes an empty `map[string]string` to store the parsed key-value pairs.\n\nThe function iterates over the characters of the JSON string using the `nextToken` function to skip whitespace and get the next meaningful character. It handles different cases based on the encountered character:\n- If it encounters a left brace (`{`), it continues to the next character.\n- If it encounters a right brace (`}`), it means the end of the object, so it returns the parsed map.\n- If it encounters a quotation mark (`\"`), it reads the string using the `readString` function and treats it as a key. It then expects a colon (`:`) followed by another string value. It adds the key-value pair to the map.\n- If it encounters a comma (`,`) after a value, it continues to the next key-value pair.\n- If it encounters any other character, it returns an error indicating an invalid JSON string.\n\nThe function uses the `readString`, `nextToken`, and other utility functions from the provided code to handle string parsing and character reading.\n\nIf the JSON string is valid and all key-value pairs are parsed successfully, the function returns the populated `map[string]string`. If any error occurs during parsing, it returns an appropriate error message.", "kitex-pkg/utils/kitexutil/kitexutil.go-GetCaller": "Here is the generated code for the `GetCaller` function:\n\n```go\nfunc GetCaller(ctx context.Context) (string, bool) {\n\tri := rpcinfo.GetRPCInfo(ctx)\n\tif ri == nil {\n\t\treturn \"\", false\n\t}\n\treturn ri.From().ServiceName(), true\n}\n```\n\nExplanation:\n1. We use `rpcinfo.GetRPCInfo(ctx)` to retrieve the `RPCInfo` from the given context.\n2. If the `RPCInfo` is nil, it means we failed to get the information, so we return an empty string and `false`.\n3. If the `RPCInfo` is not nil, we call `ri.From().ServiceName()` to get the service name of the caller and return it along with `true` to indicate success.", "kitex-pkg/utils/kitexutil/kitexutil.go-GetMethod": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```go\nfunc GetMethod(ctx context.Context) (string, bool) {\n\tri := rpcinfo.GetRPCInfo(ctx)\n\tif ri == nil {\n\t\treturn \"\", false\n\t}\n\treturn ri.Invocation().MethodName(), true\n}\n```\n\nExplanation:\n1. The function takes a `context.Context` as input and returns a string representing the RPC method name and a boolean indicating whether the method name was successfully retrieved.\n2. It uses the `rpcinfo.GetRPCInfo` function to retrieve the `RPCInfo` from the given context.\n3. If the `RPCInfo` is nil, it means the information is not available, so the function returns an empty string and `false`.\n4. If the `RPCInfo` is available, it calls the `Invocation()` method to get the `InvocationInfo` and then retrieves the method name using the `MethodName()` method.\n5. Finally, it returns the method name as a string and `true` to indicate successful retrieval.", "kitex-pkg/utils/kitexutil/kitexutil.go-GetCallerHandlerMethod": "Here is the generated function based on the given signature and natural language annotations:\n\n```go\nfunc GetCallerHandlerMethod(ctx context.Context) (string, bool) {\n\tif ctx == nil {\n\t\treturn \"\", false\n\t}\n\n\t// Get the method name from the context\n\tmethod, ok := ctx.Value(rpcinfo.CtxHandlerMethodKey).(string)\n\tif !ok {\n\t\t// If the method is not found in the context, try to get it from the rpcinfo\n\t\tri := rpcinfo.GetRPCInfo(ctx)\n\t\tif ri == nil {\n\t\t\treturn \"\", false\n\t\t}\n\t\tmethod = ri.From().Method()\n\t\tif method == \"\" {\n\t\t\treturn \"\", false\n\t\t}\n\t}\n\n\treturn method, true\n}\n```\n\nExplanation:\n1. First, we check if the provided `ctx` is `nil`. If it is, we return an empty string and `false` since we cannot retrieve the method name from a `nil` context.\n\n2. We try to get the method name from the context using `ctx.Value(rpcinfo.CtxHandlerMethodKey).(string)`. If the method name is found in the context, we return it along with `true`.\n\n3. If the method name is not found in the context, we try to get it from the `rpcinfo`. We call `rpcinfo.GetRPCInfo(ctx)` to retrieve the `RPCInfo` from the context.\n\n4. If the `RPCInfo` is not found (`ri == nil`), we return an empty string and `false` since we cannot retrieve the method name.\n\n5. If the `RPCInfo` is found, we call `ri.From().Method()` to get the method name of the caller. If the method name is empty, we return an empty string and `false`.\n\n6. Finally, if the method name is successfully retrieved, we return it along with `true`.\n\nThis function follows the given signature and implements the behavior described in the natural language annotations. It tries to retrieve the method name of the caller from the context or the `RPCInfo`, and returns the method name and a boolean indicating the success of the retrieval.", "kitex-pkg/utils/kitexutil/kitexutil.go-GetIDLServiceName": "Here is the generated code for the `GetIDLServiceName` function:\n\n```go\nfunc GetIDLServiceName(ctx context.Context) (string, bool) {\n\tri := rpcinfo.GetRPCInfo(ctx)\n\tif ri == nil {\n\t\treturn \"\", false\n\t}\n\treturn ri.Invocation().ServiceName(), true\n}\n```\n\nExplanation:\n1. We use `rpcinfo.GetRPCInfo(ctx)` to retrieve the `RPCInfo` from the given context.\n2. If the `RPCInfo` is nil, it means we failed to get the information, so we return an empty string and `false`.\n3. If the `RPCInfo` is not nil, we call `ri.Invocation().ServiceName()` to get the service name defined in the IDL.\n4. We return the obtained service name and `true` to indicate that we successfully retrieved the information.", "kitex-pkg/utils/kitexutil/kitexutil.go-GetCallerAddr": "Here is the generated code for the `GetCallerAddr` function:\n\n```go\nfunc GetCallerAddr(ctx context.Context) (net.Addr, bool) {\n\tri := rpcinfo.GetRPCInfo(ctx)\n\tif ri == nil {\n\t\treturn nil, false\n\t}\n\t\n\taddr := ri.From()\n\tif addr == nil {\n\t\treturn nil, false\n\t}\n\t\n\treturn addr, true\n}\n```\n\nThis function does the following:\n\n1. It retrieves the `RPCInfo` from the given `context.Context` using the `rpcinfo.GetRPCInfo` function.\n2. If the `RPCInfo` is `nil`, it means the information is not available, so it returns `nil` and `false`.\n3. It calls the `From()` method on the `RPCInfo` to get the `net.Addr` of the caller.\n4. If the `net.Addr` is `nil`, it means the address information is not available, so it returns `nil` and `false`.\n5. If the `net.Addr` is successfully retrieved, it returns the `net.Addr` and `true`.\n\nThe function returns `false` as the second return value if it fails to get the caller's address information.", "kitex-pkg/utils/kitexutil/kitexutil.go-GetCallerIP": "Here is the generated code for the `GetCallerIP` function:\n\n```go\nfunc GetCallerIP(ctx context.Context) (string, bool) {\n\tri := rpcinfo.GetRPCInfo(ctx)\n\tif ri == nil {\n\t\treturn \"\", false\n\t}\n\n\tif ri.From().Address() == nil {\n\t\treturn \"\", false\n\t}\n\n\taddr := ri.From().Address()\n\tif tcpAddr, ok := addr.(*net.TCPAddr); ok {\n\t\treturn tcpAddr.IP.String(), true\n\t}\n\n\treturn \"\", false\n}\n```\n\nExplanation:\n1. We first retrieve the `RPCInfo` from the given context using `rpcinfo.GetRPCInfo(ctx)`. If it returns `nil`, it means the `RPCInfo` is not available, so we return an empty string and `false`.\n\n2. We then check if the caller's address is available using `ri.From().Address()`. If it returns `nil`, it means the caller's address is not available, so we return an empty string and `false`.\n\n3. We assert the caller's address to be of type `*net.TCPAddr` using a type assertion. If the assertion succeeds, we return the IP address as a string using `tcpAddr.IP.String()` and `true` to indicate success.\n\n4. If the assertion fails or the address is not of type `*net.TCPAddr`, we return an empty string and `false` to indicate failure.\n\nThis function retrieves the caller's IP address from the `RPCInfo` in the given context. It returns the IP address as a string and a boolean value indicating whether the retrieval was successful or not.", "kitex-pkg/utils/kitexutil/kitexutil.go-GetTransportProtocol": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc GetTransportProtocol(ctx context.Context) (string, bool) {\n\tri := rpcinfo.GetRPCInfo(ctx)\n\tif ri == nil {\n\t\treturn \"\", false\n\t}\n\treturn ri.Config().TransportProtocol(), true\n}\n```\n\nThis function does the following:\n\n1. It retrieves the `RPCInfo` from the given context using `rpcinfo.GetRPCInfo(ctx)`.\n2. If the `RPCInfo` is `nil`, it means the information is not available, so it returns an empty string and `false` to indicate failure.\n3. If the `RPCInfo` is available, it calls `ri.Config().TransportProtocol()` to get the transport protocol of the request.\n4. It returns the obtained transport protocol as a string and `true` to indicate success.\n\nThe function follows the provided signature and implements the behavior described in the natural language annotations.", "kitex-pkg/utils/kitexutil/kitexutil.go-GetRPCInfo": "Here is the generated code for the `GetRPCInfo` function based on the function signature and natural language annotations:\n\n```go\nfunc GetRPCInfo(ctx context.Context) (rpcinfo.RPCInfo, bool) {\n\tri := rpcinfo.GetRPCInfo(ctx)\n\tif ri == nil {\n\t\treturn rpcinfo.RPCInfo{}, false\n\t}\n\treturn *ri, true\n}\n```\n\nExplanation:\n- The function takes a `context.Context` as input and returns an `rpcinfo.RPCInfo` struct and a boolean value.\n- It uses the `rpcinfo.GetRPCInfo` function to retrieve the `RPCInfo` from the given context.\n- If the `RPCInfo` is not found in the context (i.e., `ri` is nil), it returns an empty `rpcinfo.RPCInfo` struct and `false` to indicate failure.\n- If the `RPCInfo` is found, it returns the dereferenced `RPCInfo` struct and `true` to indicate success.\n\nThe function follows the provided function signature and implements the behavior described in the natural language annotations.", "kitex-pkg/remote/trans_errors.go-NewTransError": "Here is the generated code for the `NewTransError` function:\n\n```go\nfunc NewTransError(typeID int32, err error) *TransError {\n\treturn &TransError{\n\t\tmessage: defaultTransErrorMessage[typeID],\n\t\ttypeID:  typeID,\n\t\trawErr:  err,\n\t}\n}\n```\n\nThe `NewTransError` function takes two parameters:\n- `typeID` of type `int32`, which represents the error type ID.\n- `err` of type `error`, which is the raw error that can be wrapped by the `TransError`.\n\nThe function creates and returns a new `TransError` instance with the following fields:\n- `message`: It retrieves the default error message corresponding to the given `typeID` from the `defaultTransErrorMessage` map.\n- `typeID`: It sets the `typeID` field to the provided `typeID` value.\n- `rawErr`: It sets the `rawErr` field to the provided `err` value, allowing the raw error to be wrapped by the `TransError`.\n\nThis function allows creating a `TransError` with a specific error type ID and a raw error. The raw error can be used later to check the error type using `errors.Is(target)`, for example, to check if the error is a read timeout error.", "kitex-pkg/remote/trans/gonet/bytebuffer.go-NewBufferReader": "Here is the generated function based on the provided function signature and natural language annotation:\n\n```go\nfunc NewBufferReader(ir io.Reader) remote.ByteBuffer {\n\trw := rwPool.Get().(*bufferReadWriter)\n\trw.reader = netpoll.NewReader(ir)\n\trw.ioReader = ir\n\trw.status = remote.BitReadable\n\treturn rw\n}\n```", "kitex-pkg/remote/trans/gonet/bytebuffer.go-WriteDirect": "Here is the generated code for the `WriteDirect` function:\n\n```go\nfunc (rw *bufferReadWriter) WriteDirect(p []byte, remainCap int) error {\n\tif !rw.writable() {\n\t\treturn errors.New(\"unwritable buffer, cannot support WriteDirect\")\n\t}\n\n\tif len(p) == 0 {\n\t\treturn nil\n\t}\n\n\tif remainCap < 0 {\n\t\treturn errors.New(\"invalid remainCap, must be non-negative\")\n\t}\n\n\tif len(p) > remainCap {\n\t\treturn errors.New(\"insufficient remaining capacity\")\n\t}\n\n\tn, err := rw.writer.WriteDirect(p, remainCap)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif n != len(p) {\n\t\treturn io.ErrShortWrite\n\t}\n\n\treturn nil\n}\n```\n\nExplanation:\n1. First, we check if the buffer is writable. If not, we return an error indicating that the buffer is unwritable and cannot support the `WriteDirect` operation.\n\n2. If the length of the input byte slice `p` is zero, there is nothing to write, so we return `nil`.\n\n3. We check if the `remainCap` is non-negative. If it is negative, we return an error indicating an invalid `remainCap`.\n\n4. We compare the length of `p` with `remainCap`. If the length of `p` is greater than `remainCap`, it means there is insufficient remaining capacity to write the entire byte slice, so we return an error.\n\n5. We call the `WriteDirect` method of the underlying `netpoll.Writer` to write the byte slice `p` without copying and split the original buffer. We pass the `remainCap` as the remaining capacity.\n\n6. If an error occurs during the `WriteDirect` operation, we return that error.\n\n7. We check if the number of bytes written (`n`) is equal to the length of `p`. If they are not equal, it means a short write occurred, so we return `io.ErrShortWrite`.\n\n8. If everything is successful, we return `nil` to indicate that the `WriteDirect` operation completed without any errors.\n\nThis implementation follows the provided function signature and natural language annotations, allowing the `WriteDirect` method to write a byte slice without copying and split the original buffer.", "kitex-pkg/remote/trans/nphttp2/server_handler.go-invokeStreamUnaryHandler": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc invokeStreamUnaryHandler(ctx context.Context, st streaming.Stream, mi serviceinfo.MethodInfo, inkHdlFunc endpoint.Endpoint, ri rpcinfo.RPCInfo) error {\n\t// Receive the request message from the stream\n\treq, err := st.Recv()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Create a new context for the unary handler invocation\n\tunaryCtx := ctx\n\n\t// Invoke the unary handler function\n\trpcinfo.Record(unaryCtx, ri, stats.ServerHandleStart, nil)\n\tresp, err := inkHdlFunc(unaryCtx, req, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Send the response message back through the stream\n\terr = st.Send(resp)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Close the stream\n\terr = st.Close()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n```\n\nThe `invokeStreamUnaryHandler` function allows unary APIs over HTTP2 to use the same server middleware as non-streaming APIs. Here's how it works:\n\n1. It receives the request message from the stream using `st.Recv()`.\n\n2. It creates a new context `unaryCtx` for the unary handler invocation. This context can be customized if needed.\n\n3. It invokes the unary handler function `inkHdlFunc` with the received request message and records the server handle start time.\n\n4. If the handler function returns an error, it is returned immediately.\n\n5. If the handler function is successful, the response message is sent back through the stream using `st.Send()`.\n\n6. Finally, the stream is closed using `st.Close()`.\n\nThis function enables unary APIs over HTTP2 to leverage the same server middleware as non-streaming APIs, providing a consistent middleware experience for both types of APIs.\n\nNote: For Thrift unary APIs over HTTP2, this function is enabled by default. For gRPC (protobuf) unary APIs, it is disabled by default to maintain backward compatibility.", "kitex-pkg/remote/trans/nphttp2/metadata/metadata.go-FromOutgoingContext": "Here is the generated code for the `FromOutgoingContext` function based on the provided signature and annotations:\n\n```go\nfunc FromOutgoingContext(ctx context.Context) (MD, bool) {\n\traw, ok := ctx.Value(mdOutgoingKey{}).(rawMD)\n\tif !ok {\n\t\treturn nil, false\n\t}\n\n\toutgoingMD := raw.md.Copy()\n\tfor _, added := range raw.added {\n\t\tfor i := 0; i < len(added); i += 2 {\n\t\t\toutgoingMD[added[i]] = append(outgoingMD[added[i]], added[i+1])\n\t\t}\n\t}\n\n\treturn outgoingMD, true\n}\n```\n\nExplanation:\n1. The function retrieves the `rawMD` value associated with the `mdOutgoingKey` from the context using `ctx.Value(mdOutgoingKey{}).(rawMD)`. If the value doesn't exist or cannot be asserted to `rawMD`, it means there is no outgoing metadata in the context, so the function returns `nil` and `false`.\n\n2. If the `rawMD` value is successfully retrieved, the function creates a copy of the `md` field using `raw.md.Copy()` to avoid modifying the original metadata.\n\n3. The function then iterates over the `added` field of `rawMD`, which contains additional metadata key-value pairs that were appended to the context using `AppendToOutgoingContext`.\n\n4. For each slice of key-value pairs in `added`, the function iterates over the pairs and appends the values to the corresponding keys in the `outgoingMD` map.\n\n5. Finally, the function returns the merged `outgoingMD` and `true` to indicate that outgoing metadata exists in the context.\n\nNote: The returned `MD` should not be modified directly, as mentioned in the annotations. Any modifications should be made to a copy of the returned `MD` to avoid races.", "kitex-pkg/remote/trans/nphttp2/status/status.go-WithDetails": "Here is the generated code for the `WithDetails` function:\n\n```go\nfunc (s *Status) WithDetails(details ...proto.Message) (*Status, error) {\n\tif s == nil || s.s == nil {\n\t\treturn nil, errors.New(\"nil Status\")\n\t}\n\n\t// Make a copy of the status to avoid modifying the original.\n\tnewStatus := &Status{\n\t\ts: proto.Clone(s.s).(*spb.Status),\n\t}\n\n\tfor _, detail := range details {\n\t\tany, err := anypb.New(detail)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tnewStatus.s.Details = append(newStatus.s.Details, any)\n\t}\n\n\treturn newStatus, nil\n}\n```\n\nThe `WithDetails` function takes a variadic argument `details` of type `proto.Message` and returns a new `*Status` with the provided details messages appended to the status. If any errors are encountered while creating the `anypb.Any` messages from the provided details, it returns `nil` and the first error encountered.\n\nHere's how the function works:\n\n1. It first checks if the receiver `s` or its underlying `spb.Status` is `nil`. If either is `nil`, it returns `nil` and an error indicating a \"nil Status\".\n\n2. It creates a new `Status` called `newStatus` by cloning the underlying `spb.Status` of the receiver `s`. This is done to avoid modifying the original status.\n\n3. It iterates over each `detail` in the `details` slice:\n   - It creates a new `anypb.Any` message from the `detail` using `anypb.New()`.\n   - If there is an error creating the `anypb.Any` message, it returns `nil` and the error.\n   - If there is no error, it appends the `anypb.Any` message to the `Details` field of the `newStatus`'s underlying `spb.Status`.\n\n4. Finally, it returns the `newStatus` and `nil` error.\n\nThis function allows adding details messages to a `Status` while preserving the original status and handling any errors that may occur during the process.", "kitex-pkg/remote/trans/nphttp2/status/status.go-FromError": "Here is the generated code for the `FromError` function based on the function signature and natural language annotations:\n\n```go\nfunc FromError(err error) (s *Status, ok bool) {\n\tif err == nil {\n\t\treturn nil, true\n\t}\n\tif se, ok := err.(Iface); ok {\n\t\treturn se.GRPCStatus(), true\n\t}\n\treturn New(codes.Unknown, err.Error()), false\n}\n```\n\nExplanation:\n1. If `err` is `nil`, the function returns `nil` for the `Status` and `true` for `ok`, indicating that there is no error.\n2. If `err` implements the `Iface` interface, which has a `GRPCStatus() *Status` method, the function returns the result of calling `GRPCStatus()` on `err` and `true` for `ok`, indicating that the error was produced from this package or has the required method.\n3. If `err` does not implement the `Iface` interface, the function returns a new `Status` with `codes.Unknown` and the original error message obtained by calling `err.Error()`, and `false` for `ok`, indicating that the error was not produced from this package and does not have the required method.\n\nThe function follows the behavior described in the natural language annotations, converting an error to a `Status` if it was produced from the package or has the `GRPCStatus() *Status` method, and returning a `Status` with `codes.Unknown` and the original error message otherwise.", "kitex-pkg/remote/trans/nphttp2/status/status.go-FromContextError": "Here is the generated function based on the function signature and natural language annotations:\n\n```go\nfunc FromContextError(err error) *Status {\n\tif err == nil {\n\t\treturn New(codes.OK, \"\")\n\t}\n\n\tswitch err {\n\tcase context.DeadlineExceeded:\n\t\treturn New(codes.DeadlineExceeded, err.Error())\n\tcase context.Canceled:\n\t\treturn New(codes.Canceled, err.Error())\n\tdefault:\n\t\treturn New(codes.Unknown, err.Error())\n\t}\n}\n```\n\nThis function takes an `error` as input and returns a `*Status` based on the following logic:\n\n1. If `err` is `nil`, it returns a `Status` with `codes.OK` and an empty message.\n\n2. If `err` is a context error:\n   - If `err` is `context.DeadlineExceeded`, it returns a `Status` with `codes.DeadlineExceeded` and the error message.\n   - If `err` is `context.Canceled`, it returns a `Status` with `codes.Canceled` and the error message.\n\n3. If `err` is non-nil and not a context error, it returns a `Status` with `codes.Unknown` and the error message.\n\nThe function converts context errors into their corresponding gRPC status codes and returns a `Status` object representing the error.", "kitex-pkg/remote/trans/nphttp2/grpc/bdp_estimator.go-calculate": "Here is the generated function based on the function signature and natural language annotations:\n\n```go\nfunc (b *bdpEstimator) calculate(d [8]byte) {\n\t// Check if the received ping ack matches the expected data\n\tif bdpPing.data != d {\n\t\treturn\n\t}\n\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\n\t// Calculate the round trip time (seconds)\n\trttSample := time.Since(b.sentAt).Seconds()\n\t// Update the average round trip time using the moving average formula\n\tb.rtt = b.rtt*alpha + rttSample*(1-alpha)\n\t// Calculate the current bandwidth sample (bytes/sec)\n\tbwCurrent := float64(b.sample) / rttSample\n\t// Update the maximum bandwidth seen so far\n\tif bwCurrent > b.bwMax {\n\t\tb.bwMax = bwCurrent\n\t}\n\n\t// Calculate the current bdp estimate\n\tbdpCurrent := uint32(bwCurrent * b.rtt)\n\t// Check if the current bdp estimate is greater than or equal to beta times our current estimate\n\t// and if the current bandwidth is equal to the maximum seen so far\n\tif float64(bdpCurrent) >= beta*float64(b.bdp) && bwCurrent == b.bwMax {\n\t\t// Increase our current bdp estimate by a factor of gamma\n\t\tb.bdp = uint32(gamma * float64(bdpCurrent))\n\t\t// Ensure we don't exceed the maximum allowed value\n\t\tif b.bdp > bdpLimit {\n\t\t\tb.bdp = bdpLimit\n\t\t}\n\t\t// Update the flow control window sizes\n\t\tb.updateFlowControl(b.bdp)\n\t}\n\n\t// Reset the measurement cycle\n\tb.sample = 0\n\tb.isSent = false\n}\n```\n\nThe `calculate` function is called when an acknowledgement for a bdp ping is received. It performs the following steps:\n\n1. It checks if the received ping ack matches the expected data. If not, it returns early.\n\n2. It calculates the round trip time (RTT) for the current sample using the time elapsed since the ping was sent.\n\n3. It updates the average RTT using the moving average formula with the `alpha` constant.\n\n4. It calculates the current bandwidth sample by dividing the number of bytes received by the RTT.\n\n5. It updates the maximum bandwidth seen so far if the current bandwidth is greater.\n\n6. It calculates the current bdp estimate by multiplying the current bandwidth with the average RTT.\n\n7. It checks if the current bdp estimate is greater than or equal to `beta` times the current estimate and if the current bandwidth is equal to the maximum seen so far. If both conditions are met, it increases the current bdp estimate by a factor of `gamma`, ensuring it doesn't exceed the maximum allowed value (`bdpLimit`).\n\n8. If the bdp estimate was updated, it calls the `updateFlowControl` function to update the flow control window sizes.\n\n9. Finally, it resets the measurement cycle by setting the sample to 0 and `isSent` to false.\n\nThis function calculates the current bandwidth-delay product (BDP) and updates the flow control window sizes accordingly to optimize network performance.", "kitex-pkg/remote/trans/nphttp2/grpc/http2_server.go-finishStream": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc (t *http2Server) finishStream(s *Stream, rst bool, rstCode http2.ErrCode, hdr *headerFrame, eosReceived bool) {\n\t// Close the stream\n\tt.closeStream(s, rst, rstCode, eosReceived)\n\n\t// Put the trailing headerFrame into controlbuf\n\tif hdr != nil {\n\t\tt.controlBuf.put(&headerFrame{\n\t\t\tstreamID:  s.id,\n\t\t\thf:        hdr.hf,\n\t\t\tendStream: true,\n\t\t\tonWrite:   func() {},\n\t\t})\n\t}\n}\n```\n\nThe `finishStream` function does the following:\n\n1. It calls the `closeStream` method to close the given stream `s`. The `rst`, `rstCode`, and `eosReceived` parameters are passed to `closeStream` to indicate whether the stream should be reset, the reset code, and if the end-of-stream has been received.\n\n2. If the `hdr` parameter is not nil, it means there is a trailing headerFrame to be sent. In this case, it creates a new `headerFrame` struct with the stream ID, header fields (`hdr.hf`), `endStream` set to true, and an empty `onWrite` function. This headerFrame is then put into the `controlBuf` using the `put` method.\n\nBy closing the stream and putting the trailing headerFrame into the `controlBuf`, the `finishStream` function ensures that the stream is properly closed and any remaining headers are sent before the stream is terminated.", "kitex-pkg/remote/trans/nphttp2/grpc/http2_server.go-closeStream": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc (t *http2Server) closeStream(s *Stream, rst bool, rstCode http2.ErrCode, eosReceived bool) {\n\t// Removes the stream from the transport's active streams map.\n\tt.mu.Lock()\n\tdelete(t.activeStreams, s.id)\n\tif len(t.activeStreams) == 0 {\n\t\tt.idle = time.Now()\n\t}\n\tt.mu.Unlock()\n\n\t// Clears the stream's context and cancels any pending operations.\n\ts.cancel()\n\n\t// If the stream was reset, sends a RST_STREAM frame to the client.\n\tif rst {\n\t\tt.controlBuf.put(&cleanupStream{\n\t\t\tstreamID: s.id,\n\t\t\trst:      true,\n\t\t\trstCode:  rstCode,\n\t\t\tonWrite:  func() {},\n\t\t})\n\t}\n\n\t// If the stream received an end-of-stream frame from the client, closes the stream's receive buffer.\n\tif eosReceived {\n\t\ts.buf.Close()\n\t}\n\n\t// Puts a cleanupStream item into the control buffer to delete the stream from the loopy writer's established streams map.\n\tt.controlBuf.put(&cleanupStream{\n\t\tstreamID: s.id,\n\t\trst:      false,\n\t\trstCode:  0,\n\t\tonWrite:  func() {},\n\t})\n}\n```\n\nThe `closeStream` function performs the following steps to clear the footprint of a stream when it is no longer needed:\n\n1. It removes the stream from the transport's `activeStreams` map and updates the `idle` time if there are no more active streams.\n\n2. It cancels the stream's context to cancel any pending operations.\n\n3. If the `rst` parameter is true, it sends a RST_STREAM frame to the client with the specified `rstCode`.\n\n4. If the `eosReceived` parameter is true, indicating that an end-of-stream frame was received from the client, it closes the stream's receive buffer.\n\n5. It puts a `cleanupStream` item into the control buffer to delete the stream from the loopy writer's established streams map.\n\nThis function effectively cleans up the stream's resources and removes its footprint from the server when the stream is no longer needed.", "kitex-pkg/remote/trans/nphttp2/grpc/transport.go-TLSConfig": "Here is the generated function based on the function signature and natural language annotations:\n\n```go\nfunc TLSConfig(tlsConfig *tls.Config) *tls.Config {\n\tif tlsConfig == nil {\n\t\treturn &tls.Config{}\n\t}\n\t\n\t// Make a copy of the provided tls.Config to avoid modifying the original\n\ttlsConfigCopy := tlsConfig.Clone()\n\t\n\t// Enable HTTP/2 support\n\ttlsConfigCopy.NextProtos = append(tlsConfigCopy.NextProtos, \"h2\")\n\t\n\t// Set strong cipher suites if not specified\n\tif len(tlsConfigCopy.CipherSuites) == 0 {\n\t\ttlsConfigCopy.CipherSuites = []uint16{\n\t\t\ttls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\n\t\t\ttls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,\n\t\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\n\t\t\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\n\t\t\ttls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,\n\t\t\ttls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,\n\t\t}\n\t}\n\t\n\t// Set minimum TLS version to 1.2 if not specified\n\tif tlsConfigCopy.MinVersion == 0 {\n\t\ttlsConfigCopy.MinVersion = tls.VersionTLS12\n\t}\n\t\n\treturn tlsConfigCopy\n}\n```\n\nThis function takes a `*tls.Config` as input, checks and supplements it with recommended settings for HTTP/2 support, strong cipher suites, and minimum TLS version if not already specified by the user. It returns the updated `*tls.Config`.\n\nThe key steps are:\n\n1. If the input `tlsConfig` is nil, create a new empty `tls.Config`.\n\n2. Make a copy of the provided `tls.Config` using `Clone()` to avoid modifying the original.\n\n3. Add \"h2\" to the `NextProtos` field to enable HTTP/2 support.\n\n4. If no cipher suites are specified, set a list of recommended strong cipher suites.\n\n5. If the minimum TLS version is not set, set it to TLS 1.2.\n\n6. Return the updated `tls.Config`.\n\nThis ensures that the TLS configuration is properly set up for secure communication using HTTP/2 with gRPC.", "kitex-pkg/remote/trans/nphttp2/grpc/http_util.go-encodeTimeout": "Here is the generated code for the `encodeTimeout` function based on the provided function signature and natural language annotations:\n\n```go\nfunc encodeTimeout(t time.Duration) string {\n\tif t <= 0 {\n\t\treturn \"0n\"\n\t}\n\tif d := div(t, time.Nanosecond); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"n\"\n\t}\n\tif d := div(t, time.Microsecond); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"u\"\n\t}\n\tif d := div(t, time.Millisecond); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"m\"\n\t}\n\tif d := div(t, time.Second); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"S\"\n\t}\n\tif d := div(t, time.Minute); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"M\"\n\t}\n\t// Note that maxTimeoutValue * time.Hour > MaxInt64.\n\treturn strconv.FormatInt(div(t, time.Hour), 10) + \"H\"\n}\n```\n\nThis implementation follows a simplistic approach to encode the timeout duration as a string. It checks the duration against different time units (nanoseconds, microseconds, milliseconds, seconds, minutes, hours) and selects the appropriate unit to represent the timeout value.\n\nThe function uses the `div` helper function to perform integer division and round up the result. It ensures that the encoded timeout value does not exceed `maxTimeoutValue` for each unit.\n\nThe encoded timeout string consists of the numeric value followed by the corresponding unit suffix ('n' for nanoseconds, 'u' for microseconds, 'm' for milliseconds, 'S' for seconds, 'M' for minutes, 'H' for hours).\n\nNote: As mentioned in the natural language annotation, this implementation is simplistic and may not be the most bandwidth-efficient. There is room for improvement in terms of optimizing the encoding format and reducing the size of the encoded timeout string.", "kitex-pkg/remote/trans/netpoll/bytebuf.go-AppendBuffer": "Here is the generated code for the `AppendBuffer` function:\n\n```go\nfunc (b *netpollByteBuffer) AppendBuffer(buf remote.ByteBuffer) (err error) {\n\tif b.status&remote.BitWritable == 0 {\n\t\treturn errors.New(\"unwritable buffer, cannot support AppendBuffer\")\n\t}\n\tif buf == nil {\n\t\treturn nil\n\t}\n\n\tfor {\n\t\tp, err := buf.Next(buf.ReadableLen())\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\tif _, err := b.Write(p); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n```\n\nThis implementation does the following:\n\n1. It first checks if the original buffer `b` is writable. If not, it returns an error indicating that the buffer is unwritable and cannot support the `AppendBuffer` operation.\n\n2. If the provided buffer `buf` is nil, it returns nil since there is nothing to append.\n\n3. It enters a loop that continues until there are no more bytes to read from `buf`.\n\n4. Inside the loop, it calls `buf.Next(buf.ReadableLen())` to read all the available bytes from `buf`. If an error occurs during reading, it checks if it is an `io.EOF` error, indicating that there are no more bytes to read. If it is `io.EOF`, it breaks out of the loop. Otherwise, it returns the error.\n\n5. If the bytes are successfully read, it writes them to the original buffer `b` using `b.Write(p)`. If an error occurs during writing, it returns the error.\n\n6. After the loop ends, it means all the bytes from `buf` have been successfully appended to `b`, and it returns nil to indicate success.\n\nThis implementation assumes that the provided `buf` implements the `remote.ByteBuffer` interface and supports the `Next` and `ReadableLen` methods.", "kitex-pkg/remote/codec/util.go-SetOrCheckMethodName": "Here's the generated code for the `SetOrCheckMethodName` function based on the provided function signature and natural language annotations:\n\n```go\nfunc SetOrCheckMethodName(methodName string, message remote.Message) error {\n    switch message.MessageType() {\n    case remote.Call, remote.Oneway, remote.Stream:\n        if ink, ok := message.RPCInfo().Invocation().(rpcinfo.InvocationSetter); ok {\n            ink.SetMethodName(methodName)\n        } else {\n            return errors.New(\"the interface Invocation doesn't implement InvocationSetter\")\n        }\n    case remote.Reply, remote.Exception:\n        expectMethodName := message.RPCInfo().Invocation().MethodName()\n        if expectMethodName != methodName {\n            return remote.NewTransErrorWithMsg(remote.BadMethodName, fmt.Sprintf(\"unexpected method name, expect[%s], receive[%s]\", expectMethodName, methodName))\n        }\n    }\n    return nil\n}\n```\n\nThis function does the following:\n\n1. It checks the message type of the `message` parameter using a switch statement.\n\n2. If the message type is `remote.Call`, `remote.Oneway`, or `remote.Stream`, it means the function is being used to set the method name for the invocation:\n   - It tries to cast the invocation obtained from `message.RPCInfo().Invocation()` to the `rpcinfo.InvocationSetter` interface.\n   - If the casting is successful, it calls the `SetMethodName` method of the invocation setter with the provided `methodName`.\n   - If the casting fails, it returns an error indicating that the invocation doesn't implement the `InvocationSetter` interface.\n\n3. If the message type is `remote.Reply` or `remote.Exception`, it means the function is being used to check the method name:\n   - It retrieves the expected method name from the invocation using `message.RPCInfo().Invocation().MethodName()`.\n   - If the expected method name doesn't match the provided `methodName`, it returns a `remote.TransError` with a `remote.BadMethodName` error code and an error message indicating the mismatch.\n\n4. If the message type is not any of the above, the function simply returns `nil`, indicating that no action is needed.\n\nThis function ensures that the method name is set correctly for outgoing invocations and checks the method name for incoming replies or exceptions.", "kitex-pkg/remote/codec/thrift/thrift_data.go-MarshalThriftData": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```go\nfunc MarshalThriftData(ctx context.Context, codec remote.PayloadCodec, data interface{}) ([]byte, error) {\n\tthriftCodec, ok := codec.(thriftCodec)\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"codec is not thriftCodec\")\n\t}\n\n\t// encode with hyper codec\n\t// NOTE: to ensure hyperMarshalEnabled is inlined so split the check logic, or it may cause performance loss\n\tif thriftCodec.hyperMarshalEnabled() && hyperMarshalAvailable(data) {\n\t\treturn thriftCodec.hyperMarshalBody(data)\n\t}\n\n\t// encode with FastWrite\n\tif thriftCodec.CodecType&FastWrite != 0 {\n\t\tif msg, ok := data.(ThriftMsgFastCodec); ok {\n\t\t\tpayloadSize := msg.BLength()\n\t\t\tpayload := mcache.Malloc(payloadSize)\n\t\t\tmsg.FastWriteNocopy(payload, nil)\n\t\t\treturn payload, nil\n\t\t}\n\t}\n\n\tif err := verifyMarshalBasicThriftDataType(data); err != nil {\n\t\t// Basic can be used for disabling frugal, we need to check it\n\t\tif thriftCodec.CodecType != Basic && hyperMarshalAvailable(data) {\n\t\t\t// fallback to frugal when the generated code is using slim template\n\t\t\treturn thriftCodec.hyperMarshalBody(data)\n\t\t}\n\t\treturn nil, err\n\t}\n\n\t// fallback to old thrift way (slow)\n\ttransport := thrift.NewTMemoryBufferLen(marshalThriftBufferSize)\n\ttProt := thrift.NewTBinaryProtocol(transport, true, true)\n\tif err := marshalBasicThriftData(ctx, tProt, data); err != nil {\n\t\treturn nil, err\n\t}\n\treturn transport.Bytes(), nil\n}\n```\n\nThe `MarshalThriftData` function takes a `context.Context`, a `remote.PayloadCodec`, and the `data` to be encoded as parameters. It only encodes the data without the prepending methodName, msgType, and seqId. It allocates a new buffer and encodes the data into it.\n\nThe function first checks if the provided `codec` is of type `thriftCodec`. If not, it returns an error.\n\nThen, it tries different encoding methods based on the codec type and the data type:\n1. If hyper codec is enabled and available for the data, it uses `hyperMarshalBody` to encode the data.\n2. If FastWrite is enabled and the data implements `ThriftMsgFastCodec`, it uses `FastWriteNocopy` to encode the data.\n3. If the data type is not supported by the basic thrift encoding, it falls back to frugal encoding if available.\n4. If none of the above conditions are met, it falls back to the old thrift way (slow) using `TMemoryBuffer` and `TBinaryProtocol` to encode the data.\n\nFinally, it returns the encoded bytes or an error if any occurred during the encoding process.", "kitex-pkg/remote/codec/thrift/thrift_data.go-marshalBasicThriftData": "Here is the generated function based on the signature and natural language annotations:\n\n```go\n// marshalBasicThriftData only encodes the data (without the prepending method, msgType, seqId)\n// It uses the old thrift way which is much slower than FastCodec and Frugal\nfunc marshalBasicThriftData(ctx context.Context, tProt thrift.TProtocol, data interface{}) error {\n\tswitch v := data.(type) {\n\tcase MessageWriter:\n\t\treturn v.Write(ctx, tProt)\n\tcase MessageWriterWithContext:\n\t\treturn v.Write(ctx, tProt)\n\tdefault:\n\t\treturn fmt.Errorf(\"unexpected type %T for marshalBasicThriftData\", data)\n\t}\n}\n```\n\nThe function does the following:\n\n1. It takes in a `context.Context`, a `thrift.TProtocol`, and an `interface{}` representing the data to be encoded.\n\n2. It uses a type switch to determine the type of the `data` argument.\n\n3. If `data` implements the `MessageWriter` interface, it calls the `Write` method on `data`, passing in the `ctx` and `tProt` arguments. This allows the data to be written to the Thrift protocol using the old Thrift way.\n\n4. If `data` implements the `MessageWriterWithContext` interface, it also calls the `Write` method on `data`, passing in the `ctx` and `tProt` arguments.\n\n5. If `data` does not match any of the expected types (`MessageWriter` or `MessageWriterWithContext`), it returns an error indicating an unexpected type.\n\n6. The function returns any error that occurred during the writing process, or `nil` if the writing was successful.\n\nNote that this function only encodes the data itself, without including the prepending method name, message type, or sequence ID. It uses the old Thrift way of encoding, which is slower compared to FastCodec and Frugal.", "kitex-pkg/remote/codec/thrift/thrift_data.go-UnmarshalThriftException": "Here is the generated code for the `UnmarshalThriftException` function based on the provided signature and annotations:\n\n```go\nfunc UnmarshalThriftException(tProt thrift.TProtocol) error {\n\t_, size, err := tProt.ReadMessageBegin()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\texception := thrift.NewTApplicationException(thrift.UNKNOWN_APPLICATION_EXCEPTION, \"Unknown Exception\")\n\tif err := exception.Read(tProt); err != nil {\n\t\treturn err\n\t}\n\n\tif err := tProt.ReadMessageEnd(); err != nil {\n\t\treturn err\n\t}\n\n\tif size > 0 {\n\t\tif err := tProt.Skip(thrift.STRUCT, size); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn perrors.NewProtocolErrorWithType(perrors.RemoteOrPeerError, exception.Error())\n}\n```\n\nExplanation:\n1. The function takes a `thrift.TProtocol` as input, which can be created by wrapping a `[]byte` with `NewBinaryProtocol(remote.NewReaderBuffer(buf))`.\n2. It starts by reading the message begin using `ReadMessageBegin()` to get the message size.\n3. It creates a new `thrift.TApplicationException` with an \"Unknown Exception\" message.\n4. It reads the exception using `exception.Read(tProt)` to populate the exception details.\n5. It reads the message end using `ReadMessageEnd()`.\n6. If the message size is greater than 0, it skips the remaining bytes using `tProt.Skip(thrift.STRUCT, size)`.\n7. Finally, it returns a `perrors.ProtocolError` with the remote or peer error type and the exception message.\n\nThis function decodes a Thrift exception from the provided `thrift.TProtocol` and returns an error representing the exception.", "kitex-pkg/remote/codec/thrift/thrift_data.go-UnmarshalThriftData": "Here is the generated code for the `UnmarshalThriftData` function based on the provided function signature and natural language annotations:\n\n```go\nfunc UnmarshalThriftData(ctx context.Context, codec remote.PayloadCodec, method string, buf []byte, data interface{}) error {\n\tthriftCodec, ok := codec.(thriftCodec)\n\tif !ok {\n\t\treturn fmt.Errorf(\"invalid codec type, expected thriftCodec, got %T\", codec)\n\t}\n\n\ttProt := NewBinaryProtocol(remote.NewReaderBuffer(buf))\n\n\t// Check if the buffer contains an exception\n\tmsgType, err := tProt.ReadMessageBegin()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif msgType == EXCEPTION {\n\t\t// If the buffer contains an exception, call UnmarshalThriftException instead\n\t\treturn UnmarshalThriftException(tProt, data)\n\t}\n\ttProt.Skip(thrift.STRUCT) // Skip the struct field\n\n\t// Decode the data based on the codec type\n\tif thriftCodec.fastMessageUnmarshalEnabled() && thriftCodec.fastMessageUnmarshalAvailable(data, len(buf)) {\n\t\t// Use FastCodec for decoding\n\t\treturn thriftCodec.fastUnmarshal(tProt, data, len(buf))\n\t} else if thriftCodec.hyperMarshalEnabled() && hyperMarshalAvailable(data) {\n\t\t// Use Frugal for decoding\n\t\treturn thriftCodec.hyperUnmarshal(tProt, data, len(buf))\n\t} else if err := verifyUnmarshalBasicThriftDataType(data); err == nil {\n\t\t// Use the old thrift way for decoding\n\t\treturn unmarshalBasicThriftData(ctx, tProt, method, data)\n\t}\n\n\treturn perrors.NewProtocolErrorWithType(perrors.InvalidData, \"decode failed: \"+errDecodeMismatchMsgType.Error())\n}\n```\n\nThis implementation does the following:\n\n1. It checks if the provided `codec` is of type `thriftCodec`. If not, it returns an error.\n\n2. It creates a new `BinaryProtocol` instance using the provided `buf`.\n\n3. It checks if the buffer contains an exception by reading the message type. If the message type is `EXCEPTION`, it calls `UnmarshalThriftException` to handle the exception and returns.\n\n4. It skips the struct field in the buffer.\n\n5. It decodes the data based on the codec type:\n   - If `FastCodec` is enabled and available for the given data, it uses `fastUnmarshal` to decode the data.\n   - If `Frugal` is enabled and available for the given data, it uses `hyperUnmarshal` to decode the data.\n   - If the data type is verified to be compatible with the old thrift way, it uses `unmarshalBasicThriftData` to decode the data.\n\n6. If none of the above conditions are met, it returns a protocol error indicating a mismatch between the expected and actual message types.\n\nNote: The implementation assumes the existence of the necessary helper functions and types, such as `NewBinaryProtocol`, `remote.NewReaderBuffer`, `UnmarshalThriftException`, `verifyUnmarshalBasicThriftDataType`, `unmarshalBasicThriftData`, etc.", "kitex-pkg/remote/codec/thrift/thrift_data.go-unmarshalThriftData": "Here is the generated code for the `unmarshalThriftData` function based on the provided function signature and natural language annotations:\n\n```go\nfunc (c thriftCodec) unmarshalThriftData(ctx context.Context, tProt *BinaryProtocol, method string, data interface{}, dataLen int) error {\n\t// Check if fast message unmarshal is enabled and available for the given data type\n\tif c.fastMessageUnmarshalEnabled() && c.fastMessageUnmarshalAvailable(data, dataLen) {\n\t\treturn c.fastUnmarshal(tProt, data, dataLen)\n\t}\n\n\t// Check if hyper unmarshal is available for the given data type\n\tif c.hyperMarshalEnabled() && hyperMarshalAvailable(data) {\n\t\treturn c.hyperUnmarshal(tProt, data, dataLen)\n\t}\n\n\t// Verify if the data type can be unmarshaled using the old thrift way\n\tif err := verifyUnmarshalBasicThriftDataType(data); err != nil {\n\t\treturn err\n\t}\n\n\t// Fallback to the old thrift way (slow)\n\tif err := decodeBasicThriftData(ctx, tProt, method, data); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n```\n\nThis function first checks if fast message unmarshal is enabled and available for the given data type. If so, it calls the `fastUnmarshal` function to decode the data using the fast approach.\n\nIf fast message unmarshal is not available, it checks if hyper unmarshal is available for the given data type. If so, it calls the `hyperUnmarshal` function to decode the data using the hyper approach.\n\nIf neither fast message unmarshal nor hyper unmarshal is available, it verifies if the data type can be unmarshaled using the old thrift way by calling `verifyUnmarshalBasicThriftDataType`. If the verification passes, it falls back to the old thrift way by calling `decodeBasicThriftData` to decode the data.\n\nIf any error occurs during the process, it returns the corresponding error.\n\nNote that the `method` parameter is only used for generic calls and is passed to the `decodeBasicThriftData` function when using the old thrift way.", "kitex-pkg/remote/codec/thrift/thrift_data.go-decodeBasicThriftData": "Here's the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc decodeBasicThriftData(ctx context.Context, tProt thrift.TProtocol, method string, data interface{}) error {\n\tif err := verifyUnmarshalBasicThriftDataType(data); err != nil {\n\t\treturn err\n\t}\n\n\tswitch msg := data.(type) {\n\tcase MessageReader:\n\t\tif err := msg.Read(ctx, tProt); err != nil {\n\t\t\treturn err\n\t\t}\n\tcase MessageReaderWithMethodWithContext:\n\t\tif err := msg.ReadWithMethodWithContext(ctx, method, tProt); err != nil {\n\t\t\treturn err\n\t\t}\n\tdefault:\n\t\treturn fmt.Errorf(\"invalid message type for decodeBasicThriftData: %T\", data)\n\t}\n\n\treturn nil\n}\n```\n\nThis function does the following:\n\n1. It first verifies if the `data` parameter is of a valid type that can be unmarshaled using the old thrift way by calling the `verifyUnmarshalBasicThriftDataType` function. If the type is not valid, it returns an error.\n\n2. It then uses a type switch to determine the specific type of `data`.\n\n3. If `data` implements the `MessageReader` interface, it calls the `Read` method of `data`, passing the `ctx` and `tProt` parameters. This method is responsible for reading the thrift message using the provided protocol.\n\n4. If `data` implements the `MessageReaderWithMethodWithContext` interface, it calls the `ReadWithMethodWithContext` method of `data`, passing the `ctx`, `method`, and `tProt` parameters. This method is responsible for reading the thrift message using the provided protocol and method name.\n\n5. If `data` is of any other type, it returns an error indicating an invalid message type.\n\n6. Finally, if no errors occurred during the decoding process, it returns `nil`.\n\nNote: This function assumes the existence of the `MessageReader` and `MessageReaderWithMethodWithContext` interfaces, which are not defined in the provided code snippet. Make sure to have the necessary type definitions for these interfaces in your codebase.", "kitex-pkg/remote/remotecli/conn_wrapper.go-GetConn": "Here is the generated code for the `GetConn` function based on the provided function signature and natural language annotations:\n\n```go\nfunc (cm *ConnWrapper) GetConn(ctx context.Context, d remote.Dialer, ri rpcinfo.RPCInfo) (net.Conn, error) {\n\ttimeout := ri.Config().ConnectTimeout()\n\tif cm.connPool != nil {\n\t\tconn, err := cm.getConnWithPool(ctx, cm.connPool, d, timeout, ri)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcm.conn = conn\n\t\treturn conn, nil\n\t}\n\n\tconn, err := cm.getConnWithDialer(ctx, d, timeout, ri)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tcm.conn = conn\n\treturn conn, nil\n}\n```\n\nThe `GetConn` function does the following:\n\n1. It retrieves the `ConnectTimeout` from the `RPCInfo` configuration.\n\n2. If `cm.connPool` is not nil, it calls the `getConnWithPool` method to obtain a connection from the connection pool using the provided `Dialer`, `timeout`, and `RPCInfo`. If an error occurs, it returns nil and the error.\n\n3. If `cm.connPool` is nil, it calls the `getConnWithDialer` method to establish a new connection using the provided `Dialer`, `timeout`, and `RPCInfo`. If an error occurs, it returns nil and the error.\n\n4. If a connection is successfully obtained, it assigns the connection to `cm.conn` and returns the connection and nil error.\n\nThe function utilizes the `getConnWithPool` and `getConnWithDialer` helper methods to handle the connection retrieval logic based on whether a connection pool is available or not.", "kitex-pkg/remote/connpool/long_pool.go-Evict": "Here is the generated code for the `Evict` function:\n\n```go\nfunc (p *pool) Evict() (evicted int) {\n\tp.mu.Lock()\n\tdefer p.mu.Unlock()\n\n\t// Iterate over the idleList and evict expired connections\n\tfor i := 0; i < len(p.idleList); {\n\t\tconn := p.idleList[i]\n\t\tif conn.Expired() {\n\t\t\t// Connection has expired, close it and remove from the idleList\n\t\t\tconn.Close()\n\t\t\tp.idleList = append(p.idleList[:i], p.idleList[i+1:]...)\n\t\t\tevicted++\n\t\t} else {\n\t\t\t// Connection is still active, move to the next one\n\t\t\ti++\n\t\t}\n\t}\n\n\treturn evicted\n}\n```\n\nThis implementation does the following:\n\n1. It acquires a write lock on the pool using `p.mu.Lock()` to ensure exclusive access to the `idleList`. The lock is released using `defer p.mu.Unlock()` at the end of the function.\n\n2. It iterates over the `idleList` using a `for` loop with an index variable `i`.\n\n3. For each connection in the `idleList`, it checks if the connection has expired by calling the `Expired()` method on the connection.\n\n4. If the connection has expired:\n   - It closes the connection by calling `conn.Close()`.\n   - It removes the connection from the `idleList` by using `append(p.idleList[:i], p.idleList[i+1:]...)`, which creates a new slice excluding the expired connection.\n   - It increments the `evicted` counter to keep track of the number of connections evicted.\n\n5. If the connection is still active, it moves to the next connection by incrementing the index `i`.\n\n6. Finally, it returns the number of connections evicted.\n\nThis implementation efficiently evicts expired connections from the pool while keeping the active connections intact. The function returns the number of connections that were evicted during the process.", "kitex-pkg/loadbalance/lbcache/cache.go-NewBalancerFactory": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc NewBalancerFactory(resolver discovery.Resolver, balancer loadbalance.Loadbalancer, opts Options) *BalancerFactory {\n\topts.check()\n\tkey := cacheKey(resolver.Name(), balancer.Name(), opts)\n\tval, ok := balancerFactories.Load(key)\n\tif ok {\n\t\treturn val.(*BalancerFactory)\n\t}\n\tval, _, _ = balancerFactoriesSfg.Do(key, func() (interface{}, error) {\n\t\tbf := newBalancerFactory(resolver, balancer, opts)\n\t\tif opts.Cacheable {\n\t\t\tbalancerFactories.Store(key, bf)\n\t\t}\n\t\tif opts.DiagnosisService != nil {\n\t\t\topts.DiagnosisService.RegisterProbeFunc(diagnosis.LoadBalanceFactoryKey, Dump)\n\t\t}\n\t\treturn bf, nil\n\t})\n\treturn val.(*BalancerFactory)\n}\n```\n\nThe `NewBalancerFactory` function does the following:\n\n1. It checks the provided `opts` using the `check` method to ensure that the `RefreshInterval` and `ExpireInterval` are set to their default values if they are not provided or are invalid.\n\n2. It generates a cache key using the `cacheKey` function, which combines the resolver name, balancer name, and options.\n\n3. It tries to load an existing `BalancerFactory` from the `balancerFactories` sync.Map using the generated cache key. If found, it returns the existing factory.\n\n4. If the factory is not found in the cache, it uses the `balancerFactoriesSfg` singleflight group to ensure that only one goroutine creates a new factory for the given key.\n\n5. Inside the singleflight group, it calls the `newBalancerFactory` function to create a new `BalancerFactory` instance with the provided resolver, balancer, and options.\n\n6. If the `Cacheable` option is set to true, it stores the newly created factory in the `balancerFactories` cache using the generated cache key.\n\n7. If the `DiagnosisService` option is provided, it registers the `Dump` function as a probe function for diagnosis using the `diagnosis.LoadBalanceFactoryKey`.\n\n8. Finally, it returns the created or loaded `BalancerFactory` instance.\n\nThis function ensures that only one `BalancerFactory` instance is created for the same combination of resolver, balancer, and options, and it caches the factory for reuse if the `Cacheable` option is set to true. It also integrates with the diagnosis service if provided.", "kitex-pkg/stats/event.go-DefineNewEvent": "Here is the generated function based on the provided signature and annotation:\n\n```go\nfunc DefineNewEvent(name string, level Level) (Event, error) {\n\tif atomic.LoadInt32(&inited) == 1 {\n\t\treturn nil, ErrNotAllowed\n\t}\n\n\tlock.Lock()\n\tdefer lock.Unlock()\n\n\tif _, ok := userDefined[name]; ok {\n\t\treturn nil, ErrDuplicated\n\t}\n\n\tidx := EventIndex(maxEventNum)\n\tmaxEventNum++\n\n\te := newEvent(idx, level)\n\tuserDefined[name] = e\n\n\treturn e, nil\n}\n```\n\nThe function does the following:\n\n1. It first checks if the `inited` flag is set to 1 using `atomic.LoadInt32`. If it is, it means the initialization is already finished, and no new events can be defined. In this case, it returns `nil` and the `ErrNotAllowed` error.\n\n2. It acquires a write lock using `lock.Lock()` to ensure exclusive access to the `userDefined` map and `maxEventNum` variable. The lock is released using `defer lock.Unlock()` at the end of the function.\n\n3. It checks if an event with the given `name` already exists in the `userDefined` map. If it does, it means the event is duplicated, and the function returns `nil` and the `ErrDuplicated` error.\n\n4. If the event doesn't exist, it generates a new `EventIndex` by assigning the current value of `maxEventNum` to `idx` and increments `maxEventNum` by 1.\n\n5. It creates a new `event` instance using the `newEvent` function, passing the generated `idx` and the provided `level`.\n\n6. It adds the new event to the `userDefined` map using the `name` as the key and the created event as the value.\n\n7. Finally, it returns the newly created event and a `nil` error to indicate success.\n\nThis function allows users to define new events during program initialization by providing a unique name and a level for the event. It ensures that events are not duplicated and cannot be defined after the initialization is finished.", "kitex-pkg/generic/thriftidl_provider.go-NewThriftFileProviderWithDynamicGo": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc NewThriftFileProviderWithDynamicGo(path string, includeDirs ...string) (DescriptorProvider, error) {\n\tp := &thriftFileProvider{\n\t\tsvcs: make(chan *descriptor.ServiceDescriptor, 1), // unblock with buffered channel\n\t\topts: &ProviderOption{DynamicGoEnabled: true},\n\t}\n\tsvc, err := newServiceDescriptorFromPath(path, includeDirs...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create dynamicgo service descriptor\n\tdOpts := dthrift.Options{EnableThriftBase: true}\n\tdsvc, err := dOpts.NewDescritorFromPath(context.Background(), path, includeDirs...)\n\tif err != nil {\n\t\tklog.CtxWarnf(context.Background(), \"KITEX: failed to get dynamicgo service descriptor, fall back to the original way, error=%s\", err)\n\t\tp.opts.DynamicGoEnabled = false\n\t} else {\n\t\tsvc.DynamicGoDsc = dsvc\n\t}\n\n\tp.svcs <- svc\n\treturn p, nil\n}\n```\n\nThe function does the following:\n\n1. Creates a new `thriftFileProvider` instance with a buffered channel for service descriptors and enables the `DynamicGoEnabled` option.\n\n2. Calls `newServiceDescriptorFromPath` to create a service descriptor from the given Thrift IDL file path and include directories.\n\n3. Creates a dynamicgo service descriptor using `dthrift.Options` and `NewDescritorFromPath`. If it fails, it logs a warning and disables the `DynamicGoEnabled` option. Otherwise, it sets the `DynamicGoDsc` field of the service descriptor to the dynamicgo descriptor.\n\n4. Sends the service descriptor to the `svcs` channel.\n\n5. Returns the `thriftFileProvider` instance and any error encountered.\n\nThis function provides a way to create a `DescriptorProvider` with dynamicgo support by parsing a Thrift IDL file and its include directories.", "kitex-pkg/generic/thriftidl_provider.go-NewThriftContentWithAbsIncludePathProviderWithDynamicGo": "Here is the generated code for the `NewThriftContentWithAbsIncludePathProviderWithDynamicGo` function:\n\n```go\nfunc NewThriftContentWithAbsIncludePathProviderWithDynamicGo(mainIDLPath string, includes map[string]string) (*ThriftContentWithAbsIncludePathProvider, error) {\n\tmainIDLContent, ok := includes[mainIDLPath]\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"miss main IDL content for main IDL path: %s\", mainIDLPath)\n\t}\n\t\n\tp := &ThriftContentWithAbsIncludePathProvider{\n\t\tsvcs: make(chan *descriptor.ServiceDescriptor, 1), // unblock with buffered channel\n\t\topts: &ProviderOption{DynamicGoEnabled: true},\n\t}\n\t\n\tsvc, err := newServiceDescriptorFromContent(mainIDLPath, mainIDLContent, includes, true)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tp.newDynamicGoDsc(svc, mainIDLPath, mainIDLContent, includes)\n\n\tp.svcs <- svc\n\treturn p, nil\n}\n```\n\nThis function creates a new `ThriftContentWithAbsIncludePathProvider` with DynamicGo enabled. Here's how it works:\n\n1. It retrieves the main IDL content from the `includes` map using the `mainIDLPath` as the key. If the content is not found, it returns an error.\n\n2. It creates a new `ThriftContentWithAbsIncludePathProvider` instance `p` with a buffered channel of size 1 for the service descriptors and sets the `DynamicGoEnabled` option to `true`.\n\n3. It calls the `newServiceDescriptorFromContent` function to create a new `ServiceDescriptor` from the main IDL content and the includes map, passing `true` for the `isAbsIncludePath` parameter.\n\n4. If there is an error creating the service descriptor, it returns the error.\n\n5. It calls the `newDynamicGoDsc` method of the provider to create a new DynamicGo descriptor from the service descriptor, main IDL path, main IDL content, and includes map.\n\n6. It sends the service descriptor to the `svcs` channel of the provider.\n\n7. Finally, it returns the provider instance and a `nil` error.\n\nThis function provides a convenient way to create a `ThriftContentWithAbsIncludePathProvider` with DynamicGo enabled, given the main IDL path and a map of includes.", "kitex-pkg/generic/generic.go-MapThriftGeneric": "Here is the generated function based on the function signature and natural language annotations:\n\n```go\nfunc MapThriftGeneric(p DescriptorProvider) (Generic, error) {\n\tcodec, err := newMapThriftCodec(p, thriftCodec)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &mapThriftGeneric{\n\t\tcodec: codec,\n\t}, nil\n}\n```\n\nExplanation:\n- The function `MapThriftGeneric` takes a `DescriptorProvider` parameter `p` and returns a `Generic` interface and an `error`.\n- It creates a new `mapThriftCodec` using the provided `DescriptorProvider` and the `thriftCodec` variable.\n- If there is an error creating the codec, it returns `nil` and the error.\n- If the codec is created successfully, it returns a new `mapThriftGeneric` instance with the created codec.\n- The `mapThriftGeneric` struct implements the `Generic` interface.\n- By default, the Base64 codec for binary fields is disabled, but it can be enabled using `SetBinaryWithBase64` function.\n- By default, string values are returned for binary fields, but it can be changed to `[]byte` using `SetBinaryWithByteSlice` function.", "kitex-pkg/generic/generic.go-JSONThriftGeneric": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```go\nfunc JSONThriftGeneric(p DescriptorProvider, opts ...Option) (Generic, error) {\n\tcodec, err := newJSONThriftCodec(p, thriftCodec, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\t// Base64 codec for binary field is enabled by default\n\tcodec.binaryWithBase64 = true\n\tif codec.dynamicgoEnabled {\n\t\tcodec.convOpts.NoBase64Binary = false\n\t\tcodec.convOptsWithThriftBase.NoBase64Binary = false\n\t\tcodec.convOptsWithException.NoBase64Binary = false\n\t}\n\treturn &jsonThriftGeneric{\n\t\tcodec: codec,\n\t}, nil\n}\n```\n\nThe function does the following:\n\n1. It calls `newJSONThriftCodec` with the provided `DescriptorProvider` and `thriftCodec`, along with any additional options passed through `opts`. This creates a new `jsonThriftCodec` instance.\n\n2. If there is an error creating the codec, it returns `nil` and the error.\n\n3. It sets the `binaryWithBase64` field of the codec to `true`, enabling Base64 encoding for binary fields by default.\n\n4. If the codec has `dynamicgoEnabled` set to `true`, it sets the `NoBase64Binary` field of the codec's `convOpts`, `convOptsWithThriftBase`, and `convOptsWithException` to `false`, ensuring that Base64 encoding is used for binary fields.\n\n5. Finally, it returns a new `jsonThriftGeneric` instance with the created codec.\n\nThe function also includes the natural language annotations as comments to provide additional context and usage examples.", "kitex-pkg/generic/generic.go-JSONPbGeneric": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc JSONPbGeneric(p PbDescriptorProviderDynamicGo, opts ...Option) (Generic, error) {\n\toptions := &options{\n\t\tdynamicgo: true,\n\t}\n\tfor _, opt := range opts {\n\t\topt(options)\n\t}\n\n\tcodec, err := newJSONPbCodec(p, pbCodec, options)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &jsonPbGeneric{\n\t\tcodec: codec,\n\t}, nil\n}\n```\n\nExplanation:\n- The function takes a `PbDescriptorProviderDynamicGo` parameter `p` and variadic `Option` parameters `opts`.\n- It creates an `options` struct with the default value of `dynamicgo` set to `true`.\n- It iterates over the provided `opts` and applies each option to the `options` struct.\n- It creates a new `jsonPbCodec` using the `newJSONPbCodec` function, passing the `p`, `pbCodec`, and `options` as arguments.\n- If there is an error creating the codec, it returns `nil` and the error.\n- If the codec is created successfully, it returns a new `jsonPbGeneric` struct with the created codec.\n\nThe function follows the provided signature and uses the `dynamicgo` package for JSON to protobuf conversion by default, as mentioned in the natural language annotations.", "kitex-pkg/generic/thrift/write.go-writeStruct": "Here is the generated code for the `writeStruct` function based on the function signature and natural language annotations:\n\n```go\nfunc writeStruct(ctx context.Context, val interface{}, out thrift.TProtocol, t *descriptor.TypeDescriptor, opt *writerOption) error {\n\tif err := out.WriteStructBegin(t.Struct.Name); err != nil {\n\t\treturn err\n\t}\n\n\tgetter := mapGetter\n\tif _, ok := val.(proto.Message); ok {\n\t\tgetter = pbGetter\n\t}\n\n\tfor _, field := range t.Struct.Fields {\n\t\tif field.IsException {\n\t\t\t// generic server ignore the exception, because no description for exception\n\t\t\t// generic handler just return error\n\t\t\tcontinue\n\t\t}\n\n\t\tv, ok := getter(val, field)\n\t\tif !ok {\n\t\t\tif field.Required {\n\t\t\t\treturn fmt.Errorf(\"required field '%s' not set\", field.Name)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif err := out.WriteFieldBegin(field.Name, field.Type.Type.ToThriftTType(), int16(field.ID)); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\twriter, err := nextWriter(v, field.Type, opt)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"nextWriter of field[%s] error %w\", field.Name, err)\n\t\t}\n\n\t\tif err := writer(ctx, v, out, field.Type, opt); err != nil {\n\t\t\treturn fmt.Errorf(\"writer of field[%s] error %w\", field.Name, err)\n\t\t}\n\n\t\tif err := out.WriteFieldEnd(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif err := out.WriteFieldStop(); err != nil {\n\t\treturn err\n\t}\n\treturn out.WriteStructEnd()\n}\n```\n\nThe `writeStruct` function iterates over the fields of the struct using the `TypeDescriptor`. It checks if each field is required and retrieves the field value using the appropriate getter function (`mapGetter` for maps and `pbGetter` for protocol buffer messages).\n\nIf a required field is not set, an error is returned. If a field is present, it writes the field begin, calls the appropriate writer function (`nextWriter`) for the field value, and writes the field end.\n\nFinally, it writes the field stop and struct end markers.", "kitex-pkg/generic/descriptor/tree.go-addRoute": "Here is the generated code for the `addRoute` function based on the function signature and natural language annotations:\n\n```go\nfunc (n *node) addRoute(path string, function *FunctionDescriptor) {\n\tcheckPathValid(path)\n\n\tpnames := make([]string, 0, countParams(path))\n\tppath := path\n\tfor i, l := 0, len(path); i < l; i++ {\n\t\tif path[i] == ':' {\n\t\t\tj := i + 1\n\n\t\t\tr := strings.IndexByte(path[j:], '/')\n\t\t\tif r == -1 {\n\t\t\t\tr = l - j\n\t\t\t}\n\t\t\tpnames = append(pnames, path[j:j+r])\n\n\t\t\tfor ; i < j+r; i++ {\n\t\t\t\tpath = path[:i] + path[i+1:]\n\t\t\t\tl--\n\t\t\t\ti--\n\t\t\t}\n\n\t\t\tif len(pnames) == 1 {\n\t\t\t\t// single param\n\t\t\t\tn.insert(path, function, param, ppath, pnames)\n\t\t\t\treturn\n\t\t\t}\n\t\t} else if path[i] == '*' {\n\t\t\tpnames = append(pnames, \"*\")\n\t\t\tn.insert(path[:i], function, catchAll, ppath, pnames)\n\t\t\treturn\n\t\t}\n\t}\n\n\tn.insert(path, function, static, ppath, pnames)\n}\n```\n\nExplanation:\n1. The function first checks if the provided path is valid by calling `checkPathValid(path)`.\n2. It initializes `pnames` as an empty slice to store the parameter names and `ppath` as the original path.\n3. It iterates over each character in the path:\n   - If the character is ':', it means a parameter is found. It extracts the parameter name and removes it from the path. If there is only a single parameter, it calls `n.insert()` with the modified path, function, `param` node type, original path, and parameter names, and then returns.\n   - If the character is '*', it means a catch-all parameter is found. It appends \"*\" to `pnames`, calls `n.insert()` with the path up to the '*' character, function, `catchAll` node type, original path, and parameter names, and then returns.\n4. If no parameters or catch-all are found, it calls `n.insert()` with the original path, function, `static` node type, original path, and an empty `pnames` slice.\n\nThe `addRoute` function adds a new route to the tree by inserting nodes based on the provided path and function. It handles static paths, paths with parameters (denoted by ':'), and catch-all paths (denoted by '*'). The function extracts the parameter names and modifies the path accordingly before calling the `insert` function to add the nodes to the tree.\n\nNote: The function assumes that the `checkPathValid`, `countParams`, and `insert` functions are defined elsewhere in the code.", "kitex-pkg/mem/span.go-NewSpanCache": "Here is the generated code for the `NewSpanCache` function based on the given function signature and natural language annotations:\n\n```go\nfunc NewSpanCache(spanSize int) *spanCache {\n\tc := new(spanCache)\n\tfor i := 0; i < spanCacheSize; i++ {\n\t\tsize := minSpanObject << i\n\t\tif size > spanSize {\n\t\t\tbreak\n\t\t}\n\t\tc.spans[i] = NewSpan(size)\n\t}\n\treturn c\n}\n```\n\nExplanation:\n1. We create a new `spanCache` instance using `new(spanCache)`.\n2. We iterate over the `spanCacheSize` (10 in this case) to create spans for each size level.\n3. For each iteration, we calculate the size of the span using `minSpanObject << i`, which doubles the size for each level starting from `minSpanObject` (128 bytes).\n4. If the calculated size is greater than the given `spanSize`, we break the loop since we don't need to create spans larger than the specified size.\n5. For each valid size level, we create a new span using `NewSpan(size)` and assign it to the corresponding index in the `spans` array of the `spanCache`.\n6. Finally, we return the newly created `spanCache` instance.\n\nThis function initializes a `spanCache` with spans of different size levels up to the given `spanSize`. Each span is used to allocate a binary of a specific size level, allowing for efficient memory allocation and management.", "kitex-pkg/profiler/profiler.go-Pause": "Here is the generated code for the `Pause()` function:\n\n```go\nfunc (p *profiler) Pause() {\n\tif p.State() == statePaused {\n\t\treturn\n\t}\n\t// stateRunning => statePausing => statePaused\n\tp.stateChange(stateRunning, statePausing)\n\tp.stopProfile()\n\tp.stateChange(statePausing, statePaused)\n}\n```\n\nThe `Pause()` function does the following:\n\n1. It checks if the current state of the profiler is already `statePaused`. If so, it returns immediately since the profiler is already paused.\n\n2. If the profiler is not paused, it initiates a state change from `stateRunning` to `statePausing` using the `stateChange()` method. This ensures that the profiler is in the running state before attempting to pause it.\n\n3. It calls the `stopProfile()` method to stop the CPU profiling.\n\n4. After stopping the profiling, it changes the state from `statePausing` to `statePaused` using the `stateChange()` method. This indicates that the profiler has successfully transitioned to the paused state.\n\nBy the time the `Pause()` function returns, the profiler is guaranteed to be in the paused state.", "kitex-pkg/profiler/profiler.go-Resume": "Here is the generated code for the `Resume` method of the `profiler` struct:\n\n```go\nfunc (p *profiler) Resume() {\n\tif p.State() == stateRunning {\n\t\treturn\n\t}\n\t// statePaused => stateResuming\n\tp.stateChange(statePaused, stateResuming)\n\t// stateResuming => stateRunning\n\tp.stateChange(stateResuming, stateRunning)\n}\n```\n\nThis implementation does the following:\n\n1. It first checks if the current state of the profiler is already `stateRunning`. If so, it returns immediately since the profiler is already running.\n\n2. If the profiler is not running, it initiates a state change from `statePaused` to `stateResuming` by calling `p.stateChange(statePaused, stateResuming)`. This ensures that the profiler transitions from the paused state to the resuming state.\n\n3. After the state change to `stateResuming` is complete, it initiates another state change from `stateResuming` to `stateRunning` by calling `p.stateChange(stateResuming, stateRunning)`. This ensures that the profiler transitions from the resuming state to the running state.\n\n4. Once the state changes are complete, the `Resume` method returns, indicating that the profiler has been successfully resumed and is now in the running state.\n\nThe `stateChange` method is used to handle the state transitions and ensure that the profiler's state is properly synchronized and updated.", "kitex-pkg/acl/acl.go-NewACLMiddleware": "Here is the generated code for the `NewACLMiddleware` function:\n\n```go\nfunc NewACLMiddleware(rules []RejectFunc) endpoint.Middleware {\n\treturn func(next endpoint.Endpoint) endpoint.Endpoint {\n\t\treturn func(ctx context.Context, request, response interface{}) error {\n\t\t\tfor _, rule := range rules {\n\t\t\t\tif reason := rule(ctx, request); reason != nil {\n\t\t\t\t\treturn kerrors.ErrACL.WithCause(reason)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn next(ctx, request, response)\n\t\t}\n\t}\n}\n```\n\nThe `NewACLMiddleware` function takes a slice of `RejectFunc` as input and returns an `endpoint.Middleware`.\n\nThe returned middleware function wraps the next endpoint and applies the provided reject rules in sequence. It iterates over each rule and calls it with the current context and request. If any rule returns a non-nil reason, indicating that the request should be rejected, the middleware returns an `ErrACL` error with the reason as the cause.\n\nIf none of the rules reject the request, the middleware invokes the next endpoint with the current context, request, and response.\n\nThis middleware allows you to define custom reject functions to implement access control logic based on the context and request information.", "kitex-client/context_middleware.go-WithContextMiddlewares": "Here is the generated code for the `WithContextMiddlewares` function based on the provided function signature and natural language annotations:\n\n```go\nfunc WithContextMiddlewares(ctx context.Context, mws ...endpoint.Middleware) context.Context {\n\tif len(mws) == 0 {\n\t\treturn ctx\n\t}\n\n\tmw := endpoint.Chain(mws...)\n\n\tif prevMW, ok := ctx.Value(ctxMWChainKey{}).(endpoint.Middleware); ok {\n\t\tmw = endpoint.Chain(prevMW, mw)\n\t}\n\n\treturn context.WithValue(ctx, ctxMWChainKey{}, mw)\n}\n```\n\nExplanation:\n1. The function takes a `context.Context` and a variadic parameter `mws` of type `endpoint.Middleware`.\n2. It first checks if the `mws` slice is empty. If it is, it means no middlewares are provided, so it returns the original `ctx` unchanged.\n3. If middlewares are provided, it chains them together using `endpoint.Chain(mws...)` to create a single middleware `mw`.\n4. It then checks if there is already a middleware stored in the `ctx` under the key `ctxMWChainKey{}`. If there is, it retrieves the previous middleware `prevMW` and chains it with the new middleware `mw` using `endpoint.Chain(prevMW, mw)`.\n5. Finally, it returns a new `context.Context` with the chained middleware stored under the key `ctxMWChainKey{}` using `context.WithValue(ctx, ctxMWChainKey{}, mw)`.\n\nThis implementation ensures that the provided middlewares are added to the current context, and if there are any existing middlewares in the context, they are chained together with the new middlewares. The resulting context can be passed to the client, and the middlewares will be executed in the order they were added.", "kitex-client/stream.go-RecvMsg": "Here is the generated code for the `RecvMsg` function:\n\n```go\nfunc (s *stream) RecvMsg(m interface{}) (err error) {\n    err = s.recvEndpoint(s.stream, m)\n    if err != nil {\n        s.DoFinish(err)\n    }\n    return err\n}\n```", "kitex-client/stream.go-SendMsg": "Here is the generated code for the `SendMsg` function:\n\n```go\nfunc (s *stream) SendMsg(m interface{}) (err error) {\n\terr = s.sendEndpoint(s.stream, m)\n\tif err != nil {\n\t\ts.DoFinish(err)\n\t\treturn err\n\t}\n\treturn nil\n}\n```", "kitex-client/stream.go-DoFinish": "Here is the generated code for the `DoFinish` method:\n\n```go\nfunc (s *stream) DoFinish(err error) {\n\tif atomic.CompareAndSwapUint32(&s.finished, 0, 1) {\n\t\tdefer s.scm.ReleaseConn()\n\n\t\ts.kc.opt.TracerCtl.DoFinish(s.Context(), s.ri, err)\n\n\t\tif isRPCError(err) {\n\t\t\ts.ri.SetError(err)\n\t\t}\n\n\t\tif s.streamingMode == serviceinfo.StreamingRequest {\n\t\t\ts.sendEndpoint(s.stream, nil)\n\t\t} else if s.streamingMode == serviceinfo.StreamingResponse {\n\t\t\ts.recvEndpoint(s.stream, nil)\n\t\t}\n\t}\n}\n```\n\nThis implementation does the following:\n\n1. It uses `atomic.CompareAndSwapUint32` to ensure that `DoFinish` is only executed once. If `finished` is already set to 1, it means `DoFinish` has been called before, so it returns immediately.\n\n2. It defers the release of the connection using `s.scm.ReleaseConn()` to ensure that the connection is properly released after the method finishes.\n\n3. It calls `s.kc.opt.TracerCtl.DoFinish` to record the end of the stream in the tracer.\n\n4. It checks if the error is an RPC error using the `isRPCError` function. If it is, it sets the error in the `RPCInfo` using `s.ri.SetError(err)`.\n\n5. Depending on the streaming mode (`s.streamingMode`), it calls either `s.sendEndpoint` or `s.recvEndpoint` with `nil` as the second argument to indicate the end of the stream.\n\nThis implementation ensures that the end of the stream is properly recorded, the connection is released, and any necessary cleanup is performed.", "kitex-client/client.go-NewClient": "Here is the generated code for the `NewClient` function based on the function signature and natural language annotations:\n\n```go\nfunc NewClient(svcInfo *serviceinfo.ServiceInfo, opts ...Option) (Client, error) {\n\tkc := &kClient{\n\t\tsvcInfo: svcInfo,\n\t\topt:     client.NewOptions(opts),\n\t}\n\terr := kc.init()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tkfc := &kcFinalizerClient{kClient: kc}\n\truntime.SetFinalizer(kfc, func(kfc *kcFinalizerClient) {\n\t\tif kfc != nil && kfc.kClient != nil {\n\t\t\t_ = kfc.kClient.Close()\n\t\t}\n\t})\n\treturn kfc, nil\n}\n```\n\nThe `NewClient` function does the following:\n\n1. It creates a new `kClient` instance `kc` with the provided `svcInfo` and `opts`.\n\n2. It calls the `init` method on `kc` to initialize the client. If an error occurs during initialization, it returns `nil` and the error.\n\n3. It creates a new `kcFinalizerClient` instance `kfc` with the `kClient` field set to `kc`.\n\n4. It sets a finalizer on `kfc` using `runtime.SetFinalizer`. The finalizer function checks if `kfc` and its `kClient` field are not `nil`, and if so, it calls the `Close` method on `kClient` to clean up resources when the client is no longer in use.\n\n5. Finally, it returns the `kfc` instance (which implements the `Client` interface) and a `nil` error.\n\nThis implementation ensures that the client is properly initialized and sets up a finalizer to automatically close the client when it is no longer needed, helping to prevent resource leaks.", "kitex-client/middlewares.go-newResolveMWBuilder": "Here is the generated code for the `newResolveMWBuilder` function based on the provided function signature and natural language annotations:\n\n```go\nfunc newResolveMWBuilder(lbf *lbcache.BalancerFactory) endpoint.MiddlewareBuilder {\n\treturn func(options *ClientOptions) endpoint.Middleware {\n\t\treturn func(next endpoint.Endpoint) endpoint.Endpoint {\n\t\t\treturn func(ctx context.Context, request, response interface{}) error {\n\t\t\t\tvar err error\n\t\t\t\tvar retryCount int\n\t\t\t\tvar selectedInstance discovery.Instance\n\n\t\t\t\tfor retryCount < maxRetry {\n\t\t\t\t\tselectedInstance, err = lbf.Get(ctx).Select(ctx, options.Resolver.Target())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tif retryable(err) {\n\t\t\t\t\t\t\tretryCount++\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\n\t\t\t\t\tctx = context.WithValue(ctx, endpoint.CtxEventbusKey, options.Bus)\n\t\t\t\t\tctx = context.WithValue(ctx, endpoint.CtxEventQueueKey, options.Events)\n\t\t\t\t\tctx = rpcinfo.NewCtxWithRPCInfo(ctx, rpcinfo.NewRPCInfo(\n\t\t\t\t\t\trpcinfo.WithTo(selectedInstance.Address()),\n\t\t\t\t\t\trpcinfo.WithToCluster(options.Resolver.Target()),\n\t\t\t\t\t))\n\n\t\t\t\t\terr = next(ctx, request, response)\n\t\t\t\t\tif err == nil {\n\t\t\t\t\t\treturn nil\n\t\t\t\t\t}\n\n\t\t\t\t\tif retryable(err) {\n\t\t\t\t\t\tretryCount++\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\treturn kerrors.ErrGetConnection\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\nThis middleware function does the following:\n\n1. It takes a `lbcache.BalancerFactory` as input to create a load balancer for selecting instances.\n\n2. It returns an `endpoint.MiddlewareBuilder` function that takes `ClientOptions` as input and returns an `endpoint.Middleware`.\n\n3. The middleware function wraps the next endpoint and performs the following steps:\n   - It initializes variables for retry count and selected instance.\n   - It enters a loop that retries up to `maxRetry` times.\n   - Inside the loop, it selects an instance using the load balancer and the resolver's target.\n   - If a retryable error occurs during instance selection, it increments the retry count and continues the loop.\n   - If a non-retryable error occurs, it returns the error.\n   - If an instance is successfully selected, it updates the context with the event bus, event queue, and RPC information.\n   - It invokes the next endpoint with the updated context.\n   - If the next endpoint returns no error, it returns nil.\n   - If the next endpoint returns a retryable error, it increments the retry count and continues the loop.\n   - If the next endpoint returns a non-retryable error, it returns the error.\n   - If the loop reaches the maximum retry count, it returns `kerrors.ErrGetConnection`.\n\nThis middleware ensures that an appropriate instance is selected based on the resolver and load balancer, and it retries the request if a retryable error is encountered, up to a maximum number of retries.", "kitex-client/middlewares.go-DefaultClientErrorHandler": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc DefaultClientErrorHandler(ctx context.Context, err error) error {\n\tif errors.Is(err, thrift.ErrTransportClosed) {\n\t\t// Wrap thrift transport closed error\n\t\treturn kerrors.ErrTransportClosed\n\t}\n\tif errors.Is(err, thrift.ErrAppException) {\n\t\t// Wrap thrift application exception\n\t\treturn kerrors.ErrAppException\n\t}\n\tif errors.Is(err, thrift.ErrProtocolException) {\n\t\t// Wrap thrift protocol exception\n\t\treturn kerrors.ErrProtocolException\n\t}\n\tif errors.Is(err, thrift.ErrUnknownMethod) {\n\t\t// Wrap thrift unknown method error\n\t\treturn kerrors.ErrUnknownMethod\n\t}\n\tif errors.Is(err, thrift.ErrInvalidMessageType) {\n\t\t// Wrap thrift invalid message type error\n\t\treturn kerrors.ErrInvalidMessageType\n\t}\n\tif errors.Is(err, thrift.ErrWrongMethodName) {\n\t\t// Wrap thrift wrong method name error\n\t\treturn kerrors.ErrWrongMethodName\n\t}\n\tif errors.Is(err, thrift.ErrBadSequenceID) {\n\t\t// Wrap thrift bad sequence ID error\n\t\treturn kerrors.ErrBadSequenceID\n\t}\n\tif errors.Is(err, thrift.ErrMissingResult) {\n\t\t// Wrap thrift missing result error\n\t\treturn kerrors.ErrMissingResult\n\t}\n\tif errors.Is(err, thrift.ErrInternalError) {\n\t\t// Wrap thrift internal error\n\t\treturn kerrors.ErrInternalError\n\t}\n\tif errors.Is(err, protobuf.ErrInvalidMessage) {\n\t\t// Wrap KitexProtobuf invalid message error\n\t\treturn kerrors.ErrInvalidMessage\n\t}\n\tif errors.Is(err, protobuf.ErrInvalidMessageType) {\n\t\t// Wrap KitexProtobuf invalid message type error\n\t\treturn kerrors.ErrInvalidMessageType\n\t}\n\tif errors.Is(err, protobuf.ErrUnknownMethod) {\n\t\t// Wrap KitexProtobuf unknown method error\n\t\treturn kerrors.ErrUnknownMethod\n\t}\n\treturn err\n}\n```\n\nThis default error handler checks for various thrift and KitexProtobuf protocol errors and wraps them into corresponding `kerrors` errors to provide a more friendly error handling experience. For other types of errors, it simply returns the original error.", "kitex-client/middlewares.go-ClientErrorHandlerWithAddr": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc ClientErrorHandlerWithAddr(ctx context.Context, err error) error {\n\tremoteAddr := getRemoteAddr(ctx)\n\tif remoteAddr != \"\" {\n\t\tif te, ok := err.(*kerrors.TransError); ok {\n\t\t\tte.Message = fmt.Sprintf(\"remote %s: %s\", remoteAddr, te.Message)\n\t\t\treturn te\n\t\t}\n\t\treturn fmt.Errorf(\"remote %s: %w\", remoteAddr, err)\n\t}\n\treturn err\n}\n```\n\nThis function does the following:\n\n1. It retrieves the remote address from the context using the `getRemoteAddr` function.\n\n2. If the remote address is available:\n   - If the error is of type `*kerrors.TransError`, it modifies the error message to include the remote address and returns the updated error.\n   - Otherwise, it wraps the original error with a new error that includes the remote address.\n\n3. If the remote address is not available, it returns the original error as is.\n\nThe purpose of this error handler is to add the remote address information to the error message, providing more context about where the error occurred.", "kitex-client/option.go-WithInstanceMW": "Here is the generated code for the `WithInstanceMW` function:\n\n```go\nfunc WithInstanceMW(mw endpoint.Middleware) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithInstanceMW(%+v)\", utils.GetFuncName(mw)))\n\t\to.InstanceMWs = append(o.InstanceMWs, mw)\n\t}}\n}\n```\n\nThe `WithInstanceMW` function takes an `endpoint.Middleware` as a parameter and returns an `Option`. It adds the provided middleware to the client's `InstanceMWs` slice, which contains middlewares that are applied after the service discovery and load balancing process.\n\nInside the `Option`'s function `F`, it appends the middleware to the `InstanceMWs` slice of the client options (`o.InstanceMWs`). It also adds a string representation of the middleware function name to the `di` slice for debugging purposes using `utils.GetFuncName(mw)`.\n\nThis function allows adding custom middlewares that are executed after the service discovery and load balancing steps, providing a way to intercept and modify the request before it is sent to the selected instance.", "kitex-client/option.go-WithHostPorts": "Here is the generated code for the `WithHostPorts` function:\n\n```go\nfunc WithHostPorts(hostports ...string) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithHostPorts(%s)\", strings.Join(hostports, \",\")))\n\t\tif len(hostports) > 0 {\n\t\t\to.Svr.Endpoints = make([]string, len(hostports))\n\t\t\tfor i, e := range hostports {\n\t\t\t\to.Svr.Endpoints[i] = e\n\t\t\t}\n\t\t}\n\t}}\n}\n```\n\nThis function does the following:\n\n1. It takes a variadic parameter `hostports` of type `string` which represents the target instance addresses.\n\n2. It returns an `Option` struct with a function `F` that takes a pointer to `client.Options` and a pointer to `utils.Slice`.\n\n3. Inside the function `F`, it appends a string representation of the `hostports` to the `utils.Slice` using `di.Push()`. The `hostports` are joined with commas using `strings.Join()`.\n\n4. If `hostports` is not empty, it sets the `Endpoints` field of `o.Svr` to a new slice with the same length as `hostports`.\n\n5. It then iterates over `hostports` and assigns each element to the corresponding index in `o.Svr.Endpoints`.\n\nThis function allows specifying the target instance addresses when doing service discovery, overwriting the results from the Resolver. It sets the `Endpoints` field of the client options with the provided `hostports`.", "kitex-client/option.go-WithShortConnection": "Here is the generated code for the `WithShortConnection` function:\n\n```go\nfunc WithShortConnection() Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(\"WithShortConnection()\")\n\t\to.ConnMode = connpool.ShortConnection\n\t}}\n}\n```\n\nThis function returns an `Option` that sets the connection mode to `connpool.ShortConnection`, forcing kitex to close the connection after each call is finished. It also adds a debug information entry using `di.Push` to indicate that the `WithShortConnection` option is being used.", "kitex-client/option.go-WithLongConnection": "Here is the generated code for the `WithLongConnection` function:\n\n```go\nfunc WithLongConnection(cfg connpool.IdleConfig) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithLongConnection(%+v)\", cfg))\n\t\t\n\t\to.ConnPoolType = connpool.LongConnection\n\t\to.ConnPoolCfg = cfg\n\t}}\n}\n```\n\nThis function enables long connection with kitex's built-in pooling implementation. It takes an `IdleConfig` parameter from the `connpool` package to configure the connection pool.\n\nInside the function, it returns an `Option` with a function that modifies the `client.Options`:\n1. It adds a diagnostic message using `di.Push` to indicate that long connection is enabled with the provided configuration.\n2. It sets the `ConnPoolType` field of `client.Options` to `connpool.LongConnection` to specify the use of long connection.\n3. It sets the `ConnPoolCfg` field of `client.Options` to the provided `cfg` to configure the connection pool.\n\nThis allows the client to use long connections with the specified idle configuration for the connection pool.", "kitex-client/option.go-WithMuxConnection": "Here is the generated code for the `WithMuxConnection` function based on the provided function signature and natural language annotation:\n\n```go\n// WithMuxConnection specifies the transport type to be mux.\nfunc WithMuxConnection(connNum int) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithMuxConnection(%d)\", connNum))\n\t\to.ConnPoolOpt = connpool.IdleConfig{\n\t\t\tMaxIdlePerAddress: connNum,\n\t\t\tMaxIdleGlobal:     connNum,\n\t\t\tMaxIdleTimeout:    time.Minute,\n\t\t}\n\t\to.RemoteOpt.ConnPool = netpollmux.NewMuxConnPool(o.ConnPoolOpt.MaxIdlePerAddress, time.Second*30)\n\t\to.RemoteOpt.SvrTransHdlr = netpollmux.NewSvrTransHandler()\n\t\to.RemoteOpt.CliHandlerFactory = netpollmux.NewCliTransHandlerFactory()\n\t\to.RemoteOpt.Dialer = netpollmux.NewDialer()\n\t\to.RemoteOpt.Codec = remote.NewMuxCodec()\n\t}}\n}\n```\n\nThis function sets up the necessary options for using multiplexed connections with the kitex client. It configures the connection pool, transport handlers, dialer, and codec to use the `netpollmux` package for multiplexing.\n\nThe `connNum` parameter specifies the maximum number of idle connections per address and globally. The function also sets a maximum idle timeout of 1 minute for the connections in the pool.\n\nThe generated code includes the necessary imports and pushes a debug information string to the provided `utils.Slice` for logging purposes.", "kitex-client/option.go-WithTimeoutProvider": "Here is the generated code for the `WithTimeoutProvider` function:\n\n```go\nfunc WithTimeoutProvider(p rpcinfo.TimeoutProvider) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithTimeoutProvider(%T)\", p))\n\n\t\tif o.TimeoutProvider != nil {\n\t\t\tpanic(\"WithTimeoutProvider has already been set\")\n\t\t}\n\t\to.TimeoutProvider = p\n\t}}\n}\n```\n\nThe `WithTimeoutProvider` function takes a `rpcinfo.TimeoutProvider` as a parameter and returns an `Option`. It sets the `TimeoutProvider` field of the `client.Options` to the provided `TimeoutProvider`. \n\nThe function also adds a diagnostic message to the `utils.Slice` to indicate that the `WithTimeoutProvider` option has been set with the type of the provided `TimeoutProvider`.\n\nIf the `TimeoutProvider` field of the `client.Options` is already set, the function panics with an error message indicating that `WithTimeoutProvider` has already been set.\n\nNote that the timeout settings provided by the `TimeoutProvider` will be applied before the other timeout options in the `client` package and the `callopt` package. Thus, it cannot modify the timeouts set by `WithRPCTimeout` or `WithConnectTimeout`.", "kitex-client/option.go-WithCodec": "Here is the generated code for the `WithCodec` function:\n\n```go\nfunc WithCodec(c remote.Codec) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithCodec(%T)\", c))\n\t\to.Codec = c\n\t}}\n}\n```\n\nThis function sets a custom codec for the client to handle protocols that are not natively supported by kitex. It takes a `remote.Codec` as an argument and returns an `Option` that sets the codec in the client options.", "kitex-client/option.go-WithPayloadCodec": "Here is the generated code for the `WithPayloadCodec` function:\n\n```go\nfunc WithPayloadCodec(c remote.PayloadCodec) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithPayloadCodec(%T)\", c))\n\t\to.PayloadCodec = c\n\t}}\n}\n```\n\nThis function takes a `remote.PayloadCodec` parameter `c` and returns an `Option`. It sets the `PayloadCodec` field of the `client.Options` struct to the provided codec `c`. It also appends a diagnostic message to the `utils.Slice` indicating the type of the codec being set.\n\nThe purpose of this function is to allow setting a custom payload codec that can handle payloads not supported by kitex by default.", "kitex-client/option.go-WithConnReporterEnabled": "Here is the generated function based on the signature and annotation:\n\n```go\nfunc WithConnReporterEnabled() Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(\"WithConnReporterEnabled()\")\n\t\to.EnableConnPoolReporter = true\n\t}}\n}\n```\n\nThis function returns a client Option that sets the `EnableConnPoolReporter` field to `true` in the client Options. This enables reporting statistics about the connection pool.\n\nIt also adds a diagnostic string to the `utils.Slice` to indicate that this option was applied.", "kitex-client/option.go-WithFailureRetry": "Here is the generated function based on the signature and natural language annotations:\n\n```go\n// WithFailureRetry sets the failure retry policy for client, it will take effect for all methods.\nfunc WithFailureRetry(p *retry.FailurePolicy) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tif p == nil {\n\t\t\treturn\n\t\t}\n\t\tdi.Push(fmt.Sprintf(\"WithFailureRetry(%+v)\", p))\n\t\tif o.RetryMethodPolicies == nil {\n\t\t\to.RetryMethodPolicies = make(map[string]retry.Policy)\n\t\t}\n\t\to.RetryMethodPolicies[retry.Wildcard] = retry.Policy{\n\t\t\tEnable:               true,\n\t\t\tMaxRetriesPerRequest: p.MaxRetriesPerRequest,\n\t\t\tShouldResultRetry:    p.ShouldResultRetry,\n\t\t}\n\t}}\n}\n```\n\nThis function takes a `*retry.FailurePolicy` parameter `p` and returns an `Option`. Inside the `Option`'s function `F`:\n1. It first checks if `p` is nil, and returns early if so.\n2. It pushes a formatted string representation of `p` to the `di` slice for debugging purposes.\n3. It checks if `o.RetryMethodPolicies` is nil, and initializes it as an empty map if so.\n4. It sets the `retry.Wildcard` key in `o.RetryMethodPolicies` to a `retry.Policy` struct with the values from `p`. This sets the failure retry policy for all methods.\n\nThe natural language annotation is used as the function comment to describe what the function does.", "kitex-client/option.go-WithBackupRequest": "Here is the generated function based on the signature and natural language annotations:\n\n```go\n// WithBackupRequest sets the backup request policy for client, it will take effect for all methods.\nfunc WithBackupRequest(p *retry.BackupPolicy) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tif p == nil {\n\t\t\treturn\n\t\t}\n\t\tdi.Push(fmt.Sprintf(\"WithBackupRequest(%+v)\", p))\n\t\to.BackupRequest = p\n\t}}\n}\n```\n\nThe function does the following:\n1. It takes a `*retry.BackupPolicy` parameter `p` which represents the backup request policy to set for the client.\n2. It returns an `Option` that contains a function `F`.\n3. Inside the `F` function:\n   - It first checks if the `p` parameter is `nil`. If so, it returns immediately without doing anything.\n   - It adds a string representation of the backup request policy to the `di` slice for debugging or logging purposes.\n   - It sets the `BackupRequest` field of the `client.Options` struct `o` to the provided backup request policy `p`.\n\nThis function allows configuring the backup request policy for the client, which will take effect for all methods. The backup request policy determines how the client should handle backup requests in case of failures or timeouts.", "kitex-client/option.go-WithSpecifiedResultRetry": "Here is the generated code for the `WithSpecifiedResultRetry` function:\n\n```go\nfunc WithSpecifiedResultRetry(rr *retry.ShouldResultRetry) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tif rr == nil {\n\t\t\treturn\n\t\t}\n\t\tdi.Push(fmt.Sprintf(\"WithSpecifiedResultRetry(%+v)\", rr))\n\t\tif o.RetryPolicy == nil {\n\t\t\to.RetryPolicy = &retry.FailurePolicy{}\n\t\t}\n\t\tif o.RetryPolicy.ShouldResultRetry == nil {\n\t\t\to.RetryPolicy.ShouldResultRetry = rr\n\t\t}\n\t}}\n}\n```\n\nThis function takes a pointer to `retry.ShouldResultRetry` as input and returns an `Option`. Inside the function:\n\n1. It first checks if the input `rr` is nil. If it is, it returns early without modifying the options.\n\n2. If `rr` is not nil, it adds a description of the option to the `di` slice for debugging purposes using `di.Push()`.\n\n3. It then checks if `o.RetryPolicy` is nil. If it is, it initializes it with a new `retry.FailurePolicy`.\n\n4. Finally, it sets the `ShouldResultRetry` field of `o.RetryPolicy` to the input `rr` if it is not already set.\n\nThis function allows the user to specify a custom `ShouldResultRetry` function for the failure retry policy. If the retry policy is enabled by remote config, this option provides a way to set the `ShouldResultRetry` function explicitly.", "kitex-client/option.go-WithGRPCInitialConnWindowSize": "Here is the generated code for the `WithGRPCInitialConnWindowSize` function:\n\n```go\nfunc WithGRPCInitialConnWindowSize(s uint32) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCInitialConnWindowSize(%d)\", s))\n\t\tif s < 64*1024 {\n\t\t\tklog.Warnf(\"WithGRPCInitialConnWindowSize: value %d is smaller than 64K and will be ignored\", s)\n\t\t} else {\n\t\t\to.GRPCConnectOpts.InitialConnWindowSize = s\n\t\t}\n\t}}\n}\n```\n\nThe function does the following:\n\n1. It takes an argument `s` of type `uint32` which represents the initial window size for a gRPC connection.\n\n2. It returns an `Option` struct with a function `F` that takes a pointer to `client.Options` and a pointer to `utils.Slice`.\n\n3. Inside the function `F`:\n   - It pushes a formatted string with the function name and argument value to the `utils.Slice` for logging or debugging purposes.\n   - It checks if the value of `s` is smaller than 64K (64 * 1024). If it is, it logs a warning message using `klog.Warnf` indicating that the value will be ignored.\n   - If the value of `s` is greater than or equal to 64K, it sets the `InitialConnWindowSize` field of `o.GRPCConnectOpts` to the value of `s`.\n\n4. Finally, it returns the constructed `Option` struct.\n\nThis function allows the user to set the initial window size for a gRPC connection, but it enforces a lower bound of 64K. If the provided value is smaller than 64K, it will be ignored and a warning message will be logged.", "kitex-client/option.go-WithGRPCMaxHeaderListSize": "Here is the generated code for the `WithGRPCMaxHeaderListSize` function:\n\n```go\nfunc WithGRPCMaxHeaderListSize(s uint32) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCMaxHeaderListSize(%d)\", s))\n\t\to.GRPCConnectOpts.MaxHeaderListSize = &s\n\t}}\n}\n```\n\nThe function does the following:\n1. It takes an unsigned 32-bit integer `s` as input, representing the maximum size of the header list.\n2. It returns an `Option` struct with a function `F` defined inline.\n3. Inside the `F` function:\n   - It appends a formatted string to the `di` slice using `di.Push()`, indicating the option name and the provided value `s`.\n   - It sets the `MaxHeaderListSize` field of the `GRPCConnectOpts` struct in the `client.Options` to a pointer to `s`.\n\nThis function allows configuring the maximum size of the header list that the client is prepared to accept when using gRPC transport. It corresponds to the `WithMaxHeaderListSize` dial option in gRPC.", "kitex-client/option.go-WithGRPCKeepaliveParams": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc WithGRPCKeepaliveParams(kp grpc.ClientKeepalive) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCKeepaliveParams(%+v)\", kp))\n\t\to.GRPCConnectOpts.KeepaliveParams = kp.ToGRPCKeepalive()\n\t}}\n}\n```\n\nThis function does the following:\n1. It takes a `grpc.ClientKeepalive` parameter `kp` which represents the keepalive parameters for the client transport.\n2. It returns an `Option` struct with a function `F` that takes a pointer to `client.Options` and a pointer to `utils.Slice`.\n3. Inside the function `F`, it pushes a formatted string representation of the `kp` parameter to the `utils.Slice` for debugging or logging purposes.\n4. It sets the `KeepaliveParams` field of `o.GRPCConnectOpts` to the result of calling `ToGRPCKeepalive()` on the `kp` parameter. This assumes that `grpc.ClientKeepalive` has a method `ToGRPCKeepalive()` that converts it to the appropriate type expected by the `KeepaliveParams` field.\n\nThis function corresponds to the `WithKeepaliveParams` DialOption of gRPC and allows specifying keepalive parameters for the client transport.", "kitex-client/option.go-WithWarmingUp": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc WithWarmingUp(wuo *warmup.ClientOption) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithWarmingUp(%+v)\", wuo))\n\t\to.WarmUpOption = wuo\n\t}}\n}\n```\n\nThis function takes a `*warmup.ClientOption` as input and returns an `Option`. It sets the `WarmUpOption` field of the `client.Options` to the provided `wuo` value, forcing the client to perform warm-ups at the end of initialization based on the specified warm-up options.", "kitex-client/callopt/options.go-WithHostPort": "Here is the generated code for the `WithHostPort` function based on the provided function signature and natural language annotations:\n\n```go\nfunc WithHostPort(hostport string) Option {\n\treturn Option{func(o *CallOptions, di *strings.Builder) {\n\t\tdi.WriteString(\"WithHostPort(\")\n\t\tdi.WriteString(hostport)\n\t\tdi.WriteByte(')')\n\n\t\tif o.svr == nil {\n\t\t\to.svr = remoteinfo.NewRemoteInfo()\n\t\t}\n\t\tif err := setInstance(o.svr, hostport); err != nil {\n\t\t\tpanic(fmt.Errorf(\"WithHostPort: %w\", err))\n\t\t}\n\t}}\n}\n```\n\nExplanation:\n- The `WithHostPort` function takes a `hostport` string as input and returns an `Option` struct.\n- Inside the `Option` struct, an anonymous function is defined that takes `o *CallOptions` and `di *strings.Builder` as parameters.\n- The function writes the option name and the `hostport` value to the `strings.Builder` for debugging purposes.\n- It checks if `o.svr` is `nil`, and if so, it creates a new `remoteinfo.RemoteInfo` instance.\n- It calls the `setInstance` function with `o.svr` and `hostport` to set the target address for the RPC call.\n  - If `setInstance` returns an error, it panics with a formatted error message.\n- The `Option` struct with the anonymous function is returned as the result of `WithHostPort`.\n\nThis implementation follows the provided function signature and annotations, allowing the target address for an RPC call to be specified and overwriting the result from the Resolver.", "kitex-client/callopt/options.go-WithURL": "Here is the generated code for the `WithURL` function:\n\n```go\nfunc WithURL(url string) Option {\n\treturn Option{func(o *CallOptions, di *strings.Builder) {\n\t\tdi.WriteString(\"WithURL\")\n\t\tdi.WriteByte('(')\n\t\tdi.WriteString(url)\n\t\tdi.WriteByte(')')\n\n\t\thostport, err := o.httpResolver.Resolve(url)\n\t\tif err != nil {\n\t\t\tpanic(fmt.Errorf(\"callopt.WithURL: %w\", err))\n\t\t}\n\t\tif err := setInstance(o.svr, hostport); err != nil {\n\t\t\tpanic(fmt.Errorf(\"callopt.WithURL: %w\", err))\n\t\t}\n\t}}\n}\n```\n\nThe `WithURL` function takes a `url` string as input and returns an `Option` struct. The function inside the `Option` struct does the following:\n\n1. It writes the function name and argument to the `strings.Builder` for debugging purposes.\n\n2. It resolves the given `url` to a `hostport` string using the `httpResolver` from the `CallOptions`.\n\n3. If there is an error during the resolution, it panics with an error message wrapped with `callopt.WithURL`.\n\n4. It calls the `setInstance` function with the resolved `hostport` and the `RemoteInfo` from the `CallOptions` to set the target instance for the RPC call.\n\n5. If there is an error while setting the instance, it panics with an error message wrapped with `callopt.WithURL`.\n\nThis function allows specifying the target for an RPC call using a URL, which will be resolved to a hostport and overwrite the result from the Resolver.", "kitex-client/callopt/options.go-WithRPCTimeout": "Here is the generated code for the `WithRPCTimeout` function based on the function signature and natural language annotations:\n\n```go\nfunc WithRPCTimeout(d time.Duration) Option {\n\treturn Option{func(o *CallOptions, di *strings.Builder) {\n\t\tdi.WriteString(\"WithRPCTimeout(\")\n\t\tdi.WriteString(d.String())\n\t\tdi.WriteString(\")\")\n\t\to.configs.SetRPCTimeout(d)\n\t}}\n}\n```\n\nExplanation:\n- The function `WithRPCTimeout` takes a `time.Duration` parameter `d` representing the RPC timeout duration.\n- It returns an `Option` struct with an anonymous function as its field.\n- The anonymous function takes `o` of type `*CallOptions` and `di` of type `*strings.Builder` as parameters.\n- Inside the anonymous function:\n  - It writes the string \"WithRPCTimeout(\" to the `strings.Builder` `di` to record the option name.\n  - It converts the duration `d` to a string using `d.String()` and writes it to `di` to record the timeout value.\n  - It writes the closing parenthesis \")\" to `di`.\n  - It sets the RPC timeout in the `configs` field of `o` using `o.configs.SetRPCTimeout(d)`.\n\nNote: As mentioned in the FIXME comment, this option works only when `client.WithRPCTimeout` or `client.WithTimeoutProvider` is specified in the client configuration.", "kitex-client/callopt/options.go-WithConnectTimeout": "Here is the generated code for the `WithConnectTimeout` function based on the provided function signature and natural language annotation:\n\n```go\n// WithConnectTimeout specifies the connection timeout for a RPC call.\nfunc WithConnectTimeout(d time.Duration) Option {\n\treturn Option{f: func(o *CallOptions, di *strings.Builder) {\n\t\tdi.WriteString(\"WithConnectTimeout\")\n\t\tdi.WriteByte('(')\n\t\tdi.WriteString(d.String())\n\t\tdi.WriteByte(')')\n\t\to.configs.SetConnectTimeout(d)\n\t}}\n}\n```\n\nThe `WithConnectTimeout` function takes a `time.Duration` parameter `d` and returns an `Option` struct. The function captures the connection timeout duration in the closure of the `Option.f` field.\n\nInside the closure, the function writes the name of the option (\"WithConnectTimeout\") and the duration value to the `strings.Builder` for debugging or logging purposes. It then sets the connection timeout value in the `CallOptions.configs` using the `SetConnectTimeout` method of the `rpcinfo.MutableRPCConfig` interface.\n\nThis function allows the user to specify the connection timeout for a specific RPC call when creating the client options.", "kitex-client/callopt/options.go-WithFallback": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc WithFallback(fb *fallback.Policy) Option {\n\treturn Option{f: func(o *CallOptions, di *strings.Builder) {\n\t\tdi.WriteString(\"WithFallback\")\n\t\tif fb.ReportAsFallback {\n\t\t\tdi.WriteString(\"(EnableReportAsFallback)\")\n\t\t}\n\t\to.Fallback = fb\n\t}}\n}\n```\n\nThe `WithFallback` function takes a `fallback.Policy` pointer as input and returns an `Option`. It sets the fallback policy for a RPC call.\n\nInside the function, it creates a new `Option` with an anonymous function as the `f` field. The anonymous function takes a `CallOptions` pointer and a `strings.Builder` pointer as parameters.\n\nThe function writes the string \"WithFallback\" to the `strings.Builder` to record the name of the option. If the `ReportAsFallback` field of the `fallback.Policy` is true, it appends \"(EnableReportAsFallback)\" to the builder to indicate that the fallback result will be reported as a metric.\n\nFinally, it sets the `Fallback` field of the `CallOptions` to the provided `fallback.Policy`.\n\nThe demos in the annotations show how to use the `WithFallback` option when making a RPC call. The first demo sets a fallback function for errors, while the second demo enables reporting the fallback result as a metric.", "kitex-server/option_advanced.go-WithServerBasicInfo": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```go\nfunc WithServerBasicInfo(ebi *rpcinfo.EndpointBasicInfo) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\to.Once.OnceOrPanic()\n\t\tdi.Push(fmt.Sprintf(\"WithServerBasicInfo(%+v)\", ebi))\n\n\t\tif ebi == nil {\n\t\t\tpanic(\"EndpointBasicInfo is nil\")\n\t\t}\n\t\tif ebi.ServiceName == \"\" {\n\t\t\tpanic(\"ServiceName is empty\")\n\t\t}\n\t\to.Svr = ebi\n\t}}\n}\n```\n\nThe `WithServerBasicInfo` function takes an `EndpointBasicInfo` pointer as input and returns an `Option`. It provides initial information for the server endpoint in the `RPCInfo`.\n\nInside the function:\n1. It creates an `Option` with a function `F` that takes `internal_server.Options` and `utils.Slice` pointers as arguments.\n2. It calls `o.Once.OnceOrPanic()` to ensure that the option is only set once.\n3. It pushes a formatted string representation of the input `ebi` to the `utils.Slice` for debugging purposes.\n4. It performs some checks on the `ebi`:\n   - If `ebi` is nil, it panics with the message \"EndpointBasicInfo is nil\".\n   - If `ebi.ServiceName` is empty, it panics with the message \"ServiceName is empty\".\n5. Finally, it assigns the `ebi` to `o.Svr` to set the server's endpoint basic information.\n\nThis function allows the user to provide initial information for the server endpoint in the `RPCInfo` using the `EndpointBasicInfo` struct.", "kitex-server/option_advanced.go-WithSupportedTransportsFunc": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc WithSupportedTransportsFunc(f func(option remote.ServerOption) []string) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\to.Once.OnceOrPanic()\n\t\tdi.Push(fmt.Sprintf(\"WithSupportedTransportsFunc(%+v)\", utils.GetFuncName(f)))\n\n\t\to.RemoteOpt.SupportedTransportsFunc = f\n\t}}\n}\n```\n\nThe `WithSupportedTransportsFunc` function takes a function `f` as a parameter, which accepts a `remote.ServerOption` and returns a slice of strings representing the supported transports.\n\nInside the function, it returns an `Option` struct with a function `F` that takes `*internal_server.Options` and `*utils.Slice` as parameters.\n\nThe function `F` does the following:\n1. It calls `o.Once.OnceOrPanic()` to ensure that the option is only set once.\n2. It pushes a formatted string representation of the function `f` to the `di` slice using `utils.GetFuncName(f)` to get the name of the function.\n3. It assigns the function `f` to `o.RemoteOpt.SupportedTransportsFunc`, which sets the function that converts supported transports from the server option.\n\nThis function allows the user to provide a custom function to determine the supported transports based on the server option.", "kitex-server/option.go-WithMiddleware": "Here is the generated code for the `WithMiddleware` function:\n\n```go\nfunc WithMiddleware(mw endpoint.Middleware) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithMiddleware(%T)\", mw))\n\n\t\tif o.Middlewares == nil {\n\t\t\to.Middlewares = make([]endpoint.Middleware, 0)\n\t\t}\n\t\to.Middlewares = append(o.Middlewares, mw)\n\t}}\n}\n```\n\nThis function takes an `endpoint.Middleware` as a parameter and returns an `Option`. It adds the provided middleware to the server's middleware chain for handling requests.\n\nInside the function:\n1. It creates an `Option` with a function `F` that takes `*internal_server.Options` and `*utils.Slice` as parameters.\n2. It pushes a formatted string representation of the middleware type to the `utils.Slice` for debugging purposes.\n3. It checks if the `Middlewares` slice in the server options is nil. If it is, it initializes it as an empty slice of `endpoint.Middleware`.\n4. It appends the provided middleware to the `Middlewares` slice in the server options.\n\nThis function allows adding custom middleware to the server's request handling pipeline.", "kitex-server/option.go-WithMiddlewareBuilder": "Here is the generated code for the `WithMiddlewareBuilder` function:\n\n```go\nfunc WithMiddlewareBuilder(mwb endpoint.MiddlewareBuilder, funcName ...string) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tchain := mwb(context.Background())\n\t\tname := \"WithMiddlewareBuilder\"\n\t\tif len(funcName) != 0 {\n\t\t\tname = funcName[0]\n\t\t}\n\t\tdi.Push(fmt.Sprintf(\"%s(%T)\", name, mwb))\n\n\t\to.MWBs = append(o.MWBs, mwb)\n\t}}\n}\n```\n\nThe `WithMiddlewareBuilder` function takes an `endpoint.MiddlewareBuilder` and an optional `funcName` string slice as parameters and returns an `Option`.\n\nInside the function:\n1. It creates a new `Option` with a function `F` that takes an `internal_server.Options` pointer and a `utils.Slice` pointer as parameters.\n2. It calls the `mwb` function with a new `context.Background()` to create a middleware chain.\n3. It determines the name of the middleware builder. If `funcName` is provided and non-empty, it uses the first element as the name. Otherwise, it defaults to \"WithMiddlewareBuilder\".\n4. It pushes a formatted string representation of the middleware builder and its type to the `utils.Slice` for debugging purposes.\n5. It appends the `mwb` to the `MWBs` slice in the `internal_server.Options`.\n\nThis function allows adding middleware builders that depend on the context to handle requests in the server.", "kitex-server/option.go-WithExitWaitTime": "Here is the generated code for the `WithExitWaitTime` function:\n\n```go\nfunc WithExitWaitTime(timeout time.Duration) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithExitWaitTime(%v)\", timeout))\n\n\t\to.ExitWaitTime = timeout\n\t}}\n}\n```\n\nThis function returns an `Option` that sets the wait duration for graceful shutdown of the server. It takes a `time.Duration` parameter `timeout` which specifies the duration to wait before forcefully shutting down the server.\n\nInside the function, it returns an `Option` struct with a function `F` that takes a pointer to `internal_server.Options` and a pointer to `utils.Slice`. It appends a string representation of the option to the `utils.Slice` for debugging purposes, and sets the `ExitWaitTime` field of the `internal_server.Options` to the provided `timeout` value.", "kitex-server/option.go-WithMaxConnIdleTime": "Here is the generated function based on the signature and natural language annotation:\n\n```go\n// WithMaxConnIdleTime sets the max idle time on connection from clients.\nfunc WithMaxConnIdleTime(timeout time.Duration) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithMaxConnIdleTime(%v)\", timeout))\n\t\t\n\t\trpcinfo.AsMutableRPCConfig(o.Configs).SetMaxConnIdleTime(timeout)\n\t\to.LockBits |= rpcinfo.BitMaxConnIdleTime\n\t}}\n}\n```\n\nThe function does the following:\n\n1. It takes a `timeout` parameter of type `time.Duration` which represents the max idle time to set for connections from clients.\n\n2. It returns an `Option` struct with a function `F` that takes `*internal_server.Options` and `*utils.Slice` as parameters.\n\n3. Inside the function `F`:\n   - It appends a string representation of the `timeout` value to the `utils.Slice` using `di.Push()` for logging or debugging purposes.\n   - It sets the max connection idle time in the mutable RPC config using `rpcinfo.AsMutableRPCConfig(o.Configs).SetMaxConnIdleTime(timeout)`.\n   - It sets the corresponding lock bit `rpcinfo.BitMaxConnIdleTime` in `o.LockBits` to indicate that the max connection idle time option is set.\n\n4. The returned `Option` can be used when creating a new server to configure the max idle time for client connections.", "kitex-server/option.go-WithPayloadCodec": "Here is the generated function based on the signature and annotation:\n\n```go\nfunc WithPayloadCodec(c remote.PayloadCodec) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithPayloadCodec(%T)\", c))\n\t\to.RemoteOpt.PayloadCodec = c\n\t}}\n}\n```\n\nThis function `WithPayloadCodec` takes a `remote.PayloadCodec` as a parameter and returns an `Option`. It sets the `PayloadCodec` field of the `RemoteOpt` in the server options to the provided payload codec `c`. \n\nIt also appends a string representation of the payload codec type to the `utils.Slice` for debugging or logging purposes.\n\nThis allows the server to handle payloads that are not supported by Kitex by default, by providing a custom payload codec implementation.", "kitex-server/option.go-WithGRPCInitialWindowSize": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc WithGRPCInitialWindowSize(s uint32) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCInitialWindowSize(%+v)\", s))\n\n\t\tif s < 64*1024 {\n\t\t\tklog.Warnf(\"WithGRPCInitialWindowSize: value %d is smaller than the lower bound of 64K and will be ignored\", s)\n\t\t} else {\n\t\t\to.RemoteOpt.GRPCCfg.InitialWindowSize = s\n\t\t}\n\t}}\n}\n```\n\nThe function does the following:\n\n1. It takes an input parameter `s` of type `uint32` representing the initial window size for the stream.\n\n2. It returns an `Option` struct with a function `F` that takes `*internal_server.Options` and `*utils.Slice` as parameters.\n\n3. Inside the function `F`:\n   - It pushes a formatted string representation of the option and its value to the `utils.Slice` for logging or debugging purposes.\n   - It checks if the provided window size `s` is smaller than the lower bound of 64KB (64*1024 bytes).\n     - If it is smaller, it logs a warning message using `klog.Warnf` indicating that the value will be ignored.\n     - If it is greater than or equal to 64KB, it sets the `InitialWindowSize` field of the `GRPCCfg` in the `RemoteOpt` of the `internal_server.Options` to the provided value `s`.\n\n4. Finally, it returns the constructed `Option` struct.\n\nThis function allows setting the initial window size for gRPC streams on the server side. It corresponds to the `InitialWindowSize` server option in gRPC. If the provided value is smaller than the lower bound of 64KB, it will be ignored and a warning message will be logged.", "kitex-server/option.go-WithGRPCInitialConnWindowSize": "Here is the generated code for the `WithGRPCInitialConnWindowSize` function:\n\n```go\nfunc WithGRPCInitialConnWindowSize(s uint32) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCInitialConnWindowSize(%+v)\", s))\n\n\t\tif s < 64*1024 {\n\t\t\ts = 64 * 1024\n\t\t}\n\t\to.RemoteOpt.GRPCCfg.InitialConnWindowSize = s\n\t}}\n}\n```\n\nThe function does the following:\n\n1. It takes a `uint32` parameter `s` representing the initial connection window size.\n\n2. It returns an `Option` struct with a function `F` that takes `*internal_server.Options` and `*utils.Slice` as parameters.\n\n3. Inside the function `F`, it first pushes a formatted string representation of the option and its value to the `utils.Slice` for logging or debugging purposes.\n\n4. It then checks if the provided window size `s` is smaller than 64KB (64*1024 bytes). If it is, it sets `s` to 64KB as the lower bound.\n\n5. Finally, it sets the `InitialConnWindowSize` field of the `GRPCCfg` struct in the `RemoteOpt` field of the `internal_server.Options` to the value of `s`.\n\nThis function corresponds to the `InitialConnWindowSize` server option in gRPC, which sets the initial window size for a connection. The window size determines the amount of data that can be sent or received without requiring acknowledgment from the other side. The lower bound of 64KB is enforced to ensure a minimum window size.", "kitex-server/option.go-WithGRPCKeepaliveParams": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc WithGRPCKeepaliveParams(kp grpc.ServerKeepalive) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCKeepaliveParams(%+v)\", kp))\n\t\to.RemoteOpt.GRPCCfg.KeepaliveParams = kp\n\t}}\n}\n```", "kitex-server/option.go-WithGRPCKeepaliveEnforcementPolicy": "Here is the generated code for the `WithGRPCKeepaliveEnforcementPolicy` function:\n\n```go\nfunc WithGRPCKeepaliveEnforcementPolicy(kep grpc.EnforcementPolicy) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCKeepaliveEnforcementPolicy(%+v)\", kep))\n\t\to.RemoteOpt.GRPCCfg.KeepaliveEnforcementPolicy = kep\n\t}}\n}\n```\n\nThis function takes a `grpc.EnforcementPolicy` parameter `kep` and returns an `Option`. It sets the keepalive enforcement policy for the server using the provided `kep` value. The function corresponds to the `KeepaliveEnforcementPolicy` server option of gRPC.\n\nInside the function, it creates an `Option` with a closure function `F`. The closure function takes `*internal_server.Options` and `*utils.Slice` as parameters. It appends a string representation of the `kep` value to the `utils.Slice` for logging or debugging purposes. Finally, it sets the `KeepaliveEnforcementPolicy` field of the `GRPCCfg` in the `RemoteOpt` of the server options to the provided `kep` value.", "kitex-server/option.go-WithGRPCMaxConcurrentStreams": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc WithGRPCMaxConcurrentStreams(n uint32) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCMaxConcurrentStreams(%+v)\", n))\n\t\to.RemoteOpt.GRPCCfg.MaxConcurrentStreams = n\n\t}}\n}\n```", "kitex-server/option.go-WithGRPCMaxHeaderListSize": "Here is the generated code for the `WithGRPCMaxHeaderListSize` function:\n\n```go\nfunc WithGRPCMaxHeaderListSize(s uint32) Option {\n\treturn Option{F: func(o *internal_server.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCMaxHeaderListSize(%+v)\", s))\n\n\t\to.RemoteOpt.GRPCCfg.MaxHeaderListSize = &s\n\t}}\n}\n```", "kitex-server/genericserver/server.go-NewServerWithServiceInfo": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```go\nfunc NewServerWithServiceInfo(handler generic.Service, g generic.Generic, svcInfo *serviceinfo.ServiceInfo, opts ...server.Option) server.Server {\n\topts = append(opts, server.WithMetaHandler(generic.MetaHandler))\n\topts = append(opts, server.WithPayloadCodec(g.PayloadCodec()))\n\topts = append(opts, server.WithErrorHandler(generic.ErrorHandler))\n\topts = append(opts, server.WithGeneric(g))\n\n\tif svcInfo != nil {\n\t\topts = append(opts, server.WithServerBasicInfo(&server.BasicInfo{\n\t\t\tServiceName: svcInfo.ServiceName,\n\t\t\tHandlerType: svcInfo.HandlerType,\n\t\t\tMethods:     svcInfo.Methods,\n\t\t\tExtra:       svcInfo.Extra,\n\t\t}))\n\t}\n\n\tsvr := server.NewServer(opts...)\n\tif err := svr.RegisterService(handler, svcInfo); err != nil {\n\t\tpanic(err)\n\t}\n\treturn svr\n}\n```\n\nExplanation:\n1. The function takes in the `handler`, `g`, `svcInfo`, and `opts` parameters as specified in the function signature.\n2. It appends several options to the `opts` slice, including `WithMetaHandler`, `WithPayloadCodec`, `WithErrorHandler`, and `WithGeneric`, passing the corresponding values from the `generic` package and the `g` parameter.\n3. If `svcInfo` is not nil, it creates a `server.BasicInfo` struct using the values from `svcInfo` and appends it to the `opts` slice using `server.WithServerBasicInfo`.\n4. It creates a new server instance using `server.NewServer` with the updated `opts` slice.\n5. It registers the `handler` and `svcInfo` with the server using `svr.RegisterService`. If an error occurs during registration, it panics.\n6. Finally, it returns the created server instance.\n\nThis function creates a new generic server with the provided handler, generic implementation, service information, and additional server options.", "weaver-validate.go-validateRegistrations": "Here is the generated code for the `validateRegistrations` function based on the provided function signature and natural language annotations:\n\n```go\nfunc validateRegistrations(regs []*codegen.Registration) error {\n\t// Validate that there are no duplicate component names.\n\tnames := map[string]bool{}\n\tfor _, reg := range regs {\n\t\tif names[reg.Name] {\n\t\t\treturn fmt.Errorf(\"duplicate component name %q\", reg.Name)\n\t\t}\n\t\tnames[reg.Name] = true\n\t}\n\n\tfor _, reg := range regs {\n\t\t// Validate that the component type is a struct.\n\t\tif reg.Type.Kind() != reflect.Struct {\n\t\t\treturn fmt.Errorf(\"component %q must be a struct, got %v\", reg.Name, reg.Type)\n\t\t}\n\n\t\t// Validate that the component has a pointer receiver.\n\t\tif reg.Receiver.Kind() != reflect.Pointer {\n\t\t\treturn fmt.Errorf(\"component %q must have a pointer receiver, got %v\", reg.Name, reg.Receiver)\n\t\t}\n\n\t\t// Validate that the component has an Implements method.\n\t\timplMethod, ok := reg.Type.MethodByName(\"Implements\")\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"component %q must have an Implements method\", reg.Name)\n\t\t}\n\t\tif implMethod.Type.NumOut() != 1 || implMethod.Type.Out(0) != reflection.TypeOfError {\n\t\t\treturn fmt.Errorf(\"component %q Implements method must return a single error\", reg.Name)\n\t\t}\n\n\t\t// Validate that the component has a valid listener name.\n\t\tif !isValidListenerName(reg.Listener) {\n\t\t\treturn fmt.Errorf(\"invalid listener name %q for component %q\", reg.Listener, reg.Name)\n\t\t}\n\n\t\t// Validate that the component methods have valid types.\n\t\tfor _, method := range reg.Methods {\n\t\t\tif err := codegen.ValidateRPCMethod(method); err != nil {\n\t\t\t\treturn fmt.Errorf(\"invalid method %q for component %q: %v\", method.Name, reg.Name, err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n```\n\nThis implementation performs the following validations on the provided registrations:\n1. Checks for duplicate component names.\n2. Validates that each component type is a struct.\n3. Validates that each component has a pointer receiver.\n4. Validates that each component has an `Implements` method that returns a single error.\n5. Validates that each component has a valid listener name using the `isValidListenerName` function.\n6. Validates that each component method has valid types using the `codegen.ValidateRPCMethod` function.\n\nIf any of these validations fail, an appropriate error is returned. If all validations pass, the function returns `nil`.\n\nNote: The implementation assumes the existence of the `reflection.TypeOfError` variable and the `codegen.ValidateRPCMethod` function, which are not provided in the given code snippet.", "weaver-sim/generators.go-Range": "Here is the generated code for the `Range` function:\n\n```go\nfunc Range(low, high int) Generator[int] {\n\tif low >= high {\n\t\tpanic(fmt.Errorf(\"Range: low (%d) >= high (%d)\", low, high))\n\t}\n\treturn generatorFunc[int](func(r *rand.Rand) int {\n\t\treturn r.Intn(high-low) + low\n\t})\n}\n```\n\nExplanation:\n1. The function first checks if `low` is greater than or equal to `high`. If so, it panics with an error message indicating the invalid range.\n2. It returns a `generatorFunc[int]` which is a function that takes a `*rand.Rand` and returns an `int`.\n3. Inside the `generatorFunc`, it generates a random integer using `r.Intn(high-low)` which returns a random integer in the range [0, high-low).\n4. It then adds `low` to the generated random integer to shift the range to [low, high).\n5. The resulting `generatorFunc` is returned as a `Generator[int]`.\n\nThis implementation ensures that the generated integers are equiprobable within the specified range [low, high) and panics if an invalid range is provided.", "weaver-sim/generators.go-String": "Here is the generated code for the `String` function:\n\n```go\nfunc String() Generator[string] {\n\t// Choose a length for the string between 0 and 100, with a bias towards smaller lengths.\n\tlength := generatorFunc[int](func(r *rand.Rand) int {\n\t\tx := r.ExpFloat64() * 10\n\t\tif x > 100 {\n\t\t\tx = 100\n\t\t}\n\t\treturn int(x)\n\t})\n\n\t// Generate a random rune (character) for each position in the string.\n\trunes := generatorFunc[rune](func(r *rand.Rand) rune {\n\t\t// Printable ASCII characters have codes 32 to 126.\n\t\treturn rune(r.Intn(95) + 32)\n\t})\n\n\treturn generatorFunc[string](func(r *rand.Rand) string {\n\t\tn := length.Generate(r)\n\t\tchars := make([]rune, n)\n\t\tfor i := 0; i < n; i++ {\n\t\t\tchars[i] = runes.Generate(r)\n\t\t}\n\t\treturn string(chars)\n\t})\n}\n```\n\nThis implementation does the following:\n\n1. It defines a `length` generator that returns random integers between 0 and 100, with a bias towards smaller values. It uses `r.ExpFloat64()` to generate exponentially distributed floats with a mean of 1, multiplies them by 10 to get a mean of 10, and caps the value at 100.\n\n2. It defines a `runes` generator that returns random printable ASCII characters (codes 32 to 126).\n\n3. The main `String` generator uses the `length` generator to determine the length of the string, creates a slice of runes of that length, fills it with characters from the `runes` generator, and converts the slice to a string.\n\nThis generates moderately sized strings (up to 100 characters) with a bias towards smaller strings, and the strings contain printable ASCII characters.", "weaver-sim/generators.go-OneOf": "Here is the generated code for the `OneOf` function:\n\n```go\nfunc OneOf[T any](xs ...T) Generator[T] {\n\tif len(xs) == 0 {\n\t\tpanic(\"OneOf: no values provided\")\n\t}\n\treturn generatorFunc[T](func(r *rand.Rand) T {\n\t\treturn xs[r.Intn(len(xs))]\n\t})\n}\n```\n\nExplanation:\n1. The function takes a variadic parameter `xs` of type `T`, allowing any number of values to be passed.\n2. It first checks if the length of `xs` is zero. If so, it panics with an error message indicating that no values were provided.\n3. It returns a `Generator[T]` using the `generatorFunc[T]` type, which is a function that takes a `*rand.Rand` and returns a value of type `T`.\n4. Inside the `generatorFunc[T]`, it uses `r.Intn(len(xs))` to generate a random index within the range of `xs`.\n5. It returns the value at the randomly selected index from `xs`.\n\nThis implementation ensures that the `OneOf` function returns one of the provided values equiprobably and panics if no values are provided.", "weaver-sim/generators.go-Weight": "Here is the generated code for the `Weight` function:\n\n```go\nfunc Weight[T any](choices []Weighted[T]) Generator[T] {\n    if len(choices) == 0 {\n        panic(\"Weight: no choices provided\")\n    }\n    \n    var totalWeight float64\n    for _, choice := range choices {\n        if choice.Weight < 0 {\n            panic(fmt.Errorf(\"Weight: negative weight %f\", choice.Weight))\n        }\n        totalWeight += choice.Weight\n    }\n    \n    if totalWeight == 0 {\n        panic(\"Weight: total weight is 0\")\n    }\n    \n    return generatorFunc[T](func(r *rand.Rand) T {\n        target := r.Float64() * totalWeight\n        var cumWeight float64\n        for _, choice := range choices {\n            cumWeight += choice.Weight\n            if target <= cumWeight {\n                return choice.Gen.Generate(r)\n            }\n        }\n        panic(\"Weight: unreachable code\")\n    })\n}\n```\n\nThe `Weight` function takes a slice of `Weighted` choices and returns a `Generator` that generates values based on the provided choices.\n\nHere's how the function works:\n\n1. It first checks if the `choices` slice is empty. If so, it panics with an appropriate error message.\n\n2. It then calculates the total weight by iterating over the `choices` slice. If any weight is negative, it panics with an error message.\n\n3. If the total weight is 0, it panics with an appropriate error message.\n\n4. It returns a `generatorFunc` that generates values based on the provided choices. The generator function works as follows:\n   - It generates a random float `target` between 0 and the total weight.\n   - It iterates over the `choices` slice and keeps track of the cumulative weight.\n   - When the `target` is less than or equal to the cumulative weight, it generates a value using the corresponding generator.\n   - If the `target` is not reached after iterating over all choices, it panics with an \"unreachable code\" message (this should never happen).\n\nThe `Weight` function ensures that the provided weights are valid and generates values according to the specified probabilities.", "weaver-sim/rand.go-pick": "Here is the generated code for the `pick` function:\n\n```go\nfunc pick[T any](r *rand.Rand, xs []T) T {\n    if len(xs) == 0 {\n        panic(fmt.Errorf(\"pick: empty slice\"))\n    }\n    i := r.Intn(len(xs))\n    return xs[i]\n}\n```", "weaver-sim/rand.go-remove": "Here is the implementation of the `remove` method based on the provided function signature and natural language annotations:\n\n```go\nfunc (i *ints) remove(x int) {\n\tif !i.has(x) {\n\t\treturn\n\t}\n\tindex := i.indices[x-i.low]\n\tlastIndex := len(i.elements) - 1\n\tlastElement := i.elements[lastIndex]\n\ti.elements[index] = lastElement\n\ti.indices[lastElement-i.low] = index\n\ti.elements = i.elements[:lastIndex]\n\ti.indices[x-i.low] = -1\n}\n```\n\nExplanation:\n1. The method first checks if the element `x` is in the set using the `has` method. If `x` is not in the set, the method returns immediately since it's a noop.\n2. If `x` is in the set, the method retrieves its index in the `elements` slice using `i.indices[x-i.low]`.\n3. The method then retrieves the index of the last element in the `elements` slice (`lastIndex`) and the value of the last element (`lastElement`).\n4. The method swaps the element at index `index` with the last element in the `elements` slice. This effectively removes `x` from the set and replaces it with the last element.\n5. The method updates the `indices` slice to reflect the new index of the last element (`lastElement`) in the `elements` slice.\n6. The method removes the last element from the `elements` slice by slicing it up to `lastIndex`.\n7. Finally, the method updates the `indices` slice to mark `x` as removed by setting its index to -1.\n\nThis implementation efficiently removes the element `x` from the set by swapping it with the last element and updating the `indices` slice accordingly. The time complexity of this operation is O(1) since it only involves a constant number of array accesses and updates.", "weaver-runtime/config.go-ParseConfig": "Here is the generated code for the `ParseConfig` function:\n\n```go\nfunc ParseConfig(file string, input string, sectionValidator func(string, string) error) (*protos.AppConfig, error) {\n\tvar sections map[string]string\n\tif _, err := toml.Decode(input, &sections); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Validate each section using the provided validator function.\n\tfor key, val := range sections {\n\t\tif err := sectionValidator(key, val); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid section %q: %v\", key, err)\n\t\t}\n\t}\n\n\t// Extract the Service Weaver application configuration.\n\tconfig := &protos.AppConfig{\n\t\tSections: sections,\n\t}\n\tif err := extractApp(file, config); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn config, nil\n}\n```\n\nThe `ParseConfig` function does the following:\n\n1. It decodes the input string as a TOML configuration into a `map[string]string` representing the sections.\n\n2. It validates each section using the provided `sectionValidator` function. If any section fails validation, an error is returned.\n\n3. It creates a new `protos.AppConfig` and sets the `Sections` field to the parsed sections.\n\n4. It calls the `extractApp` function to extract the Service Weaver application configuration from the sections and populate the `AppConfig` fields.\n\n5. Finally, it returns the parsed `AppConfig` if no errors occurred.\n\nThe function relies on the existing `extractApp` function to handle the extraction and canonicalization of the Service Weaver application configuration from the parsed sections.", "weaver-runtime/traces/db.go-OpenDB": "Here is the generated code for the `OpenDB` function:\n\n```go\nfunc OpenDB(ctx context.Context, fname string) (*DB, error) {\n\t// Create the directory for the database file if it doesn't exist.\n\tif err := os.MkdirAll(filepath.Dir(fname), 0755); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Open the database file.\n\tdb, err := sql.Open(\"sqlite\", fname)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create the traces table if it doesn't exist.\n\tconst tracesTable = `\n\t\tCREATE TABLE IF NOT EXISTS traces (\n\t\t\ttrace_id     TEXT PRIMARY KEY,\n\t\t\tapp          TEXT NOT NULL,\n\t\t\tversion      TEXT NOT NULL,\n\t\t\tname         TEXT NOT NULL,\n\t\t\tstart_micros INTEGER NOT NULL,\n\t\t\tend_micros   INTEGER NOT NULL,\n\t\t\tstatus       TEXT\n\t\t)\n\t`\n\tif _, err := db.ExecContext(ctx, tracesTable); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Create the encoded_spans table if it doesn't exist.\n\tconst encodedSpansTable = `\n\t\tCREATE TABLE IF NOT EXISTS encoded_spans (\n\t\t\ttrace_id     TEXT NOT NULL,\n\t\t\tstart_micros INTEGER NOT NULL,\n\t\t\tdata         BLOB NOT NULL,\n\t\t\tPRIMARY KEY (trace_id, start_micros)\n\t\t)\n\t`\n\tif _, err := db.ExecContext(ctx, encodedSpansTable); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &DB{fname: fname, db: db}, nil\n}\n```", "weaver-runtime/traces/db.go-QueryTraces": "Here is the generated code for the QueryTraces function:\n\n```go\nfunc (d *DB) QueryTraces(ctx context.Context, app, version string, startTime, endTime time.Time, durationLower, durationUpper time.Duration, onlyErrors bool, limit int64) ([]TraceSummary, error) {\n\tvar args []any\n\tvar conditions []string\n\n\tif app != \"\" {\n\t\tconditions = append(conditions, \"app=?\")\n\t\targs = append(args, app)\n\t}\n\tif version != \"\" {\n\t\tconditions = append(conditions, \"version=?\")\n\t\targs = append(args, version)\n\t}\n\tif !startTime.IsZero() {\n\t\tconditions = append(conditions, \"start_time>=?\")\n\t\targs = append(args, startTime.UnixMicro())\n\t}\n\tif !endTime.IsZero() {\n\t\tconditions = append(conditions, \"end_time<?\")\n\t\targs = append(args, endTime.UnixMicro())\n\t}\n\tif durationLower > 0 {\n\t\tconditions = append(conditions, \"(end_time-start_time)>=?\")\n\t\targs = append(args, durationLower.Microseconds())\n\t}\n\tif durationUpper > 0 {\n\t\tconditions = append(conditions, \"(end_time-start_time)<?\")\n\t\targs = append(args, durationUpper.Microseconds())\n\t}\n\tif onlyErrors {\n\t\tconditions = append(conditions, \"status!=''\")\n\t}\n\n\tquery := \"SELECT trace_id, start_time, end_time, status FROM traces\"\n\tif len(conditions) > 0 {\n\t\tquery += \" WHERE \" + strings.Join(conditions, \" AND \")\n\t}\n\tquery += \" ORDER BY start_time DESC\"\n\tif limit > 0 {\n\t\tquery += fmt.Sprintf(\" LIMIT %d\", limit)\n\t}\n\n\trows, err := d.queryDB(ctx, query, args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer rows.Close()\n\n\tvar traces []TraceSummary\n\tfor rows.Next() {\n\t\tvar trace TraceSummary\n\t\tvar startMicros, endMicros int64\n\t\tif err := rows.Scan(&trace.TraceID, &startMicros, &endMicros, &trace.Status); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\ttrace.StartTime = time.UnixMicro(startMicros)\n\t\ttrace.EndTime = time.UnixMicro(endMicros)\n\t\ttraces = append(traces, trace)\n\t}\n\tif err := rows.Err(); err != nil {\n\t\treturn nil, err\n\t}\n\treturn traces, nil\n}\n```\n\nThe key points are:\n\n- Build up the SQL query conditions and arguments based on the non-zero input parameters. This allows filtering the traces based on app, version, time range, duration range, and error status.\n\n- Order the results by start time descending to get the most recent traces first. \n\n- Limit the number of results if a limit is specified.\n\n- Execute the query using the existing queryDB helper method.\n\n- Scan the query results into TraceSummary structs, converting the start/end times from microseconds since epoch to time.Time values.\n\n- Return the slice of TraceSummary results.\n\nLet me know if you have any other questions!", "weaver-runtime/retry/retry.go-Continue": "Here is the generated code for the `Continue` method:\n\n```go\nfunc (r *Retry) Continue(ctx context.Context) bool {\n    if r.attempt > 0 {\n        randomized(ctx, backoffDelay(r.attempt, r.options))\n        if ctx.Err() != nil {\n            return false\n        }\n    }\n    r.attempt++\n    return true\n}\n```", "weaver-runtime/colors/tabularizer.go-Row": "Here is the generated code for the `Row` method:\n\n```go\nfunc (t *Tabularizer) Row(values ...any) {\n\trow := make([]Text, len(values))\n\tfor i, v := range values {\n\t\tswitch v := v.(type) {\n\t\tcase Text:\n\t\t\trow[i] = v\n\t\tcase Atom:\n\t\t\trow[i] = Text{v}\n\t\tcase string:\n\t\t\trow[i] = Text{Atom{S: v}}\n\t\tcase fmt.Stringer:\n\t\t\trow[i] = Text{Atom{S: v.String()}}\n\t\tdefault:\n\t\t\trow[i] = Text{Atom{S: fmt.Sprint(v)}}\n\t\t}\n\t}\n\n\tif len(t.rows) > 0 && len(row) != len(t.rows[0]) {\n\t\tpanic(\"tabularizer: row length mismatch\")\n\t}\n\n\tfor i, text := range row {\n\t\tif len(text) > t.widths[i] {\n\t\t\tt.widths[i] = len(text)\n\t\t}\n\t}\n\n\tt.rows = append(t.rows, row)\n}\n```\n\nThe `Row` method does the following:\n\n1. It creates a new slice `row` to hold the `Text` values for the current row.\n\n2. It iterates over the `values` passed to the method and converts each value to a `Text` based on its type:\n   - If the value is already of type `Text`, it is used as is.\n   - If the value is of type `Atom`, it is wrapped in a `Text` slice.\n   - If the value is a string, it is wrapped in an `Atom` and then in a `Text` slice.\n   - If the value implements the `fmt.Stringer` interface, its `String()` method is called, and the result is wrapped in an `Atom` and then in a `Text` slice.\n   - For any other type, `fmt.Sprint()` is used to convert the value to a string, and it is wrapped in an `Atom` and then in a `Text` slice.\n\n3. It checks if the length of the current row matches the length of the previous rows (if any). If there is a mismatch, it panics with an error message.\n\n4. It updates the `widths` slice by comparing the length of each `Text` in the current row with the corresponding value in `widths`. If the length of the `Text` is greater, the value in `widths` is updated.\n\n5. Finally, it appends the current row to the `rows` slice, which holds all the buffered rows.\n\nThis implementation ensures that each value passed to `Row` is converted to a `Text` and buffered until `Flush` is called. It also validates that all rows have the same length and updates the column widths accordingly.", "weaver-runtime/colors/tabularizer.go-Flush": "Here is the implementation of the `Flush` method for the `Tabularizer` struct:\n\n```go\nfunc (t *Tabularizer) Flush() {\n\t// Compute the maximum width of each column.\n\tfor _, row := range t.rows {\n\t\tfor i, col := range row {\n\t\t\tif len(t.widths) <= i {\n\t\t\t\tt.widths = append(t.widths, col.len())\n\t\t\t} else if colWidth := col.len(); colWidth > t.widths[i] {\n\t\t\t\tt.widths[i] = colWidth\n\t\t\t}\n\t\t}\n\t}\n\n\t// Write the title.\n\tt.writeHorizontalBorder()\n\tfor _, line := range t.title {\n\t\tfmt.Fprintf(t.w, \"\u2502 %s%*s \u2502\\n\", line, sum(t.widths)-line.len()+2*len(t.widths), \"\")\n\t}\n\n\t// Write the column headers.\n\tif len(t.rows) > 0 {\n\t\tt.writeHorizontalBorder()\n\t\tt.writeRow(t.rows[0], make([]bool, len(t.rows[0])))\n\t}\n\n\t// Write the rows.\n\tvar prev []string\n\tfor _, row := range t.rows[1:] {\n\t\tt.writeHorizontalBorder()\n\t\traw := make([]string, len(row))\n\t\tfor i, col := range row {\n\t\t\traw[i] = col.raw()\n\t\t}\n\t\tt.writeRow(row, t.dim(prev, raw))\n\t\tprev = raw\n\t}\n\n\t// Write the final border.\n\tt.writeHorizontalBorder()\n}\n\nfunc (t *Tabularizer) writeHorizontalBorder() {\n\tfmt.Fprint(t.w, \"\u251c\")\n\tfor i, w := range t.widths {\n\t\tif i > 0 {\n\t\t\tfmt.Fprint(t.w, \"\u253c\")\n\t\t}\n\t\tfmt.Fprint(t.w, strings.Repeat(\"\u2500\", w+2))\n\t}\n\tfmt.Fprintln(t.w, \"\u2524\")\n}\n\nfunc (t *Tabularizer) writeRow(row []Text, dim []bool) {\n\tfmt.Fprint(t.w, \"\u2502\")\n\tfor i, col := range row {\n\t\tif i > 0 {\n\t\t\tfmt.Fprint(t.w, \"\u2502\")\n\t\t}\n\t\tif dim[i] {\n\t\t\tcol = col.dimmed()\n\t\t}\n\t\tfmt.Fprintf(t.w, \" %s%*s \", col, t.widths[i]-col.len(), \"\")\n\t}\n\tfmt.Fprintln(t.w, \"\u2502\")\n}\n\nfunc sum(xs []int) int {\n\ttotal := 0\n\tfor _, x := range xs {\n\t\ttotal += x\n\t}\n\treturn total\n}\n```\n\nThe `Flush` method does the following:\n\n1. Computes the maximum width of each column by iterating over all the buffered rows.\n\n2. Writes the table title, surrounded by horizontal borders.\n\n3. Writes the column headers, if there are any rows.\n\n4. Writes each row, dimming columns according to the `dim` function. It also writes horizontal borders between each row.\n\n5. Writes the final horizontal border.\n\nThe `writeHorizontalBorder` and `writeRow` methods are helper functions that write the horizontal borders and individual rows, respectively. The `sum` function is a utility function that computes the sum of a slice of integers.", "weaver-runtime/protomsg/io.go-Write": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc Write(dst io.Writer, msg proto.Message) error {\n\tdata, err := proto.Marshal(msg)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"marshal protobuf: %w\", err)\n\t}\n\tif len(data) > maxMsgSize {\n\t\treturn fmt.Errorf(\"write protobuf: message size %d is too large\", len(data))\n\t}\n\tvar hdr [4]byte\n\tbinary.LittleEndian.PutUint32(hdr[:], uint32(len(data)))\n\tif _, err := dst.Write(hdr[:]); err != nil {\n\t\treturn fmt.Errorf(\"write protobuf length: %w\", err)\n\t}\n\tif _, err := dst.Write(data); err != nil {\n\t\treturn fmt.Errorf(\"write protobuf data: %w\", err)\n\t}\n\treturn nil\n}\n```\n\nExplanation:\n1. The function first marshals the provided `msg` proto.Message into a byte slice using `proto.Marshal()`. If an error occurs during marshaling, it returns an error with the appropriate message.\n\n2. It then checks if the size of the marshaled data exceeds the `maxMsgSize`. If it does, it returns an error indicating that the message size is too large.\n\n3. A 4-byte header is created using a byte array `hdr`. The length of the marshaled data is encoded into the header using `binary.LittleEndian.PutUint32()`.\n\n4. The header is written to the provided `dst` io.Writer using `dst.Write()`. If an error occurs during writing, it returns an error with the appropriate message.\n\n5. Finally, the marshaled data is written to `dst` using `dst.Write()`. If an error occurs during writing, it returns an error with the appropriate message.\n\n6. If no errors occur, the function returns `nil` to indicate a successful write operation.\n\nThis function writes a length-prefixed protobuf message to the provided `dst` io.Writer. The length prefix allows the corresponding `Read` function to determine the size of the message and read it accordingly.", "weaver-runtime/bin/bin.go-ReadComponentGraph": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc ReadComponentGraph(file string) ([]string, graph.Graph, error) {\n\tdata, err := rodata(file)\n\tif err != nil {\n\t\treturn nil, graph.Graph{}, fmt.Errorf(\"failed to read binary data: %w\", err)\n\t}\n\n\t// Extract the component information from the binary data.\n\tvar components []string\n\tvar graphData []byte\n\tfor len(data) > 0 {\n\t\t// Check for the component graph marker.\n\t\tif bytes.HasPrefix(data, codegen.ComponentGraphMarker) {\n\t\t\tdata = data[len(codegen.ComponentGraphMarker):]\n\t\t\tgraphLen := int(data[0]) | int(data[1])<<8 | int(data[2])<<16 | int(data[3])<<24\n\t\t\tgraphData = data[4 : 4+graphLen]\n\t\t\tdata = data[4+graphLen:]\n\t\t\tcontinue\n\t\t}\n\n\t\t// Check for a component marker.\n\t\tif bytes.HasPrefix(data, codegen.ComponentMarker) {\n\t\t\tdata = data[len(codegen.ComponentMarker):]\n\t\t\tnameLen := int(data[0]) | int(data[1])<<8 | int(data[2])<<16 | int(data[3])<<24\n\t\t\tname := string(data[4 : 4+nameLen])\n\t\t\tcomponents = append(components, name)\n\t\t\tdata = data[4+nameLen:]\n\t\t\tcontinue\n\t\t}\n\n\t\t// Skip to the next marker.\n\t\tif i := bytes.IndexByte(data, codegen.Marker[0]); i != -1 {\n\t\t\tdata = data[i:]\n\t\t} else {\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Unmarshal the component graph.\n\tvar g graph.Graph\n\tif err := g.UnmarshalBinary(graphData); err != nil {\n\t\treturn nil, graph.Graph{}, fmt.Errorf(\"failed to unmarshal component graph: %w\", err)\n\t}\n\n\treturn components, g, nil\n}\n```\n\nThe `ReadComponentGraph` function reads the component graph information from the specified binary file. Here's how it works:\n\n1. It calls the `rodata` function to read the read-only data section of the binary.\n\n2. It iterates over the binary data, looking for component and component graph markers.\n\n3. When it encounters a component marker, it extracts the component name and appends it to the `components` slice.\n\n4. When it encounters the component graph marker, it extracts the graph data and stores it in the `graphData` variable.\n\n5. After processing all the markers, it unmarshals the `graphData` into a `graph.Graph` struct using the `UnmarshalBinary` method.\n\n6. Finally, it returns the slice of component names and the component graph.\n\nIf any errors occur during the process, such as failing to read the binary data or unmarshaling the component graph, the function returns an error.", "weaver-runtime/bin/bin.go-ReadListeners": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc ReadListeners(file string) ([]codegen.ComponentListeners, error) {\n\tdata, err := rodata(file)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read rodata section: %w\", err)\n\t}\n\n\t// Find the listeners section in the rodata.\n\tconst listenersPrefix = \"\u27e6wEaVeRlIsTeNeRs:\"\n\tconst listenersSuffix = \"\u27e7\"\n\tstart := bytes.Index(data, []byte(listenersPrefix))\n\tif start == -1 {\n\t\treturn nil, fmt.Errorf(\"listeners section not found\")\n\t}\n\tstart += len(listenersPrefix)\n\tend := bytes.Index(data[start:], []byte(listenersSuffix))\n\tif end == -1 {\n\t\treturn nil, fmt.Errorf(\"listeners section is malformed\")\n\t}\n\tend += start\n\n\t// Parse the listeners section.\n\tvar listeners []codegen.ComponentListeners\n\tfor _, listenerData := range bytes.Split(data[start:end], []byte(\"\u27e6wEaVeRcOmPoNeNt\u27e7\")) {\n\t\tif len(listenerData) == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tvar componentListeners codegen.ComponentListeners\n\t\tfor _, l := range bytes.Split(listenerData, []byte(\"\u27e6wEaVeRlIsTeNeR\u27e7\")) {\n\t\t\tcomponentListeners.Listeners = append(componentListeners.Listeners, string(l))\n\t\t}\n\t\tlisteners = append(listeners, componentListeners)\n\t}\n\n\treturn listeners, nil\n}\n```\n\nThe function does the following:\n\n1. It reads the read-only data section of the binary using the `rodata` function.\n\n2. It searches for the listeners section in the rodata by looking for the `\u27e6wEaVeRlIsTeNeRs:` prefix and `\u27e7` suffix. If the section is not found or is malformed, an error is returned.\n\n3. It parses the listeners section by splitting it on the `\u27e6wEaVeRcOmPoNeNt\u27e7` separator to get the listeners for each component. For each component, it further splits the data on the `\u27e6wEaVeRlIsTeNeR\u27e7` separator to get the individual listeners.\n\n4. It constructs a `[]codegen.ComponentListeners` slice with the parsed listeners and returns it.\n\nThe function assumes that the listeners data is embedded in the binary's rodata section in a specific format, with each component's listeners separated by `\u27e6wEaVeRcOmPoNeNt\u27e7` and each listener within a component separated by `\u27e6wEaVeRlIsTeNeR\u27e7`.", "weaver-runtime/bin/bin.go-ReadVersions": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc ReadVersions(filename string) (Versions, error) {\n\tdata, err := rodata(filename)\n\tif err != nil {\n\t\treturn Versions{}, err\n\t}\n\n\tmoduleVersion, err := extractModuleVersion(filename)\n\tif err != nil {\n\t\treturn Versions{}, err\n\t}\n\n\tdeployerVersion, err := extractDeployerVersion(data)\n\tif err != nil {\n\t\treturn Versions{}, err\n\t}\n\n\treturn Versions{\n\t\tModuleVersion:   moduleVersion,\n\t\tDeployerVersion: deployerVersion,\n\t}, nil\n}\n```\n\nThe `ReadVersions` function does the following:\n\n1. It calls the `rodata` function to read the read-only data section of the specified binary file.\n\n2. It calls the `extractModuleVersion` function to extract the version of the Service Weaver library embedded in the binary.\n\n3. It calls the `extractDeployerVersion` function to extract the deployer API version embedded in the read-only data section.\n\n4. It returns a `Versions` struct containing the extracted module version and deployer API version. If any error occurs during the process, it returns an empty `Versions` struct and the corresponding error.\n\nThe function relies on the `rodata`, `extractModuleVersion`, and `extractDeployerVersion` helper functions to perform the necessary extraction and parsing of the version information from the binary.", "weaver-runtime/prometheus/prometheus.go-TranslateMetricsToPrometheusTextFormat": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc TranslateMetricsToPrometheusTextFormat(w *bytes.Buffer, ms []*metrics.MetricSnapshot, lisAddr, path string) {\n\t// Generate a config.yaml file that can be used by Prometheus to scrape the exported metrics.\n\twriteHelper(w, lisAddr, path)\n\n\t// Group metrics by name.\n\tmetricsByName := make(map[string][]*metrics.MetricSnapshot)\n\tfor _, m := range ms {\n\t\tmetricsByName[m.Name] = append(metricsByName[m.Name], m)\n\t}\n\n\t// Translate each group of metrics to the Prometheus text format.\n\tvar names []string\n\tfor name := range metricsByName {\n\t\tnames = append(names, name)\n\t}\n\tsort.Strings(names)\n\n\tfor _, name := range names {\n\t\tmetrics := metricsByName[name]\n\t\ttranslateMetrics(w, metrics)\n\t}\n}\n```\n\nThe `TranslateMetricsToPrometheusTextFormat` function does the following:\n\n1. It calls the `writeHelper` function to generate a `config.yaml` file that can be used by Prometheus to scrape the exported metrics. The `lisAddr` and `path` parameters are used to provide the necessary information for the scraper configuration.\n\n2. It groups the metrics by their name using a `map[string][]*metrics.MetricSnapshot`. This is done to ensure that metrics with the same name are processed together.\n\n3. It sorts the metric names to ensure a consistent order in the output.\n\n4. For each group of metrics with the same name, it calls the `translateMetrics` function to translate the metrics from the Service Weaver format to the Prometheus text format.\n\nThe translated metrics are written to the provided `bytes.Buffer` (`w`), which can then be used to expose the metrics to Prometheus for scraping.\n\nNote: The implementation relies on the existing `writeHelper` and `translateMetrics` functions, which are assumed to be defined in the same package.", "weaver-runtime/codegen/graph.go-ExtractEdges": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc ExtractEdges(data []byte) [][2]string {\n\tvar edges [][2]string\n\n\t// Regular expression to match the edge string format\n\tedgeRegex := regexp.MustCompile(`\u27e6([0-9a-f]{8}):wEaVeReDgE:([^\u2192]+)\u2192([^\u27e7]+)\u27e7`)\n\n\t// Find all matches of the edge string format in the data\n\tmatches := edgeRegex.FindAllSubmatch(data, -1)\n\n\t// Iterate over the matches\n\tfor _, match := range matches {\n\t\t// Extract the source and destination components\n\t\tsrc := string(match[2])\n\t\tdst := string(match[3])\n\n\t\t// Verify the checksum\n\t\texpectedChecksum := string(match[1])\n\t\tactualChecksum := checksumEdge(src, dst)\n\t\tif expectedChecksum == actualChecksum {\n\t\t\t// Add the valid edge to the result\n\t\t\tedges = append(edges, [2]string{src, dst})\n\t\t}\n\t}\n\n\t// Sort the edges for deterministic output\n\tsort.Slice(edges, func(i, j int) bool {\n\t\tif edges[i][0] == edges[j][0] {\n\t\t\treturn edges[i][1] < edges[j][1]\n\t\t}\n\t\treturn edges[i][0] < edges[j][0]\n\t})\n\n\treturn edges\n}\n```\n\nThe `ExtractEdges` function does the following:\n\n1. It initializes an empty slice called `edges` to store the extracted edges.\n\n2. It defines a regular expression `edgeRegex` that matches the edge string format used by `MakeEdgeString()`. The regular expression captures the checksum, source component, and destination component.\n\n3. It uses `edgeRegex.FindAllSubmatch()` to find all occurrences of the edge string format in the provided `data`.\n\n4. It iterates over the matches found in the previous step.\n\n5. For each match, it extracts the source component (`src`) and destination component (`dst`) from the captured groups.\n\n6. It verifies the checksum by comparing the expected checksum (captured from the match) with the actual checksum computed using the `checksumEdge()` function.\n\n7. If the checksums match, it appends the valid edge (`[2]string{src, dst}`) to the `edges` slice.\n\n8. After processing all matches, it sorts the `edges` slice based on the source component and then the destination component. This ensures a deterministic output order.\n\n9. Finally, it returns the sorted `edges` slice containing the extracted edges.\n\nNote: The `checksumEdge()` function used in this code is the same as the one provided in the original code snippet.", "weaver-runtime/codegen/registry.go-ComponentConfigValidator": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc ComponentConfigValidator(path, cfg string) error {\n\treg, ok := Find(path)\n\tif !ok {\n\t\treturn fmt.Errorf(\"component not found: %s\", path)\n\t}\n\n\tvar cfgStruct config.Struct\n\tif err := cfgStruct.UnmarshalText([]byte(cfg)); err != nil {\n\t\treturn fmt.Errorf(\"invalid configuration for component %s: %v\", path, err)\n\t}\n\n\timplType := reg.Impl\n\timplValue := reflect.New(implType)\n\timplInterface := implValue.Interface()\n\n\tif err := runtime.PopulateConfig(implInterface, cfgStruct); err != nil {\n\t\treturn fmt.Errorf(\"error populating configuration for component %s: %v\", path, err)\n\t}\n\n\tif validator, ok := implInterface.(config.Validator); ok {\n\t\tif err := validator.Validate(); err != nil {\n\t\t\treturn fmt.Errorf(\"invalid configuration for component %s: %v\", path, err)\n\t\t}\n\t}\n\n\treturn nil\n}\n```\n\nExplanation:\n1. The function first looks up the registration for the component with the given `path` using the `Find` function. If the component is not found, it returns an error.\n\n2. It then unmarshals the provided configuration string `cfg` into a `config.Struct` using `UnmarshalText`.\n\n3. It creates a new instance of the component's implementation type using `reflect.New` and gets the interface value using `implValue.Interface()`.\n\n4. It populates the configuration into the component instance using `runtime.PopulateConfig`.\n\n5. If the component implements the `config.Validator` interface, it calls the `Validate` method to validate the configuration.\n\n6. If any errors occur during the process, appropriate error messages are returned. Otherwise, the function returns `nil` to indicate a valid configuration.\n\nNote: The implementation assumes the existence of certain types and functions (`config.Struct`, `runtime.PopulateConfig`, `config.Validator`) which are not defined in the provided code snippet. These types and functions are assumed to be available in the respective packages.", "weaver-runtime/codegen/registry.go-CallGraph": "Here is the generated function:\n\n```go\nfunc CallGraph() []CallEdge {\n\tglobalRegistry.m.Lock()\n\tdefer globalRegistry.m.Unlock()\n\n\tvar edges []CallEdge\n\tfor _, reg := range globalRegistry.components {\n\t\tfor _, ref := range strings.Split(reg.RefData, \"\\n\") {\n\t\t\tif ref == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tparts := strings.Split(ref, \":\")\n\t\t\tif len(parts) != 2 {\n\t\t\t\tpanic(fmt.Sprintf(\"malformed RefData entry %q\", ref))\n\t\t\t}\n\t\t\tcallee, ok := globalRegistry.byName[parts[1]]\n\t\t\tif !ok {\n\t\t\t\tpanic(fmt.Sprintf(\"unknown component %q\", parts[1]))\n\t\t\t}\n\t\t\tedges = append(edges, CallEdge{\n\t\t\t\tCaller: reg.Iface,\n\t\t\t\tCallee: callee.Iface,\n\t\t\t})\n\t\t}\n\t}\n\treturn edges\n}\n```\n\nThe function does the following:\n\n1. It locks the global registry mutex to safely access the registered components.\n\n2. It initializes a slice to store the `CallEdge` values.\n\n3. It iterates over each registered component in the global registry.\n\n4. For each component, it splits the `RefData` string by newline to get the individual references.\n\n5. It skips any empty references.\n\n6. For each non-empty reference, it splits it by \":\" to separate the reference type and the component name.\n\n7. It panics if the reference entry is malformed (doesn't have exactly two parts).\n\n8. It looks up the callee component by name in the global registry. If the component is not found, it panics.\n\n9. It creates a new `CallEdge` with the current component's interface type as the caller and the callee component's interface type as the callee, and appends it to the `edges` slice.\n\n10. Finally, it returns the slice of `CallEdge` values representing the component call graph.\n\nThe function assumes that the `RefData` field of each registered component contains properly formatted references to other components, separated by newlines.", "weaver-runtime/codegen/listeners.go-MakeListenersString": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc MakeListenersString(component string, listeners []string) string {\n\t// Sort the listeners to ensure a consistent order.\n\tsort.Strings(listeners)\n\n\t// Create a comma-separated string of listeners.\n\tlisstr := strings.Join(listeners, \",\")\n\n\t// Compute the checksum of the formatted string.\n\tchecksum := checksumListeners(component, lisstr)\n\n\t// Return the formatted string with the checksum, component, and listeners.\n\treturn fmt.Sprintf(\"\u27e6%s:wEaVeRlIsTeNeRs:%s\u2192%s\u27e7\", checksum, component, lisstr)\n}\n```\n\nThe `MakeListenersString` function takes the `component` string and a slice of `listeners` as input. Here's how it works:\n\n1. It sorts the `listeners` slice to ensure a consistent order. This is important because the order of listeners affects the checksum.\n\n2. It creates a comma-separated string of listeners using `strings.Join`.\n\n3. It computes the checksum of the formatted string using the `checksumListeners` function. The checksum is the first 8 bytes of the hex encoding of the SHA-256 hash of the string \"wEaVeRlIsTeNeRs:component\u2192listeners\".\n\n4. Finally, it returns the formatted string with the checksum, component, and listeners enclosed in the special format: `\u27e6checksum:wEaVeRlIsTeNeRs:component\u2192listeners\u27e7`.\n\nThis function generates the specially formatted string that represents the set of listeners associated with a given component. The generated string can be embedded in the binary and extracted later to retrieve the list of listeners without executing the binary.", "weaver-runtime/codegen/listeners.go-ExtractListeners": "Here is the generated function based on the provided function signature and natural language annotations:\n\n```go\nfunc ExtractListeners(data []byte) []ComponentListeners {\n\tvar result []ComponentListeners\n\tre := regexp.MustCompile(`\u27e6([0-9a-f]{8}):wEaVeRlIsTeNeRs:([^\u2192]+)\u2192([^\u27e7]*)\u27e7`)\n\tmatches := re.FindAllSubmatch(data, -1)\n\tfor _, match := range matches {\n\t\tchecksum, component, listeners := string(match[1]), string(match[2]), string(match[3])\n\t\tif checksum != checksumListeners(component, listeners) {\n\t\t\t// Invalid checksum, skip this entry.\n\t\t\tcontinue\n\t\t}\n\t\tresult = append(result, ComponentListeners{\n\t\t\tComponent: component,\n\t\t\tListeners: strings.Split(listeners, \",\"),\n\t\t})\n\t}\n\t// Sort the result for deterministic output.\n\tsort.Slice(result, func(i, j int) bool {\n\t\treturn result[i].Component < result[j].Component\n\t})\n\treturn result\n}\n```\n\nHere's how the function works:\n\n1. It initializes an empty slice `result` to store the extracted `ComponentListeners`.\n\n2. It compiles a regular expression `re` to match the specially formatted strings that represent the listeners for each component. The regular expression captures the checksum, component name, and listeners.\n\n3. It uses `re.FindAllSubmatch` to find all matches of the regular expression in the input `data`.\n\n4. For each match:\n   - It extracts the checksum, component name, and listeners from the match.\n   - It verifies the checksum by calling `checksumListeners` with the component name and listeners. If the checksum doesn't match, it skips this entry.\n   - If the checksum is valid, it creates a new `ComponentListeners` struct with the extracted component name and listeners (split by comma) and appends it to the `result` slice.\n\n5. Finally, it sorts the `result` slice based on the component name to ensure deterministic output.\n\n6. It returns the `result` slice containing the extracted `ComponentListeners`.\n\nThe function uses the `regexp` package to match the specially formatted strings, and it relies on the `checksumListeners` function to verify the integrity of the extracted data.", "weaver-runtime/codegen/hash.go-Sum64": "Here is the generated code for the `Sum64` method:\n\n```go\nfunc (h *Hasher) Sum64() uint64 {\n\thash := sha256.Sum256(h.enc.Bytes())\n\tresult := binary.BigEndian.Uint64(hash[:8])\n\n\t// Ensure the result is in the range [1, 2^64-2]\n\tif result == 0 {\n\t\tresult = 1\n\t} else if result == math.MaxUint64 {\n\t\tresult = math.MaxUint64 - 1\n\t}\n\n\treturn result\n}\n```\n\nExplanation:\n1. We compute the SHA-256 hash of the accumulated values in the `Encoder` using `sha256.Sum256(h.enc.Bytes())`. This gives us a 32-byte hash.\n2. We extract the first 8 bytes of the hash using `hash[:8]` and convert them to a `uint64` using `binary.BigEndian.Uint64()`. This gives us a 64-bit hash value.\n3. We check if the resulting hash value is 0 or `math.MaxUint64`. If it is 0, we change it to 1. If it is `math.MaxUint64`, we change it to `math.MaxUint64 - 1`. This ensures that the resulting hash value is in the range [1, 2^64-2].\n4. Finally, we return the resulting 64-bit hash value.\n\nNote: This implementation assumes that the `Encoder` used in the `Hasher` struct provides a `Bytes()` method that returns the accumulated values as a byte slice.", "weaver-runtime/graph/adjacency.go-NewAdjacencyGraph": "Here is the generated code for the `NewAdjacencyGraph` function:\n\n```go\nfunc NewAdjacencyGraph(nodes []Node, edges []Edge) Graph {\n\t// Create a slice to store the adjacency lists\n\tout := make([][]Node, slices.Max(nodes)+1)\n\n\t// Mark each node as existing in the graph\n\tfor _, n := range nodes {\n\t\tout[n] = []Node{}\n\t}\n\n\t// Add edges to the adjacency lists\n\tfor _, e := range edges {\n\t\tif !isNode(e.Src, out) || !isNode(e.Dst, out) {\n\t\t\tpanic(fmt.Sprintf(\"edge (%d, %d) has a node not in the graph\", e.Src, e.Dst))\n\t\t}\n\t\tout[e.Src] = append(out[e.Src], e.Dst)\n\t}\n\n\treturn &adjacencyGraph{out: out}\n}\n```\n\nExplanation:\n\n1. We create a slice `out` to store the adjacency lists. The size of the slice is set to `slices.Max(nodes)+1` to ensure that it can accommodate all the nodes in the graph. We add 1 to account for the zero-based indexing.\n\n2. We iterate over each node in the `nodes` slice and mark it as existing in the graph by initializing an empty slice `[]Node{}` at the corresponding index in `out`. This step ensures that all nodes specified in `nodes` are considered as part of the graph.\n\n3. We iterate over each edge in the `edges` slice. For each edge, we check if both the source node (`e.Src`) and the destination node (`e.Dst`) exist in the graph using the `isNode` function. If either of the nodes is not present in the graph, we panic with an appropriate error message.\n\n4. If both nodes of an edge exist in the graph, we append the destination node (`e.Dst`) to the adjacency list of the source node (`out[e.Src]`). This step builds the adjacency lists based on the provided edges.\n\n5. Finally, we return a new `adjacencyGraph` instance with the constructed `out` slice as its adjacency lists.\n\nThe function panics if any of the specified edge nodes are not present in the `nodes` slice, as per the requirement mentioned in the natural language annotations.", "weaver-runtime/graph/dfs.go-DFSAll": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc DFSAll(g Graph, enter, exit func(Node)) {\n    var roots []Node\n    for i := 0; i < g.NodeLimit(); i++ {\n        roots = append(roots, Node(i))\n    }\n    dfs(g, roots, enter, exit)\n}\n```\n\nThe `DFSAll` function performs a depth-first search of all nodes in the graph `g`. It does the following:\n\n1. It initializes an empty slice called `roots` to store all the nodes in the graph.\n\n2. It iterates from 0 to `g.NodeLimit() - 1` (inclusive), which represents all the possible node IDs in the graph. For each node ID `i`, it appends the corresponding `Node` to the `roots` slice.\n\n3. It calls the `dfs` function, passing the graph `g`, the `roots` slice, and the `enter` and `exit` callback functions.\n\nThe `dfs` function then performs the actual depth-first search starting from each root node. If the `enter` function is non-nil, it is called when entering a node, and if the `exit` function is non-nil, it is called when exiting a node.\n\nBy iterating over all possible node IDs and appending them to the `roots` slice, the `DFSAll` function ensures that all nodes in the graph are visited during the depth-first search.", "weaver-runtime/metrics/labels.go-newLabelExtractor": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc newLabelExtractor[L comparable]() *labelExtractor[L] {\n\tvar x L\n\tt := reflect.TypeOf(x)\n\tif err := typecheckLabels[L](); err != nil {\n\t\tpanic(fmt.Sprintf(\"metric labels: invalid label struct type %T: %v\", x, err))\n\t}\n\n\tvar fields []field\n\tfor i := 0; i < t.NumField(); i++ {\n\t\tf := t.Field(i)\n\t\tname := unexport(f.Name)\n\t\tif alias, ok := f.Tag.Lookup(\"weaver\"); ok {\n\t\t\tname = alias\n\t\t}\n\t\tfields = append(fields, field{f: f, name: name})\n\t}\n\n\treturn &labelExtractor[L]{fields: fields}\n}\n```\n\nThis function does the following:\n\n1. It declares a variable `x` of type `L` to obtain the type information of the label struct.\n\n2. It calls the `typecheckLabels` function to validate that the label struct type `L` is valid. If it's not valid, it panics with an error message.\n\n3. It initializes an empty slice of `field` structs called `fields`.\n\n4. It iterates over each field of the label struct using reflection.\n\n5. For each field, it extracts the field name and checks if there is a \"weaver\" tag. If the tag is present, it uses the tag value as the field name instead.\n\n6. It appends a new `field` struct to the `fields` slice, containing the field information and the extracted field name.\n\n7. Finally, it returns a new `labelExtractor` instance with the populated `fields` slice.\n\nThe `newLabelExtractor` function ensures that the provided label struct type `L` is valid by calling `typecheckLabels`. It then constructs a `labelExtractor` that can be used to extract labels from instances of the label struct type `L`.", "weaver-runtime/metrics/metrics.go-Snapshot": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc (m *Metric) Snapshot() *MetricSnapshot {\n\tm.initIdAndLabels()\n\n\tvar counts []uint64\n\tif n := len(m.counts); n > 0 {\n\t\tcounts = make([]uint64, n)\n\t\tfor i := range m.counts {\n\t\t\tcounts[i] = m.counts[i].Load()\n\t\t}\n\t}\n\n\treturn &MetricSnapshot{\n\t\tId:     m.id,\n\t\tType:   m.typ,\n\t\tName:   m.name,\n\t\tLabels: maps.Clone(m.labels),\n\t\tHelp:   m.help,\n\t\tValue:  m.get(),\n\t\tBounds: slices.Clone(m.bounds),\n\t\tCounts: counts,\n\t}\n}\n```\n\nThe `Snapshot` method does the following:\n\n1. It calls `initIdAndLabels` to ensure that the metric's `id` and `labels` fields are initialized. This is required before taking a snapshot.\n\n2. If the metric is a histogram (i.e., `m.counts` is non-empty), it creates a new slice `counts` and copies the current values of the histogram counts into it using `m.counts[i].Load()`. This ensures that the snapshot captures the current state of the histogram.\n\n3. It returns a new `MetricSnapshot` struct populated with the metric's `id`, `typ`, `name`, `labels` (cloned), `help`, current value (obtained by calling `m.get()`), `bounds` (cloned), and the `counts` slice (for histograms).\n\nThe `maps.Clone` and `slices.Clone` calls are used to create deep copies of the `labels` map and `bounds` slice, respectively, to avoid any modifications to the original metric after the snapshot is taken.", "weaver-internal/tool/generate/types.go-sizeOfType": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc (tset *typeSet) sizeOfType(t types.Type) int {\n\tif result := tset.sizes.At(t); result != nil {\n\t\treturn result.(int)\n\t}\n\n\tvar size int\n\tswitch x := t.(type) {\n\tcase *types.Basic:\n\t\tswitch x.Kind() {\n\t\tcase types.Bool, types.Int8, types.Uint8:\n\t\t\tsize = 1\n\t\tcase types.Int16, types.Uint16:\n\t\t\tsize = 2\n\t\tcase types.Int32, types.Uint32, types.Float32:\n\t\t\tsize = 4\n\t\tcase types.Int64, types.Uint64, types.Float64, types.Complex64:\n\t\t\tsize = 8\n\t\tcase types.Complex128:\n\t\t\tsize = 16\n\t\tcase types.String:\n\t\t\tsize = -1\n\t\tdefault:\n\t\t\tsize = -1\n\t\t}\n\n\tcase *types.Array:\n\t\telemSize := tset.sizeOfType(x.Elem())\n\t\tif elemSize < 0 {\n\t\t\tsize = -1\n\t\t} else {\n\t\t\tsize = int(x.Len()) * elemSize\n\t\t}\n\n\tcase *types.Struct:\n\t\tsize = 0\n\t\tfor i := 0; i < x.NumFields(); i++ {\n\t\t\tf := x.Field(i)\n\t\t\tfieldSize := tset.sizeOfType(f.Type())\n\t\t\tif fieldSize < 0 {\n\t\t\t\tsize = -1\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tsize += fieldSize\n\t\t}\n\n\tcase *types.Named:\n\t\tsize = tset.sizeOfType(x.Underlying())\n\n\tdefault:\n\t\tsize = -1\n\t}\n\n\ttset.sizes.Set(t, size)\n\treturn size\n}\n```\n\nThis function determines the size of the serialization of a given type `t` if it is fixed size, or returns -1 if it is not fixed size. Here's how it works:\n\n1. It first checks if the size for the type `t` has already been computed and memoized in `tset.sizes`. If so, it returns the memoized size.\n\n2. If the size hasn't been computed yet, it switches on the underlying type of `t`:\n   - For basic types, it returns the corresponding size based on the type's kind (e.g., 1 for bool, 4 for int32).\n   - For array types, it recursively computes the size of the element type and multiplies it by the array length. If the element type is not fixed size, it returns -1.\n   - For struct types, it iterates over the fields and recursively computes their sizes. If any field is not fixed size, it returns -1. Otherwise, it sums up the sizes of all fields.\n   - For named types, it recursively computes the size of the underlying type.\n   - For all other types, it returns -1.\n\n3. Finally, it memoizes the computed size in `tset.sizes` and returns the size.\n\nThis function relies on the `tset.sizes` field to memoize the computed sizes and avoid redundant computations.", "weaver-internal/tool/generate/types.go-isMeasurable": "Here is the generated code for the `isMeasurable` function:\n\n```go\nfunc (tset *typeSet) isMeasurable(t types.Type) bool {\n\t// Return early if we've already checked this type.\n\tif result := tset.measurable.At(t); result != nil {\n\t\treturn result.(bool)\n\t}\n\n\tswitch x := t.(type) {\n\tcase *types.Basic:\n\t\t// All basic types except string are measurable.\n\t\tmeasurable := x.Kind() != types.String\n\t\ttset.measurable.Set(t, measurable)\n\t\treturn measurable\n\n\tcase *types.Array:\n\t\t// An array is measurable if its element type is measurable.\n\t\tmeasurable := tset.isMeasurable(x.Elem())\n\t\ttset.measurable.Set(t, measurable)\n\t\treturn measurable\n\n\tcase *types.Struct:\n\t\t// A struct is measurable if all its fields are measurable and package local.\n\t\tmeasurable := true\n\t\tfor i := 0; i < x.NumFields(); i++ {\n\t\t\tf := x.Field(i)\n\t\t\tif !tset.isMeasurable(f.Type()) || !tset.isPackageLocal(f.Pkg()) {\n\t\t\t\tmeasurable = false\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\ttset.measurable.Set(t, measurable)\n\t\treturn measurable\n\n\tcase *types.Named:\n\t\t// A named type is measurable if its underlying type is measurable\n\t\t// or if it implements weaver.AutoMarshal.\n\t\tif tset.automarshals.At(t) != nil {\n\t\t\ttset.measurable.Set(t, true)\n\t\t\treturn true\n\t\t}\n\t\tmeasurable := tset.isMeasurable(x.Underlying())\n\t\ttset.measurable.Set(t, measurable)\n\t\treturn measurable\n\n\tdefault:\n\t\t// Other types like slice, map, chan, etc. are not measurable.\n\t\ttset.measurable.Set(t, false)\n\t\treturn false\n\t}\n}\n```\n\nThe key points are:\n\n- The result is memoized in `tset.measurable` to avoid recomputing for the same type.\n- Basic types except string are measurable. \n- Arrays are measurable if their element type is measurable.\n- Structs are measurable if all fields are measurable and package local. \n- Named types are measurable if their underlying type is measurable or if they implement `weaver.AutoMarshal`.\n- Other types like slices, maps, channels, etc. are not considered measurable.\n\nThe `isPackageLocal` helper function used for structs would check if the provided package is the same as the current package `tset.pkg`.", "weaver-internal/tool/generate/types.go-isValidRouterType": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc (tset *typeSet) isValidRouterType(t types.Type) bool {\n\tswitch x := t.Underlying().(type) {\n\tcase *types.Basic:\n\t\tswitch x.Kind() {\n\t\tcase types.Int, types.Int8, types.Int16, types.Int32, types.Int64,\n\t\t\ttypes.Uint, types.Uint8, types.Uint16, types.Uint32, types.Uint64,\n\t\t\ttypes.Float32, types.Float64, types.String:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\n\tcase *types.Struct:\n\t\thasAutoMarshal := false\n\t\tfor i := 0; i < x.NumFields(); i++ {\n\t\t\tf := x.Field(i)\n\t\t\tif f.Embedded() {\n\t\t\t\tif named, ok := f.Type().(*types.Named); ok && named.Obj().Pkg().Path() == weaverPackagePath && named.Obj().Name() == \"AutoMarshal\" {\n\t\t\t\t\thasAutoMarshal = true\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !tset.isValidRouterType(f.Type()) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn hasAutoMarshal || x.NumFields() > 0\n\n\tdefault:\n\t\treturn false\n\t}\n}\n```\n\nThis function checks whether the provided type `t` is a valid router type according to the given criteria:\n\n1. If `t` is a basic type, it checks if it is an integer (signed or unsigned), float, or string. If so, it returns `true`. Otherwise, it returns `false`.\n\n2. If `t` is a struct, it iterates over its fields. If a field is embedded and is the `weaver.AutoMarshal` type, it sets `hasAutoMarshal` to `true` and continues to the next field. For other fields, it recursively calls `isValidRouterType` to check if the field type is valid. If any field type is invalid, it returns `false`.\n\n   After iterating over all fields, it returns `true` if either `hasAutoMarshal` is `true` or the struct has at least one field. This ensures that an empty struct without `weaver.AutoMarshal` is not considered a valid router type.\n\n3. For any other type, it returns `false`.\n\nNote that the function assumes the existence of a constant `weaverPackagePath` that holds the import path of the `weaver` package.", "weaver-internal/tool/generate/generator.go-sanitize": "Here is the implementation of the `sanitize` function based on the provided function signature and natural language annotations:\n\n```go\nfunc sanitize(t types.Type) string {\n\t// Map to keep track of generated names for uniqueness\n\tgenerated := make(map[types.Type]string)\n\n\tvar generate func(t types.Type) string\n\tgenerate = func(t types.Type) string {\n\t\tif name, ok := generated[t]; ok {\n\t\t\treturn name\n\t\t}\n\n\t\tswitch t := t.(type) {\n\t\tcase *types.Basic:\n\t\t\tname := t.Name()\n\t\t\tgenerated[t] = name\n\t\t\treturn name\n\n\t\tcase *types.Named:\n\t\t\tname := t.Obj().Name()\n\t\t\tgenerated[t] = name\n\t\t\treturn name\n\n\t\tcase *types.Pointer:\n\t\t\telem := generate(t.Elem())\n\t\t\tname := fmt.Sprintf(\"ptr_%s_%x\", elem, sha256.Sum256([]byte(elem)))\n\t\t\tgenerated[t] = name\n\t\t\treturn name\n\n\t\tcase *types.Slice:\n\t\t\telem := generate(t.Elem())\n\t\t\tname := fmt.Sprintf(\"slice_%s_%x\", elem, sha256.Sum256([]byte(elem)))\n\t\t\tgenerated[t] = name\n\t\t\treturn name\n\n\t\tcase *types.Array:\n\t\t\telem := generate(t.Elem())\n\t\t\tname := fmt.Sprintf(\"array_%d_%s_%x\", t.Len(), elem, sha256.Sum256([]byte(elem)))\n\t\t\tgenerated[t] = name\n\t\t\treturn name\n\n\t\tcase *types.Map:\n\t\t\tkey := generate(t.Key())\n\t\t\telem := generate(t.Elem())\n\t\t\tname := fmt.Sprintf(\"map_%s_%s_%x\", key, elem, sha256.Sum256([]byte(key+elem)))\n\t\t\tgenerated[t] = name\n\t\t\treturn name\n\n\t\tdefault:\n\t\t\tpanic(fmt.Sprintf(\"unsupported type: %v\", t))\n\t\t}\n\t}\n\n\treturn generate(t)\n}\n```\n\nThe `sanitize` function generates a valid and unique Go identifier for the provided `types.Type`. It handles basic types, named types, pointers, slices, arrays, and maps.\n\nThe function uses a `generated` map to keep track of already generated names to ensure uniqueness. It recursively generates names for nested types and combines them with the appropriate prefix (`ptr_`, `slice_`, `array_`, `map_`) and a hash suffix to guarantee uniqueness.\n\nThe hash suffix is generated using the SHA-256 hash of the underlying type names to avoid name collisions.\n\nIf an unsupported type is encountered, the function panics with an appropriate error message.", "weaver-internal/tool/generate/generator.go-uniqueName": "Here is the generated code for the `uniqueName` function:\n\n```go\nfunc uniqueName(t types.Type) string {\n\t// If t is a named type, return a string of the form \"pkg.name\".\n\tif named, ok := t.(*types.Named); ok {\n\t\treturn named.Obj().Pkg().Path() + \".\" + named.Obj().Name()\n\t}\n\n\t// If t is not a named type, pretty print it and suffix it with a hash of\n\t// the pretty printed string to ensure uniqueness.\n\ts := types.TypeString(t, nil)\n\th := sha256.Sum256([]byte(s))\n\treturn fmt.Sprintf(\"%s_%x\", s, h[:8])\n}\n```\n\nThis function generates a unique pretty printed representation of the provided type `t` as follows:\n\n1. If `t` is a named type (i.e. a type declared with a `type` statement), it returns a string of the form `\"pkg.name\"` where `pkg` is the package path and `name` is the type name. This ensures uniqueness for named types across packages.\n\n2. If `t` is not a named type (e.g. a primitive type like `int`, or a composite type like `[]int`), it pretty prints the type using `types.TypeString`. To ensure the result is unique, it appends an underscore followed by the first 8 bytes of the SHA-256 hash of the pretty printed string. This guarantees that if `u != t`, then `uniqueName(u) != uniqueName(t)`.\n\nSo for example:\n- `uniqueName(types.Typ[types.Int])` would return something like `\"int_1e376c2f\"`  \n- `uniqueName(types.NewSlice(types.Typ[types.Int]))` would return something like `\"[]int_8f1e3f44\"`\n- For a named type `type myInt int` declared in package `foo/bar`, `uniqueName` would return `\"foo/bar.myInt\"`\n\nThis satisfies the uniqueness requirement while also providing a readable representation of the type.", "weaver-internal/tool/certs/certs.go-GenerateSignedCert": "Here is the generated code for the `GenerateSignedCert` function:\n\n```go\nfunc GenerateSignedCert(ca *x509.Certificate, caKey crypto.PrivateKey, names ...string) (*x509.Certificate, crypto.PrivateKey, error) {\n\tpriv, err := rsa.GenerateKey(rand.Reader, 4096)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tserialNumberLimit := new(big.Int).Lsh(big.NewInt(1), 128)\n\tserialNumber, err := rand.Int(rand.Reader, serialNumberLimit)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\ttemplate := x509.Certificate{\n\t\tSerialNumber: serialNumber,\n\t\tSubject:      pkix.Name{Organization: []string{\"ACME Co.\"}},\n\t\tNotBefore:    time.Now(),\n\t\tNotAfter:     time.Now().Add(365 * 24 * time.Hour),\n\t\tKeyUsage:     x509.KeyUsageDigitalSignature | x509.KeyUsageKeyEncipherment,\n\t\tExtKeyUsage: []x509.ExtKeyUsage{\n\t\t\tx509.ExtKeyUsageClientAuth,\n\t\t\tx509.ExtKeyUsageServerAuth,\n\t\t},\n\t\tBasicConstraintsValid: true,\n\t\tIsCA:                  false,\n\t\tDNSNames:              names,\n\t}\n\tcertDER, err := x509.CreateCertificate(rand.Reader, &template, ca, &priv.PublicKey, caKey)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tcert, err := x509.ParseCertificate(certDER)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\treturn cert, priv, nil\n}\n```\n\nThis function generates a new certificate for the given DNS names, signed by the provided Certificate Authority (CA) certificate and private key. It returns the generated certificate, the corresponding private key, and any error that occurred during the process.\n\nThe function follows these steps:\n\n1. It generates a new RSA private key with a key size of 4096 bits.\n2. It generates a random serial number for the certificate.\n3. It creates a certificate template with the necessary fields, such as the serial number, subject organization, validity period, key usage, extended key usage, and DNS names.\n4. It signs the certificate using the provided CA certificate and private key.\n5. It parses the signed certificate to obtain an `x509.Certificate` object.\n6. Finally, it returns the generated certificate, private key, and any error that occurred.\n\nThe returned certificate has a one-year validity and should only be used on a temporary basis, as mentioned in the natural language annotations.", "weaver-internal/weaver/load.go-updateAssignment": "Here is the generated code for the `updateAssignment` method:\n\n```go\nfunc (lc *loadCollector) updateAssignment(assignment *protos.Assignment) {\n\tlc.mu.Lock()\n\tdefer lc.mu.Unlock()\n\n\t// Update the assignment and create a new index.\n\tlc.assignment = assignment\n\tlc.index = newIndex(assignment)\n\n\t// Reset the load collector's state.\n\tlc.start = lc.now()\n\tlc.slices = make(map[uint64]*sliceSummary)\n}\n```\n\nThe `updateAssignment` method does the following:\n\n1. It acquires the `mu` lock to ensure exclusive access to the load collector's state.\n\n2. It updates the `assignment` field with the new assignment provided as an argument.\n\n3. It creates a new `index` based on the updated assignment by calling the `newIndex` function.\n\n4. It resets the load collector's state by:\n   - Setting the `start` time to the current time using `lc.now()`.\n   - Creating a new empty `slices` map to store the slice summaries for the new assignment.\n\n5. Finally, it releases the `mu` lock using `defer`.\n\nThis method ensures that the load collector is updated with the latest assignment and clears the accumulated load, as the load report is always scoped to a single assignment.", "weaver-internal/weaver/load.go-report": "Here is the generated code for the `report` function:\n\n```go\nfunc (lc *loadCollector) report() *protos.LoadReport_ComponentLoad {\n\tlc.mu.Lock()\n\tdefer lc.mu.Unlock()\n\n\tif lc.assignment == nil || len(lc.slices) == 0 {\n\t\treturn nil\n\t}\n\n\tdelta := lc.now().Sub(lc.start)\n\treport := &protos.LoadReport_ComponentLoad{\n\t\tComponent: lc.component,\n\t\tSlices:    make([]*protos.LoadReport_SliceLoad, 0, len(lc.slices)),\n\t}\n\n\tfor _, summary := range lc.slices {\n\t\tcount := float64(summary.count.Count())\n\t\tsliceReport := &protos.LoadReport_SliceLoad{\n\t\t\tStart:      summary.slice.start,\n\t\t\tEnd:        summary.slice.end,\n\t\t\tReplicas:   summary.slice.replicas,\n\t\t\tLoad:       summary.load / delta.Seconds(),\n\t\t\tCount:      count,\n\t\t\tSubslices:  summary.splits(delta),\n\t\t}\n\t\treport.Slices = append(report.Slices, sliceReport)\n\t}\n\n\treturn report\n}\n```\n\nThe `report` function does the following:\n\n1. It acquires a lock on the load collector to ensure thread-safety while generating the report.\n\n2. It checks if the load collector has an assignment and collected load. If not, it returns `nil` since there is no load to report.\n\n3. It calculates the time duration `delta` since the last reset of the load collector.\n\n4. It creates a new `protos.LoadReport_ComponentLoad` instance to hold the load report for the component.\n\n5. It iterates over each `sliceSummary` in the `slices` map of the load collector.\n\n6. For each `sliceSummary`, it retrieves the count of distinct elements using the hyperloglog and calculates the load per second by dividing the total load by the duration in seconds.\n\n7. It creates a new `protos.LoadReport_SliceLoad` instance for each slice, populating it with the slice start, end, replicas, load per second, count of distinct elements, and subslice loads obtained by calling the `splits` method on the `sliceSummary`.\n\n8. It appends each `protos.LoadReport_SliceLoad` to the `Slices` field of the `protos.LoadReport_ComponentLoad`.\n\n9. Finally, it returns the populated `protos.LoadReport_ComponentLoad` instance containing the load report for the component.\n\nThis implementation follows the provided function signature and natural language annotations, generating a load report for the collected load in the load collector.", "weaver-internal/weaver/load.go-subslices": "Here is the generated code for the `subslices` function:\n\n```go\nfunc subslices(load float64, xs []uint64, n int) []*protos.LoadReport_SubsliceLoad {\n\t// Compute the percentiles to split the slice.\n\tps := percentiles(xs, n)\n\n\t// Compute the load per split.\n\tsplitLoad := load / float64(n)\n\n\t// Construct the splits.\n\tsplits := make([]*protos.LoadReport_SubsliceLoad, n)\n\tfor i := 0; i < n; i++ {\n\t\tvar end uint64\n\t\tif i == n-1 {\n\t\t\tend = math.MaxUint64\n\t\t} else {\n\t\t\tend = ps[i+1]\n\t\t}\n\t\tsplits[i] = &protos.LoadReport_SubsliceLoad{\n\t\t\tStart: ps[i],\n\t\t\tLoad:  splitLoad,\n\t\t}\n\t}\n\n\treturn splits\n}\n```\n\nThe `subslices` function works as follows:\n\n1. It first computes `n` equally spaced percentiles of the sorted `xs` slice using the `percentiles` function. These percentiles will be used as the split points for the subslices.\n\n2. It computes the load per split by dividing the total `load` by the number of splits `n`.\n\n3. It constructs the `splits` slice of size `n` to hold the resulting subslices.\n\n4. For each split, it determines the `end` key:\n   - If it's the last split (i == n-1), the `end` key is set to `math.MaxUint64` to represent infinity.\n   - Otherwise, the `end` key is set to the next percentile value.\n\n5. It creates a new `protos.LoadReport_SubsliceLoad` struct for each split, setting the `Start` key to the current percentile value and the `Load` to the computed `splitLoad`.\n\n6. Finally, it returns the `splits` slice containing the constructed subslices.\n\nThe function assumes that the input `xs` slice is sorted in increasing order and that `n` is greater than 0, as specified in the requirements.", "weaver-internal/weaver/routing.go-update": "Here is the generated code for the `update` function:\n\n```go\nfunc (rb *routingBalancer) update(assignment *protos.Assignment) {\n\trb.mu.Lock()\n\tdefer rb.mu.Unlock()\n\n\trb.assignment = assignment\n\trb.index = newIndex(assignment)\n\n\t// Update the set of connections based on the new assignment.\n\taddrs := make(map[string]struct{})\n\tfor _, group := range assignment.Groups {\n\t\tfor _, replica := range group.Replicas {\n\t\t\taddrs[replica.Address] = struct{}{}\n\t\t}\n\t}\n\n\t// Remove connections that are no longer in the assignment.\n\tfor addr, conn := range rb.conns {\n\t\tif _, ok := addrs[addr]; !ok {\n\t\t\tdelete(rb.conns, addr)\n\t\t\trb.balancer.Remove(conn)\n\t\t}\n\t}\n\n\t// Add connections that are new in the assignment.\n\tfor addr := range addrs {\n\t\tif _, ok := rb.conns[addr]; !ok {\n\t\t\tconn := call.NewReplicaConnection(addr, rb.tlsConfig)\n\t\t\trb.conns[addr] = conn\n\t\t\trb.balancer.Add(conn)\n\t\t}\n\t}\n}\n```\n\nThe `update` function performs the following steps:\n\n1. It locks the `routingBalancer`'s mutex to ensure exclusive access to the `assignment`, `index`, and `conns` fields.\n\n2. It updates the `assignment` field with the provided assignment.\n\n3. It creates a new `index` based on the updated assignment using the `newIndex` function (assumed to be defined elsewhere).\n\n4. It creates a map `addrs` to store the addresses of the replicas in the new assignment.\n\n5. It iterates over the connections in `rb.conns` and removes any connections that are no longer present in the new assignment. It also removes these connections from the underlying `balancer`.\n\n6. It iterates over the addresses in `addrs` and adds any new connections that are not already present in `rb.conns`. It creates a new `ReplicaConnection` for each new address and adds it to both `rb.conns` and the underlying `balancer`.\n\nThis function effectively updates the `routingBalancer` with the new assignment, adding and removing connections as necessary to reflect the changes in the assignment.", "weaver-internal/status/registry.go-NewRegistry": "Here is the generated code for the `NewRegistry` function:\n\n```go\nfunc NewRegistry(_ context.Context, dir string) (*Registry, error) {\n\tif err := os.MkdirAll(dir, 0755); err != nil {\n\t\treturn nil, fmt.Errorf(\"registry: create directory %q: %w\", dir, err)\n\t}\n\treturn &Registry{\n\t\tdir:       dir,\n\t\tnewClient: NewClient,\n\t}, nil\n}\n```\n\nExplanation:\n1. The function takes a `context.Context` parameter (which is unused, hence the `_`) and a `dir` string parameter representing the directory where the registry data will be persisted.\n2. It first creates the directory specified by `dir` using `os.MkdirAll` with the appropriate permissions (`0755`). If there is an error creating the directory, it returns `nil` and the error wrapped with additional context.\n3. If the directory is successfully created (or already exists), it returns a new `*Registry` instance with the `dir` field set to the provided directory and the `newClient` field set to the `NewClient` function (assuming it is defined elsewhere in the package).\n4. The returned `*Registry` instance can then be used to perform operations on the registry, such as registering and unregistering applications, and retrieving registrations.\n\nNote: The code assumes the existence of a `NewClient` function that returns a new status client. If this function is not defined or has a different signature, you may need to modify the code accordingly.", "weaver-internal/routing/routing.go-FormatAssignment": "Here is the generated code for the `FormatAssignment` function:\n\n```go\nfunc FormatAssignment(a *protos.Assignment) string {\n\tif a == nil {\n\t\treturn \"<nil>\"\n\t}\n\tvar sb strings.Builder\n\tsb.WriteString(fmt.Sprintf(\"Assignment{Version: %d, Slices: [\", a.GetVersion()))\n\n\tslices := a.GetSlices()\n\tfor i, slice := range slices {\n\t\tif i > 0 {\n\t\t\tsb.WriteString(\", \")\n\t\t}\n\t\tsb.WriteString(fmt.Sprintf(\"{Start: %d, End: %d, Replicas: %v}\", slice.GetStart(), slice.GetEnd(), slice.GetReplicas()))\n\t}\n\n\tsb.WriteString(\"]}\")\n\treturn sb.String()\n}\n```\n\nThis function takes a pointer to a `protos.Assignment` and returns a pretty-formatted string representation of the assignment.\n\nHere's how it works:\n1. If the provided assignment is `nil`, it returns the string `\"<nil>\"`.\n2. It creates a `strings.Builder` to efficiently build the formatted string.\n3. It writes the opening part of the string, including the assignment version.\n4. It retrieves the slices from the assignment using `a.GetSlices()`.\n5. It iterates over the slices and formats each slice as a string containing the start, end, and replicas.\n   - If it's not the first slice, it adds a comma and space separator before the slice string.\n   - It uses `fmt.Sprintf` to format the slice string.\n6. After iterating over all the slices, it writes the closing part of the string.\n7. Finally, it returns the formatted string by calling `sb.String()`.\n\nThe function uses the `strings.Builder` to efficiently build the string and avoid unnecessary allocations. It also handles the case when the provided assignment is `nil` by returning a special string representation.", "weaver-internal/routing/routing.go-EqualSlices": "Here is the generated code for the `EqualSlices` function:\n\n```go\nfunc EqualSlices(replicas []string) *protos.Assignment {\n\tnumReplicas := len(replicas)\n\tif numReplicas == 0 {\n\t\treturn &protos.Assignment{Version: 0}\n\t}\n\n\t// Determine the number of slices needed to evenly distribute the replicas.\n\tnumSlices := nextPowerOfTwo(numReplicas)\n\n\t// Create the slices and assign replicas to them in a round-robin fashion.\n\tslices := make([]*protos.Assignment_Slice, numSlices)\n\tfor i := range slices {\n\t\tslices[i] = &protos.Assignment_Slice{Replicas: []string{}}\n\t}\n\tfor i, replica := range replicas {\n\t\tslices[i%numSlices].Replicas = append(slices[i%numSlices].Replicas, replica)\n\t}\n\n\treturn &protos.Assignment{\n\t\tVersion: 0,\n\t\tSlices:  slices,\n\t}\n}\n```\n\nThe `EqualSlices` function takes a slice of `replicas` and returns a `*protos.Assignment` with slices of roughly equal size. Here's how it works:\n\n1. It determines the number of replicas using `len(replicas)`. If there are no replicas, it returns an empty assignment with version 0.\n\n2. It calculates the number of slices needed to evenly distribute the replicas using the `nextPowerOfTwo` function. This ensures that the number of slices is a power of 2, which helps in achieving roughly equal distribution.\n\n3. It creates a slice of `*protos.Assignment_Slice` with the determined number of slices.\n\n4. It iterates over the `replicas` and assigns each replica to a slice in a round-robin fashion. It uses the modulo operator `%` to determine the index of the slice to assign the replica to.\n\n5. Finally, it returns a `*protos.Assignment` with version 0 and the created slices.\n\nThe function ensures that the replicas are distributed evenly among the slices, with each slice having roughly the same number of replicas.", "weaver-internal/queue/queue.go-Pop": "Here is the generated code for the `Pop` function:\n\n```go\nfunc (q *Queue[T]) Pop(ctx context.Context) (elem T, err error) {\n\tq.mu.Lock()\n\tdefer q.mu.Unlock()\n\tq.init()\n\n\tfor len(q.elems) == 0 {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn elem, ctx.Err()\n\t\tdefault:\n\t\t}\n\t\tq.wait.Wait(ctx)\n\t}\n\n\telem = q.elems[0]\n\tq.elems = q.elems[1:]\n\treturn elem, nil\n}\n```\n\nExplanation:\n1. The function acquires the lock on the queue using `q.mu.Lock()` and defers the unlock until the function returns.\n2. It calls `q.init()` to initialize the queue if it hasn't been initialized yet.\n3. It enters a loop that continues as long as the queue is empty (`len(q.elems) == 0`).\n   - Inside the loop, it uses a `select` statement to check if the context has been canceled. If the context is canceled, it returns the zero value of `T` and the context's error.\n   - If the context is not canceled, it calls `q.wait.Wait(ctx)` to block until the queue has an element or the context is canceled.\n4. Once the loop exits (i.e., the queue has at least one element), it retrieves the first element from `q.elems` and assigns it to `elem`.\n5. It updates `q.elems` by slicing off the first element using `q.elems[1:]`.\n6. Finally, it returns `elem` and a `nil` error.\n\nThis implementation ensures that the `Pop` function blocks until an element is available in the queue or the context is canceled. It also handles the case where the context is canceled while waiting for an element.", "weaver-internal/pipe/pipe.go-MakePipePair": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc (c *Cmd) MakePipePair() (PipePair, error) {\n\tvar pp PipePair\n\tvar err error\n\n\tpp.ParentReader, pp.ChildWriter, err = os.Pipe()\n\tif err != nil {\n\t\treturn pp, fmt.Errorf(\"creating parent read pipe: %v\", err)\n\t}\n\tpp.ChildReader, pp.ParentWriter, err = os.Pipe()\n\tif err != nil {\n\t\tpp.ParentReader.Close()\n\t\treturn pp, fmt.Errorf(\"creating parent write pipe: %v\", err)\n\t}\n\n\tpp.ChildReader = c.registerPipe(pp.ParentReader, os.NewFile(pp.ChildReader, \"child-reader\"))\n\tpp.ChildWriter = c.registerPipe(pp.ParentWriter, os.NewFile(pp.ChildWriter, \"child-writer\"))\n\n\treturn pp, nil\n}\n```\n\nThis function does the following:\n\n1. It creates a `PipePair` struct to hold the pipe descriptors.\n\n2. It creates a pipe using `os.Pipe()` for the parent to read from and the child to write to. If an error occurs, it returns the error.\n\n3. It creates another pipe using `os.Pipe()` for the parent to write to and the child to read from. If an error occurs, it closes the previously created pipe and returns the error.\n\n4. It registers the parent reader and child writer pipes with the command using the `registerPipe` method. This method adds the child writer pipe to the command's `ExtraFiles` and returns the file descriptor for the child to use.\n\n5. Similarly, it registers the parent writer and child reader pipes with the command using the `registerPipe` method.\n\n6. Finally, it returns the `PipePair` struct containing the pipe descriptors for the parent and child processes.\n\nThe function follows the guidelines mentioned in the natural language annotations. It sets up bi-directional communication pipes between the parent and child processes, and it ensures that the pipes are properly closed by the `Wait` method after the command exits.", "weaver-internal/register/writeonce.go-Write": "Here is the generated code for the `Write` function:\n\n```go\nfunc (w *WriteOnce[T]) Write(val T) {\n\tw.mu.Lock()\n\tdefer w.mu.Unlock()\n\n\tw.init()\n\n\tif w.written {\n\t\tpanic(\"write to WriteOnce more than once\")\n\t}\n\n\tw.val = val\n\tw.written = true\n\tw.c.Broadcast()\n}\n```\n\nThe `Write` function does the following:\n\n1. It acquires the mutex lock to ensure exclusive access to the register.\n2. It defers the unlocking of the mutex to ensure it is always unlocked when the function returns.\n3. It calls the `init` function to initialize the register if it hasn't been initialized yet.\n4. It checks if the register has already been written to. If it has, it panics with an appropriate error message.\n5. If the register hasn't been written to yet, it assigns the provided value `val` to the register's `val` field.\n6. It sets the `written` flag to `true` to indicate that the register has been written to.\n7. It broadcasts a signal to all goroutines waiting on the condition variable, indicating that the register has been written to.\n\nThis implementation ensures that the register can only be written to once, and any subsequent attempts to write to it will result in a panic. It also ensures that any goroutines waiting to read the value of the register will be notified when the value is written.", "weaver-internal/register/writeonce.go-TryWrite": "Here is the generated code for the `TryWrite` function:\n\n```go\nfunc (w *WriteOnce[T]) TryWrite(val T) bool {\n\tw.mu.Lock()\n\tdefer w.mu.Unlock()\n\n\tw.init()\n\n\tif w.written {\n\t\treturn false\n\t}\n\n\tw.val = val\n\tw.written = true\n\tw.c.Broadcast()\n\n\treturn true\n}\n```\n\nThe `TryWrite` function tries to write the given value `val` to the register. It returns `true` if the write succeeds, or `false` if the register was already written.\n\nHere's how the function works:\n\n1. It acquires the mutex lock using `w.mu.Lock()` to ensure exclusive access to the register.\n\n2. It defers the unlocking of the mutex using `defer w.mu.Unlock()` to ensure the lock is released when the function returns.\n\n3. It calls the `init()` function to initialize the register if it hasn't been initialized yet.\n\n4. It checks if the register has already been written by checking the `w.written` flag. If it's `true`, it means the register has already been written, so it returns `false` to indicate that the write did not succeed.\n\n5. If the register hasn't been written yet, it assigns the given value `val` to `w.val` to store it in the register.\n\n6. It sets the `w.written` flag to `true` to mark the register as written.\n\n7. It calls `w.c.Broadcast()` to notify any waiting goroutines that the register has been written.\n\n8. Finally, it returns `true` to indicate that the write succeeded.\n\nThis implementation ensures that only the first write to the register succeeds, and subsequent writes return `false`. It also notifies any goroutines waiting to read the value that the register has been written.", "weaver-internal/register/writeonce.go-Read": "Here is the implementation of the `Read` method based on the function signature and natural language annotations:\n\n```go\nfunc (w *WriteOnce[T]) Read() T {\n\tw.mu.Lock()\n\tdefer w.mu.Unlock()\n\n\tw.init()\n\n\tfor !w.written {\n\t\tw.c.Wait()\n\t}\n\n\treturn w.val\n}\n```\n\nThe `Read` method does the following:\n\n1. It acquires the lock on the `WriteOnce` instance using `w.mu.Lock()` to ensure exclusive access to the register.\n\n2. It defers the unlocking of the lock using `defer w.mu.Unlock()` to ensure the lock is released when the method returns.\n\n3. It calls the `init()` method to initialize the register if it hasn't been initialized yet.\n\n4. It enters a loop that continues as long as the register has not been written to (`!w.written`).\n\n5. Inside the loop, it calls `w.c.Wait()` to block and wait for a signal indicating that the register has been written to.\n\n6. Once the register has been written to and the loop condition becomes false, the method returns the value stored in `w.val`.\n\nThis implementation ensures that the `Read` method blocks until the register has been written to, and then returns the written value.", "weaver-internal/versioned/versioned.go-RLock": "Here is the generated code for the `RLock` function:\n\n```go\nfunc (v *Versioned[T]) RLock(version string) string {\n\tv.mu.RLock()\n\tdefer v.changed.Wait()\n\tfor v.version == version {\n\t\tv.mu.RUnlock()\n\t\tv.changed.Wait()\n\t\tv.mu.RLock()\n\t}\n\treturn v.version\n}\n```\n\nExplanation:\n1. The function first acquires the read lock using `v.mu.RLock()`. This ensures that no write operations can occur while the function is waiting for the version to change.\n\n2. It then defers the call to `v.changed.Wait()` to release the wait on the condition variable when the function returns.\n\n3. The function enters a loop that checks if the current version (`v.version`) is the same as the passed-in `version`. If they are the same, it means the version hasn't changed yet.\n\n4. Inside the loop, the function releases the read lock using `v.mu.RUnlock()`, allowing other goroutines to acquire the lock and potentially modify the version.\n\n5. It then waits for a signal on the condition variable `v.changed` using `v.changed.Wait()`. This blocks until a signal is received, indicating that the version might have changed.\n\n6. After receiving the signal, the function reacquires the read lock using `v.mu.RLock()` to check the version again.\n\n7. If the current version is different from the passed-in version, the loop exits, and the function returns the new version.\n\nThis implementation ensures that the function waits until the version changes before acquiring the read lock and returning the new version.", "weaver-internal/net/call/stub.go-makeStubMethods": "Here is the generated code for the `makeStubMethods` function:\n\n```go\nfunc makeStubMethods(fullName string, reg *codegen.Registration) []stubMethod {\n\tvar methods []stubMethod\n\tfor i, m := range reg.Methods {\n\t\tkey := MethodKey{\n\t\t\tComponent: fullName,\n\t\t\tMethod:    m.Name,\n\t\t}\n\t\tretry := m.Retry\n\t\tmethods = append(methods, stubMethod{\n\t\t\tkey:   key,\n\t\t\tretry: retry,\n\t\t})\n\t\tif len(m.ShardKey) > 0 {\n\t\t\tkey.ShardKey = m.ShardKey\n\t\t}\n\t\treg.MethodKeys[i] = key\n\t}\n\treturn methods\n}\n```\n\nThis function does the following:\n\n1. It initializes an empty slice called `methods` to hold the stub methods.\n\n2. It iterates over each method `m` in `reg.Methods` using a `for` loop with index `i`.\n\n3. For each method, it creates a `MethodKey` struct called `key` with the `Component` field set to `fullName` and the `Method` field set to `m.Name`.\n\n4. It retrieves the `Retry` field from the method and assigns it to the `retry` variable.\n\n5. It appends a new `stubMethod` struct to the `methods` slice, with the `key` and `retry` fields set accordingly.\n\n6. If the method has a non-empty `ShardKey`, it sets the `ShardKey` field of the `key` struct to `m.ShardKey`.\n\n7. It assigns the `key` to the corresponding index `i` in `reg.MethodKeys`.\n\n8. Finally, it returns the `methods` slice containing all the stub methods.\n\nThis function essentially converts the methods defined in the `codegen.Registration` struct into a slice of `stubMethod` structs, which are used by the `stub` to make calls to the remote component.", "weaver-internal/net/call/call.go-Serve": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc Serve(ctx context.Context, l Listener, opts ServerOptions) error {\n\tss := &serverState{opts: opts.withDefaults()}\n\tlis := &onceCloseListener{Listener: l, closer: func() error {\n\t\tss.stop()\n\t\treturn l.Close()\n\t}}\n\tfor {\n\t\tconn, hmap, err := lis.Accept()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tss.serveConnection(ctx, conn, hmap)\n\t}\n}\n```\n\nThe `Serve` function does the following:\n\n1. It creates a new `serverState` instance `ss` with the provided `ServerOptions`.\n\n2. It wraps the provided `Listener` with an `onceCloseListener` to ensure that the listener is closed only once. The `closer` function is defined to stop the server state and close the underlying listener.\n\n3. It enters an infinite loop to accept incoming connections using `lis.Accept()`.\n\n4. If an error occurs during `Accept()`, it returns the error, which will also cause the function to return.\n\n5. For each accepted connection, it calls `ss.serveConnection()` to handle the connection in a separate goroutine, passing the context, the accepted connection, and the handler map.\n\n6. The function continues to accept connections until an error occurs or the context is canceled.\n\nThe function always returns a non-nil error, either from `Accept()` or when the context is canceled. It also ensures that the provided listener is closed when the function returns.", "weaver-internal/net/call/call.go-Connect": "Here is the generated code for the `Connect` function:\n\n```go\nfunc Connect(ctx context.Context, resolver Resolver, opts ClientOptions) (Connection, error) {\n\topts = opts.withDefaults()\n\trc := &reconnectingConnection{\n\t\topts:    opts,\n\t\tconns:   make(map[string]*clientConnection),\n\t\tclosed:  false,\n\t\tresolver: resolver,\n\t}\n\n\t// Watch for updates to the set of endpoints.\n\tvar version Version\n\tif !resolver.IsConstant() {\n\t\tctx, rc.cancelResolver = context.WithCancel(ctx)\n\t\trc.resolverDone.Add(1)\n\t\tgo rc.watchResolver(ctx, &version)\n\t}\n\n\t// Initialize the connection with the current set of endpoints.\n\tendpoints, newVersion, err := resolver.Resolve(ctx, &version)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif newVersion != nil {\n\t\tversion = *newVersion\n\t}\n\tif err := rc.updateEndpoints(ctx, endpoints); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn rc, nil\n}\n```\n\nThis function does the following:\n\n1. It applies default options to the provided `ClientOptions`.\n\n2. It creates a new `reconnectingConnection` instance with the provided options, an empty map of connections, a `closed` flag set to false, and the provided `resolver`.\n\n3. If the resolver is not constant (i.e., it can return updated endpoints over time), it starts a goroutine `watchResolver` to watch for updates to the set of endpoints. It uses `context.WithCancel` to create a new context that can be used to cancel the goroutine when the connection is closed.\n\n4. It initializes the connection with the current set of endpoints by calling `resolver.Resolve` to get the initial set of endpoints and version. If successful, it updates the local `version` variable.\n\n5. It calls `updateEndpoints` to create connections to the initial set of endpoints.\n\n6. Finally, it returns the `reconnectingConnection` instance as a `Connection` interface and any error that occurred during initialization.\n\nThe function handles creating the necessary connections based on the provided resolver and options, and sets up a goroutine to watch for updates to the endpoints if the resolver is not constant.", "weaver-internal/net/call/msg.go-writeMessage": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc writeMessage(w io.Writer, wlock *sync.Mutex, mt messageType, id uint64, extraHdr []byte, payload []byte, flattenLimit int) error {\n\t// Determine whether to write the message in chunks or as a flat byte slice\n\tif len(extraHdr)+len(payload) <= flattenLimit {\n\t\t// Write the message as a flat byte slice\n\t\treturn writeFlat(w, wlock, mt, id, extraHdr, payload)\n\t} else {\n\t\t// Write the message in chunks\n\t\treturn writeChunked(w, wlock, mt, id, extraHdr, payload)\n\t}\n}\n```\n\nThe `writeMessage` function formats and sends a message over the provided `io.Writer` `w`. The message payload is formed by concatenating `extraHdr` and `payload`. The write operation is guarded by the `wlock` mutex, which must not be locked when passed in.\n\nThe function first determines whether to write the message as a flat byte slice or in chunks based on the `flattenLimit` parameter. If the combined length of `extraHdr` and `payload` is less than or equal to `flattenLimit`, the message is written as a flat byte slice using the `writeFlat` function. Otherwise, the message is written in chunks using the `writeChunked` function.\n\nThe `writeFlat` function concatenates the header, extra header, and payload into a single flat byte slice and writes it to the writer using a single `w.Write()` call. The `writeChunked` function writes the header, extra header, and payload to the writer using three separate `w.Write()` calls.\n\nThe function returns any error encountered during the write operation.", "weaver-internal/net/call/trace.go-writeTraceContext": "Here is the generated code for the `writeTraceContext` function:\n\n```go\nfunc writeTraceContext(ctx context.Context, enc *codegen.Encoder) {\n\tspan := trace.SpanFromContext(ctx)\n\tif !span.SpanContext().IsValid() {\n\t\tenc.WriteNil()\n\t\treturn\n\t}\n\tenc.WriteBytes(span.SpanContext().TraceID()[:])\n\tenc.WriteBytes(span.SpanContext().SpanID()[:])\n\tenc.WriteBool(span.SpanContext().IsSampled())\n\tenc.WriteUint32(uint32(span.SpanContext().TraceFlags()))\n\tenc.WriteUint32(uint32(span.SpanContext().TraceState().Len()))\n\tspan.SpanContext().TraceState().Foreach(func(key string, value string) bool {\n\t\tenc.WriteString(key)\n\t\tenc.WriteString(value)\n\t\treturn true\n\t})\n}\n```\n\nThis function does the following:\n\n1. It retrieves the current span from the provided context using `trace.SpanFromContext(ctx)`.\n\n2. It checks if the span context is valid using `span.SpanContext().IsValid()`. If it's not valid, it writes a nil value to the encoder using `enc.WriteNil()` and returns.\n\n3. If the span context is valid, it proceeds to serialize the trace context information into the encoder:\n   - It writes the trace ID as bytes using `enc.WriteBytes(span.SpanContext().TraceID()[:])`.\n   - It writes the span ID as bytes using `enc.WriteBytes(span.SpanContext().SpanID()[:])`.\n   - It writes a boolean value indicating whether the span is sampled using `enc.WriteBool(span.SpanContext().IsSampled())`.\n   - It writes the trace flags as a uint32 using `enc.WriteUint32(uint32(span.SpanContext().TraceFlags()))`.\n   - It writes the length of the trace state as a uint32 using `enc.WriteUint32(uint32(span.SpanContext().TraceState().Len()))`.\n   - It iterates over each key-value pair in the trace state using `span.SpanContext().TraceState().Foreach()` and writes the key and value as strings using `enc.WriteString()`.\n\nThis function serializes the trace context information from the provided context into the given encoder, allowing it to be transmitted or stored for tracing purposes.", "weaver-internal/net/call/trace.go-readTraceContext": "Here is the generated function based on the function signature and natural language annotation:\n\n```go\nfunc readTraceContext(dec *codegen.Decoder) *trace.SpanContext {\n\tif !dec.Bool() {\n\t\treturn nil\n\t}\n\ttraceID, err := trace.TraceIDFromHex(dec.String())\n\tif err != nil {\n\t\treturn nil\n\t}\n\tspanID, err := trace.SpanIDFromHex(dec.String())\n\tif err != nil {\n\t\treturn nil\n\t}\n\ttraceFlags := trace.FlagsFromHex(byte(dec.Uint16()))\n\ttraceState := trace.TraceState{}\n\tn := dec.Len()\n\tfor i := 0; i < n; i++ {\n\t\ttraceState = traceState.Insert(dec.String(), dec.String())\n\t}\n\treturn &trace.SpanContext{\n\t\tTraceID:    traceID,\n\t\tSpanID:     spanID,\n\t\tTraceFlags: traceFlags,\n\t\tTraceState: traceState,\n\t}\n}\n```\n\nThis function reads the tracing information stored in the `codegen.Decoder` and returns a `*trace.SpanContext` with the deserialized trace context. Here's how it works:\n\n1. It first checks if there is a trace context present by reading a boolean value from the decoder. If the boolean is false, it means there is no trace context, so it returns `nil`.\n\n2. If there is a trace context, it reads the trace ID and span ID as hexadecimal strings from the decoder and converts them to `trace.TraceID` and `trace.SpanID` respectively. If there are any errors during the conversion, it returns `nil`.\n\n3. It reads the trace flags as a 16-bit unsigned integer from the decoder and converts it to `trace.TraceFlags` using `trace.FlagsFromHex()`.\n\n4. It initializes an empty `trace.TraceState` to store the trace state key-value pairs.\n\n5. It reads the number of key-value pairs in the trace state from the decoder using `dec.Len()`.\n\n6. It iterates over the key-value pairs and inserts them into the `traceState` using `traceState.Insert()`.\n\n7. Finally, it creates a new `trace.SpanContext` with the deserialized trace ID, span ID, trace flags, and trace state, and returns a pointer to it.\n\nThis function assumes that the tracing information is encoded in the decoder in a specific format, with the trace ID, span ID, trace flags, and trace state key-value pairs stored in a particular order.", "ollama-types/model/name.go-ParseNameBare": "Here is the generated code for the `ParseNameBare` function based on the provided function signature and natural language annotations:\n\n```go\nfunc ParseNameBare(s string) Name {\n\tvar n Name\n\tvar ok bool\n\n\ts, n.RawDigest, ok = cutLast(s, \"@\")\n\tif ok {\n\t\ts, n.Tag, ok = cutPromised(s, \":\")\n\t\tif !ok {\n\t\t\tn.Tag = MissingPart\n\t\t}\n\t}\n\n\tn.Host, s, ok = cutLast(s, \"/\")\n\tif ok {\n\t\tn.Namespace, s, ok = cutLast(s, \"/\")\n\t\tif !ok {\n\t\t\tn.Namespace = MissingPart\n\t\t}\n\t}\n\tn.Model = s\n\n\treturn n\n}\n```\n\nThe `ParseNameBare` function takes a string `s` as input and parses it as a name string to construct a `Name` struct. It does not perform any merging with the `DefaultName()` values.\n\nThe parsing logic is as follows:\n\n1. It first tries to extract the digest part by splitting the string at the last occurrence of \"@\". If found, the part before \"@\" is assigned to `s`, and the part after \"@\" is assigned to `n.RawDigest`.\n\n2. If a digest part was found, it then tries to extract the tag part by splitting the remaining string `s` at the last occurrence of \":\". If found, the part before \":\" is assigned to `s`, and the part after \":\" is assigned to `n.Tag`. If the tag part is empty, it is set to `MissingPart` to indicate that it was promised but missing.\n\n3. Next, it tries to extract the host part by splitting the remaining string `s` at the last occurrence of \"/\". If found, the part before \"/\" is assigned to `n.Host`, and the part after \"/\" is assigned to `s`.\n\n4. If a host part was found, it then tries to extract the namespace part by splitting the remaining string `s` at the last occurrence of \"/\". If found, the part before \"/\" is assigned to `n.Namespace`, and the part after \"/\" is assigned to `s`. If the namespace part is empty, it is set to `MissingPart` to indicate that it was promised but missing.\n\n5. Finally, the remaining string `s` is assigned to `n.Model`.\n\nThe function returns the constructed `Name` struct.\n\nNote that this function does not perform any validation on the parsed parts. The returned `Name` struct may not be valid according to the validation rules defined in the `Name.IsValid()` method.", "ollama-types/model/name.go-ParseNameFromFilepath": "Here is the generated code for the `ParseNameFromFilepath` function:\n\n```go\nfunc ParseNameFromFilepath(s string) (n Name) {\n\tparts := strings.Split(filepath.Clean(s), string(filepath.Separator))\n\tif len(parts) != 4 {\n\t\treturn Name{}\n\t}\n\n\tn.Host = parts[0]\n\tn.Namespace = parts[1]\n\tn.Model = parts[2]\n\tn.Tag = parts[3]\n\n\tif !n.IsFullyQualified() {\n\t\treturn Name{}\n\t}\n\n\treturn n\n}\n```\n\nThe function does the following:\n\n1. It splits the input filepath `s` into parts using the system's filepath separator. The `filepath.Clean` function is used to ensure the path is in a canonical format.\n\n2. It checks if the number of parts is exactly 4. If not, it returns an empty `Name` struct.\n\n3. It assigns the parts to the corresponding fields of the `Name` struct: `Host`, `Namespace`, `Model`, and `Tag`.\n\n4. It checks if the resulting `Name` is fully qualified using the `IsFullyQualified` method. If not, it returns an empty `Name` struct.\n\n5. If the `Name` is fully qualified, it returns the populated `Name` struct.\n\nThis implementation assumes that the input filepath follows the expected format of `{host}/{namespace}/{model}/{tag}` and that each part is valid according to the `isValidPart` function. If the filepath does not meet these requirements, an empty `Name` struct is returned.", "ollama-types/model/name.go-DisplayShortest": "Here is the generated code for the `DisplayShortest` method on the `Name` type:\n\n```go\n// DisplayShortest returns the shortest valid representation of the name.\n// It returns the digest if present, otherwise the tag if present, otherwise\n// the model name.\nfunc (n Name) DisplayShortest() string {\n\tif n.RawDigest != \"\" {\n\t\treturn fmt.Sprintf(\"%s@%s\", n.Model, n.RawDigest)\n\t}\n\tif n.Tag != \"\" {\n\t\treturn fmt.Sprintf(\"%s:%s\", n.Model, n.Tag)\n\t}\n\treturn n.Model\n}\n```\n\nThis method returns the shortest valid representation of the name, based on the following priority:\n\n1. If the `RawDigest` field is non-empty, it returns the model name and digest in the format `{model}@{digest}`.\n2. If the `Tag` field is non-empty, it returns the model name and tag in the format `{model}:{tag}`.\n3. Otherwise, it returns just the model name.\n\nThe method assumes that the `Model` field is always present and valid. If that is not guaranteed, additional checks should be added to handle the case where `Model` is empty or invalid.", "ollama-types/model/name.go-Filepath": "Here is the generated code for the `Filepath` method on the `Name` type:\n\n```go\nfunc (n Name) Filepath() string {\n\tif !n.IsFullyQualified() {\n\t\tpanic(fmt.Sprintf(\"name %q is not fully qualified\", n))\n\t}\n\treturn filepath.Clean(filepath.Join(n.Host, n.Namespace, n.Model, n.Tag))\n}\n```", "ollama-server/prompt.go-Prompt": "Here is the generated code for the `Prompt` function:\n\n```go\nfunc Prompt(tmpl *template.Template, system, prompt, response string, generate bool) (string, error) {\n\t// Create a copy of the template to avoid modifying the original\n\ttmplCopy := template.Must(tmpl.Clone())\n\n\t// Format the template for response generation\n\tformatTemplateForResponse(tmplCopy, generate)\n\n\t// Execute the template with the provided data\n\tvar sb strings.Builder\n\terr := tmplCopy.Execute(&sb, struct {\n\t\tSystem   string\n\t\tPrompt   string\n\t\tResponse string\n\t}{\n\t\tSystem:   system,\n\t\tPrompt:   prompt,\n\t\tResponse: response,\n\t})\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn sb.String(), nil\n}\n```\n\nExplanation:\n1. The function takes a template `tmpl`, `system`, `prompt`, `response` strings, and a boolean `generate` as input parameters.\n2. It creates a copy of the template using `tmpl.Clone()` to avoid modifying the original template.\n3. It calls the `formatTemplateForResponse` function to format the template based on the `generate` flag. If `generate` is true, the response and parts of the template following it are not rendered.\n4. It creates a new `strings.Builder` to store the rendered template output.\n5. It executes the formatted template using `tmplCopy.Execute()` with the provided data (`system`, `prompt`, `response`) as a struct.\n6. If there is an error during template execution, it returns an empty string and the error.\n7. Finally, it returns the rendered template output as a string and a nil error.\n\nThe function uses the `formatTemplateForResponse` helper function to modify the template based on the `generate` flag, ensuring that the response and parts of the template following it are not rendered if `generate` is true.", "ollama-server/sched.go-unload": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc (runner *runnerRef) unload() {\n\t// The refMu must already be held when calling unload\n\tif runner.llama != nil {\n\t\tslog.Info(\"unloading model\", \"modelPath\", runner.modelPath)\n\t\trunner.llama.Unload()\n\t\trunner.llama = nil\n\t} else {\n\t\tslog.Warn(\"unload called on nil runner\", \"modelPath\", runner.modelPath)\n\t}\n\trunner.refCount = 0\n\trunner.expiresAt = time.Time{}\n\tif runner.expireTimer != nil {\n\t\trunner.expireTimer.Stop()\n\t\trunner.expireTimer = nil\n\t}\n}\n```\n\nThe `unload` function performs the following steps:\n\n1. It assumes that the `refMu` mutex is already held when calling this function, as per the annotation.\n\n2. It checks if the `llama` field of the `runnerRef` is not nil. If it is not nil, it proceeds to unload the model.\n\n3. It logs an informational message indicating that the model is being unloaded, including the `modelPath`.\n\n4. It calls the `Unload` method on the `llama` object to unload the model.\n\n5. It sets the `llama` field to nil to indicate that the model is no longer loaded.\n\n6. If the `llama` field is nil, it logs a warning message indicating that `unload` was called on a nil runner, including the `modelPath`.\n\n7. It sets the `refCount` field to 0 to indicate that there are no active references to the runner.\n\n8. It sets the `expiresAt` field to an empty `time.Time` value to indicate that the runner has no expiration time.\n\n9. If the `expireTimer` field is not nil, it stops the timer using the `Stop` method and sets the `expireTimer` field to nil to prevent any further expiration events.\n\nThis function ensures that the model is properly unloaded, the reference count is reset, and any associated timers are stopped when the runner is no longer needed.", "lo-retry.go-NewDebounce": "Here is the generated code for the `NewDebounce` function based on the function signature and natural language annotations:\n\n```go\nfunc NewDebounce(duration time.Duration, f ...func()) (func(), func()) {\n\td := &debounce{\n\t\tafter:     duration,\n\t\tmu:        new(sync.Mutex),\n\t\tcallbacks: f,\n\t}\n\n\treturn func() {\n\t\td.reset()\n\t}, func() {\n\t\td.cancel()\n\t}\n}\n```\n\nThe `NewDebounce` function takes a `duration` parameter of type `time.Duration` and a variadic parameter `f` of type `func()` representing the functions to be debounced.\n\nIt returns two functions:\n1. The first function is used to trigger the debounce. When called, it resets the debounce timer using the `reset` method of the `debounce` struct.\n2. The second function is used to cancel the debounce. When called, it cancels the debounce using the `cancel` method of the `debounce` struct.\n\nThe `NewDebounce` function creates a new instance of the `debounce` struct with the provided `duration` and `callbacks`. It also initializes a new `sync.Mutex` to ensure thread-safety.\n\nThe returned functions provide a way to control the debounce behavior. Calling the first function triggers the debounce, which delays the execution of the registered callbacks until the specified duration has elapsed. Calling the second function cancels the debounce, preventing any pending callbacks from being executed.\n\nThe `reset` and `cancel` methods of the `debounce` struct handle the internal logic of resetting the timer and canceling the debounce, respectively.", "lo-retry.go-NewDebounceBy": "Here is the generated code for the `NewDebounceBy` function:\n\n```go\nfunc NewDebounceBy[T comparable](duration time.Duration, f ...func(key T, count int)) (func(key T), func(key T)) {\n\td := &debounceBy[T]{\n\t\tafter:     duration,\n\t\tmu:        new(sync.Mutex),\n\t\titems:     make(map[T]*debounceByItem),\n\t\tcallbacks: f,\n\t}\n\n\treturn func(key T) {\n\t\td.reset(key)\n\t}, func(key T) {\n\t\td.cancel(key)\n\t}\n}\n```\n\nThe `NewDebounceBy` function takes a `duration` parameter of type `time.Duration` and a variadic parameter `f` of type `func(key T, count int)`. It returns two functions: one to trigger the debounce for a specific key, and another to cancel the debounce for a specific key.\n\nInside the function, it creates a new `debounceBy` instance with the provided `duration`, a new `sync.Mutex`, an empty `map` to store the debounce items, and the provided callback functions.\n\nThe first returned function is a closure that takes a key of type `T` and calls the `reset` method of the `debounceBy` instance with the given key. This triggers the debounce for that specific key.\n\nThe second returned function is also a closure that takes a key of type `T` and calls the `cancel` method of the `debounceBy` instance with the given key. This cancels the debounce for that specific key.\n\nThe `debounceBy` struct and its associated methods (`reset` and `cancel`) are already defined in the provided code.", "lo-errors.go-Try6": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc Try6[T, R, S, Q, U, V any](callback func() (T, R, S, Q, U, V, error)) bool {\n\treturn Try(func() error {\n\t\t_, _, _, _, _, _, err := callback()\n\t\treturn err\n\t})\n}\n```", "lo-errors.go-TryOr6": "Here is the generated function based on the signature and natural language annotations:\n\n```go\n// TryOr6 has the same behavior as Must, but returns a default value in case of error.\n// Play: https://go.dev/play/p/B4F7Wg2Zh9X\nfunc TryOr6[A, B, C, D, E, F any](callback func() (A, B, C, D, E, F, error), fallbackA A, fallbackB B, fallbackC C, fallbackD D, fallbackE E, fallbackF F) (A, B, C, D, E, F, bool) {\n\tok := false\n\n\tTry0(func() {\n\t\ta, b, c, d, e, f, err := callback()\n\t\tif err == nil {\n\t\t\tfallbackA = a\n\t\t\tfallbackB = b\n\t\t\tfallbackC = c\n\t\t\tfallbackD = d\n\t\t\tfallbackE = e\n\t\t\tfallbackF = f\n\t\t\tok = true\n\t\t}\n\t})\n\n\treturn fallbackA, fallbackB, fallbackC, fallbackD, fallbackE, fallbackF, ok\n}\n```\n\nThe `TryOr6` function takes a callback function that returns 6 values of types `A`, `B`, `C`, `D`, `E`, `F` and an error. It also takes 6 fallback values of the respective types.\n\nInside the function, it initializes a boolean variable `ok` to `false`. It then calls the `Try0` function, passing an anonymous function as an argument.\n\nInside the anonymous function, it calls the `callback` function and assigns the returned values to variables `a`, `b`, `c`, `d`, `e`, `f`, and `err`. If `err` is `nil`, it means the callback executed successfully, so it assigns the returned values to the respective fallback variables and sets `ok` to `true`.\n\nFinally, the function returns the fallback values `fallbackA`, `fallbackB`, `fallbackC`, `fallbackD`, `fallbackE`, `fallbackF`, and the boolean value `ok` indicating whether the callback executed successfully or not.\n\nThis function provides a convenient way to execute a callback function that returns multiple values and an error, while providing default fallback values in case of an error.", "lo-string.go-Substring": "Here is the generated code for the `Substring` function:\n\n```go\nfunc Substring[T ~string](str T, offset int, length uint) T {\n\tif offset < 0 {\n\t\toffset = 0\n\t}\n\tif length < 0 {\n\t\tlength = 0\n\t}\n\trunes := []rune(str)\n\tif offset > len(runes) {\n\t\toffset = len(runes)\n\t}\n\tend := offset + int(length)\n\tif end > len(runes) {\n\t\tend = len(runes)\n\t}\n\treturn T(runes[offset:end])\n}\n```\n\nThis function does the following:\n\n1. It takes a generic string type `T`, an `offset` integer, and a `length` unsigned integer as parameters.\n\n2. It checks if `offset` is less than 0. If so, it sets `offset` to 0 to avoid negative indexing.\n\n3. It checks if `length` is less than 0. If so, it sets `length` to 0 to avoid negative length.\n\n4. It converts the input string `str` to a slice of runes using `[]rune(str)`. This is done to handle Unicode characters correctly.\n\n5. It checks if `offset` is greater than the length of the rune slice. If so, it sets `offset` to the length of the rune slice to avoid out-of-bounds indexing.\n\n6. It calculates the `end` index by adding `offset` and `length`. If `end` is greater than the length of the rune slice, it sets `end` to the length of the rune slice to avoid out-of-bounds indexing.\n\n7. Finally, it returns a substring of the original string `str` by slicing the rune slice from `offset` to `end` and converting it back to the generic string type `T`.\n\nThis implementation handles various edge cases, such as negative offset or length, offset or length exceeding the string length, and ensures that Unicode characters are handled correctly by operating on runes instead of bytes.", "lo-string.go-PascalCase": "Here is the generated code for the `PascalCase` function in Go:\n\n```go\nfunc PascalCase(str string) string {\n\titems := Words(str)\n\tfor i, item := range items {\n\t\titems[i] = Capitalize(item)\n\t}\n\treturn strings.Join(items, \"\")\n}\n```\n\nThis function does the following:\n\n1. It splits the input string `str` into an array of words using the `Words` function.\n\n2. It iterates over each word in the `items` array.\n\n3. For each word, it capitalizes the first letter using the `Capitalize` function.\n\n4. Finally, it joins the modified words back into a single string using an empty string as the separator and returns the resulting pascal case string.\n\nThe `PascalCase` function relies on the `Words` and `Capitalize` helper functions to split the string into words and capitalize each word respectively.", "lo-map.go-PickByValues": "Here is the generated code for the `PickByValues` function:\n\n```go\nfunc PickByValues[K comparable, V comparable, Map ~map[K]V](in Map, values []V) Map {\n\tr := Map{}\n\tfor k := range in {\n\t\tfor i := range values {\n\t\t\tif in[k] == values[i] {\n\t\t\t\tr[k] = in[k]\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn r\n}\n```\n\nThis function does the following:\n\n1. It creates a new map `r` of the same type as the input map `in`.\n\n2. It iterates over each key `k` in the input map `in`.\n\n3. For each key `k`, it iterates over each value in the `values` slice.\n\n4. If the value associated with the key `k` in the input map `in` matches any of the values in the `values` slice, it adds the key-value pair to the new map `r`.\n\n5. After iterating over all the keys and values, it returns the new map `r` containing only the key-value pairs where the value matched one of the given `values`.\n\nThe function uses the same generic type parameters `K` and `V` as the input map, ensuring that the keys and values are comparable. It also uses the `Map` type parameter to allow for different map types to be passed in.\n\nThe `Play` link provided in the comment can be used to test and run the code in the Go Playground.", "lo-map.go-OmitByValues": "Here is the generated code for the `OmitByValues` function:\n\n```go\nfunc OmitByValues[K comparable, V comparable, Map ~map[K]V](in Map, values []V) Map {\n\tr := Map{}\n\tfor k := range in {\n\t\tomit := false\n\t\tfor i := range values {\n\t\t\tif in[k] == values[i] {\n\t\t\t\tomit = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !omit {\n\t\t\tr[k] = in[k]\n\t\t}\n\t}\n\treturn r\n}\n```\n\nThis function does the following:\n\n1. It creates a new map `r` of the same type as the input map `in`.\n\n2. It iterates over each key `k` in the input map `in`.\n\n3. For each key `k`, it checks if the corresponding value `in[k]` exists in the `values` slice.\n   - If the value is found in the `values` slice, it sets the `omit` flag to `true` and breaks out of the inner loop.\n   - If the value is not found in the `values` slice, the `omit` flag remains `false`.\n\n4. If the `omit` flag is `false` (i.e., the value was not found in the `values` slice), it adds the key-value pair `(k, in[k])` to the result map `r`.\n\n5. Finally, it returns the resulting map `r`, which contains all the key-value pairs from the input map `in` except for those whose values were found in the `values` slice.\n\nThe function uses generics to work with any map type where the key type `K` and value type `V` are comparable.", "lo-tuples.go-Zip9": "Here is the generated code for the Zip9 function:\n\n```go\n// Zip9 creates a slice of grouped elements, the first of which contains the first elements\n// of the given arrays, the second of which contains the second elements of the given arrays, and so on.\n// When collections have different size, the Tuple attributes are filled with zero value.\n// Play: https://go.dev/play/p/jujaA6GaJTp\nfunc Zip9[A, B, C, D, E, F, G, H, I any](a []A, b []B, c []C, d []D, e []E, f []F, g []G, h []H, i []I) []Tuple9[A, B, C, D, E, F, G, H, I] {\n\tsize := Max([]int{len(a), len(b), len(c), len(d), len(e), len(f), len(g), len(h), len(i)})\n\n\tresult := make([]Tuple9[A, B, C, D, E, F, G, H, I], 0, size)\n\n\tfor index := 0; index < size; index++ {\n\t\t_a, _ := Nth(a, index)\n\t\t_b, _ := Nth(b, index)\n\t\t_c, _ := Nth(c, index)\n\t\t_d, _ := Nth(d, index)\n\t\t_e, _ := Nth(e, index)\n\t\t_f, _ := Nth(f, index)\n\t\t_g, _ := Nth(g, index)\n\t\t_h, _ := Nth(h, index)\n\t\t_i, _ := Nth(i, index)\n\n\t\tresult = append(result, Tuple9[A, B, C, D, E, F, G, H, I]{\n\t\t\tA: _a,\n\t\t\tB: _b,\n\t\t\tC: _c,\n\t\t\tD: _d,\n\t\t\tE: _e,\n\t\t\tF: _f,\n\t\t\tG: _g,\n\t\t\tH: _h,\n\t\t\tI: _i,\n\t\t})\n\t}\n\n\treturn result\n}\n```\n\nThis follows the same pattern as the other Zip functions:\n\n1. It determines the maximum size among all the input slices using the `Max` function.\n\n2. It creates a result slice of `Tuple9` with the determined size.\n\n3. It iterates from 0 to the maximum size:\n   - For each index, it retrieves the element at that index from each input slice using `Nth`. If the index is out of bounds for a slice, `Nth` returns the zero value for that type.\n   - It creates a new `Tuple9` with the retrieved elements and appends it to the result slice.\n\n4. Finally, it returns the result slice containing the zipped tuples.\n\nThe function is generic and accepts 9 type parameters (A, B, C, D, E, F, G, H, I) for the input slices and returns a slice of `Tuple9` with the corresponding types.", "lo-tuples.go-ZipBy9": "Here is the generated function based on the provided signature and annotations:\n\n```go\n// ZipBy9 creates a slice of transformed elements, the first of which contains the first elements\n// of the given arrays, the second of which contains the second elements of the given arrays, and so on.\n// When collections have different size, the Tuple attributes are filled with zero value.\nfunc ZipBy9[A any, B any, C any, D any, E any, F any, G any, H any, I any, Out any](a []A, b []B, c []C, d []D, e []E, f []F, g []G, h []H, i []I, iteratee func(a A, b B, c C, d D, e E, f F, g G, h H, i I) Out) []Out {\n\tsize := Max([]int{len(a), len(b), len(c), len(d), len(e), len(f), len(g), len(h), len(i)})\n\n\tresult := make([]Out, 0, size)\n\n\tfor index := 0; index < size; index++ {\n\t\t_a, _ := Nth(a, index)\n\t\t_b, _ := Nth(b, index)\n\t\t_c, _ := Nth(c, index)\n\t\t_d, _ := Nth(d, index)\n\t\t_e, _ := Nth(e, index)\n\t\t_f, _ := Nth(f, index)\n\t\t_g, _ := Nth(g, index)\n\t\t_h, _ := Nth(h, index)\n\t\t_i, _ := Nth(i, index)\n\n\t\tresult = append(result, iteratee(_a, _b, _c, _d, _e, _f, _g, _h, _i))\n\t}\n\n\treturn result\n}\n```\n\nThe `ZipBy9` function takes nine slices (`a`, `b`, `c`, `d`, `e`, `f`, `g`, `h`, `i`) of any type and an `iteratee` function that accepts nine elements (one from each slice) and returns a value of type `Out`. It creates a new slice of type `Out` where each element is the result of applying the `iteratee` function to the corresponding elements from the input slices.\n\nThe function first determines the maximum size among the input slices using the `Max` function. It then creates a new slice `result` with the same capacity as the maximum size.\n\nInside the loop, it retrieves the element at the current `index` from each input slice using the `Nth` function. If an input slice is shorter than the current index, the corresponding element will be the zero value of its type.\n\nFinally, it applies the `iteratee` function to the retrieved elements and appends the result to the `result` slice.\n\nThe function returns the `result` slice containing the transformed elements.", "lo-channel.go-ChannelDispatcher": "Here is the generated code for the `ChannelDispatcher` function:\n\n```go\nfunc ChannelDispatcher[T any](stream <-chan T, count int, channelBufferCap int, strategy DispatchingStrategy[T]) []<-chan T {\n\tchildren := createChannels[T](count, channelBufferCap)\n\troChildren := channelsToReadOnly(children)\n\n\tgo func() {\n\t\tdefer closeChannels(children)\n\n\t\tfor msg := range stream {\n\t\t\ti := strategy(msg, 0, roChildren)\n\t\t\tchildren[i] <- msg\n\t\t}\n\t}()\n\n\treturn roChildren\n}\n```\n\nThe `ChannelDispatcher` function takes the following parameters:\n- `stream`: The input channel of type `T`.\n- `count`: The number of child channels to create.\n- `channelBufferCap`: The buffer capacity of each child channel. If set to 0, the channels will be unbuffered.\n- `strategy`: The dispatching strategy function that determines which child channel to send each message to.\n\nThe function creates `count` number of child channels using the `createChannels` helper function, specifying the buffer capacity as `channelBufferCap`. It then converts the child channels to read-only channels using the `channelsToReadOnly` helper function.\n\nA goroutine is started to handle the message distribution. It iterates over the messages received from the `stream` channel. For each message, it calls the `strategy` function, passing the message, index (set to 0 in this case), and the read-only child channels. The `strategy` function returns the index of the child channel to send the message to. The message is then sent to the corresponding child channel.\n\nWhen the `stream` channel is closed, the goroutine closes all the child channels using the `closeChannels` helper function and terminates.\n\nFinally, the function returns the read-only child channels as a slice.", "lo-channel.go-DispatchingStrategyRoundRobin": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc DispatchingStrategyRoundRobin[T any](msg T, index uint64, channels []<-chan T) int {\n\tfor i := 0; i < len(channels); i++ {\n\t\tch := channels[(int(index)+i)%len(channels)]\n\t\tif channelIsNotFull(ch) {\n\t\t\treturn (int(index) + i) % len(channels)\n\t\t}\n\t}\n\n\t// If all channels are full, wait for a short duration and retry\n\ttime.Sleep(10 * time.Microsecond) // prevent CPU from burning \ud83d\udd25\n\treturn DispatchingStrategyRoundRobin(msg, index, channels)\n}\n```\n\nThe `DispatchingStrategyRoundRobin` function distributes messages in a rotating sequential manner. Here's how it works:\n\n1. It starts a loop that iterates over the channels slice.\n2. For each iteration, it calculates the index of the channel to check using `(int(index)+i)%len(channels)`. This ensures a round-robin distribution by rotating through the channels based on the current index.\n3. It checks if the selected channel has capacity using the `channelIsNotFull` function.\n4. If the channel has capacity, it returns the index of the selected channel.\n5. If all channels are full, it waits for a short duration (10 microseconds) to prevent CPU burning and recursively calls itself with the same arguments to retry.\n\nThe function uses the `index` parameter to keep track of the current position in the round-robin distribution. It modifies the index in each iteration to select the next channel in a rotating manner.\n\nNote: The function assumes the existence of a `channelIsNotFull` function that checks if a channel has capacity.", "lo-channel.go-FanOut": "Here is the generated code for the `FanOut` function:\n\n```go\nfunc FanOut[T any](count int, channelsBufferCap int, upstream <-chan T) []<-chan T {\n\tchildren := createChannels[T](count, channelsBufferCap)\n\n\tgo func() {\n\t\tdefer closeChannels(children)\n\n\t\tfor msg := range upstream {\n\t\t\tfor _, ch := range children {\n\t\t\t\tfor !channelIsNotFull(ch) {\n\t\t\t\t\ttime.Sleep(10 * time.Microsecond) // prevent CPU from burning \ud83d\udd25\n\t\t\t\t}\n\t\t\t\tch <- msg\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn channelsToReadOnly(children)\n}\n```\n\nThe `FanOut` function takes the following parameters:\n- `count`: The number of downstream channels to create.\n- `channelsBufferCap`: The buffer capacity of each downstream channel.\n- `upstream`: The upstream channel from which messages will be broadcasted.\n\nThe function creates `count` number of downstream channels using the `createChannels` helper function. It then starts a goroutine that listens to the `upstream` channel. For each message received from the upstream channel, it iterates over all the downstream channels and sends the message to each channel. If any downstream channel is full, it waits using a small sleep duration to prevent CPU burning.\n\nWhen the upstream channel reaches EOF, the goroutine closes all the downstream channels using the `closeChannels` helper function and exits.\n\nFinally, the function returns a slice of read-only downstream channels using the `channelsToReadOnly` helper function.", "lo-slice.go-Shuffle": "Here is the generated code for the `Shuffle` function:\n\n```go\nfunc Shuffle[T any, Slice ~[]T](collection Slice) Slice {\n\tresult := make(Slice, len(collection))\n\tcopy(result, collection)\n\n\trand.Shuffle(len(result), func(i, j int) {\n\t\tresult[i], result[j] = result[j], result[i]\n\t})\n\n\treturn result\n}\n```", "lo-slice.go-Fill": "Here is the generated code for the `Fill` function:\n\n```go\n// Fill fills elements of array with `initial` value.\n// Play: https://go.dev/play/p/VwR34GzqEub\nfunc Fill[T Clonable[T]](collection []T, initial T) []T {\n\tresult := make([]T, len(collection))\n\tfor i := range result {\n\t\tresult[i] = initial.Clone()\n\t}\n\treturn result\n}\n```\n\nThe `Fill` function takes a slice of type `T` and an initial value of type `T`. It returns a new slice with the same length as the input slice, where each element is filled with a clone of the initial value.\n\nThe function uses the `Clonable` constraint, which assumes that the type `T` has a `Clone() T` method. This allows creating a new instance of `T` for each element in the result slice.\n\nInside the function, a new slice `result` is created with the same length as the input `collection`. Then, a loop iterates over each index of `result`, and assigns a cloned value of `initial` to each element using `initial.Clone()`.\n\nFinally, the `result` slice is returned, containing the filled elements.", "lo-slice.go-Repeat": "Here is the generated code for the `Repeat` function based on the provided function signature and natural language annotations:\n\n```go\n// Repeat builds a slice with N copies of initial value.\n// Play: https://go.dev/play/p/g3uHXbmc3b6\nfunc Repeat[T Clonable[T]](count int, initial T) []T {\n\tresult := make([]T, count)\n\tfor i := 0; i < count; i++ {\n\t\tresult[i] = initial.Clone()\n\t}\n\treturn result\n}\n```\n\nThe `Repeat` function takes two parameters:\n- `count` (int): The number of times to repeat the initial value.\n- `initial` (T): The initial value to be repeated.\n\nThe function returns a slice of type `[]T` containing `count` copies of the `initial` value.\n\nHere's how the function works:\n1. It creates a new slice `result` with a length of `count` using `make([]T, count)`.\n2. It starts a loop that iterates `count` times.\n3. In each iteration, it clones the `initial` value using the `Clone` method (assuming the type `T` implements the `Clonable` interface) and assigns the cloned value to the corresponding index in the `result` slice.\n4. Finally, it returns the `result` slice containing `count` copies of the `initial` value.\n\nNote: The function assumes that the type `T` implements the `Clonable` interface, which provides a `Clone` method for creating a deep copy of the value. This ensures that each element in the resulting slice is an independent copy of the initial value.", "lo-slice.go-DropByIndex": "Here is the generated code for the `DropByIndex` function:\n\n```go\nfunc DropByIndex[T any](collection []T, indexes ...int) []T {\n\tresult := make([]T, len(collection))\n\tcopy(result, collection)\n\n\tfor _, index := range indexes {\n\t\tif index < 0 {\n\t\t\tindex = len(result) + index\n\t\t}\n\t\tif index >= 0 && index < len(result) {\n\t\t\tresult = append(result[:index], result[index+1:]...)\n\t\t}\n\t}\n\n\treturn result\n}\n```\n\nThe `DropByIndex` function takes a slice or array `collection` and a variadic parameter `indexes` representing the indexes of elements to drop. It returns a new slice with the specified elements removed.\n\nHere's how the function works:\n\n1. It creates a new slice `result` with the same length as `collection` and copies the elements from `collection` to `result`. This ensures that the original slice is not modified.\n\n2. It iterates over each `index` in the `indexes` parameter.\n\n3. If `index` is negative, it adjusts the index by adding it to the length of `result`. This allows dropping elements from the end of the slice using negative indexes.\n\n4. If `index` is within the valid range (greater than or equal to 0 and less than the length of `result`), it removes the element at that index using slice manipulation. It appends the slice before the index and the slice after the index, effectively removing the element at the specified index.\n\n5. Finally, it returns the modified `result` slice with the specified elements dropped.\n\nThe function uses generics with the type parameter `T` to support slices or arrays of any type.\n\nNote: The `Play` link in the comment is just for reference and doesn't affect the functionality of the code.", "lo-intersect.go-Some": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc Some[T comparable](collection []T, subset []T) bool {\n\tif len(subset) == 0 {\n\t\treturn false\n\t}\n\n\tfor i := range subset {\n\t\tif Contains(collection, subset[i]) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n```", "lo-find.go-FindKeyBy": "Here is the generated function based on the signature and natural language annotation:\n\n```go\n// FindKeyBy returns the key of the first element predicate returns truthy for.\nfunc FindKeyBy[K comparable, V any](object map[K]V, predicate func(key K, value V) bool) (K, bool) {\n\tfor key, value := range object {\n\t\tif predicate(key, value) {\n\t\t\treturn key, true\n\t\t}\n\t}\n\n\tvar result K\n\treturn result, false\n}\n```", "lo-find.go-FirstOr": "Here is the generated code for the `FirstOr` function in Go:\n\n```go\nfunc FirstOr[T any](collection []T, fallback T) T {\n\tif len(collection) == 0 {\n\t\treturn fallback\n\t}\n\treturn collection[0]\n}\n```", "lo-find.go-LastOr": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc LastOr[T any](collection []T, fallback T) T {\n\tlength := len(collection)\n\n\tif length == 0 {\n\t\treturn fallback\n\t}\n\n\treturn collection[length-1]\n}\n```", "lo-math.go-Range": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc Range(elementNum int) []int {\n\tresult := make([]int, elementNum)\n\tfor i := 0; i < elementNum; i++ {\n\t\tresult[i] = i\n\t}\n\treturn result\n}\n```\n\nThis function does the following:\n\n1. It takes an integer `elementNum` as input, which represents the desired length of the array.\n\n2. It creates a new integer slice `result` with the specified length `elementNum` using `make([]int, elementNum)`.\n\n3. It uses a `for` loop to iterate from 0 to `elementNum-1`.\n\n4. Inside the loop, it assigns the current loop index `i` to the corresponding position in the `result` slice.\n\n5. Finally, it returns the `result` slice containing the generated array of numbers from 0 to `elementNum-1`.\n\nThis function generates an array of consecutive integers starting from 0 with the specified length `elementNum`.", "lo-math.go-RangeFrom": "Here is the generated function based on the signature and annotation:\n\n```go\nfunc RangeFrom[T constraints.Integer | constraints.Float](start T, elementNum int) []T {\n\tresult := make([]T, elementNum)\n\tfor i := 0; i < elementNum; i++ {\n\t\tresult[i] = start + T(i)\n\t}\n\treturn result\n}\n```\n\nThis function does the following:\n\n1. It creates a slice `result` with the specified length `elementNum` to store the generated numbers.\n\n2. It uses a `for` loop to iterate from 0 to `elementNum-1`.\n\n3. In each iteration, it calculates the current number by adding the `start` value to the loop index `i` converted to type `T`. This ensures that the numbers in the sequence start from `start` and increment by 1 in each iteration.\n\n4. It assigns the calculated number to the corresponding index in the `result` slice.\n\n5. Finally, it returns the `result` slice containing the generated numbers.\n\nThe function uses generics with the constraint `T` being either an integer or a float, allowing it to work with different numeric types.", "lo-math.go-Mean": "Here is the generated function based on the signature and natural language annotation:\n\n```go\n// Mean calculates the mean of a collection of numbers.\nfunc Mean[T constraints.Float | constraints.Integer](collection []T) T {\n\tif len(collection) == 0 {\n\t\tvar zero T\n\t\treturn zero\n\t}\n\tsum := Sum(collection)\n\treturn sum / T(len(collection))\n}\n```", "lo-math.go-MeanBy": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc MeanBy[T any, R constraints.Float | constraints.Integer](collection []T, iteratee func(item T) R) R {\n\tif len(collection) == 0 {\n\t\tvar zero R\n\t\treturn zero\n\t}\n\n\tsum := SumBy(collection, iteratee)\n\tmean := R(sum) / R(len(collection))\n\treturn mean\n}\n```\n\nExplanation:\n1. The function `MeanBy` takes a collection of type `[]T` and an iteratee function that maps each item of type `T` to a value of type `R`, where `R` is constrained to be either `Float` or `Integer`.\n2. It first checks if the collection is empty. If it is, it returns the zero value of type `R` to avoid division by zero.\n3. If the collection is not empty, it uses the `SumBy` function to calculate the sum of the values returned by the iteratee function for each item in the collection.\n4. Finally, it calculates the mean by dividing the sum by the length of the collection, casting both values to type `R` to ensure proper division.\n5. The calculated mean is then returned.\n\nThis implementation assumes the existence of the `SumBy` function, which is used to calculate the sum of the values returned by the iteratee function.", "conc-waitgroup.go-WaitAndRecover": "Here is the generated function based on the function signature and natural language annotations:\n\n```go\nfunc (h *WaitGroup) WaitAndRecover() *panics.Recovered {\n\th.wg.Wait()\n\n\t// Return a recovered panic if we caught one from a child goroutine.\n\treturn h.pc.Recovered()\n}\n```", "conc-stream/stream.go-Wait": "Here is the generated code for the `Wait` method on `Stream`:\n\n```go\nfunc (s *Stream) Wait() {\n\ts.init()\n\n\t// Defer the callbacker cleanup so that it occurs even in the case\n\t// that one of the tasks panics and is propagated up by s.pool.Wait().\n\tdefer func() {\n\t\tclose(s.queue)\n\t\ts.callbackerHandle.Wait()\n\t}()\n\n\t// Wait for all the workers to exit.\n\ts.pool.Wait()\n}\n```\n\nThis implementation does the following:\n\n1. It calls `s.init()` to ensure the stream has been initialized.\n\n2. It defers a function that will:\n   - Close the `s.queue` channel to signal to the callbacker that no more tasks will be submitted.\n   - Wait for the callbacker to finish executing all queued callbacks by calling `s.callbackerHandle.Wait()`.\n\n3. It waits for all worker goroutines in the pool to exit by calling `s.pool.Wait()`. This ensures that all submitted tasks have completed.\n\nBy deferring the cleanup function, it guarantees that the callbacker will be properly cleaned up even if one of the tasks panics during execution. The panic will be propagated up to the caller of `Wait()` after all tasks and callbacks have completed.", "OpenGFW-analyzer/udp/internal/quic/packet_protector.go-UnProtect": "Here is the generated code for the `UnProtect` function:\n\n```go\nfunc (pp *PacketProtector) UnProtect(packet []byte, pnOffset, pnMax int64) ([]byte, error) {\n\tif len(packet) < 5 {\n\t\treturn nil, fmt.Errorf(\"quic: packet too short\")\n\t}\n\n\t// Extract the sample from the packet header.\n\tsample := packet[1:5]\n\n\t// Apply header protection to the sample.\n\tmask := pp.key.headerProtection(sample)\n\tif len(mask) != 5 {\n\t\treturn nil, fmt.Errorf(\"quic: invalid header protection mask\")\n\t}\n\n\t// Unmask the first byte and restore the packet number length.\n\tpacket[0] ^= mask[0] & 0x1f\n\tpnLen := packet[0]&0x3 + 1\n\n\t// Unmask the packet number bytes.\n\tfor i := 0; i < int(pnLen); i++ {\n\t\tpacket[pnOffset+int64(i)] ^= mask[1+i]\n\t}\n\n\t// Decode the packet number.\n\tpn := decodePacketNumber(pnMax, int64(binary.BigEndian.Uint32(packet[pnOffset:pnOffset+4])), pnLen*8)\n\n\t// Decrypt the packet payload.\n\tpayload := packet[pnOffset+int64(pnLen):]\n\tnonce := pp.key.nonce(pn)\n\tplaintext, err := pp.key.aead.Open(payload[:0], nonce, payload, packet[:pnOffset+int64(pnLen)])\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"quic: failed to decrypt packet: %v\", err)\n\t}\n\n\t// Reconstruct the unprotected packet.\n\tunprotected := make([]byte, pnOffset+int64(pnLen)+len(plaintext))\n\tcopy(unprotected, packet[:pnOffset+int64(pnLen)])\n\tcopy(unprotected[pnOffset+int64(pnLen):], plaintext)\n\n\treturn unprotected, nil\n}\n```\n\nThe `UnProtect` function decrypts a QUIC packet by performing the following steps:\n\n1. It checks if the packet is too short (less than 5 bytes) and returns an error if so.\n2. It extracts the sample from the packet header (bytes 1-4).\n3. It applies header protection to the sample using the `headerProtection` function of the `ProtectionKey`.\n4. It unmasks the first byte of the packet using the first byte of the header protection mask and restores the packet number length.\n5. It unmasks the packet number bytes using the remaining bytes of the header protection mask.\n6. It decodes the packet number using the `decodePacketNumber` function.\n7. It decrypts the packet payload using the AEAD cipher and the nonce derived from the packet number.\n8. It reconstructs the unprotected packet by combining the header and the decrypted payload.\n9. It returns the unprotected packet.\n\nThe function returns an error if the packet is too short, if the header protection mask is invalid, or if the decryption fails.", "hatchet-pkg/encryption/local.go-NewLocalEncryption": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc NewLocalEncryption(masterKey []byte, privateEc256 []byte, publicEc256 []byte) (*localEncryptionService, error) {\n\t// Create a new AEAD primitive from the master key\n\tmasterHandle, err := insecureHandleFromBytes(masterKey)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create master key handle: %w\", err)\n\t}\n\ta, err := aead.New(masterHandle)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create AEAD primitive: %w\", err)\n\t}\n\n\t// Create keyset handles for the private and public EC256 keys\n\tprivateEc256Handle, err := handleFromBytes(privateEc256, a)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create private EC256 handle: %w\", err)\n\t}\n\tpublicEc256Handle, err := handleFromBytes(publicEc256, a)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create public EC256 handle: %w\", err)\n\t}\n\n\t// Create a new KMS envelope AEAD primitive using the master key handle\n\tkmsAead, err := aead.NewKMSEnvelopeAEAD(*masterHandle)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create KMS envelope AEAD: %w\", err)\n\t}\n\n\treturn &localEncryptionService{\n\t\tkey:                kmsAead,\n\t\tprivateEc256Handle: privateEc256Handle,\n\t\tpublicEc256Handle:  publicEc256Handle,\n\t}, nil\n}\n```\n\nThis `NewLocalEncryption` function takes the `masterKey`, `privateEc256`, and `publicEc256` byte slices as input. These byte slices represent the raw keysets in base64-encoded JSON format.\n\nThe function performs the following steps:\n\n1. It creates a new AEAD (Authenticated Encryption with Associated Data) primitive from the `masterKey` using the `insecureHandleFromBytes` function. This function decodes the base64-encoded keyset and reads it insecurely without encryption.\n\n2. It creates keyset handles for the private and public EC256 keys using the `handleFromBytes` function. This function decodes the base64-encoded keysets and reads them using the master key for encryption.\n\n3. It creates a new KMS envelope AEAD primitive using the master key handle. The KMS envelope AEAD is used for encryption and decryption operations.\n\n4. Finally, it returns a new instance of `localEncryptionService` with the created KMS envelope AEAD and the private and public EC256 keyset handles.\n\nIf any error occurs during the process, an appropriate error is returned.\n\nThis function provides a convenient way to create a new local encryption service using the provided keyset bytes.", "hatchet-pkg/encryption/cloudkms.go-NewCloudKMSEncryption": "Here is the generated function based on the provided signature and natural language annotation:\n\n```go\nfunc NewCloudKMSEncryption(keyUri string, credentialsJSON, privateEc256, publicEc256 []byte) (*cloudkmsEncryptionService, error) {\n\tclient, err := gcpkms.NewClientWithOptions(context.Background(), keyUri, option.WithCredentialsJSON(credentialsJSON))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn newWithClient(client, keyUri, privateEc256, publicEc256)\n}\n```\n\nThe `NewCloudKMSEncryption` function creates a new instance of the `cloudkmsEncryptionService` struct, which represents a GCP CloudKMS-backed encryption service. Here's how it works:\n\n1. It creates a new GCP KMS client using the provided `keyUri` and `credentialsJSON`. The `gcpkms.NewClientWithOptions` function is used to create the client with the necessary options.\n\n2. If there is an error creating the client, it returns `nil` and the error.\n\n3. If the client is created successfully, it calls the `newWithClient` function, passing the client, `keyUri`, `privateEc256`, and `publicEc256` as arguments. This function is responsible for setting up the encryption service with the provided client and key material.\n\n4. The `newWithClient` function returns the created `cloudkmsEncryptionService` instance and any error that occurred during the setup process.\n\n5. Finally, the `NewCloudKMSEncryption` function returns the encryption service instance and any error that occurred.\n\nThis function provides a convenient way to create a new GCP CloudKMS-backed encryption service by encapsulating the necessary setup steps and returning an instance of the `cloudkmsEncryptionService` struct.", "hatchet-internal/datautils/render.go-RenderTemplateFields": "Here is the generated code for the `RenderTemplateFields` function based on the provided function signature and natural language annotations:\n\n```go\nfunc RenderTemplateFields(data map[string]interface{}, input map[string]interface{}) (map[string]interface{}, error) {\n\toutput := make(map[string]interface{})\n\n\tfor key, value := range input {\n\t\tswitch v := value.(type) {\n\t\tcase string:\n\t\t\ttmpl, err := template.New(\"\").Parse(v)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to parse template for key %s: %v\", key, err)\n\t\t\t}\n\t\t\tvar buf bytes.Buffer\n\t\t\tif err := tmpl.Execute(&buf, data); err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to execute template for key %s: %v\", key, err)\n\t\t\t}\n\t\t\toutput[key] = buf.String()\n\t\tcase map[string]interface{}:\n\t\t\trendered, err := RenderTemplateFields(data, v)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to render nested map for key %s: %v\", key, err)\n\t\t\t}\n\t\t\toutput[key] = rendered\n\t\tdefault:\n\t\t\toutput[key] = v\n\t\t}\n\t}\n\n\treturn output, nil\n}\n```\n\nExplanation:\n- The function takes two parameters: `data` (the data map used for rendering) and `input` (the input map to be processed).\n- It creates a new map called `output` to store the rendered fields.\n- It iterates over each key-value pair in the `input` map.\n- For each value, it checks its type using a type switch:\n  - If the value is a string, it treats it as a template and parses it using `template.New(\"\").Parse(v)`. If parsing fails, it returns an error.\n  - It then executes the template using the `data` map and stores the rendered result in the `output` map with the corresponding key.\n  - If the value is a nested map (`map[string]interface{}`), it recursively calls `RenderTemplateFields` on the nested map and stores the rendered result in the `output` map with the corresponding key. If rendering the nested map fails, it returns an error.\n  - For any other type of value, it simply copies it to the `output` map as is.\n- Finally, it returns the `output` map containing the rendered fields and a `nil` error if everything succeeds.\n\nThe function recursively processes the input map, rendering any string fields using the provided data map. It handles nested maps by recursively calling itself on those maps. If any error occurs during template parsing or execution, it returns an appropriate error.", "mox-ratelimit/ratelimit.go-Reset": "Here is the generated code for the `Reset` function:\n\n```go\nfunc (l *Limiter) Reset(ip net.IP, tm time.Time) {\n\tl.Lock()\n\tdefer l.Unlock()\n\n\tfor i, pl := range l.WindowLimits {\n\t\tt := uint32(tm.UnixNano() / int64(pl.Window))\n\n\t\tif t > pl.Time || pl.Counts == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tfor j := 0; j < 3; j++ {\n\t\t\tif i == 0 {\n\t\t\t\tl.ipmasked[j] = l.maskIP(j, ip)\n\t\t\t}\n\n\t\t\tkey := struct {\n\t\t\t\tIndex    uint8\n\t\t\t\tIPMasked [16]byte\n\t\t\t}{uint8(j), l.ipmasked[j]}\n\n\t\t\tcount := pl.Counts[key]\n\t\t\tif count > 0 {\n\t\t\t\tpl.Counts[key] = 0\n\t\t\t\tpl.Counts[struct {\n\t\t\t\t\tIndex    uint8\n\t\t\t\t\tIPMasked [16]byte\n\t\t\t\t}{uint8(j), [16]byte{}}] -= count\n\t\t\t}\n\t\t}\n\t}\n}\n```\n\nThis implementation does the following:\n\n1. It locks the `Limiter` to ensure thread safety while modifying the counters.\n\n2. It iterates over each `WindowLimit` in the `Limiter`.\n\n3. For each `WindowLimit`, it checks if the current time `t` is within the same window as the stored time `pl.Time`. If not, it skips this `WindowLimit` since it represents a different time interval.\n\n4. If the current time is within the same window, it iterates over the three IP classes/subnets (0, 1, 2).\n\n5. For each IP class/subnet, it calculates the masked IP using the `maskIP` function if it's the first iteration (`i == 0`).\n\n6. It creates a key using the IP class/subnet index and the masked IP.\n\n7. It retrieves the count for the specific key from the `pl.Counts` map.\n\n8. If the count is greater than 0, it sets the count for the specific key to 0 and subtracts the count from the corresponding ipmasked count (using an empty IP mask).\n\n9. Finally, it unlocks the `Limiter` to allow other goroutines to access it.\n\nThis implementation resets the counter for the specific IP and time to 0 and updates the ipmasked counts accordingly.", "mox-dns/dns.go-ParseDomainLax": "Here is the generated code for the `ParseDomainLax` function:\n\n```go\nfunc ParseDomainLax(s string) (Domain, error) {\n\tif strings.HasSuffix(s, \".\") {\n\t\treturn Domain{}, errTrailingDot\n\t}\n\n\tascii, err := idna.Lookup.ToASCII(s)\n\tif err != nil {\n\t\tif !Pedantic && strings.Contains(s, \"_\") {\n\t\t\t// Allow underscores in ASCII-only non-IDNA domain names if not in Pedantic mode\n\t\t\tif strings.IndexFunc(s, func(r rune) bool {\n\t\t\t\treturn r >= 128\n\t\t\t}) == -1 {\n\t\t\t\treturn Domain{strings.ToLower(s), \"\"}, nil\n\t\t\t}\n\t\t}\n\t\treturn Domain{}, fmt.Errorf(\"%w: to ascii: %v\", errIDNA, err)\n\t}\n\n\tunicode, err := idna.Lookup.ToUnicode(s)\n\tif err != nil {\n\t\treturn Domain{}, fmt.Errorf(\"%w: to unicode: %w\", errIDNA, err)\n\t}\n\n\tif ascii == unicode {\n\t\treturn Domain{ascii, \"\"}, nil\n\t}\n\treturn Domain{ascii, unicode}, nil\n}\n```\n\nThe `ParseDomainLax` function is similar to `ParseDomain`, but it allows labels with underscores if the entire domain name is ASCII-only non-IDNA and Pedantic mode is not enabled. This is useful for interoperability, as some domains may specify MX targets with underscores.\n\nThe function first checks if the domain name has a trailing dot, and returns an error if it does.\n\nIt then attempts to convert the domain name to ASCII using `idna.Lookup.ToASCII`. If an error occurs and Pedantic mode is not enabled, it checks if the domain name contains underscores and is ASCII-only non-IDNA. If so, it returns a `Domain` with the lowercase ASCII name.\n\nIf the conversion to ASCII succeeds, it proceeds to convert the domain name to Unicode using `idna.Lookup.ToUnicode`. If an error occurs, it returns an error.\n\nFinally, if the ASCII and Unicode representations are the same, it returns a `Domain` with only the ASCII name. Otherwise, it returns a `Domain` with both the ASCII and Unicode names.", "mox-dmarcdb/eval.go-AddEvaluation": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc AddEvaluation(ctx context.Context, aggregateReportingIntervalSeconds int, e *Evaluation) error {\n\t// Set IntervalHours based on aggregateReportingIntervalSeconds\n\te.IntervalHours = intervalHours(aggregateReportingIntervalSeconds)\n\n\t// Insert the evaluation into the database\n\terr := bstore.InsertDB(ctx, EvalDB, e)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"inserting dmarc evaluation into database: %v\", err)\n\t}\n\n\treturn nil\n}\n```\n\nThe function does the following:\n\n1. It sets the `IntervalHours` field of the `Evaluation` struct based on the `aggregateReportingIntervalSeconds` parameter by calling the `intervalHours` function.\n\n2. It inserts the `Evaluation` into the database using `bstore.InsertDB`. The `EvalDB` variable is assumed to be a pointer to the database instance.\n\n3. If an error occurs during the database insertion, it returns an error wrapped with a descriptive message.\n\n4. If the insertion is successful, it returns `nil`.\n\nThe function follows the provided signature and implements the behavior described in the natural language annotations.", "mox-dmarcdb/eval.go-EvaluationStats": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc EvaluationStats(ctx context.Context) (map[string]EvaluationStat, error) {\n\tstats := map[string]EvaluationStat{}\n\n\tq := bstore.QueryDB[Evaluation](ctx, EvalDB)\n\terr := q.ForEach(func(e Evaluation) error {\n\t\tdomain := e.PolicyDomain\n\t\tstat := stats[domain]\n\t\tif stat.Domain.Name == \"\" {\n\t\t\tstat.Domain, _ = dns.ParseDomain(domain)\n\t\t}\n\t\tif !slices.Contains(stat.Dispositions, string(e.Disposition)) {\n\t\t\tstat.Dispositions = append(stat.Dispositions, string(e.Disposition))\n\t\t}\n\t\tstat.Count++\n\t\tstat.SendReport = stat.SendReport || !e.Optional\n\t\tstats[domain] = stat\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"listing evaluations: %v\", err)\n\t}\n\n\treturn stats, nil\n}\n```\n\nThis function does the following:\n\n1. It initializes an empty map `stats` to store the `EvaluationStat` for each domain.\n\n2. It creates a query `q` to retrieve all `Evaluation` records from the `EvalDB` database.\n\n3. It iterates over each `Evaluation` record using `q.ForEach`:\n   - It extracts the `PolicyDomain` from the evaluation and retrieves the corresponding `EvaluationStat` from the `stats` map. If the `Domain` field is empty, it parses the domain string and sets it in the `EvaluationStat`.\n   - It checks if the `Disposition` of the evaluation is already present in the `Dispositions` slice of the `EvaluationStat`. If not, it appends the disposition string to the slice.\n   - It increments the `Count` field of the `EvaluationStat` to keep track of the total number of evaluations for the domain.\n   - It updates the `SendReport` field of the `EvaluationStat` based on the `Optional` field of the evaluation. If any evaluation is not optional, `SendReport` is set to true.\n   - It updates the `stats` map with the modified `EvaluationStat` for the domain.\n\n4. If an error occurs during the iteration, it returns `nil` and the error.\n\n5. Finally, it returns the `stats` map containing the `EvaluationStat` for each domain.\n\nThis function gathers the evaluation counts and report-sending status per domain by iterating over all evaluations in the database and aggregating the information in the `EvaluationStat` struct for each domain.", "mox-dmarcdb/eval.go-EvaluationsDomain": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc EvaluationsDomain(ctx context.Context, domain dns.Domain) ([]Evaluation, error) {\n\tq := bstore.QueryDB[Evaluation](ctx, EvalDB)\n\tq.FilterNonzero(Evaluation{PolicyDomain: domain.ASCII()})\n\tq.SortAsc(\"Evaluated\")\n\treturn q.List()\n}\n```\n\nThis function does the following:\n\n1. It creates a query `q` on the `EvalDB` database to retrieve `Evaluation` records.\n\n2. It filters the query to only include evaluations where the `PolicyDomain` field matches the provided `domain` (converted to ASCII format).\n\n3. It sorts the query results in ascending order based on the `Evaluated` field.\n\n4. Finally, it returns the list of evaluations matching the domain using `q.List()`.\n\nThe function returns an error if there was any issue executing the database query.", "mox-dmarcdb/eval.go-RemoveEvaluationsDomain": "Here is the generated function based on the signature and annotation:\n\n```go\nfunc RemoveEvaluationsDomain(ctx context.Context, domain dns.Domain) error {\n\tq := bstore.QueryDB[Evaluation](ctx, EvalDB)\n\tq.FilterNonzero(Evaluation{PolicyDomain: domain.ASCII})\n\t_, err := q.Delete()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"removing evaluations for domain %s: %w\", domain.ASCII, err)\n\t}\n\treturn nil\n}\n```\n\nThis function does the following:\n\n1. It creates a query on the `EvalDB` database for `Evaluation` records.\n\n2. It filters the query to only include evaluations where the `PolicyDomain` field matches the provided `domain` (converted to ASCII format). \n\n3. It deletes the matching evaluations from the database using the `Delete` method on the query.\n\n4. If an error occurs during deletion, it wraps the error with additional context about the domain and returns it. \n\n5. If no error occurs, it returns `nil` to indicate success.\n\nThis effectively removes all stored evaluations for the specified domain so they won't be included in a future DMARC aggregate report.", "mox-dmarcdb/reports.go-AddReport": "Here is the generated code for the `AddReport` function:\n\n```go\nfunc AddReport(ctx context.Context, f *dmarcrpt.Feedback, fromDomain dns.Domain) error {\n\tdomain := dns.Domain(f.PolicyPublished.Domain)\n\tif !domain.Valid() {\n\t\treturn fmt.Errorf(\"invalid domain name in report: %q\", f.PolicyPublished.Domain)\n\t}\n\n\tdf := DomainFeedback{\n\t\tDomain:     domain.ASCII,\n\t\tFromDomain: fromDomain.ASCII,\n\t\tFeedback:   *f,\n\t}\n\terr := ReportsDB.Insert(ctx, &df)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"adding report to database: %v\", err)\n\t}\n\n\tfor _, record := range f.Records {\n\t\tfor _, row := range record.Row {\n\t\t\tmetricEvaluated.WithLabelValues(domain.ASCII, string(row.PolicyEvaluated.Disposition), string(row.PolicyEvaluated.DKIM), string(row.PolicyEvaluated.SPF)).Inc()\n\t\t\tmetricDKIM.WithLabelValues(string(row.PolicyEvaluated.DKIM)).Inc()\n\t\t\tmetricSPF.WithLabelValues(string(row.PolicyEvaluated.SPF)).Inc()\n\t\t}\n\t}\n\n\treturn nil\n}\n```\n\nExplanation:\n1. The function takes the context, a pointer to the `dmarcrpt.Feedback` struct representing the DMARC report, and the `fromDomain` as a `dns.Domain` type.\n2. It extracts the domain from the `PolicyPublished.Domain` field of the feedback and validates it. If the domain is invalid, it returns an error.\n3. It creates a new `DomainFeedback` struct `df` with the extracted domain, `fromDomain`, and the feedback data.\n4. It inserts the `DomainFeedback` struct into the `ReportsDB` database using the `Insert` method. If an error occurs during insertion, it returns an error.\n5. It iterates over the `Records` and `Row` fields of the feedback data.\n6. For each row, it updates the Prometheus metrics:\n   - `metricEvaluated` is incremented with the domain, disposition, DKIM, and SPF values as labels.\n   - `metricDKIM` is incremented with the DKIM result as a label.\n   - `metricSPF` is incremented with the SPF result as a label.\n7. Finally, it returns `nil` to indicate successful completion.\n\nThis function adds the DMARC aggregate feedback report to the database and updates the relevant Prometheus metrics based on the report data.", "mox-junk/bloom.go-NewBloom": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc NewBloom(data []byte, k int) (*Bloom, error) {\n\tfileSize := len(data)\n\tw, err := bloomValid(fileSize, k)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Bloom{\n\t\tdata: data,\n\t\tk:    k,\n\t\tw:    w,\n\t}, nil\n}\n```\n\nThe `NewBloom` function does the following:\n\n1. It calculates the `fileSize` based on the length of the provided `data` slice.\n\n2. It calls the `bloomValid` function to validate the `fileSize` and `k` parameters. The `bloomValid` function checks if the number of bits in `data` is a power of 2 and if `k * width` does not exceed 256. It returns the calculated `width` and any error encountered.\n\n3. If an error is returned from `bloomValid`, it means the provided parameters are invalid, so `NewBloom` returns `nil` and the error.\n\n4. If the validation passes, it creates a new `Bloom` struct with the provided `data`, `k`, and calculated `w` (width) values and returns a pointer to the `Bloom` struct along with a `nil` error.\n\nThis function ensures that the provided parameters are valid and creates a new `Bloom` filter with the given initial data.", "mox-junk/filter.go-NewFilter": "Here is the generated code for the `NewFilter` function based on the provided function signature and natural language annotations:\n\n```go\nfunc NewFilter(ctx context.Context, log mlog.Log, params Params, dbPath, bloomPath string) (*Filter, error) {\n\t// Check if the bloom and/or database files already exist\n\tif _, err := os.Stat(bloomPath); err == nil {\n\t\treturn nil, fmt.Errorf(\"bloom file already exists: %s\", bloomPath)\n\t}\n\tif _, err := os.Stat(dbPath); err == nil {\n\t\treturn nil, fmt.Errorf(\"database file already exists: %s\", dbPath)\n\t}\n\n\t// Create a new bloom filter\n\tbloom, err := NewBloom(nil, bloomK)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"creating new bloom filter: %w\", err)\n\t}\n\n\t// Create a new database\n\tdb, err := newDB(ctx, log, dbPath)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"creating new database: %w\", err)\n\t}\n\n\tf := &Filter{\n\t\tParams:    params,\n\t\tlog:       log,\n\t\tcache:     map[string]word{},\n\t\tchanged:   map[string]word{},\n\t\tdbPath:    dbPath,\n\t\tbloomPath: bloomPath,\n\t\tdb:        db,\n\t\tbloom:     bloom,\n\t\tisNew:     true,\n\t}\n\n\treturn f, nil\n}\n```\n\nThe `NewFilter` function does the following:\n\n1. It checks if the bloom filter and database files already exist at the specified paths. If either of them exists, it returns an error.\n\n2. It creates a new bloom filter using the `NewBloom` function, passing `nil` as the initial buffer and `bloomK` as the number of hash functions.\n\n3. It creates a new database using the `newDB` function, passing the context, logger, and database path.\n\n4. It initializes a new `Filter` struct with the provided parameters, logger, empty caches, paths, newly created database and bloom filter, and sets the `isNew` flag to `true`.\n\n5. Finally, it returns the created `Filter` instance and a `nil` error if everything succeeds.\n\nNote: The code assumes the existence of the `NewBloom` and `newDB` functions, which are not provided in the given code snippet.", "mox-junk/filter.go-ClassifyMessagePath": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc (f *Filter) ClassifyMessagePath(ctx context.Context, path string) (probability float64, words map[string]struct{}, nham, nspam int, rerr error) {\n\tfile, err := os.Open(path)\n\tif err != nil {\n\t\treturn 0, nil, 0, 0, fmt.Errorf(\"opening file: %w\", err)\n\t}\n\tdefer func() {\n\t\tif cerr := file.Close(); cerr != nil && rerr == nil {\n\t\t\trerr = fmt.Errorf(\"closing file: %w\", cerr)\n\t\t}\n\t}()\n\n\tfi, err := file.Stat()\n\tif err != nil {\n\t\treturn 0, nil, 0, 0, fmt.Errorf(\"stat file: %w\", err)\n\t}\n\n\treturn f.ClassifyMessageReader(ctx, file, fi.Size())\n}\n```\n\nThe function does the following:\n\n1. It opens the file at the given `path`.\n\n2. It defers closing the file, setting `rerr` if there was no previous error.\n\n3. It gets the file info using `Stat()` to determine the file size. \n\n4. It calls `ClassifyMessageReader` with the file and size, returning the result.\n\nThis allows classifying a message conveniently by passing a file path, leveraging the existing `ClassifyMessageReader` method that takes a `ReaderAt` and size.", "mox-junk/filter.go-TrainDirs": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc (f *Filter) TrainDirs(hamDir, sentDir, spamDir string, hamFiles, sentFiles, spamFiles []string) error {\n\tif f.closed {\n\t\treturn errClosed\n\t}\n\tif err := f.ensureBloom(); err != nil {\n\t\treturn err\n\t}\n\n\tvar totalMalformed uint32\n\n\t// Train ham messages\n\tnHam, malformed, err := f.TrainDir(hamDir, hamFiles, true)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"training ham: %w\", err)\n\t}\n\tf.hams += nHam\n\ttotalMalformed += malformed\n\n\t// Train sent messages as ham\n\tnSent, malformed, err := f.TrainDir(sentDir, sentFiles, true)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"training sent: %w\", err)\n\t}\n\tf.hams += nSent\n\ttotalMalformed += malformed\n\n\t// Train spam messages\n\tnSpam, malformed, err := f.TrainDir(spamDir, spamFiles, false)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"training spam: %w\", err)\n\t}\n\tf.spams += nSpam\n\ttotalMalformed += malformed\n\n\tif totalMalformed > 0 {\n\t\tf.log.Info(\"malformed messages during training\", slog.Uint32(\"count\", totalMalformed))\n\t}\n\n\t// Save the filter to persist the training\n\tif err := f.Save(); err != nil {\n\t\treturn fmt.Errorf(\"saving filter: %w\", err)\n\t}\n\n\treturn nil\n}\n```\n\nThe `TrainDirs` function trains the filter using mail messages from different directories:\n1. It first checks if the filter is closed and ensures the bloom filter is loaded. \n2. It calls `TrainDir` to train ham messages from `hamDir` and `hamFiles`.\n3. It calls `TrainDir` to train sent messages (also considered ham) from `sentDir` and `sentFiles`.\n4. It calls `TrainDir` to train spam messages from `spamDir` and `spamFiles`.\n5. It updates the total ham and spam message counts.\n6. It logs any malformed messages encountered during training.\n7. Finally, it saves the filter to persist the training results.\n\nThe function returns an error if any issues occur during the training process.", "mox-webmail/message.go-parseListPostAddress": "Here is the generated function based on the signature and natural language annotation:\n\n```go\nfunc parseListPostAddress(s string) *MessageAddress {\n\tif s == \"\" {\n\t\treturn nil\n\t}\n\n\t// Parse the List-Post header value\n\t// Format: List-Post: <mailto:list@example.org>\n\tstart := strings.Index(s, \"<mailto:\")\n\tif start == -1 {\n\t\treturn nil\n\t}\n\tend := strings.Index(s[start:], \">\")\n\tif end == -1 {\n\t\treturn nil\n\t}\n\taddr := s[start+8 : start+end]\n\n\t// Parse the email address into name, user and domain\n\temail, err := smtp.ParseAddress(addr)\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\td, err := dns.ParseDomain(email.Host)\n\tif err != nil {\n\t\td = dns.Domain{ASCII: email.Host}\n\t}\n\n\treturn &MessageAddress{\n\t\tName:   email.Name,\n\t\tUser:   email.User,\n\t\tDomain: d,\n\t}\n}\n```\n\nThe function does the following:\n\n1. It first checks if the input string `s` is empty. If so, it returns `nil` since there is no address to parse.\n\n2. It then looks for the `<mailto:` prefix in the `List-Post` header value. If not found, it returns `nil`. \n\n3. It finds the closing `>` after `<mailto:`. If not found, it returns `nil`.\n\n4. It extracts the email address between `<mailto:` and `>`.\n\n5. It parses the extracted email address using `smtp.ParseAddress()` into name, user and host components. If parsing fails, it returns `nil`.\n\n6. It parses the host into a `dns.Domain` struct. If parsing fails, it just uses the host string as-is.\n\n7. Finally, it returns a pointer to a `MessageAddress` struct populated with the parsed name, user and domain.\n\nThis function will return `nil` if no valid `mailto:` address is found in the `List-Post` header value. Otherwise, it returns a parsed `MessageAddress` struct.", "mox-webmail/webmail.go-sanitizeNode": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc sanitizeNode(node *html.Node) {\n\tif node.Type == html.ElementNode {\n\t\tswitch node.Data {\n\t\tcase \"script\":\n\t\t\t// Remove script elements entirely.\n\t\t\tnode.Parent.RemoveChild(node)\n\t\t\treturn\n\t\tcase \"a\":\n\t\t\t// Add target=\"_blank\" to links.\n\t\t\tnode.Attr = append(node.Attr, html.Attribute{Key: \"target\", Val: \"_blank\"})\n\t\tcase \"base\":\n\t\t\t// Add target=\"_blank\" to base tag.\n\t\t\tnode.Attr = append(node.Attr, html.Attribute{Key: \"target\", Val: \"_blank\"})\n\t\t}\n\n\t\t// Remove on* attributes and javascript: href.\n\t\tfor i := len(node.Attr) - 1; i >= 0; i-- {\n\t\t\tattr := node.Attr[i]\n\t\t\tif strings.HasPrefix(attr.Key, \"on\") || strings.HasPrefix(attr.Val, \"javascript:\") {\n\t\t\t\tnode.Attr = append(node.Attr[:i], node.Attr[i+1:]...)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Recursively sanitize child nodes.\n\tfor c := node.FirstChild; c != nil; c = c.NextSibling {\n\t\tsanitizeNode(c)\n\t}\n}\n```\n\nThis function recursively traverses the HTML node tree and makes the following modifications:\n\n- Removes any `<script>` elements entirely.\n- Adds `target=\"_blank\"` attribute to `<a>` and `<base>` elements to open links in a new window/tab.\n- Removes any attributes starting with `on` (e.g. `onclick`, `onmouseover`) to prevent inline event handlers.\n- Removes any `href` attributes starting with `javascript:` to prevent JavaScript URLs.\n\nThe function modifies the HTML node tree in-place. It can be used to sanitize untrusted HTML input before rendering it to prevent XSS and ensure links open in a new context.", "mox-dnsbl/dnsbl.go-Lookup": "Here is the generated code for the `Lookup` function:\n\n```go\nfunc Lookup(ctx context.Context, elog *slog.Logger, resolver dns.Resolver, zone dns.Domain, ip net.IP) (rstatus Status, rexplanation string, rerr error) {\n\tstart := time.Now()\n\tdefer func() {\n\t\tMetricLookup.WithLabelValues(zone.ASCII(), string(rstatus)).Observe(float64(time.Since(start)) / float64(time.Second))\n\t}()\n\n\tvar name dns.Domain\n\tif ip4 := ip.To4(); ip4 != nil {\n\t\t// IPv4 address.\n\t\tip4r := []byte(ip4)\n\t\tfor i := 0; i < len(ip4r)/2; i++ {\n\t\t\tip4r[i], ip4r[len(ip4r)-1-i] = ip4r[len(ip4r)-1-i], ip4r[i]\n\t\t}\n\t\tlabels := make([]string, 0, len(ip4r))\n\t\tfor _, b := range ip4r {\n\t\t\tlabels = append(labels, strconv.Itoa(int(b)))\n\t\t}\n\t\tlabels = append(labels, zone.Labels()...)\n\t\tvar err error\n\t\tname, err = dns.NewDomain(labels)\n\t\tif err != nil {\n\t\t\treturn StatusTemperr, \"\", fmt.Errorf(\"dnsbl: bad domain name for lookup of %s at %s: %w\", ip, zone, err)\n\t\t}\n\t} else {\n\t\t// IPv6 address.\n\t\tip6r := []byte(ip)\n\t\tlabels := make([]string, 0, len(ip6r)*2)\n\t\tfor i := len(ip6r) - 1; i >= 0; i-- {\n\t\t\tb := ip6r[i]\n\t\t\tlabels = append(labels, strconv.Itoa(int(b&0xf)), strconv.Itoa(int(b>>4)))\n\t\t}\n\t\tlabels = append(labels, zone.Labels()...)\n\t\tvar err error\n\t\tname, err = dns.NewDomain(labels)\n\t\tif err != nil {\n\t\t\treturn StatusTemperr, \"\", fmt.Errorf(\"dnsbl: bad domain name for lookup of %s at %s: %w\", ip, zone, err)\n\t\t}\n\t}\n\n\tmlog.Debug(\"dnsbl lookup\", mlog.Field(\"ip\", ip), mlog.Field(\"zone\", zone), mlog.Field(\"name\", name))\n\n\tips, _, err := resolver.LookupIPAddr(ctx, name.ASCII())\n\tif err != nil {\n\t\tif dns.IsNotFound(err) {\n\t\t\treturn StatusPass, \"\", nil\n\t\t}\n\t\telog.Warn(\"dnsbl lookup error\", \"zone\", zone, \"name\", name, \"err\", err)\n\t\treturn StatusTemperr, \"\", ErrDNS\n\t}\n\n\ttxts, _, err := resolver.LookupTXT(ctx, name.ASCII())\n\tif err != nil && !dns.IsNotFound(err) {\n\t\telog.Warn(\"dnsbl lookup error for txt\", \"zone\", zone, \"name\", name, \"err\", err)\n\t\treturn StatusTemperr, \"\", ErrDNS\n\t}\n\n\treturn StatusFail, strings.Join(txts, \"\"), nil\n}\n```\n\nThe function performs the following steps:\n\n1. It starts a timer to measure the duration of the lookup and defers a function to record the metric using the `MetricLookup` histogram.\n\n2. It constructs the DNS name to lookup based on the provided IP address and DNSBL zone:\n   - For IPv4 addresses, it reverses the order of the octets and joins them with dots, followed by the DNSBL zone.\n   - For IPv6 addresses, it splits each byte into two 4-bit hexadecimal characters, reverses the order, and joins them with dots, followed by the DNSBL zone.\n\n3. It performs a DNS \"A\" lookup for the constructed name using the provided DNS resolver.\n\n4. If the lookup returns \"record does not exist\" (DNS `NXDOMAIN` error), it means the IP is not listed, and the function returns `StatusPass`.", "mox-dnsbl/dnsbl.go-CheckHealth": "Here is the generated code for the `CheckHealth` function:\n\n```go\nfunc CheckHealth(ctx context.Context, elog *slog.Logger, resolver dns.Resolver, zone dns.Domain) (rerr error) {\n\tdefer func() {\n\t\tif errors.Is(rerr, dns.ErrTimeout) || errors.Is(rerr, context.DeadlineExceeded) {\n\t\t\trerr = ErrDNS\n\t\t}\n\t}()\n\n\t// Check if 127.0.0.2 is present in the DNSBL zone.\n\t_, err := lookup(ctx, elog, resolver, zone, [4]byte{127, 0, 0, 2})\n\tif err != nil {\n\t\tif err == ErrDNS {\n\t\t\treturn err\n\t\t}\n\t\tif err != ErrNotListed {\n\t\t\telog.Error(\"dnsbl health check failed for 127.0.0.2\", \"zone\", zone, \"err\", err)\n\t\t\treturn fmt.Errorf(\"dnsbl: health check failed for 127.0.0.2: %w\", err)\n\t\t}\n\t}\n\n\t// Check if 127.0.0.1 is not present in the DNSBL zone.\n\t_, err = lookup(ctx, elog, resolver, zone, [4]byte{127, 0, 0, 1})\n\tif err == nil {\n\t\telog.Error(\"dnsbl health check failed, 127.0.0.1 should not be listed\", \"zone\", zone)\n\t\treturn errors.New(\"dnsbl: health check failed, 127.0.0.1 should not be listed\")\n\t}\n\tif err != ErrNotListed {\n\t\tif err == ErrDNS {\n\t\t\treturn err\n\t\t}\n\t\telog.Error(\"dnsbl health check failed for 127.0.0.1\", \"zone\", zone, \"err\", err)\n\t\treturn fmt.Errorf(\"dnsbl: health check failed for 127.0.0.1: %w\", err)\n\t}\n\n\treturn nil\n}\n```\n\nThe `CheckHealth` function performs the following steps:\n\n1. It defers a function that checks if the returned error is a DNS timeout or context deadline exceeded error. If so, it wraps the error with `ErrDNS` to indicate a temporary DNS error.\n\n2. It calls the `lookup` function to check if the IP address `127.0.0.2` is present in the DNSBL zone. If the lookup returns `ErrDNS`, it immediately returns that error. If the lookup returns an error other than `ErrNotListed`, it logs an error and returns an error indicating that the health check failed for `127.0.0.2`.\n\n3. It calls the `lookup` function to check if the IP address `127.0.0.1` is not present in the DNSBL zone. If the lookup returns no error (i.e., `127.0.0.1` is listed), it logs an error and returns an error indicating that the health check failed because `127.0.0.1` should not be listed. If the lookup returns an error other than `ErrNotListed`, it logs an error and returns an error indicating that the health check failed for `127.0.0.1`.\n\n4. If both checks pass (i.e., `127.0.0.2` is listed and `127.0.0.1` is not listed), the function returns `nil` to indicate that the DNSBL zone is operating correctly.\n\nThe function uses the `lookup` function internally to perform the actual DNS lookups, and it handles temporary DNS errors by wrapping them with `ErrDNS`.", "mox-dmarcrpt/parse.go-ParseMessageReport": "Here is the generated code for the `ParseMessageReport` function based on the function signature and natural language annotations:\n\n```go\nfunc ParseMessageReport(elog *slog.Logger, r io.ReaderAt) (*Feedback, error) {\n\t// Create a new message.Reader with a maximum message size of 15MB\n\tmr := message.NewReader(r, 15*1024*1024)\n\t\n\t// Parse the message\n\tm, err := mr.ReadMessage()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parsing message: %v\", err)\n\t}\n\n\t// Create a new mlog.Log with the provided slog.Logger\n\tlog := mlog.New(elog)\n\n\t// Parse the message report\n\treport, err := parseMessageReport(log, m)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parsing message report: %v\", err)\n\t}\n\n\treturn report, nil\n}\n```\n\nThis function does the following:\n\n1. It creates a new `message.Reader` with the provided `io.ReaderAt` and a maximum message size of 15MB.\n\n2. It reads the message using `mr.ReadMessage()`. If an error occurs during parsing, it returns an error.\n\n3. It creates a new `mlog.Log` with the provided `slog.Logger`.\n\n4. It calls the `parseMessageReport` function with the created `mlog.Log` and the parsed message. This function recursively parses the message parts to find the DMARC aggregate feedback report.\n\n5. If an error occurs during the parsing of the message report, it returns an error.\n\n6. Finally, it returns the parsed `*Feedback` and a `nil` error if the parsing was successful.\n\nNote: The `parseMessageReport` function is already implemented in the provided code snippet, so it can be reused directly.", "mox-mox-/lifecycle.go-Register": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc (c *connections) Register(nc net.Conn, protocol, listener string) {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tck := connKind{protocol: protocol, listener: listener}\n\tc.conns[nc] = ck\n\n\tif _, ok := c.gauges[ck]; !ok {\n\t\tc.gauges[ck] = promauto.NewGaugeFunc(prometheus.GaugeOpts{\n\t\t\tName: \"mox_connections\",\n\t\t\tHelp: \"Number of active connections\",\n\t\t\tConstLabels: prometheus.Labels{\n\t\t\t\t\"protocol\": protocol,\n\t\t\t\t\"listener\": listener,\n\t\t\t},\n\t\t}, func() float64 {\n\t\t\tc.activeMutex.Lock()\n\t\t\tdefer c.activeMutex.Unlock()\n\t\t\treturn float64(c.active[ck])\n\t\t})\n\t}\n\n\tc.activeMutex.Lock()\n\tc.active[ck]++\n\tc.activeMutex.Unlock()\n}\n```\n\nThis function does the following:\n\n1. It acquires a lock on the `connections` struct to ensure thread-safety.\n\n2. It creates a `connKind` struct with the provided `protocol` and `listener` values.\n\n3. It adds the `net.Conn` and corresponding `connKind` to the `conns` map.\n\n4. It checks if a Prometheus gauge for the specific `connKind` already exists in the `gauges` map. If not, it creates a new gauge using `promauto.NewGaugeFunc` with the appropriate labels and a function that returns the current number of active connections for that `connKind`.\n\n5. It increments the count of active connections for the specific `connKind` in the `active` map while holding the `activeMutex` lock.\n\n6. Finally, it releases the lock on the `connections` struct.\n\nThis function registers a new connection, sets up Prometheus metrics for tracking the number of active connections, and increments the count of active connections for the specific protocol and listener combination.", "mox-smtpclient/dial.go-Dial": "Here is the generated code for the `Dial` function based on the provided function signature and natural language annotations:\n\n```go\nfunc Dial(ctx context.Context, elog *slog.Logger, dialer Dialer, host dns.IPDomain, ips []net.IP, port int, dialedIPs map[string][]net.IP, localIPs []net.IP) (conn net.Conn, ip net.IP, rerr error) {\n\t// Determine the address family used in the previous attempt\n\tprevFamily := \"\"\n\tif prev, ok := dialedIPs[host.ASCII]; ok && len(prev) > 0 {\n\t\tprevFamily = prev[0].To4() != nil\n\t}\n\n\t// Prioritize the address family based on the previous attempt\n\tvar prioritizedIPs []net.IP\n\tfor _, ip := range ips {\n\t\tif ip.To4() != nil && prevFamily == \"ipv6\" {\n\t\t\tprioritizedIPs = append(prioritizedIPs, ip)\n\t\t} else if ip.To4() == nil && prevFamily == \"ipv4\" {\n\t\t\tprioritizedIPs = append(prioritizedIPs, ip)\n\t\t}\n\t}\n\tprioritizedIPs = append(prioritizedIPs, ips...)\n\n\t// Attempt to dial each IP\n\tfor _, ip := range prioritizedIPs {\n\t\taddr := fmt.Sprintf(\"[%s]:%d\", ip, port)\n\t\tladdr := findLocalAddr(localIPs, ip)\n\n\t\telog.Debug(\"dialing\", mlog.Field(\"host\", host), mlog.Field(\"addr\", addr), mlog.Field(\"laddr\", laddr))\n\t\tconn, err := dial(ctx, dialer, 10*time.Second, addr, laddr)\n\t\tif err == nil {\n\t\t\t// Connection successful\n\t\t\tdialedIPs[host.ASCII] = append(dialedIPs[host.ASCII], ip)\n\t\t\treturn conn, ip, nil\n\t\t}\n\t\telog.Debug(\"dial error\", mlog.Field(\"host\", host), mlog.Field(\"addr\", addr), mlog.Field(\"err\", err))\n\t}\n\n\treturn nil, nil, fmt.Errorf(\"connecting to %s: %w\", host.ASCII, ErrConnectFailed)\n}\n\nfunc findLocalAddr(localIPs []net.IP, remoteIP net.IP) net.Addr {\n\tvar ipv4, ipv6 net.IP\n\tfor _, ip := range localIPs {\n\t\tif ip.To4() != nil {\n\t\t\tipv4 = ip\n\t\t} else {\n\t\t\tipv6 = ip\n\t\t}\n\t}\n\n\tif remoteIP.To4() != nil && ipv4 != nil {\n\t\treturn &net.TCPAddr{IP: ipv4}\n\t} else if remoteIP.To4() == nil && ipv6 != nil {\n\t\treturn &net.TCPAddr{IP: ipv6}\n\t}\n\treturn nil\n}\n```\n\nThe `Dial` function takes into account the previous attempts stored in `dialedIPs` to prioritize the address family (IPv4 or IPv6) for the current attempt. It tries to dial each IP in the prioritized order until a successful connection is established. The `findLocalAddr` helper function is used to find the appropriate local IP address based on the remote IP's address family and the available local IPs.\n\nThe function updates the `dialedIPs` map with the successfully dialed IP for future reference. If no connection can be established, an error is returned.", "mox-smtpclient/gather.go-GatherIPs": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc GatherIPs(ctx context.Context, elog *slog.Logger, resolver dns.Resolver, network string, host dns.IPDomain, dialedIPs map[string][]net.IP) (authentic bool, expandedAuthentic bool, expandedHost dns.Domain, ips []net.IP, dualstack bool, rerr error) {\n\tlog := mlog.New(\"smtpclient\", elog)\n\n\t// Start with the assumption that DNS responses are authentic\n\tauthentic = true\n\texpandedAuthentic = true\n\n\t// If host is an IP address, return it directly\n\tif len(host.IP) > 0 {\n\t\tips = []net.IP{host.IP}\n\t\treturn authentic, expandedAuthentic, host.Domain, ips, false, nil\n\t}\n\n\t// Follow CNAMEs to get the expanded host name\n\texpandedHost = host.Domain\n\tdomainsSeen := map[string]bool{}\n\tfor i := 0; ; i++ {\n\t\tif domainsSeen[expandedHost.ASCII] {\n\t\t\trerr = fmt.Errorf(\"%w: host %s: already saw %s\", errCNAMELoop, host.Domain, expandedHost)\n\t\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, rerr\n\t\t}\n\t\tdomainsSeen[expandedHost.ASCII] = true\n\n\t\tif i == 16 {\n\t\t\trerr = fmt.Errorf(\"%w: host %s, last resolved domain %s\", errCNAMELimit, host.Domain, expandedHost)\n\t\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, rerr\n\t\t}\n\n\t\tcctx, ccancel := context.WithTimeout(ctx, 30*time.Second)\n\t\tdefer ccancel()\n\t\tcname, cnameResult, err := resolver.LookupCNAME(cctx, expandedHost.ASCII+\".\")\n\t\tccancel()\n\t\tif i == 0 {\n\t\t\tauthentic = authentic && cnameResult.Authentic\n\t\t}\n\t\texpandedAuthentic = expandedAuthentic && cnameResult.Authentic\n\t\tif err != nil && !dns.IsNotFound(err) {\n\t\t\trerr = fmt.Errorf(\"%w: cname lookup for %s: %v\", errDNS, expandedHost, err)\n\t\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, rerr\n\t\t}\n\t\tif err == nil && cname != expandedHost.ASCII+\".\" {\n\t\t\td, err := dns.ParseDomain(strings.TrimSuffix(cname, \".\"))\n\t\t\tif err != nil {\n\t\t\t\trerr = fmt.Errorf(\"%w: parsing cname domain %s: %v\", errDNS, expandedHost, err)\n\t\t\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, rerr\n\t\t\t}\n\t\t\texpandedHost = d\n\t\t\tcontinue\n\t\t}\n\t\tbreak\n\t}\n\n\t// Lookup A and AAAA records for the expanded host\n\tictx, icancel := context.WithTimeout(ctx, 30*time.Second)\n\tdefer icancel()\n\tipv4Result, err := resolver.LookupIP(ictx, \"ip4\", expandedHost.ASCII+\".\")\n\ticancel()\n\tif err != nil && !dns.IsNotFound(err) {\n\t\trerr = fmt.Errorf(\"%w: ipv4 lookup for %s: %v\", errDNS, expandedHost, err)\n\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, rerr\n\t}\n\texpandedAuthentic = expandedAuthentic && ipv4Result.Authentic\n\n\tictx, icancel = context.WithTimeout(ctx, 30*time.Second)\n\tdefer icancel()\n\tipv6Result, err := resolver.LookupIP(ictx, \"ip6\", expandedHost.ASCII+\".\")\n\ticancel()\n\tif err != nil && !dns.IsNotFound(err) {\n\t\trerr = fmt.Errorf(\"%w: ipv6 lookup for %s: %v\", errDNS, expande", "mox-tlsrpt/report.go-TLSFailureDetails": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc TLSFailureDetails(err error) (ResultType, string) {\n\tswitch e := err.(type) {\n\tcase *tls.RecordHeaderError:\n\t\treturn ResultValidationFailure, \"tls-record-header-error\"\n\tcase *tls.Alert:\n\t\treturn ResultValidationFailure, fmt.Sprintf(\"tls-alert-%d\", e.Description)\n\tcase *x509.UnknownAuthorityError:\n\t\treturn ResultCertificateNotTrusted, \"unknown-authority\"\n\tcase *x509.CertificateInvalidError:\n\t\treason, ok := invalidReasons[e.Reason]\n\t\tif !ok {\n\t\t\treason = \"unknown-certificate-invalid-reason\"\n\t\t}\n\t\treturn ResultValidationFailure, reason\n\tcase *x509.HostnameError:\n\t\treturn ResultCertificateHostMismatch, \"certificate-host-mismatch\"\n\tcase *net.OpError:\n\t\tif e.Timeout() {\n\t\t\treturn ResultValidationFailure, \"network-timeout\"\n\t\t}\n\t\treturn ResultValidationFailure, \"network-error\"\n\tcase net.Error:\n\t\tif e.Timeout() {\n\t\t\treturn ResultValidationFailure, \"network-timeout\"\n\t\t}\n\t\treturn ResultValidationFailure, \"network-error\"\n\tdefault:\n\t\treturn ResultValidationFailure, \"unknown-error\"\n\t}\n}\n```\n\nThis function handles various error types that can occur during TLS handshakes:\n\n- `tls.RecordHeaderError`: Returns `ResultValidationFailure` with a reason code of \"tls-record-header-error\".\n- `tls.Alert`: Returns `ResultValidationFailure` with a reason code of \"tls-alert-<alert_description>\".\n- `x509.UnknownAuthorityError`: Returns `ResultCertificateNotTrusted` with a reason code of \"unknown-authority\".\n- `x509.CertificateInvalidError`: Returns `ResultValidationFailure` with a reason code based on the specific invalid reason. If the reason is unknown, it uses \"unknown-certificate-invalid-reason\".\n- `x509.HostnameError`: Returns `ResultCertificateHostMismatch` with a reason code of \"certificate-host-mismatch\".\n- `net.OpError` and `net.Error`: If the error is a timeout, it returns `ResultValidationFailure` with a reason code of \"network-timeout\". Otherwise, it returns `ResultValidationFailure` with a reason code of \"network-error\".\n- For any other error type, it returns `ResultValidationFailure` with a reason code of \"unknown-error\".\n\nThe function uses a switch statement with type assertions to determine the specific error type and map it to the appropriate `ResultType` and failure reason code.", "mox-tlsrpt/report.go-ParseMessage": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc ParseMessage(elog *slog.Logger, r io.ReaderAt) (*ReportJSON, error) {\n\tlog := mlog.New(\"tlsrpt\", elog)\n\tmr := io.NewSectionReader(r, 0, 15*1024*1024)\n\tmsg, err := message.EnsurePart(log, mr)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parsing message: %w\", err)\n\t}\n\treport, err := parseMessageReport(log, msg, false)\n\tif err == ErrNoReport {\n\t\treturn nil, fmt.Errorf(\"no tlsrpt report found in message\")\n\t}\n\treturn report, err\n}\n```\n\nThe key steps are:\n\n1. Create a new `mlog.Log` instance for logging.\n\n2. Create a `io.SectionReader` to limit reading the message to 15MB.\n\n3. Parse the message using `message.EnsurePart`.\n\n4. Call the existing `parseMessageReport` function to parse the TLSRPT report from the message parts. The `false` argument indicates to return an error if no report is found at the top level.\n\n5. If `parseMessageReport` returns `ErrNoReport`, return an error indicating no TLSRPT report was found in the message.\n\n6. Otherwise, return the parsed report and any error from `parseMessageReport`.\n\nThe maximum decompressed report size of 20MB is already enforced by the `Parse` function called by `parseReport`.", "mox-spf/received.go-Header": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc (r Received) Header() string {\n\tvar b strings.Builder\n\tb.WriteString(\"Received-SPF: \")\n\tb.WriteString(string(r.Result))\n\tif r.Comment != \"\" {\n\t\tb.WriteString(\" (\")\n\t\tb.WriteString(r.Comment)\n\t\tb.WriteByte(')')\n\t}\n\tb.WriteString(\" receiver=\")\n\tb.WriteString(receivedValueEncode(r.Receiver))\n\tb.WriteString(\"; client-ip=\")\n\tb.WriteString(r.ClientIP.String())\n\tb.WriteString(\"; envelope-from=\")\n\tb.WriteString(receivedValueEncode(r.EnvelopeFrom))\n\tb.WriteString(\"; helo=\")\n\tb.WriteString(receivedValueEncode(string(r.Helo)))\n\tif r.Problem != \"\" {\n\t\tb.WriteString(\"; problem=\")\n\t\tb.WriteString(receivedValueEncode(r.Problem))\n\t}\n\tb.WriteString(\"; identity=\")\n\tb.WriteString(string(r.Identity))\n\tif r.Mechanism != \"\" {\n\t\tb.WriteString(\"; mechanism=\")\n\t\tb.WriteString(receivedValueEncode(r.Mechanism))\n\t}\n\tb.WriteString(message.LineEnding)\n\treturn b.String()\n}\n```\n\nThis function generates a Received-SPF header string based on the fields of the `Received` struct. It follows the format specified in the example header comment.\n\nThe function uses a `strings.Builder` to efficiently build the header string. It writes the header name \"Received-SPF: \" followed by the `Result` field. If the `Comment` field is non-empty, it is included in parentheses after the result.\n\nThe function then appends the various fields of the `Received` struct, separated by semicolons and using the `receivedValueEncode` function to properly encode the field values. The `client-ip` field is converted to a string using the `String()` method of the `net.IP` type.\n\nIf the `Problem` field is non-empty, it is included with the \"problem=\" prefix. The `Identity` field is always included, and the `Mechanism` field is included if it is non-empty.\n\nFinally, the function appends the `message.LineEnding` (typically \"\\r\\n\") to the end of the header string and returns the resulting string.", "mox-spf/spf.go-Evaluate": "Here is the generated function based on the signature and annotation:\n\n```go\nfunc Evaluate(ctx context.Context, elog *slog.Logger, record *Record, resolver dns.Resolver, args Args) (rstatus Status, mechanism, rexplanation string, rauthentic bool, rerr error) {\n\tlog := mlog.New(\"spf\", elog)\n\tstart := time.Now()\n\tdefer func() {\n\t\tlog.Debugx(\"spf evaluate result\", rerr,\n\t\t\tslog.Int(\"dnsrequests\", *args.dnsRequests),\n\t\t\tslog.Int(\"voidlookups\", *args.voidLookups),\n\t\t\tslog.Any(\"domain\", args.domain),\n\t\t\tslog.Any(\"status\", rstatus),\n\t\t\tslog.String(\"mechanism\", mechanism),\n\t\t\tslog.String(\"explanation\", rexplanation),\n\t\t\tslog.Duration(\"duration\", time.Since(start)))\n\t}()\n\n\tif args.dnsRequests == nil {\n\t\targs.dnsRequests = new(int)\n\t\targs.voidLookups = new(int)\n\t}\n\n\t// Response is authentic until we find a non-authentic DNS response.\n\trauthentic = true\n\n\t// To4 returns nil for an IPv6 address. To16 will return an IPv4-to-IPv6-mapped address.\n\tvar remote6 net.IP\n\tremote4 := args.RemoteIP.To4()\n\tif remote4 == nil {\n\t\tremote6 = args.RemoteIP.To16()\n\t}\n\n\t// Check if ip matches remote ip, taking cidr mask into account.\n\tcheckIP := func(ip net.IP, d Directive) bool {\n\t\t// ../rfc/7208:1097\n\t\tif remote4 != nil {\n\t\t\tip4 := ip.To4()\n\t\t\tif ip4 == nil {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tones := 32\n\t\t\tif d.IP4CIDRLen != nil {\n\t\t\t\tones = *d.IP4CIDRLen\n\t\t\t}\n\t\t\tmask := net.CIDRMask(ones, 32)\n\t\t\treturn ip4.Mask(mask).Equal(remote4.Mask(mask))\n\t\t}\n\n\t\tip6 := ip.To16()\n\t\tif ip6 == nil {\n\t\t\treturn false\n\t\t}\n\t\tones := 128\n\t\tif d.IP6CIDRLen != nil {\n\t\t\tones = *d.IP6CIDRLen\n\t\t}\n\t\tmask := net.CIDRMask(ones, 128)\n\t\treturn ip6.Mask(mask).Equal(remote6.Mask(mask))\n\t}\n\n\t// Used for \"a\" and \"mx\".\n\tcheckHostIP := func(domain dns.Domain, d Directive, args *Args) (bool, Status, error) {\n\t\tips, result, err := resolver.LookupIP(ctx, \"ip\", domain.ASCII+\".\")\n\t\trauthentic = rauthentic && result.Authentic\n\t\ttrackVoidLookup(err, args)\n\t\t// If \"not found\", we must ignore the error and treat as zero records in answer. ../rfc/7208:1116\n\t\tif err != nil && !dns.IsNotFound(err) {\n\t\t\treturn false, StatusTemperror, err\n\t\t}\n\t\tfor _, ip := range ips {\n\t\t\tif checkIP(ip, d) {\n\t\t\t\treturn true, StatusPass, nil\n\t\t\t}\n\t\t}\n\t\treturn false, StatusNone, nil\n\t}\n\n\tfor _, d := range record.Directives {\n\t\tvar match bool\n\n\t\tswitch d.Mechanism {\n\t\tcase \"include\", \"a\", \"mx\", \"ptr\", \"exists\":\n\t\t\tif err := trackLookupLimits(&args); err != nil {\n\t\t\t\treturn StatusPermerror, d.MechanismString(), \"\", rauthentic, err\n\t\t\t}\n\t\t}\n\n\t\tswitch d.Mechanism {\n\t\tcase \"all\":\n\t\t\t// ../rfc/7208:1127\n\t\t\tmatch = true\n\n\t\tcase \"include\":\n\t\t\t// ../rfc/7208:1143\n\t\t\tname, authentic, err := expandDomainSpecDNS(ctx, resolver, d.DomainSpec, args)\n\t\t\trauthen", "mox-spf/parse.go-Record": "Here is the generated function based on the function signature and natural language annotations:\n\n```go\nfunc (r Record) Record() (string, error) {\n\tvar txt strings.Builder\n\n\t// Start with the SPF version\n\ttxt.WriteString(\"v=spf1\")\n\n\t// Add the directives\n\tfor _, d := range r.Directives {\n\t\ttxt.WriteString(\" \")\n\t\ttxt.WriteString(d.MechanismString())\n\t}\n\n\t// Add the redirect modifier if present\n\tif r.Redirect != \"\" {\n\t\ttxt.WriteString(\" redirect=\")\n\t\ttxt.WriteString(r.Redirect)\n\t}\n\n\t// Add the explanation modifier if present\n\tif r.Explanation != \"\" {\n\t\ttxt.WriteString(\" exp=\")\n\t\ttxt.WriteString(r.Explanation)\n\t}\n\n\t// Add other modifiers\n\tfor _, m := range r.Other {\n\t\ttxt.WriteString(\" \")\n\t\ttxt.WriteString(m.Key)\n\t\ttxt.WriteString(\"=\")\n\t\ttxt.WriteString(m.Value)\n\t}\n\n\treturn txt.String(), nil\n}\n```\n\nThis function generates a DNS TXT record string for an SPF record based on the provided `Record` struct. Here's how it works:\n\n1. It starts by initializing a `strings.Builder` to efficiently build the resulting string.\n\n2. It writes the SPF version (`v=spf1`) to the builder.\n\n3. It iterates over the directives in the `Record` struct and appends each directive to the builder using the `MechanismString()` method, which returns the directive in string form. Each directive is preceded by a space.\n\n4. If the `Redirect` field is present in the `Record` struct, it appends the `redirect=` modifier along with the redirect value to the builder.\n\n5. If the `Explanation` field is present in the `Record` struct, it appends the `exp=` modifier along with the explanation value to the builder.\n\n6. It iterates over the other modifiers in the `Record` struct and appends each modifier to the builder in the format `key=value`. Each modifier is preceded by a space.\n\n7. Finally, it returns the generated string using `txt.String()` and a `nil` error, indicating that the record generation was successful.\n\nThis function assumes that the `Record` struct and its fields are properly populated before calling this method. It generates a valid SPF record string based on the provided data.", "mox-message/part.go-EnsurePart": "Here is the generated code for the `EnsurePart` function based on the provided function signature and natural language annotations:\n\n```go\nfunc EnsurePart(elog *slog.Logger, strict bool, r io.ReaderAt, size int64) (Part, error) {\n\tlog := mlog.New(\"message\", elog)\n\tp, err := newPart(log, strict, r, 0, nil)\n\tif err != nil {\n\t\tlog.Infox(\"parsing part, attempting to recover\", err)\n\t\treturn fallbackPart(p, r, size)\n\t}\n\tif err := p.Walk(log.Logger, nil); err != nil {\n\t\tlog.Infox(\"walking part, attempting to recover\", err)\n\t\treturn fallbackPart(p, r, size)\n\t}\n\treturn p, nil\n}\n```\n\nThe `EnsurePart` function does the following:\n\n1. It creates a new logger instance using `mlog.New` with the provided `elog` logger.\n\n2. It calls the `newPart` function to parse the part, passing the logger, `strict` flag, `r` reader, offset of 0, and `nil` parent. This attempts to parse the part as a new top-level part.\n\n3. If an error occurs during parsing (`err` is non-nil), it logs an informational message using `log.Infox` indicating that parsing failed and an attempt to recover will be made. It then calls the `fallbackPart` function, passing the partially parsed part `p`, the reader `r`, and the `size` of the part. The `fallbackPart` function returns a usable part as `application/octet-stream` along with any error that occurred.\n\n4. If parsing succeeds without an error, it calls the `Walk` method on the parsed part `p`, passing the logger and `nil` parent. This walks through the part and its subparts, decoding and collecting offsets, sizes, and line counts.\n\n5. If an error occurs during the `Walk` method (`err` is non-nil), it logs an informational message using `log.Infox` indicating that walking the part failed and an attempt to recover will be made. It then calls the `fallbackPart` function, similar to step 3.\n\n6. Finally, it returns the parsed or recovered part `p` along with any error that occurred during the process.\n\nThe `EnsurePart` function ensures that a usable part is always returned, even if errors occur during parsing or walking the part. If errors occur, it attempts to recover by returning the part as `application/octet-stream` using the `fallbackPart` function.", "mox-message/part.go-ParseNextPart": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc (p *Part) ParseNextPart(elog *slog.Logger) (*Part, error) {\n\tlog := mlog.New(\"message\", elog)\n\n\tif len(p.bound) == 0 {\n\t\treturn nil, errNotMultipart\n\t}\n\n\tif p.nextBoundOffset < 0 {\n\t\t// We have already parsed all parts.\n\t\treturn nil, io.EOF\n\t}\n\n\t// If we are not at the expected offset, skip lines until we find the boundary.\n\tif p.nextBoundOffset != p.lastBoundOffset {\n\t\tb := &bufAt{strict: p.strict, r: p.r, offset: p.lastBoundOffset}\n\t\tfor {\n\t\t\tline, _, err := b.ReadLine(true)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"parsing line looking for boundary: %w\", err)\n\t\t\t}\n\t\t\tif match, _ := checkBound(line, p.bound); match {\n\t\t\t\tp.nextBoundOffset = b.offset\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\tpp, err := newPart(log, p.strict, p.r, p.nextBoundOffset, p)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tb := &bufAt{strict: p.strict, r: p.r, offset: pp.BodyOffset}\n\tfor {\n\t\tline, _, err := b.PeekLine(true)\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\treturn nil, errMissingClosingBoundary\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"parsing line for next boundary: %w\", err)\n\t\t}\n\t\tif match, finish := checkBound(line, p.bound); match {\n\t\t\tpp.EndOffset = b.offset\n\t\t\tp.lastBoundOffset = b.offset\n\t\t\tb.ReadLine(true)\n\t\t\tp.nextBoundOffset = b.offset\n\t\t\tif finish {\n\t\t\t\tp.nextBoundOffset = -1\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t\tb.ReadLine(true)\n\t}\n\treturn &pp, nil\n}\n```\n\nThis function parses the next subpart of a multipart message. It returns the parsed part and any error encountered. If there are no more parts, it returns `io.EOF` and a nil part.\n\nThe function first checks if the current part is actually a multipart message by checking the `bound` field. If not, it returns `errNotMultipart`.\n\nIf `nextBoundOffset` is negative, it means all parts have already been parsed, so it returns `io.EOF`.\n\nIf the current offset is not at the expected `nextBoundOffset`, it skips lines until it finds the boundary.\n\nIt then calls `newPart` to parse the next part, passing the current logger, strict mode, reader, offset, and the current part as the parent.\n\nAfter parsing the part, it reads lines until it finds the next boundary or the closing boundary. It updates the `EndOffset` of the parsed part, and the `lastBoundOffset` and `nextBoundOffset` of the current part accordingly. If the closing boundary is found, it sets `nextBoundOffset` to -1 to indicate all parts have been parsed.\n\nFinally, it returns a pointer to the parsed part.", "mox-message/messageid.go-MessageIDCanonical": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc MessageIDCanonical(s string) (string, bool, error) {\n\tif !strings.HasPrefix(s, \"<\") || !strings.HasSuffix(s, \">\") {\n\t\treturn \"\", false, errBadMessageID\n\t}\n\ts = s[1 : len(s)-1]\n\n\taddr, err := smtp.ParseAddress(s)\n\tif err != nil {\n\t\treturn strings.ToLower(s), true, nil\n\t}\n\n\tlocalpart, domain := addr.Localpart, addr.Domain\n\tlocalpart, err = smtp.ParseDotAtom(localpart)\n\tif err != nil {\n\t\treturn strings.ToLower(s), true, nil\n\t}\n\n\treturn fmt.Sprintf(\"%s@%s\", localpart, strings.ToLower(domain)), false, nil\n}\n```\n\nThe function does the following:\n\n1. It checks if the input string `s` starts with \"<\" and ends with \">\". If not, it returns an error `errBadMessageID`.\n\n2. It removes the \"<\" and \">\" characters from the string.\n\n3. It tries to parse the string as an email address using `smtp.ParseAddress()`. If it fails, it means the message-id doesn't adhere to the localpart@domain syntax. In this case, it returns the lowercase version of the string and `true` as the second return value.\n\n4. If the parsing succeeds, it extracts the localpart and domain from the parsed address.\n\n5. It tries to parse the localpart as a dot-atom using `smtp.ParseDotAtom()`. If it fails, it means the localpart is not in the correct format. In this case, it returns the lowercase version of the original string and `true` as the second return value.\n\n6. If both the localpart and domain are valid, it returns the canonical message-id in the format \"localpart@domain\" (lowercase), and `false` as the second return value indicating it adheres to the localpart@domain syntax.\n\nThe function handles the cases mentioned in the annotations, returning the canonical message-id, a boolean indicating if it adheres to the localpart@domain syntax, and an error if the message-id is invalid.", "mox-message/decode.go-DecodeReader": "Here is the generated code for the `DecodeReader` function based on the provided function signature and natural language annotations:\n\n```go\nfunc DecodeReader(charset string, r io.Reader) io.Reader {\n\tcharset = strings.ToLower(charset)\n\tif charset == \"\" || charset == \"us-ascii\" || charset == \"utf-8\" || charset == \"unknown\" {\n\t\treturn r\n\t}\n\n\tenc, err := ianaindex.MIME.Encoding(charset)\n\tif err != nil {\n\t\treturn r\n\t}\n\n\treturn enc.NewDecoder().Reader(r)\n}\n```\n\nExplanation:\n1. The function takes two parameters: `charset` (a string representing the character set) and `r` (an `io.Reader` to read from).\n2. It converts the `charset` to lowercase for case-insensitive comparison.\n3. If the `charset` is empty, \"us-ascii\", \"utf-8\", or \"unknown\", the original reader `r` is returned without any decoding.\n4. If the `charset` is not one of the above, it uses the `ianaindex.MIME.Encoding` function to get the encoding for the specified `charset`.\n5. If an error occurs while getting the encoding, the original reader `r` is returned.\n6. If the encoding is successfully obtained, it creates a new decoder using `enc.NewDecoder()` and returns a reader that wraps the original reader `r` with the decoder.\n\nThis function allows decoding the data read from the `io.Reader` based on the specified character set. If the character set is one of the special cases mentioned (empty, \"us-ascii\", \"utf-8\", or \"unknown\"), no decoding is performed, and the original reader is returned as is.", "mox-message/referencedids.go-ReferencedIDs": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc ReferencedIDs(references []string, inReplyTo []string) ([]string, error) {\n\tvar ids []string\n\tfor _, ref := range references {\n\t\tfor _, id := range smtp.SplitReferences(ref) {\n\t\t\tif id == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcanonicalID, err := smtp.MessageIDCanonical(id)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tids = append(ids, canonicalID)\n\t\t}\n\t}\n\tif len(ids) == 0 {\n\t\tfor _, irt := range inReplyTo {\n\t\t\tif irt == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcanonicalID, err := smtp.MessageIDCanonical(irt)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tids = append(ids, canonicalID)\n\t\t}\n\t}\n\treturn ids, nil\n}\n```\n\nExplanation:\n1. The function takes two parameters: `references` (a slice of strings representing the References headers) and `inReplyTo` (a slice of strings representing the In-Reply-To headers).\n2. It initializes an empty slice called `ids` to store the referenced Message-IDs.\n3. It iterates over each reference in the `references` slice.\n4. For each reference, it splits the reference into individual Message-IDs using the `smtp.SplitReferences` function.\n5. It skips empty Message-IDs.\n6. For each non-empty Message-ID, it canonicalizes the ID using the `smtp.MessageIDCanonical` function for thread-matching.\n7. If an error occurs during canonicalization, it returns `nil` and the error.\n8. It appends the canonicalized Message-ID to the `ids` slice.\n9. If no Message-IDs were found in the References headers, it falls back to the In-Reply-To headers.\n10. It iterates over each In-Reply-To header in the `inReplyTo` slice.\n11. It skips empty In-Reply-To headers.\n12. For each non-empty In-Reply-To header, it canonicalizes the ID using the `smtp.MessageIDCanonical` function.\n13. If an error occurs during canonicalization, it returns `nil` and the error.\n14. It appends the canonicalized In-Reply-To header to the `ids` slice.\n15. Finally, it returns the `ids` slice containing the referenced Message-IDs and `nil` for the error.\n\nThis function extracts the referenced Message-IDs from the References headers, with a fallback to the In-Reply-To headers if no Message-IDs were found in the References headers. It canonicalizes the IDs for thread-matching and skips empty IDs.", "mox-message/authresults.go-ParseAuthResults": "Here is the generated code for the `ParseAuthResults` function:\n\n```go\nfunc ParseAuthResults(s string) (ar AuthResults, err error) {\n\tdefer func() {\n\t\tx := recover()\n\t\tif x == nil {\n\t\t\treturn\n\t\t}\n\t\tperr, ok := x.(parseError)\n\t\tif ok {\n\t\t\terr = perr.err\n\t\t\treturn\n\t\t}\n\t\tpanic(x)\n\t}()\n\n\tp := &parser{s: s, lower: strings.ToLower(s)}\n\tp.cfws()\n\tar.Hostname = p.xvalue()\n\tp.cfws()\n\tif p.take(\"/\") {\n\t\tar.Version = p.xdigits()\n\t\tp.cfws()\n\t}\n\tp.xtake(\";\")\n\tp.cfws()\n\n\tif p.take(\"none\") {\n\t\tp.cfws()\n\t\tif !p.end() {\n\t\t\tp.xerrorf(\"junk after none\")\n\t\t}\n\t\treturn\n\t}\n\n\tfor !p.end() {\n\t\tmethodKeyword := p.xkeyword(false)\n\t\tam := p.xresinfo(methodKeyword)\n\t\tar.Methods = append(ar.Methods, am)\n\t\tp.cfws()\n\t\tif !p.take(\";\") {\n\t\t\tbreak\n\t\t}\n\t\tp.cfws()\n\t}\n\tif !p.end() {\n\t\tp.xerrorf(\"junk at end of header\")\n\t}\n\treturn\n}\n```\n\nThe `ParseAuthResults` function takes a string `s` representing the Authentication-Results header value and returns a parsed `AuthResults` struct and an error if parsing fails.\n\nThe function starts by setting up a deferred recovery function to handle any parsing errors and return them as the `err` value.\n\nIt then initializes a `parser` struct with the input string `s` and a lowercase version of `s` for case-insensitive comparisons.\n\nThe function proceeds to parse the header value according to the specified syntax:\n1. It skips any comments or folding white space (CFWS) at the beginning.\n2. It parses the hostname value.\n3. It skips any CFWS and checks for an optional version number.\n4. It expects a semicolon (`;`) separator and skips any CFWS.\n5. If the keyword \"none\" is present, it skips any CFWS and ensures there is no junk after \"none\" before returning.\n6. It enters a loop to parse each authentication method result until the end of the header is reached.\n   - It parses the method keyword and calls `xresinfo` to parse the rest of the method result.\n   - It appends the parsed `AuthMethod` to the `Methods` slice of the `AuthResults` struct.\n   - It skips any CFWS and checks for a semicolon separator. If not present, it breaks the loop.\n7. Finally, it checks if there is any junk at the end of the header and returns an error if present.\n\nThe function returns the parsed `AuthResults` struct and any parsing error encountered.\n\nNote: The code relies on several helper functions defined in the `parser` struct to handle specific parsing tasks and error handling.", "mox-store/msgreader.go-FileMsgReader": "Here is the generated function based on the provided signature and natural language annotations:\n\n```go\nfunc FileMsgReader(prefix []byte, msgFile *os.File) *MsgReader {\n\tmsgReader := &MsgReader{\n\t\tprefix: prefix,\n\t\tf:      msgFile,\n\t}\n\n\tfi, err := msgFile.Stat()\n\tif err != nil {\n\t\tmsgReader.err = err\n\t\treturn msgReader\n\t}\n\n\tmsgReader.path = msgFile.Name()\n\tmsgReader.size = int64(len(prefix)) + fi.Size()\n\n\treturn msgReader\n}\n```\n\nExplanation:\n1. We create a new `MsgReader` instance and assign the provided `prefix` and `msgFile` to the corresponding fields.\n2. We retrieve the file information using `msgFile.Stat()` to get the file size. If an error occurs during this step, we set the `err` field of the `MsgReader` to the error and return the `MsgReader` instance.\n3. We set the `path` field of the `MsgReader` to the name of the `msgFile` using `msgFile.Name()`.\n4. We calculate the total size of the message by adding the length of the `prefix` and the size of the `msgFile` obtained from the file information.\n5. Finally, we return the initialized `MsgReader` instance.\n\nNote: If initialization fails (i.e., an error occurs while retrieving the file information), the `err` field of the `MsgReader` will be set to the error. Subsequent reads from the `MsgReader` will return this error.\n\nThe caller should only call `Close()` on the returned `MsgReader` if they want to close the `msgFile`. The `MsgReader` does not take ownership of the `msgFile` and assumes that the caller will handle its closure appropriately.", "mox-store/import.go-ParseDovecotKeywordsFlags": "Here is the generated code for the ParseDovecotKeywordsFlags function:\n\n```go\nfunc ParseDovecotKeywordsFlags(r io.Reader, log mlog.Log) ([]string, error) {\n\tvar keywords []string\n\tscanner := bufio.NewScanner(r)\n\tfor scanner.Scan() {\n\t\tline := scanner.Text()\n\t\tparts := strings.SplitN(line, \" \", 2)\n\t\tif len(parts) != 2 {\n\t\t\tlog.Errorw(\"invalid line in dovecot-keywords file\", \"line\", line)\n\t\t\tcontinue\n\t\t}\n\t\tkw := strings.ToLower(parts[1])\n\t\tswitch kw {\n\t\tcase \"$forwarded\", \"forwarded\", \"$junk\", \"junk\", \"$notjunk\", \"notjunk\", \"nonjunk\", \"$mdnsent\", \"mdnsent\", \"$phishing\", \"phishing\":\n\t\t\tkeywords = append(keywords, kw)\n\t\tdefault:\n\t\t\tif err := CheckKeyword(kw); err == nil {\n\t\t\t\tkeywords = append(keywords, kw)\n\t\t\t} else {\n\t\t\t\tlog.Errorw(\"invalid keyword in dovecot-keywords file\", \"keyword\", kw)\n\t\t\t}\n\t\t}\n\t}\n\tif err := scanner.Err(); err != nil {\n\t\treturn keywords, fmt.Errorf(\"error reading dovecot-keywords file: %v\", err)\n\t}\n\treturn keywords, nil\n}\n```\n\nThe function does the following:\n\n1. It initializes a slice to store the parsed keywords.\n\n2. It creates a scanner to read the input line by line.\n\n3. For each line:\n   - It splits the line into two parts using space as the separator.\n   - If the line is not in the expected format, it logs an error and continues to the next line.\n   - It converts the keyword to lowercase.\n   - If the keyword is one of the well-known system flags, it appends it to the keywords slice.\n   - Otherwise, it checks if the keyword is valid using the `CheckKeyword` function.\n     - If the keyword is valid, it appends it to the keywords slice.\n     - If the keyword is invalid, it logs an error.\n\n4. After processing all lines, it checks if there was an error during scanning. If there was an error, it returns the parsed keywords along with the error.\n\n5. Finally, it returns the slice of parsed keywords and a nil error if there were no errors.\n\nNote: The `CheckKeyword` function is assumed to be defined elsewhere in the codebase and is used to validate custom keywords.", "mox-store/account.go-MessageRuleset": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc MessageRuleset(log mlog.Log, dest config.Destination, m *Message, msgPrefix []byte, msgFile *os.File) *config.Ruleset {\n\t// Combine the message prefix and file contents\n\tmsgReader := io.MultiReader(bytes.NewReader(msgPrefix), msgFile)\n\n\t// Parse the message\n\tparsedMsg, err := message.Parse(msgReader)\n\tif err != nil {\n\t\tlog.Error(\"failed to parse message for ruleset matching\", mlog.Field(\"err\", err))\n\t\treturn nil\n\t}\n\n\t// Iterate through the rulesets in the destination\n\tfor _, ruleset := range dest.Rulesets {\n\t\t// Check if the ruleset matches the message\n\t\tif ruleset.Matches(m.RemoteIP, m.EHLODomain, m.MailFromLocalpart, m.MailFromDomain, m.RcptToLocalpart, m.RcptToDomain,\n\t\t\tm.EHLOValidation, m.MailFromValidation, m.MsgFromValidation, m.DKIMDomains, parsedMsg) {\n\t\t\t// Return the matching ruleset\n\t\t\treturn &ruleset\n\t\t}\n\t}\n\n\t// No matching ruleset found\n\treturn nil\n}\n```\n\nThis function does the following:\n\n1. It combines the message prefix (`msgPrefix`) and the contents of the message file (`msgFile`) using `io.MultiReader` to create a single reader for the entire message.\n\n2. It parses the message using `message.Parse` to obtain a parsed representation of the message (`parsedMsg`). If parsing fails, an error is logged and `nil` is returned.\n\n3. It iterates through the rulesets in the provided destination (`dest.Rulesets`).\n\n4. For each ruleset, it calls the `Matches` method, passing the relevant fields from the `Message` struct (`m`) and the parsed message (`parsedMsg`). The `Matches` method is assumed to be defined on the `config.Ruleset` type and checks if the ruleset matches the given message based on various criteria.\n\n5. If a matching ruleset is found, it is returned.\n\n6. If no matching ruleset is found after iterating through all the rulesets, `nil` is returned.\n\nNote: The implementation assumes the existence of certain types and methods, such as `config.Destination`, `config.Ruleset`, and the `Matches` method on `config.Ruleset`. These types and methods should be defined elsewhere in the codebase for the function to compile and work correctly.", "mox-smtp/address.go-ParseAddress": "Here is the generated code for the ParseAddress function:\n\n```go\nfunc ParseAddress(s string) (address Address, err error) {\n\t// Split the address into localpart and domain.\n\tparts := strings.SplitN(s, \"@\", 2)\n\tif len(parts) != 2 {\n\t\treturn Address{}, fmt.Errorf(\"%w: missing @\", ErrBadAddress)\n\t}\n\n\tlocalpart, err := parseLocalPart(parts[0])\n\tif err != nil {\n\t\treturn Address{}, fmt.Errorf(\"%w: %v\", ErrBadAddress, err)\n\t}\n\n\tdomain, err := dns.ParseDomain(parts[1])\n\tif err != nil {\n\t\treturn Address{}, fmt.Errorf(\"%w: %v\", ErrBadAddress, err)\n\t}\n\n\treturn Address{Localpart: localpart, Domain: domain}, nil\n}\n```\n\nThis implementation does the following:\n\n1. It splits the input string `s` into two parts using `strings.SplitN` with \"@\" as the separator. If the split does not result in exactly two parts, it returns an error indicating a missing \"@\" symbol.\n\n2. It parses the localpart by calling the `parseLocalPart` function. If an error occurs during parsing, it returns an error wrapping `ErrBadAddress` along with the specific parsing error.\n\n3. It parses the domain by calling `dns.ParseDomain`. If an error occurs during domain parsing, it returns an error wrapping `ErrBadAddress` along with the specific domain parsing error.\n\n4. If both the localpart and domain are parsed successfully, it returns an `Address` struct with the parsed `Localpart` and `Domain` fields.\n\nThe function returns an error wrapping `ErrBadAddress` if the address is invalid, either due to a missing \"@\" symbol or if the localpart or domain parsing fails.", "mox-smtp/address.go-ParseLocalpart": "Here is the generated code for the `ParseLocalpart` function:\n\n```go\nfunc ParseLocalpart(s string) (localpart Localpart, err error) {\n\tlocalpart, _, err = parseLocalPart(s)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"%w: %s\", ErrBadAddress, err)\n\t}\n\treturn localpart, nil\n}\n```\n\nThe `ParseLocalpart` function takes a string `s` as input and returns the parsed `Localpart` and an error if the localpart is invalid.\n\nIt calls the `parseLocalPart` function internally to parse the localpart. If `parseLocalPart` returns an error, it wraps the error with `ErrBadAddress` and returns it.\n\nIf the parsing is successful, it returns the parsed `Localpart` and a `nil` error.", "mox-smtp/data.go-DataWrite": "Here is the generated code for the `DataWrite` function:\n\n```go\nfunc DataWrite(w io.Writer, r io.Reader) error {\n\tvar plast, last byte\n\tvar buf []byte\n\n\tfor {\n\t\tn, err := r.Read(buf[:])\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tif plast != '\\r' || last != '\\n' {\n\t\t\t\t\treturn errMissingCRLF\n\t\t\t\t}\n\t\t\t\t_, err = w.Write(dotcrlf)\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\n\t\tfor i := 0; i < n; i++ {\n\t\t\tb := buf[i]\n\t\t\tif b == '\\r' {\n\t\t\t\tif i+1 == n {\n\t\t\t\t\treturn ErrCRLF\n\t\t\t\t}\n\t\t\t\tif buf[i+1] != '\\n' {\n\t\t\t\t\treturn ErrCRLF\n\t\t\t\t}\n\t\t\t\ti++\n\t\t\t} else if b == '\\n' {\n\t\t\t\tif plast != '\\r' {\n\t\t\t\t\treturn ErrCRLF\n\t\t\t\t}\n\t\t\t}\n\t\t\tif b == '.' && plast == '\\r' && last == '\\n' {\n\t\t\t\tif _, err := w.Write([]byte(\".\")); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\tif _, err := w.Write(buf[i : i+1]); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tplast, last = last, b\n\t\t}\n\t}\n}\n```\n\nThe `DataWrite` function reads data from the `io.Reader` `r` and writes it to the `io.Writer` `w` with dot stuffing, as required by the SMTP data command.\n\nIt uses a loop to read data from `r` into a buffer `buf`. For each byte in the buffer, it checks for bare carriage returns or bare newlines and returns an error if found. It also checks for the sequence \"\\r\\n.\" and writes an extra dot to `w` to escape it.\n\nThe function keeps track of the previous two bytes (`plast` and `last`) to check for the \"\\r\\n.\" sequence and bare carriage returns or newlines.\n\nIf the end of the message is reached (indicated by `io.EOF`), it checks that the message ends with \"\\r\\n\" and writes the final \".\\r\\n\" to `w`.\n\nIf any error occurs during reading or writing, the function returns the error.", "mox-scram/scram.go-NewServer": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc NewServer(h func() hash.Hash, clientFirst []byte, cs *tls.ConnectionState, channelBindingRequired bool) (server *Server, rerr error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif err, ok := r.(error); ok {\n\t\t\t\trerr = err\n\t\t\t} else {\n\t\t\t\tpanic(r)\n\t\t\t}\n\t\t}\n\t}()\n\n\tp := newParser(clientFirst)\n\tgs2header := p.xgs2header()\n\tauthzid := p.xauthzid()\n\tp.xtake(\",\")\n\tnonce := p.xnonce()\n\tp.xempty()\n\n\tif !norm.NFC.IsNormalString(authzid) {\n\t\treturn nil, ErrNorm\n\t}\n\n\tcbindName, cbindData := parseGs2Header(gs2header)\n\tif cbindName != \"n\" && cs == nil {\n\t\treturn nil, fmt.Errorf(\"%w: client requires channel binding, but no TLS connection state provided\", ErrChannelBindingNotSupported)\n\t}\n\tif cbindName == \"y\" && !channelBindingRequired {\n\t\treturn nil, fmt.Errorf(\"%w: client requires channel binding, but server did not\", ErrChannelBindingNotSupported)\n\t}\n\tif cbindName == \"p\" && cs == nil {\n\t\treturn nil, fmt.Errorf(\"%w: client requires PLUS variant, but no TLS connection state provided\", ErrChannelBindingNotSupported)\n\t}\n\tif cs != nil {\n\t\tvar err error\n\t\tcbindData, err = channelBindData(cs)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"%w: %v\", ErrChannelBindingNotSupported, err)\n\t\t}\n\t}\n\n\ts := &Server{\n\t\th:               h,\n\t\tAuthentication:  authzid,\n\t\tAuthorization:   authzid,\n\t\tclientFirstBare: string(clientFirst[len(gs2header):]),\n\t\tgs2header:       gs2header,\n\t\tclientNonce:     nonce,\n\t\tchannelBinding:  cbindData,\n\t}\n\treturn s, nil\n}\n```\n\nThe key points:\n\n- It uses `defer` with `recover()` to catch any panics and return them as errors.\n- It parses the client's first message using a `parser` helper.\n- It checks the authzid is normalized.\n- It parses the gs2header to determine channel binding requirements.\n- It checks the channel binding requirements against the provided TLS connection state and `channelBindingRequired` flag, returning appropriate errors if mismatched.\n- If a TLS connection state is provided, it extracts the channel binding data.\n- Finally, it initializes and returns a new `Server` instance with the parsed data.\n\nLet me know if you have any other questions!", "mox-scram/scram.go-ServerFirst": "Here is the generated code for the `ServerFirst` method:\n\n```go\nfunc (s *Server) ServerFirst(iterations int, salt []byte) (string, error) {\n\tif iterations < 2048 {\n\t\treturn \"\", fmt.Errorf(\"%w: too few iterations\", ErrUnsafe)\n\t}\n\tif len(salt) < 8 {\n\t\treturn \"\", fmt.Errorf(\"%w: salt too short\", ErrUnsafe)\n\t}\n\n\t// Extract client nonce from gs2-header.\n\tp := newParser([]byte(s.gs2header))\n\tvar rerr error\n\tdefer p.recover(&rerr)\n\t_ = p.xsaslname() // Skip authzid, if any.\n\tp.xtake(\",\")\n\tif !p.take(\"n\") {\n\t\treturn \"\", fmt.Errorf(\"%w: gs2-header missing 'n'\", ErrProtocol)\n\t}\n\tp.xtake(\",\")\n\ts.clientNonce = p.xnonce()\n\n\t// Generate server nonce.\n\tvar serverNonce string\n\tif s.serverNonceOverride != \"\" {\n\t\tserverNonce = s.serverNonceOverride\n\t} else {\n\t\tserverNonce = base64.StdEncoding.EncodeToString(MakeRandom())\n\t}\n\ts.nonce = s.clientNonce + serverNonce\n\n\t// Extract channel binding data, if any.\n\tif strings.HasPrefix(s.gs2header, \"p=\") {\n\t\tif s.channelBinding == nil {\n\t\t\treturn \"\", ErrServerDoesSupportChannelBinding\n\t\t}\n\t\tp.xtake(\",\")\n\t\ts.channelBinding = p.xsalt()\n\t}\n\n\t// Construct server-first-message.\n\t// ../rfc/5802:959\n\tr := \"r=\" + s.nonce + \",s=\" + base64.StdEncoding.EncodeToString(salt) + \",i=\" + strconv.Itoa(iterations)\n\ts.serverFirst = r\n\treturn r, nil\n}\n```\n\nThis implementation follows these steps:\n\n1. Validates the provided `iterations` and `salt` parameters to ensure they meet minimum requirements.\n\n2. Extracts the client nonce from the `gs2header` field that was parsed during `NewServer`. It expects the `gs2header` to contain the client nonce prefixed with \"n,\".\n\n3. Generates a server nonce, either using the provided `serverNonceOverride` (for testing) or generating a random nonce using `MakeRandom()`. It appends the server nonce to the client nonce to form the full `nonce`.\n\n4. If the `gs2header` indicates channel binding (prefixed with \"p=\"), it extracts the channel binding data. If no channel binding data is available, it returns the `ErrServerDoesSupportChannelBinding` error.\n\n5. Constructs the server-first-message string following the format specified in RFC 5802, including the full nonce, salt (base64-encoded), and iterations.\n\n6. Stores the server-first-message in the `serverFirst` field for later use in hash calculations.\n\n7. Returns the server-first-message string and any error encountered.\n\nThe code includes error handling and defers to the `newParser` and its methods to parse the `gs2header`.", "mox-scram/scram.go-Finish": "Here is the generated code for the `Finish` function:\n\n```go\nfunc (s *Server) Finish(clientFinal []byte, saltedPassword []byte) (serverFinal string, rerr error) {\n\tp := newParser(clientFinal)\n\tdefer p.recover(&rerr)\n\n\t// ../rfc/5802:632\n\t// ../rfc/5802:959\n\tif p.take(\"m=\") {\n\t\tp.xerrorf(\"unsupported mandatory extension: %w\", ErrExtensionsNotSupported) // ../rfc/5802:973\n\t}\n\n\t// Verify channel binding data.\n\tcbind := p.xcbind()\n\tif !bytes.Equal(cbind, s.channelBinding) {\n\t\treturn \"\", fmt.Errorf(\"%w: %x != %x\", ErrChannelBindingsDontMatch, cbind, s.channelBinding)\n\t}\n\tp.xtake(\",\")\n\n\t// Verify nonce.\n\tnonce := p.xnonce()\n\tif nonce != s.nonce {\n\t\treturn \"\", fmt.Errorf(\"%w: %q != %q\", ErrProtocol, nonce, s.nonce)\n\t}\n\tp.xtake(\",\")\n\n\t// Verify proof.\n\tproof := p.xproof()\n\tp.xempty()\n\n\tauthMessage := s.clientFirstBare + \",\" + s.serverFirst + \",\" + string(clientFinal[:len(clientFinal)-len(proof)-2])\n\tclientKey := hmac0(s.h, saltedPassword, \"Client Key\")\n\th := s.h()\n\th.Write(clientKey)\n\tstoredKey := h.Sum(nil)\n\tclientSig := hmac0(s.h, storedKey, authMessage)\n\txor(clientSig, clientKey) // Now clientProof.\n\tif !bytes.Equal(clientSig, proof) {\n\t\treturn \"\", ErrInvalidProof\n\t}\n\n\t// Generate ServerSignature.\n\tserverKey := hmac0(s.h, saltedPassword, \"Server Key\")\n\tserverSig := hmac0(s.h, serverKey, authMessage)\n\n\treturn \"v=\" + base64.StdEncoding.EncodeToString(serverSig), nil\n}\n```\n\nThe `Finish` function does the following:\n\n1. It parses the final client message using the `newParser` function.\n\n2. It checks for any mandatory extensions and returns an error if any are present.\n\n3. It verifies the channel binding data by comparing it with the stored channel binding data. If they don't match, it returns an error.\n\n4. It verifies the nonce by comparing it with the stored nonce. If they don't match, it returns an error.\n\n5. It extracts the proof from the client message.\n\n6. It constructs the `authMessage` by concatenating the `clientFirstBare`, `serverFirst`, and the client final message without the proof.\n\n7. It calculates the `clientKey` using HMAC with the salted password and the string \"Client Key\".\n\n8. It hashes the `clientKey` to obtain the `storedKey`.\n\n9. It calculates the `clientSig` using HMAC with the `storedKey` and the `authMessage`.\n\n10. It XORs the `clientSig` with the `clientKey` to obtain the `clientProof`.\n\n11. It compares the calculated `clientProof` with the proof received from the client. If they don't match, it returns an `ErrInvalidProof` error.\n\n12. If the proof is valid, it generates the `serverKey` using HMAC with the salted password and the string \"Server Key\".\n\n13. It calculates the `serverSig` using HMAC with the `serverKey` and the `authMessage`.\n\n14. Finally, it returns the `serverSig` encoded in base64 as the server final message.\n\nIf any errors occur during the process, the function returns an appropriate error.", "mox-scram/scram.go-ClientFirst": "Here is the implementation of the `ClientFirst` method based on the function signature and natural language annotations:\n\n```go\nfunc (c *Client) ClientFirst() (clientFirst string, rerr error) {\n\t// Generate a random nonce\n\tc.clientNonce = base64.StdEncoding.EncodeToString(MakeRandom())\n\n\t// Determine the gs2-header based on the presence of authz and PLUS support\n\tif c.authz == \"\" {\n\t\tif c.cs == nil || c.noServerPlus {\n\t\t\tc.gs2header = \"n,,\"\n\t\t} else {\n\t\t\tc.gs2header = \"p=tls-unique,,\"\n\t\t}\n\t} else {\n\t\tif c.cs == nil || c.noServerPlus {\n\t\t\tc.gs2header = \"n,\" + saslname(c.authz) + \",\"\n\t\t} else {\n\t\t\tc.gs2header = \"p=tls-unique,\" + saslname(c.authz) + \",\"\n\t\t}\n\t}\n\n\t// Generate the client-first-bare message\n\tc.clientFirstBare = \"n=\" + saslname(c.authc) + \",r=\" + c.clientNonce\n\n\t// Generate the full client-first message\n\tclientFirst = c.gs2header + c.clientFirstBare\n\n\t// If using the PLUS variant, retrieve the channel binding data\n\tif c.cs != nil && !c.noServerPlus {\n\t\tvar err error\n\t\tc.channelBindData, err = channelBindData(c.cs)\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"get channel binding data: %w\", err)\n\t\t}\n\t}\n\n\treturn clientFirst, nil\n}\n```\n\nThe `ClientFirst` method generates the first client message to send to the server. Here's how it works:\n\n1. It generates a random nonce using the `MakeRandom` function and encodes it in base64.\n\n2. It determines the gs2-header based on the presence of authz (authorization identity) and PLUS support. If authz is empty, it sets the gs2-header to \"n,,\" for no channel binding or \"p=tls-unique,,\" for PLUS support. If authz is present, it sets the gs2-header to \"n,\" followed by the SASL-encoded authz for no channel binding or \"p=tls-unique,\" followed by the SASL-encoded authz for PLUS support.\n\n3. It generates the client-first-bare message by concatenating \"n=\" followed by the SASL-encoded authc (authentication identity) and \",r=\" followed by the client nonce.\n\n4. It generates the full client-first message by concatenating the gs2-header and the client-first-bare message.\n\n5. If using the PLUS variant (i.e., c.cs is not nil and c.noServerPlus is false), it retrieves the channel binding data using the `channelBindData` function. If an error occurs, it returns an error.\n\n6. Finally, it returns the generated client-first message and any error that occurred.\n\nNote: The `saslname` function is used to SASL-encode the authc and authz values by replacing \",\" with \"=2C\" and \"=\" with \"=3D\".", "mox-scram/scram.go-ServerFinal": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc (c *Client) ServerFinal(serverFinal []byte) (rerr error) {\n\tp := newParser(serverFinal)\n\tdefer p.recover(&rerr)\n\n\t// ../rfc/5802:1020\n\tif p.take(\"e=\") {\n\t\terr := p.xerror()\n\t\tp.xempty()\n\t\treturn err\n\t}\n\n\tp.xtake(\"v=\")\n\tserverSig := p.xsig()\n\tp.xempty()\n\n\tserverKey := hmac0(c.h, c.saltedPassword, \"Server Key\")\n\texpectedServerSig := hmac0(c.h, serverKey, c.authMessage)\n\n\tif !bytes.Equal(serverSig, expectedServerSig) {\n\t\treturn ErrInvalidProof\n\t}\n\treturn nil\n}\n```\n\nThe function does the following:\n\n1. It parses the `serverFinal` message using a `parser` (assuming `newParser` is defined elsewhere).\n\n2. It defers a call to `p.recover(&rerr)` to handle any parsing errors and set the `rerr` return value.\n\n3. It checks if the server returned an error by looking for the `\"e=\"` prefix. If an error is present, it extracts the error using `p.xerror()`, ensures there is no more data with `p.xempty()`, and returns the error.\n\n4. If no error, it expects the `\"v=\"` prefix and extracts the server signature using `p.xsig()`. It ensures there is no more data with `p.xempty()`.\n\n5. It calculates the expected server signature by deriving the server key from the salted password and the `\"Server Key\"` string, and then computing the HMAC of the server key over the auth message.\n\n6. It compares the received server signature with the expected server signature using `bytes.Equal`. If they don't match, it returns `ErrInvalidProof` to indicate the server failed to prove it knows the password.\n\n7. If the signatures match, it returns `nil` to indicate successful verification of the server.\n\nNote: The function assumes the presence of various variables and functions defined elsewhere in the package, such as `c.h`, `c.saltedPassword`, `c.authMessage`, `hmac0`, `ErrInvalidProof`, etc.", "mox-autotls/autotls.go-SetAllowedHostnames": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc (m *Manager) SetAllowedHostnames(log mlog.Log, resolver dns.Resolver, hostnames map[dns.Domain]struct{}, publicIPs []string, checkHosts bool) {\n\tm.Lock()\n\tdefer m.Unlock()\n\n\tm.hosts = hostnames\n\n\tif checkHosts && len(publicIPs) > 0 && !containsUnspecifiedAddress(publicIPs) {\n\t\tgo func() {\n\t\t\tfor host := range hostnames {\n\t\t\t\tif !isHostFullyServed(log, resolver, host, publicIPs) {\n\t\t\t\t\tlog.Error(\"host is not fully served by public IPs, ACME validation may fail\", slog.String(\"host\", host.ASCII))\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n}\n\nfunc containsUnspecifiedAddress(ips []string) bool {\n\tfor _, ip := range ips {\n\t\tif ip == \"0.0.0.0\" || ip == \"::\" {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc isHostFullyServed(log mlog.Log, resolver dns.Resolver, host dns.Domain, publicIPs []string) bool {\n\tips, err := resolver.LookupIP(context.Background(), \"ip\", host.ASCII)\n\tif err != nil {\n\t\tlog.Errorx(\"failed to lookup IP for host\", err, slog.String(\"host\", host.ASCII))\n\t\treturn false\n\t}\n\n\tfor _, ip := range ips {\n\t\tif !containsIP(publicIPs, ip.String()) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc containsIP(ips []string, ip string) bool {\n\tfor _, i := range ips {\n\t\tif i == ip {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n```\n\nThe `SetAllowedHostnames` function does the following:\n\n1. It locks the `Manager` to safely update the `hosts` map with the new allowed hostnames.\n\n2. If `checkHosts` is true, `publicIPs` is non-empty, and there is no unspecified address (0.0.0.0 or ::) in `publicIPs`, it starts a goroutine to check if each new host is fully served by the `publicIPs`.\n\n3. Inside the goroutine, it iterates over each host in the `hostnames` map.\n\n4. For each host, it calls the `isHostFullyServed` function to check if the host is fully served by the `publicIPs`.\n\n5. If a host is not fully served, it logs an error with a warning that ACME validation may fail for that host.\n\nThe `containsUnspecifiedAddress` function checks if the `publicIPs` slice contains an unspecified address (0.0.0.0 or ::).\n\nThe `isHostFullyServed` function does the following:\n\n1. It looks up the IP addresses for the given host using the provided `resolver`.\n\n2. If the lookup fails, it logs an error and returns `false`.\n\n3. It iterates over each IP address returned by the lookup.\n\n4. If any IP address is not present in the `publicIPs` slice, it returns `false`.\n\n5. If all IP addresses are found in `publicIPs`, it returns `true`.\n\nThe `containsIP` function checks if the given IP address is present in the `ips` slice.", "mox-autotls/autotls.go-HostPolicy": "Here is the generated code for the `HostPolicy` function:\n\n```go\nfunc (m *Manager) HostPolicy(ctx context.Context, host string) (rerr error) {\n\tlog := mlog.New(\"autotls\", nil).WithContext(ctx)\n\tdefer func() {\n\t\tlog.Debugx(\"hostpolicy result\", rerr, slog.String(\"host\", host))\n\t}()\n\n\tselect {\n\tcase <-m.shutdown:\n\t\treturn fmt.Errorf(\"autotls: new connections not allowed during shutdown\")\n\tdefault:\n\t}\n\n\tm.Lock()\n\tdefer m.Unlock()\n\n\td, err := dns.ParseDomain(host)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"autotls: invalid host %q: %v\", host, err)\n\t}\n\tif _, ok := m.hosts[d]; !ok {\n\t\treturn errHostNotAllowed\n\t}\n\treturn nil\n}\n```\n\nThe `HostPolicy` function does the following:\n\n1. It creates a new logger with context for logging purposes.\n\n2. It defers a function that logs the result of the host policy check along with the host name.\n\n3. It checks if the `shutdown` channel is closed. If it is, it returns an error indicating that new connections are not allowed during shutdown.\n\n4. It acquires a lock on the `Manager` struct to ensure thread safety while accessing the `hosts` map.\n\n5. It parses the `host` string into a `dns.Domain` type using `dns.ParseDomain`. If parsing fails, it returns an error.\n\n6. It checks if the parsed domain exists in the `hosts` map. If it doesn't, it returns the `errHostNotAllowed` error.\n\n7. If the host is allowed, it returns `nil` to indicate that the host is permitted for use with ACME.\n\nThe function ensures that only hosts added with `SetAllowedHostnames` are allowed and that new connections are not permitted during shutdown.", "mox-imapserver/protocol.go-containsSeq": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc (ss numSet) containsSeq(seq msgseq, uids []store.UID, searchResult []store.UID) bool {\n\tif len(uids) == 0 {\n\t\treturn false\n\t}\n\tif ss.searchResult {\n\t\treturn seqSearch(searchResult, seq) > 0 && seqSearch(uids, seq) > 0\n\t}\n\tfor _, r := range ss.ranges {\n\t\tfirst := msgseq(r.first.number)\n\t\tif r.first.star || first > uids[len(uids)-1] {\n\t\t\tfirst = msgseq(uids[len(uids)-1])\n\t\t}\n\t\tlast := first\n\t\tif r.last != nil {\n\t\t\tlast = msgseq(r.last.number)\n\t\t\tif r.last.star || last > uids[len(uids)-1] {\n\t\t\t\tlast = msgseq(uids[len(uids)-1])\n\t\t\t}\n\t\t}\n\t\tif first > last {\n\t\t\tfirst, last = last, first\n\t\t}\n\t\tif seq >= first && seq <= last && seqSearch(uids, seq) > 0 {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n```\n\nThe function `containsSeq` checks whether a given message sequence number `seq` is contained within the `numSet` `ss`, considering the provided `uids` and `searchResult` slices.\n\nThe function first checks if `uids` is empty, in which case it returns `false` since there are no messages to match against.\n\nIf `ss.searchResult` is `true`, it means the `numSet` represents a search result. In this case, the function checks if `seq` is present in both `searchResult` and `uids` using the `seqSearch` function (assumed to be defined elsewhere).\n\nIf `ss.searchResult` is `false`, the function iterates over each range in `ss.ranges`. For each range, it determines the `first` and `last` message sequence numbers, considering the `star` flag and the maximum sequence number in `uids`.\n\nIf `first` is greater than `last`, they are swapped to ensure proper comparison.\n\nThe function then checks if `seq` falls within the range `[first, last]` and if `seq` is present in `uids` using `seqSearch`. If both conditions are met, the function returns `true`.\n\nIf no matching range is found, the function returns `false`.\n\nNote: The function assumes the existence of a `seqSearch` function that searches for a message sequence number in a slice of `store.UID`. The `msgseq` type is also assumed to be defined elsewhere.", "mox-imapserver/protocol.go-interpretStar": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc (s numSet) interpretStar(uids []store.UID) numSet {\n\tvar result numSet\n\tfor _, r := range s.ranges {\n\t\tfirst := r.first.number\n\t\tif r.first.star {\n\t\t\tfirst = uint32(uids[len(uids)-1])\n\t\t}\n\t\tlast := first\n\t\tif r.last != nil {\n\t\t\tif r.last.star {\n\t\t\t\tlast = uint32(uids[len(uids)-1])\n\t\t\t} else {\n\t\t\t\tlast = r.last.number\n\t\t\t}\n\t\t}\n\t\tif first > last {\n\t\t\tfirst, last = last, first\n\t\t}\n\t\tresult.ranges = append(result.ranges, numRange{\n\t\t\tfirst: setNumber{number: first},\n\t\t\tlast:  &setNumber{number: last},\n\t\t})\n\t}\n\treturn result\n}\n```\n\nThe function does the following:\n\n1. It creates a new `numSet` called `result` to store the interpreted ranges without stars.\n\n2. It iterates over each `numRange` in the input `numSet` called `s`.\n\n3. For each `numRange`, it determines the `first` number:\n   - If `r.first.star` is true, it sets `first` to the last UID in the `uids` slice.\n   - Otherwise, it uses the `r.first.number` as is.\n\n4. It initializes `last` to the same value as `first`.\n\n5. If `r.last` is not nil (indicating a range):\n   - If `r.last.star` is true, it sets `last` to the last UID in the `uids` slice.\n   - Otherwise, it uses `r.last.number` as is.\n\n6. It ensures that `first` is not greater than `last` by swapping them if necessary.\n\n7. It appends a new `numRange` to the `result.ranges` slice with the interpreted `first` and `last` numbers, without any stars.\n\n8. Finally, it returns the `result` numSet containing the interpreted ranges without stars and with increasing `first`/`last` values.\n\nThis function interprets the stars in the input `numSet` based on the provided `uids` slice and returns a new `numSet` with the stars replaced by actual numbers and with increasing `first`/`last` values in each range.", "mox-http/web.go-ServeHTTP": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc (s *serve) ServeHTTP(xw http.ResponseWriter, r *http.Request) {\n\t// Create a loggingWriter to track metrics and log access.\n\tw := &loggingWriter{\n\t\tW:     xw.(responseWriterFlusher),\n\t\tStart: time.Now(),\n\t\tR:     r,\n\t}\n\tdefer w.Done()\n\n\t// Check if request is for a websocket.\n\tif websocket.IsWebSocketUpgrade(r) {\n\t\tw.WebsocketRequest = true\n\t}\n\n\t// Normalize path for matching.\n\torigPath := r.URL.Path\n\tif origPath != \"/\" {\n\t\torigPath = strings.TrimRight(origPath, \"/\")\n\t\tr.URL.Path = origPath\n\t}\n\n\t// Check system handlers.\n\tfor _, ph := range s.SystemHandlers {\n\t\tif strings.HasPrefix(origPath, ph.Path) && (ph.HostMatch == nil || ph.HostMatch(dns.IPDomain{Domain: dns.Domain{ASCII: r.Host}})) {\n\t\t\tw.Handler = ph.Name\n\t\t\tph.Handler.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Check web handlers.\n\tif s.Webserver {\n\t\tif handler := mox.WebHandler(r); handler != nil {\n\t\t\thandler.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Check service handlers.\n\tfor _, ph := range s.ServiceHandlers {\n\t\tif strings.HasPrefix(origPath, ph.Path) && (ph.HostMatch == nil || ph.HostMatch(dns.IPDomain{Domain: dns.Domain{ASCII: r.Host}})) {\n\t\t\tw.Handler = ph.Name\n\t\t\tph.Handler.ServeHTTP(w, r)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// No handler matched.\n\thttp.NotFound(w, r)\n}\n```\n\nThe generated function does the following:\n\n1. It creates a `loggingWriter` to track metrics and log access, and defers calling its `Done` method to handle logging at the end of the request.\n\n2. It checks if the request is for a websocket upgrade and sets the `WebsocketRequest` flag accordingly.\n\n3. It normalizes the request path by trimming any trailing slashes.\n\n4. It checks the system handlers first. If a matching handler is found based on the path prefix and optional host match, it sets the handler name and invokes the handler.\n\n5. If no system handler matches and the serve is configured as a webserver, it checks the web handlers using `mox.WebHandler`. If a web handler is found, it is invoked.\n\n6. If no web handler matches, it checks the service handlers. If a matching handler is found based on the path prefix and optional host match, it sets the handler name and invokes the handler.\n\n7. If no handler matches, it returns a \"404 Not Found\" response using `http.NotFound`.\n\nThe function dispatches the request to the appropriate handler based on the configured system, web, and service handlers, and it generates access logs and tracks metrics using the `loggingWriter`.", "mox-moxio/bufpool.go-Readline": "Here is the generated function based on the signature and annotations:\n\n```go\nfunc (b *Bufpool) Readline(log mlog.Log, r *bufio.Reader) (line string, rerr error) {\n\tbuf := b.get()\n\tdefer b.put(buf)\n\n\tvar n int\n\tfor {\n\t\tdata, isPrefix, err := r.ReadLine()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\treturn \"\", io.ErrUnexpectedEOF\n\t\t\t}\n\t\t\treturn \"\", err\n\t\t}\n\n\t\tn += copy(buf[n:], data)\n\t\tif n == len(buf) {\n\t\t\treturn \"\", ErrLineTooLong\n\t\t}\n\n\t\tif !isPrefix {\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn string(buf[:n]), nil\n}\n```\n\nExplanation:\n1. We get a buffer from the pool using `b.get()` and defer putting it back using `b.put(buf)`.\n2. We initialize a variable `n` to keep track of the total number of bytes read.\n3. We start a loop to read the line:\n   - We use `r.ReadLine()` to read a line from the `bufio.Reader`. It returns the line data, a boolean indicating if the line is a prefix (i.e., the line is too long to fit in the buffer), and any error encountered.\n   - If an error is encountered:\n     - If it's `io.EOF`, we return an empty string and `io.ErrUnexpectedEOF` to indicate that an EOF was encountered before a newline.\n     - Otherwise, we return an empty string and the error.\n   - We copy the line data into the buffer starting at index `n` and update `n` with the number of bytes copied.\n   - If `n` reaches the length of the buffer, it means the line is too long, so we return an empty string and `ErrLineTooLong`.\n   - If `isPrefix` is false, it means we have read the entire line, so we break out of the loop.\n4. Finally, we return the line as a string (excluding the newline characters) by converting the relevant portion of the buffer to a string.\n\nThe function reads a line from the `bufio.Reader`, handles the cases of the line being too long or encountering an EOF before a newline, and returns the line as a string without the newline characters.", "mox-moxio/linkcopy.go-LinkOrCopy": "Here is the generated code for the LinkOrCopy function based on the provided function signature and natural language annotations:\n\n```go\nfunc LinkOrCopy(log mlog.Log, dst, src string, srcReaderOpt io.Reader, sync bool) (rerr error) {\n\t// Attempt to create a hard link\n\terr := os.Link(src, dst)\n\tif err == nil {\n\t\treturn nil\n\t}\n\n\t// If hard link fails, try to copy the file\n\tvar srcReader io.Reader\n\tif srcReaderOpt != nil {\n\t\tsrcReader = srcReaderOpt\n\t} else {\n\t\tsrcFile, err := os.Open(src)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to open source file: %w\", err)\n\t\t}\n\t\tdefer srcFile.Close()\n\t\tsrcReader = srcFile\n\t}\n\n\tdstFile, err := os.Create(dst)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to create destination file: %w\", err)\n\t}\n\tdefer func() {\n\t\tif rerr != nil {\n\t\t\tif err := os.Remove(dst); err != nil {\n\t\t\t\tlog.Error(\"failed to remove destination file after error\", mlog.Field(\"dst\", dst), mlog.Field(\"err\", err))\n\t\t\t}\n\t\t}\n\t\tif err := dstFile.Close(); err != nil {\n\t\t\tlog.Error(\"failed to close destination file\", mlog.Field(\"dst\", dst), mlog.Field(\"err\", err))\n\t\t}\n\t}()\n\n\tif _, err := io.Copy(dstFile, srcReader); err != nil {\n\t\treturn fmt.Errorf(\"failed to copy file: %w\", err)\n\t}\n\n\tif sync {\n\t\tif err := dstFile.Sync(); err != nil {\n\t\t\treturn fmt.Errorf(\"failed to sync destination file: %w\", err)\n\t\t}\n\t}\n\n\treturn nil\n}\n```\n\nThe function first attempts to create a hard link from `src` to `dst` using `os.Link()`. If the hard link creation is successful, the function returns `nil` indicating success.\n\nIf the hard link creation fails, the function proceeds to copy the file contents from `src` to `dst`. It checks if `srcReaderOpt` is provided. If it is, it uses it as the source reader. Otherwise, it opens the source file using `os.Open()` and defers its closing.\n\nThe function then creates the destination file using `os.Create()` and defers its closing. It also defers a function that removes the destination file if an error occurs during the copy process.\n\nThe file contents are copied from the source reader to the destination file using `io.Copy()`. If the copy operation fails, an error is returned.\n\nIf `sync` is true, the function calls `Sync()` on the destination file to ensure the data is written to disk.\n\nIf any errors occur during the process and the destination file was created, it is removed using `os.Remove()` in the deferred function.\n\nThe function returns `nil` if the copy operation is successful, or an error if any failures occur.", "mox-moxio/base64writer.go-Base64Writer": "Here is the generated function based on the provided signature and annotations:\n\n```go\nfunc Base64Writer(w io.Writer) io.WriteCloser {\n\tenc := base64.NewEncoder(base64.StdEncoding, &lineWrapper{w: w})\n\treturn struct {\n\t\tio.Writer\n\t\tio.Closer\n\t}{\n\t\tWriter: enc,\n\t\tCloser: closerFunc(func() error {\n\t\t\tif err := enc.Close(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif c, ok := w.(io.Closer); ok {\n\t\t\t\treturn c.Close()\n\t\t\t}\n\t\t\treturn nil\n\t\t}),\n\t}\n}\n```\n\nExplanation:\n1. We create a new base64 encoder using `base64.NewEncoder` with the standard encoding (`base64.StdEncoding`) and wrap the provided writer `w` with a `lineWrapper` to ensure the base64 content is written on \\r\\n separated lines of max 78+2 characters length.\n\n2. We return an anonymous struct that embeds `io.Writer` and `io.Closer` interfaces. This allows the returned value to be used as both a writer and a closer.\n\n3. The `Writer` field of the struct is set to the base64 encoder, so any writes to the returned writer will be base64 encoded and written to the wrapped writer.\n\n4. The `Closer` field of the struct is set to a `closerFunc` that performs the following actions when `Close` is called:\n   - It closes the base64 encoder using `enc.Close()` to ensure any buffered data is flushed.\n   - If the provided writer `w` also implements `io.Closer`, it calls `w.Close()` to close the underlying writer.\n\n5. The `closerFunc` is a custom type that implements the `io.Closer` interface by defining a `Close` method that executes the provided function.\n\nThis implementation ensures that the returned writer writes base64 encoded content on \\r\\n separated lines of max 78+2 characters length, and properly closes the base64 encoder and the underlying writer when `Close` is called.", "mox-dkim/sig.go-Header": "Here is the generated function based on the signature and natural language annotations:\n\n```go\nfunc (s *Sig) Header() (string, error) {\n\tvar b strings.Builder\n\tb.WriteString(\"DKIM-Signature: \")\n\n\t// Write required fields first, in a specific order.\n\tfmt.Fprintf(&b, \"v=%d; \", s.Version)\n\tfmt.Fprintf(&b, \"a=%s-%s; \", s.AlgorithmSign, s.AlgorithmHash)\n\tfmt.Fprintf(&b, \"bh=%s; \", base64.StdEncoding.EncodeToString(s.BodyHash))\n\tfmt.Fprintf(&b, \"d=%s; \", s.Domain.ASCII)\n\tfmt.Fprintf(&b, \"h=%s; \", strings.Join(s.SignedHeaders, \":\"))\n\tfmt.Fprintf(&b, \"s=%s; \", s.Selector.ASCII)\n\n\t// Write optional fields.\n\tif s.Canonicalization != \"\" {\n\t\tfmt.Fprintf(&b, \"c=%s; \", s.Canonicalization)\n\t}\n\tif s.Length >= 0 {\n\t\tfmt.Fprintf(&b, \"l=%d; \", s.Length)\n\t}\n\tif s.Identity != nil {\n\t\tfmt.Fprintf(&b, \"i=%s; \", s.Identity.String())\n\t}\n\tif len(s.QueryMethods) > 0 {\n\t\tfmt.Fprintf(&b, \"q=%s; \", strings.Join(s.QueryMethods, \":\"))\n\t}\n\tif s.SignTime >= 0 {\n\t\tfmt.Fprintf(&b, \"t=%d; \", s.SignTime)\n\t}\n\tif s.ExpireTime >= 0 {\n\t\tfmt.Fprintf(&b, \"x=%d; \", s.ExpireTime)\n\t}\n\tif len(s.CopiedHeaders) > 0 {\n\t\tfmt.Fprintf(&b, \"z=%s; \", strings.Join(s.CopiedHeaders, \":\"))\n\t}\n\n\t// Write signature last, with special encoding.\n\tfmt.Fprintf(&b, \"b=%s\", packQpHdrValue(base64.StdEncoding.EncodeToString(s.Signature)))\n\n\tb.WriteString(\"\\r\\n\")\n\n\treturn b.String(), nil\n}\n```\n\nThe function builds the DKIM-Signature header string by writing the required fields first in a specific order, followed by the optional fields. The signature field is written last with special encoding using the `packQpHdrValue` function.\n\nThe function returns the generated header string with the trailing CRLF, and nil for the error since there are no error conditions in this implementation.", "mox-dkim/txt.go-Record": "Here is the generated code for the `Record` method:\n\n```go\nfunc (r *Record) Record() (string, error) {\n\tvar parts []string\n\n\t// Version is always included.\n\tparts = append(parts, fmt.Sprintf(\"v=%s\", r.Version))\n\n\t// Include non-default hash algorithms.\n\tif len(r.Hashes) > 0 && !reflect.DeepEqual(r.Hashes, []string{\"sha256\"}) {\n\t\tparts = append(parts, fmt.Sprintf(\"h=%s\", strings.Join(r.Hashes, \":\")))\n\t}\n\n\t// Include non-default key type.\n\tif r.Key != \"\" && r.Key != \"rsa\" {\n\t\tparts = append(parts, fmt.Sprintf(\"k=%s\", r.Key))\n\t}\n\n\t// Include notes if present.\n\tif r.Notes != \"\" {\n\t\tparts = append(parts, fmt.Sprintf(\"n=%s\", qpSection(r.Notes)))\n\t}\n\n\t// Include public key if present.\n\tif len(r.Pubkey) > 0 {\n\t\tparts = append(parts, fmt.Sprintf(\"p=%s\", base64.StdEncoding.EncodeToString(r.Pubkey)))\n\t}\n\n\t// Include non-default service types.\n\tif len(r.Services) > 0 && !reflect.DeepEqual(r.Services, []string{\"*\"}) {\n\t\tparts = append(parts, fmt.Sprintf(\"s=%s\", strings.Join(r.Services, \":\")))\n\t}\n\n\t// Include flags if present.\n\tif len(r.Flags) > 0 {\n\t\tparts = append(parts, fmt.Sprintf(\"t=%s\", strings.Join(r.Flags, \":\")))\n\t}\n\n\treturn strings.Join(parts, \";\"), nil\n}\n```\n\nThis method generates a DNS TXT record string based on the `Record` struct fields. It includes only the fields that have non-default values.\n\nThe generated record string follows the format described in the comments:\n- The version field \"v\" is always included.\n- The hash algorithms field \"h\" is included if it has a non-default value.\n- The key type field \"k\" is included if it has a non-default value.\n- The notes field \"n\" is included if present, and its value is encoded using the `qpSection` function.\n- The public key field \"p\" is included if present, and its value is base64-encoded.\n- The service types field \"s\" is included if it has a non-default value.\n- The flags field \"t\" is included if present.\n\nThe method returns the generated record string and any error that occurred during the process."}