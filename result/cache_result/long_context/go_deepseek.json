{"dtm-dtmsvr/storage/boltdb/boltdb.go-cleanupExpiredData": {"response": ["```go\nfunc cleanupExpiredData(expire time.Duration, db *bolt.DB) error {\n\t// Calculate the expiration time based on the current time minus the expire duration\n\texpirationTime := time.Now().Add(-expire).Unix()\n\n\t// Start a transaction to perform the cleanup\n\treturn db.Update(func(t *bolt.Tx) error {\n\t\t// Iterate over all buckets that contain data that might need to be cleaned up\n\t\tfor _, bucket := range allBuckets {\n\t\t\tb := t.Bucket(bucket)\n\t\t\tif b == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// Use a cursor to iterate over the bucket's data\n\t\t\tcursor := b.Cursor()\n\t\t\tfor k, v := cursor.First(); k != nil; k, v = cursor.Next() {\n\t\t\t\t// Unmarshal the data to check its timestamp\n\t\t\t\tvar data struct {\n\t\t\t\t\tCreateTime int64 `json:\"create_time\"`\n\t\t\t\t}\n\t\t\t\terr := json.Unmarshal(v, &data)\n\t\t\t\tif err != nil {\n\t\t\t\t\t// If unmarshalling fails, log the error and continue\n\t\t\t\t\tlogger.Errorf(\"Failed to unmarshal data for key %s: %v\", k, err)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// Check if the data's create time is older than the expiration time\n\t\t\t\tif data.CreateTime < expirationTime {\n\t\t\t\t\t// If the data is expired, delete it\n\t\t\t\t\terr := cursor.Delete()\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t// If deletion fails, log the error and continue\n\t\t\t\t\t\tlogger.Errorf(\"Failed to delete expired data for key %s: %v\", k, err)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlogger.Debugf(\"Deleted expired data for key %s\", k)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t})\n}\n```"]}, "dtm-dtmsvr/config/config.go-MustLoadConfig": {"response": ["```go\nfunc MustLoadConfig(confFile string) {\n\t// Load config from environment variables\n\tloadFromEnv(\"\", &Config)\n\n\t// Load config from file if provided\n\tif confFile != \"\" {\n\t\tdata, err := ioutil.ReadFile(confFile)\n\t\tdtmimp.PanicIf(err, fmt.Errorf(\"failed to read config file: %s\", confFile))\n\n\t\tswitch {\n\t\tcase strings.HasSuffix(confFile, \".yaml\") || strings.HasSuffix(confFile, \".yml\"):\n\t\t\terr = yaml.Unmarshal(data, &Config)\n\t\tcase strings.HasSuffix(confFile, \".json\"):\n\t\t\terr = json.Unmarshal(data, &Config)\n\t\tdefault:\n\t\t\tdtmimp.PanicIf(true, fmt.Errorf(\"unsupported config file format: %s\", confFile))\n\t\t}\n\t\tdtmimp.PanicIf(err, fmt.Errorf(\"failed to unmarshal config file: %s\", confFile))\n\t}\n\n\t// Check the loaded config for validity\n\terr := checkConfig(&Config)\n\tdtmimp.PanicIf(err, fmt.Errorf(\"invalid config: %v\", err))\n}\n```"]}, "dtm-client/dtmcli/dtmimp/utils.go-MustRemarshal": {"response": ["```go\n// MustRemarshal marshal and unmarshal, and check error\nfunc MustRemarshal(from interface{}, to interface{}) {\n\tbytes := MustMarshal(from)\n\tMustUnmarshal(bytes, to)\n}\n```"]}, "kitex-tool/internal_pkg/generator/type.go-FixHasStreamingForExtendedService": {"response": ["```go\nfunc (s *ServiceInfo) FixHasStreamingForExtendedService() {\n\t// FixHasStreamingForExtendedService updates the HasStreaming field for extended services.\n\ts.HasStreaming = s.HasStreamingRecursive()\n}\n\nfunc (s *ServiceInfo) HasStreamingRecursive() bool {\n\t// HasStreamingRecursive recursively check if the service has streaming method\n\tif s.HasStreaming {\n\t\treturn true\n\t}\n\tfor base := s.Base; base != nil; base = base.Base {\n\t\tif base.HasStreamingRecursive() {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n```"]}, "kitex-tool/internal_pkg/generator/type.go-HasStreamingRecursive": {"response": ["```go\nfunc (s *ServiceInfo) HasStreamingRecursive() bool {\n\t// Check if the current service has streaming methods\n\tif s.HasStreaming {\n\t\treturn true\n\t}\n\n\t// Recursively check the base service if it exists\n\tfor base := s.Base; base != nil; base = base.Base {\n\t\tif base.HasStreamingRecursive() {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// Check if any combined services have streaming methods\n\tfor _, cs := range s.CombineServices {\n\t\tif cs.HasStreamingRecursive() {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n```"]}, "kitex-tool/internal_pkg/generator/generator.go-Unpack": {"response": ["```go\nfunc (c *Config) Unpack(args []string) error {\n\tfor _, arg := range args {\n\t\tparts := strings.SplitN(arg, \"=\", 2)\n\t\tif len(parts) != 2 {\n\t\t\treturn fmt.Errorf(\"invalid argument format: %s\", arg)\n\t\t}\n\t\tkey, val := parts[0], parts[1]\n\n\t\tswitch key {\n\t\tcase \"Verbose\":\n\t\t\tc.Verbose, _ = strconv.ParseBool(val)\n\t\tcase \"GenerateMain\":\n\t\t\tc.GenerateMain, _ = strconv.ParseBool(val)\n\t\tcase \"GenerateInvoker\":\n\t\t\tc.GenerateInvoker, _ = strconv.ParseBool(val)\n\t\tcase \"Version\":\n\t\t\tc.Version = val\n\t\tcase \"NoFastAPI\":\n\t\t\tc.NoFastAPI, _ = strconv.ParseBool(val)\n\t\tcase \"ModuleName\":\n\t\t\tc.ModuleName = val\n\t\tcase \"ServiceName\":\n\t\t\tc.ServiceName = val\n\t\tcase \"Use\":\n\t\t\tc.Use = val\n\t\tcase \"IDLType\":\n\t\t\tc.IDLType = val\n\t\tcase \"Includes\":\n\t\t\tc.Includes = util.StringSlice(strings.Split(val, \";\"))\n\t\tcase \"ThriftOptions\":\n\t\t\tc.ThriftOptions = util.StringSlice(strings.Split(val, \";\"))\n\t\tcase \"ProtobufOptions\":\n\t\t\tc.ProtobufOptions = util.StringSlice(strings.Split(val, \";\"))\n\t\tcase \"Hessian2Options\":\n\t\t\tc.Hessian2Options = util.StringSlice(strings.Split(val, \";\"))\n\t\tcase \"IDL\":\n\t\t\tc.IDL = val\n\t\tcase \"OutputPath\":\n\t\t\tc.OutputPath = val\n\t\tcase \"PackagePrefix\":\n\t\t\tc.PackagePrefix = val\n\t\tcase \"CombineService\":\n\t\t\tc.CombineService, _ = strconv.ParseBool(val)\n\t\tcase \"CopyIDL\":\n\t\t\tc.CopyIDL, _ = strconv.ParseBool(val)\n\t\tcase \"ThriftPlugins\":\n\t\t\tc.ThriftPlugins = util.StringSlice(strings.Split(val, \";\"))\n\t\tcase \"ProtobufPlugins\":\n\t\t\tc.ProtobufPlugins = util.StringSlice(strings.Split(val, \";\"))\n\t\tcase \"Features\":\n\t\t\tfor _, f := range strings.Split(val, \";\") {\n\t\t\t\tc.AddFeature(f)\n\t\t\t}\n\t\tcase \"FrugalPretouch\":\n\t\t\tc.FrugalPretouch, _ = strconv.ParseBool(val)\n\t\tcase \"ThriftPluginTimeLimit\":\n\t\t\tlimit, _ := time.ParseDuration(val)\n\t\t\tc.ThriftPluginTimeLimit = limit\n\t\tcase \"CompilerPath\":\n\t\t\tc.CompilerPath = val\n\t\tcase \"ExtensionFile\":\n\t\t\tc.ExtensionFile = val\n\t\tcase \"Record\":\n\t\t\tc.Record, _ = strconv.ParseBool(val)\n\t\tcase \"RecordCmd\":\n\t\t\tc.RecordCmd = strings.Split(val, \";\")\n\t\tcase \"TemplateDir\":\n\t\t\tc.TemplateDir = val\n\t\tcase \"GenPath\":\n\t\t\tc.GenPath = val\n\t\tcase \"DeepCopyAPI\":\n\t\t\tc.DeepCopyAPI, _ = strconv.ParseBool(val)\n\t\tcase \"Protocol\":\n\t\t\tc.Protocol = val\n\t\tcase \"HandlerReturnKeepResp\":\n\t\t\tc.HandlerReturnKeepResp, _ = strconv.ParseBool(val)\n\t\tcase \"NoDependencyCheck\":\n\t\t\tc.NoDependencyCheck, _ = strconv.ParseBool(val)\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"unknown key: %s\", key)\n\t\t}\n\t}\n\treturn nil\n}\n```"]}, "kitex-tool/internal_pkg/util/util.go-CombineOutputPath": {"response": ["```go\n// CombineOutputPath reads the output and path variables and renders them into the final path\nfunc CombineOutputPath(outputPath, ns string) string {\n\t// If the namespace is not empty, append it to the output path\n\tif ns != \"\" {\n\t\toutputPath = filepath.Join(outputPath, ns)\n\t}\n\treturn outputPath\n}\n```"]}, "kitex-pkg/rpcinfo/stats_util.go-CalcEventCostUs": {"response": ["```go\nfunc CalcEventCostUs(start, end Event) uint64 {\n\t// Calculate the duration between start and end events\n\tduration := end.Time().Sub(start.Time())\n\t// Convert the duration to microseconds\n\treturn uint64(duration.Microseconds())\n}\n```"]}, "kitex-pkg/rpcinfo/invocation.go-NewInvocation": {"response": ["```go\nfunc NewInvocation(service, method string, pkgOpt ...string) *invocation {\n\tivk := invocationPool.Get().(*invocation)\n\tivk.serviceName = service\n\tivk.methodName = method\n\tif len(pkgOpt) > 0 {\n\t\tivk.packageName = pkgOpt[0]\n\t}\n\tivk.seqID = genSeqID()\n\treturn ivk\n}\n```"]}, "kitex-pkg/retry/retryer.go-InitWithPolicies": {"response": ["```go\nfunc (rc *Container) InitWithPolicies(methodPolicies map[string]Policy) error {\n\trc.Lock()\n\tdefer rc.Unlock()\n\n\trc.hasCodeCfg = true\n\trc.msg = \"\"\n\n\tfor method, policy := range methodPolicies {\n\t\tif err := rc.initRetryer(method, policy); err != nil {\n\t\t\treturn fmt.Errorf(\"InitWithPolicies failed to init retryer for method %s, err=%w\", method, err)\n\t\t}\n\t}\n\n\treturn nil\n}\n```"]}, "kitex-pkg/retry/retryer.go-WithRetryIfNeeded": {"response": ["```go\nfunc (rc *Container) WithRetryIfNeeded(ctx context.Context, callOptRetry *Policy, rpcCall RPCCallFunc, ri rpcinfo.RPCInfo, request interface{}) (lastRI rpcinfo.RPCInfo, recycleRI bool, err error) {\n\t// Get the retryer for the current method or wildcard\n\tretryer := rc.getRetryer(ctx, ri)\n\n\t// If no retryer is found and no call option retry policy is provided, return immediately\n\tif retryer == nil && callOptRetry == nil {\n\t\treturn rpcCall(ctx, nil)\n\t}\n\n\t// If a call option retry policy is provided, use it to create a new retryer\n\tif callOptRetry != nil {\n\t\tvar err error\n\t\tretryer, err = NewRetryer(*callOptRetry, rc.shouldResultRetry, rc.cbContainer)\n\t\tif err != nil {\n\t\t\treturn rpcCall(ctx, nil)\n\t\t}\n\t}\n\n\t// Check if the current request can be retried\n\tmsg, ok := retryer.AllowRetry(ctx)\n\tif !ok {\n\t\t// If retry is not allowed, append the reason to the error message and return the result of the initial call\n\t\t_, _, err = rpcCall(ctx, nil)\n\t\tif err != nil {\n\t\t\tappendErrMsg(err, msg)\n\t\t}\n\t\treturn nil, false, err\n\t}\n\n\t// If retry is allowed, use the retryer to perform the call\n\treturn retryer.Do(ctx, rpcCall, ri, request)\n}\n```"]}, "kitex-pkg/discovery/discovery.go-DefaultDiff": {"response": ["```go\n// DefaultDiff provides a natural implementation for the Diff method of the Resolver interface.\nfunc DefaultDiff(cacheKey string, prev, next Result) (Change, bool) {\n\t// Initialize the Change struct with the next Result and empty slices for Added, Updated, and Removed instances.\n\tchange := Change{\n\t\tResult:  next,\n\t\tAdded:   []Instance{},\n\t\tUpdated: []Instance{},\n\t\tRemoved: []Instance{},\n\t}\n\n\t// If the next Result is cacheable, set the CacheKey in the Change struct.\n\tif next.Cacheable {\n\t\tchange.Result.CacheKey = cacheKey\n\t}\n\n\t// Create maps for quick lookup of instances in prev and next Results.\n\tprevInstances := make(map[string]Instance)\n\tnextInstances := make(map[string]Instance)\n\n\t// Populate the prevInstances map with instances from the prev Result.\n\tfor _, inst := range prev.Instances {\n\t\tprevInstances[inst.Address().String()] = inst\n\t}\n\n\t// Populate the nextInstances map with instances from the next Result.\n\tfor _, inst := range next.Instances {\n\t\tnextInstances[inst.Address().String()] = inst\n\t}\n\n\t// Identify added instances.\n\tfor addr, nextInst := range nextInstances {\n\t\tif _, exists := prevInstances[addr]; !exists {\n\t\t\tchange.Added = append(change.Added, nextInst)\n\t\t}\n\t}\n\n\t// Identify removed instances.\n\tfor addr, prevInst := range prevInstances {\n\t\tif _, exists := nextInstances[addr]; !exists {\n\t\t\tchange.Removed = append(change.Removed, prevInst)\n\t\t}\n\t}\n\n\t// Identify updated instances.\n\tfor addr, nextInst := range nextInstances {\n\t\tif prevInst, exists := prevInstances[addr]; exists {\n\t\t\tif !instancesEqual(prevInst, nextInst) {\n\t\t\t\tchange.Updated = append(change.Updated, nextInst)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Determine if the Change is cacheable.\n\tisCacheable := next.Cacheable\n\n\treturn change, isCacheable\n}\n\n// Helper function to compare two instances for equality.\nfunc instancesEqual(a, b Instance) bool {\n\tif a.Address().String() != b.Address().String() {\n\t\treturn false\n\t}\n\tif a.Weight() != b.Weight() {\n\t\treturn false\n\t}\n\tif len(a.(*instance).tags) != len(b.(*instance).tags) {\n\t\treturn false\n\t}\n\tfor k, v := range a.(*instance).tags {\n\t\tif v2, exists := b.(*instance).tags[k]; !exists || v != v2 {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n```"]}, "kitex-pkg/protocol/bthrift/binary.go-SetSpanCache": {"response": ["```go\n// SetSpanCache enable/disable binary protocol bytes/string allocator\nfunc SetSpanCache(enable bool) {\n\tif enable {\n\t\tSetAllocator(mem.NewAllocator())\n\t} else {\n\t\tSetAllocator(nil)\n\t}\n}\n```"]}, "kitex-pkg/protocol/bthrift/unknown.go-GetUnknownFields": {"response": ["```go\nfunc GetUnknownFields(v interface{}) (fields []UnknownField, err error) {\n\t// Check if the input is a struct that implements the thrift.TStruct interface\n\tthriftStruct, ok := v.(thrift.TStruct)\n\tif !ok {\n\t\treturn nil, errors.New(\"input is not a thrift.TStruct\")\n\t}\n\n\t// Get the unknown fields from the thrift struct\n\tunknownFields := thriftStruct.GetUnknownFields()\n\tif len(unknownFields) == 0 {\n\t\treturn nil, errors.New(\"no unknown fields found\")\n\t}\n\n\t// Convert the unknown fields to a list of UnknownField\n\tfields, err = ConvertUnknownFields(unknownFields)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to convert unknown fields: %v\", err)\n\t}\n\n\treturn fields, nil\n}\n```"]}, "kitex-pkg/protocol/bthrift/unknown.go-WriteUnknownFields": {"response": ["```go\nfunc WriteUnknownFields(buf []byte, fs []UnknownField) (offset int, err error) {\n\tfor _, f := range fs {\n\t\toffset, err = writeUnknownField(buf[offset:], &f)\n\t\tif err != nil {\n\t\t\treturn offset, err\n\t\t}\n\t}\n\treturn offset, nil\n}\n```"]}, "kitex-pkg/circuitbreak/circuitbreak.go-NewCircuitBreakerMW": {"response": ["```go\n// NewCircuitBreakerMW creates a circuit breaker MW using the given Control strategy and Panel.\nfunc NewCircuitBreakerMW(control Control, panel circuitbreaker.Panel) endpoint.Middleware {\n\treturn func(next endpoint.Endpoint) endpoint.Endpoint {\n\t\treturn func(ctx context.Context, request, response interface{}) (err error) {\n\t\t\t// Get the circuit breaker key and check if it's enabled\n\t\t\tkey, enabled := control.GetKey(ctx, request)\n\t\t\tif !enabled {\n\t\t\t\t// If circuit breaker is not enabled, proceed with the next middleware\n\t\t\t\treturn next(ctx, request, response)\n\t\t\t}\n\n\t\t\t// Check if the circuit breaker is open\n\t\t\tif !panel.Allow(key) {\n\t\t\t\t// If the circuit breaker is open, return the decorated error\n\t\t\t\treturn control.DecorateError(ctx, request, kerrors.ErrCircuitBreak)\n\t\t\t}\n\n\t\t\t// Proceed with the next middleware\n\t\t\terr = next(ctx, request, response)\n\n\t\t\t// Record the result of the request to the circuit breaker\n\t\t\tRecordStat(ctx, request, response, err, key, &control, panel)\n\n\t\t\treturn err\n\t\t}\n\t}\n}\n```"]}, "kitex-pkg/circuitbreak/cbsuite.go-RPCInfo2Key": {"response": ["```go\nfunc RPCInfo2Key(ri rpcinfo.RPCInfo) string {\n\t// Extract the service name and method name from the RPCInfo\n\tserviceName := ri.To().ServiceName()\n\tmethodName := ri.To().Method()\n\n\t// Combine the service name and method name to form the circuit breaker key\n\treturn fmt.Sprintf(\"%s:%s\", serviceName, methodName)\n}\n```"]}, "kitex-pkg/circuitbreak/default.go-ErrorTypeOnServiceLevel": {"response": ["```go\nfunc ErrorTypeOnServiceLevel(ctx context.Context, request, response interface{}, err error) ErrorType {\n\t// Check if the error is of a type that should be ignored by the circuit breaker\n\tif errorType, ok := ignoreErrTypes[err]; ok {\n\t\treturn errorType\n\t}\n\n\t// If the error is not ignorable, determine its type based on the error itself\n\tswitch {\n\tcase errors.Is(err, kerrors.ErrTimeout):\n\t\treturn TypeTimeout\n\tcase errors.Is(err, kerrors.ErrConnection):\n\t\treturn TypeFailure\n\tdefault:\n\t\treturn FailIfError(ctx, request, response, err)\n\t}\n}\n```"]}, "kitex-pkg/circuitbreak/default.go-ErrorTypeOnInstanceLevel": {"response": ["```go\nfunc ErrorTypeOnInstanceLevel(ctx context.Context, request, response interface{}, err error) ErrorType {\n\t// Check if the error is a connection error\n\tif errors.Is(err, kerrors.ErrConnection) {\n\t\treturn TypeFailure\n\t}\n\n\t// If the error is not a connection error, it is considered ignorable\n\treturn TypeIgnorable\n}\n```"]}, "kitex-pkg/utils/ring.go-NewRing": {"response": ["```go\n// Deprecated: it's not used by kitex anymore.\n// NewRing creates a ringbuffer with fixed size.\nfunc NewRing(size int) *Ring {\n\treturn &Ring{\n\t\tlength: size,\n\t\trings:  make([]*ring, size),\n\t}\n}\n```"]}, "kitex-pkg/utils/thrift.go-Serialize": {"response": ["```go\nfunc (t *ThriftMessageCodec) Serialize(msg thrift.TStruct) (b []byte, err error) {\n\t// Serialize the message into bytes using the normal Thrift serialization process.\n\t// This function is intended for standard Thrift serialization.\n\t// Note: For binary generic use cases, prefer the Encode method instead of Serialize.\n\n\t// Reset the memory buffer to ensure it's empty before writing the new message.\n\tt.tb.Reset()\n\n\t// Write the message to the memory buffer using the Thrift protocol.\n\terr = msg.Write(t.tProt)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Retrieve the serialized bytes from the memory buffer.\n\tb = t.tb.Bytes()\n\treturn b, nil\n}\n```"]}, "kitex-pkg/utils/thrift.go-Deserialize": {"response": ["```go\nfunc (t *ThriftMessageCodec) Deserialize(msg thrift.TStruct, b []byte) (err error) {\n\t// Reset the memory buffer with the provided byte slice\n\tt.tb.Reset()\n\tt.tb.Write(b)\n\n\t// Create a new binary protocol reader\n\tproto := thrift.NewTBinaryProtocol(t.tb, true, true)\n\n\t// Read the message header\n\t_, _, _, err = proto.ReadMessageBegin()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"read message begin error: %w\", err)\n\t}\n\n\t// Deserialize the message\n\terr = msg.Read(proto)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"deserialize message error: %w\", err)\n\t}\n\n\t// Read the message end\n\terr = proto.ReadMessageEnd()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"read message end error: %w\", err)\n\t}\n\n\treturn nil\n}\n```"]}, "kitex-pkg/utils/thrift.go-MarshalError": {"response": ["```go\nfunc MarshalError(method string, err error) []byte {\n\t// Create a new TMemoryBuffer for encoding the error\n\ttransport := thrift.NewTMemoryBufferLen(1024)\n\ttProt := thrift.NewTBinaryProtocol(transport, true, true)\n\n\t// Create a new TApplicationException with the provided error message\n\tappErr := thrift.NewTApplicationException(thrift.INTERNAL_ERROR, err.Error())\n\n\t// Write the exception to the protocol\n\tif err := appErr.Write(tProt); err != nil {\n\t\treturn nil\n\t}\n\n\t// Write the message begin to the protocol\n\tif err := tProt.WriteMessageBegin(method, thrift.EXCEPTION, 0); err != nil {\n\t\treturn nil\n\t}\n\n\t// Write the message end to the protocol\n\tif err := tProt.WriteMessageEnd(); err != nil {\n\t\treturn nil\n\t}\n\n\t// Flush the transport to ensure all data is written\n\tif err := tProt.Flush(); err != nil {\n\t\treturn nil\n\t}\n\n\t// Return the encoded error as a byte slice\n\treturn transport.Bytes()\n}\n```"]}, "kitex-pkg/utils/rpcstats.go-CalculateEventCost": {"response": ["```go\n// CalculateEventCost get events from rpcstats, and calculates the time duration of (end - start).\n// It returns 0 when get nil rpcinfo event of either stats event.\nfunc CalculateEventCost(rpcstats rpcinfo.RPCStats, start, end stats.Event) time.Duration {\n    startEvent := rpcstats.GetEvent(start)\n    endEvent := rpcstats.GetEvent(end)\n\n    if startEvent == nil || endEvent == nil {\n        return 0\n    }\n\n    return endEvent.Time().Sub(startEvent.Time())\n}\n```"]}, "kitex-pkg/utils/json.go-_Map2JSONStr": {"response": ["```go\nfunc _Map2JSONStr(mapInfo map[string]string) (str string, err error) {\n\tif len(mapInfo) == 0 {\n\t\treturn \"{}\", nil\n\t}\n\n\tvar sb strings.Builder\n\tsb.WriteByte('{')\n\tfirst := true\n\tfor k, v := range mapInfo {\n\t\tif !first {\n\t\t\tsb.WriteByte(',')\n\t\t}\n\t\tfirst = false\n\t\tsb.WriteByte('\"')\n\t\tsb.WriteString(k)\n\t\tsb.WriteByte('\"')\n\t\tsb.WriteByte(':')\n\t\tsb.WriteByte('\"')\n\t\tsb.WriteString(v)\n\t\tsb.WriteByte('\"')\n\t}\n\tsb.WriteByte('}')\n\treturn sb.String(), nil\n}\n```"]}, "kitex-pkg/utils/json.go-_JSONStr2Map": {"response": ["```go\nfunc _JSONStr2Map(jsonStr string) (mapInfo map[string]string, err error) {\n\tmapInfo = make(map[string]string)\n\tvar key, value string\n\tvar idx, lastIdx int\n\tvar c byte\n\n\tidx = 0\n\tlastIdx = len(jsonStr) - 1\n\n\tfor idx <= lastIdx {\n\t\tif key, idx, err = readString(jsonStr, idx, lastIdx); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif c, idx, err = nextToken(jsonStr, idx, lastIdx); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif c != Colon {\n\t\t\treturn nil, fmt.Errorf(\"json str is invalid, expects ':', but found %s\", string(c))\n\t\t}\n\t\tif value, idx, err = readString(jsonStr, idx, lastIdx); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tmapInfo[key] = value\n\t\tif c, idx, err = nextToken(jsonStr, idx, lastIdx); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif c == RightBrace {\n\t\t\tbreak\n\t\t} else if c != Comma {\n\t\t\treturn nil, fmt.Errorf(\"json str is invalid, expects ',' or '}', but found %s\", string(c))\n\t\t}\n\t}\n\n\treturn mapInfo, nil\n}\n```"]}, "kitex-pkg/utils/kitexutil/kitexutil.go-GetCaller": {"response": ["```go\n// GetCaller is used to get the Service Name of the caller.\n// Return false if failed to get the information.\nfunc GetCaller(ctx context.Context) (string, bool) {\n\trpcInfo := rpcinfo.GetRPCInfo(ctx)\n\tif rpcInfo == nil {\n\t\treturn \"\", false\n\t}\n\tcaller := rpcInfo.From()\n\tif caller == nil {\n\t\treturn \"\", false\n\t}\n\tserviceName := caller.ServiceName()\n\tif serviceName == \"\" {\n\t\treturn \"\", false\n\t}\n\treturn serviceName, true\n}\n```"]}, "kitex-pkg/utils/kitexutil/kitexutil.go-GetMethod": {"response": ["```go\n// GetMethod is used to get the current RPC Method name.\n// Return false if failed to get the information.\nfunc GetMethod(ctx context.Context) (string, bool) {\n\trpcInfo, ok := rpcinfo.GetRPCInfo(ctx)\n\tif !ok {\n\t\treturn \"\", false\n\t}\n\tmethod := rpcInfo.To().Method()\n\tif method == \"\" {\n\t\treturn \"\", false\n\t}\n\treturn method, true\n}\n```"]}, "kitex-pkg/utils/kitexutil/kitexutil.go-GetCallerHandlerMethod": {"response": ["```go\nfunc GetCallerHandlerMethod(ctx context.Context) (string, bool) {\n\t// Retrieve the RPCInfo from the context\n\trpcInfo, ok := rpcinfo.GetRPCInfo(ctx)\n\tif !ok {\n\t\treturn \"\", false\n\t}\n\n\t// Check if the caller is a Kitex server and has the method information\n\tif caller := rpcInfo.From(); caller != nil {\n\t\tif method := caller.Method(); method != \"\" {\n\t\t\treturn method, true\n\t\t}\n\t}\n\n\t// Alternatively, check if the K_METHOD is set in the context\n\tif method, ok := ctx.Value(\"K_METHOD\").(string); ok {\n\t\treturn method, true\n\t}\n\n\t// Return false if the method information is not found\n\treturn \"\", false\n}\n```"]}, "kitex-pkg/utils/kitexutil/kitexutil.go-GetIDLServiceName": {"response": ["```go\n// GetIDLServiceName gets the serviceName which defined in IDL.\n// Return false if failed to get the information.\nfunc GetIDLServiceName(ctx context.Context) (string, bool) {\n\trpcInfo := rpcinfo.GetRPCInfo(ctx)\n\tif rpcInfo == nil {\n\t\treturn \"\", false\n\t}\n\tserviceName := rpcInfo.To().ServiceName()\n\tif serviceName == \"\" {\n\t\treturn \"\", false\n\t}\n\treturn serviceName, true\n}\n```"]}, "kitex-pkg/utils/kitexutil/kitexutil.go-GetCallerAddr": {"response": ["```go\nfunc GetCallerAddr(ctx context.Context) (net.Addr, bool) {\n\trpcInfo := rpcinfo.GetRPCInfo(ctx)\n\tif rpcInfo == nil {\n\t\treturn nil, false\n\t}\n\n\tremoteAddr := rpcInfo.From().Address()\n\tif remoteAddr == nil {\n\t\treturn nil, false\n\t}\n\n\treturn remoteAddr, true\n}\n```"]}, "kitex-pkg/utils/kitexutil/kitexutil.go-GetCallerIP": {"response": ["```go\n// GetCallerIP is used for the server to get the IP of the caller.\n// Return false if failed to get the information.\nfunc GetCallerIP(ctx context.Context) (string, bool) {\n\trpcInfo := rpcinfo.GetRPCInfo(ctx)\n\tif rpcInfo == nil {\n\t\treturn \"\", false\n\t}\n\n\tremoteAddr := rpcInfo.From().Address()\n\tif remoteAddr == nil {\n\t\treturn \"\", false\n\t}\n\n\tip, _, err := net.SplitHostPort(remoteAddr.String())\n\tif err != nil {\n\t\treturn \"\", false\n\t}\n\n\treturn ip, true\n}\n```"]}, "kitex-pkg/utils/kitexutil/kitexutil.go-GetTransportProtocol": {"response": ["```go\n// GetTransportProtocol gets the transport protocol of the request.\n// Return false if failed to get the information.\nfunc GetTransportProtocol(ctx context.Context) (string, bool) {\n\trpcInfo, ok := rpcinfo.GetRPCInfo(ctx)\n\tif !ok {\n\t\treturn \"\", false\n\t}\n\ttransInfo := rpcInfo.TransInfo()\n\tprotocol := transInfo.TransportProtocol()\n\tif protocol == \"\" {\n\t\treturn \"\", false\n\t}\n\treturn protocol, true\n}\n```"]}, "kitex-pkg/utils/kitexutil/kitexutil.go-GetRPCInfo": {"response": ["```go\nfunc GetRPCInfo(ctx context.Context) (rpcinfo.RPCInfo, bool) {\n\trpcInfo, ok := rpcinfo.GetRPCInfo(ctx)\n\tif !ok {\n\t\treturn nil, false\n\t}\n\treturn rpcInfo, true\n}\n```"]}, "kitex-pkg/remote/trans_errors.go-NewTransError": {"response": ["```go\nfunc NewTransError(typeID int32, err error) *TransError {\n\treturn &TransError{\n\t\ttypeID: typeID,\n\t\trawErr: err,\n\t}\n}\n```"]}, "kitex-pkg/remote/trans/gonet/bytebuffer.go-NewBufferReader": {"response": ["```go\nfunc NewBufferReader(ir io.Reader) remote.ByteBuffer {\n\trw := rwPool.Get().(*bufferReadWriter)\n\trw.reader = netpoll.NewReader(ir)\n\trw.ioReader = ir\n\trw.status = remote.BitReadable\n\treturn rw\n}\n```"]}, "kitex-pkg/remote/trans/gonet/bytebuffer.go-WriteDirect": {"response": ["```go\nfunc (rw *bufferReadWriter) WriteDirect(p []byte, remainCap int) error {\n\tif !rw.writable() {\n\t\treturn errors.New(\"unwritable buffer, cannot support WriteDirect\")\n\t}\n\n\t// Ensure the remaining capacity is sufficient for the data to be written\n\tif remainCap < len(p) {\n\t\treturn errors.New(\"insufficient remaining capacity for WriteDirect\")\n\t}\n\n\t// Write the data directly into the buffer without copying\n\t_, err := rw.writer.Write(p)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/server_handler.go-invokeStreamUnaryHandler": {"response": ["```go\nfunc invokeStreamUnaryHandler(ctx context.Context, st streaming.Stream, mi serviceinfo.MethodInfo, inkHdlFunc endpoint.Endpoint, ri rpcinfo.RPCInfo) error {\n\t// Prepare the arguments and result for the unary handler\n\targs := &streaming.Args{Stream: st}\n\tresult := &streaming.Result{Stream: st}\n\n\t// Invoke the unary handler function\n\terr := inkHdlFunc(ctx, args, result)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// If there is a business status error, return it\n\tif bizStatusErr := ri.Invocation().BizStatusErr(); bizStatusErr != nil {\n\t\treturn bizStatusErr\n\t}\n\n\treturn nil\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/metadata/metadata.go-FromOutgoingContext": {"response": ["```go\n// FromOutgoingContext returns the outgoing metadata in ctx if it exists.  The\n// returned MD should not be modified. Writing to it may cause races.\n// Modification should be made to copies of the returned MD.\nfunc FromOutgoingContext(ctx context.Context) (MD, bool) {\n\traw, ok := ctx.Value(mdOutgoingKey{}).(rawMD)\n\tif !ok {\n\t\treturn nil, false\n\t}\n\n\t// Merge the raw metadata with the added metadata\n\tmd := raw.md.Copy()\n\tfor _, kv := range raw.added {\n\t\tif len(kv)%2 != 0 {\n\t\t\tcontinue // Skip invalid pairs\n\t\t}\n\t\tkey := strings.ToLower(kv[0])\n\t\tmd.Append(key, kv[1:]...)\n\t}\n\n\treturn md, true\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/status/status.go-WithDetails": {"response": ["```go\nfunc (s *Status) WithDetails(details ...proto.Message) (*Status, error) {\n\tif s == nil || s.s == nil {\n\t\treturn nil, errors.New(\"status is nil\")\n\t}\n\n\tfor _, detail := range details {\n\t\tanyDetail, err := anypb.New(detail)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\ts.s.Details = append(s.s.Details, anyDetail)\n\t}\n\n\treturn s, nil\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/status/status.go-FromError": {"response": ["```go\nfunc FromError(err error) (s *Status, ok bool) {\n\tif err == nil {\n\t\treturn nil, true\n\t}\n\n\tvar se Iface\n\tif errors.As(err, &se) {\n\t\treturn se.GRPCStatus(), true\n\t}\n\n\treturn New(codes.Unknown, err.Error()), false\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/status/status.go-FromContextError": {"response": ["```go\nfunc FromContextError(err error) *Status {\n\tif err == nil {\n\t\treturn New(codes.OK, \"\")\n\t}\n\tif errors.Is(err, context.Canceled) {\n\t\treturn New(codes.Canceled, err.Error())\n\t}\n\tif errors.Is(err, context.DeadlineExceeded) {\n\t\treturn New(codes.DeadlineExceeded, err.Error())\n\t}\n\treturn New(codes.Unknown, err.Error())\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/grpc/bdp_estimator.go-calculate": {"response": ["```go\nfunc (b *bdpEstimator) calculate(d [8]byte) {\n\tb.mu.Lock()\n\tdefer b.mu.Unlock()\n\tif b.sentAt.IsZero() {\n\t\t// This is a keepalive ping.\n\t\treturn\n\t}\n\trtt := time.Since(b.sentAt).Seconds()\n\tb.sentAt = time.Time{}\n\tif rtt == 0 {\n\t\t// This shouldn't happen in reality.\n\t\tklog.Warnf(\"transport: bdpEstimator.calculate found rtt was 0\")\n\t\treturn\n\t}\n\tb.rtt = alpha*b.rtt + (1-alpha)*rtt\n\tbw := float64(b.sample) / rtt\n\tb.bwMax = math.Max(b.bwMax, bw)\n\tb.sample = 0\n\tif bw >= beta*b.bwMax {\n\t\tb.bdp = uint32(math.Min(float64(bdpLimit), gamma*float64(b.bdp)))\n\t\tb.updateFlowControl(b.bdp)\n\t}\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/grpc/http2_server.go-finishStream": {"response": ["```go\nfunc (t *http2Server) finishStream(s *Stream, rst bool, rstCode http2.ErrCode, hdr *headerFrame, eosReceived bool) {\n\t// Set stream status to done.\n\tif s.swapState(streamDone) == streamDone {\n\t\t// If it was already done, return.  If multiple finishStream calls\n\t\t// happen simultaneously, wait for the first to finish.\n\t\t<-s.done\n\t\treturn\n\t}\n\t// status and trailers can be updated here without any synchronization because the stream goroutine will\n\t// only read it after it sees an io.EOF error from read or write and we'll write those errors\n\t// only after updating this.\n\ts.status = hdr.status\n\tif len(hdr.trailer) > 0 {\n\t\ts.trailer = hdr.trailer\n\t}\n\tif hdr.err != nil {\n\t\t// This will unblock reads eventually.\n\t\ts.write(recvMsg{err: hdr.err})\n\t}\n\t// If headerChan isn't closed, then close it.\n\tif atomic.CompareAndSwapUint32(&s.headerChanClosed, 0, 1) {\n\t\ts.noHeaders = true\n\t\tclose(s.headerChan)\n\t}\n\tcleanup := &cleanupStream{\n\t\tstreamID: s.id,\n\t\tonWrite: func() {\n\t\t\tt.mu.Lock()\n\t\t\tif t.activeStreams != nil {\n\t\t\t\tdelete(t.activeStreams, s.id)\n\t\t\t}\n\t\t\tt.mu.Unlock()\n\t\t},\n\t\trst:     rst,\n\t\trstCode: rstCode,\n\t}\n\taddBackStreamQuota := func(interface{}) bool {\n\t\tt.streamQuota++\n\t\tif t.streamQuota > 0 && t.waitingStreams > 0 {\n\t\t\tselect {\n\t\t\tcase t.streamsQuotaAvailable <- struct{}{}:\n\t\t\tdefault:\n\t\t\t}\n\t\t}\n\t\treturn true\n\t}\n\tt.controlBuf.executeAndPut(addBackStreamQuota, cleanup)\n\t// This will unblock write.\n\tclose(s.done)\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/grpc/http2_server.go-closeStream": {"response": ["```go\nfunc (t *http2Server) closeStream(s *Stream, rst bool, rstCode http2.ErrCode, eosReceived bool) {\n\t// closeStream clears the footprint of a stream when the stream is not needed any more.\n\t// This must not be executed in reader's goroutine.\n\n\t// Set stream status to done.\n\tif s.swapState(streamDone) == streamDone {\n\t\t// If it was already done, return.\n\t\treturn\n\t}\n\n\t// If headerChan isn't closed, then close it.\n\tif atomic.CompareAndSwapUint32(&s.headerChanClosed, 0, 1) {\n\t\ts.noHeaders = true\n\t\tclose(s.headerChan)\n\t}\n\n\t// If rst is true, send a RST_STREAM frame.\n\tif rst {\n\t\tt.controlBuf.put(&cleanupStream{\n\t\t\tstreamID: s.id,\n\t\t\trst:      true,\n\t\t\trstCode:  rstCode,\n\t\t\tonWrite:  func() {},\n\t\t})\n\t}\n\n\t// If eosReceived is true, it means the end of the stream was received.\n\tif eosReceived {\n\t\ts.write(recvMsg{err: io.EOF})\n\t}\n\n\t// This will unblock write.\n\tclose(s.done)\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/grpc/transport.go-TLSConfig": {"response": ["```go\nfunc TLSConfig(tlsConfig *tls.Config) *tls.Config {\n    if tlsConfig == nil {\n        tlsConfig = &tls.Config{}\n    }\n    tlsConfig.NextProtos = tlsAppendH2ToALPNProtocols(tlsConfig.NextProtos)\n    return tlsConfig\n}\n```"]}, "kitex-pkg/remote/trans/nphttp2/grpc/http_util.go-encodeTimeout": {"response": ["```go\nfunc encodeTimeout(t time.Duration) string {\n\tif t <= 0 {\n\t\treturn \"0n\"\n\t}\n\tif d := div(t, time.Nanosecond); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"n\"\n\t}\n\tif d := div(t, time.Microsecond); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"u\"\n\t}\n\tif d := div(t, time.Millisecond); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"m\"\n\t}\n\tif d := div(t, time.Second); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"S\"\n\t}\n\tif d := div(t, time.Minute); d <= maxTimeoutValue {\n\t\treturn strconv.FormatInt(d, 10) + \"M\"\n\t}\n\t// The max is \"100000000H\"\n\treturn strconv.FormatInt(div(t, time.Hour), 10) + \"H\"\n}\n```"]}, "kitex-pkg/remote/trans/netpoll/bytebuf.go-AppendBuffer": {"response": ["```go\nfunc (b *netpollByteBuffer) AppendBuffer(buf remote.ByteBuffer) (err error) {\n\t// AppendBuffer appends buf to the original buffer.\n\tif b.status&remote.BitWritable == 0 {\n\t\treturn errors.New(\"unwritable buffer, cannot support AppendBuffer\")\n\t}\n\n\t// Convert the incoming buffer to a netpollByteBuffer\n\tnpBuf, ok := buf.(*netpollByteBuffer)\n\tif !ok {\n\t\treturn errors.New(\"invalid buffer type, expected netpollByteBuffer\")\n\t}\n\n\t// Append the content of the incoming buffer to the original buffer\n\t_, err = b.writer.Write(npBuf.Bytes())\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n```"]}, "kitex-pkg/remote/codec/util.go-SetOrCheckMethodName": {"response": ["```go\n// SetOrCheckMethodName is used to set method name to invocation.\nfunc SetOrCheckMethodName(methodName string, message remote.Message) error {\n\tif ink, ok := message.RPCInfo().Invocation().(rpcinfo.InvocationSetter); ok {\n\t\tink.SetMethodName(methodName)\n\t} else {\n\t\treturn errors.New(\"the interface Invocation doesn't implement InvocationSetter\")\n\t}\n\treturn nil\n}\n```"]}, "kitex-pkg/remote/codec/thrift/thrift_data.go-MarshalThriftData": {"response": ["```go\nfunc MarshalThriftData(ctx context.Context, codec remote.PayloadCodec, data interface{}) ([]byte, error) {\n\t// Cast the codec to thriftCodec to access its methods\n\tthriftCodec, ok := codec.(*thriftCodec)\n\tif !ok {\n\t\treturn nil, errors.New(\"codec is not of type thriftCodec\")\n\t}\n\n\t// Encode with hyper codec if enabled and available\n\tif thriftCodec.hyperMarshalEnabled() && hyperMarshalAvailable(data) {\n\t\treturn thriftCodec.hyperMarshalBody(data)\n\t}\n\n\t// Encode with FastWrite if enabled\n\tif thriftCodec.CodecType&FastWrite != 0 {\n\t\tif msg, ok := data.(ThriftMsgFastCodec); ok {\n\t\t\tpayloadSize := msg.BLength()\n\t\t\tpayload := mcache.Malloc(payloadSize)\n\t\t\tmsg.FastWriteNocopy(payload, nil)\n\t\t\treturn payload, nil\n\t\t}\n\t}\n\n\t// Verify if the data type can be marshaled by the old thrift way\n\tif err := verifyMarshalBasicThriftDataType(data); err != nil {\n\t\t// Fallback to frugal if the generated code is using slim template\n\t\tif thriftCodec.CodecType != Basic && hyperMarshalAvailable(data) {\n\t\t\treturn thriftCodec.hyperMarshalBody(data)\n\t\t}\n\t\treturn nil, err\n\t}\n\n\t// Fallback to old thrift way (slow)\n\ttransport := thrift.NewTMemoryBufferLen(marshalThriftBufferSize)\n\ttProt := thrift.NewTBinaryProtocol(transport, true, true)\n\tif err := marshalBasicThriftData(ctx, tProt, data); err != nil {\n\t\treturn nil, err\n\t}\n\treturn transport.Bytes(), nil\n}\n```"]}, "kitex-pkg/remote/codec/thrift/thrift_data.go-marshalBasicThriftData": {"response": ["```go\nfunc marshalBasicThriftData(ctx context.Context, tProt thrift.TProtocol, data interface{}) error {\n\t// marshalBasicThriftData only encodes the data (without the prepending method, msgType, seqId)\n\t// It uses the old thrift way which is much slower than FastCodec and Frugal\n\n\t// Verify if the data type can be marshaled by the old thrift way\n\tif err := verifyMarshalBasicThriftDataType(data); err != nil {\n\t\treturn err\n\t}\n\n\t// Write the data to the thrift protocol\n\tswitch d := data.(type) {\n\tcase MessageWriter:\n\t\tif err := d.Write(tProt); err != nil {\n\t\t\treturn perrors.NewProtocolErrorWithMsg(fmt.Sprintf(\"thrift marshal, Write failed: %s\", err.Error()))\n\t\t}\n\tcase MessageWriterWithContext:\n\t\tif err := d.Write(ctx, tProt); err != nil {\n\t\t\treturn perrors.NewProtocolErrorWithMsg(fmt.Sprintf(\"thrift marshal, WriteWithContext failed: %s\", err.Error()))\n\t\t}\n\tdefault:\n\t\treturn errEncodeMismatchMsgType\n\t}\n\n\treturn nil\n}\n```"]}, "kitex-pkg/remote/codec/thrift/thrift_data.go-UnmarshalThriftException": {"response": ["```go\nfunc UnmarshalThriftException(tProt thrift.TProtocol) error {\n\t// Read the exception message\n\t_, _, _, err := tProt.ReadMessageBegin()\n\tif err != nil {\n\t\treturn perrors.NewProtocolErrorWithErrMsg(err, fmt.Sprintf(\"thrift unmarshal, ReadMessageBegin failed: %s\", err.Error()))\n\t}\n\n\t// Read the exception struct\n\t_, err = tProt.ReadStructBegin()\n\tif err != nil {\n\t\treturn perrors.NewProtocolErrorWithErrMsg(err, fmt.Sprintf(\"thrift unmarshal, ReadStructBegin failed: %s\", err.Error()))\n\t}\n\n\t// Read fields until STOP\n\tfor {\n\t\t_, typeID, _, err := tProt.ReadFieldBegin()\n\t\tif err != nil {\n\t\t\treturn perrors.NewProtocolErrorWithErrMsg(err, fmt.Sprintf(\"thrift unmarshal, ReadFieldBegin failed: %s\", err.Error()))\n\t\t}\n\t\tif typeID == thrift.STOP {\n\t\t\tbreak\n\t\t}\n\t\t// Skip the field\n\t\terr = tProt.Skip(typeID)\n\t\tif err != nil {\n\t\t\treturn perrors.NewProtocolErrorWithErrMsg(err, fmt.Sprintf(\"thrift unmarshal, Skip failed: %s\", err.Error()))\n\t\t}\n\t\terr = tProt.ReadFieldEnd()\n\t\tif err != nil {\n\t\t\treturn perrors.NewProtocolErrorWithErrMsg(err, fmt.Sprintf(\"thrift unmarshal, ReadFieldEnd failed: %s\", err.Error()))\n\t\t}\n\t}\n\n\t// Read the end of the struct\n\terr = tProt.ReadStructEnd()\n\tif err != nil {\n\t\treturn perrors.NewProtocolErrorWithErrMsg(err, fmt.Sprintf(\"thrift unmarshal, ReadStructEnd failed: %s\", err.Error()))\n\t}\n\n\t// Read the end of the message\n\terr = tProt.ReadMessageEnd()\n\tif err != nil {\n\t\treturn perrors.NewProtocolErrorWithErrMsg(err, fmt.Sprintf(\"thrift unmarshal, ReadMessageEnd failed: %s\", err.Error()))\n\t}\n\n\treturn nil\n}\n```"]}, "kitex-pkg/remote/codec/thrift/thrift_data.go-UnmarshalThriftData": {"response": ["```go\nfunc UnmarshalThriftData(ctx context.Context, codec remote.PayloadCodec, method string, buf []byte, data interface{}) error {\n\t// UnmarshalThriftData only decodes the data (after methodName, msgType and seqId)\n\t// It will decode from the given buffer.\n\t// Note:\n\t// 1. `method` is only used for generic calls\n\t// 2. if the buf contains an exception, you should call UnmarshalThriftException instead.\n\n\t// Create a new BinaryProtocol with the given buffer\n\ttProt := NewBinaryProtocol(remote.NewReaderBuffer(buf))\n\n\t// Check if the codec is a thriftCodec\n\tthriftCodec, ok := codec.(*thriftCodec)\n\tif !ok {\n\t\treturn errors.New(\"codec is not a thriftCodec\")\n\t}\n\n\t// Decode the data using the appropriate method based on the codec type\n\tif thriftCodec.fastMessageUnmarshalEnabled() && thriftCodec.fastMessageUnmarshalAvailable(data, len(buf)) {\n\t\treturn thriftCodec.fastUnmarshal(tProt, data, len(buf))\n\t} else if thriftCodec.hyperMessageUnmarshalEnabled() && thriftCodec.hyperMessageUnmarshalAvailable(data, len(buf)) {\n\t\treturn thriftCodec.hyperUnmarshal(tProt, data, len(buf))\n\t} else {\n\t\t// Fallback to the old thrift way (slow)\n\t\tif err := verifyUnmarshalBasicThriftDataType(data); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn decodeBasicThriftData(ctx, tProt, data)\n\t}\n}\n```"]}, "kitex-pkg/remote/codec/thrift/thrift_data.go-unmarshalThriftData": {"response": ["```go\nfunc (c thriftCodec) unmarshalThriftData(ctx context.Context, tProt *BinaryProtocol, method string, data interface{}, dataLen int) error {\n\t// unmarshalThriftData only decodes the data (after methodName, msgType and seqId)\n\t// method is only used for generic calls\n\n\t// Check if hyper unmarshal is enabled and available\n\tif c.hyperMessageUnmarshalEnabled() && c.hyperMessageUnmarshalAvailable(data, dataLen) {\n\t\treturn c.hyperUnmarshal(tProt, data, dataLen)\n\t}\n\n\t// Check if fast unmarshal is enabled and available\n\tif c.fastMessageUnmarshalEnabled() && c.fastMessageUnmarshalAvailable(data, dataLen) {\n\t\treturn c.fastUnmarshal(tProt, data, dataLen)\n\t}\n\n\t// Verify if the data type can be unmarshaled by the old thrift way\n\tif err := verifyUnmarshalBasicThriftDataType(data); err != nil {\n\t\treturn err\n\t}\n\n\t// Fallback to old thrift way (slow)\n\tif err := decodeBasicThriftData(ctx, tProt, data); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n```"]}, "kitex-pkg/remote/codec/thrift/thrift_data.go-decodeBasicThriftData": {"response": ["```go\nfunc decodeBasicThriftData(ctx context.Context, tProt thrift.TProtocol, method string, data interface{}) error {\n\t// decodeBasicThriftData decode thrift body the old way (slow)\n\tswitch d := data.(type) {\n\tcase MessageReader:\n\t\tif err := d.Read(tProt); err != nil {\n\t\t\treturn perrors.NewProtocolErrorWithMsg(fmt.Sprintf(\"thrift unmarshal, Read failed: %s\", err.Error()))\n\t\t}\n\tcase MessageReaderWithMethodWithContext:\n\t\tif err := d.Read(ctx, method, tProt); err != nil {\n\t\t\treturn perrors.NewProtocolErrorWithMsg(fmt.Sprintf(\"thrift unmarshal, Read failed: %s\", err.Error()))\n\t\t}\n\tdefault:\n\t\treturn errDecodeMismatchMsgType\n\t}\n\treturn nil\n}\n```"]}, "kitex-pkg/remote/remotecli/conn_wrapper.go-GetConn": {"response": ["```go\nfunc (cm *ConnWrapper) GetConn(ctx context.Context, d remote.Dialer, ri rpcinfo.RPCInfo) (net.Conn, error) {\n\t// Get the timeout duration from the RPCInfo configuration\n\ttimeout := ri.Config().ConnectTimeout()\n\n\t// Check if the connection pool is available\n\tif cm.connPool != nil {\n\t\t// Use the connection pool to get a connection\n\t\tconn, err := cm.getConnWithPool(ctx, cm.connPool, d, timeout, ri)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn conn, nil\n\t}\n\n\t// If no connection pool is available, use the dialer directly\n\tconn, err := cm.getConnWithDialer(ctx, d, timeout, ri)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn conn, nil\n}\n```"]}, "kitex-pkg/remote/connpool/long_pool.go-Evict": {"response": ["```go\nfunc (p *pool) Evict() (evicted int) {\n\tp.mu.Lock()\n\tdefer p.mu.Unlock()\n\n\tevicted = 0\n\tfor i := 0; i < len(p.idleList); i++ {\n\t\tif p.idleList[i].Expired() {\n\t\t\tp.idleList[i].Close()\n\t\t\tp.idleList[i] = nil\n\t\t\tevicted++\n\t\t} else {\n\t\t\t// Since the list is FIFO, we can break early if we find an active connection\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Remove evicted connections from the idleList\n\tp.idleList = p.idleList[evicted:]\n\n\treturn evicted\n}\n```"]}, "kitex-pkg/loadbalance/lbcache/cache.go-NewBalancerFactory": {"response": ["```go\nfunc NewBalancerFactory(resolver discovery.Resolver, balancer loadbalance.Loadbalancer, opts Options) *BalancerFactory {\n\t// Check and set default values for options if necessary\n\topts.check()\n\n\t// Create a cache key based on resolver name, balancer name, and options\n\tcacheKey := cacheKey(resolver.Name(), balancer.Name(), opts)\n\n\t// Use singleflight to ensure that only one instance of the BalancerFactory is created for the same cache key\n\tval, err, _ := balancerFactoriesSfg.Do(cacheKey, func() (interface{}, error) {\n\t\t// Create a new BalancerFactory instance\n\t\tbf := newBalancerFactory(resolver, balancer, opts)\n\n\t\t// Store the BalancerFactory instance in the balancerFactories map\n\t\tbalancerFactories.Store(cacheKey, bf)\n\n\t\treturn bf, nil\n\t})\n\n\t// Return the BalancerFactory instance\n\treturn val.(*BalancerFactory)\n}\n```"]}, "kitex-pkg/stats/event.go-DefineNewEvent": {"response": ["```go\n// DefineNewEvent allows user to add event definitions during program initialization.\nfunc DefineNewEvent(name string, level Level) (Event, error) {\n\tlock.Lock()\n\tdefer lock.Unlock()\n\n\t// Check if the initialization is already finished\n\tif atomic.LoadInt32(&inited) == 1 {\n\t\treturn nil, ErrNotAllowed\n\t}\n\n\t// Check if the event name is already defined\n\tif _, exists := userDefined[name]; exists {\n\t\treturn nil, ErrDuplicated\n\t}\n\n\t// Create a new event with the next available index\n\tnewEventIndex := EventIndex(maxEventNum + 1)\n\tnewEvent := newEvent(newEventIndex, level)\n\n\t// Store the new event in the userDefined map\n\tuserDefined[name] = newEvent\n\n\t// Update the maxEventNum\n\tmaxEventNum++\n\n\treturn newEvent, nil\n}\n```"]}, "kitex-pkg/generic/thriftidl_provider.go-NewThriftFileProviderWithDynamicGo": {"response": ["```go\nfunc NewThriftFileProviderWithDynamicGo(path string, includeDirs ...string) (DescriptorProvider, error) {\n\tp := &ThriftContentProvider{\n\t\tsvcs: make(chan *descriptor.ServiceDescriptor, 1), // unblock with buffered channel\n\t\topts: &ProviderOption{DynamicGoEnabled: true},\n\t}\n\tsvc, err := newServiceDescriptorFromPath(path, includeDirs...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tp.newDynamicGoDsc(svc, defaultMainIDLPath, \"\", nil)\n\n\tp.svcs <- svc\n\treturn p, nil\n}\n```"]}, "kitex-pkg/generic/thriftidl_provider.go-NewThriftContentWithAbsIncludePathProviderWithDynamicGo": {"response": ["```go\nfunc NewThriftContentWithAbsIncludePathProviderWithDynamicGo(mainIDLPath string, includes map[string]string) (*ThriftContentWithAbsIncludePathProvider, error) {\n\tp := &ThriftContentWithAbsIncludePathProvider{\n\t\tsvcs: make(chan *descriptor.ServiceDescriptor, 1), // unblock with buffered channel\n\t\topts: &ProviderOption{DynamicGoEnabled: true},\n\t}\n\tsvc, err := newServiceDescriptorFromContent(mainIDLPath, includes[mainIDLPath], includes, true)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tp.newDynamicGoDsc(svc, mainIDLPath, includes[mainIDLPath], includes)\n\n\tp.svcs <- svc\n\treturn p, nil\n}\n```"]}, "kitex-pkg/generic/generic.go-MapThriftGeneric": {"response": ["```go\nfunc MapThriftGeneric(p DescriptorProvider) (Generic, error) {\n\tcodec, err := newMapThriftCodec(p, thriftCodec)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &mapThriftGeneric{\n\t\tcodec: codec,\n\t}, nil\n}\n```"]}, "kitex-pkg/generic/generic.go-JSONThriftGeneric": {"response": ["```go\nfunc JSONThriftGeneric(p DescriptorProvider, opts ...Option) (Generic, error) {\n\toptions := &Options{\n\t\tdynamicgoConvOpts: DefaultJSONDynamicGoConvOpts,\n\t}\n\toptions.apply(opts)\n\n\tcodec, err := newJsonThriftCodec(p, thriftCodec, options)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &jsonThriftGeneric{\n\t\tcodec: codec,\n\t}, nil\n}\n```"]}, "kitex-pkg/generic/generic.go-JSONPbGeneric": {"response": ["```go\nfunc JSONPbGeneric(p PbDescriptorProviderDynamicGo, opts ...Option) (Generic, error) {\n\t// Create default options\n\toptions := &Options{\n\t\tdynamicgoConvOpts: DefaultJSONDynamicGoConvOpts,\n\t}\n\t// Apply provided options\n\toptions.apply(opts)\n\n\t// Create the JSONPb codec\n\tcodec, err := newJsonPbCodec(p, pbCodec, options)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Return the generic implementation\n\treturn &jsonPbGeneric{\n\t\tcodec: codec,\n\t}, nil\n}\n```"]}, "kitex-pkg/generic/thrift/write.go-writeStruct": {"response": ["```go\nfunc writeStruct(ctx context.Context, val interface{}, out thrift.TProtocol, t *descriptor.TypeDescriptor, opt *writerOption) error {\n\tvar fs fieldGetter\n\tvar st interface{}\n\tif opt == nil || opt.pbDsc == nil {\n\t\tif opt == nil {\n\t\t\topt = &writerOption{}\n\t\t}\n\t\tholder := map[string]interface{}{}\n\t\tfs = getMapFieldSetter(holder)\n\t\tst = holder\n\t} else {\n\t\tholder := proto.NewMessage(opt.pbDsc)\n\t\tfs = getPbFieldSetter(holder)\n\t\tst = holder\n\t}\n\n\tvar err error\n\t// set default value\n\t// void is nil struct\n\t// default value with struct NOT SUPPORT pb.\n\tif t.Struct != nil {\n\t\t// set all fields even if it is empty, to be compatible with code-gen\n\t\tif opt.setFieldsForEmptyStruct != 0 {\n\t\t\tfor _, field := range t.Struct.FieldsByID {\n\t\t\t\tif opt.setFieldsForEmptyStruct == 1 {\n\t\t\t\t\t// ignore optional fields if setFieldsForEmptyStruct == 1\n\t\t\t\t\tif field.Optional {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif err := fs(field, readEmptyValue(field.Type)); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor _, field := range t.Struct.DefaultFields {\n\t\t\tval := field.DefaultValue\n\t\t\tif field.ValueMapping != nil {\n\t\t\t\tif val, err = field.ValueMapping.Response(ctx, val, field); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\tif err := fs(field, val); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\t_, err = in.ReadStructBegin()\n\tif err != nil {\n\t\treturn err\n\t}\n\treadFields := map[int32]struct{}{}\n\tfor {\n\t\t_, fieldType, fieldID, err := in.ReadFieldBegin()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif fieldType == thrift.STOP {\n\t\t\tif err := in.ReadFieldEnd(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\t// check required\n\t\t\t// void is nil struct\n\t\t\tif t.Struct != nil {\n\t\t\t\tif err := t.Struct.CheckRequired(readFields); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn st, in.ReadStructEnd()\n\t\t}\n\t\tfield, ok := t.Struct.FieldsByID[int32(fieldID)]\n\t\tif !ok {\n\t\t\t// just ignore the missing field, maybe server update its idls\n\t\t\tif err := in.Skip(fieldType); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\tnest := unnestPb(opt, field.ID)\n\t\t\t_fieldType := descriptor.FromThriftTType(fieldType)\n\t\t\treader, err := nextReader(_fieldType, field.Type, opt)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"nextReader of %s/%s/%d error %w\", t.Name, field.Name, fieldID, err)\n\t\t\t}\n\t\t\tval, err := reader(ctx, in, field.Type, opt)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"reader of %s/%s/%d error %w\", t.Name, field.Name, fieldID, err)\n\t\t\t}\n\t\t\tif field.ValueMapping != nil {\n\t\t\t\tif val, err = field.ValueMapping.Response(ctx, val, field); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\tnest()\n\n\t\t\tif err := fs(field, val); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif err := in.ReadFieldEnd(); err != nil {\n\t\t\treturn err\n\t\t}\n\t\treadFields[int32(fieldID)] = struct{}{}\n\t}\n}\n```"]}, "kitex-pkg/generic/descriptor/tree.go-addRoute": {"response": ["```go\nfunc (n *node) addRoute(path string, function *FunctionDescriptor) {\n\tcheckPathValid(path)\n\tn.insert(path, function, static, path, nil)\n}\n```"]}, "kitex-pkg/mem/span.go-NewSpanCache": {"response": ["```go\nfunc NewSpanCache(spanSize int) *spanCache {\n\tcache := &spanCache{}\n\tfor i := 0; i < spanCacheSize; i++ {\n\t\tsize := minSpanObject << i\n\t\tcache.spans[i] = NewSpan(size)\n\t}\n\treturn cache\n}\n```"]}, "kitex-pkg/profiler/profiler.go-Pause": {"response": ["```go\nfunc (p *profiler) Pause() {\n\tif p.State() == statePaused || p.State() == stateStopped {\n\t\treturn\n\t}\n\t// stateRunning => statePausing => statePaused\n\tp.stateChange(stateRunning, statePausing)\n\tp.stateWait(statePaused)\n}\n```"]}, "kitex-pkg/profiler/profiler.go-Resume": {"response": ["```go\nfunc (p *profiler) Resume() {\n\tif p.State() == stateStopped {\n\t\treturn\n\t}\n\t// statePaused => stateResuming\n\tp.stateChange(statePaused, stateResuming)\n\t// stateResuming => stateRunning\n\tp.stateChange(stateResuming, stateRunning)\n}\n```"]}, "kitex-pkg/acl/acl.go-NewACLMiddleware": {"response": ["```go\n// NewACLMiddleware creates a new ACL middleware using the provided reject funcs.\nfunc NewACLMiddleware(rules []RejectFunc) endpoint.Middleware {\n\treturn func(next endpoint.Endpoint) endpoint.Endpoint {\n\t\treturn func(ctx context.Context, request interface{}) (response interface{}, err error) {\n\t\t\tfor _, rule := range rules {\n\t\t\t\tif reason := rule(ctx, request); reason != nil {\n\t\t\t\t\treturn nil, kerrors.New(kerrors.ErrForbidden, reason.Error())\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn next(ctx, request)\n\t\t}\n\t}\n}\n```"]}, "kitex-client/context_middleware.go-WithContextMiddlewares": {"response": ["```go\nfunc WithContextMiddlewares(ctx context.Context, mws ...endpoint.Middleware) context.Context {\n\t// Combine the provided middlewares into a single middleware chain\n\tcombinedMW := endpoint.Chain(mws...)\n\n\t// Store the combined middleware in the context\n\treturn context.WithValue(ctx, ctxMWChainKey{}, combinedMW)\n}\n```"]}, "kitex-client/stream.go-RecvMsg": {"response": ["```go\nfunc (s *stream) RecvMsg(m interface{}) (err error) {\n\terr = s.recvEndpoint(s.stream, m)\n\tif err != nil {\n\t\ts.DoFinish(err)\n\t}\n\treturn err\n}\n```"]}, "kitex-client/stream.go-SendMsg": {"response": ["```go\nfunc (s *stream) SendMsg(m interface{}) (err error) {\n    defer func() {\n        if err != nil {\n            s.DoFinish(err)\n        }\n    }()\n    return s.sendEndpoint(s.stream, m)\n}\n```"]}, "kitex-client/stream.go-DoFinish": {"response": ["```go\nfunc (s *stream) DoFinish(err error) {\n\tif atomic.CompareAndSwapUint32(&s.finished, 0, 1) {\n\t\ts.kc.opt.TracerCtl.GetStreamEventHandler().Finish(s.stream, err)\n\t\ts.scm.Release(s.stream, err)\n\t}\n}\n```"]}, "kitex-client/client.go-NewClient": {"response": ["```go\nfunc NewClient(svcInfo *serviceinfo.ServiceInfo, opts ...Option) (Client, error) {\n\tif svcInfo == nil {\n\t\treturn nil, errors.New(\"NewClient: no service info\")\n\t}\n\tkc := &kClient{}\n\tkc.svcInfo = svcInfo\n\tkc.opt = client.NewOptions(opts)\n\tif err := kc.init(); err != nil {\n\t\t_ = kc.Close()\n\t\treturn nil, err\n\t}\n\treturn &kcFinalizerClient{kClient: kc}, nil\n}\n```"]}, "kitex-client/middlewares.go-newResolveMWBuilder": {"response": ["```go\nfunc newResolveMWBuilder(lbf *lbcache.BalancerFactory) endpoint.MiddlewareBuilder {\n\treturn func(ctx context.Context) endpoint.Middleware {\n\t\treturn func(next endpoint.Endpoint) endpoint.Endpoint {\n\t\t\treturn func(ctx context.Context, request, response interface{}) error {\n\t\t\t\tri := rpcinfo.GetRPCInfo(ctx)\n\t\t\t\tcfg := ri.Config()\n\t\t\t\ttimeout := cfg.RPCTimeout()\n\t\t\t\tif timeout <= 0 {\n\t\t\t\t\ttimeout = time.Second * 5 // default timeout\n\t\t\t\t}\n\n\t\t\t\tvar err error\n\t\t\t\tvar retryCount int\n\t\t\t\tfor {\n\t\t\t\t\tretryCount++\n\t\t\t\t\tif retryCount > maxRetry {\n\t\t\t\t\t\treturn fmt.Errorf(\"max retry count exceeded: %w\", err)\n\t\t\t\t\t}\n\n\t\t\t\t\tlb, err := lbf.Get(ctx, ri.To().ImmutableView())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"service discovery failed: %w\", err)\n\t\t\t\t\t}\n\n\t\t\t\t\tinst, err := lb.Pick(ctx)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tif retryable(err) {\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn fmt.Errorf(\"instance selection failed: %w\", err)\n\t\t\t\t\t}\n\n\t\t\t\t\trpcinfo.AsMutableEndpointInfo(ri.To()).SetAddress(inst.Address())\n\n\t\t\t\t\terr = next(ctx, request, response)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tif retryable(err) {\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn fmt.Errorf(\"rpc call failed: %w\", err)\n\t\t\t\t\t}\n\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n```"]}, "kitex-client/middlewares.go-DefaultClientErrorHandler": {"response": ["```go\nfunc DefaultClientErrorHandler(ctx context.Context, err error) error {\n\t// DefaultClientErrorHandler is Default ErrorHandler for client\n\t// when no ErrorHandler is specified with Option `client.WithErrorHandler`, this ErrorHandler will be injected.\n\t// for thrift\u3001KitexProtobuf, >= v0.4.0 wrap protocol error to TransError, which will be more friendly.\n\treturn err\n}\n```"]}, "kitex-client/middlewares.go-ClientErrorHandlerWithAddr": {"response": ["```go\nfunc ClientErrorHandlerWithAddr(ctx context.Context, err error) error {\n\t// ClientErrorHandlerWithAddr is ErrorHandler for client, which will add remote addr info into error\n\tremoteAddr := getRemoteAddr(ctx)\n\tif remoteAddr != \"\" {\n\t\treturn fmt.Errorf(\"remote addr: %s, error: %w\", remoteAddr, err)\n\t}\n\treturn err\n}\n```"]}, "kitex-client/option.go-WithInstanceMW": {"response": ["```go\nfunc WithInstanceMW(mw endpoint.Middleware) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithInstanceMW(%+v)\", utils.GetFuncName(mw)))\n\t\to.IMWBs = append(o.IMWBs, func(ctx context.Context) endpoint.Middleware {\n\t\t\treturn mw\n\t\t})\n\t}}\n}\n```"]}, "kitex-client/option.go-WithHostPorts": {"response": ["```go\nfunc WithHostPorts(hostports ...string) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithHostPorts(%+v)\", hostports))\n\n\t\tvar targets []string\n\t\tfor _, hp := range hostports {\n\t\t\tif _, _, err := net.SplitHostPort(hp); err != nil {\n\t\t\t\tpanic(fmt.Errorf(\"invalid hostport: %s\", hp))\n\t\t\t}\n\t\t\ttargets = append(targets, hp)\n\t\t}\n\t\to.Targets = targets\n\t}}\n}\n```"]}, "kitex-client/option.go-WithShortConnection": {"response": ["```go\n// WithShortConnection forces kitex to close connection after each call is finished.\nfunc WithShortConnection() Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(\"WithShortConnection()\")\n\n\t\to.RemoteOpt.DisableConnectionPool = true\n\t}}\n}\n```"]}, "kitex-client/option.go-WithLongConnection": {"response": ["```go\n// WithLongConnection enables long connection with kitex's built-in pooling implementation.\nfunc WithLongConnection(cfg connpool.IdleConfig) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithLongConnection(%+v)\", cfg))\n\t\to.RemoteOpt.ConnPool = connpool.NewLongPool(cfg)\n\t}}\n}\n```"]}, "kitex-client/option.go-WithMuxConnection": {"response": ["```go\n// WithMuxConnection specifies the transport type to be mux.\nfunc WithMuxConnection(connNum int) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithMuxConnection(%d)\", connNum))\n\n\t\to.RemoteOpt.ConnPool = netpollmux.NewMuxConnectionPool(connNum)\n\t\to.RemoteOpt.Dialer = netpollmux.NewMuxDialer()\n\t\to.RemoteOpt.CliHandlerFactory = grpc.NewCliTransHandlerFactory()\n\t}}\n}\n```"]}, "kitex-client/option.go-WithTimeoutProvider": {"response": ["```go\nfunc WithTimeoutProvider(p rpcinfo.TimeoutProvider) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithTimeoutProvider(%T)\", p))\n\t\to.Timeouts = p\n\t}}\n}\n```"]}, "kitex-client/option.go-WithCodec": {"response": ["```go\n// WithCodec to set a codec that handle other protocols which not support by kitex\nfunc WithCodec(c remote.Codec) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithCodec(%T)\", c))\n\t\to.RemoteOpt.Codec = c\n\t}}\n}\n```"]}, "kitex-client/option.go-WithPayloadCodec": {"response": ["```go\n// WithPayloadCodec to set a payloadCodec that handle other payload which not support by kitex\nfunc WithPayloadCodec(c remote.PayloadCodec) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithPayloadCodec(%T)\", c))\n\t\to.RemoteOpt.PayloadCodec = c\n\t}}\n}\n```"]}, "kitex-client/option.go-WithConnReporterEnabled": {"response": ["```go\nfunc WithConnReporterEnabled() Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(\"WithConnReporterEnabled()\")\n\t\to.RemoteOpt.EnableConnPoolReporter = true\n\t}}\n}\n```"]}, "kitex-client/option.go-WithFailureRetry": {"response": ["```go\n// WithFailureRetry sets the failure retry policy for client, it will take effect for all methods.\nfunc WithFailureRetry(p *retry.FailurePolicy) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithFailureRetry(%+v)\", p))\n\t\to.RetryContainer = retry.NewRetryContainerWithFailFast(o.Bus, o.Events)\n\t\to.RetryContainer.AddPolicy(retry.NewFailurePolicyWithResultRetry(p, o.RetryWithResult))\n\t}}\n}\n```"]}, "kitex-client/option.go-WithBackupRequest": {"response": ["```go\n// WithBackupRequest sets the backup request policy for client, it will take effect for all methods.\nfunc WithBackupRequest(p *retry.BackupPolicy) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithBackupRequest(%+v)\", p))\n\t\tif p == nil {\n\t\t\tpanic(\"invalid BackupPolicy: nil\")\n\t\t}\n\t\to.RetryContainer = retry.NewRetryContainerWithBackup(o.CBSuite, p)\n\t}}\n}\n```"]}, "kitex-client/option.go-WithSpecifiedResultRetry": {"response": ["```go\n// WithSpecifiedResultRetry is used with FailureRetry.\n// When you enable FailureRetry and want to retry with the specified error or response, you can configure this Option.\n// ShouldResultRetry is defined inside retry.FailurePolicy, so WithFailureRetry also can set ShouldResultRetry.\n// But if your retry policy is enabled by remote config, WithSpecifiedResultRetry is useful.\nfunc WithSpecifiedResultRetry(rr *retry.ShouldResultRetry) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithSpecifiedResultRetry(%+v)\", rr))\n\t\to.RetryWithResult = rr\n\t}}\n}\n```"]}, "kitex-client/option.go-WithGRPCInitialConnWindowSize": {"response": ["```go\nfunc WithGRPCInitialConnWindowSize(s uint32) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCInitialConnWindowSize(%d)\", s))\n\t\tif s < 64*1024 {\n\t\t\ts = 64 * 1024\n\t\t}\n\t\to.GRPCConnectOpts.InitialConnWindowSize = s\n\t}}\n}\n```"]}, "kitex-client/option.go-WithGRPCMaxHeaderListSize": {"response": ["```go\nfunc WithGRPCMaxHeaderListSize(s uint32) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCMaxHeaderListSize(%d)\", s))\n\t\to.GRPCConnectOpts.MaxHeaderListSize = s\n\t}}\n}\n```"]}, "kitex-client/option.go-WithGRPCKeepaliveParams": {"response": ["```go\nfunc WithGRPCKeepaliveParams(kp grpc.ClientKeepalive) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithGRPCKeepaliveParams(%+v)\", kp))\n\t\to.GRPCConnectOpts.KeepaliveParams = kp\n\t}}\n}\n```"]}, "kitex-client/option.go-WithWarmingUp": {"response": ["```go\nfunc WithWarmingUp(wuo *warmup.ClientOption) Option {\n\treturn Option{F: func(o *client.Options, di *utils.Slice) {\n\t\tdi.Push(fmt.Sprintf(\"WithWarmingUp(%+v)\", wuo))\n\t\to.WarmUpOption = wuo\n\t}}\n}\n```"]}, "kitex-client/callopt/options.go-WithHostPort": {"response": ["```go\n// WithHostPort specifies the target address for a RPC call.\n// The given address will overwrite the result from Resolver.\nfunc WithHostPort(hostport string) Option {\n\treturn Option{func(o *CallOptions, di *strings.Builder) {\n\t\tif err := setInstance(o.svr, hostport); err != nil {\n\t\t\tdi.WriteString(fmt.Sprintf(\"WithHostPort(%s) failed: %s\", hostport, err.Error()))\n\t\t} else {\n\t\t\tdi.WriteString(fmt.Sprintf(\"WithHostPort(%s)\", hostport))\n\t\t}\n\t}}\n}\n```"]}, "kitex-client/callopt/options.go-WithURL": {"response": ["```go\nfunc WithURL(url string) Option {\n\treturn Option{func(o *CallOptions, di *strings.Builder) {\n\t\thostport, err := net.ResolveTCPAddr(\"tcp\", url)\n\t\tif err != nil {\n\t\t\thostport, err = net.ResolveUnixAddr(\"unix\", url)\n\t\t\tif err != nil {\n\t\t\t\tdi.WriteString(fmt.Sprintf(\"InvalidURL(%s)\", url))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t\tdi.WriteString(fmt.Sprintf(\"WithURL(%s)\", url))\n\t\to.svr.SetInstance(discovery.NewInstance(hostport.Network(), hostport.String(), discovery.DefaultWeight, nil))\n\t}}\n}\n```"]}, "kitex-client/callopt/options.go-WithRPCTimeout": {"response": ["```go\n// WithRPCTimeout specifies the RPC timeout for a RPC call.\n// FIXME: callopt.WithRPCTimeout works only when client.WithRPCTimeout or\n// client.WithTimeoutProvider is specified.\nfunc WithRPCTimeout(d time.Duration) Option {\n\treturn Option{f: func(o *CallOptions, di *strings.Builder) {\n\t\tdi.WriteString(\"WithRPCTimeout\")\n\t\tdi.WriteByte('(')\n\t\tdi.WriteString(d.String())\n\t\tdi.WriteByte(')')\n\t\to.configs.SetRPCTimeout(d)\n\t}}\n}\n```"]}, "kitex-client/callopt/options.go-WithConnectTimeout": {"response": ["```go\n// WithConnectTimeout specifies the connection timeout for a RPC call.\nfunc WithConnectTimeout(d time.Duration) Option {\n\treturn Option{func(o *CallOptions, di *strings.Builder) {\n\t\to.configs.SetConnectTimeout(d)\n\t\tdi.WriteString(\"WithConnectTimeout(\")\n\t\tdi.WriteString(d.String())\n\t\tdi.WriteByte(')')\n\t}}\n}\n```"]}, "kitex-client/callopt/options.go-WithFallback": {"response": ["```go\n// WithFallback is used to set the fallback policy for a RPC call.\n// Demos are provided below:\n//\n//\tdemo1. call with fallback for error\n//\t\t`resp, err := cli.Mock(ctx, req, callopt.WithFallback(fallback.ErrorFallback(yourFBFunc))`\n//\tdemo2. call with fallback for error and enable reportAsFallback, which sets reportAsFallback to be true and will do report(metric) as Fallback result\n//\t\t`resp, err := cli.Mock(ctx, req, callopt.WithFallback(fallback.ErrorFallback(yourFBFunc).EnableReportAsFallback())`\nfunc WithFallback(fb *fallback.Policy) Option {\n\treturn Option{f: func(o *CallOptions, di *strings.Builder) {\n\t\tif fb == nil {\n\t\t\treturn\n\t\t}\n\t\tdi.WriteString(\"WithFallback\")\n\t\to.Fallback = fb\n\t}}\n}\n```"]}, "kitex-server/option_advanced.go-WithServerBasicInfo": {"response": ["```go\nfunc WithServerBasicInfo(ebi *rpcinfo.EndpointBasicInfo) Option {\n\treturn func(o *options) {\n\t\to.serverBasicInfo = ebi\n\t}\n}\n```"]}, "kitex-server/option_advanced.go-WithSupportedTransportsFunc": {"response": ["```go\nfunc WithSupportedTransportsFunc(f func(option remote.ServerOption) []string) Option {\n\treturn func(o *options) {\n\t\to.supportedTransportsFunc = f\n\t}\n}\n```"]}, "kitex-server/option.go-WithMiddleware": {"response": ["```go\nfunc WithMiddleware(mw endpoint.Middleware) Option {\n\treturn func(s *Server) {\n\t\ts.mw = append(s.mw, mw)\n\t}\n}\n```"]}, "kitex-server/option.go-WithMiddlewareBuilder": {"response": ["```go\nfunc WithMiddlewareBuilder(mwb endpoint.MiddlewareBuilder, funcName ...string) Option {\n\treturn func(s *Server) error {\n\t\t// Apply the middleware builder to the specified functions\n\t\tfor _, fn := range funcName {\n\t\t\tswitch fn {\n\t\t\tcase \"GenerateHandler\":\n\t\t\t\ts.GenerateHandler = mwb(s.GenerateHandler)\n\t\t\tcase \"EmbeddingsHandler\":\n\t\t\t\ts.EmbeddingsHandler = mwb(s.EmbeddingsHandler)\n\t\t\tcase \"PullModelHandler\":\n\t\t\t\ts.PullModelHandler = mwb(s.PullModelHandler)\n\t\t\tcase \"PushModelHandler\":\n\t\t\t\ts.PushModelHandler = mwb(s.PushModelHandler)\n\t\t\tcase \"CreateModelHandler\":\n\t\t\t\ts.CreateModelHandler = mwb(s.CreateModelHandler)\n\t\t\tcase \"DeleteModelHandler\":\n\t\t\t\ts.DeleteModelHandler = mwb(s.DeleteModelHandler)\n\t\t\tcase \"ShowModelHandler\":\n\t\t\t\ts.ShowModelHandler = mwb(s.ShowModelHandler)\n\t\t\tcase \"ListModelsHandler\":\n\t\t\t\ts.ListModelsHandler = mwb(s.ListModelsHandler)\n\t\t\tcase \"CopyModelHandler\":\n\t\t\t\ts.CopyModelHandler = mwb(s.CopyModelHandler)\n\t\t\tcase \"HeadBlobHandler\":\n\t\t\t\ts.HeadBlobHandler = mwb(s.HeadBlobHandler)\n\t\t\tcase \"CreateBlobHandler\":\n\t\t\t\ts.CreateBlobHandler = mwb(s.CreateBlobHandler)\n\t\t\tcase \"ProcessHandler\":\n\t\t\t\ts.ProcessHandler = mwb(s.ProcessHandler)\n\t\t\tcase \"ChatHandler\":\n\t\t\t\ts.ChatHandler = mwb(s.ChatHandler)\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"unknown function name: %s\", fn)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}\n```"]}, "kitex-server/option.go-WithExitWaitTime": {"response": ["```go\nfunc WithExitWaitTime(timeout time.Duration) Option {\n\treturn func(s *Server) {\n\t\ts.exitWaitTime = timeout\n\t}\n}\n```"]}, "kitex-server/option.go-WithMaxConnIdleTime": {"response": ["```go\nfunc WithMaxConnIdleTime(timeout time.Duration) Option {\n\treturn func(s *Server) {\n\t\ts.maxConnIdleTime = timeout\n\t}\n}\n```"]}, "kitex-server/option.go-WithPayloadCodec": {"response": ["```go\nfunc WithPayloadCodec(c remote.PayloadCodec) Option {\n\treturn func(o *options) {\n\t\to.payloadCodec = c\n\t}\n}\n```"]}, "kitex-server/option.go-WithGRPCInitialWindowSize": {"response": ["```go\nfunc WithGRPCInitialWindowSize(s uint32) Option {\n\treturn func(opts *Options) {\n\t\tif s < 64*1024 {\n\t\t\ts = 64 * 1024\n\t\t}\n\t\topts.InitialWindowSize = s\n\t}\n}\n```"]}, "kitex-server/option.go-WithGRPCInitialConnWindowSize": {"response": ["```go\nfunc WithGRPCInitialConnWindowSize(s uint32) Option {\n\treturn func(o *options) {\n\t\tif s < 64*1024 {\n\t\t\ts = 64 * 1024\n\t\t}\n\t\to.grpcInitialConnWindowSize = int32(s)\n\t}\n}\n```"]}, "kitex-server/option.go-WithGRPCKeepaliveParams": {"response": ["```go\nfunc WithGRPCKeepaliveParams(kp grpc.ServerKeepalive) Option {\n\treturn func(s *Server) {\n\t\ts.grpcKeepalive = kp\n\t}\n}\n```"]}, "kitex-server/option.go-WithGRPCKeepaliveEnforcementPolicy": {"response": ["```go\nfunc WithGRPCKeepaliveEnforcementPolicy(kep grpc.EnforcementPolicy) Option {\n\treturn func(s *Server) {\n\t\ts.grpcKeepaliveEnforcementPolicy = kep\n\t}\n}\n```"]}, "kitex-server/option.go-WithGRPCMaxConcurrentStreams": {"response": ["```go\nfunc WithGRPCMaxConcurrentStreams(n uint32) Option {\n\treturn func(s *Server) {\n\t\ts.grpcMaxConcurrentStreams = n\n\t}\n}\n```"]}, "kitex-server/option.go-WithGRPCMaxHeaderListSize": {"response": ["```go\nfunc WithGRPCMaxHeaderListSize(s uint32) Option {\n\treturn func(opts *serverOptions) {\n\t\topts.grpcMaxHeaderListSize = s\n\t}\n}\n```"]}, "kitex-server/genericserver/server.go-NewServerWithServiceInfo": {"response": ["```go\n// NewServerWithServiceInfo creates a generic server with the given handler, serviceInfo and options.\nfunc NewServerWithServiceInfo(handler generic.Service, g generic.Generic, svcInfo *serviceinfo.ServiceInfo, opts ...server.Option) server.Server {\n\t// Create a new server instance with the provided handler, generic type, service info, and options\n\tsvr := server.NewServer(svcInfo, handler, opts...)\n\n\t// Additional logic can be added here if needed\n\n\treturn svr\n}\n```"]}, "weaver-validate.go-validateRegistrations": {"response": ["```go\nfunc validateRegistrations(regs []*codegen.Registration) error {\n\t// Check for duplicate component names.\n\tnames := make(map[string]bool)\n\tfor _, reg := range regs {\n\t\tname := reg.Name\n\t\tif names[name] {\n\t\t\treturn fmt.Errorf(\"duplicate component name: %q\", name)\n\t\t}\n\t\tnames[name] = true\n\t}\n\n\t// Check for valid listener names.\n\tfor _, reg := range regs {\n\t\tif reg.Name == \"github.com/ServiceWeaver/weaver/Listener\" {\n\t\t\treturn fmt.Errorf(\"invalid component name: %q\", reg.Name)\n\t\t}\n\t}\n\n\t// Check for valid component interface types.\n\tfor _, reg := range regs {\n\t\tiface := reg.Iface\n\t\tif iface.Kind() != reflect.Interface {\n\t\t\treturn fmt.Errorf(\"component %q is not an interface\", reg.Name)\n\t\t}\n\t}\n\n\t// Check for valid component implementation types.\n\tfor _, reg := range regs {\n\t\timpl := reg.Impl\n\t\tif impl.Kind() != reflect.Struct {\n\t\t\treturn fmt.Errorf(\"implementation of component %q is not a struct\", reg.Name)\n\t\t}\n\t}\n\n\t// Check for valid component method signatures.\n\tfor _, reg := range regs {\n\t\tiface := reg.Iface\n\t\tfor i := 0; i < iface.NumMethod(); i++ {\n\t\t\tmethod := iface.Method(i)\n\t\t\tmethodType := method.Type\n\t\t\tif methodType.NumIn() != 2 {\n\t\t\t\treturn fmt.Errorf(\"method %q of component %q has an invalid number of input parameters\", method.Name, reg.Name)\n\t\t\t}\n\t\t\tif methodType.In(0) != reflect.TypeOf((*context.Context)(nil)).Elem() {\n\t\t\t\treturn fmt.Errorf(\"first parameter of method %q of component %q is not of type context.Context\", method.Name, reg.Name)\n\t\t\t}\n\t\t\tif methodType.NumOut() != 2 {\n\t\t\t\treturn fmt.Errorf(\"method %q of component %q has an invalid number of return values\", method.Name, reg.Name)\n\t\t\t}\n\t\t\tif methodType.Out(1) != reflect.TypeOf((*error)(nil)).Elem() {\n\t\t\t\treturn fmt.Errorf(\"second return value of method %q of component %q is not of type error\", method.Name, reg.Name)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n```"]}, "weaver-sim/generators.go-Range": {"response": ["```go\n// Range returns a [Generator] that returns integers equiprobably in the range\n// [low, high). Range panics if low >= high.\nfunc Range(low, high int) Generator[int] {\n\tif low >= high {\n\t\tpanic(fmt.Errorf(\"Range: low (%d) >= high (%d)\", low, high))\n\t}\n\treturn generatorFunc[int](func(r *rand.Rand) int {\n\t\treturn low + r.Intn(high-low)\n\t})\n}\n```"]}, "weaver-sim/generators.go-String": {"response": ["```go\n// Strings\n\n// String returns a [Generator] that returns moderately sized readable strings,\n// with a bias towards smaller strings.\nfunc String() Generator[string] {\n\tconst (\n\t\tminLength = 1\n\t\tmaxLength = 20\n\t)\n\n\t// Define a set of readable characters.\n\treadableChars := []rune(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 \")\n\n\treturn generatorFunc[string](func(r *rand.Rand) string {\n\t\t// Generate a random length for the string.\n\t\tlength := r.Intn(maxLength-minLength+1) + minLength\n\n\t\t// Generate the string with the chosen length.\n\t\tvar sb strings.Builder\n\t\tfor i := 0; i < length; i++ {\n\t\t\tsb.WriteRune(readableChars[r.Intn(len(readableChars))])\n\t\t}\n\t\treturn sb.String()\n\t})\n}\n```"]}, "weaver-sim/generators.go-OneOf": {"response": ["```go\n// Combinators\n// OneOf returns a [Generator] that returns one of the provided values\n// equiprobably. OneOf panics if no values are provided.\nfunc OneOf[T any](xs ...T) Generator[T] {\n\tif len(xs) == 0 {\n\t\tpanic(fmt.Errorf(\"OneOf: no values provided\"))\n\t}\n\treturn generatorFunc[T](func(r *rand.Rand) T {\n\t\treturn xs[r.Intn(len(xs))]\n\t})\n}\n```"]}, "weaver-sim/generators.go-Weight": {"response": ["```go\nfunc Weight[T any](choices []Weighted[T]) Generator[T] {\n\tif len(choices) == 0 {\n\t\tpanic(fmt.Errorf(\"Weight: no choices provided\"))\n\t}\n\n\tvar totalWeight float64\n\tfor _, choice := range choices {\n\t\tif choice.Weight < 0 {\n\t\t\tpanic(fmt.Errorf(\"Weight: negative weight %f\", choice.Weight))\n\t\t}\n\t\ttotalWeight += choice.Weight\n\t}\n\n\tif totalWeight == 0 {\n\t\tpanic(fmt.Errorf(\"Weight: sum of all weights is 0\"))\n\t}\n\n\treturn generatorFunc[T](func(r *rand.Rand) T {\n\t\tp := r.Float64() * totalWeight\n\t\tfor _, choice := range choices {\n\t\t\tif p < choice.Weight {\n\t\t\t\treturn choice.Gen.Generate(r)\n\t\t\t}\n\t\t\tp -= choice.Weight\n\t\t}\n\t\t// This should never happen due to the totalWeight check above.\n\t\tpanic(fmt.Errorf(\"Weight: internal error\"))\n\t})\n}\n```"]}, "weaver-sim/rand.go-pick": {"response": ["```go\nfunc pick[T any](r *rand.Rand, xs []T) T {\n\tif len(xs) == 0 {\n\t\tpanic(fmt.Errorf(\"pick: empty slice\"))\n\t}\n\ti := r.Intn(len(xs))\n\treturn xs[i]\n}\n```"]}, "weaver-sim/rand.go-remove": {"response": ["```go\nfunc (i *ints) remove(x int) {\n\tif i.low <= x && x < i.high && i.indices[x-i.low] != -1 {\n\t\tindex := i.indices[x-i.low]\n\t\tlast := i.elements[len(i.elements)-1]\n\t\ti.elements[index] = last\n\t\ti.indices[last-i.low] = index\n\t\ti.indices[x-i.low] = -1\n\t\ti.elements = i.elements[:len(i.elements)-1]\n\t}\n}\n```"]}, "weaver-runtime/config.go-ParseConfig": {"response": ["```go\n// ParseConfig parses the specified configuration input, which should\n// hold a set of sections in TOML format from the specified file.\n// The section corresponding to the common Service Weaver application\n// configuration is parsed and returned as a *AppConfig.\n//\n// sectionValidator(key, val) is used to validate every section config entry.\nfunc ParseConfig(file string, input string, sectionValidator func(string, string) error) (*protos.AppConfig, error) {\n\t// Parse the input into sections.\n\tsections := make(map[string]string)\n\tif _, err := toml.Decode(input, &sections); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse TOML input: %w\", err)\n\t}\n\n\t// Validate each section using the provided validator.\n\tfor key, val := range sections {\n\t\tif err := sectionValidator(key, val); err != nil {\n\t\t\treturn nil, fmt.Errorf(\"validation failed for section %q: %w\", key, err)\n\t\t}\n\t}\n\n\t// Extract the application configuration.\n\tconfig := &protos.AppConfig{\n\t\tSections: sections,\n\t}\n\tif err := extractApp(file, config); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to extract application configuration: %w\", err)\n\t}\n\n\treturn config, nil\n}\n```"]}, "weaver-runtime/traces/db.go-OpenDB": {"response": ["```go\n// OpenDB opens the trace database persisted in the provided file. If the\n// file doesn't exist, this call creates it.\nfunc OpenDB(ctx context.Context, fname string) (*DB, error) {\n\t// Ensure the directory exists.\n\tdir := filepath.Dir(fname)\n\tif err := os.MkdirAll(dir, 0755); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create directory %s: %w\", dir, err)\n\t}\n\n\t// Open the SQLite database.\n\tdb, err := sql.Open(\"sqlite\", fname)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to open database %s: %w\", fname, err)\n\t}\n\n\t// Create the necessary tables if they don't exist.\n\tconst createTracesTable = `\n\tCREATE TABLE IF NOT EXISTS traces (\n\t\ttrace_id TEXT PRIMARY KEY,\n\t\tapp TEXT,\n\t\tversion TEXT,\n\t\tname TEXT,\n\t\tstart_micros INTEGER,\n\t\tend_micros INTEGER,\n\t\tstatus TEXT\n\t)`\n\tconst createEncodedSpansTable = `\n\tCREATE TABLE IF NOT EXISTS encoded_spans (\n\t\ttrace_id TEXT,\n\t\tstart_micros INTEGER,\n\t\tdata BLOB,\n\t\tPRIMARY KEY (trace_id, start_micros)\n\t)`\n\n\tif _, err := db.ExecContext(ctx, createTracesTable); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create traces table: %w\", err)\n\t}\n\tif _, err := db.ExecContext(ctx, createEncodedSpansTable); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create encoded_spans table: %w\", err)\n\t}\n\n\treturn &DB{fname: fname, db: db}, nil\n}\n```"]}, "weaver-runtime/traces/db.go-QueryTraces": {"response": ["```go\nfunc (d *DB) QueryTraces(ctx context.Context, app, version string, startTime, endTime time.Time, durationLower, durationUpper time.Duration, onlyErrors bool, limit int64) ([]TraceSummary, error) {\n\t// Construct the base query\n\tquery := `SELECT trace_id, start_time, end_time, status FROM traces WHERE 1=1`\n\tvar args []interface{}\n\n\t// Add conditions based on the provided arguments\n\tif app != \"\" {\n\t\tquery += ` AND app = ?`\n\t\targs = append(args, app)\n\t}\n\tif version != \"\" {\n\t\tquery += ` AND version = ?`\n\t\targs = append(args, version)\n\t}\n\tif !startTime.IsZero() {\n\t\tquery += ` AND start_time >= ?`\n\t\targs = append(args, startTime.UnixMicro())\n\t}\n\tif !endTime.IsZero() {\n\t\tquery += ` AND end_time <= ?`\n\t\targs = append(args, endTime.UnixMicro())\n\t}\n\tif durationLower > 0 {\n\t\tquery += ` AND (end_time - start_time) >= ?`\n\t\targs = append(args, durationLower.Microseconds())\n\t}\n\tif durationUpper > 0 {\n\t\tquery += ` AND (end_time - start_time) < ?`\n\t\targs = append(args, durationUpper.Microseconds())\n\t}\n\tif onlyErrors {\n\t\tquery += ` AND status != ''`\n\t}\n\n\t// Add ordering and limit\n\tquery += ` ORDER BY start_time DESC`\n\tif limit > 0 {\n\t\tquery += ` LIMIT ?`\n\t\targs = append(args, limit)\n\t}\n\n\t// Execute the query\n\trows, err := d.queryDB(ctx, query, args...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer rows.Close()\n\n\tvar summaries []TraceSummary\n\tfor rows.Next() {\n\t\tvar traceID string\n\t\tvar startMicros, endMicros int64\n\t\tvar status string\n\t\tif err := rows.Scan(&traceID, &startMicros, &endMicros, &status); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tsummaries = append(summaries, TraceSummary{\n\t\t\tTraceID:   traceID,\n\t\t\tStartTime: time.UnixMicro(startMicros),\n\t\t\tEndTime:   time.UnixMicro(endMicros),\n\t\t\tStatus:    status,\n\t\t})\n\t}\n\tif err := rows.Err(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn summaries, nil\n}\n```"]}, "weaver-runtime/retry/retry.go-Continue": {"response": ["```go\nfunc (r *Retry) Continue(ctx context.Context) bool {\n\t// If this is the first attempt, do not sleep.\n\tif r.attempt == 0 {\n\t\tr.attempt++\n\t\treturn true\n\t}\n\n\t// Calculate the backoff delay for the current attempt.\n\tdelay := backoffDelay(r.attempt, r.options)\n\n\t// Apply jitter to the delay.\n\trandomized(ctx, delay)\n\n\t// Check if the context is done.\n\tif ctx.Err() != nil {\n\t\treturn false\n\t}\n\n\t// Increment the attempt counter.\n\tr.attempt++\n\treturn true\n}\n```"]}, "weaver-runtime/colors/tabularizer.go-Row": {"response": ["```go\nfunc (t *Tabularizer) Row(values ...any) {\n\t// Convert all values to Text type\n\tvar row []Text\n\tfor _, value := range values {\n\t\tswitch v := value.(type) {\n\t\tcase Text:\n\t\t\trow = append(row, v)\n\t\tcase Atom:\n\t\t\trow = append(row, Text{v})\n\t\tcase string:\n\t\t\trow = append(row, Text{Atom{S: v}})\n\t\tcase fmt.Stringer:\n\t\t\trow = append(row, Text{Atom{S: v.String()}})\n\t\tdefault:\n\t\t\trow = append(row, Text{Atom{S: fmt.Sprintf(\"%v\", v)}})\n\t\t}\n\t}\n\n\t// Ensure all rows have the same length\n\tif len(t.rows) > 0 && len(row) != len(t.rows[0]) {\n\t\tpanic(\"all rows must have the same length\")\n\t}\n\n\t// Update column widths\n\tif len(t.widths) == 0 {\n\t\tt.widths = make([]int, len(row))\n\t}\n\tfor i, cell := range row {\n\t\tif cellLen := cell.len(); cellLen > t.widths[i] {\n\t\t\tt.widths[i] = cellLen\n\t\t}\n\t}\n\n\t// Buffer the row\n\tt.rows = append(t.rows, row)\n}\n```"]}, "weaver-runtime/colors/tabularizer.go-Flush": {"response": ["```go\nfunc (t *Tabularizer) Flush() {\n\t// Calculate the maximum width for each column\n\tfor _, row := range t.rows {\n\t\tfor i, cell := range row {\n\t\t\tif i >= len(t.widths) {\n\t\t\t\tt.widths = append(t.widths, 0)\n\t\t\t}\n\t\t\tcellLen := cell.len()\n\t\t\tif cellLen > t.widths[i] {\n\t\t\t\tt.widths[i] = cellLen\n\t\t\t}\n\t\t}\n\t}\n\n\t// Write the table title\n\tif len(t.title) > 0 {\n\t\ttitleLen := 0\n\t\tfor _, text := range t.title {\n\t\t\ttitleLen += text.len()\n\t\t}\n\t\tt.writeLine('\u256d', '\u2500', '\u256e', titleLen+2)\n\t\tfor _, text := range t.title {\n\t\t\tfmt.Fprint(t.w, \"\u2502 \")\n\t\t\tfmt.Fprint(t.w, text.String())\n\t\t}\n\t\tfmt.Fprintln(t.w, \" \u2502\")\n\t\tt.writeLine('\u251c', '\u2500', '\u2524', titleLen+2)\n\t}\n\n\t// Write the table rows\n\tfor i, row := range t.rows {\n\t\tdimmed := t.dim(nil, nil) // Assuming dim function is correctly implemented\n\t\tfor j, cell := range row {\n\t\t\tif dimmed[j] {\n\t\t\t\tcell = cell.dimmed()\n\t\t\t}\n\t\t\tfmt.Fprint(t.w, \"\u2502 \")\n\t\t\tfmt.Fprint(t.w, cell.String())\n\t\t\tfmt.Fprint(t.w, strings.Repeat(\" \", t.widths[j]-cell.len()))\n\t\t}\n\t\tfmt.Fprintln(t.w, \"\u2502\")\n\t\tif i < len(t.rows)-1 {\n\t\t\tt.writeLine('\u251c', '\u2500', '\u253c', 0)\n\t\t}\n\t}\n\n\t// Write the table footer\n\tt.writeLine('\u2570', '\u2500', '\u256f', 0)\n}\n\nfunc (t *Tabularizer) writeLine(left, mid, right rune, extra int) {\n\tfmt.Fprint(t.w, string(left))\n\tfor i, width := range t.widths {\n\t\tfmt.Fprint(t.w, strings.Repeat(string(mid), width+2))\n\t\tif i < len(t.widths)-1 {\n\t\t\tfmt.Fprint(t.w, string(mid))\n\t\t}\n\t}\n\tfmt.Fprint(t.w, strings.Repeat(string(mid), extra))\n\tfmt.Fprintln(t.w, string(right))\n}\n```"]}, "weaver-runtime/protomsg/io.go-Write": {"response": ["```go\n// Write writes a length prefixed protobuf to dst. Use Read to read it.\nfunc Write(dst io.Writer, msg proto.Message) error {\n\tdata, err := proto.Marshal(msg)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"marshal protobuf: %w\", err)\n\t}\n\n\t// Write the length of the message as a 4-byte little-endian integer.\n\tvar hdr [4]byte\n\tbinary.LittleEndian.PutUint32(hdr[:], uint32(len(data)))\n\tif _, err := dst.Write(hdr[:]); err != nil {\n\t\treturn fmt.Errorf(\"write protobuf length: %w\", err)\n\t}\n\n\t// Write the message data.\n\tif _, err := dst.Write(data); err != nil {\n\t\treturn fmt.Errorf(\"write protobuf data: %w\", err)\n\t}\n\n\treturn nil\n}\n```"]}, "weaver-runtime/bin/bin.go-ReadComponentGraph": {"response": ["```go\n// ReadComponentGraph reads component graph information from the specified\n// binary. It returns a slice of components and a component graph whose nodes\n// are indices into that slice.\nfunc ReadComponentGraph(file string) ([]string, graph.Graph, error) {\n\t// Read the read-only data section of the binary.\n\trodataSection, err := rodata(file)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to read rodata section: %w\", err)\n\t}\n\n\t// Extract the component graph from the read-only data section.\n\tcomponents, componentGraph, err := codegen.ExtractComponentGraph(rodataSection)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"failed to extract component graph: %w\", err)\n\t}\n\n\treturn components, componentGraph, nil\n}\n```"]}, "weaver-runtime/bin/bin.go-ReadListeners": {"response": ["```go\n// ReadListeners reads the sets of listeners associated with each component\n// in the specified binary.\nfunc ReadListeners(file string) ([]codegen.ComponentListeners, error) {\n\t// Read the read-only data section of the binary.\n\trodataSection, err := rodata(file)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to read rodata section: %w\", err)\n\t}\n\n\t// Extract the component graph information from the binary.\n\tcomponents, _, err := codegen.ExtractComponentGraph(rodataSection)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to extract component graph: %w\", err)\n\t}\n\n\t// Extract the listeners for each component.\n\tlisteners := make([]codegen.ComponentListeners, len(components))\n\tfor i, component := range components {\n\t\tlisteners[i], err = codegen.ExtractComponentListeners(rodataSection, component)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to extract listeners for component %s: %w\", component.Name, err)\n\t\t}\n\t}\n\n\treturn listeners, nil\n}\n```"]}, "weaver-runtime/bin/bin.go-ReadVersions": {"response": ["```go\n// ReadVersions reads the module version and deployer API version from the\n// specified binary.\nfunc ReadVersions(filename string) (Versions, error) {\n\t// Extract the read-only data section from the binary.\n\trodataSection, err := rodata(filename)\n\tif err != nil {\n\t\treturn Versions{}, fmt.Errorf(\"failed to read read-only data section: %w\", err)\n\t}\n\n\t// Extract the module version from the binary.\n\tmoduleVersion, err := extractModuleVersion(filename)\n\tif err != nil {\n\t\treturn Versions{}, fmt.Errorf(\"failed to extract module version: %w\", err)\n\t}\n\n\t// Extract the deployer API version from the read-only data section.\n\tdeployerVersion, err := extractDeployerVersion(rodataSection)\n\tif err != nil {\n\t\treturn Versions{}, fmt.Errorf(\"failed to extract deployer version: %w\", err)\n\t}\n\n\t// Return the versions.\n\treturn Versions{\n\t\tModuleVersion:   moduleVersion,\n\t\tDeployerVersion: deployerVersion,\n\t}, nil\n}\n```"]}, "weaver-runtime/prometheus/prometheus.go-TranslateMetricsToPrometheusTextFormat": {"response": ["```go\nfunc TranslateMetricsToPrometheusTextFormat(w *bytes.Buffer, ms []*metrics.MetricSnapshot, lisAddr, path string) {\n\t// Write the helper configuration for Prometheus.\n\twriteHelper(w, lisAddr, path)\n\n\t// Translate the metrics to Prometheus text format.\n\ttranslateMetrics(w, ms)\n}\n```"]}, "weaver-runtime/codegen/graph.go-ExtractEdges": {"response": ["```go\npackage codegen\n\nimport (\n\t\"regexp\"\n\t\"sort\"\n)\n\n// ExtractEdges returns the edges corresponding to MakeEdgeString() results\n// that occur in data.\nfunc ExtractEdges(data []byte) [][2]string {\n\t// Define the regular expression pattern to match the edge strings.\n\tedgePattern := regexp.MustCompile(`\u27e6[0-9a-f]{8}:wEaVeReDgE:([^\\s\u2192]+)\u2192([^\\s\u2192]+)\u27e7`)\n\n\t// Find all matches in the data.\n\tmatches := edgePattern.FindAllSubmatch(data, -1)\n\n\t// Extract the source and destination components from the matches.\n\tvar edges [][2]string\n\tfor _, match := range matches {\n\t\tsrc := string(match[1])\n\t\tdst := string(match[2])\n\t\tedges = append(edges, [2]string{src, dst})\n\t}\n\n\t// Sort the edges to ensure deterministic output.\n\tsort.Slice(edges, func(i, j int) bool {\n\t\tif edges[i][0] == edges[j][0] {\n\t\t\treturn edges[i][1] < edges[j][1]\n\t\t}\n\t\treturn edges[i][0] < edges[j][0]\n\t})\n\n\treturn edges\n}\n```"]}, "weaver-runtime/codegen/registry.go-ComponentConfigValidator": {"response": ["```go\n// ComponentConfigValidator checks that cfg is a valid configuration\n// for the component type whose fully qualified name is given by path.\n//\n// TODO(mwhittaker): Move out of codegen package? It's not used by the\n// generated code.\nfunc ComponentConfigValidator(path, cfg string) error {\n\t// Implementation of the validation logic goes here.\n\t// This function should check if the provided configuration 'cfg' is valid\n\t// for the component type specified by 'path'.\n\t// For example, it could parse the configuration, validate its fields,\n\t// and return an error if any validation fails.\n\n\t// Placeholder implementation:\n\t// For now, we just return nil, indicating that the configuration is always valid.\n\t// Replace this with actual validation logic as needed.\n\treturn nil\n}\n```"]}, "weaver-runtime/codegen/registry.go-CallGraph": {"response": ["```go\n// CallGraph returns the component call graph (as a list of CallEdge values).\nfunc CallGraph() []CallEdge {\n\tvar callGraph []CallEdge\n\n\t// Iterate over all registered components\n\tfor _, callerReg := range globalRegistry.allComponents() {\n\t\tcallerType := callerReg.Iface\n\n\t\t// Iterate over all components again to find callees\n\t\tfor _, calleeReg := range globalRegistry.allComponents() {\n\t\t\tcalleeType := calleeReg.Iface\n\n\t\t\t// Check if the caller uses the callee\n\t\t\tif callerUsesCallee(callerReg, calleeReg) {\n\t\t\t\tcallGraph = append(callGraph, CallEdge{\n\t\t\t\t\tCaller: callerType,\n\t\t\t\t\tCallee: calleeType,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn callGraph\n}\n\n// Helper function to determine if a caller uses a callee\nfunc callerUsesCallee(callerReg, calleeReg *Registration) bool {\n\t// Extract the reference data from the caller's registration\n\trefData := callerReg.RefData\n\n\t// Create the expected edge string for the callee\n\texpectedEdge := MakeEdgeString(callerReg.Name, calleeReg.Name)\n\n\t// Check if the expected edge is present in the reference data\n\treturn strings.Contains(refData, expectedEdge)\n}\n```"]}, "weaver-runtime/codegen/listeners.go-MakeListenersString": {"response": ["```go\nfunc MakeListenersString(component string, listeners []string) string {\n\t// Join the listeners into a comma-separated string.\n\tlisstr := strings.Join(listeners, \",\")\n\n\t// Calculate the checksum of the string \"wEaVeRlIsTeNeRs:component\u2192listeners\".\n\tchecksum := checksumListeners(component, lisstr)\n\n\t// Format the string as specified.\n\treturn fmt.Sprintf(\"\u27e6%s:wEaVeRlIsTeNeRs:%s\u2192%s\u27e7\\n\", checksum, component, lisstr)\n}\n```"]}, "weaver-runtime/codegen/listeners.go-ExtractListeners": {"response": ["```go\n// ExtractListeners returns the components and their listeners encoded using\n// MakeListenersString() in data.\nfunc ExtractListeners(data []byte) []ComponentListeners {\n\t// Define the regular expression pattern to match the listener strings.\n\tpattern := regexp.MustCompile(`\u27e6([0-9a-f]{8}):wEaVeRlIsTeNeRs:([^\u2192]+)\u2192([^\u27e7]+)\u27e7`)\n\n\t// Find all matches in the data.\n\tmatches := pattern.FindAllSubmatch(data, -1)\n\n\t// Create a map to store the components and their listeners.\n\tcomponentsMap := make(map[string]*ComponentListeners)\n\n\t// Process each match.\n\tfor _, match := range matches {\n\t\tchecksum := string(match[1])\n\t\tcomponent := string(match[2])\n\t\tlistenersStr := string(match[3])\n\n\t\t// Verify the checksum.\n\t\texpectedChecksum := checksumListeners(component, listenersStr)\n\t\tif checksum != expectedChecksum {\n\t\t\tpanic(fmt.Sprintf(\"invalid checksum for component %s: expected %s, got %s\", component, expectedChecksum, checksum))\n\t\t}\n\n\t\t// Split the listeners string into individual listener names.\n\t\tlisteners := strings.Split(listenersStr, \",\")\n\n\t\t// Add the component and its listeners to the map.\n\t\tif _, exists := componentsMap[component]; !exists {\n\t\t\tcomponentsMap[component] = &ComponentListeners{\n\t\t\t\tComponent: component,\n\t\t\t\tListeners: []string{},\n\t\t\t}\n\t\t}\n\t\tcomponentsMap[component].Listeners = append(componentsMap[component].Listeners, listeners...)\n\t}\n\n\t// Convert the map to a slice.\n\tvar components []ComponentListeners\n\tfor _, component := range componentsMap {\n\t\tcomponents = append(components, *component)\n\t}\n\n\t// Sort the components by name.\n\tsort.Slice(components, func(i, j int) bool {\n\t\treturn components[i].Component < components[j].Component\n\t})\n\n\treturn components\n}\n```"]}, "weaver-runtime/codegen/hash.go-Sum64": {"response": ["```go\nfunc (h *Hasher) Sum64() uint64 {\n\t// Compute the SHA-256 hash of the accumulated data.\n\thash := sha256.Sum256(h.enc.Data())\n\n\t// Convert the first 8 bytes of the hash to a uint64.\n\tsum := binary.BigEndian.Uint64(hash[:8])\n\n\t// Ensure the result is in the range [1, 2^64-2].\n\tif sum == 0 || sum == math.MaxUint64 {\n\t\tsum = (sum % (math.MaxUint64 - 1)) + 1\n\t}\n\n\treturn sum\n}\n```"]}, "weaver-runtime/graph/adjacency.go-NewAdjacencyGraph": {"response": ["```go\n// NewAdjacencyGraph returns a Graph represented using adjacency lists.\n//\n// It panics if it specified edge nodes aren't in nodes.\nfunc NewAdjacencyGraph(nodes []Node, edges []Edge) Graph {\n\t// Determine the maximum node number to allocate the adjacency list.\n\tmaxNode := -1\n\tfor _, n := range nodes {\n\t\tif int(n) > maxNode {\n\t\t\tmaxNode = int(n)\n\t\t}\n\t}\n\n\t// Create the adjacency list with enough capacity for all nodes.\n\tout := make([][]Node, maxNode+1)\n\n\t// Mark the nodes that are present in the graph.\n\tfor _, n := range nodes {\n\t\tout[n] = []Node{}\n\t}\n\n\t// Add edges to the adjacency list.\n\tfor _, e := range edges {\n\t\tif !isNode(e.Src, out) || !isNode(e.Dst, out) {\n\t\t\tpanic(fmt.Sprintf(\"edge nodes %d or %d are not in nodes\", e.Src, e.Dst))\n\t\t}\n\t\tout[e.Src] = append(out[e.Src], e.Dst)\n\t}\n\n\treturn &adjacencyGraph{out: out}\n}\n```"]}, "weaver-runtime/graph/dfs.go-DFSAll": {"response": ["```go\n// DFSAll performs a depth first search of all nodes in g.\n// If enter is non-nil, it is called on entry to a node.\n// If exit is non-nil, it is called on exit from a node.\nfunc DFSAll(g Graph, enter, exit func(Node)) {\n\tvar roots []Node\n\tg.PerNode(func(n Node) {\n\t\troots = append(roots, n)\n\t})\n\tdfs(g, roots, enter, exit)\n}\n```"]}, "weaver-runtime/metrics/labels.go-newLabelExtractor": {"response": ["```go\nfunc newLabelExtractor[L comparable]() *labelExtractor[L] {\n\tvar x L\n\tt := reflect.TypeOf(x)\n\tfields := make([]field, t.NumField())\n\tfor i := 0; i < t.NumField(); i++ {\n\t\tfi := t.Field(i)\n\t\tname := unexport(fi.Name)\n\t\tif alias, ok := fi.Tag.Lookup(\"weaver\"); ok {\n\t\t\tname = alias\n\t\t}\n\t\tfields[i] = field{f: fi, name: name}\n\t}\n\treturn &labelExtractor[L]{fields: fields}\n}\n```"]}, "weaver-runtime/metrics/metrics.go-Snapshot": {"response": ["```go\n// Snapshot returns a snapshot of the metric. You must call Init at least once\n// before calling Snapshot.\nfunc (m *Metric) Snapshot() *MetricSnapshot {\n\tm.initIdAndLabels()\n\n\tvar counts []uint64\n\tif len(m.counts) > 0 {\n\t\tcounts = make([]uint64, len(m.counts))\n\t\tfor i := range m.counts {\n\t\t\tcounts[i] = m.counts[i].Load()\n\t\t}\n\t}\n\n\treturn &MetricSnapshot{\n\t\tId:     m.id,\n\t\tType:   m.typ,\n\t\tName:   m.name,\n\t\tLabels: maps.Clone(m.labels),\n\t\tHelp:   m.help,\n\t\tValue:  m.get(),\n\t\tBounds: slices.Clone(m.bounds),\n\t\tCounts: counts,\n\t}\n}\n```"]}, "weaver-internal/tool/generate/types.go-sizeOfType": {"response": ["```go\nfunc (tset *typeSet) sizeOfType(t types.Type) int {\n\tif result := tset.sizes.At(t); result != nil {\n\t\treturn result.(int)\n\t}\n\n\tvar size int\n\tswitch x := t.(type) {\n\tcase *types.Basic:\n\t\tswitch x.Kind() {\n\t\tcase types.Bool:\n\t\t\tsize = 1\n\t\tcase types.Int8, types.Uint8:\n\t\t\tsize = 1\n\t\tcase types.Int16, types.Uint16:\n\t\t\tsize = 2\n\t\tcase types.Int32, types.Uint32, types.Float32:\n\t\t\tsize = 4\n\t\tcase types.Int64, types.Uint64, types.Float64:\n\t\t\tsize = 8\n\t\tcase types.Complex64:\n\t\t\tsize = 8\n\t\tcase types.Complex128:\n\t\t\tsize = 16\n\t\tdefault:\n\t\t\tsize = -1\n\t\t}\n\n\tcase *types.Array:\n\t\telemSize := tset.sizeOfType(x.Elem())\n\t\tif elemSize >= 0 {\n\t\t\tsize = int(x.Len()) * elemSize\n\t\t} else {\n\t\t\tsize = -1\n\t\t}\n\n\tcase *types.Struct:\n\t\tsize = 0\n\t\tfor i := 0; i < x.NumFields(); i++ {\n\t\t\tfieldSize := tset.sizeOfType(x.Field(i).Type())\n\t\t\tif fieldSize < 0 {\n\t\t\t\tsize = -1\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tsize += fieldSize\n\t\t}\n\n\tcase *types.Named:\n\t\tsize = tset.sizeOfType(x.Underlying())\n\n\tdefault:\n\t\tsize = -1\n\t}\n\n\ttset.sizes.Set(t, size)\n\treturn size\n}\n```"]}, "weaver-internal/tool/generate/types.go-isMeasurable": {"response": ["```go\nfunc (tset *typeSet) isMeasurable(t types.Type) bool {\n\t// Check if the type is a fixed size type.\n\tif tset.isFixedSizeType(t) {\n\t\treturn true\n\t}\n\n\t// Check if the type is a string.\n\tif _, ok := t.(*types.Basic); ok {\n\t\treturn true\n\t}\n\n\t// Check if the type is a struct that is package local or implements weaver.AutoMarshal.\n\tif named, ok := t.(*types.Named); ok {\n\t\tif named.Obj().Pkg() == tset.pkg.Types || isWeaverAutoMarshal(named) {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// For other types, recursively check if all nested types are measurable.\n\tswitch x := t.(type) {\n\tcase *types.Pointer:\n\t\treturn tset.isMeasurable(x.Elem())\n\tcase *types.Array:\n\t\treturn tset.isMeasurable(x.Elem())\n\tcase *types.Slice:\n\t\treturn tset.isMeasurable(x.Elem())\n\tcase *types.Map:\n\t\treturn tset.isMeasurable(x.Key()) && tset.isMeasurable(x.Elem())\n\tcase *types.Struct:\n\t\tfor i := 0; i < x.NumFields(); i++ {\n\t\t\tif !tset.isMeasurable(x.Field(i).Type()) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase *types.Named:\n\t\treturn tset.isMeasurable(x.Underlying())\n\tdefault:\n\t\treturn false\n\t}\n}\n```"]}, "weaver-internal/tool/generate/types.go-isValidRouterType": {"response": ["```go\nfunc isValidRouterType(t types.Type) bool {\n\tswitch x := t.(type) {\n\tcase *types.Basic:\n\t\tswitch x.Kind() {\n\t\tcase types.Int, types.Int8, types.Int16, types.Int32, types.Int64,\n\t\t\ttypes.Uint, types.Uint8, types.Uint16, types.Uint32, types.Uint64,\n\t\t\ttypes.Float32, types.Float64, types.String:\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\tcase *types.Named:\n\t\tif isWeaverAutoMarshal(x) {\n\t\t\treturn true\n\t\t}\n\t\treturn isValidRouterType(x.Underlying())\n\tcase *types.Struct:\n\t\tfor i := 0; i < x.NumFields(); i++ {\n\t\t\tfield := x.Field(i)\n\t\t\tif !isValidRouterType(field.Type()) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\tdefault:\n\t\treturn false\n\t}\n}\n```"]}, "weaver-internal/tool/generate/generator.go-sanitize": {"response": ["```go\nfunc sanitize(t types.Type) string {\n\tvar b strings.Builder\n\tvar f func(t types.Type)\n\tf = func(t types.Type) {\n\t\tswitch x := t.(type) {\n\t\tcase *types.Basic:\n\t\t\tb.WriteString(x.Name())\n\t\tcase *types.Pointer:\n\t\t\tb.WriteString(\"ptr_\")\n\t\t\tf(x.Elem())\n\t\tcase *types.Array:\n\t\t\tb.WriteString(\"array_\")\n\t\t\tb.WriteString(strconv.Itoa(int(x.Len())))\n\t\t\tb.WriteString(\"_\")\n\t\t\tf(x.Elem())\n\t\tcase *types.Slice:\n\t\t\tb.WriteString(\"slice_\")\n\t\t\tf(x.Elem())\n\t\tcase *types.Map:\n\t\t\tb.WriteString(\"map_\")\n\t\t\tf(x.Key())\n\t\t\tb.WriteString(\"_\")\n\t\t\tf(x.Elem())\n\t\tcase *types.Struct:\n\t\t\tb.WriteString(\"struct_\")\n\t\t\tfor i := 0; i < x.NumFields(); i++ {\n\t\t\t\tf(x.Field(i).Type())\n\t\t\t\tif i < x.NumFields()-1 {\n\t\t\t\t\tb.WriteString(\"_\")\n\t\t\t\t}\n\t\t\t}\n\t\tcase *types.Named:\n\t\t\tb.WriteString(x.Obj().Name())\n\t\tdefault:\n\t\t\tpanic(fmt.Sprintf(\"sanitize: unexpected type: %v\", t))\n\t\t}\n\t}\n\tf(t)\n\n\t// Append a hash to ensure uniqueness.\n\th := sha256.New()\n\th.Write([]byte(b.String()))\n\thash := hex.EncodeToString(h.Sum(nil))[:8]\n\n\treturn b.String() + \"_\" + hash\n}\n```"]}, "weaver-internal/tool/generate/generator.go-uniqueName": {"response": ["```go\nfunc uniqueName(t types.Type) string {\n\tvar b strings.Builder\n\tvar f func(t types.Type)\n\tf = func(t types.Type) {\n\t\tswitch x := t.(type) {\n\t\tcase *types.Basic:\n\t\t\tb.WriteString(x.Name())\n\t\tcase *types.Pointer:\n\t\t\tb.WriteString(\"ptr_\")\n\t\t\tf(x.Elem())\n\t\tcase *types.Array:\n\t\t\tb.WriteString(\"array_\")\n\t\t\tb.WriteString(strconv.Itoa(int(x.Len())))\n\t\t\tb.WriteString(\"_\")\n\t\t\tf(x.Elem())\n\t\tcase *types.Slice:\n\t\t\tb.WriteString(\"slice_\")\n\t\t\tf(x.Elem())\n\t\tcase *types.Map:\n\t\t\tb.WriteString(\"map_\")\n\t\t\tf(x.Key())\n\t\t\tb.WriteString(\"_\")\n\t\t\tf(x.Elem())\n\t\tcase *types.Struct:\n\t\t\tb.WriteString(\"struct_\")\n\t\t\tfor i := 0; i < x.NumFields(); i++ {\n\t\t\t\tf(x.Field(i).Type())\n\t\t\t\tif i < x.NumFields()-1 {\n\t\t\t\t\tb.WriteString(\"_\")\n\t\t\t\t}\n\t\t\t}\n\t\tcase *types.Named:\n\t\t\tb.WriteString(x.Obj().Pkg().Path())\n\t\t\tb.WriteString(\".\")\n\t\t\tb.WriteString(x.Obj().Name())\n\t\tdefault:\n\t\t\tpanic(fmt.Sprintf(\"uniqueName: unexpected type: %v\", t))\n\t\t}\n\t}\n\tf(t)\n\treturn b.String()\n}\n```"]}, "weaver-internal/tool/certs/certs.go-GenerateSignedCert": {"response": ["```go\n// GenerateSignedCert generates a certificate for the given DNS names, signed\n// by the given Certificate Authority, and a corresponding private key.\n//\n// The returned certificate has a one-year validity and should only ever\n// be used on a temporary basis.\nfunc GenerateSignedCert(ca *x509.Certificate, caKey crypto.PrivateKey, names ...string) (*x509.Certificate, crypto.PrivateKey, error) {\n\t// Generate a new private key for the leaf certificate\n\tpriv, err := rsa.GenerateKey(rand.Reader, 4096)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Generate a serial number for the certificate\n\tserialNumberLimit := new(big.Int).Lsh(big.NewInt(1), 128)\n\tserialNumber, err := rand.Int(rand.Reader, serialNumberLimit)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Define the key usage and extended key usage for the leaf certificate\n\tkeyUsage := x509.KeyUsageDigitalSignature | x509.KeyUsageKeyEncipherment\n\textKeyUsage := []x509.ExtKeyUsage{\n\t\tx509.ExtKeyUsageClientAuth,\n\t\tx509.ExtKeyUsageServerAuth,\n\t}\n\n\t// Create the certificate template for the leaf certificate\n\ttemplate := x509.Certificate{\n\t\tSerialNumber: serialNumber,\n\t\tSubject:      pkix.Name{Organization: []string{\"ACME Co.\"}},\n\t\tNotBefore:    time.Now(),\n\t\tNotAfter:     time.Now().Add(365 * 24 * time.Hour),\n\t\tKeyUsage:     keyUsage,\n\t\tExtKeyUsage:  extKeyUsage,\n\t\tDNSNames:     names,\n\t}\n\n\t// Create the certificate using the CA certificate and private key\n\tcertDER, err := x509.CreateCertificate(rand.Reader, &template, ca, &priv.PublicKey, caKey)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\t// Parse the generated certificate\n\tcert, err := x509.ParseCertificate(certDER)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\treturn cert, priv, nil\n}\n```"]}, "weaver-internal/weaver/load.go-updateAssignment": {"response": ["```go\nfunc (lc *loadCollector) updateAssignment(assignment *protos.Assignment) {\n\tlc.mu.Lock()\n\tdefer lc.mu.Unlock()\n\n\t// Update the assignment and reset the accumulated load.\n\tlc.assignment = assignment\n\tlc.index = newIndex(assignment)\n\tlc.start = lc.now()\n\tlc.slices = map[uint64]*sliceSummary{}\n}\n```"]}, "weaver-internal/weaver/load.go-report": {"response": ["```go\nfunc (lc *loadCollector) report() *protos.LoadReport_ComponentLoad {\n\tlc.mu.Lock()\n\tdefer lc.mu.Unlock()\n\n\tif lc.assignment == nil {\n\t\t// No assignment yet, so no load to report.\n\t\treturn nil\n\t}\n\n\tnow := lc.now()\n\tdelta := now.Sub(lc.start)\n\tif delta == 0 {\n\t\t// Avoid division by zero.\n\t\treturn nil\n\t}\n\n\tcomponentLoad := &protos.LoadReport_ComponentLoad{\n\t\tSlices: make(map[uint64]*protos.LoadReport_SliceLoad, len(lc.slices)),\n\t}\n\n\tfor start, summary := range lc.slices {\n\t\tsubsliceLoads := summary.splits(delta)\n\t\tsliceLoad := &protos.LoadReport_SliceLoad{\n\t\t\tSubslices: subsliceLoads,\n\t\t}\n\t\tcomponentLoad.Slices[start] = sliceLoad\n\t}\n\n\treturn componentLoad\n}\n```"]}, "weaver-internal/weaver/load.go-subslices": {"response": ["```go\nfunc subslices(load float64, xs []uint64, n int) []*protos.LoadReport_SubsliceLoad {\n\t// Calculate the load per split.\n\tloadPerSplit := load / float64(n)\n\n\t// Initialize the result slice.\n\tsplits := make([]*protos.LoadReport_SubsliceLoad, n)\n\n\t// Calculate the number of points per split.\n\tpointsPerSplit := len(xs) / n\n\n\t// Initialize the start of the current split.\n\tstart := xs[0]\n\n\t// Iterate over the number of splits.\n\tfor i := 0; i < n; i++ {\n\t\t// Calculate the end index of the current split.\n\t\tendIndex := (i + 1) * pointsPerSplit\n\t\tif endIndex > len(xs) {\n\t\t\tendIndex = len(xs)\n\t\t}\n\n\t\t// Calculate the end of the current split.\n\t\tend := uint64(math.MaxUint64)\n\t\tif endIndex < len(xs) {\n\t\t\tend = xs[endIndex]\n\t\t}\n\n\t\t// Create the split.\n\t\tsplits[i] = &protos.LoadReport_SubsliceLoad{\n\t\t\tStart: start,\n\t\t\tLoad:  loadPerSplit,\n\t\t}\n\n\t\t// Update the start of the next split.\n\t\tif endIndex < len(xs) {\n\t\t\tstart = end\n\t\t}\n\t}\n\n\treturn splits\n}\n```"]}, "weaver-internal/weaver/routing.go-update": {"response": ["```go\nfunc (rb *routingBalancer) update(assignment *protos.Assignment) {\n\trb.mu.Lock()\n\tdefer rb.mu.Unlock()\n\n\t// Update the assignment and index.\n\trb.assignment = assignment\n\trb.index = newIndex(assignment)\n\n\t// Rebuild the set of connections based on the new assignment.\n\tnewConns := make(map[string]call.ReplicaConnection)\n\tfor _, slice := range rb.index {\n\t\tfor _, replica := range slice.replicas {\n\t\t\tif conn, ok := rb.conns[replica]; ok {\n\t\t\t\tnewConns[replica] = conn\n\t\t\t}\n\t\t}\n\t}\n\trb.conns = newConns\n}\n```"]}, "weaver-internal/status/registry.go-NewRegistry": {"response": ["```go\nfunc NewRegistry(_ context.Context, dir string) (*Registry, error) {\n\t// Ensure the directory exists\n\tif err := os.MkdirAll(dir, 0755); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create registry directory: %w\", err)\n\t}\n\n\t// Create a new Registry instance\n\tregistry := &Registry{\n\t\tdir: dir,\n\t\tnewClient: func(addr string) Server {\n\t\t\treturn NewClient(addr)\n\t\t},\n\t}\n\n\treturn registry, nil\n}\n```"]}, "weaver-internal/routing/routing.go-FormatAssignment": {"response": ["```go\nfunc FormatAssignment(a *protos.Assignment) string {\n\tif a == nil {\n\t\treturn \"nil\"\n\t}\n\n\tvar sb strings.Builder\n\tsb.WriteString(\"Assignment {\\n\")\n\tsb.WriteString(fmt.Sprintf(\"  Version: %d,\\n\", a.Version))\n\tsb.WriteString(\"  Slices: [\\n\")\n\n\tfor i, slice := range a.Slices {\n\t\tsb.WriteString(fmt.Sprintf(\"    Slice %d: [\\n\", i))\n\t\tfor j, replica := range slice.Replicas {\n\t\t\tsb.WriteString(fmt.Sprintf(\"      Replica %d: %s,\\n\", j, replica))\n\t\t}\n\t\tsb.WriteString(\"    ],\\n\")\n\t}\n\n\tsb.WriteString(\"  ],\\n\")\n\tsb.WriteString(\"}\\n\")\n\n\treturn sb.String()\n}\n```"]}, "weaver-internal/routing/routing.go-EqualSlices": {"response": ["```go\n// EqualSlices returns an assignment with slices of roughly equal size.\n// Replicas are assigned to slices in a round robin fashion. The returned\n// assignment has a version of 0.\nfunc EqualSlices(replicas []string) *protos.Assignment {\n\t// Calculate the number of slices as the next power of two of the number of replicas.\n\tnumSlices := nextPowerOfTwo(len(replicas))\n\n\t// Initialize the assignment.\n\tassignment := &protos.Assignment{\n\t\tVersion: 0,\n\t\tSlices:  make([]*protos.Slice, numSlices),\n\t}\n\n\t// Distribute replicas to slices in a round robin fashion.\n\tfor i, replica := range replicas {\n\t\tsliceIndex := i % numSlices\n\t\tif assignment.Slices[sliceIndex] == nil {\n\t\t\tassignment.Slices[sliceIndex] = &protos.Slice{\n\t\t\t\tReplicas: []string{},\n\t\t\t}\n\t\t}\n\t\tassignment.Slices[sliceIndex].Replicas = append(assignment.Slices[sliceIndex].Replicas, replica)\n\t}\n\n\treturn assignment\n}\n```"]}, "weaver-internal/queue/queue.go-Pop": {"response": ["```go\nfunc (q *Queue[T]) Pop(ctx context.Context) (elem T, err error) {\n\tq.mu.Lock()\n\tdefer q.mu.Unlock()\n\tq.init()\n\n\tfor len(q.elems) == 0 {\n\t\tif err := q.wait.Wait(ctx); err != nil {\n\t\t\treturn elem, err\n\t\t}\n\t}\n\n\telem = q.elems[0]\n\tq.elems = q.elems[1:]\n\treturn elem, nil\n}\n```"]}, "weaver-internal/pipe/pipe.go-MakePipePair": {"response": ["```go\nfunc (c *Cmd) MakePipePair() (PipePair, error) {\n\t// Create the pipes for bi-directional communication\n\tparentReader, childWriter, err := os.Pipe()\n\tif err != nil {\n\t\treturn PipePair{}, fmt.Errorf(\"failed to create parentReader and childWriter pipe: %w\", err)\n\t}\n\n\tchildReader, parentWriter, err := os.Pipe()\n\tif err != nil {\n\t\tparentReader.Close()\n\t\tchildWriter.Close()\n\t\treturn PipePair{}, fmt.Errorf(\"failed to create childReader and parentWriter pipe: %w\", err)\n\t}\n\n\t// Register the pipes with the command\n\tchildWriterFD := c.registerPipe(parentReader, childWriter)\n\tchildReaderFD := c.registerPipe(parentWriter, childReader)\n\n\treturn PipePair{\n\t\tParentReader: parentReader,\n\t\tParentWriter: parentWriter,\n\t\tChildReader:  childReaderFD,\n\t\tChildWriter:  childWriterFD,\n\t}, nil\n}\n```"]}, "weaver-internal/register/writeonce.go-Write": {"response": ["```go\n// Write writes to the register, or panics if the register was already written.\nfunc (w *WriteOnce[T]) Write(val T) {\n\tw.mu.Lock()\n\tdefer w.mu.Unlock()\n\n\t// Initialize the condition variable if it hasn't been initialized yet.\n\tw.init()\n\n\t// Check if the register has already been written.\n\tif w.written {\n\t\tpanic(\"WriteOnce register already written\")\n\t}\n\n\t// Write the value to the register.\n\tw.val = val\n\tw.written = true\n\n\t// Signal all waiting readers that the value is now available.\n\tw.c.Broadcast()\n}\n```"]}, "weaver-internal/register/writeonce.go-TryWrite": {"response": ["```go\n// TryWrite tries to write to the register and returns if the write succeeds.\nfunc (w *WriteOnce[T]) TryWrite(val T) bool {\n\tw.mu.Lock()\n\tdefer w.mu.Unlock()\n\n\t// Initialize the condition variable if it hasn't been initialized yet.\n\tw.init()\n\n\t// If the register has already been written, return false.\n\tif w.written {\n\t\treturn false\n\t}\n\n\t// Write the value to the register.\n\tw.val = val\n\tw.written = true\n\n\t// Signal all waiting readers that the value has been written.\n\tw.c.Broadcast()\n\n\treturn true\n}\n```"]}, "weaver-internal/register/writeonce.go-Read": {"response": ["```go\n// Read returns the value of the register, blocking until it is written.\nfunc (w *WriteOnce[T]) Read() T {\n\tw.mu.Lock()\n\tdefer w.mu.Unlock()\n\n\t// Initialize the condition variable if not already initialized.\n\tw.init()\n\n\t// Wait until the value is written.\n\tfor !w.written {\n\t\tw.c.Wait()\n\t}\n\n\treturn w.val\n}\n```"]}, "weaver-internal/versioned/versioned.go-RLock": {"response": ["```go\n// RLock waits until the current version is different than the passed-in\n// version, and then acquires the read lock and returns the new\n// version.\nfunc (v *Versioned[T]) RLock(version string) string {\n\tv.mu.RLock()\n\tfor v.version == version {\n\t\tv.mu.RUnlock()\n\t\tv.changed.Wait()\n\t\tv.mu.RLock()\n\t}\n\treturn v.version\n}\n```"]}, "weaver-internal/net/call/stub.go-makeStubMethods": {"response": ["```go\nfunc makeStubMethods(fullName string, reg *codegen.Registration) []stubMethod {\n\tmethods := make([]stubMethod, reg.Iface.NumMethod())\n\tfor i := 0; i < reg.Iface.NumMethod(); i++ {\n\t\tmethodName := reg.Iface.Method(i).Name\n\t\tmethods[i] = stubMethod{\n\t\t\tkey:   MakeMethodKey(fullName, methodName),\n\t\t\tretry: reg.Iface.Method(i).Retry,\n\t\t}\n\t}\n\treturn methods\n}\n```"]}, "weaver-internal/net/call/call.go-Serve": {"response": ["```go\nfunc Serve(ctx context.Context, l Listener, opts ServerOptions) error {\n\t// Apply default options if necessary.\n\topts = opts.withDefaults()\n\n\t// Create a server state to manage live connections.\n\tss := &serverState{opts: opts}\n\n\t// Create a context that can be canceled to stop the server.\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\n\t// Start a goroutine to accept incoming connections.\n\terrCh := make(chan error, 1)\n\tgo func() {\n\t\tfor {\n\t\t\tconn, hmap, err := l.Accept()\n\t\t\tif err != nil {\n\t\t\t\terrCh <- err\n\t\t\t\treturn\n\t\t\t}\n\t\t\tss.serveConnection(ctx, conn, hmap)\n\t\t}\n\t}()\n\n\t// Wait for either the context to be canceled or an error to occur.\n\tselect {\n\tcase <-ctx.Done():\n\t\tss.stop()\n\t\treturn ctx.Err()\n\tcase err := <-errCh:\n\t\tss.stop()\n\t\treturn err\n\t}\n}\n```"]}, "weaver-internal/net/call/call.go-Connect": {"response": ["```go\nfunc Connect(ctx context.Context, resolver Resolver, opts ClientOptions) (Connection, error) {\n\t// Apply default options if necessary.\n\topts = opts.withDefaults()\n\n\t// Create a new reconnectingConnection.\n\trc := &reconnectingConnection{\n\t\topts:     opts,\n\t\tconns:    make(map[string]*clientConnection),\n\t\tresolver: resolver,\n\t}\n\n\t// Start watching the resolver for updates.\n\tctx, cancel := context.WithCancel(ctx)\n\trc.cancelResolver = cancel\n\trc.resolverDone.Add(1)\n\tgo rc.watchResolver(ctx, nil)\n\n\t// Resolve the initial set of endpoints.\n\tendpoints, _, err := resolver.Resolve(ctx, nil)\n\tif err != nil {\n\t\trc.Close()\n\t\treturn nil, err\n\t}\n\n\t// Update the endpoints.\n\tif err := rc.updateEndpoints(ctx, endpoints); err != nil {\n\t\trc.Close()\n\t\treturn nil, err\n\t}\n\n\treturn rc, nil\n}\n```"]}, "weaver-internal/net/call/msg.go-writeMessage": {"response": ["```go\nfunc writeMessage(w io.Writer, wlock *sync.Mutex, mt messageType, id uint64, extraHdr []byte, payload []byte, flattenLimit int) error {\n\t// Concatenate extraHdr and payload to form the message payload.\n\tpayload = append(extraHdr, payload...)\n\n\t// Determine the length of the payload.\n\tpayloadLen := len(payload)\n\n\t// If the payload length is less than or equal to the flatten limit, write the message in a single flat byte slice.\n\t// Otherwise, write the message in chunks.\n\tif payloadLen <= flattenLimit {\n\t\treturn writeFlat(w, wlock, mt, id, nil, payload)\n\t} else {\n\t\treturn writeChunked(w, wlock, mt, id, nil, payload)\n\t}\n}\n```"]}, "weaver-internal/net/call/trace.go-writeTraceContext": {"response": ["```go\nfunc writeTraceContext(ctx context.Context, enc *codegen.Encoder) {\n\tspan := trace.SpanFromContext(ctx)\n\tif !span.SpanContext().IsValid() {\n\t\tenc.Bool(false)\n\t\treturn\n\t}\n\tenc.Bool(true)\n\tsc := span.SpanContext()\n\tenc.String(sc.TraceID().String())\n\tenc.String(sc.SpanID().String())\n\tenc.Bool(sc.IsSampled())\n}\n```"]}, "weaver-internal/net/call/trace.go-readTraceContext": {"response": ["```go\nfunc readTraceContext(dec *codegen.Decoder) *trace.SpanContext {\n\t// Read the trace ID.\n\tvar traceID trace.TraceID\n\tdec.Decode(&traceID)\n\n\t// Read the span ID.\n\tvar spanID trace.SpanID\n\tdec.Decode(&spanID)\n\n\t// Read the trace options.\n\tvar traceOptions trace.TraceFlags\n\tdec.Decode(&traceOptions)\n\n\t// Create and return the span context.\n\treturn &trace.SpanContext{\n\t\tTraceID:    traceID,\n\t\tSpanID:     spanID,\n\t\tTraceFlags: traceOptions,\n\t\tTraceState: trace.TraceState{},\n\t\tRemote:     true,\n\t}\n}\n```"]}, "ollama-types/model/name.go-ParseNameBare": {"response": ["```go\n// ParseNameBare parses s as a name string and returns a Name. No merge with\n// [DefaultName] is performed.\nfunc ParseNameBare(s string) Name {\n\tvar n Name\n\n\t// Helper function to set part of the name\n\tsetPart := func(kind partKind, value string) {\n\t\tswitch kind {\n\t\tcase kindHost:\n\t\t\tn.Host = value\n\t\tcase kindNamespace:\n\t\t\tn.Namespace = value\n\t\tcase kindModel:\n\t\t\tn.Model = value\n\t\tcase kindTag:\n\t\t\tn.Tag = value\n\t\tcase kindDigest:\n\t\t\tn.RawDigest = value\n\t\t}\n\t}\n\n\t// Start parsing from the end of the string\n\tvar parts []string\n\tvar partKinds []partKind\n\n\t// Check for digest\n\tif before, after, ok := cutLast(s, \"@\"); ok {\n\t\tif isValidPart(kindDigest, after) {\n\t\t\tsetPart(kindDigest, after)\n\t\t\ts = before\n\t\t} else {\n\t\t\t// Invalid digest, treat as part of the model\n\t\t\ts = s + \"@\" + after\n\t\t}\n\t}\n\n\t// Check for tag\n\tif before, after, ok := cutLast(s, \":\"); ok {\n\t\tif isValidPart(kindTag, after) {\n\t\t\tsetPart(kindTag, after)\n\t\t\ts = before\n\t\t} else {\n\t\t\t// Invalid tag, treat as part of the model\n\t\t\ts = s + \":\" + after\n\t\t}\n\t}\n\n\t// Split the remaining parts by \"/\"\n\tparts = strings.Split(s, \"/\")\n\tpartKinds = []partKind{kindHost, kindNamespace, kindModel}\n\n\t// Assign parts to the corresponding fields\n\tfor i := len(parts) - 1; i >= 0; i-- {\n\t\tif i < len(partKinds) {\n\t\t\tsetPart(partKinds[i], parts[i])\n\t\t} else {\n\t\t\t// More parts than expected, treat as part of the model\n\t\t\tn.Model = parts[i] + \"/\" + n.Model\n\t\t}\n\t}\n\n\treturn n\n}\n```"]}, "ollama-types/model/name.go-ParseNameFromFilepath": {"response": ["```go\n// ParseNameFromFilepath parses a 4-part filepath as a Name. The parts are\n// expected to be in the form:\n//\n// { host } \"/\" { namespace } \"/\" { model } \"/\" { tag }\nfunc ParseNameFromFilepath(s string) (n Name) {\n\tparts := strings.Split(s, string(filepath.Separator))\n\tif len(parts) != 4 {\n\t\treturn Name{}\n\t}\n\n\tn.Host = parts[0]\n\tn.Namespace = parts[1]\n\tn.Model = parts[2]\n\tn.Tag = parts[3]\n\n\treturn n\n}\n```"]}, "ollama-types/model/name.go-DisplayShortest": {"response": ["```go\n// DisplayShortest returns the shortest possible string version of the name.\n// It prioritizes the model and tag, and includes the host and namespace only if necessary.\nfunc (n Name) DisplayShortest() string {\n\tvar b strings.Builder\n\n\t// If the model is empty, return an empty string\n\tif n.Model == \"\" {\n\t\treturn \"\"\n\t}\n\n\t// Write the model\n\tb.WriteString(n.Model)\n\n\t// If the tag is not empty, append it\n\tif n.Tag != \"\" {\n\t\tb.WriteByte(':')\n\t\tb.WriteString(n.Tag)\n\t}\n\n\t// If the host or namespace is not empty, prepend them\n\tif n.Host != \"\" || n.Namespace != \"\" {\n\t\tvar prefix strings.Builder\n\t\tif n.Host != \"\" {\n\t\t\tprefix.WriteString(n.Host)\n\t\t}\n\t\tif n.Namespace != \"\" {\n\t\t\tif prefix.Len() > 0 {\n\t\t\t\tprefix.WriteByte('/')\n\t\t\t}\n\t\t\tprefix.WriteString(n.Namespace)\n\t\t}\n\t\tif prefix.Len() > 0 {\n\t\t\tprefix.WriteByte('/')\n\t\t\treturn prefix.String() + b.String()\n\t\t}\n\t}\n\n\treturn b.String()\n}\n```"]}, "ollama-types/model/name.go-Filepath": {"response": ["```go\nfunc (n Name) Filepath() string {\n\t// Ensure the name is fully qualified before proceeding\n\tif !n.IsFullyQualified() {\n\t\tpanic(\"Name is not fully qualified\")\n\t}\n\n\t// Create the filepath using the system's filepath separator\n\tparts := []string{n.Host, n.Namespace, n.Model, n.Tag}\n\tfilepath := filepath.Join(parts...)\n\n\t// Ensure the path is clean\n\treturn filepath.Clean(filepath)\n}\n```"]}, "ollama-server/prompt.go-Prompt": {"response": ["```go\nfunc Prompt(tmpl *template.Template, system, prompt, response string, generate bool) (string, error) {\n\t// Create a new template with the same tree structure as the original template\n\tnewTmpl := template.New(tmpl.Name()).Funcs(tmpl.FuncMap).Option(tmpl.Option())\n\tnewTmpl.Tree = tmpl.Tree\n\n\t// Format the template for response if generate is false\n\tformatTemplateForResponse(newTmpl, generate)\n\n\t// Create a data structure to hold the template variables\n\tdata := struct {\n\t\tSystem   string\n\t\tPrompt   string\n\t\tResponse string\n\t}{\n\t\tSystem:   system,\n\t\tPrompt:   prompt,\n\t\tResponse: response,\n\t}\n\n\t// Execute the template with the provided data\n\tvar buf bytes.Buffer\n\tif err := newTmpl.Execute(&buf, data); err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn buf.String(), nil\n}\n```"]}, "ollama-server/sched.go-unload": {"response": ["```go\nfunc (runner *runnerRef) unload() {\n\tif runner.llama != nil {\n\t\tslog.Debug(\"shutting down runner\", \"model\", runner.modelPath)\n\t\trunner.llama.Close()\n\t}\n}\n```"]}, "lo-retry.go-NewDebounce": {"response": ["```go\npackage main\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\n// NewDebounce creates a debounced instance that delays invoking functions given until after wait milliseconds have elapsed.\nfunc NewDebounce(duration time.Duration, f ...func()) (func(), func()) {\n\tvar timer *time.Timer\n\tvar mu sync.Mutex\n\n\t// The debounced function\n\tdebounced := func() {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\n\t\tif timer != nil {\n\t\t\ttimer.Stop()\n\t\t}\n\n\t\ttimer = time.AfterFunc(duration, func() {\n\t\t\tfor _, fn := range f {\n\t\t\t\tfn()\n\t\t\t}\n\t\t})\n\t}\n\n\t// The cancel function to cancel the debounced call\n\tcancel := func() {\n\t\tmu.Lock()\n\t\tdefer mu.Unlock()\n\n\t\tif timer != nil {\n\t\t\ttimer.Stop()\n\t\t\ttimer = nil\n\t\t}\n\t}\n\n\treturn debounced, cancel\n}\n```"]}, "lo-retry.go-NewDebounceBy": {"response": ["```go\npackage main\n\nimport (\n\t\"sync\"\n\t\"time\"\n)\n\n// NewDebounceBy creates a debounced instance for each distinct key, that delays invoking functions given until after wait milliseconds have elapsed.\nfunc NewDebounceBy[T comparable](duration time.Duration, f ...func(key T, count int)) (func(key T), func(key T)) {\n\ttype debounceEntry struct {\n\t\ttimer  *time.Timer\n\t\tcount  int\n\t\tmu     sync.Mutex\n\t\tactive bool\n\t}\n\n\tdebounceMap := make(map[T]*debounceEntry)\n\tvar mu sync.Mutex\n\n\tdebounce := func(key T) {\n\t\tmu.Lock()\n\t\tentry, exists := debounceMap[key]\n\t\tif !exists {\n\t\t\tentry = &debounceEntry{}\n\t\t\tdebounceMap[key] = entry\n\t\t}\n\t\tmu.Unlock()\n\n\t\tentry.mu.Lock()\n\t\tdefer entry.mu.Unlock()\n\n\t\tif entry.active {\n\t\t\tentry.count++\n\t\t\treturn\n\t\t}\n\n\t\tentry.active = true\n\t\tentry.count++\n\n\t\tentry.timer = time.AfterFunc(duration, func() {\n\t\t\tentry.mu.Lock()\n\t\t\tdefer entry.mu.Unlock()\n\n\t\t\tfor _, fn := range f {\n\t\t\t\tfn(key, entry.count)\n\t\t\t}\n\n\t\t\tentry.count = 0\n\t\t\tentry.active = false\n\t\t})\n\t}\n\n\tcancel := func(key T) {\n\t\tmu.Lock()\n\t\tentry, exists := debounceMap[key]\n\t\tif !exists {\n\t\t\tmu.Unlock()\n\t\t\treturn\n\t\t}\n\t\tdelete(debounceMap, key)\n\t\tmu.Unlock()\n\n\t\tentry.mu.Lock()\n\t\tdefer entry.mu.Unlock()\n\n\t\tif entry.timer != nil {\n\t\t\tentry.timer.Stop()\n\t\t}\n\n\t\tentry.count = 0\n\t\tentry.active = false\n\t}\n\n\treturn debounce, cancel\n}\n```"]}, "lo-errors.go-Try6": {"response": ["```go\nfunc Try6[T, R, S, Q, U any](callback func() (T, R, S, Q, U, error)) bool {\n\t_, _, _, _, _, err := callback()\n\treturn err == nil\n}\n```"]}, "lo-errors.go-TryOr6": {"response": ["```go\nfunc TryOr6[A, B, C, D, E, F any](callback func() (A, B, C, D, E, F, error), fallbackA A, fallbackB B, fallbackC C, fallbackD D, fallbackE E, fallbackF F) (A, B, C, D, E, F, bool) {\n    a, b, c, d, e, f, err := callback()\n    if err != nil {\n        return fallbackA, fallbackB, fallbackC, fallbackD, fallbackE, fallbackF, false\n    }\n    return a, b, c, d, e, f, true\n}\n```"]}, "lo-string.go-Substring": {"response": ["```go\nfunc Substring[T ~string](str T, offset int, length uint) T {\n\tif offset < 0 {\n\t\toffset = 0\n\t}\n\tif uint(offset) >= uint(len(str)) {\n\t\treturn \"\"\n\t}\n\tif uint(offset)+length > uint(len(str)) {\n\t\tlength = uint(len(str)) - uint(offset)\n\t}\n\treturn str[offset : offset+int(length)]\n}\n```"]}, "lo-string.go-PascalCase": {"response": ["```go\nfunc PascalCase(str string) string {\n\t// PascalCase converts string to pascal case.\n\tif str == \"\" {\n\t\treturn str\n\t}\n\n\t// Split the string into words.\n\twords := strings.FieldsFunc(str, func(r rune) bool {\n\t\treturn !unicode.IsLetter(r) && !unicode.IsDigit(r)\n\t})\n\n\t// Capitalize the first letter of each word and join them together.\n\tfor i, word := range words {\n\t\twords[i] = strings.Title(strings.ToLower(word))\n\t}\n\n\treturn strings.Join(words, \"\")\n}\n```"]}, "lo-map.go-PickByValues": {"response": ["```go\nfunc PickByValues[K comparable, V comparable, Map ~map[K]V](in Map, values []V) Map {\n\tresult := make(Map)\n\tfor key, value := range in {\n\t\tfor _, v := range values {\n\t\t\tif value == v {\n\t\t\t\tresult[key] = value\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn result\n}\n```"]}, "lo-map.go-OmitByValues": {"response": ["```go\nfunc OmitByValues[K comparable, V comparable, Map ~map[K]V](in Map, values []V) Map {\n\t// Create a set of values to omit for quick lookup.\n\tomitSet := make(map[V]bool)\n\tfor _, value := range values {\n\t\tomitSet[value] = true\n\t}\n\n\t// Create a new map to store the filtered results.\n\tresult := make(Map)\n\n\t// Iterate over the input map and copy entries that are not in the omit set.\n\tfor key, value := range in {\n\t\tif !omitSet[value] {\n\t\t\tresult[key] = value\n\t\t}\n\t}\n\n\treturn result\n}\n```"]}, "lo-tuples.go-Zip9": {"response": ["```go\nfunc Zip9[A, B, C, D, E, F, G, H, I any](a []A, b []B, c []C, d []D, e []E, f []F, g []G, h []H, i []I) []Tuple9[A, B, C, D, E, F, G, H, I] {\n    // Determine the maximum length of the input slices\n    maxLen := len(a)\n    if len(b) > maxLen {\n        maxLen = len(b)\n    }\n    if len(c) > maxLen {\n        maxLen = len(c)\n    }\n    if len(d) > maxLen {\n        maxLen = len(d)\n    }\n    if len(e) > maxLen {\n        maxLen = len(e)\n    }\n    if len(f) > maxLen {\n        maxLen = len(f)\n    }\n    if len(g) > maxLen {\n        maxLen = len(g)\n    }\n    if len(h) > maxLen {\n        maxLen = len(h)\n    }\n    if len(i) > maxLen {\n        maxLen = len(i)\n    }\n\n    // Create a slice to hold the resulting tuples\n    result := make([]Tuple9[A, B, C, D, E, F, G, H, I], maxLen)\n\n    // Fill the result slice with tuples\n    for j := 0; j < maxLen; j++ {\n        result[j] = Tuple9[A, B, C, D, E, F, G, H, I]{\n            A: getOrDefault(a, j),\n            B: getOrDefault(b, j),\n            C: getOrDefault(c, j),\n            D: getOrDefault(d, j),\n            E: getOrDefault(e, j),\n            F: getOrDefault(f, j),\n            G: getOrDefault(g, j),\n            H: getOrDefault(h, j),\n            I: getOrDefault(i, j),\n        }\n    }\n\n    return result\n}\n\n// Helper function to get the element at index j or the zero value if the index is out of bounds\nfunc getOrDefault[T any](slice []T, index int) T {\n    if index < len(slice) {\n        return slice[index]\n    }\n    var zero T\n    return zero\n}\n\n// Tuple9 represents a tuple of 9 elements\ntype Tuple9[A, B, C, D, E, F, G, H, I any] struct {\n    A A\n    B B\n    C C\n    D D\n    E E\n    F F\n    G G\n    H H\n    I I\n}\n```"]}, "lo-tuples.go-ZipBy9": {"response": ["```go\nfunc ZipBy9[A any, B any, C any, D any, E any, F any, G any, H any, I any, Out any](a []A, b []B, c []C, d []D, e []E, f []F, g []G, h []H, i []I, iteratee func(a A, b B, c C, d D, e E, f F, g G, h H, i I) Out) []Out {\n    // Determine the maximum length of the input slices\n    maxLen := len(a)\n    if len(b) > maxLen {\n        maxLen = len(b)\n    }\n    if len(c) > maxLen {\n        maxLen = len(c)\n    }\n    if len(d) > maxLen {\n        maxLen = len(d)\n    }\n    if len(e) > maxLen {\n        maxLen = len(e)\n    }\n    if len(f) > maxLen {\n        maxLen = len(f)\n    }\n    if len(g) > maxLen {\n        maxLen = len(g)\n    }\n    if len(h) > maxLen {\n        maxLen = len(h)\n    }\n    if len(i) > maxLen {\n        maxLen = len(i)\n    }\n\n    // Create the output slice with the determined length\n    result := make([]Out, maxLen)\n\n    // Iterate over the slices and apply the iteratee function\n    for j := 0; j < maxLen; j++ {\n        // Get the elements from each slice, or use the zero value if the slice is shorter\n        var aVal A\n        if j < len(a) {\n            aVal = a[j]\n        }\n        var bVal B\n        if j < len(b) {\n            bVal = b[j]\n        }\n        var cVal C\n        if j < len(c) {\n            cVal = c[j]\n        }\n        var dVal D\n        if j < len(d) {\n            dVal = d[j]\n        }\n        var eVal E\n        if j < len(e) {\n            eVal = e[j]\n        }\n        var fVal F\n        if j < len(f) {\n            fVal = f[j]\n        }\n        var gVal G\n        if j < len(g) {\n            gVal = g[j]\n        }\n        var hVal H\n        if j < len(h) {\n            hVal = h[j]\n        }\n        var iVal I\n        if j < len(i) {\n            iVal = i[j]\n        }\n\n        // Apply the iteratee function and store the result\n        result[j] = iteratee(aVal, bVal, cVal, dVal, eVal, fVal, gVal, hVal, iVal)\n    }\n\n    return result\n}\n```"]}, "lo-channel.go-ChannelDispatcher": {"response": ["```go\nfunc ChannelDispatcher[T any](stream <-chan T, count int, channelBufferCap int, strategy DispatchingStrategy[T]) []<-chan T {\n\t// Create the output channels with the specified buffer capacity.\n\toutputChannels := make([]chan T, count)\n\tfor i := 0; i < count; i++ {\n\t\tif channelBufferCap > 0 {\n\t\t\toutputChannels[i] = make(chan T, channelBufferCap)\n\t\t} else {\n\t\t\toutputChannels[i] = make(chan T)\n\t\t}\n\t}\n\n\t// Start a goroutine to dispatch messages from the input stream to the output channels.\n\tgo func() {\n\t\tdefer func() {\n\t\t\t// Close all output channels when the input stream is closed.\n\t\t\tfor i := 0; i < count; i++ {\n\t\t\t\tclose(outputChannels[i])\n\t\t\t}\n\t\t}()\n\n\t\tfor msg := range stream {\n\t\t\t// Use the dispatching strategy to determine which channel to send the message to.\n\t\t\tindex := strategy(msg)\n\t\t\tif index >= 0 && index < count {\n\t\t\t\toutputChannels[index] <- msg\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Convert the output channels to read-only channels.\n\treadOnlyChannels := make([]<-chan T, count)\n\tfor i := 0; i < count; i++ {\n\t\treadOnlyChannels[i] = outputChannels[i]\n\t}\n\n\treturn readOnlyChannels\n}\n```"]}, "lo-channel.go-DispatchingStrategyRoundRobin": {"response": ["```go\nfunc DispatchingStrategyRoundRobin[T any](msg T, index uint64, channels []<-chan T) int {\n\t// Calculate the index of the channel to use using round-robin strategy.\n\tchannelIndex := int(index % uint64(len(channels)))\n\treturn channelIndex\n}\n```"]}, "lo-channel.go-FanOut": {"response": ["```go\nfunc FanOut[T any](count int, channelsBufferCap int, upstream <-chan T) []<-chan T {\n\t// Create a slice to hold the downstream channels.\n\tdownstreams := make([]chan T, count)\n\tfor i := 0; i < count; i++ {\n\t\tdownstreams[i] = make(chan T, channelsBufferCap)\n\t}\n\n\t// Start a goroutine to broadcast messages from the upstream channel to all downstream channels.\n\tgo func() {\n\t\tdefer func() {\n\t\t\t// Close all downstream channels when the upstream channel is closed.\n\t\t\tfor _, downstream := range downstreams {\n\t\t\t\tclose(downstream)\n\t\t\t}\n\t\t}()\n\n\t\tfor msg := range upstream {\n\t\t\t// Broadcast the message to all downstream channels.\n\t\t\tfor _, downstream := range downstreams {\n\t\t\t\tdownstream <- msg\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Convert the downstream channels to read-only channels.\n\treadOnlyDownstreams := make([]<-chan T, count)\n\tfor i := 0; i < count; i++ {\n\t\treadOnlyDownstreams[i] = downstreams[i]\n\t}\n\n\treturn readOnlyDownstreams\n}\n```"]}, "lo-slice.go-Shuffle": {"response": ["```go\n// Shuffle returns an array of shuffled values. Uses the Fisher-Yates shuffle algorithm.\n// Play: https://go.dev/play/p/Qp73bnTDnc7\nfunc Shuffle[T any, Slice ~[]T](collection Slice) Slice {\n    n := len(collection)\n    result := make(Slice, n)\n    copy(result, collection)\n    for i := n - 1; i > 0; i-- {\n        j := rand.Intn(i + 1)\n        result[i], result[j] = result[j], result[i]\n    }\n    return result\n}\n```"]}, "lo-slice.go-Fill": {"response": ["```go\nfunc Fill[T Clonable[T]](collection []T, initial T) []T {\n\tfor i := range collection {\n\t\tcollection[i] = initial.Clone()\n\t}\n\treturn collection\n}\n```"]}, "lo-slice.go-Repeat": {"response": ["```go\nfunc Repeat[T Clonable[T]](count int, initial T) []T {\n\tresult := make([]T, count)\n\tfor i := 0; i < count; i++ {\n\t\tresult[i] = initial.Clone()\n\t}\n\treturn result\n}\n```"]}, "lo-slice.go-DropByIndex": {"response": ["```go\nfunc DropByIndex[T any](collection []T, indexes ...int) []T {\n\t// Create a map to track the indexes to be dropped\n\tindexesToDrop := make(map[int]bool)\n\tfor _, index := range indexes {\n\t\tif index < 0 {\n\t\t\tindex = len(collection) + index\n\t\t}\n\t\tindexesToDrop[index] = true\n\t}\n\n\t// Create a new slice to store the result\n\tresult := make([]T, 0, len(collection)-len(indexesToDrop))\n\n\t// Iterate over the original collection and copy elements that are not in the drop list\n\tfor i, value := range collection {\n\t\tif !indexesToDrop[i] {\n\t\t\tresult = append(result, value)\n\t\t}\n\t}\n\n\treturn result\n}\n```"]}, "lo-intersect.go-Some": {"response": ["```go\nfunc Some[T comparable](collection []T, subset []T) bool {\n\t// Some returns true if at least 1 element of a subset is contained into a collection.\n\t// If the subset is empty Some returns false.\n\tif len(subset) == 0 {\n\t\treturn false\n\t}\n\n\tcollectionMap := make(map[T]bool)\n\tfor _, item := range collection {\n\t\tcollectionMap[item] = true\n\t}\n\n\tfor _, item := range subset {\n\t\tif collectionMap[item] {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n```"]}, "lo-find.go-FindKeyBy": {"response": ["```go\nfunc FindKeyBy[K comparable, V any](object map[K]V, predicate func(key K, value V) bool) (K, bool) {\n\tfor key, value := range object {\n\t\tif predicate(key, value) {\n\t\t\treturn key, true\n\t\t}\n\t}\n\tvar zero K\n\treturn zero, false\n}\n```"]}, "lo-find.go-FirstOr": {"response": ["```go\nfunc FirstOr[T any](collection []T, fallback T) T {\n\tif len(collection) > 0 {\n\t\treturn collection[0]\n\t}\n\treturn fallback\n}\n```"]}, "lo-find.go-LastOr": {"response": ["```go\nfunc LastOr[T any](collection []T, fallback T) T {\n\tif len(collection) == 0 {\n\t\treturn fallback\n\t}\n\treturn collection[len(collection)-1]\n}\n```"]}, "lo-math.go-Range": {"response": ["```go\nfunc Range(elementNum int) []int {\n\tresult := make([]int, elementNum)\n\tfor i := 0; i < elementNum; i++ {\n\t\tresult[i] = i - elementNum/2\n\t}\n\treturn result\n}\n```"]}, "lo-math.go-RangeFrom": {"response": ["```go\npackage main\n\nimport (\n\t\"constraints\"\n)\n\n// RangeFrom creates an array of numbers from start with specified length.\n// Play: https://go.dev/play/p/0r6VimXAi9H\nfunc RangeFrom[T constraints.Integer | constraints.Float](start T, elementNum int) []T {\n\tresult := make([]T, elementNum)\n\tfor i := 0; i < elementNum; i++ {\n\t\tresult[i] = start + T(i)\n\t}\n\treturn result\n}\n```"]}, "lo-math.go-Mean": {"response": ["```go\npackage main\n\nimport (\n\t\"constraints\"\n\t\"math\"\n)\n\n// Mean calculates the mean of a collection of numbers.\nfunc Mean[T constraints.Float | constraints.Integer](collection []T) T {\n\tif len(collection) == 0 {\n\t\treturn 0\n\t}\n\n\tvar sum T\n\tfor _, value := range collection {\n\t\tsum += value\n\t}\n\n\treturn sum / T(len(collection))\n}\n```"]}, "lo-math.go-MeanBy": {"response": ["```go\nfunc MeanBy[T any, R constraints.Float | constraints.Integer](collection []T, iteratee func(item T) R) R {\n    if len(collection) == 0 {\n        return 0\n    }\n\n    var sum R\n    for _, item := range collection {\n        sum += iteratee(item)\n    }\n\n    return sum / R(len(collection))\n}\n```"]}, "conc-waitgroup.go-WaitAndRecover": {"response": ["```go\nfunc (h *WaitGroup) WaitAndRecover() *panics.Recovered {\n    // WaitAndRecover will block until all goroutines spawned with Go exit and\n    // will return a *panics.Recovered if one of the child goroutines panics.\n    h.wg.Wait()\n    return h.recovered\n}\n```"]}, "conc-stream/stream.go-Wait": {"response": ["```go\n// Wait signals to the stream that all tasks have been submitted. Wait will\n// not return until all tasks and callbacks have been run.\nfunc (s *Stream) Wait() {\n\ts.init()\n\n\t// Defer the callbacker cleanup so that it occurs even in the case\n\t// that one of the tasks panics and is propagated up by s.pool.Wait().\n\tdefer func() {\n\t\tclose(s.queue)\n\t\ts.callbackerHandle.Wait()\n\t}()\n\n\t// Wait for all the workers to exit.\n\ts.pool.Wait()\n}\n```"]}, "OpenGFW-analyzer/udp/internal/quic/packet_protector.go-UnProtect": {"response": ["```go\nfunc (pp *PacketProtector) UnProtect(packet []byte, pnOffset, pnMax int64) ([]byte, error) {\n\t// Extract the packet number from the packet\n\tpnBytes := packet[pnOffset : pnOffset+pnMax]\n\tpn := decodePacketNumber(pp.key.aead.NonceSize(), int64(binary.BigEndian.Uint64(pnBytes)), uint8(pnMax))\n\n\t// Create the nonce for the AEAD decryption\n\tnonce := pp.key.nonce(pn)\n\n\t// Extract the encrypted payload and the associated data\n\tencryptedPayload := packet[pnOffset+pnMax:]\n\tassociatedData := packet[:pnOffset+pnMax]\n\n\t// Decrypt the payload\n\tplaintext, err := pp.key.aead.Open(nil, nonce, encryptedPayload, associatedData)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to decrypt payload: %w\", err)\n\t}\n\n\treturn plaintext, nil\n}\n```"]}, "hatchet-pkg/encryption/local.go-NewLocalEncryption": {"response": ["```go\nfunc NewLocalEncryption(masterKey []byte, privateEc256 []byte, publicEc256 []byte) (*localEncryptionService, error) {\n\t// Decode the master key\n\tmasterHandle, err := insecureHandleFromBytes(masterKey)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to decode master key: %w\", err)\n\t}\n\n\t// Create the AEAD from the master key handle\n\taead, err := aead.New(masterHandle)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create AEAD from master key: %w\", err)\n\t}\n\n\t// Decode the private EC256 key\n\tprivateEc256Handle, err := handleFromBytes(privateEc256, aead)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to decode private EC256 key: %w\", err)\n\t}\n\n\t// Decode the public EC256 key\n\tpublicEc256Handle, err := handleFromBytes(publicEc256, aead)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to decode public EC256 key: %w\", err)\n\t}\n\n\t// Create the local encryption service\n\tsvc := &localEncryptionService{\n\t\tkey:                aead,\n\t\tprivateEc256Handle: privateEc256Handle,\n\t\tpublicEc256Handle:  publicEc256Handle,\n\t}\n\n\treturn svc, nil\n}\n```"]}, "hatchet-pkg/encryption/cloudkms.go-NewCloudKMSEncryption": {"response": ["```go\npackage encryption\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/tink-crypto/tink-go-gcpkms/integration/gcpkms\"\n\t\"github.com/tink-crypto/tink-go/aead\"\n\t\"github.com/tink-crypto/tink-go/core/registry\"\n\t\"github.com/tink-crypto/tink-go/keyset\"\n\t\"google.golang.org/api/option\"\n)\n\n// NewCloudKMSEncryption creates a GCP CloudKMS-backed encryption service.\nfunc NewCloudKMSEncryption(keyUri string, credentialsJSON, privateEc256, publicEc256 []byte) (*cloudkmsEncryptionService, error) {\n\tclient, err := gcpkms.NewClientWithOptions(context.Background(), keyUri, option.WithCredentialsJSON(credentialsJSON))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create GCP KMS client: %w\", err)\n\t}\n\n\tregistry.RegisterKMSClient(client)\n\n\tremote, err := client.GetAEAD(keyUri)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get AEAD from GCP KMS: %w\", err)\n\t}\n\n\tdek := aead.AES128CTRHMACSHA256KeyTemplate()\n\ttemplate, err := aead.CreateKMSEnvelopeAEADKeyTemplate(keyUri, dek)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create KMS envelope AEAD key template: %w\", err)\n\t}\n\n\tenvelope := aead.NewKMSEnvelopeAEAD2(template, remote)\n\tif envelope == nil {\n\t\treturn nil, fmt.Errorf(\"failed to create envelope AEAD\")\n\t}\n\n\tprivateEc256Handle, err := handleFromBytes(privateEc256, remote)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create private EC256 handle: %w\", err)\n\t}\n\n\tpublicEc256Handle, err := handleFromBytes(publicEc256, remote)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create public EC256 handle: %w\", err)\n\t}\n\n\treturn &cloudkmsEncryptionService{\n\t\tkey:                envelope,\n\t\tprivateEc256Handle: privateEc256Handle,\n\t\tpublicEc256Handle:  publicEc256Handle,\n\t}, nil\n}\n```"]}, "hatchet-internal/datautils/render.go-RenderTemplateFields": {"response": ["```go\npackage datautils\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"text/template\"\n)\n\n// RenderTemplateFields recursively processes the input map, rendering any string fields using the data map.\nfunc RenderTemplateFields(data map[string]interface{}, input map[string]interface{}) (map[string]interface{}, error) {\n\tfor key, value := range input {\n\t\tswitch v := value.(type) {\n\t\tcase string:\n\t\t\t// If the value is a string, try to render it as a template\n\t\t\ttmpl, err := template.New(\"field\").Parse(v)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to parse template for key %s: %w\", key, err)\n\t\t\t}\n\n\t\t\tvar buf bytes.Buffer\n\t\t\tif err := tmpl.Execute(&buf, data); err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to execute template for key %s: %w\", key, err)\n\t\t\t}\n\n\t\t\tinput[key] = buf.String()\n\n\t\tcase map[string]interface{}:\n\t\t\t// If the value is a map, recursively process it\n\t\t\trenderedMap, err := RenderTemplateFields(data, v)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tinput[key] = renderedMap\n\n\t\tcase []interface{}:\n\t\t\t// If the value is a slice, recursively process each element\n\t\t\tfor i, elem := range v {\n\t\t\t\tswitch e := elem.(type) {\n\t\t\t\tcase string:\n\t\t\t\t\ttmpl, err := template.New(\"field\").Parse(e)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"failed to parse template for slice element at index %d: %w\", i, err)\n\t\t\t\t\t}\n\n\t\t\t\t\tvar buf bytes.Buffer\n\t\t\t\t\tif err := tmpl.Execute(&buf, data); err != nil {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"failed to execute template for slice element at index %d: %w\", i, err)\n\t\t\t\t\t}\n\n\t\t\t\t\tv[i] = buf.String()\n\n\t\t\t\tcase map[string]interface{}:\n\t\t\t\t\trenderedMap, err := RenderTemplateFields(data, e)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t\tv[i] = renderedMap\n\n\t\t\t\tcase []interface{}:\n\t\t\t\t\t// If the element is a slice, recursively process it\n\t\t\t\t\trenderedSlice, err := RenderTemplateFields(data, e)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t\tv[i] = renderedSlice\n\t\t\t\t}\n\t\t\t}\n\n\t\tdefault:\n\t\t\t// If the value is not a string, map, or slice, leave it as is\n\t\t}\n\t}\n\n\treturn input, nil\n}\n```"]}, "mox-ratelimit/ratelimit.go-Reset": {"response": ["```go\nfunc (l *Limiter) Reset(ip net.IP, tm time.Time) {\n\tl.Lock()\n\tdefer l.Unlock()\n\n\t// Iterate over each window limit\n\tfor i, pl := range l.WindowLimits {\n\t\tt := uint32(tm.UnixNano() / int64(pl.Window))\n\n\t\t// If the current time interval is different from the stored one, reset the counts\n\t\tif t > pl.Time || pl.Counts == nil {\n\t\t\tl.WindowLimits[i].Time = t\n\t\t\tpl.Counts = map[struct {\n\t\t\t\tIndex    uint8\n\t\t\t\tIPMasked [16]byte\n\t\t\t}]int64{} // Used below.\n\t\t\tl.WindowLimits[i].Counts = pl.Counts\n\t\t}\n\n\t\t// Reset the counts for the given IP and its masked versions\n\t\tfor j := 0; j < 3; j++ {\n\t\t\tif i == 0 {\n\t\t\t\tl.ipmasked[j] = l.maskIP(j, ip)\n\t\t\t}\n\n\t\t\tkey := struct {\n\t\t\t\tIndex    uint8\n\t\t\t\tIPMasked [16]byte\n\t\t\t}{uint8(j), l.ipmasked[j]}\n\n\t\t\t// Subtract the current count from the total\n\t\t\tif count, exists := pl.Counts[key]; exists {\n\t\t\t\tpl.Counts[key] = 0\n\t\t\t\tpl.Limits[j] += count\n\t\t\t}\n\t\t}\n\t}\n}\n```"]}, "mox-dns/dns.go-ParseDomainLax": {"response": ["```go\nfunc ParseDomainLax(s string) (Domain, error) {\n\tif strings.HasSuffix(s, \".\") {\n\t\treturn Domain{}, errTrailingDot\n\t}\n\n\t// Check if the domain contains underscores and if Pedantic mode is enabled.\n\tif Pedantic && strings.Contains(s, \"_\") {\n\t\treturn Domain{}, errUnderscore\n\t}\n\n\t// Convert the domain to ASCII and Unicode representations.\n\tascii, err := idna.Lookup.ToASCII(s)\n\tif err != nil {\n\t\treturn Domain{}, fmt.Errorf(\"%w: to ascii: %v\", errIDNA, err)\n\t}\n\tunicode, err := idna.Lookup.ToUnicode(s)\n\tif err != nil {\n\t\treturn Domain{}, fmt.Errorf(\"%w: to unicode: %w\", errIDNA, err)\n\t}\n\n\t// If the ASCII and Unicode representations are the same, it's an ASCII-only domain.\n\tif ascii == unicode {\n\t\treturn Domain{ascii, \"\"}, nil\n\t}\n\n\t// Return the domain with both ASCII and Unicode representations.\n\treturn Domain{ascii, unicode}, nil\n}\n```"]}, "mox-dmarcdb/eval.go-AddEvaluation": {"response": ["```go\nfunc AddEvaluation(ctx context.Context, aggregateReportingIntervalSeconds int, e *Evaluation) error {\n\t// Set Evaluation.IntervalHours based on aggregateReportingIntervalSeconds\n\te.IntervalHours = intervalHours(aggregateReportingIntervalSeconds)\n\n\t// Insert the evaluation into the database\n\terr := EvalDB.Insert(ctx, e)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"inserting evaluation into database: %v\", err)\n\t}\n\n\treturn nil\n}\n```"]}, "mox-dmarcdb/eval.go-EvaluationStats": {"response": ["```go\n// EvaluationStats returns evaluation counts and report-sending status per domain.\nfunc EvaluationStats(ctx context.Context) (map[string]EvaluationStat, error) {\n\tstats := make(map[string]EvaluationStat)\n\n\t// Query all evaluations from the database\n\tevaluations, err := Evaluations(ctx)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"fetching evaluations: %v\", err)\n\t}\n\n\t// Process each evaluation to aggregate stats per domain\n\tfor _, eval := range evaluations {\n\t\tdomain := eval.PolicyDomain\n\t\tstat, exists := stats[domain]\n\t\tif !exists {\n\t\t\tstat = EvaluationStat{\n\t\t\t\tDomain:       dns.Domain{ASCII: domain},\n\t\t\t\tDispositions: []string{},\n\t\t\t\tCount:        0,\n\t\t\t\tSendReport:   false,\n\t\t\t}\n\t\t}\n\n\t\t// Update the count\n\t\tstat.Count++\n\n\t\t// Update the dispositions list\n\t\tdisposition := eval.Disposition.String()\n\t\tif !slices.Contains(stat.Dispositions, disposition) {\n\t\t\tstat.Dispositions = append(stat.Dispositions, disposition)\n\t\t}\n\n\t\t// Update the send report status\n\t\tstat.SendReport = stat.SendReport || !eval.Optional\n\n\t\t// Store the updated stat back in the map\n\t\tstats[domain] = stat\n\t}\n\n\treturn stats, nil\n}\n```"]}, "mox-dmarcdb/eval.go-EvaluationsDomain": {"response": ["```go\n// EvaluationsDomain returns all evaluations for a domain.\nfunc EvaluationsDomain(ctx context.Context, domain dns.Domain) ([]Evaluation, error) {\n\tq := bstore.QueryDB[Evaluation](ctx, EvalDB)\n\tq.FilterNonzero(Evaluation{PolicyDomain: domain.ASCII})\n\treturn q.List()\n}\n```"]}, "mox-dmarcdb/eval.go-RemoveEvaluationsDomain": {"response": ["```go\n// RemoveEvaluationsDomain removes evaluations for domain so they won't be sent in\n// an aggregate report.\nfunc RemoveEvaluationsDomain(ctx context.Context, domain dns.Domain) error {\n\tq := bstore.QueryDB[Evaluation](ctx, EvalDB)\n\tq.FilterNonzero(Evaluation{PolicyDomain: domain.ASCII})\n\t_, err := q.Delete()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"removing evaluations for domain %s: %v\", domain.ASCII, err)\n\t}\n\treturn nil\n}\n```"]}, "mox-dmarcdb/reports.go-AddReport": {"response": ["```go\nfunc AddReport(ctx context.Context, f *dmarcrpt.Feedback, fromDomain dns.Domain) error {\n\t// Create a new DomainFeedback instance to store the report.\n\tdf := DomainFeedback{\n\t\tDomain:    f.ReportMetadata.OrgName, // Assuming OrgName is the domain where DMARC DNS record was found.\n\t\tFromDomain: fromDomain.ASCII,\n\t\tFeedback:  *f,\n\t}\n\n\t// Insert the report into the database.\n\terr := ReportsDB.Insert(ctx, &df)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"inserting report into database: %v\", err)\n\t}\n\n\t// Update prometheus metrics based on the report.\n\tfor _, record := range f.Records {\n\t\tmetricEvaluated.WithLabelValues(\n\t\t\tdf.Domain,\n\t\t\tstring(record.Row.PolicyEvaluated.Disposition),\n\t\t\tstring(record.Row.PolicyEvaluated.DKIM),\n\t\t\tstring(record.Row.PolicyEvaluated.SPF),\n\t\t).Inc()\n\n\t\tfor _, dkimResult := range record.AuthResults.DKIM {\n\t\t\tmetricDKIM.WithLabelValues(string(dkimResult.Result)).Inc()\n\t\t}\n\n\t\tfor _, spfResult := range record.AuthResults.SPF {\n\t\t\tmetricSPF.WithLabelValues(string(spfResult.Result)).Inc()\n\t\t}\n\t}\n\n\treturn nil\n}\n```"]}, "mox-junk/bloom.go-NewBloom": {"response": ["```go\nfunc NewBloom(data []byte, k int) (*Bloom, error) {\n\tfileSize := len(data)\n\tw, err := bloomValid(fileSize, k)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &Bloom{\n\t\tdata:     data,\n\t\tk:        k,\n\t\tw:        w,\n\t\tmodified: false,\n\t}, nil\n}\n```"]}, "mox-junk/filter.go-NewFilter": {"response": ["```go\nfunc NewFilter(ctx context.Context, log mlog.Log, params Params, dbPath, bloomPath string) (*Filter, error) {\n\t// Check if the bloom and/or database files already exist.\n\tif _, err := os.Stat(dbPath); err == nil {\n\t\treturn nil, fmt.Errorf(\"database file already exists: %s\", dbPath)\n\t}\n\tif _, err := os.Stat(bloomPath); err == nil {\n\t\treturn nil, fmt.Errorf(\"bloom filter file already exists: %s\", bloomPath)\n\t}\n\n\t// Create a new database.\n\tdb, err := newDB(ctx, log, dbPath)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"creating new database: %s\", err)\n\t}\n\n\t// Initialize the bloom filter.\n\tbloom := &Bloom{\n\t\tdata: make([]byte, bloomWidth(bloomFileSize)),\n\t\tk:    bloomK,\n\t\tw:    bloomWidth(bloomFileSize),\n\t}\n\n\t// Create the filter.\n\tf := &Filter{\n\t\tParams:    params,\n\t\tlog:       log,\n\t\tcache:     map[string]word{},\n\t\tchanged:   map[string]word{},\n\t\tdbPath:    dbPath,\n\t\tbloomPath: bloomPath,\n\t\tdb:        db,\n\t\tbloom:     bloom,\n\t\tisNew:     true,\n\t}\n\n\treturn f, nil\n}\n```"]}, "mox-junk/filter.go-ClassifyMessagePath": {"response": ["```go\nfunc (f *Filter) ClassifyMessagePath(ctx context.Context, path string) (probability float64, words map[string]struct{}, nham, nspam int, rerr error) {\n\t// Open the file at the given path\n\tmf, err := os.Open(path)\n\tif err != nil {\n\t\treturn 0, nil, 0, 0, fmt.Errorf(\"opening message file: %w\", err)\n\t}\n\tdefer func() {\n\t\terr := mf.Close()\n\t\tf.log.Check(err, \"closing message file\")\n\t}()\n\n\t// Get the file size\n\tfi, err := mf.Stat()\n\tif err != nil {\n\t\treturn 0, nil, 0, 0, fmt.Errorf(\"getting file info: %w\", err)\n\t}\n\tsize := fi.Size()\n\n\t// Call ClassifyMessageReader to classify the message\n\treturn f.ClassifyMessageReader(ctx, mf, size)\n}\n```"]}, "mox-junk/filter.go-TrainDirs": {"response": ["```go\nfunc (f *Filter) TrainDirs(hamDir, sentDir, spamDir string, hamFiles, sentFiles, spamFiles []string) error {\n\tif f.closed {\n\t\treturn errClosed\n\t}\n\n\t// Train on ham messages\n\thamN, hamMalformed, err := f.TrainDir(hamDir, hamFiles, true)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"training on ham messages: %w\", err)\n\t}\n\tf.log.Info(\"trained on ham messages\", slog.Int(\"count\", int(hamN)), slog.Int(\"malformed\", int(hamMalformed)))\n\n\t// Train on sent messages\n\tsentN, sentMalformed, err := f.TrainDir(sentDir, sentFiles, true)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"training on sent messages: %w\", err)\n\t}\n\tf.log.Info(\"trained on sent messages\", slog.Int(\"count\", int(sentN)), slog.Int(\"malformed\", int(sentMalformed)))\n\n\t// Train on spam messages\n\tspamN, spamMalformed, err := f.TrainDir(spamDir, spamFiles, false)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"training on spam messages: %w\", err)\n\t}\n\tf.log.Info(\"trained on spam messages\", slog.Int(\"count\", int(spamN)), slog.Int(\"malformed\", int(spamMalformed)))\n\n\t// Save the filter after training\n\tif err := f.Save(); err != nil {\n\t\treturn fmt.Errorf(\"saving filter after training: %w\", err)\n\t}\n\n\treturn nil\n}\n```"]}, "mox-webmail/message.go-parseListPostAddress": {"response": ["```go\nfunc parseListPostAddress(s string) *MessageAddress {\n\t// Attempt to parse the List-Post header value as an email address.\n\taddr, err := mail.ParseAddress(s)\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\t// Convert the parsed address to a MessageAddress.\n\tmessageAddr, err := parseAddress(addr.Address)\n\tif err != nil {\n\t\treturn nil\n\t}\n\n\treturn &messageAddr\n}\n```"]}, "mox-webmail/webmail.go-sanitizeNode": {"response": ["```go\nfunc sanitizeNode(node *html.Node) {\n\t// Remove script elements.\n\tif node.Type == html.ElementNode && node.Data == \"script\" {\n\t\tnode.Parent.RemoveChild(node)\n\t\treturn\n\t}\n\n\t// Remove on* attributes.\n\tfor i := 0; i < len(node.Attr); i++ {\n\t\tattr := node.Attr[i]\n\t\tif strings.HasPrefix(attr.Key, \"on\") {\n\t\t\tnode.Attr = append(node.Attr[:i], node.Attr[i+1:]...)\n\t\t\ti--\n\t\t}\n\t}\n\n\t// Remove javascript: href attributes.\n\tif node.Type == html.ElementNode && (node.Data == \"a\" || node.Data == \"area\" || node.Data == \"form\" || node.Data == \"base\") {\n\t\tfor i := 0; i < len(node.Attr); i++ {\n\t\t\tattr := node.Attr[i]\n\t\t\tif attr.Key == \"href\" && strings.HasPrefix(attr.Val, \"javascript:\") {\n\t\t\t\tnode.Attr = append(node.Attr[:i], node.Attr[i+1:]...)\n\t\t\t\ti--\n\t\t\t}\n\t\t}\n\t}\n\n\t// Add target=\"_blank\" to all links and to a base tag.\n\tif node.Type == html.ElementNode && (node.Data == \"a\" || node.Data == \"area\" || node.Data == \"form\" || node.Data == \"base\") {\n\t\tfor i := 0; i < len(node.Attr); i++ {\n\t\t\tattr := node.Attr[i]\n\t\t\tif attr.Key == \"target\" && attr.Val == \"_blank\" {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tif i == len(node.Attr)-1 {\n\t\t\t\tnode.Attr = append(node.Attr, html.Attribute{Key: \"target\", Val: \"_blank\"})\n\t\t\t}\n\t\t}\n\t}\n\n\t// Recursively sanitize child nodes.\n\tfor child := node.FirstChild; child != nil; child = child.NextSibling {\n\t\tsanitizeNode(child)\n\t}\n}\n```"]}, "mox-dnsbl/dnsbl.go-Lookup": {"response": ["```go\nfunc Lookup(ctx context.Context, elog *slog.Logger, resolver dns.Resolver, zone dns.Domain, ip net.IP) (rstatus Status, rexplanation string, rerr error) {\n\t// Convert the IP address to a DNSBL query string\n\tquery := reverseIP(ip) + \".\" + zone.Name()\n\n\t// Perform the DNS lookup\n\tstartTime := time.Now()\n\tanswers, err := resolver.LookupA(ctx, query)\n\tMetricLookup.WithLabelValues(\"dnsbl\", \"lookup\").Observe(time.Since(startTime).Seconds())\n\n\tif err != nil {\n\t\tif dns.IsNotFound(err) {\n\t\t\t// If the record does not exist, the IP is not listed\n\t\t\treturn StatusPass, \"\", nil\n\t\t}\n\t\t// If there is a temporary DNS error, return a temporary error status\n\t\treturn StatusTemperr, \"\", ErrDNS\n\t}\n\n\t// If an IP address is returned, the IP is listed\n\trstatus = StatusFail\n\n\t// Perform an additional TXT lookup for more information about the block\n\ttxtAnswers, err := resolver.LookupTXT(ctx, query)\n\tif err != nil && !dns.IsNotFound(err) {\n\t\t// If there is a temporary DNS error, return a temporary error status\n\t\treturn StatusTemperr, \"\", ErrDNS\n\t}\n\n\t// If TXT records are found, use them as the explanation\n\tif len(txtAnswers) > 0 {\n\t\trexplanation = strings.Join(txtAnswers, \" \")\n\t}\n\n\treturn rstatus, rexplanation, nil\n}\n\n// reverseIP converts an IP address to its reverse DNS form\nfunc reverseIP(ip net.IP) string {\n\tif ip.To4() != nil {\n\t\t// IPv4 address\n\t\treturn strings.Join(strings.Split(ip.String(), \".\"), \".\")\n\t} else {\n\t\t// IPv6 address\n\t\tparts := strings.Split(ip.String(), \":\")\n\t\tfor i, part := range parts {\n\t\t\tif part == \"\" {\n\t\t\t\tparts[i] = \"0\"\n\t\t\t}\n\t\t}\n\t\treturn strings.Join(parts, \".\")\n\t}\n}\n```"]}, "mox-dnsbl/dnsbl.go-CheckHealth": {"response": ["```go\nfunc CheckHealth(ctx context.Context, elog *slog.Logger, resolver dns.Resolver, zone dns.Domain) (rerr error) {\n\t// Define the IP addresses to check\n\tipsToCheck := []string{\"127.0.0.2\", \"127.0.0.1\"}\n\texpectedResults := []bool{true, false} // 127.0.0.2 should be present, 127.0.0.1 should not be present\n\n\tfor i, ip := range ipsToCheck {\n\t\t// Reverse the IP address and append the zone\n\t\treversedIP := reverseIP(ip)\n\t\tquery := fmt.Sprintf(\"%s.%s\", reversedIP, zone.Name())\n\n\t\t// Perform the DNS lookup\n\t\trecords, err := resolver.LookupA(ctx, query)\n\t\tif err != nil {\n\t\t\tif dns.IsNotFound(err) {\n\t\t\t\t// If the record is not found, check if it should be present\n\t\t\t\tif expectedResults[i] {\n\t\t\t\t\telog.Error(\"DNSBL health check failed\", \"ip\", ip, \"zone\", zone.Name(), \"error\", \"expected record not found\")\n\t\t\t\t\treturn ErrDNS\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// For other DNS errors, return ErrDNS\n\t\t\t\telog.Error(\"DNSBL health check failed\", \"ip\", ip, \"zone\", zone.Name(), \"error\", err)\n\t\t\t\treturn ErrDNS\n\t\t\t}\n\t\t} else {\n\t\t\t// If the record is found, check if it should not be present\n\t\t\tif !expectedResults[i] {\n\t\t\t\telog.Error(\"DNSBL health check failed\", \"ip\", ip, \"zone\", zone.Name(), \"error\", \"unexpected record found\")\n\t\t\t\treturn ErrDNS\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Helper function to reverse the IP address\nfunc reverseIP(ip string) string {\n\tparts := strings.Split(ip, \".\")\n\tfor i, j := 0, len(parts)-1; i < j; i, j = i+1, j-1 {\n\t\tparts[i], parts[j] = parts[j], parts[i]\n\t}\n\treturn strings.Join(parts, \".\")\n}\n```"]}, "mox-dmarcrpt/parse.go-ParseMessageReport": {"response": ["```go\n// ParseMessageReport parses an aggregate feedback report from a mail message. The\n// maximum message size is 15MB, the maximum report size after decompression is\n// 20MB.\nfunc ParseMessageReport(elog *slog.Logger, r io.ReaderAt) (*Feedback, error) {\n\t// Limit the message size to 15MB.\n\tlr := &moxio.LimitReader{R: io.NewSectionReader(r, 0, 15*1024*1024), Limit: 15 * 1024 * 1024}\n\n\t// Read the entire message into a buffer.\n\tbuf, err := io.ReadAll(lr)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"reading message: %v\", err)\n\t}\n\n\t// Parse the message into a message.Part.\n\tp, err := message.Parse(bytes.NewReader(buf))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parsing message: %v\", err)\n\t}\n\n\t// Call the existing parseMessageReport function to handle the parsing.\n\treturn parseMessageReport(mlog.New(elog), p)\n}\n```"]}, "mox-mox-/lifecycle.go-Register": {"response": ["```go\nfunc (c *connections) Register(nc net.Conn, protocol, listener string) {\n\tc.Lock()\n\tdefer c.Unlock()\n\n\tck := connKind{protocol: protocol, listener: listener}\n\tc.conns[nc] = ck\n\n\tc.activeMutex.Lock()\n\tc.active[ck]++\n\tc.activeMutex.Unlock()\n\n\tif _, ok := c.gauges[ck]; !ok {\n\t\tc.gauges[ck] = promauto.NewGaugeFunc(prometheus.GaugeOpts{\n\t\t\tName: \"mox_connections_active\",\n\t\t\tHelp: \"Number of active connections by protocol and listener.\",\n\t\t\tConstLabels: prometheus.Labels{\n\t\t\t\t\"protocol\": protocol,\n\t\t\t\t\"listener\": listener,\n\t\t\t},\n\t\t}, func() float64 {\n\t\t\tc.activeMutex.Lock()\n\t\t\tdefer c.activeMutex.Unlock()\n\t\t\treturn float64(c.active[ck])\n\t\t})\n\t}\n}\n```"]}, "mox-smtpclient/dial.go-Dial": {"response": ["```go\nfunc Dial(ctx context.Context, elog *slog.Logger, dialer Dialer, host dns.IPDomain, ips []net.IP, port int, dialedIPs map[string][]net.IP, localIPs []net.IP) (conn net.Conn, ip net.IP, rerr error) {\n\tlog := mlog.New(\"smtpclient\", elog)\n\n\t// Determine the local address to use for the connection.\n\tvar laddr net.Addr\n\tfor _, localIP := range localIPs {\n\t\tif localIP.To4() != nil && len(dialedIPs[host.String()]) == 0 {\n\t\t\tladdr = &net.TCPAddr{IP: localIP, Port: 0}\n\t\t\tbreak\n\t\t} else if localIP.To4() == nil && len(dialedIPs[host.String()]) > 0 {\n\t\t\tladdr = &net.TCPAddr{IP: localIP, Port: 0}\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Sort IPs based on previous attempts and address family preference.\n\tsort.Slice(ips, func(i, j int) bool {\n\t\tip1 := ips[i].String()\n\t\tip2 := ips[j].String()\n\t\tattempts1 := dialedIPs[ip1]\n\t\tattempts2 := dialedIPs[ip2]\n\n\t\t// Prefer IPs that have not been tried yet.\n\t\tif len(attempts1) == 0 && len(attempts2) > 0 {\n\t\t\treturn true\n\t\t} else if len(attempts1) > 0 && len(attempts2) == 0 {\n\t\t\treturn false\n\t\t}\n\n\t\t// If both IPs have been tried, prefer the one with fewer attempts.\n\t\tif len(attempts1) < len(attempts2) {\n\t\t\treturn true\n\t\t} else if len(attempts1) > len(attempts2) {\n\t\t\treturn false\n\t\t}\n\n\t\t// If both IPs have the same number of attempts, prefer IPv6 over IPv4 if the previous attempt was IPv4.\n\t\tif len(dialedIPs[host.String()]) > 0 && dialedIPs[host.String()][0].To4() != nil {\n\t\t\treturn ips[i].To4() == nil\n\t\t}\n\n\t\t// Otherwise, no preference.\n\t\treturn false\n\t})\n\n\t// Attempt to dial each IP in the sorted order.\n\tfor _, ip := range ips {\n\t\taddr := net.JoinHostPort(ip.String(), strconv.Itoa(port))\n\t\tconn, err := dial(ctx, dialer, 30*time.Second, addr, laddr)\n\t\tif err != nil {\n\t\t\tlog.Infox(\"dialing host failed\", err, slog.String(\"host\", host.String()), slog.String(\"ip\", ip.String()))\n\t\t\tcontinue\n\t\t}\n\n\t\t// Update dialedIPs with the successful IP.\n\t\tdialedIPs[host.String()] = append(dialedIPs[host.String()], ip)\n\t\treturn conn, ip, nil\n\t}\n\n\treturn nil, nil, fmt.Errorf(\"failed to dial any IP for host %s\", host.String())\n}\n```"]}, "mox-smtpclient/gather.go-GatherIPs": {"response": ["```go\nfunc GatherIPs(ctx context.Context, elog *slog.Logger, resolver dns.Resolver, network string, host dns.IPDomain, dialedIPs map[string][]net.IP) (authentic bool, expandedAuthentic bool, expandedHost dns.Domain, ips []net.IP, dualstack bool, rerr error) {\n\tlog := mlog.New(\"smtpclient\", elog)\n\n\t// IP addresses are dialed directly, and don't have TLSA records.\n\tif len(host.IP) > 0 {\n\t\treturn false, false, expandedHost, []net.IP{host.IP}, false, nil\n\t}\n\n\t// We start out assuming the result is authentic. Updated with each lookup.\n\tauthentic = true\n\texpandedAuthentic = true\n\n\t// We start out delivering to the recipient domain. We follow CNAMEs.\n\trcptDomain := host.Domain\n\t// Domain we are actually delivering to, after following CNAME record(s).\n\texpandedHost = rcptDomain\n\t// Keep track of CNAMEs we have followed, to detect loops.\n\tdomainsSeen := map[string]bool{}\n\tfor i := 0; ; i++ {\n\t\tif domainsSeen[expandedHost.ASCII] {\n\t\t\terr := fmt.Errorf(\"%w: recipient domain %s: already saw %s\", errCNAMELoop, rcptDomain, expandedHost)\n\t\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, err\n\t\t}\n\t\tdomainsSeen[expandedHost.ASCII] = true\n\n\t\tif i == 16 {\n\t\t\terr := fmt.Errorf(\"%w: recipient domain %s, last resolved domain %s\", errCNAMELimit, rcptDomain, expandedHost)\n\t\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, err\n\t\t}\n\n\t\t// Do explicit CNAME lookup.\n\t\tcctx, ccancel := context.WithTimeout(ctx, 30*time.Second)\n\t\tdefer ccancel()\n\t\tcname, cnameResult, err := resolver.LookupCNAME(cctx, expandedHost.ASCII+\".\")\n\t\tccancel()\n\t\tauthentic = authentic && cnameResult.Authentic\n\t\texpandedAuthentic = expandedAuthentic && cnameResult.Authentic\n\t\tif err != nil && !dns.IsNotFound(err) {\n\t\t\terr = fmt.Errorf(\"%w: cname lookup for %s: %v\", errDNS, expandedHost, err)\n\t\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, err\n\t\t}\n\t\tif err == nil && cname != expandedHost.ASCII+\".\" {\n\t\t\td, err := dns.ParseDomain(strings.TrimSuffix(cname, \".\"))\n\t\t\tif err != nil {\n\t\t\t\terr = fmt.Errorf(\"%w: parsing cname domain %s: %v\", errDNS, expandedHost, err)\n\t\t\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, err\n\t\t\t}\n\t\t\texpandedHost = d\n\t\t\t// Start again with new domain.\n\t\t\tcontinue\n\t\t}\n\n\t\t// Not a CNAME, so lookup A/AAAA records.\n\t\tactx, acancel := context.WithTimeout(ctx, 30*time.Second)\n\t\tdefer acancel()\n\t\tips, aResult, err := resolver.LookupIPAddr(actx, expandedHost.ASCII+\".\")\n\t\tacancel()\n\t\tauthentic = authentic && aResult.Authentic\n\t\texpandedAuthentic = expandedAuthentic && aResult.Authentic\n\t\tif err != nil {\n\t\t\terr = fmt.Errorf(\"%w: ip lookup for %s: %v\", errDNS, expandedHost, err)\n\t\t\treturn authentic, expandedAuthentic, expandedHost, nil, false, err\n\t\t}\n\n\t\t// Sort IPs based on previous attempts.\n\t\tsortIPs(ips, dialedIPs[expandedHost.ASCII])\n\n\t\t// Check for dual-stack support.\n\t\thasIPv4 := false\n\t\thasIPv6 := false\n\t\tfor _, ip := range ips {\n\t\t\tif ip.To4() != nil {\n\t\t\t\thasIPv4 = true\n\t\t\t} else {\n\t\t\t\thasIPv6 = true\n\t\t\t}\n\t\t}\n\t\tdualstack = hasIPv4 && hasIPv6\n\n\t\treturn authentic, expandedAuthentic, expandedHost, ips, dualstack, nil\n\t}\n}\n\nfunc sortIPs(ips []net.IP, dialedIPs []net.IP) {\n\t// Sort IPs based on previous attempts. IPs that have been dialed more recently\n\t// should come first.\n\tsort.SliceStable(ips, func(i"]}, "mox-tlsrpt/report.go-TLSFailureDetails": {"response": ["```go\nfunc TLSFailureDetails(err error) (ResultType, string) {\n\tswitch e := err.(type) {\n\tcase *tls.RecordHeaderError:\n\t\treturn ResultSTARTTLSNotSupported, \"record-header-error\"\n\tcase *tls.CertificateRequestInfoError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-request-info-error\"\n\tcase *tls.CertificateError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-error\"\n\tcase *tls.ConfigError:\n\t\treturn ResultValidationFailure, \"config-error\"\n\tcase *tls.ConnError:\n\t\tif e.IsTimeout() {\n\t\t\treturn ResultValidationFailure, \"connection-timeout\"\n\t\t}\n\t\treturn ResultValidationFailure, \"connection-error\"\n\tcase *tls.AlertError:\n\t\treturn ResultValidationFailure, formatAlert(e.Alert())\n\tcase *x509.CertificateInvalidError:\n\t\tif reason, ok := invalidReasons[e.Reason]; ok {\n\t\t\treturn ResultCertificateNotTrusted, reason\n\t\t}\n\t\treturn ResultCertificateNotTrusted, \"certificate-invalid\"\n\tcase *x509.HostnameError:\n\t\treturn ResultCertificateHostMismatch, \"hostname-mismatch\"\n\tcase *x509.UnknownAuthorityError:\n\t\treturn ResultCertificateNotTrusted, \"unknown-authority\"\n\tcase *x509.ConstraintViolationError:\n\t\treturn ResultCertificateNotTrusted, \"constraint-violation\"\n\tcase *x509.SystemRootsError:\n\t\treturn ResultCertificateNotTrusted, \"system-roots-error\"\n\tcase *x509.UnhandledCriticalExtension:\n\t\treturn ResultCertificateNotTrusted, \"unhandled-critical-extension\"\n\tcase *x509.CertificateInvalidError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-invalid\"\n\tcase *x509.CertificateRequestError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-request-error\"\n\tcase *x509.CertificateVerificationError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-verification-error\"\n\tcase *x509.ConstraintViolationError:\n\t\treturn ResultCertificateNotTrusted, \"constraint-violation\"\n\tcase *x509.SystemRootsError:\n\t\treturn ResultCertificateNotTrusted, \"system-roots-error\"\n\tcase *x509.UnhandledCriticalExtension:\n\t\treturn ResultCertificateNotTrusted, \"unhandled-critical-extension\"\n\tcase *x509.UnknownAuthorityError:\n\t\treturn ResultCertificateNotTrusted, \"unknown-authority\"\n\tcase *x509.HostnameError:\n\t\treturn ResultCertificateHostMismatch, \"hostname-mismatch\"\n\tcase *x509.CertificateInvalidError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-invalid\"\n\tcase *x509.CertificateRequestError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-request-error\"\n\tcase *x509.CertificateVerificationError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-verification-error\"\n\tcase *x509.ConstraintViolationError:\n\t\treturn ResultCertificateNotTrusted, \"constraint-violation\"\n\tcase *x509.SystemRootsError:\n\t\treturn ResultCertificateNotTrusted, \"system-roots-error\"\n\tcase *x509.UnhandledCriticalExtension:\n\t\treturn ResultCertificateNotTrusted, \"unhandled-critical-extension\"\n\tcase *x509.UnknownAuthorityError:\n\t\treturn ResultCertificateNotTrusted, \"unknown-authority\"\n\tcase *x509.HostnameError:\n\t\treturn ResultCertificateHostMismatch, \"hostname-mismatch\"\n\tcase *x509.CertificateInvalidError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-invalid\"\n\tcase *x509.CertificateRequestError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-request-error\"\n\tcase *x509.CertificateVerificationError:\n\t\treturn ResultCertificateNotTrusted, \"certificate-verification-error\"\n\tcase *x509.ConstraintViolationError:\n\t\treturn ResultCertificateNotTrusted, \"constraint-violation\"\n\tcase *x509.SystemRootsError:\n\t\treturn ResultCertificateNotTrusted, \"system-roots-error\"\n\tcase *x509.UnhandledCriticalExtension:\n\t\treturn ResultCertificateNotTrusted, \"unhandled-critical-extension\"\n\tcase *x509.UnknownAuthorityError:\n\t\treturn ResultCertificateNotTrusted, \"unknown-authority\"\n\tcase *x509.HostnameError:\n\t\treturn ResultCertificateHostMismatch, \"hostname-mismatch\"\n\tcase *x509."]}, "mox-tlsrpt/report.go-ParseMessage": {"response": ["```go\nfunc ParseMessage(elog *slog.Logger, r io.ReaderAt) (*ReportJSON, error) {\n\t// Create a logger for this function\n\tlog := mlog.New(\"tlsrpt\", elog)\n\n\t// Limit the size of the message to 15MB\n\tlimitedReader := &moxio.LimitReader{R: io.NewSectionReader(r, 0, 15*1024*1024), Limit: 15 * 1024 * 1024}\n\n\t// Parse the message part\n\tpart, err := message.Parse(limitedReader)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parsing message: %w\", err)\n\t}\n\n\t// Parse the report from the message part\n\treport, err := parseMessageReport(log, part, false)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parsing report from message: %w\", err)\n\t}\n\n\treturn report, nil\n}\n```"]}, "mox-spf/received.go-Header": {"response": ["```go\nfunc (r Received) Header() string {\n\t// Start building the header string.\n\theader := \"Received-SPF: \"\n\n\t// Add the result and comment (if any) to the header.\n\theader += string(r.Result)\n\tif r.Comment != \"\" {\n\t\theader += \" (\" + receivedValueEncode(r.Comment) + \")\"\n\t}\n\n\t// Add the client IP to the header.\n\theader += \" client-ip=\" + receivedValueEncode(r.ClientIP.String())\n\n\t// Add the envelope from to the header.\n\theader += \"; envelope-from=\" + receivedValueEncode(r.EnvelopeFrom)\n\n\t// Add the helo to the header.\n\tif r.Helo.IsIP() {\n\t\theader += \"; helo=\" + receivedValueEncode(r.Helo.IP.String())\n\t} else {\n\t\theader += \"; helo=\" + receivedValueEncode(r.Helo.Domain.ASCII)\n\t}\n\n\t// Add the problem (if any) to the header.\n\tif r.Problem != \"\" {\n\t\theader += \"; problem=\" + receivedValueEncode(r.Problem)\n\t}\n\n\t// Add the receiver to the header.\n\theader += \"; receiver=\" + receivedValueEncode(r.Receiver)\n\n\t// Add the identity to the header.\n\theader += \"; identity=\" + string(r.Identity)\n\n\t// Add the mechanism (if any) to the header.\n\tif r.Mechanism != \"\" {\n\t\theader += \"; mechanism=\" + receivedValueEncode(r.Mechanism)\n\t}\n\n\t// Add the trailing CRLF.\n\theader += \"\\r\\n\"\n\n\treturn header\n}\n```"]}, "mox-spf/spf.go-Evaluate": {"response": ["```go\nfunc Evaluate(ctx context.Context, elog *slog.Logger, record *Record, resolver dns.Resolver, args Args) (rstatus Status, mechanism, rexplanation string, rauthentic bool, rerr error) {\n\tlog := mlog.New(\"spf\", elog)\n\tstart := time.Now()\n\tdefer func() {\n\t\tlog.Debugx(\"spf evaluate result\", rerr,\n\t\t\tslog.Int(\"dnsrequests\", *args.dnsRequests),\n\t\t\tslog.Int(\"voidlookups\", *args.voidLookups),\n\t\t\tslog.Any(\"domain\", args.domain),\n\t\t\tslog.Any(\"status\", rstatus),\n\t\t\tslog.String(\"mechanism\", mechanism),\n\t\t\tslog.String(\"explanation\", rexplanation),\n\t\t\tslog.Duration(\"duration\", time.Since(start)))\n\t}()\n\n\tif args.dnsRequests == nil {\n\t\targs.dnsRequests = new(int)\n\t\targs.voidLookups = new(int)\n\t}\n\n\t// Response is authentic until we find a non-authentic DNS response.\n\trauthentic = true\n\n\t// To4 returns nil for an IPv6 address. To16 will return an IPv4-to-IPv6-mapped address.\n\tvar remote6 net.IP\n\tremote4 := args.RemoteIP.To4()\n\tif remote4 == nil {\n\t\tremote6 = args.RemoteIP.To16()\n\t}\n\n\t// Check if ip matches remote ip, taking cidr mask into account.\n\tcheckIP := func(ip net.IP, d Directive) bool {\n\t\t// ../rfc/7208:1097\n\t\tif remote4 != nil {\n\t\t\tip4 := ip.To4()\n\t\t\tif ip4 == nil {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tones := 32\n\t\t\tif d.IP4CIDRLen != nil {\n\t\t\t\tones = *d.IP4CIDRLen\n\t\t\t}\n\t\t\tmask := net.CIDRMask(ones, 32)\n\t\t\treturn ip4.Mask(mask).Equal(remote4.Mask(mask))\n\t\t}\n\n\t\tip6 := ip.To16()\n\t\tif ip6 == nil {\n\t\t\treturn false\n\t\t}\n\t\tones := 128\n\t\tif d.IP6CIDRLen != nil {\n\t\t\tones = *d.IP6CIDRLen\n\t\t}\n\t\tmask := net.CIDRMask(ones, 128)\n\t\treturn ip6.Mask(mask).Equal(remote6.Mask(mask))\n\t}\n\n\t// Used for \"a\" and \"mx\".\n\tcheckHostIP := func(domain dns.Domain, d Directive, args *Args) (bool, Status, error) {\n\t\tips, result, err := resolver.LookupIP(ctx, \"ip\", domain.ASCII+\".\")\n\t\trauthentic = rauthentic && result.Authentic\n\t\ttrackVoidLookup(err, args)\n\t\t// If \"not found\", we must ignore the error and treat as zero records in answer. ../rfc/7208:1116\n\t\tif err != nil && !dns.IsNotFound(err) {\n\t\t\treturn false, StatusTemperror, err\n\t\t}\n\t\tfor _, ip := range ips {\n\t\t\tif checkIP(ip, d) {\n\t\t\t\treturn true, StatusPass, nil\n\t\t\t}\n\t\t}\n\t\treturn false, StatusNone, nil\n\t}\n\n\tfor _, d := range record.Directives {\n\t\tvar match bool\n\n\t\tswitch d.Mechanism {\n\t\tcase \"include\", \"a\", \"mx\", \"ptr\", \"exists\":\n\t\t\tif err := trackLookupLimits(&args); err != nil {\n\t\t\t\treturn StatusPermerror, d.MechanismString(), \"\", rauthentic, err\n\t\t\t}\n\t\t}\n\n\t\tswitch d.Mechanism {\n\t\tcase \"all\":\n\t\t\t// ../rfc/7208:1127\n\t\t\tmatch = true\n\n\t\tcase \"include\":\n\t\t\t// ../rfc/7208:1143\n\t\t\tname, authentic, err := expandDomainSpecDNS(ctx, resolver, d.DomainSpec, args)\n\t\t\trauthentic = rauthentic && authentic\n\t\t\tif err != nil {\n\t\t\t\treturn StatusPermerror, d.MechanismString(), \"\", rauthentic, fmt.Errorf(\"expanding domain-spec for include: %w\", err)\n\t\t\t}\n\t\t\tnargs := args\n\t\t\tnargs.domain = dns."]}, "mox-spf/parse.go-Record": {"response": ["```go\nfunc (r Record) Record() (string, error) {\n\tvar sb strings.Builder\n\n\t// Start with the version\n\tsb.WriteString(\"v=spf1\")\n\n\t// Add directives\n\tfor _, directive := range r.Directives {\n\t\tsb.WriteString(\" \")\n\t\tsb.WriteString(directive.MechanismString())\n\t}\n\n\t// Add modifiers\n\tif r.Redirect != \"\" {\n\t\tsb.WriteString(\" redirect=\")\n\t\tsb.WriteString(r.Redirect)\n\t}\n\tif r.Explanation != \"\" {\n\t\tsb.WriteString(\" exp=\")\n\t\tsb.WriteString(r.Explanation)\n\t}\n\tfor _, modifier := range r.Other {\n\t\tsb.WriteString(\" \")\n\t\tsb.WriteString(modifier.Key)\n\t\tsb.WriteString(\"=\")\n\t\tsb.WriteString(modifier.Value)\n\t}\n\n\treturn sb.String(), nil\n}\n```"]}, "mox-message/part.go-EnsurePart": {"response": ["```go\nfunc EnsurePart(elog *slog.Logger, strict bool, r io.ReaderAt, size int64) (Part, error) {\n\tlog := mlog.New(\"message\", elog)\n\n\t// Attempt to parse the part normally.\n\tp, err := newPart(log, strict, r, 0, nil)\n\tif err == nil {\n\t\treturn p, nil\n\t}\n\n\t// If parsing fails, create a fallback part as application/octet-stream.\n\tnp := Part{\n\t\tHeaderOffset:            p.HeaderOffset,\n\t\tBodyOffset:              p.BodyOffset,\n\t\tEndOffset:               size,\n\t\tMediaType:               \"APPLICATION\",\n\t\tMediaSubType:            \"OCTET-STREAM\",\n\t\tContentTypeParams:       p.ContentTypeParams,\n\t\tContentID:               p.ContentID,\n\t\tContentDescription:      p.ContentDescription,\n\t\tContentTransferEncoding: p.ContentTransferEncoding,\n\t\tEnvelope:                p.Envelope,\n\t}\n\tnp.SetReaderAt(r)\n\n\t// By reading the body, the number of lines and decoded size will be set.\n\t_, err = io.Copy(io.Discard, np.Reader())\n\tif err != nil {\n\t\treturn np, err\n\t}\n\n\treturn np, err\n}\n```"]}, "mox-message/part.go-ParseNextPart": {"response": ["```go\nfunc (p *Part) ParseNextPart(elog *slog.Logger) (*Part, error) {\n\tlog := mlog.New(\"message\", elog)\n\n\tif len(p.bound) == 0 {\n\t\treturn nil, fmt.Errorf(\"not a multipart message\")\n\t}\n\n\tb := &bufAt{strict: p.strict, r: p.r, offset: p.nextBoundOffset}\n\n\t// Read the boundary line.\n\tline, _, err := b.ReadLine(true)\n\tif err != nil {\n\t\tif err == io.EOF {\n\t\t\treturn nil, io.EOF\n\t\t}\n\t\treturn nil, fmt.Errorf(\"reading boundary line: %w\", err)\n\t}\n\n\t// Check if this is the closing boundary.\n\tif match, finish := checkBound(line, p.bound); match && finish {\n\t\tp.EndOffset = b.offset - int64(len(line))\n\t\treturn nil, io.EOF\n\t} else if !match {\n\t\treturn nil, fmt.Errorf(\"missing boundary\")\n\t}\n\n\t// Parse the next part.\n\tpp, err := newPart(log, p.strict, p.r, b.offset, p)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"parsing next part: %w\", err)\n\t}\n\n\t// Update offsets for the next part.\n\tp.lastBoundOffset = p.nextBoundOffset\n\tp.nextBoundOffset = b.offset\n\n\treturn &pp, nil\n}\n```"]}, "mox-message/messageid.go-MessageIDCanonical": {"response": ["```go\npackage message\n\nimport (\n\t\"errors\"\n\t\"strings\"\n\n\t\"github.com/mjl-/mox/smtp\"\n)\n\nvar errBadMessageID = errors.New(\"not a message-id\")\n\n// MessageIDCanonical parses the Message-ID, returning a canonical value that is\n// lower-cased, without <>, and no unneeded quoting. For matching in threading,\n// with References/In-Reply-To. If the message-id is invalid (e.g. no <>), an error\n// is returned. If the message-id could not be parsed as address (localpart \"@\"\n// domain), the raw value and the bool return parameter true is returned. It is\n// quite common that message-id's don't adhere to the localpart @ domain\n// syntax.\nfunc MessageIDCanonical(s string) (string, bool, error) {\n\t// Trim the surrounding <> if present.\n\tif strings.HasPrefix(s, \"<\") && strings.HasSuffix(s, \">\") {\n\t\ts = s[1 : len(s)-1]\n\t} else {\n\t\treturn \"\", false, errBadMessageID\n\t}\n\n\t// Lowercase the message-id.\n\ts = strings.ToLower(s)\n\n\t// Attempt to parse the message-id as an address.\n\taddr, err := smtp.ParseAddress(s)\n\tif err != nil {\n\t\t// If parsing fails, return the raw value and indicate it's not an address.\n\t\treturn s, true, nil\n\t}\n\n\t// If parsing succeeds, return the canonical form of the address.\n\treturn addr.String(), false, nil\n}\n```"]}, "mox-message/decode.go-DecodeReader": {"response": ["```go\npackage message\n\nimport (\n\t\"io\"\n\t\"strings\"\n\n\t\"golang.org/x/text/encoding/ianaindex\"\n)\n\n// DecodeReader returns a reader that reads from r, decoding as charset. If\n// charset is empty, us-ascii, utf-8 or unknown, the original reader is\n// returned and no decoding takes place.\nfunc DecodeReader(charset string, r io.Reader) io.Reader {\n\t// If charset is empty, us-ascii, utf-8 or unknown, return the original reader.\n\tif charset == \"\" || strings.EqualFold(charset, \"us-ascii\") || strings.EqualFold(charset, \"utf-8\") {\n\t\treturn r\n\t}\n\n\t// Attempt to get the encoding for the specified charset.\n\tenc, err := ianaindex.MIME.Encoding(charset)\n\tif err != nil || enc == nil {\n\t\t// If the encoding is not found or there is an error, return the original reader.\n\t\treturn r\n\t}\n\n\t// Return a reader that decodes the input using the specified encoding.\n\treturn enc.NewDecoder().Reader(r)\n}\n```"]}, "mox-message/referencedids.go-ReferencedIDs": {"response": ["```go\npackage message\n\nimport (\n\t\"errors\"\n\t\"strings\"\n\n\t\"github.com/mjl-/mox/smtp\"\n)\n\nvar errBadMessageID = errors.New(\"not a message-id\")\n\n// ReferencedIDs returns the Message-IDs referenced from the References header(s),\n// with a fallback to the In-Reply-To header(s). The ids are canonicalized for\n// thread-matching, like with MessageIDCanonical. Empty message-id's are skipped.\nfunc ReferencedIDs(references []string, inReplyTo []string) ([]string, error) {\n\tvar ids []string\n\n\t// Process References header(s)\n\tfor _, ref := range references {\n\t\trefIDs := strings.Split(ref, \" \")\n\t\tfor _, refID := range refIDs {\n\t\t\tcanonicalID, err := MessageIDCanonical(refID)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif canonicalID != \"\" {\n\t\t\t\tids = append(ids, canonicalID)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Process In-Reply-To header(s) if no IDs were found in References\n\tif len(ids) == 0 {\n\t\tfor _, irt := range inReplyTo {\n\t\t\tcanonicalID, err := MessageIDCanonical(irt)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tif canonicalID != \"\" {\n\t\t\t\tids = append(ids, canonicalID)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ids, nil\n}\n\n// MessageIDCanonical parses the Message-ID, returning a canonical value that is\n// lower-cased, without <>, and no unneeded quoting. For matching in threading,\n// with References/In-Reply-To. If the message-id is invalid (e.g. no <>), an error\n// is returned. If the message-id could not be parsed as address (localpart \"@\"\n// domain), the raw value and the bool return parameter true is returned. It is\n// quite common that message-id's don't adhere to the localpart @ domain\n// syntax.\nfunc MessageIDCanonical(messageID string) (string, error) {\n\tif messageID == \"\" {\n\t\treturn \"\", nil\n\t}\n\n\t// Remove surrounding <> if present\n\tif strings.HasPrefix(messageID, \"<\") && strings.HasSuffix(messageID, \">\") {\n\t\tmessageID = messageID[1 : len(messageID)-1]\n\t}\n\n\t// Lowercase the message-id\n\tmessageID = strings.ToLower(messageID)\n\n\t// Check if the message-id is a valid address\n\t_, err := smtp.ParseAddress(messageID)\n\tif err != nil {\n\t\t// If it's not a valid address, return the raw value\n\t\treturn messageID, nil\n\t}\n\n\treturn messageID, nil\n}\n```"]}, "mox-message/authresults.go-ParseAuthResults": {"response": ["```go\nfunc ParseAuthResults(s string) (ar AuthResults, err error) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tif perr, ok := r.(parseError); ok {\n\t\t\t\terr = perr.err\n\t\t\t} else {\n\t\t\t\tpanic(r)\n\t\t\t}\n\t\t}\n\t}()\n\n\tp := &parser{s: s, lower: strings.ToLower(s)}\n\n\t// Parse the hostname and optional version.\n\tp.cfws()\n\tar.Hostname = p.xvalue()\n\tp.cfws()\n\tif p.take(\";\") {\n\t\tp.cfws()\n\t\tif p.prefix(\"version\") {\n\t\t\tp.xtake(\"version\")\n\t\t\tp.cfws()\n\t\t\tp.xtake(\"=\")\n\t\t\tp.cfws()\n\t\t\tar.Version = p.xvalue()\n\t\t\tp.cfws()\n\t\t\tp.xtake(\";\")\n\t\t\tp.cfws()\n\t\t}\n\t}\n\n\t// Parse the methods.\n\tfor !p.end() {\n\t\tmethodKeyword := p.xkeyword(false)\n\t\tam := p.xresinfo(methodKeyword)\n\t\tar.Methods = append(ar.Methods, am)\n\t\tp.cfws()\n\t}\n\n\treturn ar, nil\n}\n```"]}, "mox-store/msgreader.go-FileMsgReader": {"response": ["```go\nfunc FileMsgReader(prefix []byte, msgFile *os.File) *MsgReader {\n\t// Calculate the total size of the message, including the prefix and the contents of the file.\n\tsize := int64(len(prefix)) + msgFile.Size()\n\n\t// Create and return a new MsgReader instance with the provided prefix, file path, and size.\n\treturn &MsgReader{\n\t\tprefix: prefix,\n\t\tpath:   msgFile.Name(),\n\t\tsize:   size,\n\t}\n}\n```"]}, "mox-store/import.go-ParseDovecotKeywordsFlags": {"response": ["```go\nfunc ParseDovecotKeywordsFlags(r io.Reader, log mlog.Log) ([]string, error) {\n\tvar keywords []string\n\tscanner := bufio.NewScanner(r)\n\tfor scanner.Scan() {\n\t\tline := scanner.Text()\n\t\tparts := strings.SplitN(line, \" \", 2)\n\t\tif len(parts) != 2 {\n\t\t\tlog.Warn(\"invalid dovecot-keywords line, skipping\", slog.String(\"line\", line))\n\t\t\tcontinue\n\t\t}\n\t\tindex := parts[0]\n\t\tflag := strings.ToLower(parts[1])\n\t\tif _, err := strconv.Atoi(index); err != nil {\n\t\t\tlog.Warn(\"invalid index in dovecot-keywords line, skipping\", slog.String(\"index\", index), slog.String(\"line\", line))\n\t\t\tcontinue\n\t\t}\n\t\tif err := CheckKeyword(flag); err != nil {\n\t\t\tlog.Warn(\"invalid keyword in dovecot-keywords line, skipping\", slog.String(\"keyword\", flag), slog.String(\"line\", line))\n\t\t\tcontinue\n\t\t}\n\t\tkeywords = append(keywords, flag)\n\t}\n\tif err := scanner.Err(); err != nil {\n\t\treturn keywords, fmt.Errorf(\"reading dovecot-keywords file: %v\", err)\n\t}\n\treturn keywords, nil\n}\n```"]}, "mox-store/account.go-MessageRuleset": {"response": ["```go\nfunc MessageRuleset(log mlog.Log, dest config.Destination, m *Message, msgPrefix []byte, msgFile *os.File) *config.Ruleset {\n\t// Implementation of the function to match the message against the rulesets\n\t// and return the first matching ruleset.\n\t// This function will need to parse the message headers and body, and compare\n\t// them against the rules defined in the config.Destination.\n\n\t// Placeholder implementation:\n\t// For now, we assume there is a function `MatchRuleset` that takes the message\n\t// and the ruleset and returns true if the message matches the ruleset.\n\n\tfor _, rs := range dest.Rulesets {\n\t\tif MatchRuleset(m, msgPrefix, msgFile, rs) {\n\t\t\treturn &rs\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Placeholder function for matching ruleset.\nfunc MatchRuleset(m *Message, msgPrefix []byte, msgFile *os.File, rs config.Ruleset) bool {\n\t// This function should implement the logic to match the message against the ruleset.\n\t// For example, it could check the message headers and body against the ruleset's\n\t// conditions (e.g., sender, recipient, subject, etc.).\n\n\t// Placeholder logic:\n\t// For now, we assume the ruleset has a field `MatchCondition` that is a string\n\t// and we check if the message's subject contains this string.\n\n\t// Read the message headers from the msgPrefix and msgFile.\n\t// For simplicity, assume we have a function `ReadMessageHeaders` that returns the headers.\n\theaders := ReadMessageHeaders(msgPrefix, msgFile)\n\n\t// Check if the subject matches the ruleset's condition.\n\tif subject, ok := headers[\"Subject\"]; ok {\n\t\treturn strings.Contains(subject, rs.MatchCondition)\n\t}\n\n\treturn false\n}\n\n// Placeholder function for reading message headers.\nfunc ReadMessageHeaders(msgPrefix []byte, msgFile *os.File) map[string]string {\n\t// This function should implement the logic to read the message headers\n\t// from the msgPrefix and msgFile.\n\n\t// Placeholder implementation:\n\t// For now, we assume the headers are stored in the msgPrefix as a JSON string.\n\tvar headers map[string]string\n\tif err := json.Unmarshal(msgPrefix, &headers); err != nil {\n\t\tlog.Errorx(\"failed to unmarshal message headers\", err)\n\t}\n\n\treturn headers\n}\n```"]}, "mox-smtp/address.go-ParseAddress": {"response": ["```go\npackage smtp\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/mjl-/mox/dns\"\n)\n\nvar ErrBadAddress = errors.New(\"invalid email address\")\n\n// ParseAddress parses an email address. UTF-8 is allowed.\n// Returns ErrBadAddress for invalid addresses.\nfunc ParseAddress(s string) (address Address, err error) {\n\tp := &parser{s, 0}\n\n\tdefer func() {\n\t\tx := recover()\n\t\tif x == nil {\n\t\t\treturn\n\t\t}\n\t\te, ok := x.(error)\n\t\tif !ok {\n\t\t\tpanic(x)\n\t\t}\n\t\terr = fmt.Errorf(\"%w: %s\", ErrBadAddress, e)\n\t}()\n\n\tlocalpart := p.xlocalpart()\n\tdomain := p.xdomain()\n\n\tif p.empty() {\n\t\treturn Address{Localpart: localpart, Domain: domain}, nil\n\t}\n\n\tp.xerrorf(\"unexpected trailing characters\")\n\treturn Address{}, nil // This line is unreachable due to panic in xerrorf.\n}\n\nfunc (p *parser) xdomain() dns.Domain {\n\t// ../rfc/5321:2316\n\tvar s string\n\tif p.hasPrefix(\"[\") {\n\t\ts = p.xaddressLiteral()\n\t} else {\n\t\ts = p.xdomainName()\n\t}\n\treturn dns.Domain{ASCII: s, Unicode: s} // Assuming DNS package has a way to handle Unicode domains.\n}\n\nfunc (p *parser) xaddressLiteral() string {\n\tp.xtake(\"[\")\n\ts := p.takefn1(\"address literal\", func(c rune, i int) bool {\n\t\treturn c != ']'\n\t})\n\tp.xtake(\"]\")\n\treturn s\n}\n\nfunc (p *parser) xdomainName() string {\n\treturn p.takefn1(\"domain name\", func(c rune, i int) bool {\n\t\treturn isalphadigit(c) || c == '.' || c == '-' || c > 0x7f\n\t})\n}\n```"]}, "mox-smtp/address.go-ParseLocalpart": {"response": ["```go\nfunc ParseLocalpart(s string) (localpart Localpart, err error) {\n\tp := &parser{s, 0}\n\n\tdefer func() {\n\t\tx := recover()\n\t\tif x == nil {\n\t\t\treturn\n\t\t}\n\t\te, ok := x.(error)\n\t\tif !ok {\n\t\t\tpanic(x)\n\t\t}\n\t\terr = fmt.Errorf(\"%w: %s\", ErrBadLocalpart, e)\n\t}()\n\n\tlp := p.xlocalpart()\n\treturn lp, nil\n}\n```"]}, "mox-smtp/data.go-DataWrite": {"response": ["```go\nfunc DataWrite(w io.Writer, r io.Reader) error {\n\tbuf := bufio.NewReader(r)\n\tfor {\n\t\tline, err := buf.ReadString('\\n')\n\t\tif err != nil && err != io.EOF {\n\t\t\treturn err\n\t\t}\n\n\t\t// Check for bare carriage returns or newlines\n\t\tif strings.Contains(line, \"\\r\") || strings.Contains(line, \"\\n\") {\n\t\t\treturn ErrCRLF\n\t\t}\n\n\t\t// Dot stuffing: if the line starts with a dot, add an extra dot\n\t\tif strings.HasPrefix(line, \".\") {\n\t\t\tline = \".\" + line\n\t\t}\n\n\t\t_, err = w.Write([]byte(line))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// Ensure the message ends with a CRLF\n\t_, err := w.Write([]byte(\"\\r\\n.\\r\\n\"))\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n```"]}, "mox-scram/scram.go-NewServer": {"response": ["```go\nfunc NewServer(h func() hash.Hash, clientFirst []byte, cs *tls.ConnectionState, channelBindingRequired bool) (server *Server, rerr error) {\n\t// Initialize the server struct.\n\tserver = &Server{\n\t\th: h,\n\t}\n\n\t// Parse the client's first message.\n\tp := newParser(clientFirst)\n\tdefer p.recover(&rerr)\n\n\t// Extract the gs2-header, which is the first part of the client's message.\n\tgs2header := p.xtakefn1(func(c rune, i int) bool {\n\t\treturn c == 'n' || c == 'y' || c == 'p' || c == 'a' || c == '=' || c == ','\n\t})\n\tserver.gs2header = gs2header\n\n\t// Check if the client supports the PLUS variant.\n\tplusSupported := strings.Contains(gs2header, \"p=tls-unique\") || strings.Contains(gs2header, \"p=tls-exporter\")\n\n\t// If the client requires channel binding but the server does not support it, return an error.\n\tif channelBindingRequired && !plusSupported {\n\t\treturn nil, fmt.Errorf(\"%w: client requires channel binding but server does not support it\", ErrChannelBindingNotSupported)\n\t}\n\n\t// Extract the authorization ID (authzid) if present.\n\tif p.take(\"a=\") {\n\t\tserver.Authorization = p.xsaslname()\n\t}\n\n\t// Extract the authentication ID (authcid).\n\tserver.Authentication = p.xusername()\n\n\t// Extract the client nonce.\n\tserver.clientNonce = p.xnonce()\n\n\t// If the PLUS variant is supported, get the channel binding data.\n\tif plusSupported && cs != nil {\n\t\tserver.channelBinding, rerr = channelBindData(cs)\n\t\tif rerr != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to get channel binding data: %w\", rerr)\n\t\t}\n\t}\n\n\t// Generate the server nonce if not overridden.\n\tif server.serverNonceOverride == \"\" {\n\t\tserver.serverNonceOverride = base64.StdEncoding.EncodeToString(MakeRandom())\n\t}\n\tserver.nonce = server.clientNonce + server.serverNonceOverride\n\n\t// Construct the client-first-bare message.\n\tserver.clientFirstBare = fmt.Sprintf(\"n=%s,r=%s\", saslname(server.Authentication), server.clientNonce)\n\n\treturn server, nil\n}\n```"]}, "mox-scram/scram.go-ServerFirst": {"response": ["```go\nfunc (s *Server) ServerFirst(iterations int, salt []byte) (string, error) {\n\t// Generate the server nonce if not overridden.\n\tif s.serverNonceOverride == \"\" {\n\t\tnonceBytes := make([]byte, 12)\n\t\t_, err := cryptorand.Read(nonceBytes)\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"failed to generate server nonce: %w\", err)\n\t\t}\n\t\ts.serverNonceOverride = base64.StdEncoding.EncodeToString(nonceBytes)\n\t}\n\n\t// Combine client and server nonce.\n\ts.nonce = s.clientNonce + s.serverNonceOverride\n\n\t// Construct the server-first message.\n\tserverFirst := fmt.Sprintf(\"r=%s,s=%s,i=%d\", s.nonce, base64.StdEncoding.EncodeToString(salt), iterations)\n\n\t// Store the server-first message for later use.\n\ts.serverFirst = serverFirst\n\n\treturn serverFirst, nil\n}\n```"]}, "mox-scram/scram.go-Finish": {"response": ["```go\nfunc (s *Server) Finish(clientFinal []byte, saltedPassword []byte) (serverFinal string, rerr error) {\n\tdefer s.recover(&rerr)\n\n\tp := newParser(clientFinal)\n\n\t// Parse the client final message.\n\t// ../rfc/5802:1015\n\tcbindInput := p.xchannelBinding()\n\tp.xtake(\",\")\n\tnonce := p.xnonce()\n\tp.xtake(\",\")\n\tproof := p.xproof()\n\tp.xempty()\n\n\t// Verify the nonce.\n\tif nonce != s.nonce {\n\t\treturn \"\", fmt.Errorf(\"%w: nonce mismatch\", ErrProtocol)\n\t}\n\n\t// Verify the channel binding data.\n\tif !bytes.Equal(cbindInput, s.channelBinding) {\n\t\treturn \"\", fmt.Errorf(\"%w: channel binding data mismatch\", ErrChannelBindingsDontMatch)\n\t}\n\n\t// Calculate the auth message.\n\tauthMessage := s.clientFirstBare + \",\" + s.serverFirst + \",\" + string(clientFinal)\n\n\t// Calculate the server key and server signature.\n\tserverKey := hmac0(s.h, saltedPassword, \"Server Key\")\n\tserverSig := hmac0(s.h, serverKey, authMessage)\n\n\t// Verify the client proof.\n\tclientKey := hmac0(s.h, saltedPassword, \"Client Key\")\n\th := s.h()\n\th.Write(clientKey)\n\tstoredKey := h.Sum(nil)\n\tclientSig := hmac0(s.h, storedKey, authMessage)\n\txor(clientSig, clientKey) // Now clientProof.\n\tif !bytes.Equal(clientSig, proof) {\n\t\treturn \"\", fmt.Errorf(\"%w: invalid client proof\", ErrInvalidProof)\n\t}\n\n\t// Return the server final message.\n\treturn \"v=\" + base64.StdEncoding.EncodeToString(serverSig), nil\n}\n```"]}, "mox-scram/scram.go-ClientFirst": {"response": ["```go\nfunc (c *Client) ClientFirst() (clientFirst string, rerr error) {\n\t// Generate a random nonce for the client.\n\tc.clientNonce = base64.StdEncoding.EncodeToString(MakeRandom())\n\n\t// Construct the gs2-header based on whether channel binding is supported.\n\tif c.cs != nil && !c.noServerPlus {\n\t\t// Channel binding is supported.\n\t\tcbindData, err := channelBindData(c.cs)\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"failed to get channel binding data: %w\", err)\n\t\t}\n\t\tc.channelBindData = cbindData\n\t\tc.gs2header = \"p=tls-unique,\"\n\t} else {\n\t\t// No channel binding.\n\t\tc.gs2header = \"n,,\"\n\t}\n\n\t// Construct the client-first-message-bare.\n\tc.clientFirstBare = fmt.Sprintf(\"n=%s,r=%s\", saslname(c.authc), c.clientNonce)\n\n\t// Construct the full client-first message.\n\tclientFirst = c.gs2header + c.clientFirstBare\n\n\treturn clientFirst, nil\n}\n```"]}, "mox-scram/scram.go-ServerFinal": {"response": ["```go\nfunc (c *Client) ServerFinal(serverFinal []byte) (rerr error) {\n\tp := newParser(serverFinal)\n\tdefer p.recover(&rerr)\n\n\t// ../rfc/5802:1047\n\tif p.take(\"e=\") {\n\t\terrStr := p.xvalue()\n\t\tif err, ok := scramErrors[errStr]; ok {\n\t\t\treturn err\n\t\t}\n\t\treturn fmt.Errorf(\"%w: %s\", ErrOtherError, errStr)\n\t}\n\n\t// ../rfc/5802:1062\n\tserverSig := p.xproof()\n\tp.xempty()\n\n\tserverKey := hmac0(c.h, c.saltedPassword, \"Server Key\")\n\texpectedServerSig := hmac0(c.h, serverKey, c.authMessage)\n\n\tif !bytes.Equal(serverSig, expectedServerSig) {\n\t\treturn fmt.Errorf(\"%w: server signature does not match\", ErrInvalidProof)\n\t}\n\n\treturn nil\n}\n```"]}, "mox-autotls/autotls.go-SetAllowedHostnames": {"response": ["```go\nfunc (m *Manager) SetAllowedHostnames(log mlog.Log, resolver dns.Resolver, hostnames map[dns.Domain]struct{}, publicIPs []string, checkHosts bool) {\n\t// Set the new list of allowed hostnames.\n\tm.Lock()\n\tm.hosts = hostnames\n\tm.Unlock()\n\n\t// If checkHosts is true, start a goroutine to check that new hostnames are fully served by publicIPs.\n\tif checkHosts && len(publicIPs) > 0 {\n\t\tgo func() {\n\t\t\tfor host := range hostnames {\n\t\t\t\t// Resolve the host to its IP addresses.\n\t\t\t\tips, err := resolver.LookupIP(context.Background(), \"ip\", host.ASCII)\n\t\t\t\tif err != nil {\n\t\t\t\t\tlog.Errorx(\"failed to resolve host\", err, slog.String(\"host\", host.ASCII))\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// Check if all resolved IPs are in the publicIPs list.\n\t\t\t\tallServed := true\n\t\t\t\tfor _, ip := range ips {\n\t\t\t\t\tif !containsIP(publicIPs, ip.String()) {\n\t\t\t\t\t\tallServed = false\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If not all IPs are served by publicIPs, log a warning.\n\t\t\t\tif !allServed {\n\t\t\t\t\tlog.Error(\"ACME validation may fail\", slog.String(\"host\", host.ASCII), slog.Any(\"resolvedIPs\", ips), slog.Any(\"publicIPs\", publicIPs))\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n}\n\n// Helper function to check if a slice contains a specific IP.\nfunc containsIP(ips []string, ip string) bool {\n\tfor _, v := range ips {\n\t\tif v == ip {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n```"]}, "mox-autotls/autotls.go-HostPolicy": {"response": ["```go\nfunc (m *Manager) HostPolicy(ctx context.Context, host string) (rerr error) {\n\tlog := mlog.New(\"autotls\", nil).WithContext(ctx)\n\tdefer func() {\n\t\tlog.Debugx(\"host policy result\", rerr, slog.String(\"host\", host))\n\t}()\n\n\t// Check if the host is in the allowlist.\n\tm.Lock()\n\t_, allowed := m.hosts[dns.Domain(host)]\n\tm.Unlock()\n\n\tif !allowed {\n\t\treturn errHostNotAllowed\n\t}\n\n\t// Check if the system is in shutdown mode.\n\tselect {\n\tcase <-m.shutdown:\n\t\treturn fmt.Errorf(\"autotls: system is in shutdown mode, no new connections allowed\")\n\tdefault:\n\t\t// Continue if not in shutdown mode.\n\t}\n\n\treturn nil\n}\n```"]}, "mox-imapserver/protocol.go-containsSeq": {"response": ["```go\nfunc (ss numSet) containsSeq(seq msgseq, uids []store.UID, searchResult []store.UID) bool {\n\tif ss.searchResult {\n\t\t// If the numSet is a search result, we need to check if the sequence number exists in the searchResult and uids.\n\t\tuid := uids[seq-1]\n\t\treturn uidSearch(searchResult, uid) > 0 && uidSearch(uids, uid) > 0\n\t}\n\n\tfor _, r := range ss.ranges {\n\t\tfirst := r.first.number\n\t\tif r.first.star || first > uint32(len(uids)) {\n\t\t\tfirst = uint32(len(uids))\n\t\t}\n\t\tlast := first\n\t\tif r.last != nil {\n\t\t\tlast = r.last.number\n\t\t\tif r.last.star || last > uint32(len(uids)) {\n\t\t\t\tlast = uint32(len(uids))\n\t\t\t}\n\t\t}\n\t\tif first > last {\n\t\t\tfirst, last = last, first\n\t\t}\n\t\tif uint32(seq) >= first && uint32(seq) <= last {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n```"]}, "mox-imapserver/protocol.go-interpretStar": {"response": ["```go\nfunc (s numSet) interpretStar(uids []store.UID) numSet {\n\tif len(uids) == 0 {\n\t\treturn numSet{}\n\t}\n\n\tvar newRanges []numRange\n\tfor _, r := range s.ranges {\n\t\tfirst := r.first.number\n\t\tif r.first.star {\n\t\t\tfirst = uint32(uids[len(uids)-1])\n\t\t}\n\n\t\tlast := first\n\t\tif r.last != nil {\n\t\t\tlast = r.last.number\n\t\t\tif r.last.star {\n\t\t\t\tlast = uint32(uids[len(uids)-1])\n\t\t\t}\n\t\t}\n\n\t\tif first > last {\n\t\t\tfirst, last = last, first\n\t\t}\n\n\t\tnewRanges = append(newRanges, numRange{first: setNumber{number: first}, last: &setNumber{number: last}})\n\t}\n\n\treturn numSet{ranges: newRanges}\n}\n```"]}, "mox-http/web.go-ServeHTTP": {"response": ["```go\nfunc (s *serve) ServeHTTP(xw http.ResponseWriter, r *http.Request) {\n\t// Create a loggingWriter to wrap the original ResponseWriter for logging and metrics tracking.\n\tlw := &loggingWriter{\n\t\tW:     xw.(responseWriterFlusher),\n\t\tStart: time.Now(),\n\t\tR:     r,\n\t}\n\n\t// Parse the host and check if it is an IP address.\n\thost, err := dns.ParseDomain(r.Host)\n\tif err != nil {\n\t\thost = dns.IPDomain{}\n\t}\n\n\t// Try to handle the request with system handlers.\n\tfor _, h := range s.SystemHandlers {\n\t\tif h.HostMatch != nil && !h.HostMatch(host) {\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(r.URL.Path, h.Path) {\n\t\t\tlw.Handler = h.Name\n\t\t\th.Handler.ServeHTTP(lw, r)\n\t\t\tlw.Done()\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Try to handle the request with web handlers.\n\tif WebHandle(lw, r, host) {\n\t\tlw.Done()\n\t\treturn\n\t}\n\n\t// Try to handle the request with service handlers.\n\tfor _, h := range s.ServiceHandlers {\n\t\tif h.HostMatch != nil && !h.HostMatch(host) {\n\t\t\tcontinue\n\t\t}\n\t\tif strings.HasPrefix(r.URL.Path, h.Path) {\n\t\t\tlw.Handler = h.Name\n\t\t\th.Handler.ServeHTTP(lw, r)\n\t\t\tlw.Done()\n\t\t\treturn\n\t\t}\n\t}\n\n\t// If no handler matched, return a 404 Not Found response.\n\thttp.NotFound(lw, r)\n\tlw.Done()\n}\n```"]}, "mox-moxio/bufpool.go-Readline": {"response": ["```go\nfunc (b *Bufpool) Readline(log mlog.Log, r *bufio.Reader) (line string, rerr error) {\n\tbuf := b.get()\n\tdefer b.put(buf)\n\n\tvar total int\n\tvar err error\n\tvar n int\n\n\tfor {\n\t\tn, err = r.Read(buf[total:])\n\t\ttotal += n\n\n\t\tif err != nil && err != io.EOF {\n\t\t\treturn \"\", err\n\t\t}\n\n\t\t// Check for line terminators\n\t\tif total > 0 && (buf[total-1] == '\\n' || buf[total-1] == '\\r') {\n\t\t\tbreak\n\t\t}\n\n\t\t// Check if the line is too long\n\t\tif total >= b.size {\n\t\t\treturn \"\", ErrLineTooLong\n\t\t}\n\n\t\t// If we reached EOF without finding a line terminator\n\t\tif err == io.EOF {\n\t\t\treturn \"\", io.ErrUnexpectedEOF\n\t\t}\n\t}\n\n\t// Remove \\n or \\r\\n from the end of the line\n\tif total > 0 && buf[total-1] == '\\n' {\n\t\ttotal--\n\t\tif total > 0 && buf[total-1] == '\\r' {\n\t\t\ttotal--\n\t\t}\n\t}\n\n\treturn string(buf[:total]), nil\n}\n```"]}, "mox-moxio/linkcopy.go-LinkOrCopy": {"response": ["```go\npackage moxio\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\n\t\"github.com/mjl-/mox/mlog\"\n)\n\n// LinkOrCopy attempts to make a hardlink dst. If that fails, it will try to do a\n// regular file copy. If srcReaderOpt is not nil, it will be used for reading. If\n// sync is true and the file is copied, Sync is called on the file after writing to\n// ensure the file is written on disk. Callers should also sync the directory of\n// the destination file, but may want to do that after linking/copying multiple\n// files. If dst was created and an error occurred, it is removed.\nfunc LinkOrCopy(log mlog.Log, dst, src string, srcReaderOpt io.Reader, sync bool) (rerr error) {\n\t// Attempt to create a hard link\n\terr := os.Link(src, dst)\n\tif err == nil {\n\t\treturn nil // Hard link succeeded\n\t}\n\n\t// If hard link fails, attempt to copy the file\n\tsrcFile, err := os.Open(src)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"opening source file: %v\", err)\n\t}\n\tdefer srcFile.Close()\n\n\tdstFile, err := os.Create(dst)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"creating destination file: %v\", err)\n\t}\n\tdefer func() {\n\t\tif rerr != nil {\n\t\t\tos.Remove(dst) // Clean up destination file if an error occurred\n\t\t}\n\t}()\n\tdefer dstFile.Close()\n\n\tvar reader io.Reader = srcFile\n\tif srcReaderOpt != nil {\n\t\treader = srcReaderOpt\n\t}\n\n\t_, err = io.Copy(dstFile, reader)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"copying file: %v\", err)\n\t}\n\n\tif sync {\n\t\terr = dstFile.Sync()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"syncing destination file: %v\", err)\n\t\t}\n\t}\n\n\treturn nil\n}\n```"]}, "mox-moxio/base64writer.go-Base64Writer": {"response": ["```go\npackage moxio\n\nimport (\n\t\"encoding/base64\"\n\t\"io\"\n)\n\n// Base64Writer turns a writer for data into one that writes base64 content on\n// \\r\\n separated lines of max 78+2 characters length.\nfunc Base64Writer(w io.Writer) io.WriteCloser {\n\tencoder := base64.NewEncoder(base64.StdEncoding, &lineWrapper{w: w})\n\treturn struct {\n\t\tio.Writer\n\t\tio.Closer\n\t}{\n\t\tWriter: encoder,\n\t\tCloser: closerFunc(func() error {\n\t\t\terr := encoder.Close()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn nil\n\t\t}),\n\t}\n}\n```"]}, "mox-dkim/sig.go-Header": {"response": ["```go\nfunc (s *Sig) Header() (string, error) {\n\t// Initialize the header string with the DKIM-Signature field name and a colon.\n\theader := \"DKIM-Signature: \"\n\n\t// Add the required fields to the header string.\n\theader += fmt.Sprintf(\"v=%d; a=%s-%s; b=%s; bh=%s; d=%s; h=\",\n\t\ts.Version, s.AlgorithmSign, s.AlgorithmHash, base64.StdEncoding.EncodeToString(s.Signature),\n\t\tbase64.StdEncoding.EncodeToString(s.BodyHash), s.Domain.ASCII)\n\n\t// Add the signed headers to the header string.\n\tfor i, h := range s.SignedHeaders {\n\t\tif i > 0 {\n\t\t\theader += \":\"\n\t\t}\n\t\theader += h\n\t}\n\n\t// Add the selector to the header string.\n\theader += fmt.Sprintf(\"; s=%s\", s.Selector.ASCII)\n\n\t// Add optional fields to the header string if they are set.\n\tif s.Canonicalization != \"\" {\n\t\theader += fmt.Sprintf(\"; c=%s\", s.Canonicalization)\n\t}\n\tif s.Length >= 0 {\n\t\theader += fmt.Sprintf(\"; l=%d\", s.Length)\n\t}\n\tif s.Identity != nil {\n\t\theader += fmt.Sprintf(\"; i=%s\", s.Identity.String())\n\t}\n\tif len(s.QueryMethods) > 0 {\n\t\theader += \"; q=\"\n\t\tfor i, q := range s.QueryMethods {\n\t\t\tif i > 0 {\n\t\t\t\theader += \":\"\n\t\t\t}\n\t\t\theader += q\n\t\t}\n\t}\n\tif s.SignTime >= 0 {\n\t\theader += fmt.Sprintf(\"; t=%d\", s.SignTime)\n\t}\n\tif s.ExpireTime >= 0 {\n\t\theader += fmt.Sprintf(\"; x=%d\", s.ExpireTime)\n\t}\n\tif len(s.CopiedHeaders) > 0 {\n\t\theader += \"; z=\"\n\t\tfor i, h := range s.CopiedHeaders {\n\t\t\tif i > 0 {\n\t\t\t\theader += \"|\"\n\t\t\t}\n\t\t\theader += packQpHdrValue(h)\n\t\t}\n\t}\n\n\t// Add the trailing CRLF.\n\theader += \"\\r\\n\"\n\n\treturn header, nil\n}\n```"]}, "mox-dkim/txt.go-Record": {"response": ["```go\nfunc (r *Record) Record() (string, error) {\n\tvar parts []string\n\n\t// Add version if it is not the default value\n\tif r.Version != \"DKIM1\" {\n\t\tparts = append(parts, fmt.Sprintf(\"v=%s\", r.Version))\n\t}\n\n\t// Add hashes if they are not the default value\n\tif len(r.Hashes) > 0 {\n\t\thashes := strings.Join(r.Hashes, \":\")\n\t\tparts = append(parts, fmt.Sprintf(\"h=%s\", hashes))\n\t}\n\n\t// Add key type if it is not the default value\n\tif r.Key != \"rsa\" {\n\t\tparts = append(parts, fmt.Sprintf(\"k=%s\", r.Key))\n\t}\n\n\t// Add notes if present\n\tif r.Notes != \"\" {\n\t\tparts = append(parts, fmt.Sprintf(\"n=%s\", qpSection(r.Notes)))\n\t}\n\n\t// Add public key if present\n\tif len(r.Pubkey) > 0 {\n\t\tpubkey := base64.StdEncoding.EncodeToString(r.Pubkey)\n\t\tparts = append(parts, fmt.Sprintf(\"p=%s\", pubkey))\n\t} else {\n\t\t// If public key is empty, it means the key is revoked\n\t\tparts = append(parts, \"p=\")\n\t}\n\n\t// Add services if they are not the default value\n\tif len(r.Services) > 0 && !contains(r.Services, \"*\") {\n\t\tservices := strings.Join(r.Services, \":\")\n\t\tparts = append(parts, fmt.Sprintf(\"s=%s\", services))\n\t}\n\n\t// Add flags if they are not the default value\n\tif len(r.Flags) > 0 {\n\t\tflags := strings.Join(r.Flags, \":\")\n\t\tparts = append(parts, fmt.Sprintf(\"t=%s\", flags))\n\t}\n\n\treturn strings.Join(parts, \"; \"), nil\n}\n\nfunc contains(slice []string, item string) bool {\n\tfor _, s := range slice {\n\t\tif s == item {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n```"]}}